{
    "submission_name": "T5-small (Baseline)",
    "param_count": 0,
    "totto_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "mlsum_de_validation": {
        "predictions_file": "T5-small (Baseline)/mlsum_de_validation",
        "N": 11392
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 53,
        "mean_pred_length": 26.5,
        "std_pred_length": 11.5,
        "median_pred_length": 26.5,
        "min_pred_length": 15,
        "max_pred_length": 38,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 33,
        "entropy-1": 4.846240153559413,
        "distinct-2": 0.9607843137254902,
        "vocab_size-2": 49,
        "unique-2": 47,
        "entropy-2": 5.593993969422479,
        "cond_entropy-2": 0.7431138276671309,
        "distinct-3": 0.9795918367346939,
        "vocab_size-3": 48,
        "unique-3": 47,
        "entropy-3": 5.573893517584596,
        "cond_entropy-3": -0.01689917132567489,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8780487804878049,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.076825785000352,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.18233258613149267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.07594885323329875,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.89079392737262,
        "rouge1": {
            "precision": 0.39435,
            "recall": 0.42222,
            "fmeasure": 0.4043
        },
        "rouge2": {
            "precision": 0.1037,
            "recall": 0.14271,
            "fmeasure": 0.11882
        },
        "rougeL": {
            "precision": 0.30655,
            "recall": 0.36111,
            "fmeasure": 0.32639
        },
        "rougeLsum": {
            "precision": 0.30655,
            "recall": 0.36111,
            "fmeasure": 0.32639
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.2,
            "3": 0.5454545454545454
        },
        "bleu": 5.5009,
        "nubia": {
            "semantic_relation": 3.11232,
            "contradiction": 0.67765,
            "irrelevancy": 98.06842,
            "logical_agreement": 1.25393,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.44393,
            "nubia_score": 0.4827
        },
        "meteor": 0.20616054940216078,
        "bleurt": 0.062,
        "bertscore": {
            "precision": 0.79687,
            "recall": 0.85427,
            "f1": 0.81375
        }
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_validation",
        "N": 10000
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 12,
        "total_length": 151,
        "mean_pred_length": 12.583333333333334,
        "std_pred_length": 5.203497755249721,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.2847682119205298,
        "vocab_size-1": 43,
        "unique-1": 20,
        "entropy-1": 4.5157892632612855,
        "distinct-2": 0.5179856115107914,
        "vocab_size-2": 72,
        "unique-2": 42,
        "entropy-2": 5.9002251549748195,
        "cond_entropy-2": 1.300019410383121,
        "distinct-3": 0.5433070866141733,
        "vocab_size-3": 69,
        "unique-3": 39,
        "entropy-3": 5.908866969759745,
        "cond_entropy-3": 0.04891595658537886,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 4.963757537278477,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.30597014925373134,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.4167666490413655,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.659123812476188,
        "cond_entropy-2-nopunct": 1.344399831291424,
        "distinct-3-nopunct": 0.5272727272727272,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.664339826669329,
        "cond_entropy-3-nopunct": 0.01580351233852166,
        "msttr-100": 0.38,
        "msttr-100_nopunct": 0.36,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.7778716751219732,
        "rouge1": {
            "precision": 0.43092,
            "recall": 0.40283,
            "fmeasure": 0.40813
        },
        "rouge2": {
            "precision": 0.2828,
            "recall": 0.28795,
            "fmeasure": 0.28025
        },
        "rougeL": {
            "precision": 0.43092,
            "recall": 0.40283,
            "fmeasure": 0.40813
        },
        "rougeLsum": {
            "precision": 0.43092,
            "recall": 0.40283,
            "fmeasure": 0.40813
        },
        "local_recall": {
            "1": 0.17073170731707318
        },
        "bleu": 2.98386,
        "nubia": {
            "semantic_relation": 2.44535,
            "contradiction": 33.4399,
            "irrelevancy": 27.46057,
            "logical_agreement": 39.09952,
            "grammar_ref": 6.83527,
            "grammar_hyp": 6.42546,
            "nubia_score": 0.24126
        },
        "meteor": 0.08346324827679605,
        "bleurt": -0.65228,
        "bertscore": {
            "precision": 0.8195,
            "recall": 0.84649,
            "f1": 0.83254
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 2,
        "total_length": 80,
        "mean_pred_length": 40.0,
        "std_pred_length": 0.0,
        "median_pred_length": 40.0,
        "min_pred_length": 40,
        "max_pred_length": 40,
        "distinct-1": 0.4125,
        "vocab_size-1": 33,
        "unique-1": 0,
        "entropy-1": 4.93418371977919,
        "distinct-2": 0.48717948717948717,
        "vocab_size-2": 38,
        "unique-2": 0,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.2842375856242948,
        "distinct-3": 0.5,
        "vocab_size-3": 38,
        "unique-3": 0,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": 0.015156873528705471,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 38.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 38,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.42105263157894735,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.892407118592879,
        "distinct-2-nopunct": 0.4864864864864865,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.2726008523023083,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": 0.016027191368918267,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.948927856128203,
        "rouge1": {
            "precision": 0.88158,
            "recall": 0.83897,
            "fmeasure": 0.85921
        },
        "rouge2": {
            "precision": 0.64865,
            "recall": 0.61437,
            "fmeasure": 0.63063
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.45113,
            "fmeasure": 0.46184
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.45113,
            "fmeasure": 0.46184
        },
        "local_recall": {
            "1": 0.8571428571428571
        },
        "bleu": 55.14021,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2033,
            "irrelevancy": 0.42461,
            "logical_agreement": 99.37209,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.16057,
            "nubia_score": 0.96913
        },
        "meteor": 0.4794329171828729,
        "bleurt": 0.26231,
        "bertscore": {
            "precision": 0.93929,
            "recall": 0.93308,
            "f1": 0.93617
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 56,
        "mean_pred_length": 56.0,
        "std_pred_length": 0.0,
        "median_pred_length": 56.0,
        "min_pred_length": 56,
        "max_pred_length": 56,
        "distinct-1": 0.44642857142857145,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 3.7651831553653183,
        "distinct-2": 0.509090909090909,
        "vocab_size-2": 28,
        "unique-2": 22,
        "entropy-2": 4.116123803725705,
        "cond_entropy-2": 0.388071044118431,
        "distinct-3": 0.5740740740740741,
        "vocab_size-3": 31,
        "unique-3": 25,
        "entropy-3": 4.37214138178572,
        "cond_entropy-3": 0.2868552800933276,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 41.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 41,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5609756097560976,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 3.8683166381312155,
        "distinct-2-nopunct": 0.65,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.218453957701921,
        "cond_entropy-2-nopunct": 0.38736820373287867,
        "distinct-3-nopunct": 0.7435897435897436,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.587471938121898,
        "cond_entropy-3-nopunct": 0.39731218906575794,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.779644533459839,
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.46072,
            "fmeasure": 0.45599
        },
        "rouge2": {
            "precision": 0.2439,
            "recall": 0.2493,
            "fmeasure": 0.2461
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.36266,
            "fmeasure": 0.35949
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.36266,
            "fmeasure": 0.35949
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 21.25427,
        "nubia": {
            "semantic_relation": 2.97159,
            "contradiction": 51.36066,
            "irrelevancy": 37.23732,
            "logical_agreement": 11.40201,
            "grammar_ref": 4.14314,
            "grammar_hyp": 2.7071,
            "nubia_score": 0.57288
        },
        "meteor": 0.2639469042914551,
        "bleurt": -0.59242,
        "bertscore": {
            "precision": 0.91438,
            "recall": 0.8364,
            "f1": 0.87365
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064475,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.932138039759374,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.19977526577650462,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.683504233623439,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.35135,
            "fmeasure": 0.45614
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.27778,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.2973,
            "fmeasure": 0.38596
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.2973,
            "fmeasure": 0.38596
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.29411764705882354
        },
        "bleu": 38.81725,
        "nubia": {
            "semantic_relation": 3.16747,
            "contradiction": 0.25765,
            "irrelevancy": 99.5123,
            "logical_agreement": 0.23005,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.66266,
            "nubia_score": 0.30851
        },
        "meteor": 0.223995561833821,
        "bleurt": -0.25388,
        "bertscore": {
            "precision": 0.89274,
            "recall": 0.81047,
            "f1": 0.84962
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 109,
        "mean_pred_length": 109.0,
        "std_pred_length": 0.0,
        "median_pred_length": 109.0,
        "min_pred_length": 109,
        "max_pred_length": 109,
        "distinct-1": 0.3577981651376147,
        "vocab_size-1": 39,
        "unique-1": 25,
        "entropy-1": 4.409642849096349,
        "distinct-2": 0.5277777777777778,
        "vocab_size-2": 57,
        "unique-2": 43,
        "entropy-2": 5.263704430889398,
        "cond_entropy-2": 0.8666406695308336,
        "distinct-3": 0.6355140186915887,
        "vocab_size-3": 68,
        "unique-3": 55,
        "entropy-3": 5.697935744843936,
        "cond_entropy-3": 0.4388218099477576,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 72.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 72.0,
        "min_pred_length-nopunct": 72,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.4861111111111111,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.411001960450151,
        "distinct-2-nopunct": 0.704225352112676,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.384413367002744,
        "cond_entropy-2-nopunct": 0.9841004634679776,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.597579003389633,
        "cond_entropy-3-nopunct": 0.2098132614226238,
        "msttr-100": 0.36,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6843489971029246,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.50877,
            "fmeasure": 0.25013
        },
        "rouge2": {
            "precision": 0.05634,
            "recall": 0.21481,
            "fmeasure": 0.08923
        },
        "rougeL": {
            "precision": 0.13426,
            "recall": 0.4143,
            "fmeasure": 0.20199
        },
        "rougeLsum": {
            "precision": 0.13426,
            "recall": 0.4143,
            "fmeasure": 0.20199
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bleu": 5.59457,
        "nubia": {
            "semantic_relation": 2.81967,
            "contradiction": 4.81607,
            "irrelevancy": 51.10006,
            "logical_agreement": 44.08386,
            "grammar_ref": 4.75948,
            "grammar_hyp": 3.06531,
            "nubia_score": 0.07819
        },
        "meteor": 0.16786217987418234,
        "bleurt": -1.06454,
        "bertscore": {
            "precision": 0.76151,
            "recall": 0.83386,
            "f1": 0.79605
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 1.5,
        "median_pred_length": 21.5,
        "min_pred_length": 20,
        "max_pred_length": 23,
        "distinct-1": 0.627906976744186,
        "vocab_size-1": 27,
        "unique-1": 14,
        "entropy-1": 4.618011556977365,
        "distinct-2": 0.8292682926829268,
        "vocab_size-2": 34,
        "unique-2": 27,
        "entropy-2": 5.016088589983935,
        "cond_entropy-2": 0.3887235304565582,
        "distinct-3": 0.8974358974358975,
        "vocab_size-3": 35,
        "unique-3": 31,
        "entropy-3": 5.080274013734042,
        "cond_entropy-3": 0.08169636809031877,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6410256410256411,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.496815359832416,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.4309399981765246,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516393,
        "cond_entropy-3-nopunct": 0.09125822274458809,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.782253478492266,
        "rouge1": {
            "precision": 0.56413,
            "recall": 0.50614,
            "fmeasure": 0.5219
        },
        "rouge2": {
            "precision": 0.2488,
            "recall": 0.21456,
            "fmeasure": 0.225
        },
        "rougeL": {
            "precision": 0.49239,
            "recall": 0.44649,
            "fmeasure": 0.4581
        },
        "rougeLsum": {
            "precision": 0.49239,
            "recall": 0.44649,
            "fmeasure": 0.4581
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4090909090909091
        },
        "bleu": 10.94056,
        "nubia": {
            "semantic_relation": 3.41805,
            "contradiction": 0.15304,
            "irrelevancy": 97.3668,
            "logical_agreement": 2.48015,
            "grammar_ref": 3.96887,
            "grammar_hyp": 3.8815,
            "nubia_score": 0.50342
        },
        "meteor": 0.2505656073860946,
        "bleurt": -0.30032,
        "bertscore": {
            "precision": 0.84545,
            "recall": 0.82155,
            "f1": 0.83146
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7054392373313632,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.26667,
            "fmeasure": 0.2963
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.07143,
            "fmeasure": 0.08
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bleu": 5.3708,
        "nubia": {
            "semantic_relation": 2.38982,
            "contradiction": 0.31357,
            "irrelevancy": 98.7788,
            "logical_agreement": 0.90763,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.75265,
            "nubia_score": 0.17093
        },
        "meteor": 0.11753763311968543,
        "bleurt": -0.27735,
        "bertscore": {
            "precision": 0.77791,
            "recall": 0.79147,
            "f1": 0.78463
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7031594790610458,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.14286,
            "fmeasure": 0.16
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.33333,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.33333,
            "fmeasure": 0.37037
        },
        "local_recall": {
            "1": 0,
            "2": 0.46153846153846156
        },
        "bleu": 3.9989,
        "nubia": {
            "semantic_relation": 3.07302,
            "contradiction": 8.5659,
            "irrelevancy": 90.97086,
            "logical_agreement": 0.46325,
            "grammar_ref": 5.57252,
            "grammar_hyp": 5.39608,
            "nubia_score": 0.29802
        },
        "meteor": 0.17021276595744683,
        "bleurt": -0.64092,
        "bertscore": {
            "precision": 0.78279,
            "recall": 0.82199,
            "f1": 0.80191
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7454733223091325,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.55385,
            "fmeasure": 0.71053
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.44444,
            "fmeasure": 0.43915
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.47436,
            "fmeasure": 0.62939
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.47436,
            "fmeasure": 0.62939
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bleu": 31.94716,
        "nubia": {
            "semantic_relation": 3.47551,
            "contradiction": 31.71642,
            "irrelevancy": 31.75619,
            "logical_agreement": 36.52739,
            "grammar_ref": 6.66832,
            "grammar_hyp": 6.26874,
            "nubia_score": 0.56387
        },
        "meteor": 0.29854353876395345,
        "bleurt": 0.18021,
        "bertscore": {
            "precision": 0.96167,
            "recall": 0.93511,
            "f1": 0.93149
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.3572164290860831,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.456564762130954,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.3829562908893334,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2148528558815825,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.57333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.36905,
            "fmeasure": 0.43484
        },
        "rougeL": {
            "precision": 0.48889,
            "recall": 0.32889,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.48889,
            "recall": 0.32889,
            "fmeasure": 0.38889
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 31.9912,
        "nubia": {
            "semantic_relation": 3.08126,
            "contradiction": 1.12835,
            "irrelevancy": 69.50857,
            "logical_agreement": 29.36308,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.28381,
            "nubia_score": 0.37989
        },
        "meteor": 0.299219100141276,
        "bleurt": -0.4939,
        "bertscore": {
            "precision": 0.91627,
            "recall": 0.8321,
            "f1": 0.87216
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.296104175266961,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.8158639260327305,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.043068721891885896,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.402673613114325,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.311312793067121,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.05658352836636749,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.786344882381932,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.62857,
            "fmeasure": 0.73492
        },
        "rouge2": {
            "precision": 0.55769,
            "recall": 0.39132,
            "fmeasure": 0.45896
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.34048,
            "fmeasure": 0.39808
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.34048,
            "fmeasure": 0.39808
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.7142857142857143
        },
        "bleu": 43.5431,
        "nubia": {
            "semantic_relation": 3.52297,
            "contradiction": 0.51725,
            "irrelevancy": 90.62794,
            "logical_agreement": 8.8548,
            "grammar_ref": 3.72412,
            "grammar_hyp": 3.48403,
            "nubia_score": 0.52302
        },
        "meteor": 0.33317681952858696,
        "bleurt": 0.03779,
        "bertscore": {
            "precision": 0.93913,
            "recall": 0.89766,
            "f1": 0.91786
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 156,
        "mean_pred_length": 78.0,
        "std_pred_length": 8.0,
        "median_pred_length": 78.0,
        "min_pred_length": 70,
        "max_pred_length": 86,
        "distinct-1": 0.1346153846153846,
        "vocab_size-1": 21,
        "unique-1": 12,
        "entropy-1": 2.6628798048671047,
        "distinct-2": 0.2077922077922078,
        "vocab_size-2": 32,
        "unique-2": 20,
        "entropy-2": 3.763974739699553,
        "cond_entropy-2": 1.1611276934557597,
        "distinct-3": 0.24342105263157895,
        "vocab_size-3": 37,
        "unique-3": 24,
        "entropy-3": 3.998051211003548,
        "cond_entropy-3": 0.28016610026446576,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 42.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 38,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.2261904761904762,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.005633481131021,
        "distinct-2-nopunct": 0.3048780487804878,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 3.519087118338514,
        "cond_entropy-2-nopunct": 0.5368120138924685,
        "distinct-3-nopunct": 0.375,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 3.819930975215579,
        "cond_entropy-3-nopunct": 0.3718054790340538,
        "msttr-100": 0.19,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5189716315808341,
        "rouge1": {
            "precision": 0.14188,
            "recall": 0.36029,
            "fmeasure": 0.20277
        },
        "rouge2": {
            "precision": 0.01111,
            "recall": 0.03264,
            "fmeasure": 0.01658
        },
        "rougeL": {
            "precision": 0.05892,
            "recall": 0.15025,
            "fmeasure": 0.08432
        },
        "rougeLsum": {
            "precision": 0.05892,
            "recall": 0.15025,
            "fmeasure": 0.08432
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4
        },
        "bleu": 0.80057,
        "nubia": {
            "semantic_relation": 3.71036,
            "contradiction": 2.03328,
            "irrelevancy": 20.11859,
            "logical_agreement": 77.84812,
            "grammar_ref": 4.80653,
            "grammar_hyp": 1.0839,
            "nubia_score": 0.4863
        },
        "meteor": 0.1269265639165911,
        "bleurt": -0.49402,
        "bertscore": {
            "precision": 0.75917,
            "recall": 0.81025,
            "f1": 0.78105
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.5517241379310345,
        "vocab_size-1": 16,
        "unique-1": 9,
        "entropy-1": 3.71937582241537,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 21,
        "entropy-2": 4.49468036840891,
        "cond_entropy-2": 0.8159690164475464,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.680813428089397,
        "cond_entropy-3": 0.19771359870451144,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5384615384615384,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.5073801024236353,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.373660689688184,
        "cond_entropy-2-nopunct": 0.8106044718644025,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.2225599568699096,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5042114578376895,
        "rouge1": {
            "precision": 0.32692,
            "recall": 0.50347,
            "fmeasure": 0.3961
        },
        "rouge2": {
            "precision": 0.18,
            "recall": 0.28431,
            "fmeasure": 0.22024
        },
        "rougeL": {
            "precision": 0.28846,
            "recall": 0.44444,
            "fmeasure": 0.34957
        },
        "rougeLsum": {
            "precision": 0.28846,
            "recall": 0.44444,
            "fmeasure": 0.34957
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "bleu": 13.33045,
        "nubia": {
            "semantic_relation": 2.34904,
            "contradiction": 74.17095,
            "irrelevancy": 19.5166,
            "logical_agreement": 6.31246,
            "grammar_ref": 4.60656,
            "grammar_hyp": 3.0749,
            "nubia_score": 0.42342
        },
        "meteor": 0.25731006455469213,
        "bleurt": -0.2271,
        "bertscore": {
            "precision": 0.86773,
            "recall": 0.8442,
            "f1": 0.8558
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9242349747314513,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.625,
            "fmeasure": 0.57479
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.29825,
            "fmeasure": 0.27206
        },
        "rougeL": {
            "precision": 0.46875,
            "recall": 0.55,
            "fmeasure": 0.49145
        },
        "rougeLsum": {
            "precision": 0.46875,
            "recall": 0.55,
            "fmeasure": 0.49145
        },
        "local_recall": {
            "1": 0.4666666666666667,
            "2": 0.7142857142857143
        },
        "bleu": 25.77229,
        "nubia": {
            "semantic_relation": 3.06478,
            "contradiction": 58.94976,
            "irrelevancy": 36.68413,
            "logical_agreement": 4.36611,
            "grammar_ref": 5.69136,
            "grammar_hyp": 5.22061,
            "nubia_score": 0.36234
        },
        "meteor": 0.3272787325533129,
        "bleurt": 0.09664,
        "bertscore": {
            "precision": 0.85836,
            "recall": 0.88193,
            "f1": 0.86998
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 2660,
        "mean_pred_length": 16.02409638554217,
        "std_pred_length": 6.922942308554744,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4507518796992481,
        "vocab_size-1": 1199,
        "unique-1": 955,
        "entropy-1": 8.447005593840244,
        "distinct-2": 0.871692060946271,
        "vocab_size-2": 2174,
        "unique-2": 2044,
        "entropy-2": 10.866727441044743,
        "cond_entropy-2": 2.1215883765016996,
        "distinct-3": 0.9763745704467354,
        "vocab_size-3": 2273,
        "unique-3": 2231,
        "entropy-3": 11.132566735730734,
        "cond_entropy-3": 0.2836155948381216,
        "total_length-nopunct": 2346,
        "mean_pred_length-nopunct": 14.132530120481928,
        "std_pred_length-nopunct": 6.057497762332152,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5076726342710998,
        "vocab_size-1-nopunct": 1191,
        "unique-1-nopunct": 953,
        "entropy-1-nopunct": 8.761952450183266,
        "distinct-2-nopunct": 0.8784403669724771,
        "vocab_size-2-nopunct": 1915,
        "unique-2-nopunct": 1812,
        "entropy-2-nopunct": 10.68107061834719,
        "cond_entropy-2-nopunct": 2.069190443326834,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 1976,
        "unique-3-nopunct": 1943,
        "entropy-3-nopunct": 10.93599461025766,
        "cond_entropy-3-nopunct": 0.27734010487753386,
        "msttr-100": 0.71077,
        "msttr-100_nopunct": 0.75957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 12.209350771189508,
        "rouge1": {
            "precision": 0.90601,
            "recall": 0.86417,
            "fmeasure": 0.87433
        },
        "rouge2": {
            "precision": 0.80951,
            "recall": 0.77793,
            "fmeasure": 0.78068
        },
        "rougeL": {
            "precision": 0.89267,
            "recall": 0.85491,
            "fmeasure": 0.86277
        },
        "rougeLsum": {
            "precision": 0.89267,
            "recall": 0.85491,
            "fmeasure": 0.86277
        },
        "local_recall": {
            "1": 0.026121241991128634,
            "2": 0.13978494623655913,
            "3": 0.34519572953736655,
            "4": 0.4978540772532189,
            "5": 0.6774193548387096,
            "6": 0.7613636363636364,
            "7": 0.823943661971831,
            "8": 0.819935691318328,
            "9": 0.8686868686868687,
            "10": 0.9125412541254125
        },
        "bleu": 86.15387,
        "nubia": {
            "semantic_relation": 4.23681,
            "contradiction": 3.43592,
            "irrelevancy": 27.63349,
            "logical_agreement": 68.9306,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.85722,
            "nubia_score": 0.67779
        },
        "meteor": 0.5179034681931503,
        "bleurt": 0.28915,
        "bertscore": {
            "precision": 0.97501,
            "recall": 0.96519,
            "f1": 0.96697
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 82,
        "mean_pred_length": 82.0,
        "std_pred_length": 0.0,
        "median_pred_length": 82.0,
        "min_pred_length": 82,
        "max_pred_length": 82,
        "distinct-1": 0.21951219512195122,
        "vocab_size-1": 18,
        "unique-1": 10,
        "entropy-1": 3.393730828432875,
        "distinct-2": 0.2962962962962963,
        "vocab_size-2": 24,
        "unique-2": 17,
        "entropy-2": 3.72452341295657,
        "cond_entropy-2": 0.3673829694148685,
        "distinct-3": 0.35,
        "vocab_size-3": 28,
        "unique-3": 22,
        "entropy-3": 3.9366542976933783,
        "cond_entropy-3": 0.24482246711091096,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 69.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 69.0,
        "min_pred_length-nopunct": 69,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.2463768115942029,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.283486484149867,
        "distinct-2-nopunct": 0.3235294117647059,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 3.6047877857280066,
        "cond_entropy-2-nopunct": 0.36284597764620263,
        "distinct-3-nopunct": 0.3880597014925373,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 3.8600839103553124,
        "cond_entropy-3-nopunct": 0.2923509762022671,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9470163616274511,
        "rouge1": {
            "precision": 0.15244,
            "recall": 0.28788,
            "fmeasure": 0.19552
        },
        "rouge2": {
            "precision": 0.02469,
            "recall": 0.04502,
            "fmeasure": 0.03131
        },
        "rougeL": {
            "precision": 0.11585,
            "recall": 0.21818,
            "fmeasure": 0.14846
        },
        "rougeLsum": {
            "precision": 0.11585,
            "recall": 0.21818,
            "fmeasure": 0.14846
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.22727272727272727
        },
        "bleu": 1.47742,
        "nubia": {
            "semantic_relation": 3.15508,
            "contradiction": 93.17725,
            "irrelevancy": 5.04873,
            "logical_agreement": 1.77402,
            "grammar_ref": 4.34131,
            "grammar_hyp": 1.58916,
            "nubia_score": 0.43711
        },
        "meteor": 0.14246135418547448,
        "bleurt": -0.70336,
        "bertscore": {
            "precision": 0.78507,
            "recall": 0.74389,
            "f1": 0.75695
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.452819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.4905497624194164,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.3232314287976203,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.5258134337464763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2441816278287212,
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.28356,
            "fmeasure": 0.27381
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07639,
            "fmeasure": 0.0735
        },
        "rougeL": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "rougeLsum": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bleu": 6.15034,
        "nubia": {
            "semantic_relation": 1.25766,
            "contradiction": 24.30802,
            "irrelevancy": 73.51439,
            "logical_agreement": 2.17759,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.80434,
            "nubia_score": 0.10996
        },
        "meteor": 0.12124354408519472,
        "bleurt": -0.60118,
        "bertscore": {
            "precision": 0.65955,
            "recall": 0.65714,
            "f1": 0.65834
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7100667486255303,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.8022,
            "fmeasure": 0.72797
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.62393,
            "fmeasure": 0.56173
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.8022,
            "fmeasure": 0.72797
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.8022,
            "fmeasure": 0.72797
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9
        },
        "bleu": 40.21075,
        "nubia": {
            "semantic_relation": 3.15298,
            "contradiction": 86.16901,
            "irrelevancy": 6.10486,
            "logical_agreement": 7.72613,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.46877,
            "nubia_score": 0.52613
        },
        "meteor": 0.4260452572141328,
        "bleurt": 0.20913,
        "bertscore": {
            "precision": 0.91745,
            "recall": 0.95209,
            "f1": 0.93445
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.66578250153649,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.35294,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.25,
            "fmeasure": 0.25806
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bleu": 20.70317,
        "nubia": {
            "semantic_relation": 2.17157,
            "contradiction": 99.8497,
            "irrelevancy": 0.12154,
            "logical_agreement": 0.02876,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.00634,
            "nubia_score": 0.20962
        },
        "meteor": 0.21512735963051483,
        "bleurt": -0.16681,
        "bertscore": {
            "precision": 0.84619,
            "recall": 0.80411,
            "f1": 0.82461
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.18135626121219853,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.32043,
            "fmeasure": 0.34797
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.08519,
            "fmeasure": 0.09117
        },
        "rougeL": {
            "precision": 0.23333,
            "recall": 0.16559,
            "fmeasure": 0.18211
        },
        "rougeLsum": {
            "precision": 0.23333,
            "recall": 0.16559,
            "fmeasure": 0.18211
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.14285714285714285,
            "3": 0.2222222222222222
        },
        "bleu": 11.0168,
        "nubia": {
            "semantic_relation": 2.22193,
            "contradiction": 74.93439,
            "irrelevancy": 12.27789,
            "logical_agreement": 12.78772,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.45914,
            "nubia_score": 0.13811
        },
        "meteor": 0.12508677152544423,
        "bleurt": -0.5825,
        "bertscore": {
            "precision": 0.84377,
            "recall": 0.8008,
            "f1": 0.7925
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 183,
        "total_length": 2132,
        "mean_pred_length": 11.650273224043715,
        "std_pred_length": 2.2392639871254905,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.02954971857410882,
        "vocab_size-1": 63,
        "unique-1": 13,
        "entropy-1": 4.1576698093082936,
        "distinct-2": 0.05797845048742945,
        "vocab_size-2": 113,
        "unique-2": 36,
        "entropy-2": 4.755695971469638,
        "cond_entropy-2": 0.5395074716549584,
        "distinct-3": 0.06398640996602492,
        "vocab_size-3": 113,
        "unique-3": 35,
        "entropy-3": 4.68596963359436,
        "cond_entropy-3": -0.08417342344206973,
        "total_length-nopunct": 1923,
        "mean_pred_length-nopunct": 10.508196721311476,
        "std_pred_length-nopunct": 1.9582217104586637,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.031721268850754034,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.03911989870837,
        "distinct-2-nopunct": 0.05517241379310345,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.557776387789004,
        "cond_entropy-2-nopunct": 0.5405897053828757,
        "distinct-3-nopunct": 0.06165703275529865,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.4756870905792585,
        "cond_entropy-3-nopunct": -0.10104003155232871,
        "msttr-100": 0.22619,
        "msttr-100_nopunct": 0.21368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.7012123112081224,
        "rouge1": {
            "precision": 0.18466,
            "recall": 0.21579,
            "fmeasure": 0.19525
        },
        "rouge2": {
            "precision": 0.09735,
            "recall": 0.11167,
            "fmeasure": 0.1024
        },
        "rougeL": {
            "precision": 0.16857,
            "recall": 0.19832,
            "fmeasure": 0.17877
        },
        "rougeLsum": {
            "precision": 0.16857,
            "recall": 0.19832,
            "fmeasure": 0.17877
        },
        "local_recall": {
            "1": 0.13160518444666003
        },
        "bleu": 1.64787,
        "nubia": {
            "semantic_relation": 1.73734,
            "contradiction": 36.83232,
            "irrelevancy": 30.12328,
            "logical_agreement": 33.0444,
            "grammar_ref": 6.72681,
            "grammar_hyp": 5.93215,
            "nubia_score": 0.16622
        },
        "meteor": 0.07152401421539899,
        "bleurt": -0.7512,
        "bertscore": {
            "precision": 0.81296,
            "recall": 0.84785,
            "f1": 0.82998
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1194,
        "mean_pred_length": 20.586206896551722,
        "std_pred_length": 9.817357047875445,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.5,
        "vocab_size-1": 597,
        "unique-1": 478,
        "entropy-1": 8.00322235800606,
        "distinct-2": 0.9110915492957746,
        "vocab_size-2": 1035,
        "unique-2": 993,
        "entropy-2": 9.891005185015278,
        "cond_entropy-2": 1.691332108014874,
        "distinct-3": 0.9758812615955473,
        "vocab_size-3": 1052,
        "unique-3": 1040,
        "entropy-3": 10.002658484991924,
        "cond_entropy-3": 0.12186390498630545,
        "total_length-nopunct": 1064,
        "mean_pred_length-nopunct": 18.344827586206897,
        "std_pred_length-nopunct": 8.83088569802898,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5545112781954887,
        "vocab_size-1-nopunct": 590,
        "unique-1-nopunct": 476,
        "entropy-1-nopunct": 8.19903618349204,
        "distinct-2-nopunct": 0.9314115308151093,
        "vocab_size-2-nopunct": 937,
        "unique-2-nopunct": 901,
        "entropy-2-nopunct": 9.793646560436315,
        "cond_entropy-2-nopunct": 1.6946722880938518,
        "distinct-3-nopunct": 0.990506329113924,
        "vocab_size-3-nopunct": 939,
        "unique-3-nopunct": 930,
        "entropy-3-nopunct": 9.869755907126324,
        "cond_entropy-3-nopunct": 0.08716899405626752,
        "msttr-100": 0.72091,
        "msttr-100_nopunct": 0.756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 11.198996556720067,
        "rouge1": {
            "precision": 0.90462,
            "recall": 0.82861,
            "fmeasure": 0.85271
        },
        "rouge2": {
            "precision": 0.82456,
            "recall": 0.73545,
            "fmeasure": 0.76025
        },
        "rougeL": {
            "precision": 0.89758,
            "recall": 0.80683,
            "fmeasure": 0.83562
        },
        "rougeLsum": {
            "precision": 0.89758,
            "recall": 0.80683,
            "fmeasure": 0.83562
        },
        "local_recall": {
            "1": 0.03404255319148936,
            "2": 0.16279069767441862,
            "3": 0.33774834437086093,
            "4": 0.44545454545454544,
            "5": 0.6888888888888889,
            "6": 0.7115384615384616,
            "7": 0.8771929824561403,
            "8": 0.8367346938775511,
            "9": 0.8562091503267973,
            "10": 0.9342723004694836
        },
        "bleu": 86.7648,
        "nubia": {
            "semantic_relation": 4.06005,
            "contradiction": 4.95379,
            "irrelevancy": 30.4356,
            "logical_agreement": 64.61061,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.84275,
            "nubia_score": 0.60679
        },
        "meteor": 0.5045678213407102,
        "bleurt": 0.15185,
        "bertscore": {
            "precision": 0.96448,
            "recall": 0.95306,
            "f1": 0.95577
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 670,
        "mean_pred_length": 20.9375,
        "std_pred_length": 9.058619859007221,
        "median_pred_length": 20.5,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.5462686567164179,
        "vocab_size-1": 366,
        "unique-1": 295,
        "entropy-1": 7.591171402454905,
        "distinct-2": 0.9153605015673981,
        "vocab_size-2": 584,
        "unique-2": 554,
        "entropy-2": 9.108427637452452,
        "cond_entropy-2": 1.3460909694056107,
        "distinct-3": 0.9702970297029703,
        "vocab_size-3": 588,
        "unique-3": 577,
        "entropy-3": 9.170609349065314,
        "cond_entropy-3": 0.07156705689668102,
        "total_length-nopunct": 592,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 7.881941385217223,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6081081081081081,
        "vocab_size-1-nopunct": 360,
        "unique-1-nopunct": 294,
        "entropy-1-nopunct": 7.775101840847292,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 520,
        "unique-2-nopunct": 497,
        "entropy-2-nopunct": 8.955429005451556,
        "cond_entropy-2-nopunct": 1.247700957089189,
        "distinct-3-nopunct": 0.9829545454545454,
        "vocab_size-3-nopunct": 519,
        "unique-3-nopunct": 511,
        "entropy-3-nopunct": 9.008873499089109,
        "cond_entropy-3-nopunct": 0.0601932216069104,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 10.424871838336495,
        "rouge1": {
            "precision": 0.89867,
            "recall": 0.87942,
            "fmeasure": 0.87329
        },
        "rouge2": {
            "precision": 0.79862,
            "recall": 0.77901,
            "fmeasure": 0.77346
        },
        "rougeL": {
            "precision": 0.88937,
            "recall": 0.85698,
            "fmeasure": 0.85641
        },
        "rougeLsum": {
            "precision": 0.88937,
            "recall": 0.85698,
            "fmeasure": 0.85641
        },
        "local_recall": {
            "1": 0.026694045174537988,
            "2": 0.1588785046728972,
            "3": 0.323943661971831,
            "4": 0.671875,
            "5": 0.8,
            "6": 0.7205882352941176,
            "7": 0.8636363636363636,
            "8": 0.9682539682539683,
            "9": 0.9285714285714286,
            "10": 0.9274193548387096
        },
        "bleu": 88.42887,
        "nubia": {
            "semantic_relation": 4.31298,
            "contradiction": 3.22301,
            "irrelevancy": 36.18719,
            "logical_agreement": 60.58981,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.59763,
            "nubia_score": 0.6695
        },
        "meteor": 0.5284173518741988,
        "bleurt": 0.19517,
        "bertscore": {
            "precision": 0.9666,
            "recall": 0.96767,
            "f1": 0.96371
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 8.187795796183488,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.7386363636363636,
        "vocab_size-1": 65,
        "unique-1": 53,
        "entropy-1": 5.7774314773759,
        "distinct-2": 0.9879518072289156,
        "vocab_size-2": 82,
        "unique-2": 81,
        "entropy-2": 6.3509430458047635,
        "cond_entropy-2": 0.47472072784898484,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.06399618684365072,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 7.4404300950953095,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.766931830581324,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.4792139836716807,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.07001137985439648,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 7.822201215460267,
        "rouge1": {
            "precision": 0.94097,
            "recall": 0.93329,
            "fmeasure": 0.93682
        },
        "rouge2": {
            "precision": 0.91627,
            "recall": 0.8626,
            "fmeasure": 0.88588
        },
        "rougeL": {
            "precision": 0.93931,
            "recall": 0.93496,
            "fmeasure": 0.93667
        },
        "rougeLsum": {
            "precision": 0.93931,
            "recall": 0.93496,
            "fmeasure": 0.93667
        },
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.19047619047619047,
            "3": 0.375,
            "4": 0.5,
            "5": 0.5714285714285714,
            "6": 0.9230769230769231,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "bleu": 89.61615,
        "nubia": {
            "semantic_relation": 4.49155,
            "contradiction": 0.21443,
            "irrelevancy": 30.69443,
            "logical_agreement": 69.09113,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.40707,
            "nubia_score": 0.68393
        },
        "meteor": 0.6509392576082187,
        "bleurt": 0.41242,
        "bertscore": {
            "precision": 0.99093,
            "recall": 0.99015,
            "f1": 0.98811
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 602,
        "mean_pred_length": 21.5,
        "std_pred_length": 10.768671492541952,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 56,
        "distinct-1": 0.5631229235880398,
        "vocab_size-1": 339,
        "unique-1": 280,
        "entropy-1": 7.59371502810778,
        "distinct-2": 0.9146341463414634,
        "vocab_size-2": 525,
        "unique-2": 494,
        "entropy-2": 8.959422019180696,
        "cond_entropy-2": 1.2063418229287592,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 525,
        "unique-3": 510,
        "entropy-3": 9.004177419350988,
        "cond_entropy-3": 0.055293087734043365,
        "total_length-nopunct": 534,
        "mean_pred_length-nopunct": 19.071428571428573,
        "std_pred_length-nopunct": 8.786875649141132,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6235955056179775,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.719358197954192,
        "distinct-2-nopunct": 0.932806324110672,
        "vocab_size-2-nopunct": 472,
        "unique-2-nopunct": 448,
        "entropy-2-nopunct": 8.827402555023944,
        "cond_entropy-2-nopunct": 1.1721316565314455,
        "distinct-3-nopunct": 0.9811715481171548,
        "vocab_size-3-nopunct": 469,
        "unique-3-nopunct": 460,
        "entropy-3-nopunct": 8.863209904215129,
        "cond_entropy-3-nopunct": 0.04006387734148682,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 9.805298847236113,
        "rouge1": {
            "precision": 0.88523,
            "recall": 0.81916,
            "fmeasure": 0.8378
        },
        "rouge2": {
            "precision": 0.80971,
            "recall": 0.72761,
            "fmeasure": 0.74468
        },
        "rougeL": {
            "precision": 0.88155,
            "recall": 0.80245,
            "fmeasure": 0.82342
        },
        "rougeLsum": {
            "precision": 0.88155,
            "recall": 0.80245,
            "fmeasure": 0.82342
        },
        "local_recall": {
            "1": 0.025048169556840076,
            "2": 0.10526315789473684,
            "3": 0.23684210526315788,
            "4": 0.532258064516129,
            "5": 0.5483870967741935,
            "6": 0.6666666666666666,
            "7": 0.8271604938271605,
            "8": 0.8548387096774194,
            "9": 0.8545454545454545,
            "10": 0.9302325581395349
        },
        "bleu": 79.15349,
        "nubia": {
            "semantic_relation": 4.02963,
            "contradiction": 9.96702,
            "irrelevancy": 28.3988,
            "logical_agreement": 61.63417,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.90455,
            "nubia_score": 0.59071
        },
        "meteor": 0.4987368975094934,
        "bleurt": 0.05093,
        "bertscore": {
            "precision": 0.96731,
            "recall": 0.95198,
            "f1": 0.95496
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 187,
        "mean_pred_length": 26.714285714285715,
        "std_pred_length": 6.922309394048981,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 40,
        "distinct-1": 0.7005347593582888,
        "vocab_size-1": 131,
        "unique-1": 113,
        "entropy-1": 6.613945345423034,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 170,
        "unique-2": 164,
        "entropy-2": 7.35649460757077,
        "cond_entropy-2": 0.655555755431936,
        "distinct-3": 0.9884393063583815,
        "vocab_size-3": 171,
        "unique-3": 169,
        "entropy-3": 7.411506840353489,
        "cond_entropy-3": 0.04892847221225416,
        "total_length-nopunct": 165,
        "mean_pred_length-nopunct": 23.571428571428573,
        "std_pred_length-nopunct": 5.233331166861201,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.600125945230233,
        "distinct-2-nopunct": 0.9556962025316456,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.187549558451801,
        "cond_entropy-2-nopunct": 0.6213690175450212,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.238404739325059,
        "cond_entropy-3-nopunct": 0.05624338172148792,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 7.995709478602431,
        "rouge1": {
            "precision": 0.87011,
            "recall": 0.92608,
            "fmeasure": 0.89418
        },
        "rouge2": {
            "precision": 0.77896,
            "recall": 0.83182,
            "fmeasure": 0.80156
        },
        "rougeL": {
            "precision": 0.85411,
            "recall": 0.92178,
            "fmeasure": 0.88456
        },
        "rougeLsum": {
            "precision": 0.85411,
            "recall": 0.92178,
            "fmeasure": 0.88456
        },
        "local_recall": {
            "1": 0.041176470588235294,
            "2": 0.13636363636363635,
            "3": 0.6666666666666666,
            "4": 0.9166666666666666,
            "5": 0.875,
            "6": 1.0,
            "7": 0.9333333333333333,
            "8": 0.96,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "bleu": 79.29038,
        "nubia": {
            "semantic_relation": 4.34476,
            "contradiction": 2.0943,
            "irrelevancy": 47.86689,
            "logical_agreement": 50.03882,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.63586,
            "nubia_score": 0.62831
        },
        "meteor": 0.5408745827325238,
        "bleurt": 0.21891,
        "bertscore": {
            "precision": 0.97084,
            "recall": 0.97777,
            "f1": 0.97334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 71,
        "total_length": 879,
        "mean_pred_length": 12.380281690140846,
        "std_pred_length": 4.14649418245796,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.4152445961319681,
        "vocab_size-1": 365,
        "unique-1": 281,
        "entropy-1": 7.021783950769349,
        "distinct-2": 0.7685643564356436,
        "vocab_size-2": 621,
        "unique-2": 547,
        "entropy-2": 8.922786533698464,
        "cond_entropy-2": 1.602959721822294,
        "distinct-3": 0.8778833107191316,
        "vocab_size-3": 647,
        "unique-3": 597,
        "entropy-3": 9.21407025834377,
        "cond_entropy-3": 0.3088291233802579,
        "total_length-nopunct": 789,
        "mean_pred_length-nopunct": 11.112676056338028,
        "std_pred_length-nopunct": 3.686860169459239,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.45754119138149557,
        "vocab_size-1-nopunct": 361,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.171614965985812,
        "distinct-2-nopunct": 0.7715877437325905,
        "vocab_size-2-nopunct": 554,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.756241618968602,
        "cond_entropy-2-nopunct": 1.749677364259251,
        "distinct-3-nopunct": 0.8763523956723338,
        "vocab_size-3-nopunct": 567,
        "unique-3-nopunct": 521,
        "entropy-3-nopunct": 9.02675222046677,
        "cond_entropy-3-nopunct": 0.3372626879782015,
        "msttr-100": 0.6325,
        "msttr-100_nopunct": 0.66,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.915768711064927,
        "rouge1": {
            "precision": 0.736,
            "recall": 0.77128,
            "fmeasure": 0.73469
        },
        "rouge2": {
            "precision": 0.5613,
            "recall": 0.6001,
            "fmeasure": 0.565
        },
        "rougeL": {
            "precision": 0.70424,
            "recall": 0.74628,
            "fmeasure": 0.70704
        },
        "rougeLsum": {
            "precision": 0.70424,
            "recall": 0.74628,
            "fmeasure": 0.70704
        },
        "local_recall": {
            "1": 0.2569832402234637,
            "2": 0.6052631578947368,
            "3": 0.7971887550200804
        },
        "bleu": 53.21825,
        "nubia": {
            "semantic_relation": 4.07684,
            "contradiction": 12.25366,
            "irrelevancy": 45.66515,
            "logical_agreement": 42.08118,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.16011,
            "nubia_score": 0.67706
        },
        "meteor": 0.41725132362078615,
        "bleurt": 0.36372,
        "bertscore": {
            "precision": 0.935,
            "recall": 0.94191,
            "f1": 0.93671
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1680,
        "mean_pred_length": 26.666666666666668,
        "std_pred_length": 9.417983473037776,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.48214285714285715,
        "vocab_size-1": 810,
        "unique-1": 654,
        "entropy-1": 8.348855483316504,
        "distinct-2": 0.9066171923314781,
        "vocab_size-2": 1466,
        "unique-2": 1403,
        "entropy-2": 10.385185447213706,
        "cond_entropy-2": 1.885062269906863,
        "distinct-3": 0.9774774774774775,
        "vocab_size-3": 1519,
        "unique-3": 1507,
        "entropy-3": 10.527900783569246,
        "cond_entropy-3": 0.1507603679008215,
        "total_length-nopunct": 1503,
        "mean_pred_length-nopunct": 23.857142857142858,
        "std_pred_length-nopunct": 8.462535818042682,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5335994677312043,
        "vocab_size-1-nopunct": 802,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.566136239857274,
        "distinct-2-nopunct": 0.9319444444444445,
        "vocab_size-2-nopunct": 1342,
        "unique-2-nopunct": 1290,
        "entropy-2-nopunct": 10.31178540120237,
        "cond_entropy-2-nopunct": 1.8113079503776621,
        "distinct-3-nopunct": 0.9941902687000727,
        "vocab_size-3-nopunct": 1369,
        "unique-3-nopunct": 1363,
        "entropy-3-nopunct": 10.414240948709965,
        "cond_entropy-3-nopunct": 0.11069393878821211,
        "msttr-100": 0.74813,
        "msttr-100_nopunct": 0.77933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 11.360070208859199,
        "rouge1": {
            "precision": 0.88151,
            "recall": 0.87043,
            "fmeasure": 0.86434
        },
        "rouge2": {
            "precision": 0.78458,
            "recall": 0.77069,
            "fmeasure": 0.76504
        },
        "rougeL": {
            "precision": 0.86645,
            "recall": 0.86069,
            "fmeasure": 0.85206
        },
        "rougeLsum": {
            "precision": 0.86645,
            "recall": 0.86069,
            "fmeasure": 0.85206
        },
        "local_recall": {
            "1": 0.03428571428571429,
            "2": 0.20218579234972678,
            "3": 0.36403508771929827,
            "4": 0.6319018404907976,
            "5": 0.7365269461077845,
            "6": 0.7849462365591398,
            "7": 0.8614457831325302,
            "8": 0.9069767441860465,
            "9": 0.9367816091954023,
            "10": 0.9398148148148148
        },
        "bleu": 84.54152,
        "nubia": {
            "semantic_relation": 4.15646,
            "contradiction": 1.94568,
            "irrelevancy": 39.49872,
            "logical_agreement": 58.5556,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.63411,
            "nubia_score": 0.5926
        },
        "meteor": 0.5345273513824441,
        "bleurt": 0.1209,
        "bertscore": {
            "precision": 0.96345,
            "recall": 0.96633,
            "f1": 0.96256
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 214,
        "total_length": 10687,
        "mean_pred_length": 49.9392523364486,
        "std_pred_length": 13.355703440638019,
        "median_pred_length": 49.0,
        "min_pred_length": 24,
        "max_pred_length": 89,
        "distinct-1": 0.1052680827173201,
        "vocab_size-1": 1125,
        "unique-1": 490,
        "entropy-1": 5.752494898936483,
        "distinct-2": 0.25427289219898785,
        "vocab_size-2": 2663,
        "unique-2": 1361,
        "entropy-2": 9.751288438713216,
        "cond_entropy-2": 3.99658730478702,
        "distinct-3": 0.4222633784969295,
        "vocab_size-3": 4332,
        "unique-3": 2554,
        "entropy-3": 11.20268711897985,
        "cond_entropy-3": 1.4815525475460716,
        "total_length-nopunct": 9881,
        "mean_pred_length-nopunct": 46.17289719626168,
        "std_pred_length-nopunct": 13.016632566910491,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.11324764699929157,
        "vocab_size-1-nopunct": 1119,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 5.651620183976193,
        "distinct-2-nopunct": 0.25850832729905865,
        "vocab_size-2-nopunct": 2499,
        "unique-2-nopunct": 1281,
        "entropy-2-nopunct": 9.644853532880598,
        "cond_entropy-2-nopunct": 4.058694389447413,
        "distinct-3-nopunct": 0.4237808103247646,
        "vocab_size-3-nopunct": 4006,
        "unique-3-nopunct": 2399,
        "entropy-3-nopunct": 11.071143489572746,
        "cond_entropy-3-nopunct": 1.455666216007831,
        "msttr-100": 0.43811,
        "msttr-100_nopunct": 0.4351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0716602972754141,
        "rouge1": {
            "precision": 0.40335,
            "recall": 0.42593,
            "fmeasure": 0.40536
        },
        "rouge2": {
            "precision": 0.17414,
            "recall": 0.20173,
            "fmeasure": 0.18052
        },
        "rougeL": {
            "precision": 0.39285,
            "recall": 0.41493,
            "fmeasure": 0.39466
        },
        "rougeLsum": {
            "precision": 0.39285,
            "recall": 0.41493,
            "fmeasure": 0.39466
        },
        "local_recall": {
            "1": 0.1023272995936461,
            "2": 0.2312357846853677,
            "3": 0.2862190812720848,
            "4": 0.2727272727272727
        },
        "bleu": 1.98455,
        "nubia": {
            "semantic_relation": 3.34609,
            "contradiction": 30.36552,
            "irrelevancy": 17.01667,
            "logical_agreement": 52.61781,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.43646,
            "nubia_score": 0.15403
        },
        "meteor": 0.13412238757884531,
        "bleurt": -0.50421,
        "bertscore": {
            "precision": 0.85958,
            "recall": 0.87363,
            "f1": 0.86582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 52,
        "total_length": 813,
        "mean_pred_length": 15.634615384615385,
        "std_pred_length": 6.495646015583309,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.4157441574415744,
        "vocab_size-1": 338,
        "unique-1": 251,
        "entropy-1": 7.078814510119606,
        "distinct-2": 0.7385019710906702,
        "vocab_size-2": 562,
        "unique-2": 476,
        "entropy-2": 8.782590207549323,
        "cond_entropy-2": 1.4892416396430717,
        "distinct-3": 0.8519040902679831,
        "vocab_size-3": 604,
        "unique-3": 548,
        "entropy-3": 9.070738842333474,
        "cond_entropy-3": 0.2907116329798775,
        "total_length-nopunct": 701,
        "mean_pred_length-nopunct": 13.48076923076923,
        "std_pred_length-nopunct": 5.436664647116566,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.47503566333808844,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.2286330878637655,
        "distinct-2-nopunct": 0.7580893682588598,
        "vocab_size-2-nopunct": 492,
        "unique-2-nopunct": 422,
        "entropy-2-nopunct": 8.616961530875246,
        "cond_entropy-2-nopunct": 1.4687013609000066,
        "distinct-3-nopunct": 0.8576214405360134,
        "vocab_size-3-nopunct": 512,
        "unique-3-nopunct": 463,
        "entropy-3-nopunct": 8.857756773076822,
        "cond_entropy-3-nopunct": 0.2816093680433579,
        "msttr-100": 0.59875,
        "msttr-100_nopunct": 0.65857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.0570559518256735,
        "rouge1": {
            "precision": 0.6901,
            "recall": 0.73732,
            "fmeasure": 0.69461
        },
        "rouge2": {
            "precision": 0.49811,
            "recall": 0.50065,
            "fmeasure": 0.48672
        },
        "rougeL": {
            "precision": 0.65247,
            "recall": 0.69452,
            "fmeasure": 0.65534
        },
        "rougeLsum": {
            "precision": 0.65247,
            "recall": 0.69452,
            "fmeasure": 0.65534
        },
        "local_recall": {
            "1": 0.23026315789473684,
            "2": 0.5567567567567567,
            "3": 0.7917737789203085
        },
        "bleu": 43.82098,
        "nubia": {
            "semantic_relation": 4.01321,
            "contradiction": 19.88599,
            "irrelevancy": 31.4934,
            "logical_agreement": 48.62061,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.95322,
            "nubia_score": 0.65999
        },
        "meteor": 0.4019274244581759,
        "bleurt": 0.31741,
        "bertscore": {
            "precision": 0.91887,
            "recall": 0.93154,
            "f1": 0.92267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 36,
        "total_length": 567,
        "mean_pred_length": 15.75,
        "std_pred_length": 5.376776192312845,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5167548500881834,
        "vocab_size-1": 293,
        "unique-1": 238,
        "entropy-1": 7.286345517176178,
        "distinct-2": 0.8135593220338984,
        "vocab_size-2": 432,
        "unique-2": 388,
        "entropy-2": 8.533041403014305,
        "cond_entropy-2": 1.0223524557583747,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 450,
        "unique-3": 426,
        "entropy-3": 8.716862290689608,
        "cond_entropy-3": 0.1690793913529775,
        "total_length-nopunct": 498,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.362084109434133,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.570281124497992,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 234,
        "entropy-1-nopunct": 7.3847797249626685,
        "distinct-2-nopunct": 0.8116883116883117,
        "vocab_size-2-nopunct": 375,
        "unique-2-nopunct": 336,
        "entropy-2-nopunct": 8.329857780649267,
        "cond_entropy-2-nopunct": 0.9987601094964352,
        "distinct-3-nopunct": 0.9084507042253521,
        "vocab_size-3-nopunct": 387,
        "unique-3-nopunct": 366,
        "entropy-3-nopunct": 8.496953252819365,
        "cond_entropy-3-nopunct": 0.1648259836383366,
        "msttr-100": 0.694,
        "msttr-100_nopunct": 0.7325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.172505286154189,
        "rouge1": {
            "precision": 0.72392,
            "recall": 0.70458,
            "fmeasure": 0.69722
        },
        "rouge2": {
            "precision": 0.51589,
            "recall": 0.50833,
            "fmeasure": 0.49892
        },
        "rougeL": {
            "precision": 0.64508,
            "recall": 0.62832,
            "fmeasure": 0.62158
        },
        "rougeLsum": {
            "precision": 0.64508,
            "recall": 0.62832,
            "fmeasure": 0.62158
        },
        "local_recall": {
            "1": 0.19801980198019803,
            "2": 0.49206349206349204,
            "3": 0.7331378299120235
        },
        "bleu": 42.51352,
        "nubia": {
            "semantic_relation": 3.92198,
            "contradiction": 16.6999,
            "irrelevancy": 39.32352,
            "logical_agreement": 43.97658,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.64112,
            "nubia_score": 0.65798
        },
        "meteor": 0.364653037831164,
        "bleurt": 0.18205,
        "bertscore": {
            "precision": 0.92192,
            "recall": 0.91452,
            "f1": 0.9164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 41,
        "total_length": 610,
        "mean_pred_length": 14.878048780487806,
        "std_pred_length": 4.8044447000323816,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4360655737704918,
        "vocab_size-1": 266,
        "unique-1": 212,
        "entropy-1": 6.888456643024323,
        "distinct-2": 0.773286467486819,
        "vocab_size-2": 440,
        "unique-2": 398,
        "entropy-2": 8.447405084688272,
        "cond_entropy-2": 1.3407543222131457,
        "distinct-3": 0.8674242424242424,
        "vocab_size-3": 458,
        "unique-3": 433,
        "entropy-3": 8.648282061298445,
        "cond_entropy-3": 0.23381314149299368,
        "total_length-nopunct": 523,
        "mean_pred_length-nopunct": 12.75609756097561,
        "std_pred_length-nopunct": 4.218313660317748,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.497131931166348,
        "vocab_size-1-nopunct": 260,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.018193170363333,
        "distinct-2-nopunct": 0.8008298755186722,
        "vocab_size-2-nopunct": 386,
        "unique-2-nopunct": 355,
        "entropy-2-nopunct": 8.288161968711206,
        "cond_entropy-2-nopunct": 1.3939304536014188,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 387,
        "unique-3-nopunct": 367,
        "entropy-3-nopunct": 8.421855010643936,
        "cond_entropy-3-nopunct": 0.18497155002394788,
        "msttr-100": 0.63167,
        "msttr-100_nopunct": 0.65,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.013542421583005,
        "rouge1": {
            "precision": 0.72159,
            "recall": 0.74555,
            "fmeasure": 0.72145
        },
        "rouge2": {
            "precision": 0.505,
            "recall": 0.51804,
            "fmeasure": 0.50266
        },
        "rougeL": {
            "precision": 0.61233,
            "recall": 0.63966,
            "fmeasure": 0.61514
        },
        "rougeLsum": {
            "precision": 0.61233,
            "recall": 0.63966,
            "fmeasure": 0.61514
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5289256198347108,
            "3": 0.7909090909090909
        },
        "bleu": 41.58321,
        "nubia": {
            "semantic_relation": 4.06178,
            "contradiction": 7.08655,
            "irrelevancy": 37.42061,
            "logical_agreement": 55.49284,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.36869,
            "nubia_score": 0.70511
        },
        "meteor": 0.3980273495660026,
        "bleurt": 0.33663,
        "bertscore": {
            "precision": 0.91933,
            "recall": 0.92704,
            "f1": 0.92103
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 2706,
        "mean_pred_length": 15.551724137931034,
        "std_pred_length": 6.578891044254798,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.45048041389504806,
        "vocab_size-1": 1219,
        "unique-1": 958,
        "entropy-1": 8.497038362964341,
        "distinct-2": 0.8834913112164297,
        "vocab_size-2": 2237,
        "unique-2": 2114,
        "entropy-2": 10.931247549293237,
        "cond_entropy-2": 2.120658864331014,
        "distinct-3": 0.9838846480067854,
        "vocab_size-3": 2320,
        "unique-3": 2290,
        "entropy-3": 11.168556187875387,
        "cond_entropy-3": 0.2552445367496283,
        "total_length-nopunct": 2412,
        "mean_pred_length-nopunct": 13.862068965517242,
        "std_pred_length-nopunct": 5.910583559872261,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5024875621890548,
        "vocab_size-1-nopunct": 1212,
        "unique-1-nopunct": 958,
        "entropy-1-nopunct": 8.80703410796404,
        "distinct-2-nopunct": 0.8882931188561215,
        "vocab_size-2-nopunct": 1988,
        "unique-2-nopunct": 1889,
        "entropy-2-nopunct": 10.756036223836615,
        "cond_entropy-2-nopunct": 2.098383052107562,
        "distinct-3-nopunct": 0.9869186046511628,
        "vocab_size-3-nopunct": 2037,
        "unique-3-nopunct": 2013,
        "entropy-3-nopunct": 10.983967244519189,
        "cond_entropy-3-nopunct": 0.2512067032870083,
        "msttr-100": 0.71519,
        "msttr-100_nopunct": 0.7625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 9.834937737115357,
        "rouge1": {
            "precision": 0.88293,
            "recall": 0.79089,
            "fmeasure": 0.82117
        },
        "rouge2": {
            "precision": 0.7462,
            "recall": 0.66103,
            "fmeasure": 0.6876
        },
        "rougeL": {
            "precision": 0.85322,
            "recall": 0.76134,
            "fmeasure": 0.79144
        },
        "rougeLsum": {
            "precision": 0.85322,
            "recall": 0.76134,
            "fmeasure": 0.79144
        },
        "local_recall": {
            "1": 0.03830010493179433,
            "2": 0.1485148514851485,
            "3": 0.4021164021164021,
            "4": 0.5161290322580645,
            "5": 0.6625386996904025,
            "6": 0.7477611940298508,
            "7": 0.8472573839662447
        },
        "bleu": 70.0837,
        "nubia": {
            "semantic_relation": 4.25386,
            "contradiction": 4.4653,
            "irrelevancy": 14.81421,
            "logical_agreement": 80.72049,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.04846,
            "nubia_score": 0.68626
        },
        "meteor": 0.4577865871253264,
        "bleurt": 0.24707,
        "bertscore": {
            "precision": 0.96268,
            "recall": 0.94052,
            "f1": 0.94949
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 267,
        "total_length": 3994,
        "mean_pred_length": 14.958801498127341,
        "std_pred_length": 6.187018794205166,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.10640961442163245,
        "vocab_size-1": 425,
        "unique-1": 201,
        "entropy-1": 5.887127659793793,
        "distinct-2": 0.2583847598604776,
        "vocab_size-2": 963,
        "unique-2": 531,
        "entropy-2": 8.38985706101088,
        "cond_entropy-2": 2.444574511509028,
        "distinct-3": 0.37341040462427744,
        "vocab_size-3": 1292,
        "unique-3": 834,
        "entropy-3": 9.053210296173896,
        "cond_entropy-3": 0.8581153786834829,
        "total_length-nopunct": 3672,
        "mean_pred_length-nopunct": 13.752808988764045,
        "std_pred_length-nopunct": 5.879465119133731,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.11492374727668846,
        "vocab_size-1-nopunct": 422,
        "unique-1-nopunct": 201,
        "entropy-1-nopunct": 5.892053326382245,
        "distinct-2-nopunct": 0.23994126284875184,
        "vocab_size-2-nopunct": 817,
        "unique-2-nopunct": 446,
        "entropy-2-nopunct": 8.102313556386765,
        "cond_entropy-2-nopunct": 2.553262631314543,
        "distinct-3-nopunct": 0.35850860420650094,
        "vocab_size-3-nopunct": 1125,
        "unique-3-nopunct": 733,
        "entropy-3-nopunct": 8.789675099778057,
        "cond_entropy-3-nopunct": 0.9196093767805269,
        "msttr-100": 0.45846,
        "msttr-100_nopunct": 0.46778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.4147164733493318,
        "rouge1": {
            "precision": 0.43684,
            "recall": 0.52756,
            "fmeasure": 0.46205
        },
        "rouge2": {
            "precision": 0.23433,
            "recall": 0.29315,
            "fmeasure": 0.25004
        },
        "rougeL": {
            "precision": 0.39384,
            "recall": 0.47259,
            "fmeasure": 0.41561
        },
        "rougeLsum": {
            "precision": 0.39384,
            "recall": 0.47259,
            "fmeasure": 0.41561
        },
        "local_recall": {
            "1": 0.3052788844621514
        },
        "bleu": 4.55897,
        "nubia": {
            "semantic_relation": 3.00804,
            "contradiction": 39.68045,
            "irrelevancy": 24.27437,
            "logical_agreement": 36.04518,
            "grammar_ref": 7.44295,
            "grammar_hyp": 6.45127,
            "nubia_score": 0.33104
        },
        "meteor": 0.14517975676276026,
        "bleurt": -0.62339,
        "bertscore": {
            "precision": 0.82726,
            "recall": 0.86155,
            "f1": 0.84377
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 500,
        "total_length": 12996,
        "mean_pred_length": 25.992,
        "std_pred_length": 12.537780345818794,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.108264081255771,
        "vocab_size-1": 1407,
        "unique-1": 537,
        "entropy-1": 7.785231742909025,
        "distinct-2": 0.3146606914212548,
        "vocab_size-2": 3932,
        "unique-2": 2143,
        "entropy-2": 10.882430194462907,
        "cond_entropy-2": 2.94959166054438,
        "distinct-3": 0.5035011670556853,
        "vocab_size-3": 6040,
        "unique-3": 4054,
        "entropy-3": 11.972519010050945,
        "cond_entropy-3": 1.140426540773478,
        "total_length-nopunct": 11442,
        "mean_pred_length-nopunct": 22.884,
        "std_pred_length-nopunct": 11.24128747074818,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.1221814368117462,
        "vocab_size-1-nopunct": 1398,
        "unique-1-nopunct": 537,
        "entropy-1-nopunct": 8.065627385285332,
        "distinct-2-nopunct": 0.3325717419118991,
        "vocab_size-2-nopunct": 3639,
        "unique-2-nopunct": 2054,
        "entropy-2-nopunct": 10.797315514588782,
        "cond_entropy-2-nopunct": 2.8596518099482493,
        "distinct-3-nopunct": 0.5192491859796974,
        "vocab_size-3-nopunct": 5422,
        "unique-3-nopunct": 3724,
        "entropy-3-nopunct": 11.826920662276594,
        "cond_entropy-3-nopunct": 1.085553858258638,
        "msttr-100": 0.60798,
        "msttr-100_nopunct": 0.65289,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.040999337644782,
        "rouge1": {
            "precision": 0.63254,
            "recall": 0.63404,
            "fmeasure": 0.62526
        },
        "rouge2": {
            "precision": 0.37994,
            "recall": 0.38053,
            "fmeasure": 0.37493
        },
        "rougeL": {
            "precision": 0.50518,
            "recall": 0.51008,
            "fmeasure": 0.50061
        },
        "rougeLsum": {
            "precision": 0.50518,
            "recall": 0.51008,
            "fmeasure": 0.50061
        },
        "local_recall": {
            "1": 0.22099100982646874,
            "2": 0.5294117647058824,
            "3": 0.6995877397383043,
            "4": 0.7777777777777778,
            "5": 0.5454545454545454
        },
        "bleu": 37.53681,
        "nubia": {
            "semantic_relation": 3.52666,
            "contradiction": 37.91045,
            "irrelevancy": 10.17919,
            "logical_agreement": 51.91036,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.66564,
            "nubia_score": 0.54689
        },
        "meteor": 0.3126963759124584,
        "bleurt": -0.23698,
        "bertscore": {
            "precision": 0.87699,
            "recall": 0.87817,
            "f1": 0.87617
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 144,
        "total_length": 2075,
        "mean_pred_length": 14.409722222222221,
        "std_pred_length": 5.910693222227318,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.36289156626506025,
        "vocab_size-1": 753,
        "unique-1": 553,
        "entropy-1": 7.916849579064845,
        "distinct-2": 0.6866908337648887,
        "vocab_size-2": 1326,
        "unique-2": 1134,
        "entropy-2": 9.863058865692796,
        "cond_entropy-2": 1.6421117833102636,
        "distinct-3": 0.8332400671516508,
        "vocab_size-3": 1489,
        "unique-3": 1361,
        "entropy-3": 10.330231567973268,
        "cond_entropy-3": 0.46369206168877264,
        "total_length-nopunct": 1802,
        "mean_pred_length-nopunct": 12.51388888888889,
        "std_pred_length-nopunct": 5.178730688422586,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4134295227524972,
        "vocab_size-1-nopunct": 745,
        "unique-1-nopunct": 551,
        "entropy-1-nopunct": 8.175176951685483,
        "distinct-2-nopunct": 0.7104945717732207,
        "vocab_size-2-nopunct": 1178,
        "unique-2-nopunct": 1031,
        "entropy-2-nopunct": 9.690140436727047,
        "cond_entropy-2-nopunct": 1.6041003457136729,
        "distinct-3-nopunct": 0.8461030383091149,
        "vocab_size-3-nopunct": 1281,
        "unique-3-nopunct": 1180,
        "entropy-3-nopunct": 10.128298429762838,
        "cond_entropy-3-nopunct": 0.478154306400242,
        "msttr-100": 0.688,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.37168084643618,
        "rouge1": {
            "precision": 0.75259,
            "recall": 0.69268,
            "fmeasure": 0.70306
        },
        "rouge2": {
            "precision": 0.51395,
            "recall": 0.4783,
            "fmeasure": 0.48126
        },
        "rougeL": {
            "precision": 0.65797,
            "recall": 0.60607,
            "fmeasure": 0.61289
        },
        "rougeLsum": {
            "precision": 0.65797,
            "recall": 0.60607,
            "fmeasure": 0.61289
        },
        "local_recall": {
            "1": 0.24124513618677043,
            "2": 0.5253863134657837,
            "3": 0.7128404669260701
        },
        "bleu": 44.24105,
        "nubia": {
            "semantic_relation": 4.01776,
            "contradiction": 11.61356,
            "irrelevancy": 30.73427,
            "logical_agreement": 57.65216,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.77506,
            "nubia_score": 0.68546
        },
        "meteor": 0.3899838698591679,
        "bleurt": 0.20658,
        "bertscore": {
            "precision": 0.91746,
            "recall": 0.9119,
            "f1": 0.91252
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 1090,
        "mean_pred_length": 18.79310344827586,
        "std_pred_length": 9.74282869901057,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.5192660550458715,
        "vocab_size-1": 566,
        "unique-1": 458,
        "entropy-1": 8.000344237605283,
        "distinct-2": 0.9244186046511628,
        "vocab_size-2": 954,
        "unique-2": 912,
        "entropy-2": 9.812452775936123,
        "cond_entropy-2": 1.5910903420168403,
        "distinct-3": 0.9804928131416838,
        "vocab_size-3": 955,
        "unique-3": 946,
        "entropy-3": 9.873052121313467,
        "cond_entropy-3": 0.07140932464860114,
        "total_length-nopunct": 982,
        "mean_pred_length-nopunct": 16.93103448275862,
        "std_pred_length-nopunct": 8.825632865781895,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.570264765784114,
        "vocab_size-1-nopunct": 560,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 8.191767908530576,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 868,
        "unique-2-nopunct": 833,
        "entropy-2-nopunct": 9.70220271082373,
        "cond_entropy-2-nopunct": 1.608241139669232,
        "distinct-3-nopunct": 0.9919168591224018,
        "vocab_size-3-nopunct": 859,
        "unique-3-nopunct": 852,
        "entropy-3-nopunct": 9.742056932971552,
        "cond_entropy-3-nopunct": 0.049870027199102954,
        "msttr-100": 0.741,
        "msttr-100_nopunct": 0.77222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 8.311395970333036,
        "rouge1": {
            "precision": 0.84258,
            "recall": 0.71951,
            "fmeasure": 0.76012
        },
        "rouge2": {
            "precision": 0.70722,
            "recall": 0.60252,
            "fmeasure": 0.63586
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.71023,
            "fmeasure": 0.74838
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.71023,
            "fmeasure": 0.74838
        },
        "local_recall": {
            "1": 0.038686987104337635,
            "2": 0.14788732394366197,
            "3": 0.33766233766233766,
            "4": 0.41346153846153844,
            "5": 0.5865921787709497,
            "6": 0.7347670250896058,
            "7": 0.7981220657276995
        },
        "bleu": 63.39447,
        "nubia": {
            "semantic_relation": 4.08507,
            "contradiction": 5.05591,
            "irrelevancy": 13.64101,
            "logical_agreement": 81.30309,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.92524,
            "nubia_score": 0.64306
        },
        "meteor": 0.42244062772643204,
        "bleurt": 0.11074,
        "bertscore": {
            "precision": 0.95017,
            "recall": 0.92571,
            "f1": 0.93471
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 200,
        "total_length": 7152,
        "mean_pred_length": 35.76,
        "std_pred_length": 11.417635482007647,
        "median_pred_length": 34.0,
        "min_pred_length": 17,
        "max_pred_length": 85,
        "distinct-1": 0.13157158836689037,
        "vocab_size-1": 941,
        "unique-1": 473,
        "entropy-1": 5.71929919460702,
        "distinct-2": 0.3174626006904488,
        "vocab_size-2": 2207,
        "unique-2": 1285,
        "entropy-2": 9.683537516867043,
        "cond_entropy-2": 3.9488625135027244,
        "distinct-3": 0.5031101895734598,
        "vocab_size-3": 3397,
        "unique-3": 2259,
        "entropy-3": 10.980662099979131,
        "cond_entropy-3": 1.3439983378555767,
        "total_length-nopunct": 6593,
        "mean_pred_length-nopunct": 32.965,
        "std_pred_length-nopunct": 10.941379026429894,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.14166540269983316,
        "vocab_size-1-nopunct": 934,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 5.609541436289419,
        "distinct-2-nopunct": 0.31393711872360397,
        "vocab_size-2-nopunct": 2007,
        "unique-2-nopunct": 1168,
        "entropy-2-nopunct": 9.514165833884313,
        "cond_entropy-2-nopunct": 4.017445802415841,
        "distinct-3-nopunct": 0.4971742289681899,
        "vocab_size-3-nopunct": 3079,
        "unique-3-nopunct": 2067,
        "entropy-3-nopunct": 10.806357154587701,
        "cond_entropy-3-nopunct": 1.33655884387597,
        "msttr-100": 0.46211,
        "msttr-100_nopunct": 0.45385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.101778163944951,
        "rouge1": {
            "precision": 0.36967,
            "recall": 0.37373,
            "fmeasure": 0.3693
        },
        "rouge2": {
            "precision": 0.18931,
            "recall": 0.19132,
            "fmeasure": 0.18882
        },
        "rougeL": {
            "precision": 0.35482,
            "recall": 0.36091,
            "fmeasure": 0.35525
        },
        "rougeLsum": {
            "precision": 0.35482,
            "recall": 0.36091,
            "fmeasure": 0.35525
        },
        "local_recall": {
            "1": 0.10166177908113393,
            "2": 0.18346774193548387,
            "3": 0.2743823146944083,
            "4": 0.1,
            "5": 0.34615384615384615,
            "6": 0.0,
            "7": 0.16666666666666666
        },
        "bleu": 1.98675,
        "nubia": {
            "semantic_relation": 3.30061,
            "contradiction": 31.96849,
            "irrelevancy": 17.06613,
            "logical_agreement": 50.96538,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.67186,
            "nubia_score": 0.17247
        },
        "meteor": 0.1370622202458776,
        "bleurt": -0.46112,
        "bertscore": {
            "precision": 0.86407,
            "recall": 0.87569,
            "f1": 0.86918
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 32,
        "total_length": 2184,
        "mean_pred_length": 68.25,
        "std_pred_length": 5.0124844139408555,
        "median_pred_length": 69.0,
        "min_pred_length": 55,
        "max_pred_length": 76,
        "distinct-1": 0.15155677655677655,
        "vocab_size-1": 331,
        "unique-1": 147,
        "entropy-1": 5.259950868589808,
        "distinct-2": 0.3336431226765799,
        "vocab_size-2": 718,
        "unique-2": 370,
        "entropy-2": 8.597201522046905,
        "cond_entropy-2": 3.365890563907717,
        "distinct-3": 0.47358490566037736,
        "vocab_size-3": 1004,
        "unique-3": 583,
        "entropy-3": 9.475826321393763,
        "cond_entropy-3": 0.8944053439328614,
        "total_length-nopunct": 2032,
        "mean_pred_length-nopunct": 63.5,
        "std_pred_length-nopunct": 5.0373604199024715,
        "median_pred_length-nopunct": 64.0,
        "min_pred_length-nopunct": 52,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.15994094488188976,
        "vocab_size-1-nopunct": 325,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 5.1327613640502,
        "distinct-2-nopunct": 0.34,
        "vocab_size-2-nopunct": 680,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.530131045980996,
        "cond_entropy-2-nopunct": 3.445267091546869,
        "distinct-3-nopunct": 0.4796747967479675,
        "vocab_size-3-nopunct": 944,
        "unique-3-nopunct": 548,
        "entropy-3-nopunct": 9.403622984786182,
        "cond_entropy-3-nopunct": 0.8865460203074619,
        "msttr-100": 0.44571,
        "msttr-100_nopunct": 0.4475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2524961037564886,
        "rouge1": {
            "precision": 0.74209,
            "recall": 0.74795,
            "fmeasure": 0.72064
        },
        "rouge2": {
            "precision": 0.41922,
            "recall": 0.47066,
            "fmeasure": 0.41842
        },
        "rougeL": {
            "precision": 0.69727,
            "recall": 0.70537,
            "fmeasure": 0.67671
        },
        "rougeLsum": {
            "precision": 0.69727,
            "recall": 0.70537,
            "fmeasure": 0.67671
        },
        "local_recall": {
            "1": 0.09310344827586207,
            "2": 0.18568232662192394,
            "3": 0.2715654952076677
        },
        "bleu": 1.21993,
        "nubia": {
            "semantic_relation": 3.28011,
            "contradiction": 33.09144,
            "irrelevancy": 21.5788,
            "logical_agreement": 45.32975,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.41826,
            "nubia_score": 0.14328
        },
        "meteor": 0.12597740703858282,
        "bleurt": -0.48102,
        "bertscore": {
            "precision": 0.86403,
            "recall": 0.86714,
            "f1": 0.86527
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 47,
        "total_length": 750,
        "mean_pred_length": 15.957446808510639,
        "std_pred_length": 5.477060272253179,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.436,
        "vocab_size-1": 327,
        "unique-1": 242,
        "entropy-1": 7.230606433103019,
        "distinct-2": 0.7724039829302988,
        "vocab_size-2": 543,
        "unique-2": 480,
        "entropy-2": 8.79728823575653,
        "cond_entropy-2": 1.3484077756596022,
        "distinct-3": 0.8704268292682927,
        "vocab_size-3": 571,
        "unique-3": 542,
        "entropy-3": 8.978091824966263,
        "cond_entropy-3": 0.20255582508430658,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 13.382978723404255,
        "std_pred_length-nopunct": 4.359158573352478,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5103338632750397,
        "vocab_size-1-nopunct": 321,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.449558553209552,
        "distinct-2-nopunct": 0.7955326460481099,
        "vocab_size-2-nopunct": 463,
        "unique-2-nopunct": 423,
        "entropy-2-nopunct": 8.563714168959491,
        "cond_entropy-2-nopunct": 1.2024419936042345,
        "distinct-3-nopunct": 0.8803738317757009,
        "vocab_size-3-nopunct": 471,
        "unique-3-nopunct": 453,
        "entropy-3-nopunct": 8.701869655405769,
        "cond_entropy-3-nopunct": 0.1702948792978646,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.8769042143932815,
        "rouge1": {
            "precision": 0.69176,
            "recall": 0.69292,
            "fmeasure": 0.67757
        },
        "rouge2": {
            "precision": 0.43493,
            "recall": 0.42338,
            "fmeasure": 0.42118
        },
        "rougeL": {
            "precision": 0.60069,
            "recall": 0.58899,
            "fmeasure": 0.58189
        },
        "rougeLsum": {
            "precision": 0.60069,
            "recall": 0.58899,
            "fmeasure": 0.58189
        },
        "local_recall": {
            "1": 0.15862068965517243,
            "2": 0.30935251798561153,
            "3": 0.7139784946236559
        },
        "bleu": 39.24842,
        "nubia": {
            "semantic_relation": 3.80658,
            "contradiction": 19.37908,
            "irrelevancy": 26.3096,
            "logical_agreement": 54.31132,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.33493,
            "nubia_score": 0.63051
        },
        "meteor": 0.3569353363773564,
        "bleurt": 0.23382,
        "bertscore": {
            "precision": 0.90784,
            "recall": 0.9093,
            "f1": 0.90707
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 481,
        "mean_pred_length": 21.863636363636363,
        "std_pred_length": 10.150214751626304,
        "median_pred_length": 19.5,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.5841995841995842,
        "vocab_size-1": 281,
        "unique-1": 235,
        "entropy-1": 7.305374265212681,
        "distinct-2": 0.9433551198257081,
        "vocab_size-2": 433,
        "unique-2": 418,
        "entropy-2": 8.702522871807414,
        "cond_entropy-2": 1.25723804227002,
        "distinct-3": 0.9954233409610984,
        "vocab_size-3": 435,
        "unique-3": 433,
        "entropy-3": 8.762336151422726,
        "cond_entropy-3": 0.0645643193759982,
        "total_length-nopunct": 431,
        "mean_pred_length-nopunct": 19.59090909090909,
        "std_pred_length-nopunct": 9.22279335968078,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6403712296983759,
        "vocab_size-1-nopunct": 276,
        "unique-1-nopunct": 234,
        "entropy-1-nopunct": 7.43919108663722,
        "distinct-2-nopunct": 0.9437652811735942,
        "vocab_size-2-nopunct": 386,
        "unique-2-nopunct": 373,
        "entropy-2-nopunct": 8.535551355765213,
        "cond_entropy-2-nopunct": 1.1557412052971814,
        "distinct-3-nopunct": 0.9974160206718347,
        "vocab_size-3-nopunct": 386,
        "unique-3-nopunct": 385,
        "entropy-3-nopunct": 8.591021797488057,
        "cond_entropy-3-nopunct": 0.06086818047713247,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 8.284776785569115,
        "rouge1": {
            "precision": 0.84355,
            "recall": 0.77727,
            "fmeasure": 0.78926
        },
        "rouge2": {
            "precision": 0.71492,
            "recall": 0.65462,
            "fmeasure": 0.66532
        },
        "rougeL": {
            "precision": 0.81777,
            "recall": 0.75945,
            "fmeasure": 0.76863
        },
        "rougeLsum": {
            "precision": 0.81777,
            "recall": 0.75945,
            "fmeasure": 0.76863
        },
        "local_recall": {
            "1": 0.03666666666666667,
            "2": 0.15254237288135594,
            "3": 0.375,
            "4": 0.4897959183673469,
            "5": 0.581081081081081,
            "6": 0.7777777777777778,
            "7": 0.875
        },
        "bleu": 69.84115,
        "nubia": {
            "semantic_relation": 4.21215,
            "contradiction": 2.48888,
            "irrelevancy": 17.53866,
            "logical_agreement": 79.97246,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.79419,
            "nubia_score": 0.67898
        },
        "meteor": 0.4583122395734836,
        "bleurt": 0.23608,
        "bertscore": {
            "precision": 0.95439,
            "recall": 0.94146,
            "f1": 0.94563
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 3.0912061651652345,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8863636363636364,
        "vocab_size-1": 39,
        "unique-1": 35,
        "entropy-1": 5.21500235722449,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.0444618493954204,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.926829268292683,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.211210541203447,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.0482702456676074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 3.793713425366018,
        "rouge1": {
            "precision": 0.87434,
            "recall": 0.67501,
            "fmeasure": 0.75992
        },
        "rouge2": {
            "precision": 0.70938,
            "recall": 0.51453,
            "fmeasure": 0.59306
        },
        "rougeL": {
            "precision": 0.8373,
            "recall": 0.64507,
            "fmeasure": 0.72682
        },
        "rougeLsum": {
            "precision": 0.8373,
            "recall": 0.64507,
            "fmeasure": 0.72682
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.06666666666666667,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.5714285714285714,
            "7": 0.75
        },
        "bleu": 48.38841,
        "nubia": {
            "semantic_relation": 4.13486,
            "contradiction": 0.41362,
            "irrelevancy": 19.20059,
            "logical_agreement": 80.38578,
            "grammar_ref": 4.54431,
            "grammar_hyp": 5.34327,
            "nubia_score": 0.63831
        },
        "meteor": 0.3810052935344372,
        "bleurt": 0.24354,
        "bertscore": {
            "precision": 0.95108,
            "recall": 0.91695,
            "f1": 0.93188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 59,
        "total_length": 894,
        "mean_pred_length": 15.152542372881356,
        "std_pred_length": 4.624230799332217,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.4664429530201342,
        "vocab_size-1": 417,
        "unique-1": 336,
        "entropy-1": 7.477710395630323,
        "distinct-2": 0.7916167664670659,
        "vocab_size-2": 661,
        "unique-2": 584,
        "entropy-2": 9.123801578230259,
        "cond_entropy-2": 1.3930998913026933,
        "distinct-3": 0.8891752577319587,
        "vocab_size-3": 690,
        "unique-3": 636,
        "entropy-3": 9.334722499430416,
        "cond_entropy-3": 0.2110025645405706,
        "total_length-nopunct": 786,
        "mean_pred_length-nopunct": 13.322033898305085,
        "std_pred_length-nopunct": 4.147454510191178,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5190839694656488,
        "vocab_size-1-nopunct": 408,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.655724285966511,
        "distinct-2-nopunct": 0.797799174690509,
        "vocab_size-2-nopunct": 580,
        "unique-2-nopunct": 517,
        "entropy-2-nopunct": 8.930096955419815,
        "cond_entropy-2-nopunct": 1.3548008947923658,
        "distinct-3-nopunct": 0.8907185628742516,
        "vocab_size-3-nopunct": 595,
        "unique-3-nopunct": 548,
        "entropy-3-nopunct": 9.122075316470312,
        "cond_entropy-3-nopunct": 0.21929346512916448,
        "msttr-100": 0.6875,
        "msttr-100_nopunct": 0.73571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.227922126180747,
        "rouge1": {
            "precision": 0.79589,
            "recall": 0.72884,
            "fmeasure": 0.75257
        },
        "rouge2": {
            "precision": 0.56443,
            "recall": 0.51571,
            "fmeasure": 0.53326
        },
        "rougeL": {
            "precision": 0.70054,
            "recall": 0.64506,
            "fmeasure": 0.66433
        },
        "rougeLsum": {
            "precision": 0.70054,
            "recall": 0.64506,
            "fmeasure": 0.66433
        },
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.49624060150375937,
            "3": 0.7683881064162754
        },
        "bleu": 48.82492,
        "nubia": {
            "semantic_relation": 4.17128,
            "contradiction": 5.99103,
            "irrelevancy": 27.26169,
            "logical_agreement": 66.74728,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.5194,
            "nubia_score": 0.74231
        },
        "meteor": 0.39502120180379935,
        "bleurt": 0.31249,
        "bertscore": {
            "precision": 0.93612,
            "recall": 0.9196,
            "f1": 0.92634
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 632,
        "mean_pred_length": 21.066666666666666,
        "std_pred_length": 11.114355082004932,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.5300632911392406,
        "vocab_size-1": 335,
        "unique-1": 261,
        "entropy-1": 7.56250217893397,
        "distinct-2": 0.9136212624584718,
        "vocab_size-2": 550,
        "unique-2": 510,
        "entropy-2": 9.0433716285654,
        "cond_entropy-2": 1.32075726984015,
        "distinct-3": 0.972027972027972,
        "vocab_size-3": 556,
        "unique-3": 542,
        "entropy-3": 9.101287814043609,
        "cond_entropy-3": 0.06789422996388625,
        "total_length-nopunct": 564,
        "mean_pred_length-nopunct": 18.8,
        "std_pred_length-nopunct": 9.748162219960573,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 329,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.675382090514505,
        "distinct-2-nopunct": 0.9232209737827716,
        "vocab_size-2-nopunct": 493,
        "unique-2-nopunct": 458,
        "entropy-2-nopunct": 8.89773797286986,
        "cond_entropy-2-nopunct": 1.2863450028690857,
        "distinct-3-nopunct": 0.9801587301587301,
        "vocab_size-3-nopunct": 494,
        "unique-3-nopunct": 484,
        "entropy-3-nopunct": 8.937597383817314,
        "cond_entropy-3-nopunct": 0.04559103548032683,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 7.554399943597349,
        "rouge1": {
            "precision": 0.76656,
            "recall": 0.67963,
            "fmeasure": 0.70458
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.52389,
            "fmeasure": 0.53161
        },
        "rougeL": {
            "precision": 0.72838,
            "recall": 0.65245,
            "fmeasure": 0.67047
        },
        "rougeLsum": {
            "precision": 0.72838,
            "recall": 0.65245,
            "fmeasure": 0.67047
        },
        "local_recall": {
            "1": 0.042986425339366516,
            "2": 0.19753086419753085,
            "3": 0.3220338983050847,
            "4": 0.36231884057971014,
            "5": 0.5760869565217391,
            "6": 0.6103896103896104,
            "7": 0.863013698630137
        },
        "bleu": 58.57757,
        "nubia": {
            "semantic_relation": 4.02649,
            "contradiction": 3.10823,
            "irrelevancy": 14.36356,
            "logical_agreement": 82.52821,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.13201,
            "nubia_score": 0.60358
        },
        "meteor": 0.42148265086964964,
        "bleurt": 0.01651,
        "bertscore": {
            "precision": 0.93975,
            "recall": 0.91913,
            "f1": 0.92635
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 188,
        "mean_pred_length": 20.88888888888889,
        "std_pred_length": 9.802997777827903,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.7074468085106383,
        "vocab_size-1": 133,
        "unique-1": 113,
        "entropy-1": 6.641532514669839,
        "distinct-2": 0.9497206703910615,
        "vocab_size-2": 170,
        "unique-2": 165,
        "entropy-2": 7.352476252100411,
        "cond_entropy-2": 0.5766020867410967,
        "distinct-3": 0.9882352941176471,
        "vocab_size-3": 168,
        "unique-3": 166,
        "entropy-3": 7.385861524372965,
        "cond_entropy-3": 0.040338541251838896,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 18.11111111111111,
        "std_pred_length-nopunct": 7.445273585667091,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.7791411042944786,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.679247992608469,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.140099690017474,
        "cond_entropy-2-nopunct": 0.4999771613999338,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.179909090014958,
        "cond_entropy-3-nopunct": 0.04767272176366712,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.82,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 6.9803378415820285,
        "rouge1": {
            "precision": 0.83953,
            "recall": 0.73683,
            "fmeasure": 0.77094
        },
        "rouge2": {
            "precision": 0.67772,
            "recall": 0.58787,
            "fmeasure": 0.60984
        },
        "rougeL": {
            "precision": 0.78918,
            "recall": 0.68797,
            "fmeasure": 0.72222
        },
        "rougeLsum": {
            "precision": 0.78918,
            "recall": 0.68797,
            "fmeasure": 0.72222
        },
        "local_recall": {
            "1": 0.07407407407407407,
            "2": 0.18181818181818182,
            "3": 0.0,
            "4": 0.9,
            "5": 0.47058823529411764,
            "6": 0.66,
            "7": 0.8095238095238095
        },
        "bleu": 58.53998,
        "nubia": {
            "semantic_relation": 3.92547,
            "contradiction": 6.40463,
            "irrelevancy": 22.63789,
            "logical_agreement": 70.95748,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.28548,
            "nubia_score": 0.52672
        },
        "meteor": 0.41745551760446203,
        "bleurt": -0.01213,
        "bertscore": {
            "precision": 0.93891,
            "recall": 0.91311,
            "f1": 0.92397
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1533,
        "mean_pred_length": 24.333333333333332,
        "std_pred_length": 9.856107606091623,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.48140900195694714,
        "vocab_size-1": 738,
        "unique-1": 583,
        "entropy-1": 8.287361143217346,
        "distinct-2": 0.9115646258503401,
        "vocab_size-2": 1340,
        "unique-2": 1277,
        "entropy-2": 10.264787674743602,
        "cond_entropy-2": 1.8098175005652721,
        "distinct-3": 0.976545842217484,
        "vocab_size-3": 1374,
        "unique-3": 1365,
        "entropy-3": 10.37581142299397,
        "cond_entropy-3": 0.12110136317109665,
        "total_length-nopunct": 1378,
        "mean_pred_length-nopunct": 21.873015873015873,
        "std_pred_length-nopunct": 8.94691941927422,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5290275761973875,
        "vocab_size-1-nopunct": 729,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 8.482310009037839,
        "distinct-2-nopunct": 0.9315589353612167,
        "vocab_size-2-nopunct": 1225,
        "unique-2-nopunct": 1173,
        "entropy-2-nopunct": 10.177174921184575,
        "cond_entropy-2-nopunct": 1.7664433159659674,
        "distinct-3-nopunct": 0.9936102236421726,
        "vocab_size-3-nopunct": 1244,
        "unique-3-nopunct": 1238,
        "entropy-3-nopunct": 10.275641850127627,
        "cond_entropy-3-nopunct": 0.10484582971595403,
        "msttr-100": 0.752,
        "msttr-100_nopunct": 0.78462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 9.069054202988967,
        "rouge1": {
            "precision": 0.82795,
            "recall": 0.7365,
            "fmeasure": 0.76031
        },
        "rouge2": {
            "precision": 0.69131,
            "recall": 0.6134,
            "fmeasure": 0.63193
        },
        "rougeL": {
            "precision": 0.80839,
            "recall": 0.72313,
            "fmeasure": 0.74432
        },
        "rougeLsum": {
            "precision": 0.80839,
            "recall": 0.72313,
            "fmeasure": 0.74432
        },
        "local_recall": {
            "1": 0.04339440694310511,
            "2": 0.19254658385093168,
            "3": 0.39361702127659576,
            "4": 0.5373134328358209,
            "5": 0.6352941176470588,
            "6": 0.7052896725440806,
            "7": 0.8169811320754717
        },
        "bleu": 62.99014,
        "nubia": {
            "semantic_relation": 4.0167,
            "contradiction": 6.20614,
            "irrelevancy": 19.15894,
            "logical_agreement": 74.63493,
            "grammar_ref": 4.43738,
            "grammar_hyp": 5.03381,
            "nubia_score": 0.59366
        },
        "meteor": 0.4347677783945292,
        "bleurt": 0.01905,
        "bertscore": {
            "precision": 0.94167,
            "recall": 0.92878,
            "f1": 0.93251
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 453,
        "total_length": 6095,
        "mean_pred_length": 13.454746136865342,
        "std_pred_length": 6.098225105624158,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 59,
        "distinct-1": 0.17079573420836752,
        "vocab_size-1": 1041,
        "unique-1": 546,
        "entropy-1": 7.228052100176713,
        "distinct-2": 0.4390287132222616,
        "vocab_size-2": 2477,
        "unique-2": 1652,
        "entropy-2": 10.319553121588,
        "cond_entropy-2": 2.8097200891173246,
        "distinct-3": 0.6344189631913664,
        "vocab_size-3": 3292,
        "unique-3": 2532,
        "entropy-3": 11.224559186177698,
        "cond_entropy-3": 1.0126187857124769,
        "total_length-nopunct": 5306,
        "mean_pred_length-nopunct": 11.713024282560706,
        "std_pred_length-nopunct": 5.322013336421916,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.1948737278552582,
        "vocab_size-1-nopunct": 1034,
        "unique-1-nopunct": 545,
        "entropy-1-nopunct": 7.481890840259947,
        "distinct-2-nopunct": 0.4316917370698537,
        "vocab_size-2-nopunct": 2095,
        "unique-2-nopunct": 1386,
        "entropy-2-nopunct": 10.067705004101832,
        "cond_entropy-2-nopunct": 2.876411860485251,
        "distinct-3-nopunct": 0.6284090909090909,
        "vocab_size-3-nopunct": 2765,
        "unique-3-nopunct": 2117,
        "entropy-3-nopunct": 10.973570720842707,
        "cond_entropy-3-nopunct": 1.0557562796536513,
        "msttr-100": 0.5085,
        "msttr-100_nopunct": 0.54208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.914955810665592,
        "rouge1": {
            "precision": 0.60554,
            "recall": 0.6358,
            "fmeasure": 0.61161
        },
        "rouge2": {
            "precision": 0.35833,
            "recall": 0.37283,
            "fmeasure": 0.35948
        },
        "rougeL": {
            "precision": 0.52592,
            "recall": 0.55237,
            "fmeasure": 0.53083
        },
        "rougeLsum": {
            "precision": 0.52592,
            "recall": 0.55237,
            "fmeasure": 0.53083
        },
        "local_recall": {
            "1": 0.2376923076923077,
            "2": 0.5604534005037783,
            "3": 0.6364870982344952,
            "4": 0.9736842105263158
        },
        "bleu": 30.54118,
        "nubia": {
            "semantic_relation": 3.38007,
            "contradiction": 42.06488,
            "irrelevancy": 11.06048,
            "logical_agreement": 46.87464,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.31184,
            "nubia_score": 0.47439
        },
        "meteor": 0.31203267464160317,
        "bleurt": -0.26182,
        "bertscore": {
            "precision": 0.87556,
            "recall": 0.88345,
            "f1": 0.87834
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 254,
        "total_length": 5282,
        "mean_pred_length": 20.79527559055118,
        "std_pred_length": 7.791413184540968,
        "median_pred_length": 19.5,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.1628171147292692,
        "vocab_size-1": 860,
        "unique-1": 505,
        "entropy-1": 5.640352152629565,
        "distinct-2": 0.37748607796340494,
        "vocab_size-2": 1898,
        "unique-2": 1228,
        "entropy-2": 9.620352013127695,
        "cond_entropy-2": 3.9148180524320964,
        "distinct-3": 0.5643066610808546,
        "vocab_size-3": 2694,
        "unique-3": 1962,
        "entropy-3": 10.727328247934356,
        "cond_entropy-3": 1.175879116488977,
        "total_length-nopunct": 4806,
        "mean_pred_length-nopunct": 18.921259842519685,
        "std_pred_length-nopunct": 7.66586286929965,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.17769454848106533,
        "vocab_size-1-nopunct": 854,
        "unique-1-nopunct": 505,
        "entropy-1-nopunct": 5.536723241743884,
        "distinct-2-nopunct": 0.3657732864674868,
        "vocab_size-2-nopunct": 1665,
        "unique-2-nopunct": 1064,
        "entropy-2-nopunct": 9.38548531348804,
        "cond_entropy-2-nopunct": 4.064489930472159,
        "distinct-3-nopunct": 0.5514192647743137,
        "vocab_size-3-nopunct": 2370,
        "unique-3-nopunct": 1731,
        "entropy-3-nopunct": 10.496931940181751,
        "cond_entropy-3-nopunct": 1.1861721681222588,
        "msttr-100": 0.45365,
        "msttr-100_nopunct": 0.45667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.082320210200626,
        "rouge1": {
            "precision": 0.32458,
            "recall": 0.32978,
            "fmeasure": 0.32532
        },
        "rouge2": {
            "precision": 0.18652,
            "recall": 0.18701,
            "fmeasure": 0.18607
        },
        "rougeL": {
            "precision": 0.32393,
            "recall": 0.32929,
            "fmeasure": 0.32476
        },
        "rougeLsum": {
            "precision": 0.32393,
            "recall": 0.32929,
            "fmeasure": 0.32476
        },
        "local_recall": {
            "1": 0.10258152173913043,
            "2": 0.1941747572815534,
            "3": 0.23208191126279865,
            "4": 0.3142857142857143,
            "5": 0.45454545454545453,
            "6": 0.3,
            "7": 0.3333333333333333
        },
        "bleu": 3.44788,
        "nubia": {
            "semantic_relation": 3.36593,
            "contradiction": 36.52709,
            "irrelevancy": 14.94715,
            "logical_agreement": 48.52575,
            "grammar_ref": 2.90382,
            "grammar_hyp": 3.00338,
            "nubia_score": 0.21292
        },
        "meteor": 0.1561430211156045,
        "bleurt": -0.37109,
        "bertscore": {
            "precision": 0.86927,
            "recall": 0.88043,
            "f1": 0.8745
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 379,
        "total_length": 8554,
        "mean_pred_length": 22.569920844327175,
        "std_pred_length": 5.86589289588805,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.32768295534252984,
        "vocab_size-1": 2803,
        "unique-1": 2019,
        "entropy-1": 9.069783965731569,
        "distinct-2": 0.7349235474006116,
        "vocab_size-2": 6008,
        "unique-2": 5163,
        "entropy-2": 12.095660024496928,
        "cond_entropy-2": 2.812622725835703,
        "distinct-3": 0.9039250897896357,
        "vocab_size-3": 7047,
        "unique-3": 6574,
        "entropy-3": 12.691741132203415,
        "cond_entropy-3": 0.5890511520920189,
        "total_length-nopunct": 7408,
        "mean_pred_length-nopunct": 19.54617414248021,
        "std_pred_length-nopunct": 5.171451456305575,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.37648488120950324,
        "vocab_size-1-nopunct": 2789,
        "unique-1-nopunct": 2019,
        "entropy-1-nopunct": 9.479801875712448,
        "distinct-2-nopunct": 0.7737942808365343,
        "vocab_size-2-nopunct": 5439,
        "unique-2-nopunct": 4796,
        "entropy-2-nopunct": 12.010973472481759,
        "cond_entropy-2-nopunct": 2.6218145000535458,
        "distinct-3-nopunct": 0.9201503759398496,
        "vocab_size-3-nopunct": 6119,
        "unique-3-nopunct": 5780,
        "entropy-3-nopunct": 12.50220115586126,
        "cond_entropy-3-nopunct": 0.5147481612963942,
        "msttr-100": 0.682,
        "msttr-100_nopunct": 0.72757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.293125767879722,
        "rouge1": {
            "precision": 0.75021,
            "recall": 0.69926,
            "fmeasure": 0.71449
        },
        "rouge2": {
            "precision": 0.47933,
            "recall": 0.44771,
            "fmeasure": 0.4569
        },
        "rougeL": {
            "precision": 0.59714,
            "recall": 0.55854,
            "fmeasure": 0.56926
        },
        "rougeLsum": {
            "precision": 0.59714,
            "recall": 0.55854,
            "fmeasure": 0.56926
        },
        "local_recall": {
            "1": 0.20535714285714285,
            "2": 0.41164095371669,
            "3": 0.7405933429811867
        },
        "bleu": 38.01901,
        "nubia": {
            "semantic_relation": 3.98548,
            "contradiction": 15.60284,
            "irrelevancy": 28.45668,
            "logical_agreement": 55.94049,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.18717,
            "nubia_score": 0.6743
        },
        "meteor": 0.36365147222218497,
        "bleurt": 0.15889,
        "bertscore": {
            "precision": 0.92061,
            "recall": 0.90796,
            "f1": 0.91274
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 159,
        "total_length": 10297,
        "mean_pred_length": 64.76100628930817,
        "std_pred_length": 8.49599174416628,
        "median_pred_length": 66.0,
        "min_pred_length": 40,
        "max_pred_length": 81,
        "distinct-1": 0.09944644071088667,
        "vocab_size-1": 1024,
        "unique-1": 408,
        "entropy-1": 5.652036604394948,
        "distinct-2": 0.23771947129611362,
        "vocab_size-2": 2410,
        "unique-2": 1121,
        "entropy-2": 9.60776486160562,
        "cond_entropy-2": 3.968580848987367,
        "distinct-3": 0.39432808898687244,
        "vocab_size-3": 3935,
        "unique-3": 2124,
        "entropy-3": 11.063853747583588,
        "cond_entropy-3": 1.4736085949500874,
        "total_length-nopunct": 9489,
        "mean_pred_length-nopunct": 59.679245283018865,
        "std_pred_length-nopunct": 8.58426288284108,
        "median_pred_length-nopunct": 61.0,
        "min_pred_length-nopunct": 34,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.1072821161344715,
        "vocab_size-1-nopunct": 1018,
        "unique-1-nopunct": 407,
        "entropy-1-nopunct": 5.55561428738457,
        "distinct-2-nopunct": 0.24480171489817792,
        "vocab_size-2-nopunct": 2284,
        "unique-2-nopunct": 1049,
        "entropy-2-nopunct": 9.55775095829724,
        "cond_entropy-2-nopunct": 4.049991583124341,
        "distinct-3-nopunct": 0.40050158107076655,
        "vocab_size-3-nopunct": 3673,
        "unique-3-nopunct": 2020,
        "entropy-3-nopunct": 10.95960979964516,
        "cond_entropy-3-nopunct": 1.4147171316256224,
        "msttr-100": 0.43569,
        "msttr-100_nopunct": 0.43468,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0843951590826695,
        "rouge1": {
            "precision": 0.44107,
            "recall": 0.38792,
            "fmeasure": 0.39413
        },
        "rouge2": {
            "precision": 0.2212,
            "recall": 0.19842,
            "fmeasure": 0.19946
        },
        "rougeL": {
            "precision": 0.41863,
            "recall": 0.36933,
            "fmeasure": 0.37441
        },
        "rougeLsum": {
            "precision": 0.41863,
            "recall": 0.36933,
            "fmeasure": 0.37441
        },
        "local_recall": {
            "1": 0.07569850552306692,
            "2": 0.1742765273311897,
            "3": 0.27486910994764396
        },
        "bleu": 1.81961,
        "nubia": {
            "semantic_relation": 3.37886,
            "contradiction": 32.63039,
            "irrelevancy": 18.07238,
            "logical_agreement": 49.29723,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.3035,
            "nubia_score": 0.12979
        },
        "meteor": 0.1223205227324709,
        "bleurt": -0.52758,
        "bertscore": {
            "precision": 0.85803,
            "recall": 0.8662,
            "f1": 0.86161
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 149,
        "total_length": 1639,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.006101281269066504,
        "vocab_size-1": 10,
        "unique-1": 0,
        "entropy-1": 3.277613436819116,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 10,
        "unique-2": 0,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 9,
        "unique-3": 0,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 1490,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.006040268456375839,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": 0.1,
        "msttr-100_nopunct": 0.09,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.48443504967205986,
        "rouge1": {
            "precision": 0.12081,
            "recall": 0.15552,
            "fmeasure": 0.13352
        },
        "rouge2": {
            "precision": 0.04773,
            "recall": 0.06125,
            "fmeasure": 0.05289
        },
        "rougeL": {
            "precision": 0.1047,
            "recall": 0.13789,
            "fmeasure": 0.11699
        },
        "rougeLsum": {
            "precision": 0.1047,
            "recall": 0.13789,
            "fmeasure": 0.11699
        },
        "local_recall": {
            "1": 0.09249329758713137
        },
        "bleu": 0.59469,
        "nubia": {
            "semantic_relation": 1.50772,
            "contradiction": 38.40245,
            "irrelevancy": 31.0367,
            "logical_agreement": 30.56085,
            "grammar_ref": 6.81129,
            "grammar_hyp": 5.95,
            "nubia_score": 0.12566
        },
        "meteor": 0.05365822040973683,
        "bleurt": -0.78718,
        "bertscore": {
            "precision": 0.80688,
            "recall": 0.84241,
            "f1": 0.82422
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 29,
        "total_length": 1975,
        "mean_pred_length": 68.10344827586206,
        "std_pred_length": 4.573875046061029,
        "median_pred_length": 69.0,
        "min_pred_length": 56,
        "max_pred_length": 77,
        "distinct-1": 0.1539240506329114,
        "vocab_size-1": 304,
        "unique-1": 132,
        "entropy-1": 5.209342975675969,
        "distinct-2": 0.3355601233299075,
        "vocab_size-2": 653,
        "unique-2": 321,
        "entropy-2": 8.498280113211997,
        "cond_entropy-2": 3.301620612257113,
        "distinct-3": 0.4731351069379238,
        "vocab_size-3": 907,
        "unique-3": 504,
        "entropy-3": 9.343177120585732,
        "cond_entropy-3": 0.849732409073405,
        "total_length-nopunct": 1805,
        "mean_pred_length-nopunct": 62.241379310344826,
        "std_pred_length-nopunct": 4.3759150563352565,
        "median_pred_length-nopunct": 63.0,
        "min_pred_length-nopunct": 53,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.16509695290858725,
        "vocab_size-1-nopunct": 298,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 5.079973008429075,
        "distinct-2-nopunct": 0.34966216216216217,
        "vocab_size-2-nopunct": 621,
        "unique-2-nopunct": 304,
        "entropy-2-nopunct": 8.457782233208412,
        "cond_entropy-2-nopunct": 3.398519977989992,
        "distinct-3-nopunct": 0.48196908986834575,
        "vocab_size-3-nopunct": 842,
        "unique-3-nopunct": 468,
        "entropy-3-nopunct": 9.255176613625085,
        "cond_entropy-3-nopunct": 0.7995556961483099,
        "msttr-100": 0.44632,
        "msttr-100_nopunct": 0.46,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.342794598415051,
        "rouge1": {
            "precision": 0.69688,
            "recall": 0.69195,
            "fmeasure": 0.66234
        },
        "rouge2": {
            "precision": 0.38621,
            "recall": 0.46316,
            "fmeasure": 0.39562
        },
        "rougeL": {
            "precision": 0.66907,
            "recall": 0.66707,
            "fmeasure": 0.63492
        },
        "rougeLsum": {
            "precision": 0.66907,
            "recall": 0.66707,
            "fmeasure": 0.63492
        },
        "local_recall": {
            "1": 0.08741258741258741,
            "2": 0.1623529411764706,
            "3": 0.2697947214076246
        },
        "bleu": 2.51651,
        "nubia": {
            "semantic_relation": 3.1757,
            "contradiction": 35.07232,
            "irrelevancy": 21.08904,
            "logical_agreement": 43.83864,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.50301,
            "nubia_score": 0.17584
        },
        "meteor": 0.13008654665200442,
        "bleurt": -0.52093,
        "bertscore": {
            "precision": 0.86131,
            "recall": 0.85938,
            "f1": 0.86019
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 105,
        "total_length": 1493,
        "mean_pred_length": 14.219047619047618,
        "std_pred_length": 8.055735551980757,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 47,
        "distinct-1": 0.4012056262558607,
        "vocab_size-1": 599,
        "unique-1": 465,
        "entropy-1": 7.699738382459798,
        "distinct-2": 0.7629682997118156,
        "vocab_size-2": 1059,
        "unique-2": 941,
        "entropy-2": 9.721961401392395,
        "cond_entropy-2": 1.7284302663220599,
        "distinct-3": 0.8752922837100545,
        "vocab_size-3": 1123,
        "unique-3": 1044,
        "entropy-3": 10.00343309818676,
        "cond_entropy-3": 0.29571447069549145,
        "total_length-nopunct": 1271,
        "mean_pred_length-nopunct": 12.104761904761904,
        "std_pred_length-nopunct": 7.181887017614997,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.46498819826907944,
        "vocab_size-1-nopunct": 591,
        "unique-1-nopunct": 463,
        "entropy-1-nopunct": 7.967070941614393,
        "distinct-2-nopunct": 0.7898799313893653,
        "vocab_size-2-nopunct": 921,
        "unique-2-nopunct": 835,
        "entropy-2-nopunct": 9.542651827326564,
        "cond_entropy-2-nopunct": 1.695723741350487,
        "distinct-3-nopunct": 0.8934967012252591,
        "vocab_size-3-nopunct": 948,
        "unique-3-nopunct": 892,
        "entropy-3-nopunct": 9.780569264780919,
        "cond_entropy-3-nopunct": 0.2638570912851891,
        "msttr-100": 0.67357,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.73326621460903,
        "rouge1": {
            "precision": 0.67408,
            "recall": 0.59817,
            "fmeasure": 0.61401
        },
        "rouge2": {
            "precision": 0.41695,
            "recall": 0.38454,
            "fmeasure": 0.3886
        },
        "rougeL": {
            "precision": 0.5823,
            "recall": 0.51445,
            "fmeasure": 0.52896
        },
        "rougeLsum": {
            "precision": 0.5823,
            "recall": 0.51445,
            "fmeasure": 0.52896
        },
        "local_recall": {
            "1": 0.20520231213872833,
            "2": 0.37770897832817335,
            "3": 0.6935483870967742
        },
        "bleu": 39.37942,
        "nubia": {
            "semantic_relation": 3.58968,
            "contradiction": 16.29306,
            "irrelevancy": 29.13919,
            "logical_agreement": 54.56774,
            "grammar_ref": 4.94529,
            "grammar_hyp": 5.12371,
            "nubia_score": 0.6002
        },
        "meteor": 0.3493796659781803,
        "bleurt": 0.12335,
        "bertscore": {
            "precision": 0.90209,
            "recall": 0.88908,
            "f1": 0.89406
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7081,
        "mean_pred_length": 19.724233983286908,
        "std_pred_length": 9.371577245470183,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.3719813585651744,
        "vocab_size-1": 2634,
        "unique-1": 1953,
        "entropy-1": 9.151215069274848,
        "distinct-2": 0.834870574233859,
        "vocab_size-2": 5612,
        "unique-2": 5195,
        "entropy-2": 12.133574363653173,
        "cond_entropy-2": 2.7162053095405403,
        "distinct-3": 0.9636963696369637,
        "vocab_size-3": 6132,
        "unique-3": 6012,
        "entropy-3": 12.519160612429554,
        "cond_entropy-3": 0.40155610144735454,
        "total_length-nopunct": 6285,
        "mean_pred_length-nopunct": 17.506963788300837,
        "std_pred_length-nopunct": 8.274828864168686,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4175019888623707,
        "vocab_size-1-nopunct": 2624,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.503038516520459,
        "distinct-2-nopunct": 0.8543705703678705,
        "vocab_size-2-nopunct": 5063,
        "unique-2-nopunct": 4719,
        "entropy-2-nopunct": 12.03345076396359,
        "cond_entropy-2-nopunct": 2.671912891716557,
        "distinct-3-nopunct": 0.9773666247530088,
        "vocab_size-3-nopunct": 5441,
        "unique-3-nopunct": 5347,
        "entropy-3-nopunct": 12.388720492085142,
        "cond_entropy-3-nopunct": 0.3797937563546693,
        "msttr-100": 0.72371,
        "msttr-100_nopunct": 0.76774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.30797632015497,
        "rouge1": {
            "precision": 0.899,
            "recall": 0.85954,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.8075,
            "recall": 0.7682,
            "fmeasure": 0.77305
        },
        "rougeL": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "rougeLsum": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "local_recall": {
            "1": 0.029768467475192944,
            "2": 0.15768194070080863,
            "3": 0.3433734939759036,
            "4": 0.5504587155963303,
            "5": 0.6965098634294385,
            "6": 0.7549295774647887,
            "7": 0.8483606557377049,
            "8": 0.864897466827503,
            "9": 0.8857142857142857,
            "10": 0.9255813953488372
        },
        "bleu": 85.93589,
        "sari": 46.92008,
        "nubia": {
            "semantic_relation": 4.19043,
            "contradiction": 3.83901,
            "irrelevancy": 31.42769,
            "logical_agreement": 64.7333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.79962,
            "nubia_score": 0.64296
        },
        "meteor": 0.5204959402607399,
        "bleurt": 0.21083,
        "bertscore": {
            "precision": 0.97007,
            "recall": 0.96322,
            "f1": 0.96358
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 253,
        "total_length": 5252,
        "mean_pred_length": 20.75889328063241,
        "std_pred_length": 7.785232927767744,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.16374714394516374,
        "vocab_size-1": 860,
        "unique-1": 505,
        "entropy-1": 5.6455444193080675,
        "distinct-2": 0.3794758951790358,
        "vocab_size-2": 1897,
        "unique-2": 1229,
        "entropy-2": 9.626149069827411,
        "cond_entropy-2": 3.9149066149366,
        "distinct-3": 0.5672144964180362,
        "vocab_size-3": 2692,
        "unique-3": 1966,
        "entropy-3": 10.73255547291129,
        "cond_entropy-3": 1.1743981790688078,
        "total_length-nopunct": 4777,
        "mean_pred_length-nopunct": 18.881422924901187,
        "std_pred_length-nopunct": 7.65471326239167,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.17877328867490055,
        "vocab_size-1-nopunct": 854,
        "unique-1-nopunct": 505,
        "entropy-1-nopunct": 5.542360998534093,
        "distinct-2-nopunct": 0.3680371352785146,
        "vocab_size-2-nopunct": 1665,
        "unique-2-nopunct": 1066,
        "entropy-2-nopunct": 9.392394300446862,
        "cond_entropy-2-nopunct": 4.065359026844233,
        "distinct-3-nopunct": 0.5546710372278155,
        "vocab_size-3-nopunct": 2369,
        "unique-3-nopunct": 1735,
        "entropy-3-nopunct": 10.503124513247231,
        "cond_entropy-3-nopunct": 1.1848610443134442,
        "msttr-100": 0.45558,
        "msttr-100_nopunct": 0.45872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0874245092614918,
        "rouge1": {
            "precision": 0.32587,
            "recall": 0.33108,
            "fmeasure": 0.32661
        },
        "rouge2": {
            "precision": 0.18725,
            "recall": 0.18775,
            "fmeasure": 0.18681
        },
        "rougeL": {
            "precision": 0.32521,
            "recall": 0.33059,
            "fmeasure": 0.32604
        },
        "rougeLsum": {
            "precision": 0.32521,
            "recall": 0.33059,
            "fmeasure": 0.32604
        },
        "local_recall": {
            "1": 0.10307167235494881,
            "2": 0.19525801952580196,
            "3": 0.23208191126279865,
            "4": 0.3142857142857143,
            "5": 0.45454545454545453,
            "6": 0.3,
            "7": 0.3333333333333333
        },
        "bleu": 3.46695,
        "nubia": {
            "semantic_relation": 3.36702,
            "contradiction": 36.5492,
            "irrelevancy": 14.93717,
            "logical_agreement": 48.51363,
            "grammar_ref": 2.90527,
            "grammar_hyp": 3.00505,
            "nubia_score": 0.2132
        },
        "meteor": 0.15676355744820503,
        "bleurt": -0.36985,
        "bertscore": {
            "precision": 0.8696,
            "recall": 0.88069,
            "f1": 0.8748
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 297,
        "total_length": 5067,
        "mean_pred_length": 17.060606060606062,
        "std_pred_length": 6.321069756379356,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.0761791987369252,
        "vocab_size-1": 386,
        "unique-1": 135,
        "entropy-1": 6.178656127939902,
        "distinct-2": 0.22431865828092243,
        "vocab_size-2": 1070,
        "unique-2": 509,
        "entropy-2": 8.886065344029134,
        "cond_entropy-2": 2.5922459777133704,
        "distinct-3": 0.3565839481332439,
        "vocab_size-3": 1595,
        "unique-3": 934,
        "entropy-3": 9.649677648448796,
        "cond_entropy-3": 0.7871432702364843,
        "total_length-nopunct": 4601,
        "mean_pred_length-nopunct": 15.491582491582491,
        "std_pred_length-nopunct": 6.002308466192805,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.08324277331014997,
        "vocab_size-1-nopunct": 383,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.204001665022277,
        "distinct-2-nopunct": 0.22304832713754646,
        "vocab_size-2-nopunct": 960,
        "unique-2-nopunct": 438,
        "entropy-2-nopunct": 8.772273942544578,
        "cond_entropy-2-nopunct": 2.660430632586214,
        "distinct-3-nopunct": 0.3603693536311455,
        "vocab_size-3-nopunct": 1444,
        "unique-3-nopunct": 849,
        "entropy-3-nopunct": 9.52371352766469,
        "cond_entropy-3-nopunct": 0.7937383118472855,
        "msttr-100": 0.5286,
        "msttr-100_nopunct": 0.545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.5058392418017925,
        "rouge1": {
            "precision": 0.4946,
            "recall": 0.49016,
            "fmeasure": 0.47426
        },
        "rouge2": {
            "precision": 0.25816,
            "recall": 0.25993,
            "fmeasure": 0.24844
        },
        "rougeL": {
            "precision": 0.43444,
            "recall": 0.43262,
            "fmeasure": 0.41798
        },
        "rougeLsum": {
            "precision": 0.43444,
            "recall": 0.43262,
            "fmeasure": 0.41798
        },
        "local_recall": {
            "1": 0.29742473703300687
        },
        "bleu": 3.15368,
        "nubia": {
            "semantic_relation": 3.07569,
            "contradiction": 30.99351,
            "irrelevancy": 27.77586,
            "logical_agreement": 41.23063,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.0769,
            "nubia_score": 0.36987
        },
        "meteor": 0.13800404542209577,
        "bleurt": -0.6802,
        "bertscore": {
            "precision": 0.82696,
            "recall": 0.8537,
            "f1": 0.83979
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 1,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.5333333333333333,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 2.95344529780426,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 1.9029303627648395,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": 0.020802498358603594,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 29.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5172413793103449,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 2.837175514640408,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 1.9709224602917383,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": 0.021606654179938622,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.10566416671474375,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0
        },
        "bleu": 1.24149,
        "nubia": {
            "semantic_relation": 3.08917,
            "contradiction": 30.93513,
            "irrelevancy": 17.47236,
            "logical_agreement": 51.59251,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.58044,
            "nubia_score": 0.14201
        },
        "meteor": 0.02105263157894737,
        "bleurt": -0.68352,
        "bertscore": {
            "precision": 0.78519,
            "recall": 0.81326,
            "f1": 0.79894
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 494,
        "total_length": 24813,
        "mean_pred_length": 50.22874493927125,
        "std_pred_length": 16.571227187194072,
        "median_pred_length": 50.0,
        "min_pred_length": 19,
        "max_pred_length": 93,
        "distinct-1": 0.058759521218716,
        "vocab_size-1": 1458,
        "unique-1": 498,
        "entropy-1": 5.752041026817548,
        "distinct-2": 0.15329577696451335,
        "vocab_size-2": 3728,
        "unique-2": 1544,
        "entropy-2": 9.845615901047209,
        "cond_entropy-2": 4.09572256650516,
        "distinct-3": 0.27336831059811123,
        "vocab_size-3": 6513,
        "unique-3": 3133,
        "entropy-3": 11.440931801549736,
        "cond_entropy-3": 1.6330672550184415,
        "total_length-nopunct": 22843,
        "mean_pred_length-nopunct": 46.24089068825911,
        "std_pred_length-nopunct": 15.666329324711585,
        "median_pred_length-nopunct": 45.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.06347677625530797,
        "vocab_size-1-nopunct": 1450,
        "unique-1-nopunct": 497,
        "entropy-1-nopunct": 5.649137419910445,
        "distinct-2-nopunct": 0.15427983354959954,
        "vocab_size-2-nopunct": 3448,
        "unique-2-nopunct": 1418,
        "entropy-2-nopunct": 9.721840211889418,
        "cond_entropy-2-nopunct": 4.151863183463765,
        "distinct-3-nopunct": 0.2754518416838252,
        "vocab_size-3-nopunct": 6020,
        "unique-3-nopunct": 2966,
        "entropy-3-nopunct": 11.28538806282642,
        "cond_entropy-3-nopunct": 1.597583637231596,
        "msttr-100": 0.44016,
        "msttr-100_nopunct": 0.43504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.110375253829601,
        "rouge1": {
            "precision": 0.37248,
            "recall": 0.34639,
            "fmeasure": 0.34817
        },
        "rouge2": {
            "precision": 0.17709,
            "recall": 0.17226,
            "fmeasure": 0.16872
        },
        "rougeL": {
            "precision": 0.35568,
            "recall": 0.33154,
            "fmeasure": 0.33245
        },
        "rougeLsum": {
            "precision": 0.35568,
            "recall": 0.33154,
            "fmeasure": 0.33245
        },
        "local_recall": {
            "1": 0.08550443458980045,
            "2": 0.18588992974238877,
            "3": 0.2818618396749169,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "bleu": 2.21682,
        "nubia": {
            "semantic_relation": 3.34811,
            "contradiction": 31.44875,
            "irrelevancy": 17.38636,
            "logical_agreement": 51.16489,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.47503,
            "nubia_score": 0.15474
        },
        "meteor": 0.13067003704293098,
        "bleurt": -0.51116,
        "bertscore": {
            "precision": 0.85946,
            "recall": 0.87058,
            "f1": 0.86439
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 354,
        "total_length": 20582,
        "mean_pred_length": 58.14124293785311,
        "std_pred_length": 14.249089360645046,
        "median_pred_length": 62.5,
        "min_pred_length": 17,
        "max_pred_length": 88,
        "distinct-1": 0.06398795063647848,
        "vocab_size-1": 1317,
        "unique-1": 453,
        "entropy-1": 5.753169098353401,
        "distinct-2": 0.16081668973699823,
        "vocab_size-2": 3253,
        "unique-2": 1337,
        "entropy-2": 9.785814861927205,
        "cond_entropy-2": 4.040604189015433,
        "distinct-3": 0.27543524202475594,
        "vocab_size-3": 5474,
        "unique-3": 2643,
        "entropy-3": 11.258267128740469,
        "cond_entropy-3": 1.4995503461595108,
        "total_length-nopunct": 19001,
        "mean_pred_length-nopunct": 53.675141242937855,
        "std_pred_length-nopunct": 13.560040294064786,
        "median_pred_length-nopunct": 58.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.06894373980316826,
        "vocab_size-1-nopunct": 1310,
        "unique-1-nopunct": 453,
        "entropy-1-nopunct": 5.660595136721299,
        "distinct-2-nopunct": 0.1643159757601759,
        "vocab_size-2-nopunct": 3064,
        "unique-2-nopunct": 1260,
        "entropy-2-nopunct": 9.725355949802772,
        "cond_entropy-2-nopunct": 4.120640834944365,
        "distinct-3-nopunct": 0.27950582189908707,
        "vocab_size-3-nopunct": 5113,
        "unique-3-nopunct": 2511,
        "entropy-3-nopunct": 11.160673051518403,
        "cond_entropy-3-nopunct": 1.4581342957661996,
        "msttr-100": 0.44693,
        "msttr-100_nopunct": 0.44579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1441004440153197,
        "rouge1": {
            "precision": 0.51444,
            "recall": 0.52384,
            "fmeasure": 0.50596
        },
        "rouge2": {
            "precision": 0.25305,
            "recall": 0.27514,
            "fmeasure": 0.255
        },
        "rougeL": {
            "precision": 0.49553,
            "recall": 0.50508,
            "fmeasure": 0.48712
        },
        "rougeLsum": {
            "precision": 0.49553,
            "recall": 0.50508,
            "fmeasure": 0.48712
        },
        "local_recall": {
            "1": 0.0959984970881082,
            "2": 0.19584664536741214,
            "3": 0.26536668079694786,
            "4": 0.21621621621621623,
            "5": 0.3181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "bleu": 1.57236,
        "nubia": {
            "semantic_relation": 3.34944,
            "contradiction": 32.14459,
            "irrelevancy": 18.04242,
            "logical_agreement": 49.81298,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.41104,
            "nubia_score": 0.14224
        },
        "meteor": 0.12780398055013018,
        "bleurt": -0.48898,
        "bertscore": {
            "precision": 0.86117,
            "recall": 0.87166,
            "f1": 0.86587
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 124,
        "total_length": 3067,
        "mean_pred_length": 24.733870967741936,
        "std_pred_length": 9.613589902947824,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 94,
        "distinct-1": 0.39419628301271603,
        "vocab_size-1": 1209,
        "unique-1": 899,
        "entropy-1": 8.45089657074077,
        "distinct-2": 0.7713217804960925,
        "vocab_size-2": 2270,
        "unique-2": 1959,
        "entropy-2": 10.830377661295765,
        "cond_entropy-2": 2.2213136116287364,
        "distinct-3": 0.904930826534232,
        "vocab_size-3": 2551,
        "unique-3": 2376,
        "entropy-3": 11.230060851168902,
        "cond_entropy-3": 0.4099190808005457,
        "total_length-nopunct": 2663,
        "mean_pred_length-nopunct": 21.475806451612904,
        "std_pred_length-nopunct": 7.491353843875746,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.4502440856177244,
        "vocab_size-1-nopunct": 1199,
        "unique-1-nopunct": 897,
        "entropy-1-nopunct": 8.760349117868728,
        "distinct-2-nopunct": 0.8007089405277669,
        "vocab_size-2-nopunct": 2033,
        "unique-2-nopunct": 1783,
        "entropy-2-nopunct": 10.711964721192231,
        "cond_entropy-2-nopunct": 2.0260805370228785,
        "distinct-3-nopunct": 0.9229813664596274,
        "vocab_size-3-nopunct": 2229,
        "unique-3-nopunct": 2097,
        "entropy-3-nopunct": 11.056910946849765,
        "cond_entropy-3-nopunct": 0.3639201655524333,
        "msttr-100": 0.656,
        "msttr-100_nopunct": 0.70577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.136049609535825,
        "rouge1": {
            "precision": 0.71232,
            "recall": 0.65365,
            "fmeasure": 0.66981
        },
        "rouge2": {
            "precision": 0.43519,
            "recall": 0.40916,
            "fmeasure": 0.41245
        },
        "rougeL": {
            "precision": 0.57347,
            "recall": 0.5348,
            "fmeasure": 0.54364
        },
        "rougeLsum": {
            "precision": 0.57347,
            "recall": 0.5348,
            "fmeasure": 0.54364
        },
        "local_recall": {
            "1": 0.20082815734989648,
            "2": 0.38148984198645597,
            "3": 0.6958502024291497
        },
        "bleu": 34.95054,
        "nubia": {
            "semantic_relation": 3.79252,
            "contradiction": 16.4108,
            "irrelevancy": 33.08225,
            "logical_agreement": 50.50695,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.12854,
            "nubia_score": 0.62062
        },
        "meteor": 0.33498688372717617,
        "bleurt": 0.07422,
        "bertscore": {
            "precision": 0.91134,
            "recall": 0.89804,
            "f1": 0.90292
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 86,
        "total_length": 2002,
        "mean_pred_length": 23.27906976744186,
        "std_pred_length": 6.9494037937189805,
        "median_pred_length": 22.5,
        "min_pred_length": 12,
        "max_pred_length": 49,
        "distinct-1": 0.14835164835164835,
        "vocab_size-1": 297,
        "unique-1": 125,
        "entropy-1": 6.096936282980091,
        "distinct-2": 0.3778705636743215,
        "vocab_size-2": 724,
        "unique-2": 426,
        "entropy-2": 8.681996072626243,
        "cond_entropy-2": 2.519272548073208,
        "distinct-3": 0.5360655737704918,
        "vocab_size-3": 981,
        "unique-3": 701,
        "entropy-3": 9.30932250224195,
        "cond_entropy-3": 0.6348605481368759,
        "total_length-nopunct": 1854,
        "mean_pred_length-nopunct": 21.558139534883722,
        "std_pred_length-nopunct": 6.50867873414036,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.15857605177993528,
        "vocab_size-1-nopunct": 294,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.089815011670523,
        "distinct-2-nopunct": 0.38065610859728505,
        "vocab_size-2-nopunct": 673,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.574448168356863,
        "cond_entropy-2-nopunct": 2.5729094598306794,
        "distinct-3-nopunct": 0.5439952437574316,
        "vocab_size-3-nopunct": 915,
        "unique-3-nopunct": 661,
        "entropy-3-nopunct": 9.210859442285612,
        "cond_entropy-3-nopunct": 0.6247211828785533,
        "msttr-100": 0.5235,
        "msttr-100_nopunct": 0.52944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.7533626792231538,
        "rouge1": {
            "precision": 0.58194,
            "recall": 0.49286,
            "fmeasure": 0.52195
        },
        "rouge2": {
            "precision": 0.3184,
            "recall": 0.27064,
            "fmeasure": 0.28537
        },
        "rougeL": {
            "precision": 0.48455,
            "recall": 0.40662,
            "fmeasure": 0.43206
        },
        "rougeLsum": {
            "precision": 0.48455,
            "recall": 0.40662,
            "fmeasure": 0.43206
        },
        "local_recall": {
            "1": 0.2973384030418251
        },
        "bleu": 4.65519,
        "nubia": {
            "semantic_relation": 2.78284,
            "contradiction": 26.70839,
            "irrelevancy": 21.05418,
            "logical_agreement": 52.23743,
            "grammar_ref": 6.22337,
            "grammar_hyp": 5.72091,
            "nubia_score": 0.43973
        },
        "meteor": 0.1310077231729988,
        "bleurt": -0.57179,
        "bertscore": {
            "precision": 0.83146,
            "recall": 0.85569,
            "f1": 0.84315
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 9,
        "total_length": 209,
        "mean_pred_length": 23.22222222222222,
        "std_pred_length": 6.876332643007023,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.42105263157894735,
        "vocab_size-1": 88,
        "unique-1": 57,
        "entropy-1": 5.471098779901909,
        "distinct-2": 0.75,
        "vocab_size-2": 150,
        "unique-2": 122,
        "entropy-2": 7.0163564103429,
        "cond_entropy-2": 1.4964025820191074,
        "distinct-3": 0.8691099476439791,
        "vocab_size-3": 166,
        "unique-3": 150,
        "entropy-3": 7.263427946093145,
        "cond_entropy-3": 0.24522597561877466,
        "total_length-nopunct": 192,
        "mean_pred_length-nopunct": 21.333333333333332,
        "std_pred_length-nopunct": 6.429100507328638,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4479166666666667,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.426068499668405,
        "distinct-2-nopunct": 0.7704918032786885,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.943322415419536,
        "cond_entropy-2-nopunct": 1.5767036382871642,
        "distinct-3-nopunct": 0.8850574712643678,
        "vocab_size-3-nopunct": 154,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.167229884061141,
        "cond_entropy-3-nopunct": 0.20437097450597166,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.56,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.4637172236078926,
        "rouge1": {
            "precision": 0.57713,
            "recall": 0.46037,
            "fmeasure": 0.50633
        },
        "rouge2": {
            "precision": 0.34474,
            "recall": 0.25588,
            "fmeasure": 0.28963
        },
        "rougeL": {
            "precision": 0.48132,
            "recall": 0.37263,
            "fmeasure": 0.41524
        },
        "rougeLsum": {
            "precision": 0.48132,
            "recall": 0.37263,
            "fmeasure": 0.41524
        },
        "local_recall": {
            "1": 0.31851851851851853
        },
        "bleu": 2.2372,
        "nubia": {
            "semantic_relation": 2.87893,
            "contradiction": 24.49611,
            "irrelevancy": 28.91289,
            "logical_agreement": 46.59099,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.78091,
            "nubia_score": 0.44727
        },
        "meteor": 0.13621872206930277,
        "bleurt": -0.56463,
        "bertscore": {
            "precision": 0.83562,
            "recall": 0.86068,
            "f1": 0.84786
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 128,
        "total_length": 3648,
        "mean_pred_length": 28.5,
        "std_pred_length": 10.313068166166653,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 58,
        "distinct-1": 0.36211622807017546,
        "vocab_size-1": 1321,
        "unique-1": 1012,
        "entropy-1": 8.280614335871082,
        "distinct-2": 0.7085227272727272,
        "vocab_size-2": 2494,
        "unique-2": 2206,
        "entropy-2": 10.663533119052943,
        "cond_entropy-2": 2.257595374978909,
        "distinct-3": 0.8334316037735849,
        "vocab_size-3": 2827,
        "unique-3": 2671,
        "entropy-3": 11.118476258848782,
        "cond_entropy-3": 0.46222150249714455,
        "total_length-nopunct": 3101,
        "mean_pred_length-nopunct": 24.2265625,
        "std_pred_length-nopunct": 8.468890537348665,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.4221218961625282,
        "vocab_size-1-nopunct": 1309,
        "unique-1-nopunct": 1008,
        "entropy-1-nopunct": 8.630567758727848,
        "distinct-2-nopunct": 0.7453750420450723,
        "vocab_size-2-nopunct": 2216,
        "unique-2-nopunct": 1995,
        "entropy-2-nopunct": 10.566821167970502,
        "cond_entropy-2-nopunct": 1.9979465118427622,
        "distinct-3-nopunct": 0.859402460456942,
        "vocab_size-3-nopunct": 2445,
        "unique-3-nopunct": 2331,
        "entropy-3-nopunct": 10.95788808187566,
        "cond_entropy-3-nopunct": 0.40460578305496425,
        "msttr-100": 0.64778,
        "msttr-100_nopunct": 0.69419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.764245667100915,
        "rouge1": {
            "precision": 0.73539,
            "recall": 0.68702,
            "fmeasure": 0.70177
        },
        "rouge2": {
            "precision": 0.4982,
            "recall": 0.46703,
            "fmeasure": 0.4768
        },
        "rougeL": {
            "precision": 0.60721,
            "recall": 0.57391,
            "fmeasure": 0.58296
        },
        "rougeLsum": {
            "precision": 0.60721,
            "recall": 0.57391,
            "fmeasure": 0.58296
        },
        "local_recall": {
            "1": 0.23129251700680273,
            "2": 0.36627906976744184,
            "3": 0.7424036281179138
        },
        "bleu": 46.97119,
        "nubia": {
            "semantic_relation": 3.77751,
            "contradiction": 23.14739,
            "irrelevancy": 25.64395,
            "logical_agreement": 51.20866,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.00542,
            "nubia_score": 0.61992
        },
        "meteor": 0.3729681156167752,
        "bleurt": 0.09084,
        "bertscore": {
            "precision": 0.91719,
            "recall": 0.9052,
            "f1": 0.90976
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 609,
        "total_length": 10156,
        "mean_pred_length": 16.676518883415437,
        "std_pred_length": 6.704809711520962,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.06488775108310359,
        "vocab_size-1": 659,
        "unique-1": 263,
        "entropy-1": 6.271789733002461,
        "distinct-2": 0.19377815020425265,
        "vocab_size-2": 1850,
        "unique-2": 955,
        "entropy-2": 9.184576562016947,
        "cond_entropy-2": 2.8193529075826853,
        "distinct-3": 0.32188409040053706,
        "vocab_size-3": 2877,
        "unique-3": 1803,
        "entropy-3": 10.096480131997422,
        "cond_entropy-3": 1.0248401872806567,
        "total_length-nopunct": 9300,
        "mean_pred_length-nopunct": 15.270935960591133,
        "std_pred_length-nopunct": 6.380941394597261,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.07053763440860215,
        "vocab_size-1-nopunct": 656,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 6.300301947732437,
        "distinct-2-nopunct": 0.18709009319986192,
        "vocab_size-2-nopunct": 1626,
        "unique-2-nopunct": 838,
        "entropy-2-nopunct": 8.989170896424442,
        "cond_entropy-2-nopunct": 2.920322388153143,
        "distinct-3-nopunct": 0.32021776787923784,
        "vocab_size-3-nopunct": 2588,
        "unique-3-nopunct": 1636,
        "entropy-3-nopunct": 9.915706602330308,
        "cond_entropy-3-nopunct": 1.0614407548656601,
        "msttr-100": 0.52267,
        "msttr-100_nopunct": 0.53387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.6189508111693862,
        "rouge1": {
            "precision": 0.4835,
            "recall": 0.50579,
            "fmeasure": 0.47569
        },
        "rouge2": {
            "precision": 0.25547,
            "recall": 0.27275,
            "fmeasure": 0.25224
        },
        "rougeL": {
            "precision": 0.42694,
            "recall": 0.44618,
            "fmeasure": 0.42013
        },
        "rougeLsum": {
            "precision": 0.42694,
            "recall": 0.44618,
            "fmeasure": 0.42013
        },
        "local_recall": {
            "1": 0.3023255813953488
        },
        "bleu": 3.9798,
        "nubia": {
            "semantic_relation": 3.03041,
            "contradiction": 33.96359,
            "irrelevancy": 25.63284,
            "logical_agreement": 40.40357,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.21288,
            "nubia_score": 0.36706
        },
        "meteor": 0.1390928904864806,
        "bleurt": -0.63627,
        "bertscore": {
            "precision": 0.82818,
            "recall": 0.85743,
            "f1": 0.84223
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 22,
        "total_length": 342,
        "mean_pred_length": 15.545454545454545,
        "std_pred_length": 2.9034035313947837,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.09064327485380116,
        "vocab_size-1": 31,
        "unique-1": 0,
        "entropy-1": 4.282791141944347,
        "distinct-2": 0.140625,
        "vocab_size-2": 45,
        "unique-2": 0,
        "entropy-2": 5.191047029203956,
        "cond_entropy-2": 0.8859554328680275,
        "distinct-3": 0.1476510067114094,
        "vocab_size-3": 44,
        "unique-3": 0,
        "entropy-3": 5.172411459668152,
        "cond_entropy-3": 0.013562990631610974,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 13.590909090909092,
        "std_pred_length-nopunct": 2.6398879264966553,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.09698996655518395,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.130875158955175,
        "distinct-2-nopunct": 0.1407942238267148,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.99059826640193,
        "cond_entropy-2-nopunct": 0.8593354656082967,
        "distinct-3-nopunct": 0.14901960784313725,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.9701866788187985,
        "cond_entropy-3-nopunct": 0.004117935066483707,
        "msttr-100": 0.25667,
        "msttr-100_nopunct": 0.26,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.1274742950872505,
        "rouge1": {
            "precision": 0.48283,
            "recall": 0.522,
            "fmeasure": 0.49721
        },
        "rouge2": {
            "precision": 0.33225,
            "recall": 0.35704,
            "fmeasure": 0.34071
        },
        "rougeL": {
            "precision": 0.45808,
            "recall": 0.49604,
            "fmeasure": 0.47209
        },
        "rougeLsum": {
            "precision": 0.45808,
            "recall": 0.49604,
            "fmeasure": 0.47209
        },
        "local_recall": {
            "1": 0.28
        },
        "bleu": 5.27505,
        "nubia": {
            "semantic_relation": 2.9063,
            "contradiction": 28.04868,
            "irrelevancy": 25.38933,
            "logical_agreement": 46.56199,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.54221,
            "nubia_score": 0.40002
        },
        "meteor": 0.14507288555703074,
        "bleurt": -0.56147,
        "bertscore": {
            "precision": 0.85062,
            "recall": 0.88543,
            "f1": 0.86761
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 16,
        "total_length": 437,
        "mean_pred_length": 27.3125,
        "std_pred_length": 6.429606811462113,
        "median_pred_length": 28.0,
        "min_pred_length": 18,
        "max_pred_length": 44,
        "distinct-1": 0.2471395881006865,
        "vocab_size-1": 108,
        "unique-1": 56,
        "entropy-1": 5.451629096752972,
        "distinct-2": 0.49406175771971494,
        "vocab_size-2": 208,
        "unique-2": 140,
        "entropy-2": 7.18490283127204,
        "cond_entropy-2": 1.707425197616353,
        "distinct-3": 0.6123456790123457,
        "vocab_size-3": 248,
        "unique-3": 186,
        "entropy-3": 7.579722638043661,
        "cond_entropy-3": 0.3973249980417463,
        "total_length-nopunct": 393,
        "mean_pred_length-nopunct": 24.5625,
        "std_pred_length-nopunct": 5.83061692704983,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.26717557251908397,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.416357460700623,
        "distinct-2-nopunct": 0.5092838196286472,
        "vocab_size-2-nopunct": 192,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.100354968882329,
        "cond_entropy-2-nopunct": 1.6979631216554887,
        "distinct-3-nopunct": 0.6232686980609419,
        "vocab_size-3-nopunct": 225,
        "unique-3-nopunct": 168,
        "entropy-3-nopunct": 7.466759721522219,
        "cond_entropy-3-nopunct": 0.36731625377610166,
        "msttr-100": 0.505,
        "msttr-100_nopunct": 0.51333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.596401156914859,
        "rouge1": {
            "precision": 0.53516,
            "recall": 0.53323,
            "fmeasure": 0.52474
        },
        "rouge2": {
            "precision": 0.27954,
            "recall": 0.2956,
            "fmeasure": 0.28057
        },
        "rougeL": {
            "precision": 0.41354,
            "recall": 0.42333,
            "fmeasure": 0.40991
        },
        "rougeLsum": {
            "precision": 0.41354,
            "recall": 0.42333,
            "fmeasure": 0.40991
        },
        "local_recall": {
            "1": 0.3522267206477733
        },
        "bleu": 6.80117,
        "nubia": {
            "semantic_relation": 2.88118,
            "contradiction": 27.04159,
            "irrelevancy": 24.34276,
            "logical_agreement": 48.61565,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.78567,
            "nubia_score": 0.42026
        },
        "meteor": 0.165139049345054,
        "bleurt": -0.5357,
        "bertscore": {
            "precision": 0.82855,
            "recall": 0.86504,
            "f1": 0.84624
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 34,
        "total_length": 679,
        "mean_pred_length": 19.970588235294116,
        "std_pred_length": 6.451107037316961,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 34,
        "distinct-1": 0.20913107511045656,
        "vocab_size-1": 142,
        "unique-1": 61,
        "entropy-1": 5.580017347518871,
        "distinct-2": 0.4310077519379845,
        "vocab_size-2": 278,
        "unique-2": 154,
        "entropy-2": 7.573112004586359,
        "cond_entropy-2": 1.9266648548444605,
        "distinct-3": 0.5368248772504092,
        "vocab_size-3": 328,
        "unique-3": 202,
        "entropy-3": 7.960912980407491,
        "cond_entropy-3": 0.37856616452694397,
        "total_length-nopunct": 626,
        "mean_pred_length-nopunct": 18.41176470588235,
        "std_pred_length-nopunct": 6.059109073796749,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.22364217252396165,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.543982627126008,
        "distinct-2-nopunct": 0.4391891891891892,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.470020908641059,
        "cond_entropy-2-nopunct": 1.942386211233921,
        "distinct-3-nopunct": 0.543010752688172,
        "vocab_size-3-nopunct": 303,
        "unique-3-nopunct": 191,
        "entropy-3-nopunct": 7.838675607232313,
        "cond_entropy-3-nopunct": 0.37138594553786547,
        "msttr-100": 0.51667,
        "msttr-100_nopunct": 0.52667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.927507754094334,
        "rouge1": {
            "precision": 0.46349,
            "recall": 0.48273,
            "fmeasure": 0.45817
        },
        "rouge2": {
            "precision": 0.2844,
            "recall": 0.30043,
            "fmeasure": 0.28204
        },
        "rougeL": {
            "precision": 0.39893,
            "recall": 0.42642,
            "fmeasure": 0.3995
        },
        "rougeLsum": {
            "precision": 0.39893,
            "recall": 0.42642,
            "fmeasure": 0.3995
        },
        "local_recall": {
            "1": 0.2298507462686567
        },
        "bleu": 1.21484,
        "nubia": {
            "semantic_relation": 2.65408,
            "contradiction": 35.31303,
            "irrelevancy": 23.57888,
            "logical_agreement": 41.10809,
            "grammar_ref": 6.46033,
            "grammar_hyp": 5.73942,
            "nubia_score": 0.28872
        },
        "meteor": 0.11401795144281861,
        "bleurt": -0.78412,
        "bertscore": {
            "precision": 0.82049,
            "recall": 0.85019,
            "f1": 0.83486
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 162,
        "total_length": 2349,
        "mean_pred_length": 14.5,
        "std_pred_length": 5.724379312949004,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.3444018731375053,
        "vocab_size-1": 809,
        "unique-1": 585,
        "entropy-1": 7.951294075116776,
        "distinct-2": 0.7151348879743942,
        "vocab_size-2": 1564,
        "unique-2": 1326,
        "entropy-2": 10.205147350784808,
        "cond_entropy-2": 1.9495082332661937,
        "distinct-3": 0.8770370370370371,
        "vocab_size-3": 1776,
        "unique-3": 1648,
        "entropy-3": 10.655188035999476,
        "cond_entropy-3": 0.4446484810241901,
        "total_length-nopunct": 2031,
        "mean_pred_length-nopunct": 12.537037037037036,
        "std_pred_length-nopunct": 4.997701803791009,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.39389463318562284,
        "vocab_size-1-nopunct": 800,
        "unique-1-nopunct": 581,
        "entropy-1-nopunct": 8.281593047611556,
        "distinct-2-nopunct": 0.7463884430176565,
        "vocab_size-2-nopunct": 1395,
        "unique-2-nopunct": 1213,
        "entropy-2-nopunct": 10.053591891859122,
        "cond_entropy-2-nopunct": 1.878896475150105,
        "distinct-3-nopunct": 0.8916227299355595,
        "vocab_size-3-nopunct": 1522,
        "unique-3-nopunct": 1428,
        "entropy-3-nopunct": 10.445268973171467,
        "cond_entropy-3-nopunct": 0.4266222384562223,
        "msttr-100": 0.6987,
        "msttr-100_nopunct": 0.749,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.295812813413759,
        "rouge1": {
            "precision": 0.7369,
            "recall": 0.71121,
            "fmeasure": 0.71123
        },
        "rouge2": {
            "precision": 0.49207,
            "recall": 0.47231,
            "fmeasure": 0.47268
        },
        "rougeL": {
            "precision": 0.61767,
            "recall": 0.59283,
            "fmeasure": 0.59432
        },
        "rougeLsum": {
            "precision": 0.61767,
            "recall": 0.59283,
            "fmeasure": 0.59432
        },
        "local_recall": {
            "1": 0.16972477064220184,
            "2": 0.36877828054298645,
            "3": 0.7387158296249206
        },
        "bleu": 41.23577,
        "nubia": {
            "semantic_relation": 4.00648,
            "contradiction": 28.87974,
            "irrelevancy": 23.16027,
            "logical_agreement": 47.95999,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.56808,
            "nubia_score": 0.66782
        },
        "meteor": 0.37883230134430906,
        "bleurt": 0.23286,
        "bertscore": {
            "precision": 0.92336,
            "recall": 0.91903,
            "f1": 0.9194
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 61,
        "total_length": 1605,
        "mean_pred_length": 26.311475409836067,
        "std_pred_length": 7.651295794266651,
        "median_pred_length": 25.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.4517133956386293,
        "vocab_size-1": 725,
        "unique-1": 565,
        "entropy-1": 7.982564492853036,
        "distinct-2": 0.810880829015544,
        "vocab_size-2": 1252,
        "unique-2": 1111,
        "entropy-2": 10.039294197613705,
        "cond_entropy-2": 1.9250026182569282,
        "distinct-3": 0.9244774106540796,
        "vocab_size-3": 1371,
        "unique-3": 1280,
        "entropy-3": 10.370227823430508,
        "cond_entropy-3": 0.3331005902178329,
        "total_length-nopunct": 1365,
        "mean_pred_length-nopunct": 22.37704918032787,
        "std_pred_length-nopunct": 6.985145678160356,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5252747252747253,
        "vocab_size-1-nopunct": 717,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.327865947869425,
        "distinct-2-nopunct": 0.848159509202454,
        "vocab_size-2-nopunct": 1106,
        "unique-2-nopunct": 999,
        "entropy-2-nopunct": 9.934203459131657,
        "cond_entropy-2-nopunct": 1.6732096271051764,
        "distinct-3-nopunct": 0.9364440868865648,
        "vocab_size-3-nopunct": 1164,
        "unique-3-nopunct": 1097,
        "entropy-3-nopunct": 10.1428132359058,
        "cond_entropy-3-nopunct": 0.2228503591558064,
        "msttr-100": 0.63813,
        "msttr-100_nopunct": 0.71231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.4418021645044785,
        "rouge1": {
            "precision": 0.68606,
            "recall": 0.64804,
            "fmeasure": 0.65335
        },
        "rouge2": {
            "precision": 0.40115,
            "recall": 0.38271,
            "fmeasure": 0.38378
        },
        "rougeL": {
            "precision": 0.55799,
            "recall": 0.53048,
            "fmeasure": 0.53069
        },
        "rougeLsum": {
            "precision": 0.55799,
            "recall": 0.53048,
            "fmeasure": 0.53069
        },
        "local_recall": {
            "1": 0.1774193548387097,
            "2": 0.42081447963800905,
            "3": 0.6889352818371608
        },
        "bleu": 34.24739,
        "nubia": {
            "semantic_relation": 3.75824,
            "contradiction": 18.47118,
            "irrelevancy": 26.49255,
            "logical_agreement": 55.03626,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.08518,
            "nubia_score": 0.61641
        },
        "meteor": 0.3324250271723993,
        "bleurt": 0.04874,
        "bertscore": {
            "precision": 0.90582,
            "recall": 0.89464,
            "f1": 0.89897
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "total_length": 49854,
        "mean_pred_length": 46.375813953488375,
        "std_pred_length": 20.01762412226462,
        "median_pred_length": 47.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.04172182773699202,
        "vocab_size-1": 2080,
        "unique-1": 601,
        "entropy-1": 5.883409460737643,
        "distinct-2": 0.1151930133869083,
        "vocab_size-2": 5619,
        "unique-2": 2079,
        "entropy-2": 10.141409708019724,
        "cond_entropy-2": 4.25670314120933,
        "distinct-3": 0.21258175415059533,
        "vocab_size-3": 10141,
        "unique-3": 4420,
        "entropy-3": 11.849608383173443,
        "cond_entropy-3": 1.7531094917851375,
        "total_length-nopunct": 45905,
        "mean_pred_length-nopunct": 42.70232558139535,
        "std_pred_length-nopunct": 18.82602711453621,
        "median_pred_length-nopunct": 43.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.04511491122971354,
        "vocab_size-1-nopunct": 2071,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 5.793987278814129,
        "distinct-2-nopunct": 0.11545839839393264,
        "vocab_size-2-nopunct": 5176,
        "unique-2-nopunct": 1891,
        "entropy-2-nopunct": 10.033164970159541,
        "cond_entropy-2-nopunct": 4.328918112220044,
        "distinct-3-nopunct": 0.2156782082047766,
        "vocab_size-3-nopunct": 9437,
        "unique-3-nopunct": 4214,
        "entropy-3-nopunct": 11.71490421409163,
        "cond_entropy-3-nopunct": 1.7197806899617736,
        "msttr-100": 0.4459,
        "msttr-100_nopunct": 0.44362,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1597529952761783,
        "rouge1": {
            "precision": 0.40989,
            "recall": 0.40209,
            "fmeasure": 0.39605
        },
        "rouge2": {
            "precision": 0.20518,
            "recall": 0.21018,
            "fmeasure": 0.20181
        },
        "rougeL": {
            "precision": 0.3962,
            "recall": 0.38931,
            "fmeasure": 0.38287
        },
        "rougeLsum": {
            "precision": 0.3962,
            "recall": 0.38931,
            "fmeasure": 0.38287
        },
        "local_recall": {
            "1": 0.09196318573809696,
            "2": 0.19090272918124562,
            "3": 0.2713903743315508,
            "4": 0.24675324675324675,
            "5": 0.3783783783783784,
            "6": 0.23076923076923078,
            "7": 0.2222222222222222
        },
        "bleu": 2.1286,
        "nubia": {
            "semantic_relation": 3.35651,
            "contradiction": 32.72375,
            "irrelevancy": 17.07737,
            "logical_agreement": 50.19887,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.57032,
            "nubia_score": 0.16376
        },
        "meteor": 0.13174157692478342,
        "bleurt": -0.4717,
        "bertscore": {
            "precision": 0.86245,
            "recall": 0.8734,
            "f1": 0.86739
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 4,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 5.0682837331783235,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.4918032786885246,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 3.560148193011857,
        "distinct-2": 0.9122807017543859,
        "vocab_size-2": 52,
        "unique-2": 48,
        "entropy-2": 5.644207777284676,
        "cond_entropy-2": 2.1100658400307934,
        "distinct-3": 0.9811320754716981,
        "vocab_size-3": 52,
        "unique-3": 51,
        "entropy-3": 5.690184605506592,
        "cond_entropy-3": 0.022481147986447524,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 5.11737237261468,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.4909090909090909,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 3.29761538956806,
        "distinct-2-nopunct": 0.9019607843137255,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.437131224324441,
        "cond_entropy-2-nopunct": 2.1457955887114952,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.512035660188278,
        "cond_entropy-3-nopunct": 0.05237627566358878,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.37337210002737375,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.07692307692307693,
            "3": 0.0
        },
        "bleu": 1.00942,
        "nubia": {
            "semantic_relation": 3.40919,
            "contradiction": 45.80502,
            "irrelevancy": 11.92599,
            "logical_agreement": 42.26899,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.11203,
            "nubia_score": 0.25194
        },
        "meteor": 0.05675675675675677,
        "bleurt": -0.32834,
        "bertscore": {
            "precision": 0.87043,
            "recall": 0.88022,
            "f1": 0.87462
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 242,
        "mean_pred_length": 20.166666666666668,
        "std_pred_length": 11.290359702959964,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.5041322314049587,
        "vocab_size-1": 122,
        "unique-1": 87,
        "entropy-1": 6.291813403140591,
        "distinct-2": 0.8130434782608695,
        "vocab_size-2": 187,
        "unique-2": 159,
        "entropy-2": 7.401225661955741,
        "cond_entropy-2": 1.0072602936019157,
        "distinct-3": 0.8990825688073395,
        "vocab_size-3": 196,
        "unique-3": 180,
        "entropy-3": 7.543324003636299,
        "cond_entropy-3": 0.1573789502487443,
        "total_length-nopunct": 200,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 9.177266598624136,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.58,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.29896667032513,
        "distinct-2-nopunct": 0.8404255319148937,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.164025436969033,
        "cond_entropy-2-nopunct": 0.8923921402257862,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 160,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.257671533385452,
        "cond_entropy-3-nopunct": 0.11459360196473702,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.096558313586701,
        "rouge1": {
            "precision": 0.7591,
            "recall": 0.74362,
            "fmeasure": 0.74741
        },
        "rouge2": {
            "precision": 0.59525,
            "recall": 0.58309,
            "fmeasure": 0.58629
        },
        "rougeL": {
            "precision": 0.72095,
            "recall": 0.70736,
            "fmeasure": 0.71032
        },
        "rougeLsum": {
            "precision": 0.72095,
            "recall": 0.70736,
            "fmeasure": 0.71032
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.4444444444444444,
            "3": 0.8201438848920863
        },
        "bleu": 62.66759,
        "nubia": {
            "semantic_relation": 4.04542,
            "contradiction": 9.95752,
            "irrelevancy": 26.42855,
            "logical_agreement": 63.61393,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.06283,
            "nubia_score": 0.70766
        },
        "meteor": 0.4568492434247541,
        "bleurt": 0.40833,
        "bertscore": {
            "precision": 0.93162,
            "recall": 0.93055,
            "f1": 0.93016
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 19,
        "total_length": 618,
        "mean_pred_length": 32.526315789473685,
        "std_pred_length": 18.423007415079287,
        "median_pred_length": 27.0,
        "min_pred_length": 14,
        "max_pred_length": 75,
        "distinct-1": 0.23300970873786409,
        "vocab_size-1": 144,
        "unique-1": 78,
        "entropy-1": 4.925075994069203,
        "distinct-2": 0.5125208681135225,
        "vocab_size-2": 307,
        "unique-2": 189,
        "entropy-2": 7.807940529343007,
        "cond_entropy-2": 2.862574323070183,
        "distinct-3": 0.6896551724137931,
        "vocab_size-3": 400,
        "unique-3": 298,
        "entropy-3": 8.39703011920897,
        "cond_entropy-3": 0.6177294374566874,
        "total_length-nopunct": 557,
        "mean_pred_length-nopunct": 29.31578947368421,
        "std_pred_length-nopunct": 16.689273679692555,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.2495511669658887,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 4.716283389748782,
        "distinct-2-nopunct": 0.5092936802973977,
        "vocab_size-2-nopunct": 274,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.610122457231683,
        "cond_entropy-2-nopunct": 2.93456282598834,
        "distinct-3-nopunct": 0.6897880539499036,
        "vocab_size-3-nopunct": 358,
        "unique-3-nopunct": 270,
        "entropy-3-nopunct": 8.2189171630219,
        "cond_entropy-3-nopunct": 0.6286334826329426,
        "msttr-100": 0.43833,
        "msttr-100_nopunct": 0.424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0932544238209552,
        "rouge1": {
            "precision": 0.26892,
            "recall": 0.2802,
            "fmeasure": 0.2733
        },
        "rouge2": {
            "precision": 0.15058,
            "recall": 0.16316,
            "fmeasure": 0.1559
        },
        "rougeL": {
            "precision": 0.24561,
            "recall": 0.26216,
            "fmeasure": 0.2528
        },
        "rougeLsum": {
            "precision": 0.24561,
            "recall": 0.26216,
            "fmeasure": 0.2528
        },
        "local_recall": {
            "1": 0.03067484662576687,
            "2": 0.21875,
            "3": 0.30434782608695654
        },
        "bleu": 2.27361,
        "nubia": {
            "semantic_relation": 3.16746,
            "contradiction": 37.22332,
            "irrelevancy": 16.03187,
            "logical_agreement": 46.74481,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.77338,
            "nubia_score": 0.17225
        },
        "meteor": 0.1678187167810391,
        "bleurt": -0.50317,
        "bertscore": {
            "precision": 0.85126,
            "recall": 0.8617,
            "f1": 0.85603
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 4,
        "total_length": 144,
        "mean_pred_length": 36.0,
        "std_pred_length": 7.648529270389178,
        "median_pred_length": 34.0,
        "min_pred_length": 28,
        "max_pred_length": 48,
        "distinct-1": 0.3402777777777778,
        "vocab_size-1": 49,
        "unique-1": 26,
        "entropy-1": 4.165364232643836,
        "distinct-2": 0.6642857142857143,
        "vocab_size-2": 93,
        "unique-2": 60,
        "entropy-2": 6.3657554955908235,
        "cond_entropy-2": 2.2198950536301534,
        "distinct-3": 0.7720588235294118,
        "vocab_size-3": 105,
        "unique-3": 78,
        "entropy-3": 6.609377914716112,
        "cond_entropy-3": 0.2513732285768964,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 33.25,
        "std_pred_length-nopunct": 7.1545440106270926,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.3458646616541353,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 3.9647026593166546,
        "distinct-2-nopunct": 0.6589147286821705,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 6.219452329164192,
        "cond_entropy-2-nopunct": 2.272845895492264,
        "distinct-3-nopunct": 0.768,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.477627884592864,
        "cond_entropy-3-nopunct": 0.2755123530689432,
        "msttr-100": 0.39,
        "msttr-100_nopunct": 0.37,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.9339858591395758,
        "rouge1": {
            "precision": 0.53889,
            "recall": 0.52121,
            "fmeasure": 0.52939
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.1125,
            "fmeasure": 0.11806
        },
        "rougeL": {
            "precision": 0.53889,
            "recall": 0.51364,
            "fmeasure": 0.525
        },
        "rougeLsum": {
            "precision": 0.53889,
            "recall": 0.51364,
            "fmeasure": 0.525
        },
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.15384615384615385,
            "3": 0.3076923076923077
        },
        "bleu": 1.16862,
        "nubia": {
            "semantic_relation": 3.13572,
            "contradiction": 31.06294,
            "irrelevancy": 15.49231,
            "logical_agreement": 53.44474,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.70054,
            "nubia_score": 0.13873
        },
        "meteor": 0.10302953388347452,
        "bleurt": -0.47867,
        "bertscore": {
            "precision": 0.85723,
            "recall": 0.8645,
            "f1": 0.86056
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 339,
        "total_length": 8290,
        "mean_pred_length": 24.454277286135692,
        "std_pred_length": 10.518145761463643,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 65,
        "distinct-1": 0.12629674306393246,
        "vocab_size-1": 1047,
        "unique-1": 546,
        "entropy-1": 5.6498481346803455,
        "distinct-2": 0.30662809709470507,
        "vocab_size-2": 2438,
        "unique-2": 1461,
        "entropy-2": 9.723778849797545,
        "cond_entropy-2": 4.028424304370752,
        "distinct-3": 0.48502364687335786,
        "vocab_size-3": 3692,
        "unique-3": 2518,
        "entropy-3": 10.99732617671526,
        "cond_entropy-3": 1.3431106359631073,
        "total_length-nopunct": 7582,
        "mean_pred_length-nopunct": 22.365781710914455,
        "std_pred_length-nopunct": 10.177864098339459,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 64,
        "distinct-1-nopunct": 0.13729886573463465,
        "vocab_size-1-nopunct": 1041,
        "unique-1-nopunct": 546,
        "entropy-1-nopunct": 5.536024999036126,
        "distinct-2-nopunct": 0.29656219798426064,
        "vocab_size-2-nopunct": 2148,
        "unique-2-nopunct": 1272,
        "entropy-2-nopunct": 9.49993075112275,
        "cond_entropy-2-nopunct": 4.1463216528642866,
        "distinct-3-nopunct": 0.47421784472769407,
        "vocab_size-3-nopunct": 3274,
        "unique-3-nopunct": 2246,
        "entropy-3-nopunct": 10.772664992200102,
        "cond_entropy-3-nopunct": 1.3470488130886054,
        "msttr-100": 0.43329,
        "msttr-100_nopunct": 0.42573,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.9813623014158304,
        "rouge1": {
            "precision": 0.27565,
            "recall": 0.27954,
            "fmeasure": 0.2762
        },
        "rouge2": {
            "precision": 0.13975,
            "recall": 0.14012,
            "fmeasure": 0.13942
        },
        "rougeL": {
            "precision": 0.27516,
            "recall": 0.27917,
            "fmeasure": 0.27578
        },
        "rougeLsum": {
            "precision": 0.27516,
            "recall": 0.27917,
            "fmeasure": 0.27578
        },
        "local_recall": {
            "1": 0.09420916162489196,
            "2": 0.16772438803263826,
            "3": 0.20642978003384094,
            "4": 0.3055555555555556,
            "5": 0.4666666666666667,
            "6": 0.25,
            "7": 0.25
        },
        "bleu": 2.55434,
        "nubia": {
            "semantic_relation": 3.34322,
            "contradiction": 35.89656,
            "irrelevancy": 15.2842,
            "logical_agreement": 48.81924,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.89196,
            "nubia_score": 0.20359
        },
        "meteor": 0.13837391653225475,
        "bleurt": -0.399,
        "bertscore": {
            "precision": 0.86585,
            "recall": 0.8779,
            "f1": 0.8714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 36,
        "total_length": 664,
        "mean_pred_length": 18.444444444444443,
        "std_pred_length": 6.829041109052998,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.40210843373493976,
        "vocab_size-1": 267,
        "unique-1": 211,
        "entropy-1": 6.8152614523566,
        "distinct-2": 0.7101910828025477,
        "vocab_size-2": 446,
        "unique-2": 380,
        "entropy-2": 8.42227195539943,
        "cond_entropy-2": 1.4573842406092319,
        "distinct-3": 0.8277027027027027,
        "vocab_size-3": 490,
        "unique-3": 439,
        "entropy-3": 8.754010473433462,
        "cond_entropy-3": 0.3497278238847664,
        "total_length-nopunct": 555,
        "mean_pred_length-nopunct": 15.416666666666666,
        "std_pred_length-nopunct": 5.489257185124818,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4702702702702703,
        "vocab_size-1-nopunct": 261,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 6.948546438497983,
        "distinct-2-nopunct": 0.7514450867052023,
        "vocab_size-2-nopunct": 390,
        "unique-2-nopunct": 340,
        "entropy-2-nopunct": 8.31379289792513,
        "cond_entropy-2-nopunct": 1.4609411330260407,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 414,
        "unique-3-nopunct": 379,
        "entropy-3-nopunct": 8.54646169192107,
        "cond_entropy-3-nopunct": 0.24913066669695028,
        "msttr-100": 0.60667,
        "msttr-100_nopunct": 0.662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.254277950766165,
        "rouge1": {
            "precision": 0.7408,
            "recall": 0.76558,
            "fmeasure": 0.74446
        },
        "rouge2": {
            "precision": 0.54924,
            "recall": 0.56761,
            "fmeasure": 0.55087
        },
        "rougeL": {
            "precision": 0.66706,
            "recall": 0.69381,
            "fmeasure": 0.67199
        },
        "rougeLsum": {
            "precision": 0.66706,
            "recall": 0.69381,
            "fmeasure": 0.67199
        },
        "local_recall": {
            "1": 0.35964912280701755,
            "2": 0.5188679245283019,
            "3": 0.7478005865102639
        },
        "bleu": 45.5483,
        "nubia": {
            "semantic_relation": 3.92589,
            "contradiction": 5.96784,
            "irrelevancy": 41.10418,
            "logical_agreement": 52.92798,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.92575,
            "nubia_score": 0.70584
        },
        "meteor": 0.42130248385232033,
        "bleurt": 0.26504,
        "bertscore": {
            "precision": 0.92159,
            "recall": 0.9266,
            "f1": 0.92229
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 40,
        "total_length": 1082,
        "mean_pred_length": 27.05,
        "std_pred_length": 8.876795593005395,
        "median_pred_length": 26.5,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.43807763401109057,
        "vocab_size-1": 474,
        "unique-1": 342,
        "entropy-1": 7.598831446709679,
        "distinct-2": 0.7840690978886756,
        "vocab_size-2": 817,
        "unique-2": 694,
        "entropy-2": 9.43854497494332,
        "cond_entropy-2": 1.7306434799506456,
        "distinct-3": 0.9051896207584831,
        "vocab_size-3": 907,
        "unique-3": 831,
        "entropy-3": 9.759520198931277,
        "cond_entropy-3": 0.33241612567783635,
        "total_length-nopunct": 914,
        "mean_pred_length-nopunct": 22.85,
        "std_pred_length-nopunct": 6.9661682437334225,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5076586433260394,
        "vocab_size-1-nopunct": 464,
        "unique-1-nopunct": 338,
        "entropy-1-nopunct": 7.856978870503718,
        "distinct-2-nopunct": 0.8192219679633868,
        "vocab_size-2-nopunct": 716,
        "unique-2-nopunct": 631,
        "entropy-2-nopunct": 9.273756562641662,
        "cond_entropy-2-nopunct": 1.4664955548759564,
        "distinct-3-nopunct": 0.9256594724220624,
        "vocab_size-3-nopunct": 772,
        "unique-3-nopunct": 725,
        "entropy-3-nopunct": 9.5353839841833,
        "cond_entropy-3-nopunct": 0.27549968325805496,
        "msttr-100": 0.638,
        "msttr-100_nopunct": 0.68889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.54741709852952,
        "rouge1": {
            "precision": 0.721,
            "recall": 0.66922,
            "fmeasure": 0.68203
        },
        "rouge2": {
            "precision": 0.4807,
            "recall": 0.44316,
            "fmeasure": 0.45393
        },
        "rougeL": {
            "precision": 0.5644,
            "recall": 0.52488,
            "fmeasure": 0.53438
        },
        "rougeLsum": {
            "precision": 0.5644,
            "recall": 0.52488,
            "fmeasure": 0.53438
        },
        "local_recall": {
            "1": 0.21232876712328766,
            "2": 0.4260355029585799,
            "3": 0.7065217391304348
        },
        "bleu": 39.54854,
        "nubia": {
            "semantic_relation": 3.77989,
            "contradiction": 19.28395,
            "irrelevancy": 28.04919,
            "logical_agreement": 52.66686,
            "grammar_ref": 4.29053,
            "grammar_hyp": 3.95778,
            "nubia_score": 0.63882
        },
        "meteor": 0.35138336098390166,
        "bleurt": 0.08499,
        "bertscore": {
            "precision": 0.91139,
            "recall": 0.90303,
            "f1": 0.90609
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 20,
        "total_length": 554,
        "mean_pred_length": 27.7,
        "std_pred_length": 10.724271537032248,
        "median_pred_length": 29.0,
        "min_pred_length": 11,
        "max_pred_length": 53,
        "distinct-1": 0.49458483754512633,
        "vocab_size-1": 274,
        "unique-1": 219,
        "entropy-1": 6.9390744796299,
        "distinct-2": 0.8071161048689138,
        "vocab_size-2": 431,
        "unique-2": 382,
        "entropy-2": 8.541124594124648,
        "cond_entropy-2": 1.5216283763499012,
        "distinct-3": 0.914396887159533,
        "vocab_size-3": 470,
        "unique-3": 446,
        "entropy-3": 8.78821480996851,
        "cond_entropy-3": 0.2447201502345691,
        "total_length-nopunct": 428,
        "mean_pred_length-nopunct": 21.4,
        "std_pred_length-nopunct": 7.4993333037010705,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6285046728971962,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.458895950439493,
        "distinct-2-nopunct": 0.8848039215686274,
        "vocab_size-2-nopunct": 361,
        "unique-2-nopunct": 333,
        "entropy-2-nopunct": 8.388079095725635,
        "cond_entropy-2-nopunct": 0.9748974117547246,
        "distinct-3-nopunct": 0.9484536082474226,
        "vocab_size-3-nopunct": 368,
        "unique-3-nopunct": 358,
        "entropy-3-nopunct": 8.46401321344173,
        "cond_entropy-3-nopunct": 0.08801382113095284,
        "msttr-100": 0.634,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.965221583427432,
        "rouge1": {
            "precision": 0.74714,
            "recall": 0.61713,
            "fmeasure": 0.66833
        },
        "rouge2": {
            "precision": 0.4673,
            "recall": 0.3914,
            "fmeasure": 0.41806
        },
        "rougeL": {
            "precision": 0.5969,
            "recall": 0.51113,
            "fmeasure": 0.5403
        },
        "rougeLsum": {
            "precision": 0.5969,
            "recall": 0.51113,
            "fmeasure": 0.5403
        },
        "local_recall": {
            "1": 0.25287356321839083,
            "2": 0.38461538461538464,
            "3": 0.6867469879518072
        },
        "bleu": 40.41011,
        "nubia": {
            "semantic_relation": 3.70481,
            "contradiction": 19.33083,
            "irrelevancy": 23.83625,
            "logical_agreement": 56.83291,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.27357,
            "nubia_score": 0.57498
        },
        "meteor": 0.3381905310799677,
        "bleurt": 0.08479,
        "bertscore": {
            "precision": 0.92957,
            "recall": 0.91343,
            "f1": 0.91578
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 26,
        "total_length": 820,
        "mean_pred_length": 31.53846153846154,
        "std_pred_length": 12.292057376867918,
        "median_pred_length": 33.0,
        "min_pred_length": 9,
        "max_pred_length": 54,
        "distinct-1": 0.43414634146341463,
        "vocab_size-1": 356,
        "unique-1": 254,
        "entropy-1": 7.237942202590624,
        "distinct-2": 0.7518891687657431,
        "vocab_size-2": 597,
        "unique-2": 489,
        "entropy-2": 8.977355744691689,
        "cond_entropy-2": 1.665444464831668,
        "distinct-3": 0.8736979166666666,
        "vocab_size-3": 671,
        "unique-3": 596,
        "entropy-3": 9.30510188482681,
        "cond_entropy-3": 0.32714308122817726,
        "total_length-nopunct": 680,
        "mean_pred_length-nopunct": 26.153846153846153,
        "std_pred_length-nopunct": 10.189331931343713,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.5161764705882353,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.525092671484319,
        "distinct-2-nopunct": 0.8012232415902141,
        "vocab_size-2-nopunct": 524,
        "unique-2-nopunct": 449,
        "entropy-2-nopunct": 8.847364830943318,
        "cond_entropy-2-nopunct": 1.3648876719430474,
        "distinct-3-nopunct": 0.893312101910828,
        "vocab_size-3-nopunct": 561,
        "unique-3-nopunct": 514,
        "entropy-3-nopunct": 9.050316325320763,
        "cond_entropy-3-nopunct": 0.20796794638126792,
        "msttr-100": 0.58875,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.33441933095611,
        "rouge1": {
            "precision": 0.72262,
            "recall": 0.64614,
            "fmeasure": 0.66597
        },
        "rouge2": {
            "precision": 0.44292,
            "recall": 0.40218,
            "fmeasure": 0.41188
        },
        "rougeL": {
            "precision": 0.5797,
            "recall": 0.52335,
            "fmeasure": 0.53696
        },
        "rougeLsum": {
            "precision": 0.5797,
            "recall": 0.52335,
            "fmeasure": 0.53696
        },
        "local_recall": {
            "1": 0.15,
            "2": 0.31092436974789917,
            "3": 0.7268722466960352
        },
        "bleu": 37.30096,
        "nubia": {
            "semantic_relation": 3.52276,
            "contradiction": 23.69613,
            "irrelevancy": 20.57268,
            "logical_agreement": 55.73119,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.85767,
            "nubia_score": 0.56921
        },
        "meteor": 0.3391726575206626,
        "bleurt": 0.03725,
        "bertscore": {
            "precision": 0.91636,
            "recall": 0.8972,
            "f1": 0.90506
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "total_length": 50503,
        "mean_pred_length": 45.95359417652411,
        "std_pred_length": 20.10904380317203,
        "median_pred_length": 46.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.04156188741262895,
        "vocab_size-1": 2099,
        "unique-1": 605,
        "entropy-1": 5.889254160141794,
        "distinct-2": 0.11482875880495506,
        "vocab_size-2": 5673,
        "unique-2": 2108,
        "entropy-2": 10.149579253751249,
        "cond_entropy-2": 4.257987770372216,
        "distinct-3": 0.21219335472518372,
        "vocab_size-3": 10250,
        "unique-3": 4486,
        "entropy-3": 11.86150257846779,
        "cond_entropy-3": 1.7567137978266232,
        "total_length-nopunct": 46495,
        "mean_pred_length-nopunct": 42.306642402183805,
        "std_pred_length-nopunct": 18.90986381519091,
        "median_pred_length-nopunct": 43.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.04495107000752769,
        "vocab_size-1-nopunct": 2090,
        "unique-1-nopunct": 605,
        "entropy-1-nopunct": 5.799001214549686,
        "distinct-2-nopunct": 0.11518636003172085,
        "vocab_size-2-nopunct": 5229,
        "unique-2-nopunct": 1919,
        "entropy-2-nopunct": 10.04049915147276,
        "cond_entropy-2-nopunct": 4.330935931636899,
        "distinct-3-nopunct": 0.2154773460956724,
        "vocab_size-3-nopunct": 9545,
        "unique-3-nopunct": 4283,
        "entropy-3-nopunct": 11.725675679345175,
        "cond_entropy-3-nopunct": 1.7235524531656388,
        "msttr-100": 0.42657,
        "msttr-100_nopunct": 0.42093,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1646495333027276,
        "rouge1": {
            "precision": 0.40815,
            "recall": 0.40066,
            "fmeasure": 0.39466
        },
        "rouge2": {
            "precision": 0.20422,
            "recall": 0.20928,
            "fmeasure": 0.20098
        },
        "rougeL": {
            "precision": 0.39436,
            "recall": 0.38782,
            "fmeasure": 0.3814
        },
        "rougeLsum": {
            "precision": 0.39436,
            "recall": 0.38782,
            "fmeasure": 0.3814
        },
        "local_recall": {
            "1": 0.09138399885501645,
            "2": 0.19131633356305996,
            "3": 0.27293190770962295,
            "4": 0.24675324675324675,
            "5": 0.3783783783783784,
            "6": 0.23076923076923078,
            "7": 0.2222222222222222
        },
        "bleu": 2.13393,
        "nubia": {
            "semantic_relation": 3.35244,
            "contradiction": 32.84218,
            "irrelevancy": 17.0376,
            "logical_agreement": 50.12022,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.5773,
            "nubia_score": 0.16418
        },
        "meteor": 0.13216639784424053,
        "bleurt": -0.47154,
        "bertscore": {
            "precision": 0.86231,
            "recall": 0.87319,
            "f1": 0.86722
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 295,
        "mean_pred_length": 29.5,
        "std_pred_length": 7.877182237323192,
        "median_pred_length": 31.5,
        "min_pred_length": 12,
        "max_pred_length": 39,
        "distinct-1": 0.5288135593220339,
        "vocab_size-1": 156,
        "unique-1": 118,
        "entropy-1": 6.552837325625817,
        "distinct-2": 0.7929824561403509,
        "vocab_size-2": 226,
        "unique-2": 187,
        "entropy-2": 7.670210621548768,
        "cond_entropy-2": 1.0587699879838208,
        "distinct-3": 0.8945454545454545,
        "vocab_size-3": 246,
        "unique-3": 219,
        "entropy-3": 7.886888626578108,
        "cond_entropy-3": 0.21700959547615134,
        "total_length-nopunct": 239,
        "mean_pred_length-nopunct": 23.9,
        "std_pred_length-nopunct": 6.640030120413611,
        "median_pred_length-nopunct": 24.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6276150627615062,
        "vocab_size-1-nopunct": 150,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.733975005576225,
        "distinct-2-nopunct": 0.851528384279476,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.514903951824064,
        "cond_entropy-2-nopunct": 0.8017238258480217,
        "distinct-3-nopunct": 0.908675799086758,
        "vocab_size-3-nopunct": 199,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.592138657774696,
        "cond_entropy-3-nopunct": 0.08291049756126334,
        "msttr-100": 0.525,
        "msttr-100_nopunct": 0.65,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.06105370682821,
        "rouge1": {
            "precision": 0.64284,
            "recall": 0.62068,
            "fmeasure": 0.62395
        },
        "rouge2": {
            "precision": 0.41063,
            "recall": 0.40611,
            "fmeasure": 0.40232
        },
        "rougeL": {
            "precision": 0.51943,
            "recall": 0.49644,
            "fmeasure": 0.49967
        },
        "rougeLsum": {
            "precision": 0.51943,
            "recall": 0.49644,
            "fmeasure": 0.49967
        },
        "local_recall": {
            "1": 0.1095890410958904,
            "2": 0.3389830508474576,
            "3": 0.726027397260274
        },
        "bleu": 37.80433,
        "nubia": {
            "semantic_relation": 3.26034,
            "contradiction": 25.91695,
            "irrelevancy": 41.8282,
            "logical_agreement": 32.25485,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.13938,
            "nubia_score": 0.50898
        },
        "meteor": 0.31799645240131275,
        "bleurt": -0.11626,
        "bertscore": {
            "precision": 0.90189,
            "recall": 0.88272,
            "f1": 0.88987
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 3,
        "total_length": 174,
        "mean_pred_length": 58.0,
        "std_pred_length": 12.727922061357855,
        "median_pred_length": 49.0,
        "min_pred_length": 49,
        "max_pred_length": 76,
        "distinct-1": 0.29310344827586204,
        "vocab_size-1": 51,
        "unique-1": 33,
        "entropy-1": 3.902856283384244,
        "distinct-2": 0.6140350877192983,
        "vocab_size-2": 105,
        "unique-2": 77,
        "entropy-2": 6.357049319250812,
        "cond_entropy-2": 2.497762255959857,
        "distinct-3": 0.75,
        "vocab_size-3": 126,
        "unique-3": 104,
        "entropy-3": 6.767700178912429,
        "cond_entropy-3": 0.42959377386935926,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 51.666666666666664,
        "std_pred_length-nopunct": 10.338708279513883,
        "median_pred_length-nopunct": 47.0,
        "min_pred_length-nopunct": 42,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.3096774193548387,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 3.6471487180906488,
        "distinct-2-nopunct": 0.5986842105263158,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.08990699150891,
        "cond_entropy-2-nopunct": 2.4859490560936983,
        "distinct-3-nopunct": 0.7315436241610739,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.546814094506569,
        "cond_entropy-3-nopunct": 0.4512167236078225,
        "msttr-100": 0.36,
        "msttr-100_nopunct": 0.39,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.45305059105483625,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.05405405405405406,
            "2": 0.0,
            "3": 0.07142857142857142
        },
        "bleu": 0.44661,
        "nubia": {
            "semantic_relation": 3.42847,
            "contradiction": 33.06418,
            "irrelevancy": 16.04567,
            "logical_agreement": 50.89015,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.19254,
            "nubia_score": 0.1493
        },
        "meteor": 0.08983041252670185,
        "bleurt": -0.54995,
        "bertscore": {
            "precision": 0.84817,
            "recall": 0.87309,
            "f1": 0.85912
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 425,
        "mean_pred_length": 30.357142857142858,
        "std_pred_length": 12.430418581948436,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 56,
        "distinct-1": 0.5294117647058824,
        "vocab_size-1": 225,
        "unique-1": 178,
        "entropy-1": 6.886307725157486,
        "distinct-2": 0.8442822384428224,
        "vocab_size-2": 347,
        "unique-2": 313,
        "entropy-2": 8.291933398982467,
        "cond_entropy-2": 1.335391342787622,
        "distinct-3": 0.9420654911838791,
        "vocab_size-3": 374,
        "unique-3": 355,
        "entropy-3": 8.50952026009347,
        "cond_entropy-3": 0.21940038525107536,
        "total_length-nopunct": 343,
        "mean_pred_length-nopunct": 24.5,
        "std_pred_length-nopunct": 8.894219631712659,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6384839650145773,
        "vocab_size-1-nopunct": 219,
        "unique-1-nopunct": 178,
        "entropy-1-nopunct": 7.169041619957271,
        "distinct-2-nopunct": 0.8905775075987842,
        "vocab_size-2-nopunct": 293,
        "unique-2-nopunct": 271,
        "entropy-2-nopunct": 8.103907746411306,
        "cond_entropy-2-nopunct": 0.9790677193020748,
        "distinct-3-nopunct": 0.9650793650793651,
        "vocab_size-3-nopunct": 304,
        "unique-3-nopunct": 294,
        "entropy-3-nopunct": 8.226970280285132,
        "cond_entropy-3-nopunct": 0.13453080175495047,
        "msttr-100": 0.6325,
        "msttr-100_nopunct": 0.73333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.192394094832842,
        "rouge1": {
            "precision": 0.64327,
            "recall": 0.63887,
            "fmeasure": 0.62367
        },
        "rouge2": {
            "precision": 0.37412,
            "recall": 0.37452,
            "fmeasure": 0.36462
        },
        "rougeL": {
            "precision": 0.52587,
            "recall": 0.53275,
            "fmeasure": 0.51476
        },
        "rougeLsum": {
            "precision": 0.52587,
            "recall": 0.53275,
            "fmeasure": 0.51476
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.37681159420289856,
            "3": 0.673728813559322
        },
        "bleu": 35.55766,
        "nubia": {
            "semantic_relation": 3.64391,
            "contradiction": 22.3011,
            "irrelevancy": 18.98865,
            "logical_agreement": 58.71025,
            "grammar_ref": 4.37064,
            "grammar_hyp": 3.97359,
            "nubia_score": 0.60315
        },
        "meteor": 0.3328747657672253,
        "bleurt": 0.06397,
        "bertscore": {
            "precision": 0.8946,
            "recall": 0.89214,
            "f1": 0.89239
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 363,
        "mean_pred_length": 25.928571428571427,
        "std_pred_length": 8.73796548495853,
        "median_pred_length": 26.5,
        "min_pred_length": 11,
        "max_pred_length": 43,
        "distinct-1": 0.5179063360881543,
        "vocab_size-1": 188,
        "unique-1": 140,
        "entropy-1": 6.755703136511194,
        "distinct-2": 0.8510028653295129,
        "vocab_size-2": 297,
        "unique-2": 257,
        "entropy-2": 8.114592968280432,
        "cond_entropy-2": 1.2762845237806195,
        "distinct-3": 0.9283582089552239,
        "vocab_size-3": 311,
        "unique-3": 287,
        "entropy-3": 8.24473370325561,
        "cond_entropy-3": 0.13806570097819262,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 21.357142857142858,
        "std_pred_length-nopunct": 6.274746925541447,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.925251740551176,
        "distinct-2-nopunct": 0.8842105263157894,
        "vocab_size-2-nopunct": 252,
        "unique-2-nopunct": 222,
        "entropy-2-nopunct": 7.915292977450399,
        "cond_entropy-2-nopunct": 1.0266293476672284,
        "distinct-3-nopunct": 0.933579335793358,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 235,
        "entropy-3-nopunct": 7.949307712940555,
        "cond_entropy-3-nopunct": 0.025780009813831176,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.798775754518041,
        "rouge1": {
            "precision": 0.56834,
            "recall": 0.48685,
            "fmeasure": 0.50743
        },
        "rouge2": {
            "precision": 0.24428,
            "recall": 0.19652,
            "fmeasure": 0.20938
        },
        "rougeL": {
            "precision": 0.42897,
            "recall": 0.3733,
            "fmeasure": 0.38674
        },
        "rougeLsum": {
            "precision": 0.42897,
            "recall": 0.3733,
            "fmeasure": 0.38674
        },
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.2647058823529412,
            "3": 0.49429657794676807
        },
        "bleu": 17.50034,
        "nubia": {
            "semantic_relation": 3.19379,
            "contradiction": 29.25733,
            "irrelevancy": 29.63477,
            "logical_agreement": 41.1079,
            "grammar_ref": 3.91022,
            "grammar_hyp": 3.96962,
            "nubia_score": 0.45714
        },
        "meteor": 0.23666251037518574,
        "bleurt": -0.17805,
        "bertscore": {
            "precision": 0.87264,
            "recall": 0.84537,
            "f1": 0.85713
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "total_length": 50677,
        "mean_pred_length": 45.98638838475499,
        "std_pred_length": 20.10243269370337,
        "median_pred_length": 46.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.04153758115121258,
        "vocab_size-1": 2105,
        "unique-1": 610,
        "entropy-1": 5.888506922507653,
        "distinct-2": 0.11475542107917297,
        "vocab_size-2": 5689,
        "unique-2": 2118,
        "entropy-2": 10.149794211432273,
        "cond_entropy-2": 4.259178877249604,
        "distinct-3": 0.21215934644028633,
        "vocab_size-3": 10284,
        "unique-3": 4510,
        "entropy-3": 11.86296235196805,
        "cond_entropy-3": 1.758045159626262,
        "total_length-nopunct": 46650,
        "mean_pred_length-nopunct": 42.33212341197822,
        "std_pred_length-nopunct": 18.898103949277328,
        "median_pred_length-nopunct": 43.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.044930332261521974,
        "vocab_size-1-nopunct": 2096,
        "unique-1-nopunct": 610,
        "entropy-1-nopunct": 5.798288856046446,
        "distinct-2-nopunct": 0.11506542548520242,
        "vocab_size-2-nopunct": 5241,
        "unique-2-nopunct": 1926,
        "entropy-2-nopunct": 10.040282147793738,
        "cond_entropy-2-nopunct": 4.331566121965098,
        "distinct-3-nopunct": 0.21540746073887415,
        "vocab_size-3-nopunct": 9574,
        "unique-3-nopunct": 4302,
        "entropy-3-nopunct": 11.72707152234157,
        "cond_entropy-3-nopunct": 1.7251987888877338,
        "msttr-100": 0.44545,
        "msttr-100_nopunct": 0.44391,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1626939455693395,
        "rouge1": {
            "precision": 0.40704,
            "recall": 0.39956,
            "fmeasure": 0.39359
        },
        "rouge2": {
            "precision": 0.20366,
            "recall": 0.20871,
            "fmeasure": 0.20043
        },
        "rougeL": {
            "precision": 0.39329,
            "recall": 0.38677,
            "fmeasure": 0.38036
        },
        "rougeLsum": {
            "precision": 0.39329,
            "recall": 0.38677,
            "fmeasure": 0.38036
        },
        "local_recall": {
            "1": 0.09128541859967168,
            "2": 0.19100041282509977,
            "3": 0.2718790819182683,
            "4": 0.24675324675324675,
            "5": 0.3783783783783784,
            "6": 0.23076923076923078,
            "7": 0.2222222222222222
        },
        "bleu": 2.12791,
        "nubia": {
            "semantic_relation": 3.35264,
            "contradiction": 32.84279,
            "irrelevancy": 17.0349,
            "logical_agreement": 50.12232,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.57626,
            "nubia_score": 0.16413
        },
        "meteor": 0.13203547935670482,
        "bleurt": -0.47175,
        "bertscore": {
            "precision": 0.86227,
            "recall": 0.87319,
            "f1": 0.8672
        }
    },
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 40,
        "total_length": 623,
        "mean_pred_length": 15.575,
        "std_pred_length": 6.737534786552126,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 42,
        "distinct-1": 0.42215088282504015,
        "vocab_size-1": 263,
        "unique-1": 207,
        "entropy-1": 6.750228505547469,
        "distinct-2": 0.7409948542024014,
        "vocab_size-2": 432,
        "unique-2": 385,
        "entropy-2": 8.36708372198455,
        "cond_entropy-2": 1.4254954739044643,
        "distinct-3": 0.8360957642725598,
        "vocab_size-3": 454,
        "unique-3": 423,
        "entropy-3": 8.592871923373666,
        "cond_entropy-3": 0.2788466434677711,
        "total_length-nopunct": 531,
        "mean_pred_length-nopunct": 13.275,
        "std_pred_length-nopunct": 5.581162513312079,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4839924670433145,
        "vocab_size-1-nopunct": 257,
        "unique-1-nopunct": 206,
        "entropy-1-nopunct": 6.917079680487659,
        "distinct-2-nopunct": 0.7433808553971487,
        "vocab_size-2-nopunct": 365,
        "unique-2-nopunct": 326,
        "entropy-2-nopunct": 8.118351657697104,
        "cond_entropy-2-nopunct": 1.3358903208301554,
        "distinct-3-nopunct": 0.835920177383592,
        "vocab_size-3-nopunct": 377,
        "unique-3-nopunct": 350,
        "entropy-3-nopunct": 8.331069362202522,
        "cond_entropy-3-nopunct": 0.2781881572102245,
        "msttr-100": 0.595,
        "msttr-100_nopunct": 0.664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.426807610799935,
        "rouge1": {
            "precision": 0.75148,
            "recall": 0.71426,
            "fmeasure": 0.72116
        },
        "rouge2": {
            "precision": 0.54569,
            "recall": 0.51119,
            "fmeasure": 0.51951
        },
        "rougeL": {
            "precision": 0.66638,
            "recall": 0.62578,
            "fmeasure": 0.63573
        },
        "rougeLsum": {
            "precision": 0.66638,
            "recall": 0.62578,
            "fmeasure": 0.63573
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4307692307692308,
            "3": 0.7281323877068558
        },
        "bleu": 48.42027,
        "nubia": {
            "semantic_relation": 4.15539,
            "contradiction": 9.1094,
            "irrelevancy": 24.24218,
            "logical_agreement": 66.64843,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.35678,
            "nubia_score": 0.72557
        },
        "meteor": 0.3805997654679799,
        "bleurt": 0.29304,
        "bertscore": {
            "precision": 0.92468,
            "recall": 0.9199,
            "f1": 0.92113
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 193,
        "mean_pred_length": 27.571428571428573,
        "std_pred_length": 5.314592925068078,
        "median_pred_length": 28.0,
        "min_pred_length": 19,
        "max_pred_length": 38,
        "distinct-1": 0.538860103626943,
        "vocab_size-1": 104,
        "unique-1": 78,
        "entropy-1": 5.9786921408153315,
        "distinct-2": 0.8494623655913979,
        "vocab_size-2": 158,
        "unique-2": 136,
        "entropy-2": 7.213732332543629,
        "cond_entropy-2": 1.1901201370012124,
        "distinct-3": 0.9385474860335196,
        "vocab_size-3": 168,
        "unique-3": 159,
        "entropy-3": 7.35247625210041,
        "cond_entropy-3": 0.15147009469619124,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 22.428571428571427,
        "std_pred_length-nopunct": 5.900536122303824,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6369426751592356,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.2537087870918695,
        "distinct-2-nopunct": 0.8866666666666667,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.982021690438175,
        "cond_entropy-2-nopunct": 0.7635554615636422,
        "distinct-3-nopunct": 0.9440559440559441,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 129,
        "entropy-3-nopunct": 7.037425357727158,
        "cond_entropy-3-nopunct": 0.053498625333746,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.15924284223944,
        "rouge1": {
            "precision": 0.74604,
            "recall": 0.62643,
            "fmeasure": 0.67043
        },
        "rouge2": {
            "precision": 0.45403,
            "recall": 0.40544,
            "fmeasure": 0.42261
        },
        "rougeL": {
            "precision": 0.65674,
            "recall": 0.55671,
            "fmeasure": 0.59335
        },
        "rougeLsum": {
            "precision": 0.65674,
            "recall": 0.55671,
            "fmeasure": 0.59335
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.55,
            "3": 0.7282608695652174
        },
        "bleu": 40.23065,
        "nubia": {
            "semantic_relation": 3.13499,
            "contradiction": 23.08737,
            "irrelevancy": 35.17773,
            "logical_agreement": 41.7349,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.32885,
            "nubia_score": 0.45663
        },
        "meteor": 0.3363977749085514,
        "bleurt": 0.10702,
        "bertscore": {
            "precision": 0.92799,
            "recall": 0.88962,
            "f1": 0.90756
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 265,
        "mean_pred_length": 44.166666666666664,
        "std_pred_length": 19.641933600222654,
        "median_pred_length": 35.0,
        "min_pred_length": 26,
        "max_pred_length": 75,
        "distinct-1": 0.46037735849056605,
        "vocab_size-1": 122,
        "unique-1": 89,
        "entropy-1": 6.14840468593165,
        "distinct-2": 0.722007722007722,
        "vocab_size-2": 187,
        "unique-2": 156,
        "entropy-2": 7.247247525612596,
        "cond_entropy-2": 1.083008431097113,
        "distinct-3": 0.8142292490118577,
        "vocab_size-3": 206,
        "unique-3": 180,
        "entropy-3": 7.516207185649712,
        "cond_entropy-3": 0.2872101128926332,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 33.666666666666664,
        "std_pred_length-nopunct": 11.382247385975916,
        "median_pred_length-nopunct": 29.5,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.5841584158415841,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.456309658981918,
        "distinct-2-nopunct": 0.8520408163265306,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.2527930228419955,
        "cond_entropy-2-nopunct": 0.8128681135673125,
        "distinct-3-nopunct": 0.9105263157894737,
        "vocab_size-3-nopunct": 173,
        "unique-3-nopunct": 162,
        "entropy-3-nopunct": 7.367069687210005,
        "cond_entropy-3-nopunct": 0.12044245872398487,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7532839743437614,
        "rouge1": {
            "precision": 0.65643,
            "recall": 0.60037,
            "fmeasure": 0.6082
        },
        "rouge2": {
            "precision": 0.49479,
            "recall": 0.44821,
            "fmeasure": 0.45574
        },
        "rougeL": {
            "precision": 0.57646,
            "recall": 0.53364,
            "fmeasure": 0.53636
        },
        "rougeLsum": {
            "precision": 0.57646,
            "recall": 0.53364,
            "fmeasure": 0.53636
        },
        "local_recall": {
            "1": 0.48484848484848486,
            "2": 0.3055555555555556,
            "3": 0.6371681415929203
        },
        "bleu": 30.90247,
        "nubia": {
            "semantic_relation": 3.30082,
            "contradiction": 10.05765,
            "irrelevancy": 27.68345,
            "logical_agreement": 62.25891,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.18526,
            "nubia_score": 0.51836
        },
        "meteor": 0.32023856942457457,
        "bleurt": -0.00358,
        "bertscore": {
            "precision": 0.87666,
            "recall": 0.88489,
            "f1": 0.87825
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 152,
        "mean_pred_length": 30.4,
        "std_pred_length": 11.740528097151337,
        "median_pred_length": 24.0,
        "min_pred_length": 19,
        "max_pred_length": 47,
        "distinct-1": 0.5526315789473685,
        "vocab_size-1": 84,
        "unique-1": 59,
        "entropy-1": 5.888589543936138,
        "distinct-2": 0.8231292517006803,
        "vocab_size-2": 121,
        "unique-2": 103,
        "entropy-2": 6.798178807362526,
        "cond_entropy-2": 0.8768481026991777,
        "distinct-3": 0.8943661971830986,
        "vocab_size-3": 127,
        "unique-3": 116,
        "entropy-3": 6.91721507719022,
        "cond_entropy-3": 0.13317336621761355,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 26.2,
        "std_pred_length-nopunct": 10.007996802557443,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.6259541984732825,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 6.033348719929099,
        "distinct-2-nopunct": 0.873015873015873,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.699346986923305,
        "cond_entropy-2-nopunct": 0.689810738486598,
        "distinct-3-nopunct": 0.9421487603305785,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.7969220182484555,
        "cond_entropy-3-nopunct": 0.10079540060517712,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5158119292373144,
        "rouge1": {
            "precision": 0.54846,
            "recall": 0.55982,
            "fmeasure": 0.53955
        },
        "rouge2": {
            "precision": 0.31969,
            "recall": 0.31549,
            "fmeasure": 0.30815
        },
        "rougeL": {
            "precision": 0.45918,
            "recall": 0.47875,
            "fmeasure": 0.45706
        },
        "rougeLsum": {
            "precision": 0.45918,
            "recall": 0.47875,
            "fmeasure": 0.45706
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.3333333333333333,
            "3": 0.5733333333333334
        },
        "bleu": 22.89966,
        "nubia": {
            "semantic_relation": 2.92853,
            "contradiction": 7.44548,
            "irrelevancy": 59.19646,
            "logical_agreement": 33.35805,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.75312,
            "nubia_score": 0.4818
        },
        "meteor": 0.2387270024636564,
        "bleurt": -0.29291,
        "bertscore": {
            "precision": 0.84283,
            "recall": 0.85583,
            "f1": 0.84785
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 6674,
        "mean_pred_length": 18.590529247910865,
        "std_pred_length": 9.175298041418927,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37114174408151035,
        "vocab_size-1": 2477,
        "unique-1": 1838,
        "entropy-1": 9.116295805436831,
        "distinct-2": 0.8478226444972288,
        "vocab_size-2": 5354,
        "unique-2": 4964,
        "entropy-2": 12.106933198268315,
        "cond_entropy-2": 2.706384434217815,
        "distinct-3": 0.9701141705842847,
        "vocab_size-3": 5778,
        "unique-3": 5680,
        "entropy-3": 12.449944986891092,
        "cond_entropy-3": 0.36008039448712986,
        "total_length-nopunct": 5971,
        "mean_pred_length-nopunct": 16.632311977715876,
        "std_pred_length-nopunct": 8.233951247765605,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41316362418355385,
        "vocab_size-1-nopunct": 2467,
        "unique-1-nopunct": 1836,
        "entropy-1-nopunct": 9.445227093609574,
        "distinct-2-nopunct": 0.8638631503920171,
        "vocab_size-2-nopunct": 4848,
        "unique-2-nopunct": 4528,
        "entropy-2-nopunct": 11.994321202463482,
        "cond_entropy-2-nopunct": 2.696332625431439,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 5150,
        "unique-3-nopunct": 5072,
        "entropy-3-nopunct": 12.313821556761653,
        "cond_entropy-3-nopunct": 0.34267752635810567,
        "msttr-100": 0.73121,
        "msttr-100_nopunct": 0.77407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.529033641252033,
        "rouge1": {
            "precision": 0.85346,
            "recall": 0.75736,
            "fmeasure": 0.78716
        },
        "rouge2": {
            "precision": 0.71098,
            "recall": 0.62831,
            "fmeasure": 0.65233
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "local_recall": {
            "1": 0.040534804753820035,
            "2": 0.16219667943805874,
            "3": 0.3741794310722101,
            "4": 0.49920760697305866,
            "5": 0.6199376947040498,
            "6": 0.7210144927536232,
            "7": 0.8342878961435662
        },
        "bleu": 65.71936,
        "sari": 46.90126,
        "nubia": {
            "semantic_relation": 4.15419,
            "contradiction": 4.64645,
            "irrelevancy": 15.7492,
            "logical_agreement": 79.60434,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02579,
            "nubia_score": 0.65128
        },
        "meteor": 0.4415426994644947,
        "bleurt": 0.15856,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.93345,
            "f1": 0.94117
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 114,
        "mean_pred_length": 22.8,
        "std_pred_length": 7.95989949685296,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 36,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 76,
        "unique-1": 60,
        "entropy-1": 5.888602816868743,
        "distinct-2": 0.908256880733945,
        "vocab_size-2": 99,
        "unique-2": 90,
        "entropy-2": 6.577772512830463,
        "cond_entropy-2": 0.625975159374977,
        "distinct-3": 0.9711538461538461,
        "vocab_size-3": 101,
        "unique-3": 98,
        "entropy-3": 6.642747410448791,
        "cond_entropy-3": 0.07412931165419918,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 19.2,
        "std_pred_length-nopunct": 5.775811631277461,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.923402344426088,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.353948486352548,
        "cond_entropy-2-nopunct": 0.46689560106355,
        "distinct-3-nopunct": 0.9767441860465116,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.379753126795122,
        "cond_entropy-3-nopunct": 0.03474918427084368,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6771366775506866,
        "rouge1": {
            "precision": 0.56749,
            "recall": 0.59422,
            "fmeasure": 0.56874
        },
        "rouge2": {
            "precision": 0.27735,
            "recall": 0.29418,
            "fmeasure": 0.27819
        },
        "rougeL": {
            "precision": 0.42949,
            "recall": 0.47176,
            "fmeasure": 0.43789
        },
        "rougeLsum": {
            "precision": 0.42949,
            "recall": 0.47176,
            "fmeasure": 0.43789
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42424242424242425,
            "3": 0.6571428571428571
        },
        "bleu": 19.45829,
        "nubia": {
            "semantic_relation": 2.88314,
            "contradiction": 46.90579,
            "irrelevancy": 51.7059,
            "logical_agreement": 1.38831,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.50966,
            "nubia_score": 0.3333
        },
        "meteor": 0.2741429577449677,
        "bleurt": -0.18534,
        "bertscore": {
            "precision": 0.86203,
            "recall": 0.87545,
            "f1": 0.86755
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 165,
        "mean_pred_length": 33.0,
        "std_pred_length": 10.334408546211051,
        "median_pred_length": 33.0,
        "min_pred_length": 19,
        "max_pred_length": 48,
        "distinct-1": 0.5333333333333333,
        "vocab_size-1": 88,
        "unique-1": 60,
        "entropy-1": 5.919600545943014,
        "distinct-2": 0.7875,
        "vocab_size-2": 126,
        "unique-2": 100,
        "entropy-2": 6.853055907333277,
        "cond_entropy-2": 0.9061051605594928,
        "distinct-3": 0.8838709677419355,
        "vocab_size-3": 137,
        "unique-3": 120,
        "entropy-3": 7.038996098808679,
        "cond_entropy-3": 0.20106510075132916,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 28.0,
        "std_pred_length-nopunct": 10.392304845413264,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.992858482691223,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.645225504410174,
        "cond_entropy-2-nopunct": 0.6870494118764918,
        "distinct-3-nopunct": 0.8846153846153846,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 101,
        "entropy-3-nopunct": 6.785791755319506,
        "cond_entropy-3-nopunct": 0.1494735621647539,
        "msttr-100": 0.55,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6067549235244463,
        "rouge1": {
            "precision": 0.54412,
            "recall": 0.49545,
            "fmeasure": 0.49502
        },
        "rouge2": {
            "precision": 0.254,
            "recall": 0.25549,
            "fmeasure": 0.24153
        },
        "rougeL": {
            "precision": 0.38873,
            "recall": 0.35325,
            "fmeasure": 0.35017
        },
        "rougeLsum": {
            "precision": 0.38873,
            "recall": 0.35325,
            "fmeasure": 0.35017
        },
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.40625,
            "3": 0.5185185185185185
        },
        "bleu": 21.65537,
        "nubia": {
            "semantic_relation": 3.02758,
            "contradiction": 13.47531,
            "irrelevancy": 44.46537,
            "logical_agreement": 42.05932,
            "grammar_ref": 4.13756,
            "grammar_hyp": 3.4705,
            "nubia_score": 0.51033
        },
        "meteor": 0.24732578427675003,
        "bleurt": -0.20435,
        "bertscore": {
            "precision": 0.86712,
            "recall": 0.84566,
            "f1": 0.85497
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 300,
        "total_length": 4734,
        "mean_pred_length": 15.78,
        "std_pred_length": 6.448638099113125,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 58,
        "distinct-1": 0.37558090409801437,
        "vocab_size-1": 1778,
        "unique-1": 1362,
        "entropy-1": 8.77329374397208,
        "distinct-2": 0.7728912945421741,
        "vocab_size-2": 3427,
        "unique-2": 3015,
        "entropy-2": 11.404729968196676,
        "cond_entropy-2": 2.308136914928252,
        "distinct-3": 0.9218674407353653,
        "vocab_size-3": 3811,
        "unique-3": 3616,
        "entropy-3": 11.820712635745638,
        "cond_entropy-3": 0.4041790242499965,
        "total_length-nopunct": 4137,
        "mean_pred_length-nopunct": 13.79,
        "std_pred_length-nopunct": 5.710741341250421,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.4276045443558134,
        "vocab_size-1-nopunct": 1769,
        "unique-1-nopunct": 1360,
        "entropy-1-nopunct": 9.167783366298819,
        "distinct-2-nopunct": 0.800625488663018,
        "vocab_size-2-nopunct": 3072,
        "unique-2-nopunct": 2759,
        "entropy-2-nopunct": 11.263197121762726,
        "cond_entropy-2-nopunct": 2.1911749609060425,
        "distinct-3-nopunct": 0.9355385920271416,
        "vocab_size-3-nopunct": 3309,
        "unique-3-nopunct": 3163,
        "entropy-3-nopunct": 11.632934311209437,
        "cond_entropy-3-nopunct": 0.3954629696682827,
        "msttr-100": 0.71106,
        "msttr-100_nopunct": 0.77049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.402443199171282,
        "rouge1": {
            "precision": 0.79455,
            "recall": 0.75316,
            "fmeasure": 0.76387
        },
        "rouge2": {
            "precision": 0.55724,
            "recall": 0.52982,
            "fmeasure": 0.53589
        },
        "rougeL": {
            "precision": 0.67729,
            "recall": 0.64681,
            "fmeasure": 0.6532
        },
        "rougeLsum": {
            "precision": 0.67729,
            "recall": 0.64681,
            "fmeasure": 0.6532
        },
        "local_recall": {
            "1": 0.17386231038506417,
            "2": 0.4058898847631242,
            "3": 0.7878048780487805
        },
        "bleu": 44.18882,
        "nubia": {
            "semantic_relation": 4.37436,
            "contradiction": 6.7905,
            "irrelevancy": 21.64604,
            "logical_agreement": 71.56346,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.87137,
            "nubia_score": 0.77611
        },
        "meteor": 0.3990658774076103,
        "bleurt": 0.36009,
        "bertscore": {
            "precision": 0.93872,
            "recall": 0.9333,
            "f1": 0.93471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 158,
        "total_length": 2535,
        "mean_pred_length": 16.044303797468356,
        "std_pred_length": 6.5034994831982775,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.4067061143984221,
        "vocab_size-1": 1031,
        "unique-1": 810,
        "entropy-1": 8.317487194401501,
        "distinct-2": 0.7791333613798906,
        "vocab_size-2": 1852,
        "unique-2": 1631,
        "entropy-2": 10.550325902629856,
        "cond_entropy-2": 1.946119032212145,
        "distinct-3": 0.900405588102749,
        "vocab_size-3": 1998,
        "unique-3": 1883,
        "entropy-3": 10.85297464722612,
        "cond_entropy-3": 0.3140764618508391,
        "total_length-nopunct": 2197,
        "mean_pred_length-nopunct": 13.905063291139241,
        "std_pred_length-nopunct": 5.644295848811048,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.4647246244879381,
        "vocab_size-1-nopunct": 1021,
        "unique-1-nopunct": 808,
        "entropy-1-nopunct": 8.630588742324392,
        "distinct-2-nopunct": 0.7969592937714566,
        "vocab_size-2-nopunct": 1625,
        "unique-2-nopunct": 1448,
        "entropy-2-nopunct": 10.378308639602873,
        "cond_entropy-2-nopunct": 1.86706087652055,
        "distinct-3-nopunct": 0.9048378522062732,
        "vocab_size-3-nopunct": 1702,
        "unique-3-nopunct": 1608,
        "entropy-3-nopunct": 10.630659550898129,
        "cond_entropy-3-nopunct": 0.28773716027307134,
        "msttr-100": 0.7112,
        "msttr-100_nopunct": 0.76286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.4281565933621625,
        "rouge1": {
            "precision": 0.7419,
            "recall": 0.69608,
            "fmeasure": 0.70448
        },
        "rouge2": {
            "precision": 0.49631,
            "recall": 0.45688,
            "fmeasure": 0.46621
        },
        "rougeL": {
            "precision": 0.63739,
            "recall": 0.59679,
            "fmeasure": 0.6043
        },
        "rougeLsum": {
            "precision": 0.63739,
            "recall": 0.59679,
            "fmeasure": 0.6043
        },
        "local_recall": {
            "1": 0.22968197879858657,
            "2": 0.44466403162055335,
            "3": 0.7213525360050094
        },
        "bleu": 39.9765,
        "nubia": {
            "semantic_relation": 4.08667,
            "contradiction": 10.91324,
            "irrelevancy": 28.2531,
            "logical_agreement": 60.83366,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.65995,
            "nubia_score": 0.70168
        },
        "meteor": 0.36856509221750877,
        "bleurt": 0.19356,
        "bertscore": {
            "precision": 0.92028,
            "recall": 0.91267,
            "f1": 0.91454
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 316,
        "total_length": 15676,
        "mean_pred_length": 49.607594936708864,
        "std_pred_length": 16.778842706518855,
        "median_pred_length": 48.0,
        "min_pred_length": 19,
        "max_pred_length": 93,
        "distinct-1": 0.08146210768053075,
        "vocab_size-1": 1277,
        "unique-1": 504,
        "entropy-1": 5.681594427682392,
        "distinct-2": 0.20657552083333333,
        "vocab_size-2": 3173,
        "unique-2": 1526,
        "entropy-2": 9.762832802669449,
        "cond_entropy-2": 4.079425676637447,
        "distinct-3": 0.3575511831959585,
        "vocab_size-3": 5379,
        "unique-3": 2998,
        "entropy-3": 11.317138249287938,
        "cond_entropy-3": 1.5911503702752485,
        "total_length-nopunct": 14440,
        "mean_pred_length-nopunct": 45.69620253164557,
        "std_pred_length-nopunct": 15.919579879943994,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.08801939058171745,
        "vocab_size-1-nopunct": 1271,
        "unique-1-nopunct": 504,
        "entropy-1-nopunct": 5.576517062183249,
        "distinct-2-nopunct": 0.2089351458510337,
        "vocab_size-2-nopunct": 2951,
        "unique-2-nopunct": 1417,
        "entropy-2-nopunct": 9.650504611242882,
        "cond_entropy-2-nopunct": 4.148800356644678,
        "distinct-3-nopunct": 0.3584878331402086,
        "vocab_size-3-nopunct": 4950,
        "unique-3-nopunct": 2800,
        "entropy-3-nopunct": 11.176798584167985,
        "cond_entropy-3-nopunct": 1.5553189003783856,
        "msttr-100": 0.40929,
        "msttr-100_nopunct": 0.40222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.9681880297748847,
        "rouge1": {
            "precision": 0.36372,
            "recall": 0.36589,
            "fmeasure": 0.36086
        },
        "rouge2": {
            "precision": 0.16654,
            "recall": 0.17084,
            "fmeasure": 0.1666
        },
        "rougeL": {
            "precision": 0.35247,
            "recall": 0.35606,
            "fmeasure": 0.3502
        },
        "rougeLsum": {
            "precision": 0.35247,
            "recall": 0.35606,
            "fmeasure": 0.3502
        },
        "local_recall": {
            "1": 0.09489222118088098,
            "2": 0.18716835504100338,
            "3": 0.2352112676056338,
            "4": 0.10526315789473684,
            "5": 0.3181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "bleu": 1.3925,
        "nubia": {
            "semantic_relation": 3.37484,
            "contradiction": 30.99022,
            "irrelevancy": 17.18746,
            "logical_agreement": 51.82232,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.44683,
            "nubia_score": 0.15503
        },
        "meteor": 0.11855285114052541,
        "bleurt": -0.49603,
        "bertscore": {
            "precision": 0.85806,
            "recall": 0.87123,
            "f1": 0.86398
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 986,
        "total_length": 44180,
        "mean_pred_length": 44.80730223123732,
        "std_pred_length": 20.36859600634543,
        "median_pred_length": 45.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.04515617926663649,
        "vocab_size-1": 1995,
        "unique-1": 597,
        "entropy-1": 5.904309285342246,
        "distinct-2": 0.12406815761448349,
        "vocab_size-2": 5359,
        "unique-2": 2065,
        "entropy-2": 10.137138819714616,
        "cond_entropy-2": 4.230116631355785,
        "distinct-3": 0.22649734647460198,
        "vocab_size-3": 9560,
        "unique-3": 4347,
        "entropy-3": 11.809617535113654,
        "cond_entropy-3": 1.7162159220768938,
        "total_length-nopunct": 40635,
        "mean_pred_length-nopunct": 41.21196754563895,
        "std_pred_length-nopunct": 19.107539658155712,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.048874123292727945,
        "vocab_size-1-nopunct": 1986,
        "unique-1-nopunct": 597,
        "entropy-1-nopunct": 5.814183499324554,
        "distinct-2-nopunct": 0.12424020782365255,
        "vocab_size-2-nopunct": 4926,
        "unique-2-nopunct": 1872,
        "entropy-2-nopunct": 10.025446534294241,
        "cond_entropy-2-nopunct": 4.302145894327426,
        "distinct-3-nopunct": 0.2292631197785997,
        "vocab_size-3-nopunct": 8864,
        "unique-3-nopunct": 4116,
        "entropy-3-nopunct": 11.668560873077501,
        "cond_entropy-3-nopunct": 1.6807894018373772,
        "msttr-100": 0.42839,
        "msttr-100_nopunct": 0.42372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2070971124182415,
        "rouge1": {
            "precision": 0.44225,
            "recall": 0.4323,
            "fmeasure": 0.42703
        },
        "rouge2": {
            "precision": 0.22179,
            "recall": 0.22763,
            "fmeasure": 0.21874
        },
        "rougeL": {
            "precision": 0.4273,
            "recall": 0.41842,
            "fmeasure": 0.41267
        },
        "rougeLsum": {
            "precision": 0.4273,
            "recall": 0.41842,
            "fmeasure": 0.41267
        },
        "local_recall": {
            "1": 0.0938291785860237,
            "2": 0.19317650724411903,
            "3": 0.2832418742085268,
            "4": 0.24675324675324675,
            "5": 0.3783783783783784,
            "6": 0.23076923076923078,
            "7": 0.2222222222222222
        },
        "bleu": 2.32882,
        "nubia": {
            "semantic_relation": 3.34862,
            "contradiction": 32.97434,
            "irrelevancy": 17.12778,
            "logical_agreement": 49.89788,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.61468,
            "nubia_score": 0.16606
        },
        "meteor": 0.1373510657219899,
        "bleurt": -0.4669,
        "bertscore": {
            "precision": 0.86338,
            "recall": 0.87387,
            "f1": 0.8681
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 128,
        "mean_pred_length": 32.0,
        "std_pred_length": 13.656500283747663,
        "median_pred_length": 35.5,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.5703125,
        "vocab_size-1": 73,
        "unique-1": 56,
        "entropy-1": 5.6767636025992605,
        "distinct-2": 0.9193548387096774,
        "vocab_size-2": 114,
        "unique-2": 105,
        "entropy-2": 6.786818185369415,
        "cond_entropy-2": 1.0882234988153539,
        "distinct-3": 0.975,
        "vocab_size-3": 117,
        "unique-3": 114,
        "entropy-3": 6.856890595608534,
        "cond_entropy-3": 0.07565168107300536,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 29.25,
        "std_pred_length-nopunct": 12.754901018824098,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.6068376068376068,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.65905895537065,
        "distinct-2-nopunct": 0.9292035398230089,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.671905621688094,
        "cond_entropy-2-nopunct": 1.0468751889444228,
        "distinct-3-nopunct": 0.981651376146789,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.731487077070493,
        "cond_entropy-3-nopunct": 0.05584836696874293,
        "msttr-100": 0.6,
        "msttr-100_nopunct": 0.62,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5218116119495306,
        "rouge1": {
            "precision": 0.62181,
            "recall": 0.61323,
            "fmeasure": 0.61638
        },
        "rouge2": {
            "precision": 0.33603,
            "recall": 0.3397,
            "fmeasure": 0.33729
        },
        "rougeL": {
            "precision": 0.52116,
            "recall": 0.52323,
            "fmeasure": 0.52118
        },
        "rougeLsum": {
            "precision": 0.52116,
            "recall": 0.52323,
            "fmeasure": 0.52118
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6071428571428571
        },
        "bleu": 18.38938,
        "nubia": {
            "semantic_relation": 3.22916,
            "contradiction": 27.93791,
            "irrelevancy": 39.79726,
            "logical_agreement": 32.26483,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.08833,
            "nubia_score": 0.52697
        },
        "meteor": 0.26614524723539557,
        "bleurt": 0.05248,
        "bertscore": {
            "precision": 0.88686,
            "recall": 0.8611,
            "f1": 0.87226
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 414,
        "total_length": 9180,
        "mean_pred_length": 22.17391304347826,
        "std_pred_length": 8.70413837118351,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 76,
        "distinct-1": 0.13899782135076252,
        "vocab_size-1": 1276,
        "unique-1": 555,
        "entropy-1": 7.662600517843203,
        "distinct-2": 0.3698380104950947,
        "vocab_size-2": 3242,
        "unique-2": 1921,
        "entropy-2": 10.631460899014252,
        "cond_entropy-2": 2.8052702329230517,
        "distinct-3": 0.5604645593869731,
        "vocab_size-3": 4681,
        "unique-3": 3308,
        "entropy-3": 11.65378779979743,
        "cond_entropy-3": 1.087976614340343,
        "total_length-nopunct": 8026,
        "mean_pred_length-nopunct": 19.386473429951693,
        "std_pred_length-nopunct": 7.754718721045319,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.15786194866683279,
        "vocab_size-1-nopunct": 1267,
        "unique-1-nopunct": 554,
        "entropy-1-nopunct": 7.951175404168543,
        "distinct-2-nopunct": 0.38163426169206516,
        "vocab_size-2-nopunct": 2905,
        "unique-2-nopunct": 1756,
        "entropy-2-nopunct": 10.501223437818167,
        "cond_entropy-2-nopunct": 2.703378520566815,
        "distinct-3-nopunct": 0.5668241178105029,
        "vocab_size-3-nopunct": 4080,
        "unique-3-nopunct": 2915,
        "entropy-3-nopunct": 11.45677468383907,
        "cond_entropy-3-nopunct": 1.0245512677413822,
        "msttr-100": 0.49714,
        "msttr-100_nopunct": 0.51825,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.525921929916208,
        "rouge1": {
            "precision": 0.6236,
            "recall": 0.64223,
            "fmeasure": 0.6251
        },
        "rouge2": {
            "precision": 0.38009,
            "recall": 0.39163,
            "fmeasure": 0.38094
        },
        "rougeL": {
            "precision": 0.51243,
            "recall": 0.53149,
            "fmeasure": 0.51504
        },
        "rougeLsum": {
            "precision": 0.51243,
            "recall": 0.53149,
            "fmeasure": 0.51504
        },
        "local_recall": {
            "1": 0.20801364023870417,
            "2": 0.5474635861376193,
            "3": 0.6899363057324841,
            "4": 0.7272727272727273,
            "5": 0.625
        },
        "bleu": 33.95073,
        "nubia": {
            "semantic_relation": 3.61794,
            "contradiction": 34.81488,
            "irrelevancy": 11.34813,
            "logical_agreement": 53.83699,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.70284,
            "nubia_score": 0.57484
        },
        "meteor": 0.31392456911823957,
        "bleurt": -0.17497,
        "bertscore": {
            "precision": 0.87542,
            "recall": 0.8837,
            "f1": 0.87836
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 217,
        "total_length": 11977,
        "mean_pred_length": 55.193548387096776,
        "std_pred_length": 13.698846358595839,
        "median_pred_length": 57.0,
        "min_pred_length": 24,
        "max_pred_length": 89,
        "distinct-1": 0.1006929949069049,
        "vocab_size-1": 1206,
        "unique-1": 526,
        "entropy-1": 5.772334908147359,
        "distinct-2": 0.2413265306122449,
        "vocab_size-2": 2838,
        "unique-2": 1410,
        "entropy-2": 9.80508892612066,
        "cond_entropy-2": 4.0322784430318555,
        "distinct-3": 0.4011955297582951,
        "vocab_size-3": 4631,
        "unique-3": 2640,
        "entropy-3": 11.271906321862073,
        "cond_entropy-3": 1.491963298240899,
        "total_length-nopunct": 11037,
        "mean_pred_length-nopunct": 50.86175115207373,
        "std_pred_length-nopunct": 13.163252251502751,
        "median_pred_length-nopunct": 52.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.10863459273353267,
        "vocab_size-1-nopunct": 1199,
        "unique-1-nopunct": 524,
        "entropy-1-nopunct": 5.678342777959199,
        "distinct-2-nopunct": 0.24695009242144178,
        "vocab_size-2-nopunct": 2672,
        "unique-2-nopunct": 1321,
        "entropy-2-nopunct": 9.723018264008056,
        "cond_entropy-2-nopunct": 4.103699245804956,
        "distinct-3-nopunct": 0.40648872960482885,
        "vocab_size-3-nopunct": 4310,
        "unique-3-nopunct": 2487,
        "entropy-3-nopunct": 11.156633388045574,
        "cond_entropy-3-nopunct": 1.4581427242147111,
        "msttr-100": 0.42218,
        "msttr-100_nopunct": 0.41618,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1179873127463757,
        "rouge1": {
            "precision": 0.48936,
            "recall": 0.49075,
            "fmeasure": 0.47754
        },
        "rouge2": {
            "precision": 0.23052,
            "recall": 0.2465,
            "fmeasure": 0.22961
        },
        "rougeL": {
            "precision": 0.4744,
            "recall": 0.47555,
            "fmeasure": 0.46254
        },
        "rougeLsum": {
            "precision": 0.4744,
            "recall": 0.47555,
            "fmeasure": 0.46254
        },
        "local_recall": {
            "1": 0.09018404907975461,
            "2": 0.19614147909967847,
            "3": 0.2978723404255319,
            "4": 0.2727272727272727
        },
        "bleu": 1.98258,
        "nubia": {
            "semantic_relation": 3.37175,
            "contradiction": 30.78915,
            "irrelevancy": 17.04439,
            "logical_agreement": 52.16647,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.3998,
            "nubia_score": 0.14069
        },
        "meteor": 0.13356536941270689,
        "bleurt": -0.50859,
        "bertscore": {
            "precision": 0.86004,
            "recall": 0.87189,
            "f1": 0.86531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 35,
        "total_length": 529,
        "mean_pred_length": 15.114285714285714,
        "std_pred_length": 5.558886983002615,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.3686200378071834,
        "vocab_size-1": 195,
        "unique-1": 154,
        "entropy-1": 6.38888884497586,
        "distinct-2": 0.680161943319838,
        "vocab_size-2": 336,
        "unique-2": 289,
        "entropy-2": 7.967328405386157,
        "cond_entropy-2": 1.4033653129544152,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 374,
        "unique-3": 343,
        "entropy-3": 8.297904069083577,
        "cond_entropy-3": 0.3672348879077486,
        "total_length-nopunct": 445,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 4.644944585684702,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42696629213483145,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.466504482370657,
        "distinct-2-nopunct": 0.7121951219512195,
        "vocab_size-2-nopunct": 292,
        "unique-2-nopunct": 254,
        "entropy-2-nopunct": 7.806236230512639,
        "cond_entropy-2-nopunct": 1.4621458821242286,
        "distinct-3-nopunct": 0.8266666666666667,
        "vocab_size-3-nopunct": 310,
        "unique-3-nopunct": 288,
        "entropy-3-nopunct": 8.033782145649093,
        "cond_entropy-3-nopunct": 0.2979288762386589,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.162520376283034,
        "rouge1": {
            "precision": 0.77734,
            "recall": 0.72406,
            "fmeasure": 0.74261
        },
        "rouge2": {
            "precision": 0.54081,
            "recall": 0.5071,
            "fmeasure": 0.51843
        },
        "rougeL": {
            "precision": 0.66686,
            "recall": 0.62695,
            "fmeasure": 0.63996
        },
        "rougeLsum": {
            "precision": 0.66686,
            "recall": 0.62695,
            "fmeasure": 0.63996
        },
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.4519230769230769,
            "3": 0.7579250720461095
        },
        "bleu": 46.12905,
        "nubia": {
            "semantic_relation": 4.12199,
            "contradiction": 6.61111,
            "irrelevancy": 19.90981,
            "logical_agreement": 73.47907,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.23033,
            "nubia_score": 0.74865
        },
        "meteor": 0.39763523916366733,
        "bleurt": 0.42543,
        "bertscore": {
            "precision": 0.93349,
            "recall": 0.92599,
            "f1": 0.92894
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9867895664125071,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.57857,
            "fmeasure": 0.64904
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25776,
            "fmeasure": 0.28889
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.36905,
            "fmeasure": 0.41186
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.36905,
            "fmeasure": 0.41186
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.2727272727272727,
            "3": 0.7777777777777778
        },
        "bleu": 20.84942,
        "nubia": {
            "semantic_relation": 3.97237,
            "contradiction": 0.16982,
            "irrelevancy": 33.52448,
            "logical_agreement": 66.3057,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.14832,
            "nubia_score": 0.68686
        },
        "meteor": 0.30215718404277325,
        "bleurt": 0.19306,
        "bertscore": {
            "precision": 0.93917,
            "recall": 0.90045,
            "f1": 0.89663
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 116,
        "total_length": 6497,
        "mean_pred_length": 56.008620689655174,
        "std_pred_length": 14.152187408394878,
        "median_pred_length": 58.0,
        "min_pred_length": 21,
        "max_pred_length": 83,
        "distinct-1": 0.09158072956749269,
        "vocab_size-1": 595,
        "unique-1": 210,
        "entropy-1": 5.268741800257006,
        "distinct-2": 0.21611032753486914,
        "vocab_size-2": 1379,
        "unique-2": 565,
        "entropy-2": 9.056156399590066,
        "cond_entropy-2": 3.793725575986718,
        "distinct-3": 0.35371109337589784,
        "vocab_size-3": 2216,
        "unique-3": 1057,
        "entropy-3": 10.325112976543231,
        "cond_entropy-3": 1.3002244233840148,
        "total_length-nopunct": 6015,
        "mean_pred_length-nopunct": 51.85344827586207,
        "std_pred_length-nopunct": 13.717126414628936,
        "median_pred_length-nopunct": 53.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.09808811305070657,
        "vocab_size-1-nopunct": 590,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 5.139756559259014,
        "distinct-2-nopunct": 0.21851161213765044,
        "vocab_size-2-nopunct": 1289,
        "unique-2-nopunct": 524,
        "entropy-2-nopunct": 8.934490695464188,
        "cond_entropy-2-nopunct": 3.8554514376316584,
        "distinct-3-nopunct": 0.35344976655715027,
        "vocab_size-3-nopunct": 2044,
        "unique-3-nopunct": 985,
        "entropy-3-nopunct": 10.196108324255018,
        "cond_entropy-3-nopunct": 1.2883413042670844,
        "msttr-100": 0.39109,
        "msttr-100_nopunct": 0.38217,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.7725042598069203,
        "rouge1": {
            "precision": 0.10776,
            "recall": 0.12131,
            "fmeasure": 0.10938
        },
        "rouge2": {
            "precision": 0.04957,
            "recall": 0.04789,
            "fmeasure": 0.04483
        },
        "rougeL": {
            "precision": 0.10417,
            "recall": 0.11771,
            "fmeasure": 0.10579
        },
        "rougeLsum": {
            "precision": 0.10417,
            "recall": 0.11771,
            "fmeasure": 0.10579
        },
        "local_recall": {
            "1": 0.07376126126126126,
            "2": 0.17452830188679244,
            "3": 0.18518518518518517
        },
        "bleu": 0.38749,
        "nubia": {
            "semantic_relation": 3.38686,
            "contradiction": 31.72456,
            "irrelevancy": 16.24537,
            "logical_agreement": 52.03007,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.24966,
            "nubia_score": 0.14775
        },
        "meteor": 0.09399473124588646,
        "bleurt": -0.51301,
        "bertscore": {
            "precision": 0.85283,
            "recall": 0.86745,
            "f1": 0.85954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 77,
        "total_length": 1255,
        "mean_pred_length": 16.2987012987013,
        "std_pred_length": 6.175075445282704,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.4653386454183267,
        "vocab_size-1": 584,
        "unique-1": 459,
        "entropy-1": 7.850948976459987,
        "distinct-2": 0.8599320882852292,
        "vocab_size-2": 1013,
        "unique-2": 925,
        "entropy-2": 9.820196554750687,
        "cond_entropy-2": 1.7168563458320256,
        "distinct-3": 0.9427792915531336,
        "vocab_size-3": 1038,
        "unique-3": 999,
        "entropy-3": 9.96828794517702,
        "cond_entropy-3": 0.14835386475889306,
        "total_length-nopunct": 1094,
        "mean_pred_length-nopunct": 14.207792207792208,
        "std_pred_length-nopunct": 5.685108509256196,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5246800731261426,
        "vocab_size-1-nopunct": 574,
        "unique-1-nopunct": 456,
        "entropy-1-nopunct": 8.070251696248404,
        "distinct-2-nopunct": 0.8672566371681416,
        "vocab_size-2-nopunct": 882,
        "unique-2-nopunct": 810,
        "entropy-2-nopunct": 9.62135620575878,
        "cond_entropy-2-nopunct": 1.6490167908598394,
        "distinct-3-nopunct": 0.9457446808510638,
        "vocab_size-3-nopunct": 889,
        "unique-3-nopunct": 856,
        "entropy-3-nopunct": 9.74985880823966,
        "cond_entropy-3-nopunct": 0.14558103585373708,
        "msttr-100": 0.70417,
        "msttr-100_nopunct": 0.743,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.209455030500598,
        "rouge1": {
            "precision": 0.76904,
            "recall": 0.71455,
            "fmeasure": 0.73159
        },
        "rouge2": {
            "precision": 0.53674,
            "recall": 0.50049,
            "fmeasure": 0.51172
        },
        "rougeL": {
            "precision": 0.67266,
            "recall": 0.62981,
            "fmeasure": 0.64235
        },
        "rougeLsum": {
            "precision": 0.67266,
            "recall": 0.62981,
            "fmeasure": 0.64235
        },
        "local_recall": {
            "1": 0.23735408560311283,
            "2": 0.4496124031007752,
            "3": 0.7776332899869961
        },
        "bleu": 46.3525,
        "nubia": {
            "semantic_relation": 4.11389,
            "contradiction": 11.96291,
            "irrelevancy": 23.60393,
            "logical_agreement": 64.43316,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.66169,
            "nubia_score": 0.70295
        },
        "meteor": 0.3863758554838733,
        "bleurt": 0.23837,
        "bertscore": {
            "precision": 0.92841,
            "recall": 0.92121,
            "f1": 0.92325
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 60,
        "mean_pred_length": 30.0,
        "std_pred_length": 4.0,
        "median_pred_length": 30.0,
        "min_pred_length": 26,
        "max_pred_length": 34,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 35,
        "unique-1": 20,
        "entropy-1": 4.8045745041515575,
        "distinct-2": 0.8103448275862069,
        "vocab_size-2": 47,
        "unique-2": 36,
        "entropy-2": 5.478670650299984,
        "cond_entropy-2": 0.6776242872331502,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 50,
        "unique-3": 44,
        "entropy-3": 5.593069207771894,
        "cond_entropy-3": 0.12794535550146072,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 24.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 24.5,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.673469387755102,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.88798248749405,
        "distinct-2-nopunct": 0.8297872340425532,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.214163319762744,
        "cond_entropy-2-nopunct": 0.3145522091461911,
        "distinct-3-nopunct": 0.9111111111111111,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.314075318551897,
        "cond_entropy-3-nopunct": 0.07059757798537057,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.770479431438394,
        "rouge1": {
            "precision": 0.51232,
            "recall": 0.45768,
            "fmeasure": 0.47381
        },
        "rouge2": {
            "precision": 0.20076,
            "recall": 0.16896,
            "fmeasure": 0.17995
        },
        "rougeL": {
            "precision": 0.36913,
            "recall": 0.38244,
            "fmeasure": 0.3725
        },
        "rougeLsum": {
            "precision": 0.36913,
            "recall": 0.38244,
            "fmeasure": 0.3725
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.42857142857142855,
            "3": 0.47368421052631576
        },
        "bleu": 14.23412,
        "nubia": {
            "semantic_relation": 3.0948,
            "contradiction": 68.87693,
            "irrelevancy": 11.221,
            "logical_agreement": 19.90206,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.79058,
            "nubia_score": 0.45891
        },
        "meteor": 0.2266925684766158,
        "bleurt": -0.31882,
        "bertscore": {
            "precision": 0.86274,
            "recall": 0.85142,
            "f1": 0.85626
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 165,
        "mean_pred_length": 41.25,
        "std_pred_length": 15.155444566227676,
        "median_pred_length": 39.5,
        "min_pred_length": 22,
        "max_pred_length": 64,
        "distinct-1": 0.4909090909090909,
        "vocab_size-1": 81,
        "unique-1": 59,
        "entropy-1": 5.616099012461923,
        "distinct-2": 0.6894409937888198,
        "vocab_size-2": 111,
        "unique-2": 90,
        "entropy-2": 6.440456646425069,
        "cond_entropy-2": 0.8383079774722979,
        "distinct-3": 0.7961783439490446,
        "vocab_size-3": 125,
        "unique-3": 106,
        "entropy-3": 6.8042148988299,
        "cond_entropy-3": 0.38644513728863084,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 30.25,
        "std_pred_length-nopunct": 11.255554184490428,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.6198347107438017,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.795456961308505,
        "distinct-2-nopunct": 0.7863247863247863,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.344860929366606,
        "cond_entropy-2-nopunct": 0.5878110202278957,
        "distinct-3-nopunct": 0.8584070796460177,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.491688559948267,
        "cond_entropy-3-nopunct": 0.16542953466010424,
        "msttr-100": 0.48,
        "msttr-100_nopunct": 0.62,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7381813421215946,
        "rouge1": {
            "precision": 0.58402,
            "recall": 0.57584,
            "fmeasure": 0.54362
        },
        "rouge2": {
            "precision": 0.35188,
            "recall": 0.35293,
            "fmeasure": 0.32213
        },
        "rougeL": {
            "precision": 0.47386,
            "recall": 0.47086,
            "fmeasure": 0.43356
        },
        "rougeLsum": {
            "precision": 0.47386,
            "recall": 0.47086,
            "fmeasure": 0.43356
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6136363636363636,
            "3": 0.5087719298245614
        },
        "bleu": 33.21548,
        "nubia": {
            "semantic_relation": 3.61338,
            "contradiction": 5.38262,
            "irrelevancy": 11.76224,
            "logical_agreement": 82.85515,
            "grammar_ref": 4.25341,
            "grammar_hyp": 3.89493,
            "nubia_score": 0.44432
        },
        "meteor": 0.27858567127848005,
        "bleurt": -0.2595,
        "bertscore": {
            "precision": 0.85374,
            "recall": 0.87628,
            "f1": 0.86001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 105,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.4142698058981855,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6571428571428571,
        "vocab_size-1": 69,
        "unique-1": 55,
        "entropy-1": 5.701689228985158,
        "distinct-2": 0.9795918367346939,
        "vocab_size-2": 96,
        "unique-2": 94,
        "entropy-2": 6.573893517584606,
        "cond_entropy-2": 0.7302440235052149,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.06295915996046836,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 6.334228364970104,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.717391304347826,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.702219316825095,
        "distinct-2-nopunct": 0.9764705882352941,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.362332112608295,
        "cond_entropy-2-nopunct": 0.7277527778375971,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.07270666599340202,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.051196299649009,
        "rouge1": {
            "precision": 0.72931,
            "recall": 0.69874,
            "fmeasure": 0.69637
        },
        "rouge2": {
            "precision": 0.52227,
            "recall": 0.51839,
            "fmeasure": 0.50906
        },
        "rougeL": {
            "precision": 0.67565,
            "recall": 0.64596,
            "fmeasure": 0.64345
        },
        "rougeLsum": {
            "precision": 0.67565,
            "recall": 0.64596,
            "fmeasure": 0.64345
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.27586206896551724,
            "3": 0.7457627118644068
        },
        "bleu": 38.00073,
        "nubia": {
            "semantic_relation": 3.80284,
            "contradiction": 27.94634,
            "irrelevancy": 29.80643,
            "logical_agreement": 42.24722,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.4994,
            "nubia_score": 0.59442
        },
        "meteor": 0.32891983903223343,
        "bleurt": -0.01995,
        "bertscore": {
            "precision": 0.89565,
            "recall": 0.89551,
            "f1": 0.8947
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.199469020553248,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.02677875348937534,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.011365041826378,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.17961067210860202,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.02136900249640835,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.053296417028095,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.75298,
            "fmeasure": 0.61725
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.56581,
            "fmeasure": 0.45657
        },
        "rougeL": {
            "precision": 0.50794,
            "recall": 0.73214,
            "fmeasure": 0.59923
        },
        "rougeLsum": {
            "precision": 0.50794,
            "recall": 0.73214,
            "fmeasure": 0.59923
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "bleu": 32.99895,
        "nubia": {
            "semantic_relation": 3.89014,
            "contradiction": 0.12172,
            "irrelevancy": 46.59617,
            "logical_agreement": 53.28211,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.33223,
            "nubia_score": 0.75683
        },
        "meteor": 0.3987346638029704,
        "bleurt": 0.31818,
        "bertscore": {
            "precision": 0.86785,
            "recall": 0.90835,
            "f1": 0.88371
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 500,
        "total_length": 12454,
        "mean_pred_length": 24.908,
        "std_pred_length": 6.440460853075655,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.012847277982977356,
        "vocab_size-1": 160,
        "unique-1": 20,
        "entropy-1": 5.797226932274379,
        "distinct-2": 0.04358373766103396,
        "vocab_size-2": 521,
        "unique-2": 119,
        "entropy-2": 7.476161191065187,
        "cond_entropy-2": 1.590599924108704,
        "distinct-3": 0.08617077003666841,
        "vocab_size-3": 987,
        "unique-3": 289,
        "entropy-3": 8.491260940751484,
        "cond_entropy-3": 1.039209344221498,
        "total_length-nopunct": 11424,
        "mean_pred_length-nopunct": 22.848,
        "std_pred_length-nopunct": 5.990734178712991,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.013830532212885153,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 5.853153309489909,
        "distinct-2-nopunct": 0.045953863053826434,
        "vocab_size-2-nopunct": 502,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 7.463752454266135,
        "cond_entropy-2-nopunct": 1.6580686088829728,
        "distinct-3-nopunct": 0.09238296239447429,
        "vocab_size-3-nopunct": 963,
        "unique-3-nopunct": 284,
        "entropy-3-nopunct": 8.54463614384045,
        "cond_entropy-3-nopunct": 1.083041219350781,
        "msttr-100": 0.48153,
        "msttr-100_nopunct": 0.48719,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.4194621016683735,
        "rouge1": {
            "precision": 0.76489,
            "recall": 0.72436,
            "fmeasure": 0.73326
        },
        "rouge2": {
            "precision": 0.46715,
            "recall": 0.44182,
            "fmeasure": 0.44738
        },
        "rougeL": {
            "precision": 0.54015,
            "recall": 0.51015,
            "fmeasure": 0.51709
        },
        "rougeLsum": {
            "precision": 0.54015,
            "recall": 0.51015,
            "fmeasure": 0.51709
        },
        "local_recall": {
            "1": 0.7190551474007254
        },
        "bleu": 32.4159,
        "nubia": {
            "semantic_relation": 4.32431,
            "contradiction": 2.93667,
            "irrelevancy": 17.73709,
            "logical_agreement": 79.32624,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.3992,
            "nubia_score": 0.79945
        },
        "meteor": 0.3681335080319614,
        "bleurt": 0.22472,
        "bertscore": {
            "precision": 0.9214,
            "recall": 0.90717,
            "f1": 0.91392
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 642,
        "total_length": 24956,
        "mean_pred_length": 38.87227414330218,
        "std_pred_length": 20.01905348174353,
        "median_pred_length": 35.0,
        "min_pred_length": 6,
        "max_pred_length": 88,
        "distinct-1": 0.0642330501682962,
        "vocab_size-1": 1603,
        "unique-1": 556,
        "entropy-1": 5.937762406627253,
        "distinct-2": 0.16854487126758247,
        "vocab_size-2": 4098,
        "unique-2": 1770,
        "entropy-2": 10.073192982259915,
        "cond_entropy-2": 4.125556695366048,
        "distinct-3": 0.28852652923284894,
        "vocab_size-3": 6830,
        "unique-3": 3396,
        "entropy-3": 11.577899272917534,
        "cond_entropy-3": 1.5523060827132797,
        "total_length-nopunct": 22984,
        "mean_pred_length-nopunct": 35.8006230529595,
        "std_pred_length-nopunct": 18.820205212016074,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.06939610163592064,
        "vocab_size-1-nopunct": 1595,
        "unique-1-nopunct": 556,
        "entropy-1-nopunct": 5.847749133017169,
        "distinct-2-nopunct": 0.16645779249843345,
        "vocab_size-2-nopunct": 3719,
        "unique-2-nopunct": 1564,
        "entropy-2-nopunct": 9.933639284724457,
        "cond_entropy-2-nopunct": 4.196552595049159,
        "distinct-3-nopunct": 0.28700460829493085,
        "vocab_size-3-nopunct": 6228,
        "unique-3-nopunct": 3102,
        "entropy-3-nopunct": 11.419154618072886,
        "cond_entropy-3-nopunct": 1.5288341899933033,
        "msttr-100": 0.43173,
        "msttr-100_nopunct": 0.42349,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.3631936675375047,
        "rouge1": {
            "precision": 0.47284,
            "recall": 0.46179,
            "fmeasure": 0.45581
        },
        "rouge2": {
            "precision": 0.26331,
            "recall": 0.26972,
            "fmeasure": 0.26067
        },
        "rougeL": {
            "precision": 0.4528,
            "recall": 0.44338,
            "fmeasure": 0.43667
        },
        "rougeLsum": {
            "precision": 0.4528,
            "recall": 0.44338,
            "fmeasure": 0.43667
        },
        "local_recall": {
            "1": 0.10159800615745491,
            "2": 0.21989100817438692,
            "3": 0.3152554233729881,
            "4": 0.25,
            "5": 0.36363636363636365,
            "6": 0.2727272727272727,
            "7": 0.25
        },
        "bleu": 3.08582,
        "nubia": {
            "semantic_relation": 3.34884,
            "contradiction": 33.34465,
            "irrelevancy": 16.95061,
            "logical_agreement": 49.70474,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.74035,
            "nubia_score": 0.17846
        },
        "meteor": 0.15211006905757274,
        "bleurt": -0.44389,
        "bertscore": {
            "precision": 0.86809,
            "recall": 0.87735,
            "f1": 0.87226
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 82,
        "mean_pred_length": 41.0,
        "std_pred_length": 0.0,
        "median_pred_length": 41.0,
        "min_pred_length": 41,
        "max_pred_length": 41,
        "distinct-1": 0.5121951219512195,
        "vocab_size-1": 42,
        "unique-1": 28,
        "entropy-1": 4.791620639294099,
        "distinct-2": 0.7625,
        "vocab_size-2": 61,
        "unique-2": 53,
        "entropy-2": 5.657412351653232,
        "cond_entropy-2": 0.8799399964922356,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 65,
        "unique-3": 60,
        "entropy-3": 5.810792603366692,
        "cond_entropy-3": 0.17041911692458217,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.024900438178646,
        "distinct-2-nopunct": 0.8548387096774194,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.542748326446117,
        "cond_entropy-2-nopunct": 0.5493027128423554,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7133965877012365,
        "cond_entropy-3-nopunct": 0.18436319405314522,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3034755612140723,
        "rouge1": {
            "precision": 0.31932,
            "recall": 0.75827,
            "fmeasure": 0.44714
        },
        "rouge2": {
            "precision": 0.21011,
            "recall": 0.55093,
            "fmeasure": 0.30321
        },
        "rougeL": {
            "precision": 0.29463,
            "recall": 0.73605,
            "fmeasure": 0.41969
        },
        "rougeLsum": {
            "precision": 0.29463,
            "recall": 0.73605,
            "fmeasure": 0.41969
        },
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 12.68855,
        "nubia": {
            "semantic_relation": 3.56891,
            "contradiction": 10.71234,
            "irrelevancy": 78.40965,
            "logical_agreement": 10.87801,
            "grammar_ref": 5.41182,
            "grammar_hyp": 3.60023,
            "nubia_score": 0.18836
        },
        "meteor": 0.2959209593651163,
        "bleurt": -0.27473,
        "bertscore": {
            "precision": 0.79756,
            "recall": 0.91158,
            "f1": 0.84353
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.51364592935837,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.39721762763487756,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.02644273772481477,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.452819531114783,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.39054976241941647,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.028107102122342915,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3138876608495655,
        "rouge1": {
            "precision": 0.87121,
            "recall": 0.93074,
            "fmeasure": 0.8999
        },
        "rouge2": {
            "precision": 0.74459,
            "recall": 0.8,
            "fmeasure": 0.7712
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.90693,
            "fmeasure": 0.87664
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.90693,
            "fmeasure": 0.87664
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9230769230769231
        },
        "bleu": 69.21554,
        "nubia": {
            "semantic_relation": 4.99398,
            "contradiction": 0.3483,
            "irrelevancy": 0.48783,
            "logical_agreement": 99.16387,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.79478,
            "nubia_score": 0.99631
        },
        "meteor": 0.5128006906589383,
        "bleurt": 0.75617,
        "bertscore": {
            "precision": 0.97611,
            "recall": 0.98551,
            "f1": 0.98077
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 143,
        "total_length": 9039,
        "mean_pred_length": 63.20979020979021,
        "std_pred_length": 11.2472860110042,
        "median_pred_length": 65.0,
        "min_pred_length": 34,
        "max_pred_length": 88,
        "distinct-1": 0.10598517535125566,
        "vocab_size-1": 958,
        "unique-1": 390,
        "entropy-1": 5.790079380035268,
        "distinct-2": 0.25202338129496404,
        "vocab_size-2": 2242,
        "unique-2": 1036,
        "entropy-2": 9.706947896719381,
        "cond_entropy-2": 3.932268983971726,
        "distinct-3": 0.40420427282074717,
        "vocab_size-3": 3538,
        "unique-3": 1888,
        "entropy-3": 11.055707930268431,
        "cond_entropy-3": 1.367771309913055,
        "total_length-nopunct": 8320,
        "mean_pred_length-nopunct": 58.18181818181818,
        "std_pred_length-nopunct": 10.82837270486538,
        "median_pred_length-nopunct": 60.0,
        "min_pred_length-nopunct": 31,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.11442307692307692,
        "vocab_size-1-nopunct": 952,
        "unique-1-nopunct": 390,
        "entropy-1-nopunct": 5.691753199400529,
        "distinct-2-nopunct": 0.258285434756023,
        "vocab_size-2-nopunct": 2112,
        "unique-2-nopunct": 975,
        "entropy-2-nopunct": 9.636663729775647,
        "cond_entropy-2-nopunct": 4.000612702713104,
        "distinct-3-nopunct": 0.4100074682598954,
        "vocab_size-3-nopunct": 3294,
        "unique-3-nopunct": 1787,
        "entropy-3-nopunct": 10.940607934067902,
        "cond_entropy-3-nopunct": 1.318844178958701,
        "msttr-100": 0.43267,
        "msttr-100_nopunct": 0.42976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2690962313386933,
        "rouge1": {
            "precision": 0.51441,
            "recall": 0.47647,
            "fmeasure": 0.47542
        },
        "rouge2": {
            "precision": 0.27737,
            "recall": 0.26745,
            "fmeasure": 0.26368
        },
        "rougeL": {
            "precision": 0.48936,
            "recall": 0.45012,
            "fmeasure": 0.44965
        },
        "rougeLsum": {
            "precision": 0.48936,
            "recall": 0.45012,
            "fmeasure": 0.44965
        },
        "local_recall": {
            "1": 0.08252615265401007,
            "2": 0.20995228357191548,
            "3": 0.2948960302457467
        },
        "bleu": 2.51733,
        "nubia": {
            "semantic_relation": 3.35551,
            "contradiction": 32.1065,
            "irrelevancy": 18.24053,
            "logical_agreement": 49.65297,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.44349,
            "nubia_score": 0.1272
        },
        "meteor": 0.1404191635635723,
        "bleurt": -0.51097,
        "bertscore": {
            "precision": 0.86409,
            "recall": 0.87193,
            "f1": 0.86766
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 56,
        "total_length": 3606,
        "mean_pred_length": 64.39285714285714,
        "std_pred_length": 8.39574418429738,
        "median_pred_length": 66.5,
        "min_pred_length": 40,
        "max_pred_length": 80,
        "distinct-1": 0.16306156405990016,
        "vocab_size-1": 588,
        "unique-1": 305,
        "entropy-1": 5.613377006756783,
        "distinct-2": 0.35859154929577464,
        "vocab_size-2": 1273,
        "unique-2": 726,
        "entropy-2": 9.18876443457332,
        "cond_entropy-2": 3.596195226420146,
        "distinct-3": 0.5320549513451631,
        "vocab_size-3": 1859,
        "unique-3": 1203,
        "entropy-3": 10.299632168851453,
        "cond_entropy-3": 1.120607030027082,
        "total_length-nopunct": 3349,
        "mean_pred_length-nopunct": 59.80357142857143,
        "std_pred_length-nopunct": 8.155672090324497,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 38,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.17348462227530606,
        "vocab_size-1-nopunct": 581,
        "unique-1-nopunct": 304,
        "entropy-1-nopunct": 5.509537879034014,
        "distinct-2-nopunct": 0.36866079562708776,
        "vocab_size-2-nopunct": 1214,
        "unique-2-nopunct": 694,
        "entropy-2-nopunct": 9.142828265041928,
        "cond_entropy-2-nopunct": 3.6782454640196582,
        "distinct-3-nopunct": 0.5350633302440532,
        "vocab_size-3-nopunct": 1732,
        "unique-3-nopunct": 1121,
        "entropy-3-nopunct": 10.208272426594881,
        "cond_entropy-3-nopunct": 1.0718408186454411,
        "msttr-100": 0.43917,
        "msttr-100_nopunct": 0.4397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.4106547953542998,
        "rouge1": {
            "precision": 0.65946,
            "recall": 0.59408,
            "fmeasure": 0.58128
        },
        "rouge2": {
            "precision": 0.42747,
            "recall": 0.43804,
            "fmeasure": 0.39968
        },
        "rougeL": {
            "precision": 0.60559,
            "recall": 0.54783,
            "fmeasure": 0.53282
        },
        "rougeLsum": {
            "precision": 0.60559,
            "recall": 0.54783,
            "fmeasure": 0.53282
        },
        "local_recall": {
            "1": 0.0844811753902663,
            "2": 0.1907790143084261,
            "3": 0.3315696649029982
        },
        "bleu": 3.42193,
        "nubia": {
            "semantic_relation": 3.3025,
            "contradiction": 32.87261,
            "irrelevancy": 20.97139,
            "logical_agreement": 46.15599,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.47625,
            "nubia_score": 0.15699
        },
        "meteor": 0.14488975020642622,
        "bleurt": -0.50514,
        "bertscore": {
            "precision": 0.86687,
            "recall": 0.86976,
            "f1": 0.86796
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 19,
        "total_length": 1273,
        "mean_pred_length": 67.0,
        "std_pred_length": 5.812871380325779,
        "median_pred_length": 69.0,
        "min_pred_length": 55,
        "max_pred_length": 77,
        "distinct-1": 0.1767478397486253,
        "vocab_size-1": 225,
        "unique-1": 102,
        "entropy-1": 5.056934322520637,
        "distinct-2": 0.38197767145135564,
        "vocab_size-2": 479,
        "unique-2": 251,
        "entropy-2": 8.189564548186452,
        "cond_entropy-2": 3.1526149833322514,
        "distinct-3": 0.5230769230769231,
        "vocab_size-3": 646,
        "unique-3": 390,
        "entropy-3": 8.93504702117877,
        "cond_entropy-3": 0.7683473629437437,
        "total_length-nopunct": 1172,
        "mean_pred_length-nopunct": 61.68421052631579,
        "std_pred_length-nopunct": 5.620007787772722,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 52,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.189419795221843,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 4.935012080773471,
        "distinct-2-nopunct": 0.39462272333044235,
        "vocab_size-2-nopunct": 455,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 8.130102909503204,
        "cond_entropy-2-nopunct": 3.2390809705541965,
        "distinct-3-nopunct": 0.5370370370370371,
        "vocab_size-3-nopunct": 609,
        "unique-3-nopunct": 371,
        "entropy-3-nopunct": 8.876302070779388,
        "cond_entropy-3-nopunct": 0.7649100620262308,
        "msttr-100": 0.43833,
        "msttr-100_nopunct": 0.43455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.3489198979029846,
        "rouge1": {
            "precision": 0.77076,
            "recall": 0.77486,
            "fmeasure": 0.7485
        },
        "rouge2": {
            "precision": 0.37398,
            "recall": 0.46061,
            "fmeasure": 0.39801
        },
        "rougeL": {
            "precision": 0.70961,
            "recall": 0.71747,
            "fmeasure": 0.68883
        },
        "rougeLsum": {
            "precision": 0.70961,
            "recall": 0.71747,
            "fmeasure": 0.68883
        },
        "local_recall": {
            "1": 0.1152542372881356,
            "2": 0.20300751879699247,
            "3": 0.25742574257425743
        },
        "bleu": 2.28571,
        "nubia": {
            "semantic_relation": 3.22676,
            "contradiction": 34.48289,
            "irrelevancy": 21.74658,
            "logical_agreement": 43.77052,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.45287,
            "nubia_score": 0.16404
        },
        "meteor": 0.13894387672112793,
        "bleurt": -0.51503,
        "bertscore": {
            "precision": 0.86562,
            "recall": 0.8656,
            "f1": 0.86536
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 12,
        "total_length": 816,
        "mean_pred_length": 68.0,
        "std_pred_length": 3.5355339059327378,
        "median_pred_length": 68.0,
        "min_pred_length": 62,
        "max_pred_length": 73,
        "distinct-1": 0.19240196078431374,
        "vocab_size-1": 157,
        "unique-1": 65,
        "entropy-1": 4.862374429367486,
        "distinct-2": 0.4017412935323383,
        "vocab_size-2": 323,
        "unique-2": 151,
        "entropy-2": 7.779184845740107,
        "cond_entropy-2": 2.9325031215290402,
        "distinct-3": 0.5265151515151515,
        "vocab_size-3": 417,
        "unique-3": 222,
        "entropy-3": 8.380010442632459,
        "cond_entropy-3": 0.6101635264540298,
        "total_length-nopunct": 750,
        "mean_pred_length-nopunct": 62.5,
        "std_pred_length-nopunct": 3.547299442298794,
        "median_pred_length-nopunct": 62.5,
        "min_pred_length-nopunct": 57,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.20533333333333334,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 4.717407930619047,
        "distinct-2-nopunct": 0.4146341463414634,
        "vocab_size-2-nopunct": 306,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.708228118915097,
        "cond_entropy-2-nopunct": 3.021599925064198,
        "distinct-3-nopunct": 0.5399449035812672,
        "vocab_size-3-nopunct": 392,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 8.302013106618775,
        "cond_entropy-3-nopunct": 0.601817134961535,
        "msttr-100": 0.435,
        "msttr-100_nopunct": 0.42571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.3436962190078356,
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.60982,
            "fmeasure": 0.64048
        },
        "rouge2": {
            "precision": 0.30833,
            "recall": 0.29094,
            "fmeasure": 0.29123
        },
        "rougeL": {
            "precision": 0.70238,
            "recall": 0.59917,
            "fmeasure": 0.61773
        },
        "rougeLsum": {
            "precision": 0.70238,
            "recall": 0.59917,
            "fmeasure": 0.61773
        },
        "local_recall": {
            "1": 0.11274509803921569,
            "2": 0.16091954022988506,
            "3": 0.2721518987341772
        },
        "bleu": 1.6422,
        "nubia": {
            "semantic_relation": 3.08821,
            "contradiction": 38.53277,
            "irrelevancy": 22.10535,
            "logical_agreement": 39.36187,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.50115,
            "nubia_score": 0.18663
        },
        "meteor": 0.12298859417702673,
        "bleurt": -0.52967,
        "bertscore": {
            "precision": 0.86408,
            "recall": 0.85853,
            "f1": 0.86111
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7081,
        "mean_pred_length": 19.724233983286908,
        "std_pred_length": 9.371577245470183,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.3719813585651744,
        "vocab_size-1": 2634,
        "unique-1": 1953,
        "entropy-1": 9.151215069274848,
        "distinct-2": 0.834870574233859,
        "vocab_size-2": 5612,
        "unique-2": 5195,
        "entropy-2": 12.133574363653173,
        "cond_entropy-2": 2.7162053095405403,
        "distinct-3": 0.9636963696369637,
        "vocab_size-3": 6132,
        "unique-3": 6012,
        "entropy-3": 12.519160612429554,
        "cond_entropy-3": 0.40155610144735454,
        "total_length-nopunct": 6285,
        "mean_pred_length-nopunct": 17.506963788300837,
        "std_pred_length-nopunct": 8.274828864168686,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4175019888623707,
        "vocab_size-1-nopunct": 2624,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.503038516520459,
        "distinct-2-nopunct": 0.8543705703678705,
        "vocab_size-2-nopunct": 5063,
        "unique-2-nopunct": 4719,
        "entropy-2-nopunct": 12.03345076396359,
        "cond_entropy-2-nopunct": 2.671912891716557,
        "distinct-3-nopunct": 0.9773666247530088,
        "vocab_size-3-nopunct": 5441,
        "unique-3-nopunct": 5347,
        "entropy-3-nopunct": 12.388720492085142,
        "cond_entropy-3-nopunct": 0.3797937563546693,
        "msttr-100": 0.72371,
        "msttr-100_nopunct": 0.76774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.30797632015497,
        "rouge1": {
            "precision": 0.899,
            "recall": 0.85954,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.8075,
            "recall": 0.7682,
            "fmeasure": 0.77305
        },
        "rougeL": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "rougeLsum": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "local_recall": {
            "1": 0.029768467475192944,
            "2": 0.15768194070080863,
            "3": 0.3433734939759036,
            "4": 0.5504587155963303,
            "5": 0.6965098634294385,
            "6": 0.7549295774647887,
            "7": 0.8483606557377049,
            "8": 0.864897466827503,
            "9": 0.8857142857142857,
            "10": 0.9255813953488372
        },
        "bleu": 85.93589,
        "nubia": {
            "semantic_relation": 4.19043,
            "contradiction": 3.83901,
            "irrelevancy": 31.42769,
            "logical_agreement": 64.7333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.79962,
            "nubia_score": 0.64296
        },
        "meteor": 0.5204959402607399,
        "bleurt": 0.21083,
        "bertscore": {
            "precision": 0.97007,
            "recall": 0.96322,
            "f1": 0.96358
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7081,
        "mean_pred_length": 19.724233983286908,
        "std_pred_length": 9.371577245470183,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.3719813585651744,
        "vocab_size-1": 2634,
        "unique-1": 1953,
        "entropy-1": 9.151215069274848,
        "distinct-2": 0.834870574233859,
        "vocab_size-2": 5612,
        "unique-2": 5195,
        "entropy-2": 12.133574363653173,
        "cond_entropy-2": 2.7162053095405403,
        "distinct-3": 0.9636963696369637,
        "vocab_size-3": 6132,
        "unique-3": 6012,
        "entropy-3": 12.519160612429554,
        "cond_entropy-3": 0.40155610144735454,
        "total_length-nopunct": 6285,
        "mean_pred_length-nopunct": 17.506963788300837,
        "std_pred_length-nopunct": 8.274828864168686,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4175019888623707,
        "vocab_size-1-nopunct": 2624,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.503038516520459,
        "distinct-2-nopunct": 0.8543705703678705,
        "vocab_size-2-nopunct": 5063,
        "unique-2-nopunct": 4719,
        "entropy-2-nopunct": 12.03345076396359,
        "cond_entropy-2-nopunct": 2.671912891716557,
        "distinct-3-nopunct": 0.9773666247530088,
        "vocab_size-3-nopunct": 5441,
        "unique-3-nopunct": 5347,
        "entropy-3-nopunct": 12.388720492085142,
        "cond_entropy-3-nopunct": 0.3797937563546693,
        "msttr-100": 0.72371,
        "msttr-100_nopunct": 0.76774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.30797632015497,
        "rouge1": {
            "precision": 0.899,
            "recall": 0.85954,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.8075,
            "recall": 0.7682,
            "fmeasure": 0.77305
        },
        "rougeL": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "rougeLsum": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "local_recall": {
            "1": 0.029768467475192944,
            "2": 0.15768194070080863,
            "3": 0.3433734939759036,
            "4": 0.5504587155963303,
            "5": 0.6965098634294385,
            "6": 0.7549295774647887,
            "7": 0.8483606557377049,
            "8": 0.864897466827503,
            "9": 0.8857142857142857,
            "10": 0.9255813953488372
        },
        "bleu": 85.93589,
        "nubia": {
            "semantic_relation": 4.19043,
            "contradiction": 3.83901,
            "irrelevancy": 31.42769,
            "logical_agreement": 64.7333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.79962,
            "nubia_score": 0.64296
        },
        "meteor": 0.5204959402607399,
        "bleurt": 0.21083,
        "bertscore": {
            "precision": 0.97007,
            "recall": 0.96322,
            "f1": 0.96358
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 460,
        "total_length": 25721,
        "mean_pred_length": 55.915217391304346,
        "std_pred_length": 15.477732495866782,
        "median_pred_length": 59.0,
        "min_pred_length": 17,
        "max_pred_length": 93,
        "distinct-1": 0.05248629524513044,
        "vocab_size-1": 1350,
        "unique-1": 404,
        "entropy-1": 5.620146649441919,
        "distinct-2": 0.136376232136495,
        "vocab_size-2": 3445,
        "unique-2": 1291,
        "entropy-2": 9.717541901969122,
        "cond_entropy-2": 4.102423513246388,
        "distinct-3": 0.245957824281279,
        "vocab_size-3": 6100,
        "unique-3": 2698,
        "entropy-3": 11.32227256082042,
        "cond_entropy-3": 1.6360140279968185,
        "total_length-nopunct": 23666,
        "mean_pred_length-nopunct": 51.447826086956525,
        "std_pred_length-nopunct": 14.785256156791068,
        "median_pred_length-nopunct": 53.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.05674807741063129,
        "vocab_size-1-nopunct": 1343,
        "unique-1-nopunct": 403,
        "entropy-1-nopunct": 5.513523749777565,
        "distinct-2-nopunct": 0.13944669482030508,
        "vocab_size-2-nopunct": 3236,
        "unique-2-nopunct": 1208,
        "entropy-2-nopunct": 9.632312812294588,
        "cond_entropy-2-nopunct": 4.176026870654358,
        "distinct-3-nopunct": 0.25129693132858527,
        "vocab_size-3-nopunct": 5716,
        "unique-3-nopunct": 2606,
        "entropy-3-nopunct": 11.208287112862465,
        "cond_entropy-3-nopunct": 1.6005104677875999,
        "msttr-100": 0.40518,
        "msttr-100_nopunct": 0.39771,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.9108716480550726,
        "rouge1": {
            "precision": 0.31521,
            "recall": 0.31272,
            "fmeasure": 0.30676
        },
        "rouge2": {
            "precision": 0.12042,
            "recall": 0.12356,
            "fmeasure": 0.11637
        },
        "rougeL": {
            "precision": 0.31023,
            "recall": 0.30775,
            "fmeasure": 0.30179
        },
        "rougeLsum": {
            "precision": 0.31023,
            "recall": 0.30775,
            "fmeasure": 0.30179
        },
        "local_recall": {
            "1": 0.08150208623087622,
            "2": 0.16152349179872116,
            "3": 0.2223110755697721,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "bleu": 1.02516,
        "nubia": {
            "semantic_relation": 3.35795,
            "contradiction": 32.14236,
            "irrelevancy": 17.15253,
            "logical_agreement": 50.7051,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.34723,
            "nubia_score": 0.14414
        },
        "meteor": 0.11175021871934365,
        "bleurt": -0.51063,
        "bertscore": {
            "precision": 0.85415,
            "recall": 0.86739,
            "f1": 0.86013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 114,
        "total_length": 1831,
        "mean_pred_length": 16.06140350877193,
        "std_pred_length": 5.665043763041965,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.4527580557072638,
        "vocab_size-1": 829,
        "unique-1": 639,
        "entropy-1": 8.220060726434802,
        "distinct-2": 0.8549796156086197,
        "vocab_size-2": 1468,
        "unique-2": 1323,
        "entropy-2": 10.357241295894775,
        "cond_entropy-2": 1.857357068127874,
        "distinct-3": 0.9613225202744854,
        "vocab_size-3": 1541,
        "unique-3": 1486,
        "entropy-3": 10.565907298729048,
        "cond_entropy-3": 0.21063852293745977,
        "total_length-nopunct": 1610,
        "mean_pred_length-nopunct": 14.12280701754386,
        "std_pred_length-nopunct": 5.283440450865846,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5099378881987577,
        "vocab_size-1-nopunct": 821,
        "unique-1-nopunct": 638,
        "entropy-1-nopunct": 8.49299414882029,
        "distinct-2-nopunct": 0.8656417112299465,
        "vocab_size-2-nopunct": 1295,
        "unique-2-nopunct": 1183,
        "entropy-2-nopunct": 10.175710790924562,
        "cond_entropy-2-nopunct": 1.793946961220911,
        "distinct-3-nopunct": 0.9659913169319826,
        "vocab_size-3-nopunct": 1335,
        "unique-3-nopunct": 1293,
        "entropy-3-nopunct": 10.361793392782694,
        "cond_entropy-3-nopunct": 0.20440021275661574,
        "msttr-100": 0.71278,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.017152379803438,
        "rouge1": {
            "precision": 0.72803,
            "recall": 0.67504,
            "fmeasure": 0.68792
        },
        "rouge2": {
            "precision": 0.48181,
            "recall": 0.44521,
            "fmeasure": 0.45399
        },
        "rougeL": {
            "precision": 0.63133,
            "recall": 0.58811,
            "fmeasure": 0.59803
        },
        "rougeLsum": {
            "precision": 0.63133,
            "recall": 0.58811,
            "fmeasure": 0.59803
        },
        "local_recall": {
            "1": 0.19651741293532338,
            "2": 0.44416243654822335,
            "3": 0.7278314310798947
        },
        "bleu": 38.86652,
        "nubia": {
            "semantic_relation": 4.0167,
            "contradiction": 11.47649,
            "irrelevancy": 34.10588,
            "logical_agreement": 54.41763,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.69546,
            "nubia_score": 0.66971
        },
        "meteor": 0.3557951685733555,
        "bleurt": 0.14341,
        "bertscore": {
            "precision": 0.91666,
            "recall": 0.91022,
            "f1": 0.91188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 79,
        "total_length": 1408,
        "mean_pred_length": 17.82278481012658,
        "std_pred_length": 8.084615008753927,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.4069602272727273,
        "vocab_size-1": 573,
        "unique-1": 436,
        "entropy-1": 7.758461009162219,
        "distinct-2": 0.7291196388261851,
        "vocab_size-2": 969,
        "unique-2": 833,
        "entropy-2": 9.542691253238091,
        "cond_entropy-2": 1.5700677151387914,
        "distinct-3": 0.844,
        "vocab_size-3": 1055,
        "unique-3": 972,
        "entropy-3": 9.818333789253723,
        "cond_entropy-3": 0.2993038434081027,
        "total_length-nopunct": 1234,
        "mean_pred_length-nopunct": 15.620253164556962,
        "std_pred_length-nopunct": 6.936062059838638,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.45786061588330634,
        "vocab_size-1-nopunct": 565,
        "unique-1-nopunct": 434,
        "entropy-1-nopunct": 7.957607701563899,
        "distinct-2-nopunct": 0.7445887445887446,
        "vocab_size-2-nopunct": 860,
        "unique-2-nopunct": 748,
        "entropy-2-nopunct": 9.386832798251111,
        "cond_entropy-2-nopunct": 1.5346808588140335,
        "distinct-3-nopunct": 0.8494423791821561,
        "vocab_size-3-nopunct": 914,
        "unique-3-nopunct": 846,
        "entropy-3-nopunct": 9.619417084720215,
        "cond_entropy-3-nopunct": 0.2802012847985077,
        "msttr-100": 0.69643,
        "msttr-100_nopunct": 0.73167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.363758995096121,
        "rouge1": {
            "precision": 0.77525,
            "recall": 0.74267,
            "fmeasure": 0.74981
        },
        "rouge2": {
            "precision": 0.56082,
            "recall": 0.53746,
            "fmeasure": 0.54275
        },
        "rougeL": {
            "precision": 0.66899,
            "recall": 0.64457,
            "fmeasure": 0.6493
        },
        "rougeLsum": {
            "precision": 0.66899,
            "recall": 0.64457,
            "fmeasure": 0.6493
        },
        "local_recall": {
            "1": 0.19838056680161945,
            "2": 0.4492753623188406,
            "3": 0.7929465301478953
        },
        "bleu": 50.06033,
        "nubia": {
            "semantic_relation": 4.07925,
            "contradiction": 12.16393,
            "irrelevancy": 29.52324,
            "logical_agreement": 58.31283,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.409,
            "nubia_score": 0.70874
        },
        "meteor": 0.3933509310033614,
        "bleurt": 0.27405,
        "bertscore": {
            "precision": 0.93098,
            "recall": 0.92843,
            "f1": 0.92729
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 76,
        "total_length": 1249,
        "mean_pred_length": 16.43421052631579,
        "std_pred_length": 6.865887312449689,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 40,
        "distinct-1": 0.4899919935948759,
        "vocab_size-1": 612,
        "unique-1": 491,
        "entropy-1": 7.947285153203335,
        "distinct-2": 0.8721227621483376,
        "vocab_size-2": 1023,
        "unique-2": 942,
        "entropy-2": 9.851851793990903,
        "cond_entropy-2": 1.6513204576820357,
        "distinct-3": 0.968094804010939,
        "vocab_size-3": 1062,
        "unique-3": 1036,
        "entropy-3": 10.027671246608243,
        "cond_entropy-3": 0.17376651401199747,
        "total_length-nopunct": 1067,
        "mean_pred_length-nopunct": 14.039473684210526,
        "std_pred_length-nopunct": 5.660204546875083,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5679475164011246,
        "vocab_size-1-nopunct": 606,
        "unique-1-nopunct": 491,
        "entropy-1-nopunct": 8.27272067439456,
        "distinct-2-nopunct": 0.8890010090817356,
        "vocab_size-2-nopunct": 881,
        "unique-2-nopunct": 823,
        "entropy-2-nopunct": 9.645339245374043,
        "cond_entropy-2-nopunct": 1.4712108657029632,
        "distinct-3-nopunct": 0.9737704918032787,
        "vocab_size-3-nopunct": 891,
        "unique-3-nopunct": 871,
        "entropy-3-nopunct": 9.781333097101077,
        "cond_entropy-3-nopunct": 0.15214422291506405,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.511580509016664,
        "rouge1": {
            "precision": 0.72243,
            "recall": 0.67704,
            "fmeasure": 0.68297
        },
        "rouge2": {
            "precision": 0.4628,
            "recall": 0.43126,
            "fmeasure": 0.43383
        },
        "rougeL": {
            "precision": 0.62377,
            "recall": 0.59304,
            "fmeasure": 0.59368
        },
        "rougeLsum": {
            "precision": 0.62377,
            "recall": 0.59304,
            "fmeasure": 0.59368
        },
        "local_recall": {
            "1": 0.19063545150501673,
            "2": 0.491869918699187,
            "3": 0.703601108033241
        },
        "bleu": 36.27875,
        "nubia": {
            "semantic_relation": 4.04954,
            "contradiction": 8.23803,
            "irrelevancy": 31.62385,
            "logical_agreement": 60.13811,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.7092,
            "nubia_score": 0.6768
        },
        "meteor": 0.3484005936089921,
        "bleurt": 0.14946,
        "bertscore": {
            "precision": 0.91068,
            "recall": 0.90945,
            "f1": 0.90762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.9161269465882835,
        "distinct-2": 0.85,
        "vocab_size-2": 17,
        "unique-2": 14,
        "entropy-2": 4.021928094887363,
        "cond_entropy-2": 0.12961067210860203,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 17,
        "unique-3": 15,
        "entropy-3": 4.03740119765411,
        "cond_entropy-3": 0.031262576450960075,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.640223928941851,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.6644977792004623,
        "cond_entropy-3-nopunct": 0.04332146930622848,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6878538509575973,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.63158,
            "fmeasure": 0.68571
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.22222,
            "fmeasure": 0.24242
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.42105,
            "fmeasure": 0.45714
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.42105,
            "fmeasure": 0.45714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6470588235294118
        },
        "bleu": 11.59911,
        "nubia": {
            "semantic_relation": 4.4117,
            "contradiction": 0.57544,
            "irrelevancy": 8.85407,
            "logical_agreement": 90.57049,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.29032,
            "nubia_score": 0.83239
        },
        "meteor": 0.30284425160698414,
        "bleurt": 0.17004,
        "bertscore": {
            "precision": 0.90292,
            "recall": 0.87853,
            "f1": 0.89056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6476388007204534,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "bleu": 22.08959,
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "meteor": 0.3387350864807313,
        "bleurt": 0.27507,
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 311,
        "mean_pred_length": 17.27777777777778,
        "std_pred_length": 5.951708956776435,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.594855305466238,
        "vocab_size-1": 185,
        "unique-1": 153,
        "entropy-1": 6.853705203944937,
        "distinct-2": 0.9180887372013652,
        "vocab_size-2": 269,
        "unique-2": 251,
        "entropy-2": 8.010885513190457,
        "cond_entropy-2": 0.9838850360351064,
        "distinct-3": 0.9818181818181818,
        "vocab_size-3": 270,
        "unique-3": 265,
        "entropy-3": 8.06692417204839,
        "cond_entropy-3": 0.0680738739204182,
        "total_length-nopunct": 274,
        "mean_pred_length-nopunct": 15.222222222222221,
        "std_pred_length-nopunct": 4.848316495393651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6532846715328468,
        "vocab_size-1-nopunct": 179,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.928770358963719,
        "distinct-2-nopunct": 0.9140625,
        "vocab_size-2-nopunct": 234,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.805178503980753,
        "cond_entropy-2-nopunct": 0.9547156099855276,
        "distinct-3-nopunct": 0.9831932773109243,
        "vocab_size-3-nopunct": 234,
        "unique-3-nopunct": 230,
        "entropy-3-nopunct": 7.86120431792984,
        "cond_entropy-3-nopunct": 0.06655853213536894,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.981561283676762,
        "rouge1": {
            "precision": 0.72331,
            "recall": 0.67996,
            "fmeasure": 0.68327
        },
        "rouge2": {
            "precision": 0.47964,
            "recall": 0.46597,
            "fmeasure": 0.45951
        },
        "rougeL": {
            "precision": 0.60003,
            "recall": 0.58107,
            "fmeasure": 0.5744
        },
        "rougeLsum": {
            "precision": 0.60003,
            "recall": 0.58107,
            "fmeasure": 0.5744
        },
        "local_recall": {
            "1": 0.2524271844660194,
            "2": 0.4318181818181818,
            "3": 0.7142857142857143
        },
        "bleu": 38.29889,
        "nubia": {
            "semantic_relation": 3.94047,
            "contradiction": 10.27026,
            "irrelevancy": 43.91287,
            "logical_agreement": 45.81687,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.63996,
            "nubia_score": 0.64708
        },
        "meteor": 0.3677572884375066,
        "bleurt": 0.06261,
        "bertscore": {
            "precision": 0.91519,
            "recall": 0.90804,
            "f1": 0.91028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 122,
        "total_length": 1971,
        "mean_pred_length": 16.15573770491803,
        "std_pred_length": 6.664095737365653,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.441400304414003,
        "vocab_size-1": 870,
        "unique-1": 687,
        "entropy-1": 8.218822232132633,
        "distinct-2": 0.8258518117901569,
        "vocab_size-2": 1527,
        "unique-2": 1349,
        "entropy-2": 10.392574259619547,
        "cond_entropy-2": 1.8955323354781035,
        "distinct-3": 0.944991314418066,
        "vocab_size-3": 1632,
        "unique-3": 1550,
        "entropy-3": 10.63700606440943,
        "cond_entropy-3": 0.23231772142803817,
        "total_length-nopunct": 1710,
        "mean_pred_length-nopunct": 14.01639344262295,
        "std_pred_length-nopunct": 6.021795939502282,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5029239766081871,
        "vocab_size-1-nopunct": 860,
        "unique-1-nopunct": 683,
        "entropy-1-nopunct": 8.543505253759651,
        "distinct-2-nopunct": 0.8482367758186398,
        "vocab_size-2-nopunct": 1347,
        "unique-2-nopunct": 1211,
        "entropy-2-nopunct": 10.232438689528463,
        "cond_entropy-2-nopunct": 1.769964430250049,
        "distinct-3-nopunct": 0.9502046384720327,
        "vocab_size-3-nopunct": 1393,
        "unique-3-nopunct": 1331,
        "entropy-3-nopunct": 10.410828194079706,
        "cond_entropy-3-nopunct": 0.19547962238088432,
        "msttr-100": 0.69895,
        "msttr-100_nopunct": 0.74706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.29480838909823,
        "rouge1": {
            "precision": 0.75628,
            "recall": 0.7063,
            "fmeasure": 0.71973
        },
        "rouge2": {
            "precision": 0.50896,
            "recall": 0.47287,
            "fmeasure": 0.48239
        },
        "rougeL": {
            "precision": 0.6471,
            "recall": 0.6017,
            "fmeasure": 0.61394
        },
        "rougeLsum": {
            "precision": 0.6471,
            "recall": 0.6017,
            "fmeasure": 0.61394
        },
        "local_recall": {
            "1": 0.1842696629213483,
            "2": 0.35014836795252224,
            "3": 0.7409326424870466
        },
        "bleu": 41.85651,
        "nubia": {
            "semantic_relation": 4.12056,
            "contradiction": 10.94863,
            "irrelevancy": 27.88833,
            "logical_agreement": 61.16304,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.70833,
            "nubia_score": 0.69953
        },
        "meteor": 0.374827881451508,
        "bleurt": 0.2102,
        "bertscore": {
            "precision": 0.92211,
            "recall": 0.9144,
            "f1": 0.91635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 60,
        "mean_pred_length": 15.0,
        "std_pred_length": 9.565563234854496,
        "median_pred_length": 11.5,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 46,
        "unique-1": 42,
        "entropy-1": 5.233451062999072,
        "distinct-2": 1.0,
        "vocab_size-2": 56,
        "unique-2": 56,
        "entropy-2": 5.807354922057609,
        "cond_entropy-2": 0.4791495399592052,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 6.684870978560469,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8979591836734694,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.354406017540444,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.16058519670698798,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.515869934356769,
        "rouge1": {
            "precision": 0.86895,
            "recall": 0.79514,
            "fmeasure": 0.82444
        },
        "rouge2": {
            "precision": 0.66695,
            "recall": 0.61459,
            "fmeasure": 0.63476
        },
        "rougeL": {
            "precision": 0.84138,
            "recall": 0.77479,
            "fmeasure": 0.80152
        },
        "rougeLsum": {
            "precision": 0.84138,
            "recall": 0.77479,
            "fmeasure": 0.80152
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.6666666666666666
        },
        "bleu": 41.73493,
        "nubia": {
            "semantic_relation": 4.34576,
            "contradiction": 2.27799,
            "irrelevancy": 28.71227,
            "logical_agreement": 69.00974,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.73276,
            "nubia_score": 0.73828
        },
        "meteor": 0.3882207871209868,
        "bleurt": 0.46884,
        "bertscore": {
            "precision": 0.94774,
            "recall": 0.93514,
            "f1": 0.94122
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 300,
        "total_length": 5234,
        "mean_pred_length": 17.446666666666665,
        "std_pred_length": 8.366231064357606,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 109,
        "distinct-1": 0.3482995796713794,
        "vocab_size-1": 1823,
        "unique-1": 1441,
        "entropy-1": 8.44929648541157,
        "distinct-2": 0.7111876773408998,
        "vocab_size-2": 3509,
        "unique-2": 3080,
        "entropy-2": 11.228180789468427,
        "cond_entropy-2": 2.5172109616646,
        "distinct-3": 0.8720328010358221,
        "vocab_size-3": 4041,
        "unique-3": 3759,
        "entropy-3": 11.828774318076167,
        "cond_entropy-3": 0.5968842198869295,
        "total_length-nopunct": 4523,
        "mean_pred_length-nopunct": 15.076666666666666,
        "std_pred_length-nopunct": 6.510820907450065,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.4006190581472474,
        "vocab_size-1-nopunct": 1812,
        "unique-1-nopunct": 1437,
        "entropy-1-nopunct": 8.80871702696367,
        "distinct-2-nopunct": 0.7426000473596969,
        "vocab_size-2-nopunct": 3136,
        "unique-2-nopunct": 2812,
        "entropy-2-nopunct": 11.093645806151544,
        "cond_entropy-2-nopunct": 2.4161018569409265,
        "distinct-3-nopunct": 0.8937037981136885,
        "vocab_size-3-nopunct": 3506,
        "unique-3-nopunct": 3303,
        "entropy-3-nopunct": 11.648558981027122,
        "cond_entropy-3-nopunct": 0.609276298874285,
        "msttr-100": 0.67865,
        "msttr-100_nopunct": 0.73333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.50233625189072,
        "rouge1": {
            "precision": 0.81109,
            "recall": 0.7471,
            "fmeasure": 0.76706
        },
        "rouge2": {
            "precision": 0.55953,
            "recall": 0.51827,
            "fmeasure": 0.53031
        },
        "rougeL": {
            "precision": 0.69139,
            "recall": 0.63726,
            "fmeasure": 0.65403
        },
        "rougeLsum": {
            "precision": 0.69139,
            "recall": 0.63726,
            "fmeasure": 0.65403
        },
        "local_recall": {
            "1": 0.188422247446084,
            "2": 0.3545197740112994,
            "3": 0.7784398699891658
        },
        "bleu": 45.47483,
        "nubia": {
            "semantic_relation": 4.36273,
            "contradiction": 7.2956,
            "irrelevancy": 22.92691,
            "logical_agreement": 69.77749,
            "grammar_ref": 4.91577,
            "grammar_hyp": 5.00008,
            "nubia_score": 0.74813
        },
        "meteor": 0.397133309570951,
        "bleurt": 0.30426,
        "bertscore": {
            "precision": 0.93769,
            "recall": 0.93062,
            "f1": 0.93282
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 44,
        "total_length": 720,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 6.578514992316445,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.5194444444444445,
        "vocab_size-1": 374,
        "unique-1": 292,
        "entropy-1": 7.580887411187534,
        "distinct-2": 0.8875739644970414,
        "vocab_size-2": 600,
        "unique-2": 541,
        "entropy-2": 9.147868249241373,
        "cond_entropy-2": 1.3360155997789604,
        "distinct-3": 0.9572784810126582,
        "vocab_size-3": 605,
        "unique-3": 579,
        "entropy-3": 9.217143267952158,
        "cond_entropy-3": 0.06987249454575717,
        "total_length-nopunct": 619,
        "mean_pred_length-nopunct": 14.068181818181818,
        "std_pred_length-nopunct": 5.52842952906621,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5945072697899838,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 292,
        "entropy-1-nopunct": 7.809899186357675,
        "distinct-2-nopunct": 0.9026086956521739,
        "vocab_size-2-nopunct": 519,
        "unique-2-nopunct": 479,
        "entropy-2-nopunct": 8.940843058983797,
        "cond_entropy-2-nopunct": 1.2011906415950622,
        "distinct-3-nopunct": 0.967984934086629,
        "vocab_size-3-nopunct": 514,
        "unique-3-nopunct": 497,
        "entropy-3-nopunct": 8.988537918977478,
        "cond_entropy-3-nopunct": 0.05374837471880058,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.896829816865287,
        "rouge1": {
            "precision": 0.79237,
            "recall": 0.74742,
            "fmeasure": 0.75896
        },
        "rouge2": {
            "precision": 0.5536,
            "recall": 0.53012,
            "fmeasure": 0.53313
        },
        "rougeL": {
            "precision": 0.71444,
            "recall": 0.67403,
            "fmeasure": 0.68424
        },
        "rougeLsum": {
            "precision": 0.71444,
            "recall": 0.67403,
            "fmeasure": 0.68424
        },
        "local_recall": {
            "1": 0.15841584158415842,
            "2": 0.496,
            "3": 0.7926565874730022
        },
        "bleu": 47.92076,
        "nubia": {
            "semantic_relation": 4.26766,
            "contradiction": 8.79771,
            "irrelevancy": 22.36286,
            "logical_agreement": 68.83944,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.72953,
            "nubia_score": 0.7534
        },
        "meteor": 0.4025965858811093,
        "bleurt": 0.33374,
        "bertscore": {
            "precision": 0.93283,
            "recall": 0.93026,
            "f1": 0.93052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 49,
        "total_length": 881,
        "mean_pred_length": 17.979591836734695,
        "std_pred_length": 8.802805202050052,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 49,
        "distinct-1": 0.5051078320090806,
        "vocab_size-1": 445,
        "unique-1": 369,
        "entropy-1": 7.635242081160197,
        "distinct-2": 0.8701923076923077,
        "vocab_size-2": 724,
        "unique-2": 676,
        "entropy-2": 9.332301257271796,
        "cond_entropy-2": 1.4894764940247853,
        "distinct-3": 0.9361430395913155,
        "vocab_size-3": 733,
        "unique-3": 711,
        "entropy-3": 9.436107797426533,
        "cond_entropy-3": 0.11214499427759382,
        "total_length-nopunct": 742,
        "mean_pred_length-nopunct": 15.142857142857142,
        "std_pred_length-nopunct": 7.199773239059517,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5862533692722371,
        "vocab_size-1-nopunct": 435,
        "unique-1-nopunct": 366,
        "entropy-1-nopunct": 7.881660728899039,
        "distinct-2-nopunct": 0.8874458874458875,
        "vocab_size-2-nopunct": 615,
        "unique-2-nopunct": 583,
        "entropy-2-nopunct": 9.10587222116397,
        "cond_entropy-2-nopunct": 1.3073693191716242,
        "distinct-3-nopunct": 0.9503105590062112,
        "vocab_size-3-nopunct": 612,
        "unique-3-nopunct": 599,
        "entropy-3-nopunct": 9.190949540401212,
        "cond_entropy-3-nopunct": 0.09729979862371425,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.72857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.678596048501145,
        "rouge1": {
            "precision": 0.76074,
            "recall": 0.66788,
            "fmeasure": 0.69961
        },
        "rouge2": {
            "precision": 0.51594,
            "recall": 0.44635,
            "fmeasure": 0.4687
        },
        "rougeL": {
            "precision": 0.65712,
            "recall": 0.57827,
            "fmeasure": 0.60353
        },
        "rougeLsum": {
            "precision": 0.65712,
            "recall": 0.57827,
            "fmeasure": 0.60353
        },
        "local_recall": {
            "1": 0.23711340206185566,
            "2": 0.3699421965317919,
            "3": 0.7248576850094877
        },
        "bleu": 41.66063,
        "nubia": {
            "semantic_relation": 4.07768,
            "contradiction": 8.39231,
            "irrelevancy": 27.71206,
            "logical_agreement": 63.89563,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.96288,
            "nubia_score": 0.66625
        },
        "meteor": 0.3578740706499623,
        "bleurt": 0.19402,
        "bertscore": {
            "precision": 0.93037,
            "recall": 0.90908,
            "f1": 0.91793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 55,
        "total_length": 858,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.1824879949867535,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5372960372960373,
        "vocab_size-1": 461,
        "unique-1": 377,
        "entropy-1": 7.792186797574997,
        "distinct-2": 0.9028642590286425,
        "vocab_size-2": 725,
        "unique-2": 681,
        "entropy-2": 9.407058703057608,
        "cond_entropy-2": 1.3508508176653116,
        "distinct-3": 0.9745989304812834,
        "vocab_size-3": 729,
        "unique-3": 715,
        "entropy-3": 9.491046281397193,
        "cond_entropy-3": 0.06769223888908912,
        "total_length-nopunct": 740,
        "mean_pred_length-nopunct": 13.454545454545455,
        "std_pred_length-nopunct": 4.438747496630437,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6135135135135135,
        "vocab_size-1-nopunct": 454,
        "unique-1-nopunct": 376,
        "entropy-1-nopunct": 8.052738464395745,
        "distinct-2-nopunct": 0.9138686131386862,
        "vocab_size-2-nopunct": 626,
        "unique-2-nopunct": 594,
        "entropy-2-nopunct": 9.203580747943382,
        "cond_entropy-2-nopunct": 1.2330069038467413,
        "distinct-3-nopunct": 0.9746031746031746,
        "vocab_size-3-nopunct": 614,
        "unique-3-nopunct": 603,
        "entropy-3-nopunct": 9.242423196941527,
        "cond_entropy-3-nopunct": 0.054558113513792895,
        "msttr-100": 0.73875,
        "msttr-100_nopunct": 0.79429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.774903918822163,
        "rouge1": {
            "precision": 0.73801,
            "recall": 0.68223,
            "fmeasure": 0.69791
        },
        "rouge2": {
            "precision": 0.49577,
            "recall": 0.46011,
            "fmeasure": 0.4689
        },
        "rougeL": {
            "precision": 0.64545,
            "recall": 0.60371,
            "fmeasure": 0.6139
        },
        "rougeLsum": {
            "precision": 0.64545,
            "recall": 0.60371,
            "fmeasure": 0.6139
        },
        "local_recall": {
            "1": 0.28431372549019607,
            "2": 0.4262295081967213,
            "3": 0.7211895910780669
        },
        "bleu": 44.47676,
        "nubia": {
            "semantic_relation": 4.05345,
            "contradiction": 9.86377,
            "irrelevancy": 34.35717,
            "logical_agreement": 55.77906,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.92418,
            "nubia_score": 0.68253
        },
        "meteor": 0.3764511941104445,
        "bleurt": 0.15564,
        "bertscore": {
            "precision": 0.91937,
            "recall": 0.91265,
            "f1": 0.91485
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 151,
        "mean_pred_length": 13.727272727272727,
        "std_pred_length": 4.20153454846958,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.6026490066225165,
        "vocab_size-1": 91,
        "unique-1": 78,
        "entropy-1": 5.848708065504995,
        "distinct-2": 0.9357142857142857,
        "vocab_size-2": 131,
        "unique-2": 125,
        "entropy-2": 6.981033820500953,
        "cond_entropy-2": 0.9697037236174413,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": 0.04283483927025257,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 12.181818181818182,
        "std_pred_length-nopunct": 3.6635348508381607,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6567164179104478,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 5.858697772981502,
        "distinct-2-nopunct": 0.9349593495934959,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.790035745159037,
        "cond_entropy-2-nopunct": 1.0311859851225835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": 0.03229476941625249,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.978093128612037,
        "rouge1": {
            "precision": 0.76823,
            "recall": 0.70582,
            "fmeasure": 0.72967
        },
        "rouge2": {
            "precision": 0.57133,
            "recall": 0.5337,
            "fmeasure": 0.54507
        },
        "rougeL": {
            "precision": 0.69174,
            "recall": 0.65208,
            "fmeasure": 0.66296
        },
        "rougeLsum": {
            "precision": 0.69174,
            "recall": 0.65208,
            "fmeasure": 0.66296
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.45161290322580644,
            "3": 0.7608695652173914
        },
        "bleu": 50.29906,
        "nubia": {
            "semantic_relation": 3.90779,
            "contradiction": 18.13962,
            "irrelevancy": 26.0767,
            "logical_agreement": 55.78368,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.44223,
            "nubia_score": 0.67952
        },
        "meteor": 0.4029611864420717,
        "bleurt": 0.20996,
        "bertscore": {
            "precision": 0.93801,
            "recall": 0.93605,
            "f1": 0.93541
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 33,
        "total_length": 544,
        "mean_pred_length": 16.484848484848484,
        "std_pred_length": 6.1748326544430725,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.5643382352941176,
        "vocab_size-1": 307,
        "unique-1": 265,
        "entropy-1": 7.212799697297372,
        "distinct-2": 0.923679060665362,
        "vocab_size-2": 472,
        "unique-2": 446,
        "entropy-2": 8.800666221091026,
        "cond_entropy-2": 1.3831676545405018,
        "distinct-3": 0.9832635983263598,
        "vocab_size-3": 470,
        "unique-3": 462,
        "entropy-3": 8.867394004633539,
        "cond_entropy-3": 0.051822547351022506,
        "total_length-nopunct": 463,
        "mean_pred_length-nopunct": 14.030303030303031,
        "std_pred_length-nopunct": 5.654093976584703,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6501079913606912,
        "vocab_size-1-nopunct": 301,
        "unique-1-nopunct": 264,
        "entropy-1-nopunct": 7.412464069716474,
        "distinct-2-nopunct": 0.9418604651162791,
        "vocab_size-2-nopunct": 405,
        "unique-2-nopunct": 390,
        "entropy-2-nopunct": 8.588172767479785,
        "cond_entropy-2-nopunct": 1.2604282729853362,
        "distinct-3-nopunct": 0.9949622166246851,
        "vocab_size-3-nopunct": 395,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.62291963039235,
        "cond_entropy-3-nopunct": 0.048048280317159735,
        "msttr-100": 0.704,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.3776059601513175,
        "rouge1": {
            "precision": 0.88678,
            "recall": 0.79496,
            "fmeasure": 0.83042
        },
        "rouge2": {
            "precision": 0.66622,
            "recall": 0.58701,
            "fmeasure": 0.61561
        },
        "rougeL": {
            "precision": 0.77462,
            "recall": 0.68894,
            "fmeasure": 0.72232
        },
        "rougeLsum": {
            "precision": 0.77462,
            "recall": 0.68894,
            "fmeasure": 0.72232
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.2537313432835821,
            "3": 0.8292682926829268
        },
        "bleu": 53.56423,
        "nubia": {
            "semantic_relation": 4.47566,
            "contradiction": 1.24523,
            "irrelevancy": 16.25872,
            "logical_agreement": 82.49606,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.25014,
            "nubia_score": 0.78392
        },
        "meteor": 0.4331427039596851,
        "bleurt": 0.34784,
        "bertscore": {
            "precision": 0.95118,
            "recall": 0.93562,
            "f1": 0.94253
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 21,
        "total_length": 278,
        "mean_pred_length": 13.238095238095237,
        "std_pred_length": 4.597149861389398,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5863309352517986,
        "vocab_size-1": 163,
        "unique-1": 133,
        "entropy-1": 6.674933752917096,
        "distinct-2": 0.9027237354085603,
        "vocab_size-2": 232,
        "unique-2": 223,
        "entropy-2": 7.736777919116858,
        "cond_entropy-2": 0.8209316675132552,
        "distinct-3": 0.9788135593220338,
        "vocab_size-3": 231,
        "unique-3": 229,
        "entropy-3": 7.824975081249797,
        "cond_entropy-3": 0.05445198737528194,
        "total_length-nopunct": 240,
        "mean_pred_length-nopunct": 11.428571428571429,
        "std_pred_length-nopunct": 3.8983687500754245,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6583333333333333,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.773415139070667,
        "distinct-2-nopunct": 0.908675799086758,
        "vocab_size-2-nopunct": 199,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.521435719622351,
        "cond_entropy-2-nopunct": 0.7945655308387318,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 198,
        "entropy-3-nopunct": 7.629356620079592,
        "cond_entropy-3-nopunct": 0.06605593916998743,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.304605621880063,
        "rouge1": {
            "precision": 0.74739,
            "recall": 0.70432,
            "fmeasure": 0.71455
        },
        "rouge2": {
            "precision": 0.49855,
            "recall": 0.46476,
            "fmeasure": 0.47431
        },
        "rougeL": {
            "precision": 0.6613,
            "recall": 0.62486,
            "fmeasure": 0.6333
        },
        "rougeLsum": {
            "precision": 0.6613,
            "recall": 0.62486,
            "fmeasure": 0.6333
        },
        "local_recall": {
            "1": 0.2318840579710145,
            "2": 0.2830188679245283,
            "3": 0.7446808510638298
        },
        "bleu": 35.54227,
        "nubia": {
            "semantic_relation": 3.95399,
            "contradiction": 16.98058,
            "irrelevancy": 36.03456,
            "logical_agreement": 46.98486,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.82754,
            "nubia_score": 0.66251
        },
        "meteor": 0.354234496346261,
        "bleurt": 0.18013,
        "bertscore": {
            "precision": 0.92317,
            "recall": 0.91088,
            "f1": 0.9159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 7.306692487168242,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.6956521739130435,
        "vocab_size-1": 80,
        "unique-1": 63,
        "entropy-1": 6.050482033855509,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 100,
        "unique-2": 93,
        "entropy-2": 6.5997496549212045,
        "cond_entropy-2": 0.4188377290769996,
        "distinct-3": 0.9801980198019802,
        "vocab_size-3": 99,
        "unique-3": 97,
        "entropy-3": 6.618607522355739,
        "cond_entropy-3": 0.029609995461231726,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 6.385570468179145,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.082205599611885,
        "distinct-2-nopunct": 0.9550561797752809,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.3773639084701905,
        "cond_entropy-2-nopunct": 0.32346503141745403,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.011414505590223126,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.034572021099079,
        "rouge1": {
            "precision": 0.68568,
            "recall": 0.6506,
            "fmeasure": 0.65492
        },
        "rouge2": {
            "precision": 0.41643,
            "recall": 0.40192,
            "fmeasure": 0.39754
        },
        "rougeL": {
            "precision": 0.52647,
            "recall": 0.50472,
            "fmeasure": 0.50246
        },
        "rougeLsum": {
            "precision": 0.52647,
            "recall": 0.50472,
            "fmeasure": 0.50246
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.6521739130434783,
            "3": 0.5964912280701754
        },
        "bleu": 28.87511,
        "nubia": {
            "semantic_relation": 4.06238,
            "contradiction": 10.12723,
            "irrelevancy": 27.72902,
            "logical_agreement": 62.14375,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.69348,
            "nubia_score": 0.68893
        },
        "meteor": 0.31909766256277067,
        "bleurt": 0.12986,
        "bertscore": {
            "precision": 0.91621,
            "recall": 0.92482,
            "f1": 0.91893
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 128,
        "total_length": 2073,
        "mean_pred_length": 16.1953125,
        "std_pred_length": 6.718745457847302,
        "median_pred_length": 14.5,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.37723106608779544,
        "vocab_size-1": 782,
        "unique-1": 593,
        "entropy-1": 7.895092782205119,
        "distinct-2": 0.7511568123393316,
        "vocab_size-2": 1461,
        "unique-2": 1284,
        "entropy-2": 10.126442006390059,
        "cond_entropy-2": 1.9754271668715655,
        "distinct-3": 0.9113924050632911,
        "vocab_size-3": 1656,
        "unique-3": 1570,
        "entropy-3": 10.588408969660142,
        "cond_entropy-3": 0.3862558518229302,
        "total_length-nopunct": 1802,
        "mean_pred_length-nopunct": 14.078125,
        "std_pred_length-nopunct": 5.95767542623589,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.4284128745837958,
        "vocab_size-1-nopunct": 772,
        "unique-1-nopunct": 591,
        "entropy-1-nopunct": 8.188926103924654,
        "distinct-2-nopunct": 0.7861409796893668,
        "vocab_size-2-nopunct": 1316,
        "unique-2-nopunct": 1181,
        "entropy-2-nopunct": 10.028337970798598,
        "cond_entropy-2-nopunct": 1.84345996171935,
        "distinct-3-nopunct": 0.9301423027166882,
        "vocab_size-3-nopunct": 1438,
        "unique-3-nopunct": 1376,
        "entropy-3-nopunct": 10.415293928350156,
        "cond_entropy-3-nopunct": 0.36668140811252264,
        "msttr-100": 0.6865,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.5410286071480765,
        "rouge1": {
            "precision": 0.79789,
            "recall": 0.7677,
            "fmeasure": 0.77432
        },
        "rouge2": {
            "precision": 0.5628,
            "recall": 0.55022,
            "fmeasure": 0.55024
        },
        "rougeL": {
            "precision": 0.69325,
            "recall": 0.67016,
            "fmeasure": 0.67359
        },
        "rougeLsum": {
            "precision": 0.69325,
            "recall": 0.67016,
            "fmeasure": 0.67359
        },
        "local_recall": {
            "1": 0.1484848484848485,
            "2": 0.32558139534883723,
            "3": 0.7874069058903183
        },
        "bleu": 46.47655,
        "nubia": {
            "semantic_relation": 4.39298,
            "contradiction": 6.42027,
            "irrelevancy": 26.57062,
            "logical_agreement": 67.00911,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.21277,
            "nubia_score": 0.81336
        },
        "meteor": 0.4014712505930356,
        "bleurt": 0.35398,
        "bertscore": {
            "precision": 0.93551,
            "recall": 0.93457,
            "f1": 0.93346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 30,
        "total_length": 488,
        "mean_pred_length": 16.266666666666666,
        "std_pred_length": 5.615059117132151,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5635245901639344,
        "vocab_size-1": 275,
        "unique-1": 214,
        "entropy-1": 7.2894235246493695,
        "distinct-2": 0.8733624454148472,
        "vocab_size-2": 400,
        "unique-2": 361,
        "entropy-2": 8.536611688918022,
        "cond_entropy-2": 1.0301871273162932,
        "distinct-3": 0.9415887850467289,
        "vocab_size-3": 403,
        "unique-3": 381,
        "entropy-3": 8.619353288956017,
        "cond_entropy-3": 0.09460553222350296,
        "total_length-nopunct": 432,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 4.868949236402724,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6180555555555556,
        "vocab_size-1-nopunct": 267,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.418357282071229,
        "distinct-2-nopunct": 0.8731343283582089,
        "vocab_size-2-nopunct": 351,
        "unique-2-nopunct": 319,
        "entropy-2-nopunct": 8.34113332942777,
        "cond_entropy-2-nopunct": 0.9814137206070529,
        "distinct-3-nopunct": 0.9408602150537635,
        "vocab_size-3-nopunct": 350,
        "unique-3-nopunct": 331,
        "entropy-3-nopunct": 8.414791438778797,
        "cond_entropy-3-nopunct": 0.09058700949216794,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.19735328006333,
        "rouge1": {
            "precision": 0.75065,
            "recall": 0.70882,
            "fmeasure": 0.7159
        },
        "rouge2": {
            "precision": 0.50463,
            "recall": 0.48887,
            "fmeasure": 0.48831
        },
        "rougeL": {
            "precision": 0.63902,
            "recall": 0.61008,
            "fmeasure": 0.61185
        },
        "rougeLsum": {
            "precision": 0.63902,
            "recall": 0.61008,
            "fmeasure": 0.61185
        },
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.3364485981308411,
            "3": 0.764179104477612
        },
        "bleu": 44.20944,
        "nubia": {
            "semantic_relation": 4.05692,
            "contradiction": 12.71681,
            "irrelevancy": 32.87832,
            "logical_agreement": 54.40486,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.86613,
            "nubia_score": 0.68057
        },
        "meteor": 0.3820281838622848,
        "bleurt": 0.20313,
        "bertscore": {
            "precision": 0.92606,
            "recall": 0.91529,
            "f1": 0.91844
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 213,
        "total_length": 7848,
        "mean_pred_length": 36.84507042253521,
        "std_pred_length": 9.132793751566696,
        "median_pred_length": 37.0,
        "min_pred_length": 17,
        "max_pred_length": 73,
        "distinct-1": 0.13748725790010194,
        "vocab_size-1": 1079,
        "unique-1": 421,
        "entropy-1": 7.70488817487971,
        "distinct-2": 0.364505566470203,
        "vocab_size-2": 2783,
        "unique-2": 1525,
        "entropy-2": 10.587441202250226,
        "cond_entropy-2": 2.782752679897086,
        "distinct-3": 0.5491781191053624,
        "vocab_size-3": 4076,
        "unique-3": 2744,
        "entropy-3": 11.544168639262669,
        "cond_entropy-3": 0.9920782845858179,
        "total_length-nopunct": 6952,
        "mean_pred_length-nopunct": 32.63849765258216,
        "std_pred_length-nopunct": 8.183105325390015,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.15405638665132337,
        "vocab_size-1-nopunct": 1071,
        "unique-1-nopunct": 421,
        "entropy-1-nopunct": 7.957225673965853,
        "distinct-2-nopunct": 0.38254933966463867,
        "vocab_size-2-nopunct": 2578,
        "unique-2-nopunct": 1458,
        "entropy-2-nopunct": 10.52746402198307,
        "cond_entropy-2-nopunct": 2.661854222104933,
        "distinct-3-nopunct": 0.5637450199203188,
        "vocab_size-3-nopunct": 3679,
        "unique-3-nopunct": 2528,
        "entropy-3-nopunct": 11.412166913035765,
        "cond_entropy-3-nopunct": 0.9156940351196666,
        "msttr-100": 0.61154,
        "msttr-100_nopunct": 0.64406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.670905416951385,
        "rouge1": {
            "precision": 0.61464,
            "recall": 0.59139,
            "fmeasure": 0.59518
        },
        "rouge2": {
            "precision": 0.33996,
            "recall": 0.32253,
            "fmeasure": 0.32671
        },
        "rougeL": {
            "precision": 0.4494,
            "recall": 0.434,
            "fmeasure": 0.43509
        },
        "rougeLsum": {
            "precision": 0.4494,
            "recall": 0.434,
            "fmeasure": 0.43509
        },
        "local_recall": {
            "1": 0.19618717504332756,
            "2": 0.49173300673606857,
            "3": 0.6912654943787835
        },
        "bleu": 34.83496,
        "nubia": {
            "semantic_relation": 3.37339,
            "contradiction": 42.31998,
            "irrelevancy": 10.24691,
            "logical_agreement": 47.43311,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.30085,
            "nubia_score": 0.53248
        },
        "meteor": 0.28957306524446375,
        "bleurt": -0.32178,
        "bertscore": {
            "precision": 0.86779,
            "recall": 0.86378,
            "f1": 0.86457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 43,
        "total_length": 685,
        "mean_pred_length": 15.930232558139535,
        "std_pred_length": 5.410563951336137,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5153284671532846,
        "vocab_size-1": 353,
        "unique-1": 277,
        "entropy-1": 7.427311038778232,
        "distinct-2": 0.8722741433021807,
        "vocab_size-2": 560,
        "unique-2": 503,
        "entropy-2": 9.026127325876951,
        "cond_entropy-2": 1.3688389172044768,
        "distinct-3": 0.9449081803005008,
        "vocab_size-3": 566,
        "unique-3": 538,
        "entropy-3": 9.108290510815362,
        "cond_entropy-3": 0.07700958382559414,
        "total_length-nopunct": 590,
        "mean_pred_length-nopunct": 13.720930232558139,
        "std_pred_length-nopunct": 4.8910244392049345,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5847457627118644,
        "vocab_size-1-nopunct": 345,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.627025006486921,
        "distinct-2-nopunct": 0.886654478976234,
        "vocab_size-2-nopunct": 485,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.823862607777965,
        "cond_entropy-2-nopunct": 1.264762251963879,
        "distinct-3-nopunct": 0.9563492063492064,
        "vocab_size-3-nopunct": 482,
        "unique-3-nopunct": 462,
        "entropy-3-nopunct": 8.886010082230008,
        "cond_entropy-3-nopunct": 0.054877890806756605,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.036885708129711,
        "rouge1": {
            "precision": 0.79859,
            "recall": 0.78385,
            "fmeasure": 0.77997
        },
        "rouge2": {
            "precision": 0.62293,
            "recall": 0.61069,
            "fmeasure": 0.60871
        },
        "rougeL": {
            "precision": 0.71506,
            "recall": 0.7141,
            "fmeasure": 0.70333
        },
        "rougeLsum": {
            "precision": 0.71506,
            "recall": 0.7141,
            "fmeasure": 0.70333
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.48872180451127817,
            "3": 0.8160377358490566
        },
        "bleu": 54.77996,
        "nubia": {
            "semantic_relation": 4.26454,
            "contradiction": 9.27367,
            "irrelevancy": 28.36676,
            "logical_agreement": 62.35957,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.48693,
            "nubia_score": 0.76051
        },
        "meteor": 0.4207350048441303,
        "bleurt": 0.32202,
        "bertscore": {
            "precision": 0.93343,
            "recall": 0.9315,
            "f1": 0.93037
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 382,
        "total_length": 10508,
        "mean_pred_length": 27.50785340314136,
        "std_pred_length": 8.195177428735573,
        "median_pred_length": 26.0,
        "min_pred_length": 11,
        "max_pred_length": 53,
        "distinct-1": 0.11562618956985155,
        "vocab_size-1": 1215,
        "unique-1": 442,
        "entropy-1": 7.7374594552888105,
        "distinct-2": 0.32846138652972545,
        "vocab_size-2": 3326,
        "unique-2": 1794,
        "entropy-2": 10.70935576501256,
        "cond_entropy-2": 2.8351892131023724,
        "distinct-3": 0.5092364532019704,
        "vocab_size-3": 4962,
        "unique-3": 3310,
        "entropy-3": 11.721499268128557,
        "cond_entropy-3": 1.0585299971911086,
        "total_length-nopunct": 9276,
        "mean_pred_length-nopunct": 24.282722513089006,
        "std_pred_length-nopunct": 7.481472047768076,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.1301207416990082,
        "vocab_size-1-nopunct": 1207,
        "unique-1-nopunct": 442,
        "entropy-1-nopunct": 8.005939240475733,
        "distinct-2-nopunct": 0.3442770407015966,
        "vocab_size-2-nopunct": 3062,
        "unique-2-nopunct": 1729,
        "entropy-2-nopunct": 10.610282741192625,
        "cond_entropy-2-nopunct": 2.72483209318863,
        "distinct-3-nopunct": 0.5236137218045113,
        "vocab_size-3-nopunct": 4457,
        "unique-3-nopunct": 3047,
        "entropy-3-nopunct": 11.572143602892558,
        "cond_entropy-3-nopunct": 1.0051152662153322,
        "msttr-100": 0.48829,
        "msttr-100_nopunct": 0.5038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.875166599777633,
        "rouge1": {
            "precision": 0.63137,
            "recall": 0.63909,
            "fmeasure": 0.62827
        },
        "rouge2": {
            "precision": 0.36818,
            "recall": 0.37137,
            "fmeasure": 0.36552
        },
        "rougeL": {
            "precision": 0.49364,
            "recall": 0.50287,
            "fmeasure": 0.49212
        },
        "rougeLsum": {
            "precision": 0.49364,
            "recall": 0.50287,
            "fmeasure": 0.49212
        },
        "local_recall": {
            "1": 0.217607560308381,
            "2": 0.53125,
            "3": 0.7098166127292341,
            "4": 0.6666666666666666,
            "5": 0.42857142857142855
        },
        "bleu": 35.54379,
        "nubia": {
            "semantic_relation": 3.58799,
            "contradiction": 39.04427,
            "irrelevancy": 10.95193,
            "logical_agreement": 50.00381,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.50292,
            "nubia_score": 0.57056
        },
        "meteor": 0.31538543239522426,
        "bleurt": -0.19635,
        "bertscore": {
            "precision": 0.87744,
            "recall": 0.87867,
            "f1": 0.87688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 136,
        "total_length": 2216,
        "mean_pred_length": 16.294117647058822,
        "std_pred_length": 6.951637182388831,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 64,
        "distinct-1": 0.36462093862815886,
        "vocab_size-1": 808,
        "unique-1": 640,
        "entropy-1": 7.681281765006788,
        "distinct-2": 0.6836538461538462,
        "vocab_size-2": 1422,
        "unique-2": 1282,
        "entropy-2": 9.719095395349381,
        "cond_entropy-2": 1.8022401356180138,
        "distinct-3": 0.7875514403292181,
        "vocab_size-3": 1531,
        "unique-3": 1433,
        "entropy-3": 10.071617923916648,
        "cond_entropy-3": 0.41758948396919215,
        "total_length-nopunct": 1926,
        "mean_pred_length-nopunct": 14.161764705882353,
        "std_pred_length-nopunct": 5.729465363923704,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4158878504672897,
        "vocab_size-1-nopunct": 801,
        "unique-1-nopunct": 640,
        "entropy-1-nopunct": 7.9413986220903885,
        "distinct-2-nopunct": 0.693854748603352,
        "vocab_size-2-nopunct": 1242,
        "unique-2-nopunct": 1132,
        "entropy-2-nopunct": 9.522153306507699,
        "cond_entropy-2-nopunct": 1.7382686579103825,
        "distinct-3-nopunct": 0.7956469165659008,
        "vocab_size-3-nopunct": 1316,
        "unique-3-nopunct": 1241,
        "entropy-3-nopunct": 9.859828291951038,
        "cond_entropy-3-nopunct": 0.4188521340563154,
        "msttr-100": 0.63682,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.842008645909895,
        "rouge1": {
            "precision": 0.77444,
            "recall": 0.75737,
            "fmeasure": 0.75584
        },
        "rouge2": {
            "precision": 0.55206,
            "recall": 0.5397,
            "fmeasure": 0.53892
        },
        "rougeL": {
            "precision": 0.67271,
            "recall": 0.66109,
            "fmeasure": 0.65828
        },
        "rougeLsum": {
            "precision": 0.67271,
            "recall": 0.66109,
            "fmeasure": 0.65828
        },
        "local_recall": {
            "1": 0.23636363636363636,
            "2": 0.45454545454545453,
            "3": 0.8032100488485694
        },
        "bleu": 52.95254,
        "nubia": {
            "semantic_relation": 4.26013,
            "contradiction": 7.90533,
            "irrelevancy": 23.72352,
            "logical_agreement": 68.37115,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.49698,
            "nubia_score": 0.75634
        },
        "meteor": 0.41345259007207413,
        "bleurt": 0.36533,
        "bertscore": {
            "precision": 0.9353,
            "recall": 0.93174,
            "f1": 0.93218
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7081,
        "mean_pred_length": 19.724233983286908,
        "std_pred_length": 9.371577245470183,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.3719813585651744,
        "vocab_size-1": 2634,
        "unique-1": 1953,
        "entropy-1": 9.151215069274848,
        "distinct-2": 0.834870574233859,
        "vocab_size-2": 5612,
        "unique-2": 5195,
        "entropy-2": 12.133574363653173,
        "cond_entropy-2": 2.7162053095405403,
        "distinct-3": 0.9636963696369637,
        "vocab_size-3": 6132,
        "unique-3": 6012,
        "entropy-3": 12.519160612429554,
        "cond_entropy-3": 0.40155610144735454,
        "total_length-nopunct": 6285,
        "mean_pred_length-nopunct": 17.506963788300837,
        "std_pred_length-nopunct": 8.274828864168686,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4175019888623707,
        "vocab_size-1-nopunct": 2624,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.503038516520459,
        "distinct-2-nopunct": 0.8543705703678705,
        "vocab_size-2-nopunct": 5063,
        "unique-2-nopunct": 4719,
        "entropy-2-nopunct": 12.03345076396359,
        "cond_entropy-2-nopunct": 2.671912891716557,
        "distinct-3-nopunct": 0.9773666247530088,
        "vocab_size-3-nopunct": 5441,
        "unique-3-nopunct": 5347,
        "entropy-3-nopunct": 12.388720492085142,
        "cond_entropy-3-nopunct": 0.3797937563546693,
        "msttr-100": 0.72371,
        "msttr-100_nopunct": 0.76774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.30797632015497,
        "rouge1": {
            "precision": 0.899,
            "recall": 0.85954,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.8075,
            "recall": 0.7682,
            "fmeasure": 0.77305
        },
        "rougeL": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "rougeLsum": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "local_recall": {
            "1": 0.029768467475192944,
            "2": 0.15768194070080863,
            "3": 0.3433734939759036,
            "4": 0.5504587155963303,
            "5": 0.6965098634294385,
            "6": 0.7549295774647887,
            "7": 0.8483606557377049,
            "8": 0.864897466827503,
            "9": 0.8857142857142857,
            "10": 0.9255813953488372
        },
        "bleu": 85.93589,
        "nubia": {
            "semantic_relation": 4.19043,
            "contradiction": 3.83901,
            "irrelevancy": 31.42769,
            "logical_agreement": 64.7333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.79962,
            "nubia_score": 0.64296
        },
        "meteor": 0.5204959402607399,
        "bleurt": 0.21083,
        "bertscore": {
            "precision": 0.97007,
            "recall": 0.96322,
            "f1": 0.96358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 103,
        "total_length": 1797,
        "mean_pred_length": 17.446601941747574,
        "std_pred_length": 7.155320045815875,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 59,
        "distinct-1": 0.4234835837506956,
        "vocab_size-1": 761,
        "unique-1": 594,
        "entropy-1": 8.009141952569239,
        "distinct-2": 0.7798110979929161,
        "vocab_size-2": 1321,
        "unique-2": 1200,
        "entropy-2": 9.951130338996943,
        "cond_entropy-2": 1.7106085679130751,
        "distinct-3": 0.8774355751099937,
        "vocab_size-3": 1396,
        "unique-3": 1337,
        "entropy-3": 10.191474343003577,
        "cond_entropy-3": 0.23788356373775624,
        "total_length-nopunct": 1581,
        "mean_pred_length-nopunct": 15.349514563106796,
        "std_pred_length-nopunct": 6.945989606169248,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.476280834914611,
        "vocab_size-1-nopunct": 753,
        "unique-1-nopunct": 591,
        "entropy-1-nopunct": 8.235115215539803,
        "distinct-2-nopunct": 0.7861975642760487,
        "vocab_size-2-nopunct": 1162,
        "unique-2-nopunct": 1072,
        "entropy-2-nopunct": 9.747232379432372,
        "cond_entropy-2-nopunct": 1.6198198495518215,
        "distinct-3-nopunct": 0.8683636363636363,
        "vocab_size-3-nopunct": 1194,
        "unique-3-nopunct": 1143,
        "entropy-3-nopunct": 9.937010758045727,
        "cond_entropy-3-nopunct": 0.2350719783340733,
        "msttr-100": 0.67941,
        "msttr-100_nopunct": 0.716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.698456944025886,
        "rouge1": {
            "precision": 0.76288,
            "recall": 0.73682,
            "fmeasure": 0.73901
        },
        "rouge2": {
            "precision": 0.54984,
            "recall": 0.52814,
            "fmeasure": 0.52987
        },
        "rougeL": {
            "precision": 0.6681,
            "recall": 0.65343,
            "fmeasure": 0.65023
        },
        "rougeLsum": {
            "precision": 0.6681,
            "recall": 0.65343,
            "fmeasure": 0.65023
        },
        "local_recall": {
            "1": 0.21341463414634146,
            "2": 0.4478114478114478,
            "3": 0.7944839857651246
        },
        "bleu": 50.54363,
        "nubia": {
            "semantic_relation": 4.19758,
            "contradiction": 9.29829,
            "irrelevancy": 26.09076,
            "logical_agreement": 64.61095,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.45702,
            "nubia_score": 0.74046
        },
        "meteor": 0.4057345525366112,
        "bleurt": 0.28145,
        "bertscore": {
            "precision": 0.93039,
            "recall": 0.92399,
            "f1": 0.92547
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "total_length": 22771,
        "mean_pred_length": 45.542,
        "std_pred_length": 20.68652305246099,
        "median_pred_length": 46.0,
        "min_pred_length": 8,
        "max_pred_length": 89,
        "distinct-1": 0.06964999341267401,
        "vocab_size-1": 1586,
        "unique-1": 581,
        "entropy-1": 5.830425025634929,
        "distinct-2": 0.17974046966907636,
        "vocab_size-2": 4003,
        "unique-2": 1773,
        "entropy-2": 10.005497310152723,
        "cond_entropy-2": 4.174552795676255,
        "distinct-3": 0.3153277295484819,
        "vocab_size-3": 6865,
        "unique-3": 3542,
        "entropy-3": 11.600878499351863,
        "cond_entropy-3": 1.6381200782354008,
        "total_length-nopunct": 20976,
        "mean_pred_length-nopunct": 41.952,
        "std_pred_length-nopunct": 19.36237836630614,
        "median_pred_length-nopunct": 43.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.07518115942028986,
        "vocab_size-1-nopunct": 1577,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 5.734845655423666,
        "distinct-2-nopunct": 0.18011330337956633,
        "vocab_size-2-nopunct": 3688,
        "unique-2-nopunct": 1620,
        "entropy-2-nopunct": 9.888032833854128,
        "cond_entropy-2-nopunct": 4.248871024207257,
        "distinct-3-nopunct": 0.31778133760512617,
        "vocab_size-3-nopunct": 6348,
        "unique-3-nopunct": 3364,
        "entropy-3-nopunct": 11.463146597919797,
        "cond_entropy-3-nopunct": 1.6101245691283208,
        "msttr-100": 0.42308,
        "msttr-100_nopunct": 0.41656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "nist": 1.1485939413560113,
        "rouge1": {
            "precision": 0.40466,
            "recall": 0.39717,
            "fmeasure": 0.39153
        },
        "rouge2": {
            "precision": 0.19734,
            "recall": 0.20678,
            "fmeasure": 0.19686
        },
        "rougeL": {
            "precision": 0.39187,
            "recall": 0.38655,
            "fmeasure": 0.38005
        },
        "rougeLsum": {
            "precision": 0.39187,
            "recall": 0.38655,
            "fmeasure": 0.38005
        },
        "local_recall": {
            "1": 0.09142764015645372,
            "2": 0.19242424242424241,
            "3": 0.268385460693153,
            "4": 0.26666666666666666,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "bleu": 2.05599,
        "nubia": {
            "semantic_relation": 3.34921,
            "contradiction": 33.24965,
            "irrelevancy": 17.03913,
            "logical_agreement": 49.71122,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.59007,
            "nubia_score": 0.16534
        },
        "meteor": 0.1310552999074365,
        "bleurt": -0.47056,
        "bertscore": {
            "precision": 0.86184,
            "recall": 0.87224,
            "f1": 0.86651
        }
    },
    "web_nlg_en_validation": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_validation",
        "N": 1667
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7081,
        "mean_pred_length": 19.724233983286908,
        "std_pred_length": 9.371577245470183,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.3719813585651744,
        "vocab_size-1": 2634,
        "unique-1": 1953,
        "entropy-1": 9.151215069274848,
        "distinct-2": 0.834870574233859,
        "vocab_size-2": 5612,
        "unique-2": 5195,
        "entropy-2": 12.133574363653173,
        "cond_entropy-2": 2.7162053095405403,
        "distinct-3": 0.9636963696369637,
        "vocab_size-3": 6132,
        "unique-3": 6012,
        "entropy-3": 12.519160612429554,
        "cond_entropy-3": 0.40155610144735454,
        "total_length-nopunct": 6285,
        "mean_pred_length-nopunct": 17.506963788300837,
        "std_pred_length-nopunct": 8.274828864168686,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4175019888623707,
        "vocab_size-1-nopunct": 2624,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.503038516520459,
        "distinct-2-nopunct": 0.8543705703678705,
        "vocab_size-2-nopunct": 5063,
        "unique-2-nopunct": 4719,
        "entropy-2-nopunct": 12.03345076396359,
        "cond_entropy-2-nopunct": 2.671912891716557,
        "distinct-3-nopunct": 0.9773666247530088,
        "vocab_size-3-nopunct": 5441,
        "unique-3-nopunct": 5347,
        "entropy-3-nopunct": 12.388720492085142,
        "cond_entropy-3-nopunct": 0.3797937563546693,
        "msttr-100": 0.72371,
        "msttr-100_nopunct": 0.76774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.30797632015497,
        "rouge1": {
            "precision": 0.899,
            "recall": 0.85954,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.8075,
            "recall": 0.7682,
            "fmeasure": 0.77305
        },
        "rougeL": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "rougeLsum": {
            "precision": 0.8876,
            "recall": 0.84667,
            "fmeasure": 0.85432
        },
        "local_recall": {
            "1": 0.029768467475192944,
            "2": 0.15768194070080863,
            "3": 0.3433734939759036,
            "4": 0.5504587155963303,
            "5": 0.6965098634294385,
            "6": 0.7549295774647887,
            "7": 0.8483606557377049,
            "8": 0.864897466827503,
            "9": 0.8857142857142857,
            "10": 0.9255813953488372
        },
        "bleu": 85.93589,
        "nubia": {
            "semantic_relation": 4.19043,
            "contradiction": 3.83901,
            "irrelevancy": 31.42769,
            "logical_agreement": 64.7333,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.79962,
            "nubia_score": 0.64296
        },
        "meteor": 0.5204959402607399,
        "bleurt": 0.21083,
        "bertscore": {
            "precision": 0.97007,
            "recall": 0.96322,
            "f1": 0.96358
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 349,
        "total_length": 6674,
        "mean_pred_length": 19.12320916905444,
        "std_pred_length": 6.379071710707266,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 59,
        "distinct-1": 0.16227150134851664,
        "vocab_size-1": 1083,
        "unique-1": 504,
        "entropy-1": 7.523359340806698,
        "distinct-2": 0.40901185770750986,
        "vocab_size-2": 2587,
        "unique-2": 1604,
        "entropy-2": 10.41963795322619,
        "cond_entropy-2": 2.712949945988783,
        "distinct-3": 0.5922021419009371,
        "vocab_size-3": 3539,
        "unique-3": 2579,
        "entropy-3": 11.316401929514058,
        "cond_entropy-3": 0.9748714534284502,
        "total_length-nopunct": 5813,
        "mean_pred_length-nopunct": 16.65616045845272,
        "std_pred_length-nopunct": 5.685335092556483,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.185102356786513,
        "vocab_size-1-nopunct": 1076,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.822373656850703,
        "distinct-2-nopunct": 0.4167276720351391,
        "vocab_size-2-nopunct": 2277,
        "unique-2-nopunct": 1429,
        "entropy-2-nopunct": 10.263587530763989,
        "cond_entropy-2-nopunct": 2.6194525383991087,
        "distinct-3-nopunct": 0.5980449657869013,
        "vocab_size-3-nopunct": 3059,
        "unique-3-nopunct": 2242,
        "entropy-3-nopunct": 11.11750936545914,
        "cond_entropy-3-nopunct": 0.9379102014179237,
        "msttr-100": 0.60545,
        "msttr-100_nopunct": 0.65483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.400041920590307,
        "rouge1": {
            "precision": 0.61804,
            "recall": 0.64461,
            "fmeasure": 0.62311
        },
        "rouge2": {
            "precision": 0.37787,
            "recall": 0.39295,
            "fmeasure": 0.38004
        },
        "rougeL": {
            "precision": 0.51391,
            "recall": 0.53767,
            "fmeasure": 0.5184
        },
        "rougeLsum": {
            "precision": 0.51391,
            "recall": 0.53767,
            "fmeasure": 0.5184
        },
        "local_recall": {
            "1": 0.21863799283154123,
            "2": 0.534366576819407,
            "3": 0.6917293233082706,
            "4": 1.0
        },
        "bleu": 34.74244,
        "nubia": {
            "semantic_relation": 3.58938,
            "contradiction": 34.90441,
            "irrelevancy": 11.66723,
            "logical_agreement": 53.42836,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.84292,
            "nubia_score": 0.56171
        },
        "meteor": 0.3232115213316683,
        "bleurt": -0.20437,
        "bertscore": {
            "precision": 0.87379,
            "recall": 0.88272,
            "f1": 0.87696
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 6674,
        "mean_pred_length": 18.590529247910865,
        "std_pred_length": 9.175298041418927,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37114174408151035,
        "vocab_size-1": 2477,
        "unique-1": 1838,
        "entropy-1": 9.116295805436831,
        "distinct-2": 0.8478226444972288,
        "vocab_size-2": 5354,
        "unique-2": 4964,
        "entropy-2": 12.106933198268315,
        "cond_entropy-2": 2.706384434217815,
        "distinct-3": 0.9701141705842847,
        "vocab_size-3": 5778,
        "unique-3": 5680,
        "entropy-3": 12.449944986891092,
        "cond_entropy-3": 0.36008039448712986,
        "total_length-nopunct": 5971,
        "mean_pred_length-nopunct": 16.632311977715876,
        "std_pred_length-nopunct": 8.233951247765605,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41316362418355385,
        "vocab_size-1-nopunct": 2467,
        "unique-1-nopunct": 1836,
        "entropy-1-nopunct": 9.445227093609574,
        "distinct-2-nopunct": 0.8638631503920171,
        "vocab_size-2-nopunct": 4848,
        "unique-2-nopunct": 4528,
        "entropy-2-nopunct": 11.994321202463482,
        "cond_entropy-2-nopunct": 2.696332625431439,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 5150,
        "unique-3-nopunct": 5072,
        "entropy-3-nopunct": 12.313821556761653,
        "cond_entropy-3-nopunct": 0.34267752635810567,
        "msttr-100": 0.73121,
        "msttr-100_nopunct": 0.77407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.529033641252033,
        "rouge1": {
            "precision": 0.85346,
            "recall": 0.75736,
            "fmeasure": 0.78716
        },
        "rouge2": {
            "precision": 0.71098,
            "recall": 0.62831,
            "fmeasure": 0.65233
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "local_recall": {
            "1": 0.040534804753820035,
            "2": 0.16219667943805874,
            "3": 0.3741794310722101,
            "4": 0.49920760697305866,
            "5": 0.6199376947040498,
            "6": 0.7210144927536232,
            "7": 0.8342878961435662
        },
        "bleu": 65.71936,
        "nubia": {
            "semantic_relation": 4.15419,
            "contradiction": 4.64645,
            "irrelevancy": 15.7492,
            "logical_agreement": 79.60434,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02579,
            "nubia_score": 0.65128
        },
        "meteor": 0.4415426994644947,
        "bleurt": 0.15856,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.93345,
            "f1": 0.94117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 66,
        "total_length": 1148,
        "mean_pred_length": 17.393939393939394,
        "std_pred_length": 11.720066692176038,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 94,
        "distinct-1": 0.460801393728223,
        "vocab_size-1": 529,
        "unique-1": 421,
        "entropy-1": 7.788834654226891,
        "distinct-2": 0.8022181146025879,
        "vocab_size-2": 868,
        "unique-2": 770,
        "entropy-2": 9.523435679861032,
        "cond_entropy-2": 1.5177496967383268,
        "distinct-3": 0.90748031496063,
        "vocab_size-3": 922,
        "unique-3": 876,
        "entropy-3": 9.73954530804018,
        "cond_entropy-3": 0.2069807624414588,
        "total_length-nopunct": 992,
        "mean_pred_length-nopunct": 15.030303030303031,
        "std_pred_length-nopunct": 9.36138052654191,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.5231854838709677,
        "vocab_size-1-nopunct": 519,
        "unique-1-nopunct": 415,
        "entropy-1-nopunct": 8.039721655703278,
        "distinct-2-nopunct": 0.8304535637149028,
        "vocab_size-2-nopunct": 769,
        "unique-2-nopunct": 694,
        "entropy-2-nopunct": 9.381932601847458,
        "cond_entropy-2-nopunct": 1.3990101281371883,
        "distinct-3-nopunct": 0.9302325581395349,
        "vocab_size-3-nopunct": 800,
        "unique-3-nopunct": 768,
        "entropy-3-nopunct": 9.569509713676176,
        "cond_entropy-3-nopunct": 0.17288424737057007,
        "msttr-100": 0.68273,
        "msttr-100_nopunct": 0.73556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.37742777069504,
        "rouge1": {
            "precision": 0.73875,
            "recall": 0.71137,
            "fmeasure": 0.71224
        },
        "rouge2": {
            "precision": 0.52053,
            "recall": 0.4982,
            "fmeasure": 0.49982
        },
        "rougeL": {
            "precision": 0.6443,
            "recall": 0.62356,
            "fmeasure": 0.62187
        },
        "rougeLsum": {
            "precision": 0.6443,
            "recall": 0.62356,
            "fmeasure": 0.62187
        },
        "local_recall": {
            "1": 0.20398009950248755,
            "2": 0.37755102040816324,
            "3": 0.7370689655172413
        },
        "bleu": 39.61086,
        "nubia": {
            "semantic_relation": 4.19224,
            "contradiction": 8.38124,
            "irrelevancy": 28.28717,
            "logical_agreement": 63.33159,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.31608,
            "nubia_score": 0.73732
        },
        "meteor": 0.3780267063039404,
        "bleurt": 0.25863,
        "bertscore": {
            "precision": 0.91666,
            "recall": 0.91738,
            "f1": 0.91528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.1176878443984663,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.590974598112907,
        "rouge1": {
            "precision": 0.55072,
            "recall": 0.49206,
            "fmeasure": 0.51753
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.30556,
            "fmeasure": 0.32426
        },
        "rougeL": {
            "precision": 0.4058,
            "recall": 0.36508,
            "fmeasure": 0.38265
        },
        "rougeLsum": {
            "precision": 0.4058,
            "recall": 0.36508,
            "fmeasure": 0.38265
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8,
            "3": 0.5
        },
        "bleu": 38.31792,
        "nubia": {
            "semantic_relation": 3.5236,
            "contradiction": 0.25148,
            "irrelevancy": 56.90689,
            "logical_agreement": 42.84163,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.16933,
            "nubia_score": 0.63792
        },
        "meteor": 0.29273840899953096,
        "bleurt": 0.04428,
        "bertscore": {
            "precision": 0.92442,
            "recall": 0.88547,
            "f1": 0.90453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 80,
        "total_length": 1403,
        "mean_pred_length": 17.5375,
        "std_pred_length": 8.286953224798605,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.4476122594440485,
        "vocab_size-1": 628,
        "unique-1": 485,
        "entropy-1": 7.938874988228688,
        "distinct-2": 0.817838246409675,
        "vocab_size-2": 1082,
        "unique-2": 960,
        "entropy-2": 9.881735310751885,
        "cond_entropy-2": 1.7126862460610441,
        "distinct-3": 0.9211584875301689,
        "vocab_size-3": 1145,
        "unique-3": 1079,
        "entropy-3": 10.09973288592864,
        "cond_entropy-3": 0.2343081748066119,
        "total_length-nopunct": 1224,
        "mean_pred_length-nopunct": 15.3,
        "std_pred_length-nopunct": 7.232565243397393,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.5073529411764706,
        "vocab_size-1-nopunct": 621,
        "unique-1-nopunct": 483,
        "entropy-1-nopunct": 8.207982401929344,
        "distinct-2-nopunct": 0.8216783216783217,
        "vocab_size-2-nopunct": 940,
        "unique-2-nopunct": 837,
        "entropy-2-nopunct": 9.679855855591109,
        "cond_entropy-2-nopunct": 1.5709979573981487,
        "distinct-3-nopunct": 0.9191729323308271,
        "vocab_size-3-nopunct": 978,
        "unique-3-nopunct": 921,
        "entropy-3-nopunct": 9.869828194399323,
        "cond_entropy-3-nopunct": 0.21540597460884595,
        "msttr-100": 0.70714,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.795149078373494,
        "rouge1": {
            "precision": 0.71917,
            "recall": 0.66383,
            "fmeasure": 0.67321
        },
        "rouge2": {
            "precision": 0.45807,
            "recall": 0.43188,
            "fmeasure": 0.43258
        },
        "rougeL": {
            "precision": 0.6011,
            "recall": 0.57405,
            "fmeasure": 0.57206
        },
        "rougeLsum": {
            "precision": 0.6011,
            "recall": 0.57405,
            "fmeasure": 0.57206
        },
        "local_recall": {
            "1": 0.2824858757062147,
            "2": 0.43859649122807015,
            "3": 0.7102199223803364
        },
        "bleu": 37.82529,
        "nubia": {
            "semantic_relation": 3.86833,
            "contradiction": 11.63254,
            "irrelevancy": 37.46172,
            "logical_agreement": 50.90574,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.53647,
            "nubia_score": 0.62769
        },
        "meteor": 0.34097881704468813,
        "bleurt": 0.11541,
        "bertscore": {
            "precision": 0.91449,
            "recall": 0.90179,
            "f1": 0.90573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 111,
        "total_length": 1915,
        "mean_pred_length": 17.25225225225225,
        "std_pred_length": 8.562929182740042,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 57,
        "distinct-1": 0.37806788511749345,
        "vocab_size-1": 724,
        "unique-1": 586,
        "entropy-1": 7.627617884418564,
        "distinct-2": 0.6951219512195121,
        "vocab_size-2": 1254,
        "unique-2": 1132,
        "entropy-2": 9.622015250922619,
        "cond_entropy-2": 1.779836218915283,
        "distinct-3": 0.789722386296515,
        "vocab_size-3": 1337,
        "unique-3": 1253,
        "entropy-3": 9.924118631472354,
        "cond_entropy-3": 0.35439048855349375,
        "total_length-nopunct": 1624,
        "mean_pred_length-nopunct": 14.63063063063063,
        "std_pred_length-nopunct": 6.973473455512499,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.4396551724137931,
        "vocab_size-1-nopunct": 714,
        "unique-1-nopunct": 583,
        "entropy-1-nopunct": 7.8873613277824335,
        "distinct-2-nopunct": 0.7151354923992069,
        "vocab_size-2-nopunct": 1082,
        "unique-2-nopunct": 997,
        "entropy-2-nopunct": 9.407366547252753,
        "cond_entropy-2-nopunct": 1.6638304822585794,
        "distinct-3-nopunct": 0.8059914407988588,
        "vocab_size-3-nopunct": 1130,
        "unique-3-nopunct": 1075,
        "entropy-3-nopunct": 9.693407034629704,
        "cond_entropy-3-nopunct": 0.3615986696127058,
        "msttr-100": 0.63895,
        "msttr-100_nopunct": 0.68312,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.508037977408591,
        "rouge1": {
            "precision": 0.77795,
            "recall": 0.73963,
            "fmeasure": 0.74631
        },
        "rouge2": {
            "precision": 0.56538,
            "recall": 0.53412,
            "fmeasure": 0.5408
        },
        "rougeL": {
            "precision": 0.68582,
            "recall": 0.64709,
            "fmeasure": 0.65516
        },
        "rougeLsum": {
            "precision": 0.68582,
            "recall": 0.64709,
            "fmeasure": 0.65516
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.42592592592592593,
            "3": 0.7789305666400639
        },
        "bleu": 51.05179,
        "nubia": {
            "semantic_relation": 4.19759,
            "contradiction": 9.3659,
            "irrelevancy": 19.38672,
            "logical_agreement": 71.24738,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.50429,
            "nubia_score": 0.73359
        },
        "meteor": 0.4033831439233443,
        "bleurt": 0.35741,
        "bertscore": {
            "precision": 0.93439,
            "recall": 0.92862,
            "f1": 0.93027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 131,
        "total_length": 2210,
        "mean_pred_length": 16.870229007633586,
        "std_pred_length": 8.649579212785008,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.42217194570135747,
        "vocab_size-1": 933,
        "unique-1": 728,
        "entropy-1": 8.19472644877977,
        "distinct-2": 0.8056758056758057,
        "vocab_size-2": 1675,
        "unique-2": 1496,
        "entropy-2": 10.459392843429324,
        "cond_entropy-2": 2.0071829575669295,
        "distinct-3": 0.9188911704312115,
        "vocab_size-3": 1790,
        "unique-3": 1698,
        "entropy-3": 10.722091470663303,
        "cond_entropy-3": 0.26879944839142966,
        "total_length-nopunct": 1875,
        "mean_pred_length-nopunct": 14.312977099236642,
        "std_pred_length-nopunct": 6.580196949958178,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.49173333333333336,
        "vocab_size-1-nopunct": 922,
        "unique-1-nopunct": 726,
        "entropy-1-nopunct": 8.587278256034214,
        "distinct-2-nopunct": 0.841743119266055,
        "vocab_size-2-nopunct": 1468,
        "unique-2-nopunct": 1342,
        "entropy-2-nopunct": 10.301494160944804,
        "cond_entropy-2-nopunct": 1.8140559983516704,
        "distinct-3-nopunct": 0.9429634221946683,
        "vocab_size-3-nopunct": 1521,
        "unique-3-nopunct": 1458,
        "entropy-3-nopunct": 10.520674527574508,
        "cond_entropy-3-nopunct": 0.24643795277961944,
        "msttr-100": 0.68364,
        "msttr-100_nopunct": 0.74833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.266554125511991,
        "rouge1": {
            "precision": 0.7589,
            "recall": 0.69305,
            "fmeasure": 0.71154
        },
        "rouge2": {
            "precision": 0.51726,
            "recall": 0.47332,
            "fmeasure": 0.48561
        },
        "rougeL": {
            "precision": 0.66965,
            "recall": 0.61125,
            "fmeasure": 0.62755
        },
        "rougeLsum": {
            "precision": 0.66965,
            "recall": 0.61125,
            "fmeasure": 0.62755
        },
        "local_recall": {
            "1": 0.22546419098143236,
            "2": 0.4567307692307692,
            "3": 0.6928471248246845
        },
        "bleu": 40.90405,
        "nubia": {
            "semantic_relation": 4.10222,
            "contradiction": 13.34076,
            "irrelevancy": 24.47959,
            "logical_agreement": 62.17965,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.60471,
            "nubia_score": 0.68986
        },
        "meteor": 0.36069332525161785,
        "bleurt": 0.2323,
        "bertscore": {
            "precision": 0.92645,
            "recall": 0.91438,
            "f1": 0.91927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 127,
        "mean_pred_length": 12.7,
        "std_pred_length": 3.5227829907617076,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.6141732283464567,
        "vocab_size-1": 78,
        "unique-1": 58,
        "entropy-1": 5.9177140689111765,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 99,
        "unique-2": 89,
        "entropy-2": 6.511056172426915,
        "cond_entropy-2": 0.400952575564772,
        "distinct-3": 0.8878504672897196,
        "vocab_size-3": 95,
        "unique-3": 89,
        "entropy-3": 6.474837780672347,
        "cond_entropy-3": -0.02132974248761318,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.138470965295043,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6608695652173913,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.969020594253328,
        "distinct-2-nopunct": 0.8380952380952381,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.3329207555965175,
        "cond_entropy-2-nopunct": 0.42832582388520873,
        "distinct-3-nopunct": 0.8736842105263158,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.269546923983781,
        "cond_entropy-3-nopunct": -0.023234382973838535,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.360752436151045,
        "rouge1": {
            "precision": 0.92321,
            "recall": 0.9114,
            "fmeasure": 0.91125
        },
        "rouge2": {
            "precision": 0.82085,
            "recall": 0.82827,
            "fmeasure": 0.81877
        },
        "rougeL": {
            "precision": 0.87643,
            "recall": 0.86743,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.87643,
            "recall": 0.86743,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.36363636363636365,
            "3": 0.9056603773584906
        },
        "bleu": 74.52507,
        "nubia": {
            "semantic_relation": 4.78754,
            "contradiction": 0.54922,
            "irrelevancy": 13.0844,
            "logical_agreement": 86.36637,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.05735,
            "nubia_score": 0.90561
        },
        "meteor": 0.5275745283662187,
        "bleurt": 0.72819,
        "bertscore": {
            "precision": 0.97686,
            "recall": 0.97297,
            "f1": 0.97431
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 251,
        "total_length": 8763,
        "mean_pred_length": 34.91235059760956,
        "std_pred_length": 9.453191816024228,
        "median_pred_length": 34.0,
        "min_pred_length": 15,
        "max_pred_length": 69,
        "distinct-1": 0.11811023622047244,
        "vocab_size-1": 1035,
        "unique-1": 363,
        "entropy-1": 7.712846265031262,
        "distinct-2": 0.31449718045112784,
        "vocab_size-2": 2677,
        "unique-2": 1365,
        "entropy-2": 10.466020893037122,
        "cond_entropy-2": 2.649456718515019,
        "distinct-3": 0.47003994673768307,
        "vocab_size-3": 3883,
        "unique-3": 2456,
        "entropy-3": 11.333175705224296,
        "cond_entropy-3": 0.9013704603368988,
        "total_length-nopunct": 7732,
        "mean_pred_length-nopunct": 30.804780876494025,
        "std_pred_length-nopunct": 8.700284893203282,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.13282462493533367,
        "vocab_size-1-nopunct": 1027,
        "unique-1-nopunct": 363,
        "entropy-1-nopunct": 7.975488563063373,
        "distinct-2-nopunct": 0.33003609143162677,
        "vocab_size-2-nopunct": 2469,
        "unique-2-nopunct": 1317,
        "entropy-2-nopunct": 10.38231439286081,
        "cond_entropy-2-nopunct": 2.4968113940369094,
        "distinct-3-nopunct": 0.48533886583679114,
        "vocab_size-3-nopunct": 3509,
        "unique-3-nopunct": 2302,
        "entropy-3-nopunct": 11.188714786310127,
        "cond_entropy-3-nopunct": 0.8392778010493392,
        "msttr-100": 0.48954,
        "msttr-100_nopunct": 0.50221,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.050001285257164,
        "rouge1": {
            "precision": 0.64045,
            "recall": 0.63831,
            "fmeasure": 0.63223
        },
        "rouge2": {
            "precision": 0.37515,
            "recall": 0.37065,
            "fmeasure": 0.36844
        },
        "rougeL": {
            "precision": 0.47315,
            "recall": 0.47795,
            "fmeasure": 0.46967
        },
        "rougeLsum": {
            "precision": 0.47315,
            "recall": 0.47795,
            "fmeasure": 0.46967
        },
        "local_recall": {
            "1": 0.22932208887447292,
            "2": 0.5696682464454976,
            "3": 0.7432203389830508
        },
        "bleu": 39.26844,
        "nubia": {
            "semantic_relation": 3.58219,
            "contradiction": 36.53538,
            "irrelevancy": 9.10555,
            "logical_agreement": 54.35907,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.33423,
            "nubia_score": 0.58275
        },
        "meteor": 0.3205798807804515,
        "bleurt": -0.20005,
        "bertscore": {
            "precision": 0.87744,
            "recall": 0.87751,
            "f1": 0.87635
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 128,
        "total_length": 1953,
        "mean_pred_length": 15.2578125,
        "std_pred_length": 5.480428378771476,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.41525857654889914,
        "vocab_size-1": 811,
        "unique-1": 633,
        "entropy-1": 8.079306466995593,
        "distinct-2": 0.8197260273972603,
        "vocab_size-2": 1496,
        "unique-2": 1356,
        "entropy-2": 10.297295924465589,
        "cond_entropy-2": 1.923959475488516,
        "distinct-3": 0.9546258102533883,
        "vocab_size-3": 1620,
        "unique-3": 1570,
        "entropy-3": 10.616925031177177,
        "cond_entropy-3": 0.28289232896878114,
        "total_length-nopunct": 1695,
        "mean_pred_length-nopunct": 13.2421875,
        "std_pred_length-nopunct": 4.914497198579296,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4749262536873156,
        "vocab_size-1-nopunct": 805,
        "unique-1-nopunct": 632,
        "entropy-1-nopunct": 8.422588189346785,
        "distinct-2-nopunct": 0.8487555839183153,
        "vocab_size-2-nopunct": 1330,
        "unique-2-nopunct": 1232,
        "entropy-2-nopunct": 10.155522910516257,
        "cond_entropy-2-nopunct": 1.8085120132872237,
        "distinct-3-nopunct": 0.9728978457261988,
        "vocab_size-3-nopunct": 1400,
        "unique-3-nopunct": 1372,
        "entropy-3-nopunct": 10.42926005639051,
        "cond_entropy-3-nopunct": 0.2775009933217809,
        "msttr-100": 0.68526,
        "msttr-100_nopunct": 0.73312,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.711139722031014,
        "rouge1": {
            "precision": 0.81562,
            "recall": 0.7585,
            "fmeasure": 0.77761
        },
        "rouge2": {
            "precision": 0.56194,
            "recall": 0.52813,
            "fmeasure": 0.53841
        },
        "rougeL": {
            "precision": 0.71486,
            "recall": 0.6674,
            "fmeasure": 0.6825
        },
        "rougeLsum": {
            "precision": 0.71486,
            "recall": 0.6674,
            "fmeasure": 0.6825
        },
        "local_recall": {
            "1": 0.18584070796460178,
            "2": 0.2816326530612245,
            "3": 0.7860998650472335
        },
        "bleu": 46.35905,
        "nubia": {
            "semantic_relation": 4.45703,
            "contradiction": 7.55061,
            "irrelevancy": 17.46543,
            "logical_agreement": 74.98396,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.63911,
            "nubia_score": 0.80231
        },
        "meteor": 0.4017539274307887,
        "bleurt": 0.39343,
        "bertscore": {
            "precision": 0.94047,
            "recall": 0.9306,
            "f1": 0.93423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 64,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 2.6874192494328497,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 14,
        "distinct-1": 0.6875,
        "vocab_size-1": 44,
        "unique-1": 36,
        "entropy-1": 5.112300876357291,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 52,
        "unique-2": 47,
        "entropy-2": 5.638069141641993,
        "cond_entropy-2": 0.32718318269005986,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 48,
        "unique-3": 44,
        "entropy-3": 5.546593564294941,
        "cond_entropy-3": -0.06610113271410559,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 2.357022603955158,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1437610031517105,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.388758439731458,
        "cond_entropy-2-nopunct": 0.30462870684845444,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.277613436819113,
        "cond_entropy-3-nopunct": -0.0990862188155306,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.650067902955608,
        "rouge1": {
            "precision": 0.72824,
            "recall": 0.72851,
            "fmeasure": 0.71766
        },
        "rouge2": {
            "precision": 0.58892,
            "recall": 0.58775,
            "fmeasure": 0.57929
        },
        "rougeL": {
            "precision": 0.71898,
            "recall": 0.72692,
            "fmeasure": 0.71075
        },
        "rougeLsum": {
            "precision": 0.71898,
            "recall": 0.72692,
            "fmeasure": 0.71075
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6666666666666666,
            "3": 0.8181818181818182
        },
        "bleu": 60.85826,
        "nubia": {
            "semantic_relation": 3.64731,
            "contradiction": 12.70833,
            "irrelevancy": 20.61802,
            "logical_agreement": 66.67365,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.11436,
            "nubia_score": 0.60731
        },
        "meteor": 0.41013129872195225,
        "bleurt": 0.1429,
        "bertscore": {
            "precision": 0.92292,
            "recall": 0.91312,
            "f1": 0.91745
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 45,
        "total_length": 733,
        "mean_pred_length": 16.288888888888888,
        "std_pred_length": 5.483803312066553,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.45020463847203274,
        "vocab_size-1": 330,
        "unique-1": 251,
        "entropy-1": 7.231787897042219,
        "distinct-2": 0.7761627906976745,
        "vocab_size-2": 534,
        "unique-2": 458,
        "entropy-2": 8.789450830883183,
        "cond_entropy-2": 1.3479700236146062,
        "distinct-3": 0.9191290824261276,
        "vocab_size-3": 591,
        "unique-3": 551,
        "entropy-3": 9.144336941304562,
        "cond_entropy-3": 0.3584508049708133,
        "total_length-nopunct": 668,
        "mean_pred_length-nopunct": 14.844444444444445,
        "std_pred_length-nopunct": 5.295514057747602,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.48952095808383234,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 7.366178662414381,
        "distinct-2-nopunct": 0.7736757624398074,
        "vocab_size-2-nopunct": 482,
        "unique-2-nopunct": 413,
        "entropy-2-nopunct": 8.631782652204041,
        "cond_entropy-2-nopunct": 1.3180998204746455,
        "distinct-3-nopunct": 0.9152249134948097,
        "vocab_size-3-nopunct": 529,
        "unique-3-nopunct": 492,
        "entropy-3-nopunct": 8.980238268983486,
        "cond_entropy-3-nopunct": 0.3830038979800101,
        "msttr-100": 0.67571,
        "msttr-100_nopunct": 0.69833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.371555033313915,
        "rouge1": {
            "precision": 0.81356,
            "recall": 0.78158,
            "fmeasure": 0.78591
        },
        "rouge2": {
            "precision": 0.59278,
            "recall": 0.5761,
            "fmeasure": 0.57475
        },
        "rougeL": {
            "precision": 0.67507,
            "recall": 0.64992,
            "fmeasure": 0.65178
        },
        "rougeLsum": {
            "precision": 0.67507,
            "recall": 0.64992,
            "fmeasure": 0.65178
        },
        "local_recall": {
            "1": 0.12666666666666668,
            "2": 0.5703125,
            "3": 0.819838056680162
        },
        "bleu": 49.16843,
        "nubia": {
            "semantic_relation": 4.49328,
            "contradiction": 3.0787,
            "irrelevancy": 26.85207,
            "logical_agreement": 70.06924,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.81435,
            "nubia_score": 0.81182
        },
        "meteor": 0.42253585832632296,
        "bleurt": 0.39331,
        "bertscore": {
            "precision": 0.94738,
            "recall": 0.94057,
            "f1": 0.94291
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 369,
        "total_length": 4316,
        "mean_pred_length": 11.696476964769648,
        "std_pred_length": 3.9564038241386683,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.20597775718257647,
        "vocab_size-1": 889,
        "unique-1": 504,
        "entropy-1": 7.183268869741072,
        "distinct-2": 0.5016468203699012,
        "vocab_size-2": 1980,
        "unique-2": 1391,
        "entropy-2": 10.168041727329344,
        "cond_entropy-2": 2.6441873443511223,
        "distinct-3": 0.6953605366126328,
        "vocab_size-3": 2488,
        "unique-3": 1999,
        "entropy-3": 10.929945166414495,
        "cond_entropy-3": 0.8676677964215062,
        "total_length-nopunct": 3755,
        "mean_pred_length-nopunct": 10.176151761517616,
        "std_pred_length-nopunct": 3.420625362998323,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.23488681757656457,
        "vocab_size-1-nopunct": 882,
        "unique-1-nopunct": 502,
        "entropy-1-nopunct": 7.438145206507379,
        "distinct-2-nopunct": 0.4884819846426462,
        "vocab_size-2-nopunct": 1654,
        "unique-2-nopunct": 1142,
        "entropy-2-nopunct": 9.898163605063502,
        "cond_entropy-2-nopunct": 2.7887542708839206,
        "distinct-3-nopunct": 0.6824660258534968,
        "vocab_size-3-nopunct": 2059,
        "unique-3-nopunct": 1635,
        "entropy-3-nopunct": 10.651159851751286,
        "cond_entropy-3-nopunct": 0.9190098524257793,
        "msttr-100": 0.57698,
        "msttr-100_nopunct": 0.62595,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.92254037019045,
        "rouge1": {
            "precision": 0.61807,
            "recall": 0.64435,
            "fmeasure": 0.62233
        },
        "rouge2": {
            "precision": 0.37071,
            "recall": 0.38237,
            "fmeasure": 0.37054
        },
        "rougeL": {
            "precision": 0.5473,
            "recall": 0.57146,
            "fmeasure": 0.55107
        },
        "rougeLsum": {
            "precision": 0.5473,
            "recall": 0.57146,
            "fmeasure": 0.55107
        },
        "local_recall": {
            "1": 0.2531779661016949,
            "2": 0.5807504078303426,
            "3": 0.6347941567065073,
            "4": 0.9736842105263158
        },
        "bleu": 31.68961,
        "nubia": {
            "semantic_relation": 3.41278,
            "contradiction": 42.58105,
            "irrelevancy": 10.11426,
            "logical_agreement": 47.30469,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.41474,
            "nubia_score": 0.47729
        },
        "meteor": 0.32239636333645794,
        "bleurt": -0.20857,
        "bertscore": {
            "precision": 0.88119,
            "recall": 0.88975,
            "f1": 0.88433
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 6674,
        "mean_pred_length": 18.590529247910865,
        "std_pred_length": 9.175298041418927,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37114174408151035,
        "vocab_size-1": 2477,
        "unique-1": 1838,
        "entropy-1": 9.116295805436831,
        "distinct-2": 0.8478226444972288,
        "vocab_size-2": 5354,
        "unique-2": 4964,
        "entropy-2": 12.106933198268315,
        "cond_entropy-2": 2.706384434217815,
        "distinct-3": 0.9701141705842847,
        "vocab_size-3": 5778,
        "unique-3": 5680,
        "entropy-3": 12.449944986891092,
        "cond_entropy-3": 0.36008039448712986,
        "total_length-nopunct": 5971,
        "mean_pred_length-nopunct": 16.632311977715876,
        "std_pred_length-nopunct": 8.233951247765605,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41316362418355385,
        "vocab_size-1-nopunct": 2467,
        "unique-1-nopunct": 1836,
        "entropy-1-nopunct": 9.445227093609574,
        "distinct-2-nopunct": 0.8638631503920171,
        "vocab_size-2-nopunct": 4848,
        "unique-2-nopunct": 4528,
        "entropy-2-nopunct": 11.994321202463482,
        "cond_entropy-2-nopunct": 2.696332625431439,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 5150,
        "unique-3-nopunct": 5072,
        "entropy-3-nopunct": 12.313821556761653,
        "cond_entropy-3-nopunct": 0.34267752635810567,
        "msttr-100": 0.73121,
        "msttr-100_nopunct": 0.77407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.529033641252033,
        "rouge1": {
            "precision": 0.85346,
            "recall": 0.75736,
            "fmeasure": 0.78716
        },
        "rouge2": {
            "precision": 0.71098,
            "recall": 0.62831,
            "fmeasure": 0.65233
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "local_recall": {
            "1": 0.040534804753820035,
            "2": 0.16219667943805874,
            "3": 0.3741794310722101,
            "4": 0.49920760697305866,
            "5": 0.6199376947040498,
            "6": 0.7210144927536232,
            "7": 0.8342878961435662
        },
        "bleu": 65.71936,
        "nubia": {
            "semantic_relation": 4.15419,
            "contradiction": 4.64645,
            "irrelevancy": 15.7492,
            "logical_agreement": 79.60434,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02579,
            "nubia_score": 0.65128
        },
        "meteor": 0.4415426994644947,
        "bleurt": 0.15856,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.93345,
            "f1": 0.94117
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 158,
        "total_length": 6187,
        "mean_pred_length": 39.15822784810127,
        "std_pred_length": 10.61854250642448,
        "median_pred_length": 38.0,
        "min_pred_length": 19,
        "max_pred_length": 73,
        "distinct-1": 0.1474058509778568,
        "vocab_size-1": 912,
        "unique-1": 358,
        "entropy-1": 7.62021296208674,
        "distinct-2": 0.365732293912755,
        "vocab_size-2": 2205,
        "unique-2": 1193,
        "entropy-2": 10.299400018780915,
        "cond_entropy-2": 2.5878667711717043,
        "distinct-3": 0.5321069664452394,
        "vocab_size-3": 3124,
        "unique-3": 2072,
        "entropy-3": 11.123831809957089,
        "cond_entropy-3": 0.8561133010556904,
        "total_length-nopunct": 5471,
        "mean_pred_length-nopunct": 34.62658227848101,
        "std_pred_length-nopunct": 9.343300705104971,
        "median_pred_length-nopunct": 33.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.16523487479437032,
        "vocab_size-1-nopunct": 904,
        "unique-1-nopunct": 358,
        "entropy-1-nopunct": 7.856979538524907,
        "distinct-2-nopunct": 0.3841520798042537,
        "vocab_size-2-nopunct": 2041,
        "unique-2-nopunct": 1133,
        "entropy-2-nopunct": 10.235191430098837,
        "cond_entropy-2-nopunct": 2.4593102153552646,
        "distinct-3-nopunct": 0.5497575169738118,
        "vocab_size-3-nopunct": 2834,
        "unique-3-nopunct": 1916,
        "entropy-3-nopunct": 11.004805940966524,
        "cond_entropy-3-nopunct": 0.7975910970194595,
        "msttr-100": 0.5177,
        "msttr-100_nopunct": 0.53704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.555570430438391,
        "rouge1": {
            "precision": 0.61309,
            "recall": 0.58643,
            "fmeasure": 0.59201
        },
        "rouge2": {
            "precision": 0.34203,
            "recall": 0.32275,
            "fmeasure": 0.3278
        },
        "rougeL": {
            "precision": 0.44027,
            "recall": 0.42542,
            "fmeasure": 0.4266
        },
        "rougeLsum": {
            "precision": 0.44027,
            "recall": 0.42542,
            "fmeasure": 0.4266
        },
        "local_recall": {
            "1": 0.21069182389937108,
            "2": 0.4554030874785592,
            "3": 0.6955595026642984
        },
        "bleu": 36.8337,
        "nubia": {
            "semantic_relation": 3.30021,
            "contradiction": 44.76398,
            "irrelevancy": 8.8605,
            "logical_agreement": 46.37551,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.28179,
            "nubia_score": 0.52291
        },
        "meteor": 0.2892675460901272,
        "bleurt": -0.36942,
        "bertscore": {
            "precision": 0.86515,
            "recall": 0.85944,
            "f1": 0.8611
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 6674,
        "mean_pred_length": 18.590529247910865,
        "std_pred_length": 9.175298041418927,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37114174408151035,
        "vocab_size-1": 2477,
        "unique-1": 1838,
        "entropy-1": 9.116295805436831,
        "distinct-2": 0.8478226444972288,
        "vocab_size-2": 5354,
        "unique-2": 4964,
        "entropy-2": 12.106933198268315,
        "cond_entropy-2": 2.706384434217815,
        "distinct-3": 0.9701141705842847,
        "vocab_size-3": 5778,
        "unique-3": 5680,
        "entropy-3": 12.449944986891092,
        "cond_entropy-3": 0.36008039448712986,
        "total_length-nopunct": 5971,
        "mean_pred_length-nopunct": 16.632311977715876,
        "std_pred_length-nopunct": 8.233951247765605,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41316362418355385,
        "vocab_size-1-nopunct": 2467,
        "unique-1-nopunct": 1836,
        "entropy-1-nopunct": 9.445227093609574,
        "distinct-2-nopunct": 0.8638631503920171,
        "vocab_size-2-nopunct": 4848,
        "unique-2-nopunct": 4528,
        "entropy-2-nopunct": 11.994321202463482,
        "cond_entropy-2-nopunct": 2.696332625431439,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 5150,
        "unique-3-nopunct": 5072,
        "entropy-3-nopunct": 12.313821556761653,
        "cond_entropy-3-nopunct": 0.34267752635810567,
        "msttr-100": 0.73121,
        "msttr-100_nopunct": 0.77407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.529033641252033,
        "rouge1": {
            "precision": 0.85346,
            "recall": 0.75736,
            "fmeasure": 0.78716
        },
        "rouge2": {
            "precision": 0.71098,
            "recall": 0.62831,
            "fmeasure": 0.65233
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "local_recall": {
            "1": 0.040534804753820035,
            "2": 0.16219667943805874,
            "3": 0.3741794310722101,
            "4": 0.49920760697305866,
            "5": 0.6199376947040498,
            "6": 0.7210144927536232,
            "7": 0.8342878961435662
        },
        "bleu": 65.71936,
        "nubia": {
            "semantic_relation": 4.15419,
            "contradiction": 4.64645,
            "irrelevancy": 15.7492,
            "logical_agreement": 79.60434,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02579,
            "nubia_score": 0.65128
        },
        "meteor": 0.4415426994644947,
        "bleurt": 0.15856,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.93345,
            "f1": 0.94117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 73,
        "total_length": 1179,
        "mean_pred_length": 16.15068493150685,
        "std_pred_length": 6.965022658021957,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.46564885496183206,
        "vocab_size-1": 549,
        "unique-1": 425,
        "entropy-1": 7.833788226997855,
        "distinct-2": 0.8309222423146474,
        "vocab_size-2": 919,
        "unique-2": 811,
        "entropy-2": 9.679110545145518,
        "cond_entropy-2": 1.5905972722529738,
        "distinct-3": 0.9196515004840271,
        "vocab_size-3": 950,
        "unique-3": 880,
        "entropy-3": 9.841003810389532,
        "cond_entropy-3": 0.15004756981400805,
        "total_length-nopunct": 1000,
        "mean_pred_length-nopunct": 13.698630136986301,
        "std_pred_length-nopunct": 5.792496165048835,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.54,
        "vocab_size-1-nopunct": 540,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 8.119774875961879,
        "distinct-2-nopunct": 0.8554476806903991,
        "vocab_size-2-nopunct": 793,
        "unique-2-nopunct": 716,
        "entropy-2-nopunct": 9.480199920941786,
        "cond_entropy-2-nopunct": 1.4517561661559848,
        "distinct-3-nopunct": 0.9391100702576113,
        "vocab_size-3-nopunct": 802,
        "unique-3-nopunct": 757,
        "entropy-3-nopunct": 9.60897672975329,
        "cond_entropy-3-nopunct": 0.13897538241657809,
        "msttr-100": 0.69364,
        "msttr-100_nopunct": 0.757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.471729090142938,
        "rouge1": {
            "precision": 0.8123,
            "recall": 0.73309,
            "fmeasure": 0.75889
        },
        "rouge2": {
            "precision": 0.58591,
            "recall": 0.54769,
            "fmeasure": 0.55892
        },
        "rougeL": {
            "precision": 0.73095,
            "recall": 0.67071,
            "fmeasure": 0.68816
        },
        "rougeLsum": {
            "precision": 0.73095,
            "recall": 0.67071,
            "fmeasure": 0.68816
        },
        "local_recall": {
            "1": 0.2651162790697674,
            "2": 0.4939759036144578,
            "3": 0.7454545454545455
        },
        "bleu": 50.523,
        "nubia": {
            "semantic_relation": 4.19521,
            "contradiction": 11.05985,
            "irrelevancy": 28.58461,
            "logical_agreement": 60.35555,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.63777,
            "nubia_score": 0.73097
        },
        "meteor": 0.40138354042695834,
        "bleurt": 0.27094,
        "bertscore": {
            "precision": 0.93982,
            "recall": 0.9234,
            "f1": 0.93048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 26,
        "total_length": 388,
        "mean_pred_length": 14.923076923076923,
        "std_pred_length": 4.1502833723742185,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5567010309278351,
        "vocab_size-1": 216,
        "unique-1": 175,
        "entropy-1": 6.908562035853986,
        "distinct-2": 0.9116022099447514,
        "vocab_size-2": 330,
        "unique-2": 308,
        "entropy-2": 8.294419014219654,
        "cond_entropy-2": 1.1697345703352449,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 330,
        "unique-3": 324,
        "entropy-3": 8.356603137064532,
        "cond_entropy-3": 0.07212786895924643,
        "total_length-nopunct": 329,
        "mean_pred_length-nopunct": 12.653846153846153,
        "std_pred_length-nopunct": 3.233744051670753,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6382978723404256,
        "vocab_size-1-nopunct": 210,
        "unique-1-nopunct": 174,
        "entropy-1-nopunct": 7.091654458915934,
        "distinct-2-nopunct": 0.9141914191419142,
        "vocab_size-2-nopunct": 277,
        "unique-2-nopunct": 261,
        "entropy-2-nopunct": 8.037350458797698,
        "cond_entropy-2-nopunct": 1.022503375073662,
        "distinct-3-nopunct": 0.9783393501805054,
        "vocab_size-3-nopunct": 271,
        "unique-3-nopunct": 265,
        "entropy-3-nopunct": 8.070420866410245,
        "cond_entropy-3-nopunct": 0.04877947491053472,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.72667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.727172588795139,
        "rouge1": {
            "precision": 0.72759,
            "recall": 0.7132,
            "fmeasure": 0.70135
        },
        "rouge2": {
            "precision": 0.48191,
            "recall": 0.46353,
            "fmeasure": 0.45909
        },
        "rougeL": {
            "precision": 0.62862,
            "recall": 0.62106,
            "fmeasure": 0.60845
        },
        "rougeLsum": {
            "precision": 0.62862,
            "recall": 0.62106,
            "fmeasure": 0.60845
        },
        "local_recall": {
            "1": 0.26436781609195403,
            "2": 0.5053763440860215,
            "3": 0.7081545064377682
        },
        "bleu": 38.985,
        "nubia": {
            "semantic_relation": 3.89567,
            "contradiction": 7.78376,
            "irrelevancy": 48.58948,
            "logical_agreement": 43.62676,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.6106,
            "nubia_score": 0.64412
        },
        "meteor": 0.3579618700843432,
        "bleurt": 0.11695,
        "bertscore": {
            "precision": 0.91296,
            "recall": 0.91246,
            "f1": 0.91082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 83,
        "total_length": 1425,
        "mean_pred_length": 17.16867469879518,
        "std_pred_length": 6.574538835095518,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.4863157894736842,
        "vocab_size-1": 693,
        "unique-1": 558,
        "entropy-1": 8.114069148830184,
        "distinct-2": 0.8718330849478391,
        "vocab_size-2": 1170,
        "unique-2": 1073,
        "entropy-2": 10.046060195544584,
        "cond_entropy-2": 1.6838345063061315,
        "distinct-3": 0.9594916600476568,
        "vocab_size-3": 1208,
        "unique-3": 1170,
        "entropy-3": 10.208083050232588,
        "cond_entropy-3": 0.1481919243333957,
        "total_length-nopunct": 1223,
        "mean_pred_length-nopunct": 14.734939759036145,
        "std_pred_length-nopunct": 5.7268850999630025,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5600981193785772,
        "vocab_size-1-nopunct": 685,
        "unique-1-nopunct": 557,
        "entropy-1-nopunct": 8.40880320606605,
        "distinct-2-nopunct": 0.8868421052631579,
        "vocab_size-2-nopunct": 1011,
        "unique-2-nopunct": 943,
        "entropy-2-nopunct": 9.842497625861027,
        "cond_entropy-2-nopunct": 1.5235261868475702,
        "distinct-3-nopunct": 0.9640491958372753,
        "vocab_size-3-nopunct": 1019,
        "unique-3-nopunct": 991,
        "entropy-3-nopunct": 9.965324893162677,
        "cond_entropy-3-nopunct": 0.141122099472002,
        "msttr-100": 0.71214,
        "msttr-100_nopunct": 0.77833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.688143342330833,
        "rouge1": {
            "precision": 0.78256,
            "recall": 0.73885,
            "fmeasure": 0.74797
        },
        "rouge2": {
            "precision": 0.54845,
            "recall": 0.51734,
            "fmeasure": 0.52437
        },
        "rougeL": {
            "precision": 0.68345,
            "recall": 0.64526,
            "fmeasure": 0.65346
        },
        "rougeLsum": {
            "precision": 0.68345,
            "recall": 0.64526,
            "fmeasure": 0.65346
        },
        "local_recall": {
            "1": 0.21370967741935484,
            "2": 0.5365853658536586,
            "3": 0.7681623931623932
        },
        "bleu": 49.90899,
        "nubia": {
            "semantic_relation": 4.23803,
            "contradiction": 8.81382,
            "irrelevancy": 28.54622,
            "logical_agreement": 62.63996,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.63564,
            "nubia_score": 0.73151
        },
        "meteor": 0.4014569669474366,
        "bleurt": 0.28551,
        "bertscore": {
            "precision": 0.9359,
            "recall": 0.92714,
            "f1": 0.93036
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 6674,
        "mean_pred_length": 18.590529247910865,
        "std_pred_length": 9.175298041418927,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37114174408151035,
        "vocab_size-1": 2477,
        "unique-1": 1838,
        "entropy-1": 9.116295805436831,
        "distinct-2": 0.8478226444972288,
        "vocab_size-2": 5354,
        "unique-2": 4964,
        "entropy-2": 12.106933198268315,
        "cond_entropy-2": 2.706384434217815,
        "distinct-3": 0.9701141705842847,
        "vocab_size-3": 5778,
        "unique-3": 5680,
        "entropy-3": 12.449944986891092,
        "cond_entropy-3": 0.36008039448712986,
        "total_length-nopunct": 5971,
        "mean_pred_length-nopunct": 16.632311977715876,
        "std_pred_length-nopunct": 8.233951247765605,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.41316362418355385,
        "vocab_size-1-nopunct": 2467,
        "unique-1-nopunct": 1836,
        "entropy-1-nopunct": 9.445227093609574,
        "distinct-2-nopunct": 0.8638631503920171,
        "vocab_size-2-nopunct": 4848,
        "unique-2-nopunct": 4528,
        "entropy-2-nopunct": 11.994321202463482,
        "cond_entropy-2-nopunct": 2.696332625431439,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 5150,
        "unique-3-nopunct": 5072,
        "entropy-3-nopunct": 12.313821556761653,
        "cond_entropy-3-nopunct": 0.34267752635810567,
        "msttr-100": 0.73121,
        "msttr-100_nopunct": 0.77407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.529033641252033,
        "rouge1": {
            "precision": 0.85346,
            "recall": 0.75736,
            "fmeasure": 0.78716
        },
        "rouge2": {
            "precision": 0.71098,
            "recall": 0.62831,
            "fmeasure": 0.65233
        },
        "rougeL": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "rougeLsum": {
            "precision": 0.82673,
            "recall": 0.73435,
            "fmeasure": 0.76243
        },
        "local_recall": {
            "1": 0.040534804753820035,
            "2": 0.16219667943805874,
            "3": 0.3741794310722101,
            "4": 0.49920760697305866,
            "5": 0.6199376947040498,
            "6": 0.7210144927536232,
            "7": 0.8342878961435662
        },
        "bleu": 65.71936,
        "nubia": {
            "semantic_relation": 4.15419,
            "contradiction": 4.64645,
            "irrelevancy": 15.7492,
            "logical_agreement": 79.60434,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02579,
            "nubia_score": 0.65128
        },
        "meteor": 0.4415426994644947,
        "bleurt": 0.15856,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.93345,
            "f1": 0.94117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 179,
        "mean_pred_length": 14.916666666666666,
        "std_pred_length": 9.23271658590014,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.5921787709497207,
        "vocab_size-1": 106,
        "unique-1": 74,
        "entropy-1": 6.319097497983902,
        "distinct-2": 0.8862275449101796,
        "vocab_size-2": 148,
        "unique-2": 135,
        "entropy-2": 7.123166717597827,
        "cond_entropy-2": 0.6301594551990256,
        "distinct-3": 0.9354838709677419,
        "vocab_size-3": 145,
        "unique-3": 139,
        "entropy-3": 7.12761117941197,
        "cond_entropy-3": 0.02461511277226966,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 7.54983443527075,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6538461538461539,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.407609289570287,
        "distinct-2-nopunct": 0.9097222222222222,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.973642622925034,
        "cond_entropy-2-nopunct": 0.6114049663512942,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.9780692140390235,
        "cond_entropy-3-nopunct": 0.007118928554981356,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.42404272079513,
        "rouge1": {
            "precision": 0.74884,
            "recall": 0.62706,
            "fmeasure": 0.6706
        },
        "rouge2": {
            "precision": 0.51132,
            "recall": 0.43061,
            "fmeasure": 0.45825
        },
        "rougeL": {
            "precision": 0.62996,
            "recall": 0.54299,
            "fmeasure": 0.57316
        },
        "rougeLsum": {
            "precision": 0.62996,
            "recall": 0.54299,
            "fmeasure": 0.57316
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.35,
            "3": 0.6615384615384615
        },
        "bleu": 32.54668,
        "nubia": {
            "semantic_relation": 3.91533,
            "contradiction": 2.35165,
            "irrelevancy": 26.20557,
            "logical_agreement": 71.44278,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.64572,
            "nubia_score": 0.67676
        },
        "meteor": 0.3221008324242504,
        "bleurt": 0.03518,
        "bertscore": {
            "precision": 0.93032,
            "recall": 0.89333,
            "f1": 0.91032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 48,
        "total_length": 755,
        "mean_pred_length": 15.729166666666666,
        "std_pred_length": 6.160152809702767,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.32847682119205296,
        "vocab_size-1": 248,
        "unique-1": 199,
        "entropy-1": 6.359057649617844,
        "distinct-2": 0.5884016973125884,
        "vocab_size-2": 416,
        "unique-2": 364,
        "entropy-2": 7.953678071455143,
        "cond_entropy-2": 1.432785922298376,
        "distinct-3": 0.6995447647951442,
        "vocab_size-3": 461,
        "unique-3": 417,
        "entropy-3": 8.335429782754684,
        "cond_entropy-3": 0.4444368631540855,
        "total_length-nopunct": 654,
        "mean_pred_length-nopunct": 13.625,
        "std_pred_length-nopunct": 5.081112903029545,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.37003058103975534,
        "vocab_size-1-nopunct": 242,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 6.434996910142179,
        "distinct-2-nopunct": 0.594059405940594,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 7.770682324953219,
        "cond_entropy-2-nopunct": 1.4606361530627403,
        "distinct-3-nopunct": 0.7060931899641577,
        "vocab_size-3-nopunct": 394,
        "unique-3-nopunct": 356,
        "entropy-3-nopunct": 8.130496963303244,
        "cond_entropy-3-nopunct": 0.46520339234406494,
        "msttr-100": 0.52143,
        "msttr-100_nopunct": 0.54167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.066112321064671,
        "rouge1": {
            "precision": 0.80576,
            "recall": 0.7974,
            "fmeasure": 0.79482
        },
        "rouge2": {
            "precision": 0.63045,
            "recall": 0.62354,
            "fmeasure": 0.62169
        },
        "rougeL": {
            "precision": 0.73655,
            "recall": 0.72631,
            "fmeasure": 0.72597
        },
        "rougeLsum": {
            "precision": 0.73655,
            "recall": 0.72631,
            "fmeasure": 0.72597
        },
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5875,
            "3": 0.8244575936883629
        },
        "bleu": 62.40449,
        "nubia": {
            "semantic_relation": 4.47355,
            "contradiction": 6.37397,
            "irrelevancy": 11.13983,
            "logical_agreement": 82.4862,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.02101,
            "nubia_score": 0.85498
        },
        "meteor": 0.45082148967257085,
        "bleurt": 0.60407,
        "bertscore": {
            "precision": 0.95304,
            "recall": 0.948,
            "f1": 0.94915
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 350,
        "total_length": 8613,
        "mean_pred_length": 24.60857142857143,
        "std_pred_length": 6.294073013720195,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 44,
        "distinct-1": 0.13177754557064902,
        "vocab_size-1": 1135,
        "unique-1": 446,
        "entropy-1": 7.691237988239901,
        "distinct-2": 0.3562870628101174,
        "vocab_size-2": 2944,
        "unique-2": 1651,
        "entropy-2": 10.605884079386454,
        "cond_entropy-2": 2.7658121963785094,
        "distinct-3": 0.5444205737394161,
        "vocab_size-3": 4308,
        "unique-3": 2955,
        "entropy-3": 11.58258613532045,
        "cond_entropy-3": 1.0282721646937942,
        "total_length-nopunct": 7589,
        "mean_pred_length-nopunct": 21.68285714285714,
        "std_pred_length-nopunct": 5.820112208750702,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.14837264461720912,
        "vocab_size-1-nopunct": 1126,
        "unique-1-nopunct": 446,
        "entropy-1-nopunct": 7.9534423912967,
        "distinct-2-nopunct": 0.36980245890316343,
        "vocab_size-2-nopunct": 2677,
        "unique-2-nopunct": 1564,
        "entropy-2-nopunct": 10.48630048902192,
        "cond_entropy-2-nopunct": 2.6648342359237085,
        "distinct-3-nopunct": 0.5565394106546668,
        "vocab_size-3-nopunct": 3834,
        "unique-3-nopunct": 2691,
        "entropy-3-nopunct": 11.419105079267684,
        "cond_entropy-3-nopunct": 0.9810714831795225,
        "msttr-100": 0.61849,
        "msttr-100_nopunct": 0.65933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.602792942439643,
        "rouge1": {
            "precision": 0.6231,
            "recall": 0.63702,
            "fmeasure": 0.62341
        },
        "rouge2": {
            "precision": 0.36665,
            "recall": 0.37523,
            "fmeasure": 0.36664
        },
        "rougeL": {
            "precision": 0.49565,
            "recall": 0.50994,
            "fmeasure": 0.49697
        },
        "rougeLsum": {
            "precision": 0.49565,
            "recall": 0.50994,
            "fmeasure": 0.49697
        },
        "local_recall": {
            "1": 0.22031388806633107,
            "2": 0.5372254954472415,
            "3": 0.6843198338525441,
            "4": 0.5,
            "5": 0.4827586206896552
        },
        "bleu": 33.71608,
        "nubia": {
            "semantic_relation": 3.55099,
            "contradiction": 41.76603,
            "irrelevancy": 10.52302,
            "logical_agreement": 47.71095,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.61708,
            "nubia_score": 0.55754
        },
        "meteor": 0.3102518053083702,
        "bleurt": -0.22654,
        "bertscore": {
            "precision": 0.8733,
            "recall": 0.87669,
            "f1": 0.87385
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 80,
        "total_length": 3414,
        "mean_pred_length": 42.675,
        "std_pred_length": 9.395178284630898,
        "median_pred_length": 42.0,
        "min_pred_length": 20,
        "max_pred_length": 89,
        "distinct-1": 0.19859402460456943,
        "vocab_size-1": 678,
        "unique-1": 328,
        "entropy-1": 7.289307565361791,
        "distinct-2": 0.46010797840431916,
        "vocab_size-2": 1534,
        "unique-2": 986,
        "entropy-2": 9.848934043989592,
        "cond_entropy-2": 2.4836391944897107,
        "distinct-3": 0.6508912108174555,
        "vocab_size-3": 2118,
        "unique-3": 1612,
        "entropy-3": 10.682801443244117,
        "cond_entropy-3": 0.8576254808743307,
        "total_length-nopunct": 3023,
        "mean_pred_length-nopunct": 37.7875,
        "std_pred_length-nopunct": 8.984283151704426,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.2216341382732385,
        "vocab_size-1-nopunct": 670,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 7.48446772066695,
        "distinct-2-nopunct": 0.4835202174651716,
        "vocab_size-2-nopunct": 1423,
        "unique-2-nopunct": 938,
        "entropy-2-nopunct": 9.794685797344385,
        "cond_entropy-2-nopunct": 2.378642782267064,
        "distinct-3-nopunct": 0.6692280824310164,
        "vocab_size-3-nopunct": 1916,
        "unique-3-nopunct": 1494,
        "entropy-3-nopunct": 10.552995787190214,
        "cond_entropy-3-nopunct": 0.7758374327478171,
        "msttr-100": 0.52147,
        "msttr-100_nopunct": 0.53733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.117511820913014,
        "rouge1": {
            "precision": 0.59614,
            "recall": 0.5503,
            "fmeasure": 0.56406
        },
        "rouge2": {
            "precision": 0.30834,
            "recall": 0.28178,
            "fmeasure": 0.29015
        },
        "rougeL": {
            "precision": 0.4328,
            "recall": 0.40511,
            "fmeasure": 0.41271
        },
        "rougeLsum": {
            "precision": 0.4328,
            "recall": 0.40511,
            "fmeasure": 0.41271
        },
        "local_recall": {
            "1": 0.20257966616084977,
            "2": 0.450402144772118,
            "3": 0.6187584345479082
        },
        "bleu": 31.42981,
        "nubia": {
            "semantic_relation": 3.08968,
            "contradiction": 47.94389,
            "irrelevancy": 11.50253,
            "logical_agreement": 40.55358,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.18089,
            "nubia_score": 0.47168
        },
        "meteor": 0.25520029083544565,
        "bleurt": -0.38595,
        "bertscore": {
            "precision": 0.85474,
            "recall": 0.8467,
            "f1": 0.84949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8563451988875919,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.75,
            "fmeasure": 0.75192
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.6381,
            "fmeasure": 0.62857
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.72619,
            "fmeasure": 0.72293
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.72619,
            "fmeasure": 0.72293
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.875
        },
        "bleu": 70.71068,
        "nubia": {
            "semantic_relation": 4.4238,
            "contradiction": 0.86014,
            "irrelevancy": 36.8869,
            "logical_agreement": 62.25295,
            "grammar_ref": 5.89248,
            "grammar_hyp": 7.19039,
            "nubia_score": 0.57852
        },
        "meteor": 0.4650618593150367,
        "bleurt": 0.38436,
        "bertscore": {
            "precision": 0.96048,
            "recall": 0.97078,
            "f1": 0.9656
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 500,
        "total_length": 7992,
        "mean_pred_length": 15.984,
        "std_pred_length": 6.87166238984425,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.07157157157157157,
        "vocab_size-1": 572,
        "unique-1": 218,
        "entropy-1": 6.37283795248662,
        "distinct-2": 0.2091564335290977,
        "vocab_size-2": 1567,
        "unique-2": 806,
        "entropy-2": 9.033610743239029,
        "cond_entropy-2": 2.581711548848135,
        "distinct-3": 0.33466819221967964,
        "vocab_size-3": 2340,
        "unique-3": 1472,
        "entropy-3": 9.803076183576808,
        "cond_entropy-3": 0.8300250910189675,
        "total_length-nopunct": 7293,
        "mean_pred_length-nopunct": 14.586,
        "std_pred_length-nopunct": 6.470749879264381,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.07788290141231317,
        "vocab_size-1-nopunct": 568,
        "unique-1-nopunct": 218,
        "entropy-1-nopunct": 6.369242586051425,
        "distinct-2-nopunct": 0.20506403650817018,
        "vocab_size-2-nopunct": 1393,
        "unique-2-nopunct": 716,
        "entropy-2-nopunct": 8.861902852673252,
        "cond_entropy-2-nopunct": 2.660744305177686,
        "distinct-3-nopunct": 0.3359288097886541,
        "vocab_size-3-nopunct": 2114,
        "unique-3-nopunct": 1346,
        "entropy-3-nopunct": 9.638437984463433,
        "cond_entropy-3-nopunct": 0.8461307167586628,
        "msttr-100": 0.54481,
        "msttr-100_nopunct": 0.55139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.5357226612400223,
        "rouge1": {
            "precision": 0.41883,
            "recall": 0.4442,
            "fmeasure": 0.41601
        },
        "rouge2": {
            "precision": 0.22348,
            "recall": 0.24245,
            "fmeasure": 0.22325
        },
        "rougeL": {
            "precision": 0.366,
            "recall": 0.38934,
            "fmeasure": 0.36424
        },
        "rougeLsum": {
            "precision": 0.366,
            "recall": 0.38934,
            "fmeasure": 0.36424
        },
        "local_recall": {
            "1": 0.2746331236897275
        },
        "bleu": 3.68709,
        "nubia": {
            "semantic_relation": 2.75005,
            "contradiction": 35.1812,
            "irrelevancy": 25.53899,
            "logical_agreement": 39.27981,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.12604,
            "nubia_score": 0.32608
        },
        "meteor": 0.12848805890987777,
        "bleurt": -0.66553,
        "bertscore": {
            "precision": 0.82513,
            "recall": 0.85504,
            "f1": 0.83956
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 114,
        "total_length": 4860,
        "mean_pred_length": 42.63157894736842,
        "std_pred_length": 9.467639397048202,
        "median_pred_length": 41.5,
        "min_pred_length": 20,
        "max_pred_length": 89,
        "distinct-1": 0.15967078189300413,
        "vocab_size-1": 776,
        "unique-1": 313,
        "entropy-1": 7.524027517657193,
        "distinct-2": 0.3860092709650232,
        "vocab_size-2": 1832,
        "unique-2": 1048,
        "entropy-2": 10.06221844919323,
        "cond_entropy-2": 2.4564012805137514,
        "distinct-3": 0.5533246977547496,
        "vocab_size-3": 2563,
        "unique-3": 1775,
        "entropy-3": 10.86699460773468,
        "cond_entropy-3": 0.8277624842635853,
        "total_length-nopunct": 4299,
        "mean_pred_length-nopunct": 37.71052631578947,
        "std_pred_length-nopunct": 8.62648277029228,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.17864619678995114,
        "vocab_size-1-nopunct": 768,
        "unique-1-nopunct": 312,
        "entropy-1-nopunct": 7.753947291797476,
        "distinct-2-nopunct": 0.407168458781362,
        "vocab_size-2-nopunct": 1704,
        "unique-2-nopunct": 1013,
        "entropy-2-nopunct": 9.99590257366446,
        "cond_entropy-2-nopunct": 2.3074378634009056,
        "distinct-3-nopunct": 0.5718496683861459,
        "vocab_size-3-nopunct": 2328,
        "unique-3-nopunct": 1669,
        "entropy-3-nopunct": 10.736099883998744,
        "cond_entropy-3-nopunct": 0.7579654616889518,
        "msttr-100": 0.60042,
        "msttr-100_nopunct": 0.6469,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.902740085092135,
        "rouge1": {
            "precision": 0.65295,
            "recall": 0.60365,
            "fmeasure": 0.62016
        },
        "rouge2": {
            "precision": 0.36735,
            "recall": 0.33904,
            "fmeasure": 0.34854
        },
        "rougeL": {
            "precision": 0.4644,
            "recall": 0.43835,
            "fmeasure": 0.44558
        },
        "rougeLsum": {
            "precision": 0.4644,
            "recall": 0.43835,
            "fmeasure": 0.44558
        },
        "local_recall": {
            "1": 0.20781426953567383,
            "2": 0.5510752688172043,
            "3": 0.7007518796992481
        },
        "bleu": 37.81318,
        "nubia": {
            "semantic_relation": 3.4939,
            "contradiction": 35.30226,
            "irrelevancy": 9.47299,
            "logical_agreement": 55.22475,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.16475,
            "nubia_score": 0.56863
        },
        "meteor": 0.29624871255151125,
        "bleurt": -0.23393,
        "bertscore": {
            "precision": 0.87637,
            "recall": 0.86879,
            "f1": 0.87125
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 41,
        "total_length": 1725,
        "mean_pred_length": 42.073170731707314,
        "std_pred_length": 8.969841730943068,
        "median_pred_length": 42.0,
        "min_pred_length": 20,
        "max_pred_length": 59,
        "distinct-1": 0.26260869565217393,
        "vocab_size-1": 453,
        "unique-1": 248,
        "entropy-1": 7.116775550081348,
        "distinct-2": 0.5350356294536817,
        "vocab_size-2": 901,
        "unique-2": 615,
        "entropy-2": 9.29089500691719,
        "cond_entropy-2": 2.1001826218798856,
        "distinct-3": 0.6975045648204504,
        "vocab_size-3": 1146,
        "unique-3": 889,
        "entropy-3": 9.90353748320311,
        "cond_entropy-3": 0.6334955445190169,
        "total_length-nopunct": 1534,
        "mean_pred_length-nopunct": 37.41463414634146,
        "std_pred_length-nopunct": 8.444873202288857,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.2920469361147327,
        "vocab_size-1-nopunct": 448,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.287318012789447,
        "distinct-2-nopunct": 0.5532484929671801,
        "vocab_size-2-nopunct": 826,
        "unique-2-nopunct": 567,
        "entropy-2-nopunct": 9.210617764443409,
        "cond_entropy-2-nopunct": 1.9886028933586375,
        "distinct-3-nopunct": 0.7128099173553719,
        "vocab_size-3-nopunct": 1035,
        "unique-3-nopunct": 816,
        "entropy-3-nopunct": 9.767786989321863,
        "cond_entropy-3-nopunct": 0.574281620648135,
        "msttr-100": 0.52824,
        "msttr-100_nopunct": 0.55,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.709877421754841,
        "rouge1": {
            "precision": 0.60701,
            "recall": 0.53155,
            "fmeasure": 0.56179
        },
        "rouge2": {
            "precision": 0.30637,
            "recall": 0.26859,
            "fmeasure": 0.28346
        },
        "rougeL": {
            "precision": 0.44337,
            "recall": 0.38578,
            "fmeasure": 0.40819
        },
        "rougeLsum": {
            "precision": 0.44337,
            "recall": 0.38578,
            "fmeasure": 0.40819
        },
        "local_recall": {
            "1": 0.19486404833836857,
            "2": 0.35459183673469385,
            "3": 0.6051454138702461
        },
        "bleu": 31.31259,
        "nubia": {
            "semantic_relation": 3.10399,
            "contradiction": 47.97214,
            "irrelevancy": 9.88715,
            "logical_agreement": 42.14071,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.18996,
            "nubia_score": 0.47961
        },
        "meteor": 0.25001050290702087,
        "bleurt": -0.38586,
        "bertscore": {
            "precision": 0.85544,
            "recall": 0.84441,
            "f1": 0.84868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 110,
        "total_length": 1751,
        "mean_pred_length": 15.918181818181818,
        "std_pred_length": 6.331927493672363,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.4591661907481439,
        "vocab_size-1": 804,
        "unique-1": 635,
        "entropy-1": 8.188575229229766,
        "distinct-2": 0.8452163315051797,
        "vocab_size-2": 1387,
        "unique-2": 1251,
        "entropy-2": 10.257485553848657,
        "cond_entropy-2": 1.7876447102528965,
        "distinct-3": 0.9464402351404311,
        "vocab_size-3": 1449,
        "unique-3": 1390,
        "entropy-3": 10.459877272578842,
        "cond_entropy-3": 0.20281094386540813,
        "total_length-nopunct": 1517,
        "mean_pred_length-nopunct": 13.790909090909091,
        "std_pred_length-nopunct": 5.582595444846998,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5240606460118655,
        "vocab_size-1-nopunct": 795,
        "unique-1-nopunct": 634,
        "entropy-1-nopunct": 8.490646180993666,
        "distinct-2-nopunct": 0.851457000710732,
        "vocab_size-2-nopunct": 1198,
        "unique-2-nopunct": 1088,
        "entropy-2-nopunct": 10.041713334112197,
        "cond_entropy-2-nopunct": 1.658080244779311,
        "distinct-3-nopunct": 0.9468003084040093,
        "vocab_size-3-nopunct": 1228,
        "unique-3-nopunct": 1178,
        "entropy-3-nopunct": 10.221615048354048,
        "cond_entropy-3-nopunct": 0.20463677453606433,
        "msttr-100": 0.71294,
        "msttr-100_nopunct": 0.76533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.406766188780257,
        "rouge1": {
            "precision": 0.74845,
            "recall": 0.69977,
            "fmeasure": 0.70661
        },
        "rouge2": {
            "precision": 0.51805,
            "recall": 0.48661,
            "fmeasure": 0.48965
        },
        "rougeL": {
            "precision": 0.65137,
            "recall": 0.60847,
            "fmeasure": 0.61463
        },
        "rougeLsum": {
            "precision": 0.65137,
            "recall": 0.60847,
            "fmeasure": 0.61463
        },
        "local_recall": {
            "1": 0.21164021164021163,
            "2": 0.5092838196286472,
            "3": 0.7415094339622641
        },
        "bleu": 44.95692,
        "nubia": {
            "semantic_relation": 4.06178,
            "contradiction": 12.40259,
            "irrelevancy": 26.01013,
            "logical_agreement": 61.58728,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.81241,
            "nubia_score": 0.68531
        },
        "meteor": 0.3751061903559049,
        "bleurt": 0.19736,
        "bertscore": {
            "precision": 0.92546,
            "recall": 0.91572,
            "f1": 0.91902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 64,
        "total_length": 1084,
        "mean_pred_length": 16.9375,
        "std_pred_length": 6.287077520597308,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.48154981549815495,
        "vocab_size-1": 522,
        "unique-1": 407,
        "entropy-1": 7.789385116775028,
        "distinct-2": 0.8862745098039215,
        "vocab_size-2": 904,
        "unique-2": 831,
        "entropy-2": 9.702047325137366,
        "cond_entropy-2": 1.680051317355746,
        "distinct-3": 0.9780334728033473,
        "vocab_size-3": 935,
        "unique-3": 914,
        "entropy-3": 9.856933753587516,
        "cond_entropy-3": 0.15353453634758107,
        "total_length-nopunct": 944,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 5.4715171570598224,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5476694915254238,
        "vocab_size-1-nopunct": 517,
        "unique-1-nopunct": 407,
        "entropy-1-nopunct": 8.054747372348363,
        "distinct-2-nopunct": 0.8977272727272727,
        "vocab_size-2-nopunct": 790,
        "unique-2-nopunct": 739,
        "entropy-2-nopunct": 9.505629646534336,
        "cond_entropy-2-nopunct": 1.5439601238812903,
        "distinct-3-nopunct": 0.9840686274509803,
        "vocab_size-3-nopunct": 803,
        "unique-3-nopunct": 790,
        "entropy-3-nopunct": 9.640562596873455,
        "cond_entropy-3-nopunct": 0.15022314554241556,
        "msttr-100": 0.703,
        "msttr-100_nopunct": 0.75667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.872963090780664,
        "rouge1": {
            "precision": 0.7496,
            "recall": 0.69968,
            "fmeasure": 0.71304
        },
        "rouge2": {
            "precision": 0.49019,
            "recall": 0.46254,
            "fmeasure": 0.46957
        },
        "rougeL": {
            "precision": 0.62794,
            "recall": 0.58841,
            "fmeasure": 0.59823
        },
        "rougeLsum": {
            "precision": 0.62794,
            "recall": 0.58841,
            "fmeasure": 0.59823
        },
        "local_recall": {
            "1": 0.20512820512820512,
            "2": 0.46255506607929514,
            "3": 0.7216783216783217
        },
        "bleu": 40.3112,
        "nubia": {
            "semantic_relation": 4.10388,
            "contradiction": 11.7049,
            "irrelevancy": 30.18635,
            "logical_agreement": 58.10875,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.61036,
            "nubia_score": 0.70466
        },
        "meteor": 0.3679614755902185,
        "bleurt": 0.22399,
        "bertscore": {
            "precision": 0.92677,
            "recall": 0.91219,
            "f1": 0.91741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2631600271133965,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.71429,
            "fmeasure": 0.64516
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.38462,
            "fmeasure": 0.34483
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.68519,
            "fmeasure": 0.50951
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.68519,
            "fmeasure": 0.50951
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.75
        },
        "bleu": 19.92341,
        "nubia": {
            "semantic_relation": 3.48026,
            "contradiction": 0.16341,
            "irrelevancy": 99.74775,
            "logical_agreement": 0.08884,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.04541,
            "nubia_score": 0.57999
        },
        "meteor": 0.31636376416252177,
        "bleurt": -0.09441,
        "bertscore": {
            "precision": 0.81113,
            "recall": 0.92566,
            "f1": 0.86462
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 5421,
        "mean_pred_length": 15.100278551532034,
        "std_pred_length": 7.214653529390721,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.3905183545471315,
        "vocab_size-1": 2117,
        "unique-1": 1609,
        "entropy-1": 8.918299839803002,
        "distinct-2": 0.8502568154879494,
        "vocab_size-2": 4304,
        "unique-2": 3985,
        "entropy-2": 11.83028820387603,
        "cond_entropy-2": 2.553966216724296,
        "distinct-3": 0.97086965766532,
        "vocab_size-3": 4566,
        "unique-3": 4483,
        "entropy-3": 12.12394073106941,
        "cond_entropy-3": 0.3137065088325672,
        "total_length-nopunct": 4818,
        "mean_pred_length-nopunct": 13.420612813370473,
        "std_pred_length-nopunct": 6.365708853429638,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.43773349937733497,
        "vocab_size-1-nopunct": 2109,
        "unique-1-nopunct": 1608,
        "entropy-1-nopunct": 9.277464900708212,
        "distinct-2-nopunct": 0.8618524332810047,
        "vocab_size-2-nopunct": 3843,
        "unique-2-nopunct": 3584,
        "entropy-2-nopunct": 11.680964358262965,
        "cond_entropy-2-nopunct": 2.5788339276196885,
        "distinct-3-nopunct": 0.978780487804878,
        "vocab_size-3-nopunct": 4013,
        "unique-3-nopunct": 3950,
        "entropy-3-nopunct": 11.953703810237416,
        "cond_entropy-3-nopunct": 0.30145109295738054,
        "msttr-100": 0.71759,
        "msttr-100_nopunct": 0.76708,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "nist": 7.461240446525202,
        "rouge1": {
            "precision": 0.68888,
            "recall": 0.58439,
            "fmeasure": 0.61449
        },
        "rouge2": {
            "precision": 0.44582,
            "recall": 0.38371,
            "fmeasure": 0.39699
        },
        "rougeL": {
            "precision": 0.63035,
            "recall": 0.54598,
            "fmeasure": 0.56746
        },
        "rougeLsum": {
            "precision": 0.63035,
            "recall": 0.54598,
            "fmeasure": 0.56746
        },
        "local_recall": {
            "1": 0.04463768115942029,
            "2": 0.1092032967032967,
            "3": 0.1910902696365768,
            "4": 0.2577903682719547,
            "5": 0.34130146082337315,
            "6": 0.39655172413793105,
            "7": 0.4554794520547945,
            "8": 0.5714285714285714,
            "9": 0.7043165467625899
        },
        "bleu": 40.29607,
        "sari": 42.67662,
        "nubia": {
            "semantic_relation": 3.3266,
            "contradiction": 12.29934,
            "irrelevancy": 30.36819,
            "logical_agreement": 57.33248,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.36221,
            "nubia_score": 0.42736
        },
        "meteor": 0.3126926690159479,
        "bleurt": -0.22095,
        "bertscore": {
            "precision": 0.90731,
            "recall": 0.88778,
            "f1": 0.89289
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6252,
        "mean_pred_length": 12.504,
        "std_pred_length": 6.986986761115266,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 42,
        "distinct-1": 0.145233525271913,
        "vocab_size-1": 908,
        "unique-1": 520,
        "entropy-1": 7.648455826655002,
        "distinct-2": 0.41220445062586925,
        "vocab_size-2": 2371,
        "unique-2": 1547,
        "entropy-2": 10.251331533323555,
        "cond_entropy-2": 2.3534096811885443,
        "distinct-3": 0.6001523229246002,
        "vocab_size-3": 3152,
        "unique-3": 2419,
        "entropy-3": 11.006436655342117,
        "cond_entropy-3": 0.7786307871173747,
        "total_length-nopunct": 5473,
        "mean_pred_length-nopunct": 10.946,
        "std_pred_length-nopunct": 6.416781436203045,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.1635300566416956,
        "vocab_size-1-nopunct": 895,
        "unique-1-nopunct": 516,
        "entropy-1-nopunct": 7.819360108351991,
        "distinct-2-nopunct": 0.4285139754675246,
        "vocab_size-2-nopunct": 2131,
        "unique-2-nopunct": 1429,
        "entropy-2-nopunct": 10.088635907485513,
        "cond_entropy-2-nopunct": 2.4101830747487565,
        "distinct-3-nopunct": 0.6181533646322379,
        "vocab_size-3-nopunct": 2765,
        "unique-3-nopunct": 2170,
        "entropy-3-nopunct": 10.817548356092818,
        "cond_entropy-3-nopunct": 0.7694223657746394,
        "msttr-100": 0.66081,
        "msttr-100_nopunct": 0.69074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.216044352718836,
        "rouge1": {
            "precision": 0.58514,
            "recall": 0.57001,
            "fmeasure": 0.56487
        },
        "rouge2": {
            "precision": 0.36708,
            "recall": 0.35841,
            "fmeasure": 0.35406
        },
        "rougeL": {
            "precision": 0.53352,
            "recall": 0.51897,
            "fmeasure": 0.51499
        },
        "rougeLsum": {
            "precision": 0.53352,
            "recall": 0.51897,
            "fmeasure": 0.51499
        },
        "local_recall": {
            "1": 0.5816023738872403
        },
        "bleu": 34.16291,
        "nubia": {
            "semantic_relation": 3.65391,
            "contradiction": 8.40418,
            "irrelevancy": 20.35488,
            "logical_agreement": 71.24094,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.43234,
            "nubia_score": 0.66533
        },
        "meteor": 0.32615892994619017,
        "bleurt": -0.02193,
        "bertscore": {
            "precision": 0.87799,
            "recall": 0.87228,
            "f1": 0.87461
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 305,
        "total_length": 9978,
        "mean_pred_length": 32.71475409836066,
        "std_pred_length": 8.108320682101484,
        "median_pred_length": 32.0,
        "min_pred_length": 15,
        "max_pred_length": 76,
        "distinct-1": 0.12607737021447185,
        "vocab_size-1": 1258,
        "unique-1": 505,
        "entropy-1": 7.722057940615395,
        "distinct-2": 0.35077018505117336,
        "vocab_size-2": 3393,
        "unique-2": 1913,
        "entropy-2": 10.73039803987731,
        "cond_entropy-2": 2.8956318598229163,
        "distinct-3": 0.5431255337318531,
        "vocab_size-3": 5088,
        "unique-3": 3499,
        "entropy-3": 11.799440564810872,
        "cond_entropy-3": 1.1073855443544143,
        "total_length-nopunct": 8795,
        "mean_pred_length-nopunct": 28.83606557377049,
        "std_pred_length-nopunct": 7.537404710256169,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.1418988061398522,
        "vocab_size-1-nopunct": 1248,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.979497875700665,
        "distinct-2-nopunct": 0.36925795053003535,
        "vocab_size-2-nopunct": 3135,
        "unique-2-nopunct": 1837,
        "entropy-2-nopunct": 10.657907060142406,
        "cond_entropy-2-nopunct": 2.782997945305912,
        "distinct-3-nopunct": 0.5609040928527794,
        "vocab_size-3-nopunct": 4591,
        "unique-3-nopunct": 3261,
        "entropy-3-nopunct": 11.660443387492151,
        "cond_entropy-3-nopunct": 1.0410852383588736,
        "msttr-100": 0.60182,
        "msttr-100_nopunct": 0.63977,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.450778051732032,
        "rouge1": {
            "precision": 0.59749,
            "recall": 0.62115,
            "fmeasure": 0.60161
        },
        "rouge2": {
            "precision": 0.33702,
            "recall": 0.34904,
            "fmeasure": 0.33869
        },
        "rougeL": {
            "precision": 0.45336,
            "recall": 0.47646,
            "fmeasure": 0.45851
        },
        "rougeLsum": {
            "precision": 0.45336,
            "recall": 0.47646,
            "fmeasure": 0.45851
        },
        "local_recall": {
            "1": 0.2076105204252938,
            "2": 0.530713640469738,
            "3": 0.6984761428928303
        },
        "bleu": 33.22019,
        "nubia": {
            "semantic_relation": 3.44136,
            "contradiction": 41.94715,
            "irrelevancy": 11.68235,
            "logical_agreement": 46.3705,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.3592,
            "nubia_score": 0.54124
        },
        "meteor": 0.2980653542618317,
        "bleurt": -0.25979,
        "bertscore": {
            "precision": 0.86563,
            "recall": 0.86954,
            "f1": 0.86653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 146,
        "mean_pred_length": 12.166666666666666,
        "std_pred_length": 4.758034141206733,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6643835616438356,
        "vocab_size-1": 97,
        "unique-1": 80,
        "entropy-1": 6.1510321361927245,
        "distinct-2": 0.9776119402985075,
        "vocab_size-2": 131,
        "unique-2": 128,
        "entropy-2": 7.021313071054795,
        "cond_entropy-2": 0.631924460642323,
        "distinct-3": 1.0,
        "vocab_size-3": 122,
        "unique-3": 122,
        "entropy-3": 6.930737337562902,
        "cond_entropy-3": -0.08617152502603381,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 4.149966532662911,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.734375,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.253453301746008,
        "distinct-2-nopunct": 0.9741379310344828,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.806256857196522,
        "cond_entropy-2-nopunct": 0.5955497656147352,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.7004397181411,
        "cond_entropy-3-nopunct": -0.09984896929417227,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.272908062229486,
        "rouge1": {
            "precision": 0.76892,
            "recall": 0.72566,
            "fmeasure": 0.73738
        },
        "rouge2": {
            "precision": 0.52883,
            "recall": 0.48203,
            "fmeasure": 0.49629
        },
        "rougeL": {
            "precision": 0.65773,
            "recall": 0.62535,
            "fmeasure": 0.63299
        },
        "rougeLsum": {
            "precision": 0.65773,
            "recall": 0.62535,
            "fmeasure": 0.63299
        },
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.6071428571428571,
            "3": 0.7391304347826086
        },
        "bleu": 40.55689,
        "nubia": {
            "semantic_relation": 4.21906,
            "contradiction": 14.10639,
            "irrelevancy": 12.43813,
            "logical_agreement": 73.45548,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.52147,
            "nubia_score": 0.72381
        },
        "meteor": 0.38186016132109296,
        "bleurt": 0.23622,
        "bertscore": {
            "precision": 0.91532,
            "recall": 0.91701,
            "f1": 0.91399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.685638950147956,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.87729,
            "fmeasure": 0.8545
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.59829,
            "fmeasure": 0.58051
        },
        "rougeL": {
            "precision": 0.54762,
            "recall": 0.57692,
            "fmeasure": 0.56173
        },
        "rougeLsum": {
            "precision": 0.54762,
            "recall": 0.57692,
            "fmeasure": 0.56173
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 38.60974,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23138,
            "irrelevancy": 0.44913,
            "logical_agreement": 99.31949,
            "grammar_ref": 5.12321,
            "grammar_hyp": 4.16617,
            "nubia_score": 1.0
        },
        "meteor": 0.4810476258322474,
        "bleurt": 0.58643,
        "bertscore": {
            "precision": 0.9486,
            "recall": 0.96263,
            "f1": 0.95556
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 150,
        "total_length": 2466,
        "mean_pred_length": 16.44,
        "std_pred_length": 6.527357811549786,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 58,
        "distinct-1": 0.42497972424979724,
        "vocab_size-1": 1048,
        "unique-1": 831,
        "entropy-1": 8.344981977363203,
        "distinct-2": 0.7897236614853195,
        "vocab_size-2": 1829,
        "unique-2": 1625,
        "entropy-2": 10.53420197031059,
        "cond_entropy-2": 1.9129700767153017,
        "distinct-3": 0.9182825484764543,
        "vocab_size-3": 1989,
        "unique-3": 1888,
        "entropy-3": 10.877647796788917,
        "cond_entropy-3": 0.336845744877261,
        "total_length-nopunct": 2128,
        "mean_pred_length-nopunct": 14.186666666666667,
        "std_pred_length-nopunct": 5.874676350423249,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.4891917293233083,
        "vocab_size-1-nopunct": 1041,
        "unique-1-nopunct": 829,
        "entropy-1-nopunct": 8.703674801175685,
        "distinct-2-nopunct": 0.8164812942366027,
        "vocab_size-2-nopunct": 1615,
        "unique-2-nopunct": 1470,
        "entropy-2-nopunct": 10.37411753966491,
        "cond_entropy-2-nopunct": 1.7716686989392993,
        "distinct-3-nopunct": 0.937636761487965,
        "vocab_size-3-nopunct": 1714,
        "unique-3-nopunct": 1648,
        "entropy-3-nopunct": 10.680606025760477,
        "cond_entropy-3-nopunct": 0.33334390904822486,
        "msttr-100": 0.69958,
        "msttr-100_nopunct": 0.75095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.19319288340866,
        "rouge1": {
            "precision": 0.83266,
            "recall": 0.77052,
            "fmeasure": 0.79104
        },
        "rouge2": {
            "precision": 0.61323,
            "recall": 0.57285,
            "fmeasure": 0.58493
        },
        "rougeL": {
            "precision": 0.72276,
            "recall": 0.67061,
            "fmeasure": 0.68778
        },
        "rougeLsum": {
            "precision": 0.72276,
            "recall": 0.67061,
            "fmeasure": 0.68778
        },
        "local_recall": {
            "1": 0.17738359201773837,
            "2": 0.41081081081081083,
            "3": 0.7903780068728522
        },
        "bleu": 48.68048,
        "nubia": {
            "semantic_relation": 4.42541,
            "contradiction": 8.27586,
            "irrelevancy": 21.69759,
            "logical_agreement": 70.02655,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.25541,
            "nubia_score": 0.76416
        },
        "meteor": 0.4074429503069803,
        "bleurt": 0.36791,
        "bertscore": {
            "precision": 0.94813,
            "recall": 0.94204,
            "f1": 0.94394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 123,
        "total_length": 1966,
        "mean_pred_length": 15.983739837398375,
        "std_pred_length": 7.7249292783222065,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.36826042726347913,
        "vocab_size-1": 724,
        "unique-1": 587,
        "entropy-1": 7.515167195359868,
        "distinct-2": 0.6814975583288118,
        "vocab_size-2": 1256,
        "unique-2": 1128,
        "entropy-2": 9.548319722101537,
        "cond_entropy-2": 1.798455840031767,
        "distinct-3": 0.7883720930232558,
        "vocab_size-3": 1356,
        "unique-3": 1283,
        "entropy-3": 9.88687759347692,
        "cond_entropy-3": 0.3925969323835151,
        "total_length-nopunct": 1693,
        "mean_pred_length-nopunct": 13.764227642276422,
        "std_pred_length-nopunct": 6.388609402250263,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4240992321323095,
        "vocab_size-1-nopunct": 718,
        "unique-1-nopunct": 587,
        "entropy-1-nopunct": 7.775591876338523,
        "distinct-2-nopunct": 0.6936305732484076,
        "vocab_size-2-nopunct": 1089,
        "unique-2-nopunct": 990,
        "entropy-2-nopunct": 9.345722576852491,
        "cond_entropy-2-nopunct": 1.7254331070980784,
        "distinct-3-nopunct": 0.7947477539737388,
        "vocab_size-3-nopunct": 1150,
        "unique-3-nopunct": 1093,
        "entropy-3-nopunct": 9.6556024698357,
        "cond_entropy-3-nopunct": 0.4058037739974201,
        "msttr-100": 0.61947,
        "msttr-100_nopunct": 0.66,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.8847134103682714,
        "rouge1": {
            "precision": 0.78158,
            "recall": 0.76041,
            "fmeasure": 0.75946
        },
        "rouge2": {
            "precision": 0.57468,
            "recall": 0.56256,
            "fmeasure": 0.56021
        },
        "rougeL": {
            "precision": 0.69216,
            "recall": 0.66981,
            "fmeasure": 0.67055
        },
        "rougeLsum": {
            "precision": 0.69216,
            "recall": 0.66981,
            "fmeasure": 0.67055
        },
        "local_recall": {
            "1": 0.254416961130742,
            "2": 0.4080267558528428,
            "3": 0.7882986913010007
        },
        "bleu": 56.30587,
        "nubia": {
            "semantic_relation": 4.25957,
            "contradiction": 11.78714,
            "irrelevancy": 22.7833,
            "logical_agreement": 65.42956,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.66273,
            "nubia_score": 0.75506
        },
        "meteor": 0.4203934887842928,
        "bleurt": 0.38337,
        "bertscore": {
            "precision": 0.93595,
            "recall": 0.92985,
            "f1": 0.93145
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 79,
        "total_length": 3583,
        "mean_pred_length": 45.35443037974684,
        "std_pred_length": 10.274754577972075,
        "median_pred_length": 44.0,
        "min_pred_length": 20,
        "max_pred_length": 69,
        "distinct-1": 0.16829472509070612,
        "vocab_size-1": 603,
        "unique-1": 259,
        "entropy-1": 7.417141220365638,
        "distinct-2": 0.3698630136986301,
        "vocab_size-2": 1296,
        "unique-2": 715,
        "entropy-2": 9.671509757112885,
        "cond_entropy-2": 2.1821178816464286,
        "distinct-3": 0.501021897810219,
        "vocab_size-3": 1716,
        "unique-3": 1098,
        "entropy-3": 10.29147927268291,
        "cond_entropy-3": 0.6406102665318046,
        "total_length-nopunct": 3165,
        "mean_pred_length-nopunct": 40.063291139240505,
        "std_pred_length-nopunct": 9.397470400479916,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.1883096366508689,
        "vocab_size-1-nopunct": 596,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 7.647208500337796,
        "distinct-2-nopunct": 0.38950097213220997,
        "vocab_size-2-nopunct": 1202,
        "unique-2-nopunct": 679,
        "entropy-2-nopunct": 9.604911380456704,
        "cond_entropy-2-nopunct": 2.0124253342704352,
        "distinct-3-nopunct": 0.5197871632856668,
        "vocab_size-3-nopunct": 1563,
        "unique-3-nopunct": 1033,
        "entropy-3-nopunct": 10.162838878541974,
        "cond_entropy-3-nopunct": 0.5727479018208707,
        "msttr-100": 0.62257,
        "msttr-100_nopunct": 0.66161,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.746706236865109,
        "rouge1": {
            "precision": 0.68893,
            "recall": 0.59241,
            "fmeasure": 0.63258
        },
        "rouge2": {
            "precision": 0.40106,
            "recall": 0.34303,
            "fmeasure": 0.36673
        },
        "rougeL": {
            "precision": 0.48557,
            "recall": 0.41821,
            "fmeasure": 0.44565
        },
        "rougeLsum": {
            "precision": 0.48557,
            "recall": 0.41821,
            "fmeasure": 0.44565
        },
        "local_recall": {
            "1": 0.24579831932773108,
            "2": 0.4108322324966975,
            "3": 0.710691823899371
        },
        "bleu": 40.74997,
        "nubia": {
            "semantic_relation": 3.45955,
            "contradiction": 26.38563,
            "irrelevancy": 7.47433,
            "logical_agreement": 66.14004,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.04318,
            "nubia_score": 0.58872
        },
        "meteor": 0.2995011294949707,
        "bleurt": -0.24439,
        "bertscore": {
            "precision": 0.88715,
            "recall": 0.86887,
            "f1": 0.87696
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 297,
        "total_length": 3321,
        "mean_pred_length": 11.181818181818182,
        "std_pred_length": 3.7453368619346366,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.2237277928334839,
        "vocab_size-1": 743,
        "unique-1": 425,
        "entropy-1": 7.067691988590295,
        "distinct-2": 0.5304232804232805,
        "vocab_size-2": 1604,
        "unique-2": 1132,
        "entropy-2": 9.95311746254964,
        "cond_entropy-2": 2.5324146863868933,
        "distinct-3": 0.7213054638797213,
        "vocab_size-3": 1967,
        "unique-3": 1595,
        "entropy-3": 10.635938047136648,
        "cond_entropy-3": 0.7858123479695951,
        "total_length-nopunct": 2892,
        "mean_pred_length-nopunct": 9.737373737373737,
        "std_pred_length-nopunct": 3.2116764827761446,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2551867219917012,
        "vocab_size-1-nopunct": 738,
        "unique-1-nopunct": 425,
        "entropy-1-nopunct": 7.3260526121909635,
        "distinct-2-nopunct": 0.5148362235067437,
        "vocab_size-2-nopunct": 1336,
        "unique-2-nopunct": 923,
        "entropy-2-nopunct": 9.676614951457115,
        "cond_entropy-2-nopunct": 2.6783332054015103,
        "distinct-3-nopunct": 0.7084421235857267,
        "vocab_size-3-nopunct": 1628,
        "unique-3-nopunct": 1307,
        "entropy-3-nopunct": 10.353705868599436,
        "cond_entropy-3-nopunct": 0.8352262244305915,
        "msttr-100": 0.57212,
        "msttr-100_nopunct": 0.62393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.332043165698607,
        "rouge1": {
            "precision": 0.65122,
            "recall": 0.67393,
            "fmeasure": 0.65335
        },
        "rouge2": {
            "precision": 0.41149,
            "recall": 0.42158,
            "fmeasure": 0.41003
        },
        "rougeL": {
            "precision": 0.58417,
            "recall": 0.60537,
            "fmeasure": 0.586
        },
        "rougeLsum": {
            "precision": 0.58417,
            "recall": 0.60537,
            "fmeasure": 0.586
        },
        "local_recall": {
            "1": 0.2503419972640219,
            "2": 0.6176165803108808,
            "3": 0.6661002548853017,
            "4": 0.9736842105263158
        },
        "bleu": 36.59494,
        "nubia": {
            "semantic_relation": 3.6073,
            "contradiction": 38.36818,
            "irrelevancy": 8.50085,
            "logical_agreement": 53.13097,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.38323,
            "nubia_score": 0.52634
        },
        "meteor": 0.34727534439385443,
        "bleurt": -0.08769,
        "bertscore": {
            "precision": 0.8962,
            "recall": 0.90355,
            "f1": 0.89877
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1779,
        "total_length": 45872,
        "mean_pred_length": 25.785272625070263,
        "std_pred_length": 12.606911524251807,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 89,
        "distinct-1": 0.0511859086152773,
        "vocab_size-1": 2348,
        "unique-1": 803,
        "entropy-1": 7.896161892969649,
        "distinct-2": 0.17574218129861882,
        "vocab_size-2": 7749,
        "unique-2": 3750,
        "entropy-2": 11.247237941741062,
        "cond_entropy-2": 3.1973922554867644,
        "distinct-3": 0.3216193222101432,
        "vocab_size-3": 13609,
        "unique-3": 8093,
        "entropy-3": 12.612203355815227,
        "cond_entropy-3": 1.4337572213104088,
        "total_length-nopunct": 40368,
        "mean_pred_length-nopunct": 22.69139966273187,
        "std_pred_length-nopunct": 11.308877618630621,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.05791716210860087,
        "vocab_size-1-nopunct": 2338,
        "unique-1-nopunct": 802,
        "entropy-1-nopunct": 8.193117140278106,
        "distinct-2-nopunct": 0.19041695820052346,
        "vocab_size-2-nopunct": 7348,
        "unique-2-nopunct": 3760,
        "entropy-2-nopunct": 11.177143571556918,
        "cond_entropy-2-nopunct": 3.1344047467313723,
        "distinct-3-nopunct": 0.33928280358598206,
        "vocab_size-3-nopunct": 12489,
        "unique-3-nopunct": 7733,
        "entropy-3-nopunct": 12.488457240139544,
        "cond_entropy-3-nopunct": 1.3870724948708284,
        "msttr-100": 0.60891,
        "msttr-100_nopunct": 0.65166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.005879411750232,
        "rouge1": {
            "precision": 0.6205,
            "recall": 0.62773,
            "fmeasure": 0.61621
        },
        "rouge2": {
            "precision": 0.36299,
            "recall": 0.36564,
            "fmeasure": 0.35935
        },
        "rougeL": {
            "precision": 0.49471,
            "recall": 0.50464,
            "fmeasure": 0.49282
        },
        "rougeLsum": {
            "precision": 0.49471,
            "recall": 0.50464,
            "fmeasure": 0.49282
        },
        "local_recall": {
            "1": 0.21785529864019737,
            "2": 0.5255899776633971,
            "3": 0.6897948717948718,
            "4": 0.8909090909090909,
            "5": 0.4827586206896552
        },
        "bleu": 35.24931,
        "nubia": {
            "semantic_relation": 3.48208,
            "contradiction": 39.58916,
            "irrelevancy": 10.62574,
            "logical_agreement": 49.7851,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.69029,
            "nubia_score": 0.53801
        },
        "meteor": 0.3042561911949249,
        "bleurt": -0.23683,
        "bertscore": {
            "precision": 0.87387,
            "recall": 0.87696,
            "f1": 0.87424
        }
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 54,
        "total_length": 860,
        "mean_pred_length": 15.925925925925926,
        "std_pred_length": 6.548541969052269,
        "median_pred_length": 14.5,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.5151162790697674,
        "vocab_size-1": 443,
        "unique-1": 348,
        "entropy-1": 7.772681656865773,
        "distinct-2": 0.8796526054590571,
        "vocab_size-2": 709,
        "unique-2": 649,
        "entropy-2": 9.355207585645337,
        "cond_entropy-2": 1.327543521678688,
        "distinct-3": 0.9654255319148937,
        "vocab_size-3": 726,
        "unique-3": 703,
        "entropy-3": 9.48242839621694,
        "cond_entropy-3": 0.13010529982116686,
        "total_length-nopunct": 758,
        "mean_pred_length-nopunct": 14.037037037037036,
        "std_pred_length-nopunct": 5.922221064090869,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5738786279683378,
        "vocab_size-1-nopunct": 435,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 7.990196735321939,
        "distinct-2-nopunct": 0.8863636363636364,
        "vocab_size-2-nopunct": 624,
        "unique-2-nopunct": 579,
        "entropy-2-nopunct": 9.168970578877138,
        "cond_entropy-2-nopunct": 1.2463914758802919,
        "distinct-3-nopunct": 0.9676923076923077,
        "vocab_size-3-nopunct": 629,
        "unique-3-nopunct": 610,
        "entropy-3-nopunct": 9.277357792524622,
        "cond_entropy-3-nopunct": 0.12302563079453852,
        "msttr-100": 0.75125,
        "msttr-100_nopunct": 0.80286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.760740444370615,
        "rouge1": {
            "precision": 0.78276,
            "recall": 0.7031,
            "fmeasure": 0.72733
        },
        "rouge2": {
            "precision": 0.54496,
            "recall": 0.50469,
            "fmeasure": 0.51333
        },
        "rougeL": {
            "precision": 0.68398,
            "recall": 0.62468,
            "fmeasure": 0.63968
        },
        "rougeLsum": {
            "precision": 0.68398,
            "recall": 0.62468,
            "fmeasure": 0.63968
        },
        "local_recall": {
            "1": 0.22346368715083798,
            "2": 0.3657142857142857,
            "3": 0.7225806451612903
        },
        "bleu": 43.84258,
        "nubia": {
            "semantic_relation": 4.17526,
            "contradiction": 9.0371,
            "irrelevancy": 26.7255,
            "logical_agreement": 64.2374,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.65061,
            "nubia_score": 0.72576
        },
        "meteor": 0.38105337307995313,
        "bleurt": 0.23212,
        "bertscore": {
            "precision": 0.9322,
            "recall": 0.92075,
            "f1": 0.92531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 80,
        "total_length": 1318,
        "mean_pred_length": 16.475,
        "std_pred_length": 7.813409947007772,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.4954476479514416,
        "vocab_size-1": 653,
        "unique-1": 527,
        "entropy-1": 8.028842386354594,
        "distinct-2": 0.8852988691437803,
        "vocab_size-2": 1096,
        "unique-2": 1009,
        "entropy-2": 9.978675839731192,
        "cond_entropy-2": 1.6910575093225038,
        "distinct-3": 0.9697754749568221,
        "vocab_size-3": 1123,
        "unique-3": 1092,
        "entropy-3": 10.113939594116948,
        "cond_entropy-3": 0.13297093767785254,
        "total_length-nopunct": 1127,
        "mean_pred_length-nopunct": 14.0875,
        "std_pred_length-nopunct": 6.616633868516528,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5732031943212067,
        "vocab_size-1-nopunct": 646,
        "unique-1-nopunct": 526,
        "entropy-1-nopunct": 8.357434137889394,
        "distinct-2-nopunct": 0.9054441260744985,
        "vocab_size-2-nopunct": 948,
        "unique-2-nopunct": 889,
        "entropy-2-nopunct": 9.780294222891225,
        "cond_entropy-2-nopunct": 1.512363902938528,
        "distinct-3-nopunct": 0.9751809720785936,
        "vocab_size-3-nopunct": 943,
        "unique-3-nopunct": 920,
        "entropy-3-nopunct": 9.866953374717573,
        "cond_entropy-3-nopunct": 0.10438419869636494,
        "msttr-100": 0.70923,
        "msttr-100_nopunct": 0.76455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.912313652928699,
        "rouge1": {
            "precision": 0.74187,
            "recall": 0.6749,
            "fmeasure": 0.69036
        },
        "rouge2": {
            "precision": 0.48187,
            "recall": 0.42669,
            "fmeasure": 0.4423
        },
        "rougeL": {
            "precision": 0.64291,
            "recall": 0.58,
            "fmeasure": 0.59571
        },
        "rougeLsum": {
            "precision": 0.64291,
            "recall": 0.58,
            "fmeasure": 0.59571
        },
        "local_recall": {
            "1": 0.2033898305084746,
            "2": 0.3286384976525822,
            "3": 0.7203107658157603
        },
        "bleu": 40.6592,
        "nubia": {
            "semantic_relation": 4.13661,
            "contradiction": 10.36957,
            "irrelevancy": 27.54782,
            "logical_agreement": 62.08261,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.84993,
            "nubia_score": 0.69583
        },
        "meteor": 0.36109928908669886,
        "bleurt": 0.21641,
        "bertscore": {
            "precision": 0.92289,
            "recall": 0.91059,
            "f1": 0.9148
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 72,
        "total_length": 995,
        "mean_pred_length": 13.819444444444445,
        "std_pred_length": 4.093783868015591,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.3236180904522613,
        "vocab_size-1": 322,
        "unique-1": 215,
        "entropy-1": 6.594350591536649,
        "distinct-2": 0.6511375947995667,
        "vocab_size-2": 601,
        "unique-2": 467,
        "entropy-2": 8.791237834647836,
        "cond_entropy-2": 1.9780226199439608,
        "distinct-3": 0.8061104582843713,
        "vocab_size-3": 686,
        "unique-3": 591,
        "entropy-3": 9.243912968222078,
        "cond_entropy-3": 0.5074258312961732,
        "total_length-nopunct": 863,
        "mean_pred_length-nopunct": 11.98611111111111,
        "std_pred_length-nopunct": 3.6533586356923204,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3650057937427578,
        "vocab_size-1-nopunct": 315,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 6.71150924764066,
        "distinct-2-nopunct": 0.6485461441213654,
        "vocab_size-2-nopunct": 513,
        "unique-2-nopunct": 396,
        "entropy-2-nopunct": 8.547320987824918,
        "cond_entropy-2-nopunct": 2.042933124646087,
        "distinct-3-nopunct": 0.7969401947148818,
        "vocab_size-3-nopunct": 573,
        "unique-3-nopunct": 487,
        "entropy-3-nopunct": 8.975607874535585,
        "cond_entropy-3-nopunct": 0.5201094751063978,
        "msttr-100": 0.58111,
        "msttr-100_nopunct": 0.61375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 3.7064976822625018,
        "rouge1": {
            "precision": 0.4813,
            "recall": 0.52234,
            "fmeasure": 0.49439
        },
        "rouge2": {
            "precision": 0.20247,
            "recall": 0.22065,
            "fmeasure": 0.20765
        },
        "rougeL": {
            "precision": 0.39519,
            "recall": 0.43159,
            "fmeasure": 0.407
        },
        "rougeLsum": {
            "precision": 0.39519,
            "recall": 0.43159,
            "fmeasure": 0.407
        },
        "local_recall": {
            "1": 0.26291079812206575,
            "2": 0.4444444444444444,
            "3": 0.5227963525835866
        },
        "bleu": 13.97935,
        "nubia": {
            "semantic_relation": 2.6104,
            "contradiction": 59.95916,
            "irrelevancy": 16.76958,
            "logical_agreement": 23.27126,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.54471,
            "nubia_score": 0.27494
        },
        "meteor": 0.23903410883038329,
        "bleurt": -0.70718,
        "bertscore": {
            "precision": 0.81929,
            "recall": 0.83283,
            "f1": 0.82477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 25,
        "total_length": 399,
        "mean_pred_length": 15.96,
        "std_pred_length": 5.414646802885669,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5764411027568922,
        "vocab_size-1": 230,
        "unique-1": 189,
        "entropy-1": 7.122620499489857,
        "distinct-2": 0.9171122994652406,
        "vocab_size-2": 343,
        "unique-2": 321,
        "entropy-2": 8.358046356991625,
        "cond_entropy-2": 1.0264531467369338,
        "distinct-3": 0.9770773638968482,
        "vocab_size-3": 341,
        "unique-3": 333,
        "entropy-3": 8.401237954003387,
        "cond_entropy-3": 0.05671939807872222,
        "total_length-nopunct": 342,
        "mean_pred_length-nopunct": 13.68,
        "std_pred_length-nopunct": 4.2494234903101855,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6549707602339181,
        "vocab_size-1-nopunct": 224,
        "unique-1-nopunct": 189,
        "entropy-1-nopunct": 7.285812121502712,
        "distinct-2-nopunct": 0.9211356466876972,
        "vocab_size-2-nopunct": 292,
        "unique-2-nopunct": 276,
        "entropy-2-nopunct": 8.123388902432541,
        "cond_entropy-2-nopunct": 0.9113752643334724,
        "distinct-3-nopunct": 0.9828767123287672,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 8.155577983537592,
        "cond_entropy-3-nopunct": 0.042595898543245386,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.378288051583526,
        "rouge1": {
            "precision": 0.76497,
            "recall": 0.69672,
            "fmeasure": 0.71789
        },
        "rouge2": {
            "precision": 0.53964,
            "recall": 0.49606,
            "fmeasure": 0.50705
        },
        "rougeL": {
            "precision": 0.65511,
            "recall": 0.60378,
            "fmeasure": 0.61863
        },
        "rougeLsum": {
            "precision": 0.65511,
            "recall": 0.60378,
            "fmeasure": 0.61863
        },
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.391304347826087,
            "3": 0.7420494699646644
        },
        "bleu": 44.55005,
        "nubia": {
            "semantic_relation": 3.9094,
            "contradiction": 15.51005,
            "irrelevancy": 27.14703,
            "logical_agreement": 57.34292,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.75206,
            "nubia_score": 0.64163
        },
        "meteor": 0.38623625028718167,
        "bleurt": 0.13503,
        "bertscore": {
            "precision": 0.92849,
            "recall": 0.91394,
            "f1": 0.92016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4182958340544896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.03462179117476819,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.052400307535792,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.61538,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.41667,
            "fmeasure": 0.41667
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.61538,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.61538,
            "fmeasure": 0.61538
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5384615384615384
        },
        "bleu": 20.74538,
        "nubia": {
            "semantic_relation": 4.39789,
            "contradiction": 14.14271,
            "irrelevancy": 5.34421,
            "logical_agreement": 80.51308,
            "grammar_ref": 3.82301,
            "grammar_hyp": 4.10969,
            "nubia_score": 0.78127
        },
        "meteor": 0.3536500174427911,
        "bleurt": 0.41571,
        "bertscore": {
            "precision": 0.95287,
            "recall": 0.89918,
            "f1": 0.92525
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 150,
        "total_length": 2347,
        "mean_pred_length": 15.646666666666667,
        "std_pred_length": 6.665469892579884,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.4077545803152961,
        "vocab_size-1": 957,
        "unique-1": 731,
        "entropy-1": 8.168786373343252,
        "distinct-2": 0.7924442421483842,
        "vocab_size-2": 1741,
        "unique-2": 1537,
        "entropy-2": 10.457369136511288,
        "cond_entropy-2": 2.0017596222494585,
        "distinct-3": 0.9291646311675623,
        "vocab_size-3": 1902,
        "unique-3": 1798,
        "entropy-3": 10.838018732170582,
        "cond_entropy-3": 0.3800530959816957,
        "total_length-nopunct": 2057,
        "mean_pred_length-nopunct": 13.713333333333333,
        "std_pred_length-nopunct": 5.7969378889969905,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4623237724842003,
        "vocab_size-1-nopunct": 951,
        "unique-1-nopunct": 730,
        "entropy-1-nopunct": 8.466009063014212,
        "distinct-2-nopunct": 0.8112218143681175,
        "vocab_size-2-nopunct": 1547,
        "unique-2-nopunct": 1394,
        "entropy-2-nopunct": 10.284120390317458,
        "cond_entropy-2-nopunct": 1.9242967781632894,
        "distinct-3-nopunct": 0.9396698918611269,
        "vocab_size-3-nopunct": 1651,
        "unique-3-nopunct": 1578,
        "entropy-3-nopunct": 10.639112484278401,
        "cond_entropy-3-nopunct": 0.3876146029626968,
        "msttr-100": 0.70435,
        "msttr-100_nopunct": 0.7515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.973795827873182,
        "rouge1": {
            "precision": 0.80388,
            "recall": 0.74294,
            "fmeasure": 0.76202
        },
        "rouge2": {
            "precision": 0.55545,
            "recall": 0.51512,
            "fmeasure": 0.52664
        },
        "rougeL": {
            "precision": 0.67416,
            "recall": 0.63156,
            "fmeasure": 0.64282
        },
        "rougeLsum": {
            "precision": 0.67416,
            "recall": 0.63156,
            "fmeasure": 0.64282
        },
        "local_recall": {
            "1": 0.1788793103448276,
            "2": 0.41081081081081083,
            "3": 0.7884267631103075
        },
        "bleu": 46.1857,
        "nubia": {
            "semantic_relation": 4.40273,
            "contradiction": 6.95859,
            "irrelevancy": 20.35971,
            "logical_agreement": 72.6817,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.88994,
            "nubia_score": 0.77684
        },
        "meteor": 0.4044409436207359,
        "bleurt": 0.33211,
        "bertscore": {
            "precision": 0.93878,
            "recall": 0.93274,
            "f1": 0.93447
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 10.03327796219494,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 38,
        "unique-1": 32,
        "entropy-1": 5.095175521464348,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 43,
        "unique-2": 41,
        "entropy-2": 5.402964207440784,
        "cond_entropy-2": 0.234776984545484,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.004297578312819156,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 8.640987597877148,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.0589840894454285,
        "distinct-2-nopunct": 0.9487179487179487,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.182838116298144,
        "cond_entropy-2-nopunct": 0.1494950524937447,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.004366106308824783,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0146235368434757,
        "rouge1": {
            "precision": 0.65785,
            "recall": 0.66746,
            "fmeasure": 0.65821
        },
        "rouge2": {
            "precision": 0.45869,
            "recall": 0.48589,
            "fmeasure": 0.46819
        },
        "rougeL": {
            "precision": 0.60847,
            "recall": 0.61984,
            "fmeasure": 0.60972
        },
        "rougeLsum": {
            "precision": 0.60847,
            "recall": 0.61984,
            "fmeasure": 0.60972
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.625
        },
        "bleu": 21.5,
        "nubia": {
            "semantic_relation": 3.9509,
            "contradiction": 17.93554,
            "irrelevancy": 18.76281,
            "logical_agreement": 63.30164,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.79577,
            "nubia_score": 0.63402
        },
        "meteor": 0.31310664222363593,
        "bleurt": 0.08379,
        "bertscore": {
            "precision": 0.91301,
            "recall": 0.91663,
            "f1": 0.91454
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 29,
        "total_length": 529,
        "mean_pred_length": 18.24137931034483,
        "std_pred_length": 9.456452540420594,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.30245746691871456,
        "vocab_size-1": 160,
        "unique-1": 116,
        "entropy-1": 5.907783071174767,
        "distinct-2": 0.532,
        "vocab_size-2": 266,
        "unique-2": 215,
        "entropy-2": 7.1791456792567905,
        "cond_entropy-2": 1.1716814791391297,
        "distinct-3": 0.6263269639065817,
        "vocab_size-3": 295,
        "unique-3": 254,
        "entropy-3": 7.501620655743686,
        "cond_entropy-3": 0.42398775686207774,
        "total_length-nopunct": 446,
        "mean_pred_length-nopunct": 15.379310344827585,
        "std_pred_length-nopunct": 7.2986243063850775,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.3452914798206278,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 5.892010101581007,
        "distinct-2-nopunct": 0.5179856115107914,
        "vocab_size-2-nopunct": 216,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 6.849949364948522,
        "cond_entropy-2-nopunct": 1.1244290369467471,
        "distinct-3-nopunct": 0.6211340206185567,
        "vocab_size-3-nopunct": 241,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.20415286421086,
        "cond_entropy-3-nopunct": 0.4850402828870443,
        "msttr-100": 0.5,
        "msttr-100_nopunct": 0.495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.049348915816448,
        "rouge1": {
            "precision": 0.85952,
            "recall": 0.85354,
            "fmeasure": 0.85144
        },
        "rouge2": {
            "precision": 0.71259,
            "recall": 0.70307,
            "fmeasure": 0.70413
        },
        "rougeL": {
            "precision": 0.79229,
            "recall": 0.7889,
            "fmeasure": 0.78695
        },
        "rougeLsum": {
            "precision": 0.79229,
            "recall": 0.7889,
            "fmeasure": 0.78695
        },
        "local_recall": {
            "1": 0.275,
            "2": 0.5087719298245614,
            "3": 0.8757396449704142
        },
        "bleu": 67.55083,
        "nubia": {
            "semantic_relation": 4.35835,
            "contradiction": 6.57533,
            "irrelevancy": 14.98926,
            "logical_agreement": 78.43542,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.34864,
            "nubia_score": 0.78821
        },
        "meteor": 0.44588505522957816,
        "bleurt": 0.43297,
        "bertscore": {
            "precision": 0.94636,
            "recall": 0.9452,
            "f1": 0.94362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 7.06320670013903,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6744186046511628,
        "vocab_size-1": 58,
        "unique-1": 49,
        "entropy-1": 5.504355306851584,
        "distinct-2": 0.8375,
        "vocab_size-2": 67,
        "unique-2": 62,
        "entropy-2": 5.90305590733327,
        "cond_entropy-2": 0.2739716215163945,
        "distinct-3": 0.8783783783783784,
        "vocab_size-3": 65,
        "unique-3": 61,
        "entropy-3": 5.9085795479736785,
        "cond_entropy-3": -0.06862185766602719,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 5.467073155618908,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7567567567567568,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.557228196622326,
        "distinct-2-nopunct": 0.8529411764705882,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.712319091186712,
        "cond_entropy-2-nopunct": 0.09499311535908783,
        "distinct-3-nopunct": 0.9032258064516129,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.724121108669287,
        "cond_entropy-3-nopunct": -0.08092600670481048,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3847255630777555,
        "rouge1": {
            "precision": 0.88532,
            "recall": 0.8506,
            "fmeasure": 0.86368
        },
        "rouge2": {
            "precision": 0.78596,
            "recall": 0.76686,
            "fmeasure": 0.77401
        },
        "rougeL": {
            "precision": 0.81627,
            "recall": 0.80204,
            "fmeasure": 0.80684
        },
        "rougeLsum": {
            "precision": 0.81627,
            "recall": 0.80204,
            "fmeasure": 0.80684
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7297297297297297
        },
        "bleu": 50.27248,
        "nubia": {
            "semantic_relation": 4.44654,
            "contradiction": 13.16894,
            "irrelevancy": 13.03714,
            "logical_agreement": 73.79392,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.97014,
            "nubia_score": 0.77165
        },
        "meteor": 0.3922798146213589,
        "bleurt": 0.55394,
        "bertscore": {
            "precision": 0.95986,
            "recall": 0.94242,
            "f1": 0.95032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 114,
        "total_length": 1925,
        "mean_pred_length": 16.885964912280702,
        "std_pred_length": 7.2010705489809235,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.45246753246753246,
        "vocab_size-1": 871,
        "unique-1": 678,
        "entropy-1": 8.284056714754945,
        "distinct-2": 0.8442849254555495,
        "vocab_size-2": 1529,
        "unique-2": 1371,
        "entropy-2": 10.402345617912319,
        "cond_entropy-2": 1.851148774918819,
        "distinct-3": 0.9558043606364172,
        "vocab_size-3": 1622,
        "unique-3": 1557,
        "entropy-3": 10.634346081742498,
        "cond_entropy-3": 0.23459085822064635,
        "total_length-nopunct": 1686,
        "mean_pred_length-nopunct": 14.789473684210526,
        "std_pred_length-nopunct": 6.410618499610868,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5106761565836299,
        "vocab_size-1-nopunct": 861,
        "unique-1-nopunct": 674,
        "entropy-1-nopunct": 8.581747853964519,
        "distinct-2-nopunct": 0.8543256997455471,
        "vocab_size-2-nopunct": 1343,
        "unique-2-nopunct": 1221,
        "entropy-2-nopunct": 10.214865312206953,
        "cond_entropy-2-nopunct": 1.7275630899757535,
        "distinct-3-nopunct": 0.9602194787379973,
        "vocab_size-3-nopunct": 1400,
        "unique-3-nopunct": 1351,
        "entropy-3-nopunct": 10.423709199487977,
        "cond_entropy-3-nopunct": 0.23039144500755726,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.365228813779056,
        "rouge1": {
            "precision": 0.72692,
            "recall": 0.71431,
            "fmeasure": 0.70762
        },
        "rouge2": {
            "precision": 0.47821,
            "recall": 0.4717,
            "fmeasure": 0.46614
        },
        "rougeL": {
            "precision": 0.59924,
            "recall": 0.59671,
            "fmeasure": 0.58657
        },
        "rougeLsum": {
            "precision": 0.59924,
            "recall": 0.59671,
            "fmeasure": 0.58657
        },
        "local_recall": {
            "1": 0.24533333333333332,
            "2": 0.4876847290640394,
            "3": 0.7688219663418955
        },
        "bleu": 41.75923,
        "nubia": {
            "semantic_relation": 4.14308,
            "contradiction": 11.25049,
            "irrelevancy": 33.07676,
            "logical_agreement": 55.67275,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.79239,
            "nubia_score": 0.69797
        },
        "meteor": 0.37589112166863375,
        "bleurt": 0.21782,
        "bertscore": {
            "precision": 0.92135,
            "recall": 0.91707,
            "f1": 0.91777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 46,
        "mean_pred_length": 11.5,
        "std_pred_length": 7.22841614740048,
        "median_pred_length": 7.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.8043478260869565,
        "vocab_size-1": 37,
        "unique-1": 32,
        "entropy-1": 5.055958151615121,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.14279772872953175,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.09175833038780645,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 6.796138609534093,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8536585365853658,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.028045297195473,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.13594933410078325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.10445318566443552,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.926575126377659,
        "rouge1": {
            "precision": 0.7686,
            "recall": 0.70076,
            "fmeasure": 0.71556
        },
        "rouge2": {
            "precision": 0.52476,
            "recall": 0.42902,
            "fmeasure": 0.4624
        },
        "rougeL": {
            "precision": 0.73065,
            "recall": 0.66309,
            "fmeasure": 0.67655
        },
        "rougeLsum": {
            "precision": 0.73065,
            "recall": 0.66309,
            "fmeasure": 0.67655
        },
        "local_recall": {
            "1": 0.47368421052631576,
            "2": 0.6857142857142857,
            "3": 0.375
        },
        "bleu": 51.09836,
        "nubia": {
            "semantic_relation": 4.05652,
            "contradiction": 2.57115,
            "irrelevancy": 70.48699,
            "logical_agreement": 26.94186,
            "grammar_ref": 5.36601,
            "grammar_hyp": 5.43454,
            "nubia_score": 0.64288
        },
        "meteor": 0.39157752232087023,
        "bleurt": 0.15347,
        "bertscore": {
            "precision": 0.89951,
            "recall": 0.89668,
            "f1": 0.89513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 35,
        "total_length": 573,
        "mean_pred_length": 16.37142857142857,
        "std_pred_length": 6.047836516524917,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.49040139616055844,
        "vocab_size-1": 281,
        "unique-1": 203,
        "entropy-1": 7.168723743966932,
        "distinct-2": 0.8568773234200744,
        "vocab_size-2": 461,
        "unique-2": 413,
        "entropy-2": 8.715100328331939,
        "cond_entropy-2": 1.3397427375567863,
        "distinct-3": 0.9443339960238568,
        "vocab_size-3": 475,
        "unique-3": 455,
        "entropy-3": 8.84815261166568,
        "cond_entropy-3": 0.13646736026361725,
        "total_length-nopunct": 492,
        "mean_pred_length-nopunct": 14.057142857142857,
        "std_pred_length-nopunct": 5.666658663459734,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.556910569105691,
        "vocab_size-1-nopunct": 274,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 7.306829517312698,
        "distinct-2-nopunct": 0.8774617067833698,
        "vocab_size-2-nopunct": 401,
        "unique-2-nopunct": 368,
        "entropy-2-nopunct": 8.520485804929947,
        "cond_entropy-2-nopunct": 1.29317944732248,
        "distinct-3-nopunct": 0.9620853080568721,
        "vocab_size-3-nopunct": 406,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.638741635384507,
        "cond_entropy-3-nopunct": 0.13217723863716885,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.995242358638101,
        "rouge1": {
            "precision": 0.7721,
            "recall": 0.69098,
            "fmeasure": 0.71997
        },
        "rouge2": {
            "precision": 0.50377,
            "recall": 0.45574,
            "fmeasure": 0.47116
        },
        "rougeL": {
            "precision": 0.65851,
            "recall": 0.59827,
            "fmeasure": 0.61669
        },
        "rougeLsum": {
            "precision": 0.65851,
            "recall": 0.59827,
            "fmeasure": 0.61669
        },
        "local_recall": {
            "1": 0.1595744680851064,
            "2": 0.3893805309734513,
            "3": 0.7002518891687658
        },
        "bleu": 37.2229,
        "nubia": {
            "semantic_relation": 3.92609,
            "contradiction": 17.91079,
            "irrelevancy": 26.86072,
            "logical_agreement": 55.22849,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.63871,
            "nubia_score": 0.6381
        },
        "meteor": 0.3364926359201036,
        "bleurt": 0.14924,
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.90718,
            "f1": 0.91678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 47,
        "total_length": 736,
        "mean_pred_length": 15.659574468085106,
        "std_pred_length": 5.702842127357278,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5163043478260869,
        "vocab_size-1": 380,
        "unique-1": 302,
        "entropy-1": 7.449999783770462,
        "distinct-2": 0.8911465892597968,
        "vocab_size-2": 614,
        "unique-2": 566,
        "entropy-2": 9.152627198369286,
        "cond_entropy-2": 1.4651698617232134,
        "distinct-3": 0.9626168224299065,
        "vocab_size-3": 618,
        "unique-3": 598,
        "entropy-3": 9.245432602387027,
        "cond_entropy-3": 0.09429987410144051,
        "total_length-nopunct": 630,
        "mean_pred_length-nopunct": 13.404255319148936,
        "std_pred_length-nopunct": 4.747494633647758,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5904761904761905,
        "vocab_size-1-nopunct": 372,
        "unique-1-nopunct": 300,
        "entropy-1-nopunct": 7.650995732336266,
        "distinct-2-nopunct": 0.9039451114922813,
        "vocab_size-2-nopunct": 527,
        "unique-2-nopunct": 489,
        "entropy-2-nopunct": 8.943149022013065,
        "cond_entropy-2-nopunct": 1.4051567458407577,
        "distinct-3-nopunct": 0.9738805970149254,
        "vocab_size-3-nopunct": 522,
        "unique-3-nopunct": 508,
        "entropy-3-nopunct": 9.013850384487636,
        "cond_entropy-3-nopunct": 0.084652003157135,
        "msttr-100": 0.67857,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.227868307149041,
        "rouge1": {
            "precision": 0.77184,
            "recall": 0.6708,
            "fmeasure": 0.70935
        },
        "rouge2": {
            "precision": 0.52122,
            "recall": 0.45331,
            "fmeasure": 0.47976
        },
        "rougeL": {
            "precision": 0.66421,
            "recall": 0.58236,
            "fmeasure": 0.61336
        },
        "rougeLsum": {
            "precision": 0.66421,
            "recall": 0.58236,
            "fmeasure": 0.61336
        },
        "local_recall": {
            "1": 0.168141592920354,
            "2": 0.4647058823529412,
            "3": 0.7041666666666667
        },
        "bleu": 40.63274,
        "nubia": {
            "semantic_relation": 4.12705,
            "contradiction": 5.94678,
            "irrelevancy": 33.90505,
            "logical_agreement": 60.14817,
            "grammar_ref": 4.69178,
            "grammar_hyp": 5.00284,
            "nubia_score": 0.67424
        },
        "meteor": 0.35357021128204985,
        "bleurt": 0.18204,
        "bertscore": {
            "precision": 0.92544,
            "recall": 0.90669,
            "f1": 0.91436
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 150,
        "total_length": 2528,
        "mean_pred_length": 16.85333333333333,
        "std_pred_length": 6.708588193916478,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.41218354430379744,
        "vocab_size-1": 1042,
        "unique-1": 798,
        "entropy-1": 8.249897125435242,
        "distinct-2": 0.7964676198486123,
        "vocab_size-2": 1894,
        "unique-2": 1681,
        "entropy-2": 10.606018628959296,
        "cond_entropy-2": 2.0897900832630123,
        "distinct-3": 0.9313285457809695,
        "vocab_size-3": 2075,
        "unique-3": 1966,
        "entropy-3": 10.964356078393212,
        "cond_entropy-3": 0.3385489338600007,
        "total_length-nopunct": 2147,
        "mean_pred_length-nopunct": 14.313333333333333,
        "std_pred_length-nopunct": 5.348067148252929,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.480204937121565,
        "vocab_size-1-nopunct": 1031,
        "unique-1-nopunct": 797,
        "entropy-1-nopunct": 8.614544435851093,
        "distinct-2-nopunct": 0.8312468703054582,
        "vocab_size-2-nopunct": 1660,
        "unique-2-nopunct": 1511,
        "entropy-2-nopunct": 10.452502782976872,
        "cond_entropy-2-nopunct": 1.936459380080149,
        "distinct-3-nopunct": 0.9512723335138061,
        "vocab_size-3-nopunct": 1757,
        "unique-3-nopunct": 1686,
        "entropy-3-nopunct": 10.743760100918278,
        "cond_entropy-3-nopunct": 0.3198131179776824,
        "msttr-100": 0.6944,
        "msttr-100_nopunct": 0.75762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.281938619883178,
        "rouge1": {
            "precision": 0.82561,
            "recall": 0.76768,
            "fmeasure": 0.78994
        },
        "rouge2": {
            "precision": 0.58088,
            "recall": 0.53783,
            "fmeasure": 0.55418
        },
        "rougeL": {
            "precision": 0.71913,
            "recall": 0.66483,
            "fmeasure": 0.68585
        },
        "rougeLsum": {
            "precision": 0.71913,
            "recall": 0.66483,
            "fmeasure": 0.68585
        },
        "local_recall": {
            "1": 0.1718377088305489,
            "2": 0.28975265017667845,
            "3": 0.7964554242749732
        },
        "bleu": 50.26342,
        "nubia": {
            "semantic_relation": 4.47069,
            "contradiction": 7.37277,
            "irrelevancy": 15.62305,
            "logical_agreement": 77.00418,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.66368,
            "nubia_score": 0.80505
        },
        "meteor": 0.41308294235547355,
        "bleurt": 0.4119,
        "bertscore": {
            "precision": 0.94555,
            "recall": 0.93754,
            "f1": 0.94039
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1654,
        "total_length": 41910,
        "mean_pred_length": 25.33857315598549,
        "std_pred_length": 12.67681235019039,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 89,
        "distinct-1": 0.05416368408494393,
        "vocab_size-1": 2270,
        "unique-1": 785,
        "entropy-1": 7.904753922890439,
        "distinct-2": 0.1832025039745628,
        "vocab_size-2": 7375,
        "unique-2": 3588,
        "entropy-2": 11.229479947328995,
        "cond_entropy-2": 3.1673979086569455,
        "distinct-3": 0.3303973887363349,
        "vocab_size-3": 12754,
        "unique-3": 7627,
        "entropy-3": 12.553226557460517,
        "cond_entropy-3": 1.392451167601449,
        "total_length-nopunct": 36883,
        "mean_pred_length-nopunct": 22.299274486094316,
        "std_pred_length-nopunct": 11.370714285708742,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.061274842068161486,
        "vocab_size-1-nopunct": 2260,
        "unique-1-nopunct": 784,
        "entropy-1-nopunct": 8.20281268048685,
        "distinct-2-nopunct": 0.19711033523517557,
        "vocab_size-2-nopunct": 6944,
        "unique-2-nopunct": 3561,
        "entropy-2-nopunct": 11.150129843925779,
        "cond_entropy-2-nopunct": 3.0986322511696955,
        "distinct-3-nopunct": 0.3466269545793001,
        "vocab_size-3-nopunct": 11638,
        "unique-3-nopunct": 7230,
        "entropy-3-nopunct": 12.421642943254472,
        "cond_entropy-3-nopunct": 1.3482697076132066,
        "msttr-100": 0.5021,
        "msttr-100_nopunct": 0.51557,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.14662679872214,
        "rouge1": {
            "precision": 0.62895,
            "recall": 0.63528,
            "fmeasure": 0.6243
        },
        "rouge2": {
            "precision": 0.3722,
            "recall": 0.37427,
            "fmeasure": 0.36832
        },
        "rougeL": {
            "precision": 0.50275,
            "recall": 0.51203,
            "fmeasure": 0.50062
        },
        "rougeLsum": {
            "precision": 0.50275,
            "recall": 0.51203,
            "fmeasure": 0.50062
        },
        "local_recall": {
            "1": 0.22106852935623938,
            "2": 0.5347514743049705,
            "3": 0.7013468013468014,
            "4": 0.8909090909090909,
            "5": 0.4827586206896552
        },
        "bleu": 36.53185,
        "nubia": {
            "semantic_relation": 3.53489,
            "contradiction": 37.69375,
            "irrelevancy": 10.48904,
            "logical_agreement": 51.81721,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.69596,
            "nubia_score": 0.54993
        },
        "meteor": 0.3114102173166568,
        "bleurt": -0.20918,
        "bertscore": {
            "precision": 0.87707,
            "recall": 0.88029,
            "f1": 0.87754
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1295,
        "total_length": 39296,
        "mean_pred_length": 30.344401544401546,
        "std_pred_length": 11.33165848855808,
        "median_pred_length": 29.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.052778908794788276,
        "vocab_size-1": 2074,
        "unique-1": 729,
        "entropy-1": 7.867552876442162,
        "distinct-2": 0.17631114970658668,
        "vocab_size-2": 6700,
        "unique-2": 3213,
        "entropy-2": 11.111175965124758,
        "cond_entropy-2": 3.1173190901827463,
        "distinct-3": 0.32090121506020813,
        "vocab_size-3": 11779,
        "unique-3": 6964,
        "entropy-3": 12.43904476970629,
        "cond_entropy-3": 1.3846309365557992,
        "total_length-nopunct": 34663,
        "mean_pred_length-nopunct": 26.766795366795368,
        "std_pred_length-nopunct": 10.221771457924895,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.059544759541874624,
        "vocab_size-1-nopunct": 2064,
        "unique-1-nopunct": 728,
        "entropy-1-nopunct": 8.151406894156368,
        "distinct-2-nopunct": 0.19275953008870775,
        "vocab_size-2-nopunct": 6432,
        "unique-2-nopunct": 3286,
        "entropy-2-nopunct": 11.064386937504977,
        "cond_entropy-2-nopunct": 3.035712317714244,
        "distinct-3-nopunct": 0.34031740092913043,
        "vocab_size-3-nopunct": 10915,
        "unique-3-nopunct": 6742,
        "entropy-3-nopunct": 12.332409540420988,
        "cond_entropy-3-nopunct": 1.324805543311162,
        "msttr-100": 0.61031,
        "msttr-100_nopunct": 0.64974,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.965355009449156,
        "rouge1": {
            "precision": 0.61838,
            "recall": 0.61957,
            "fmeasure": 0.61135
        },
        "rouge2": {
            "precision": 0.35647,
            "recall": 0.35575,
            "fmeasure": 0.35146
        },
        "rougeL": {
            "precision": 0.4752,
            "recall": 0.48028,
            "fmeasure": 0.47132
        },
        "rougeLsum": {
            "precision": 0.4752,
            "recall": 0.48028,
            "fmeasure": 0.47132
        },
        "local_recall": {
            "1": 0.2125807548452907,
            "2": 0.5172010297215072,
            "3": 0.6910019969458475,
            "4": 0.7058823529411765,
            "5": 0.4827586206896552
        },
        "bleu": 35.41266,
        "nubia": {
            "semantic_relation": 3.46277,
            "contradiction": 40.21967,
            "irrelevancy": 10.82585,
            "logical_agreement": 48.95447,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.48415,
            "nubia_score": 0.54542
        },
        "meteor": 0.2996224130428712,
        "bleurt": -0.26198,
        "bertscore": {
            "precision": 0.8707,
            "recall": 0.87155,
            "f1": 0.86994
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 115,
        "total_length": 2260,
        "mean_pred_length": 19.652173913043477,
        "std_pred_length": 7.339048011076415,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 59,
        "distinct-1": 0.24690265486725663,
        "vocab_size-1": 558,
        "unique-1": 288,
        "entropy-1": 7.231411191604898,
        "distinct-2": 0.531002331002331,
        "vocab_size-2": 1139,
        "unique-2": 766,
        "entropy-2": 9.596127519971807,
        "cond_entropy-2": 2.19821830506903,
        "distinct-3": 0.6950738916256157,
        "vocab_size-3": 1411,
        "unique-3": 1095,
        "entropy-3": 10.188262815525515,
        "cond_entropy-3": 0.6406543925711773,
        "total_length-nopunct": 1950,
        "mean_pred_length-nopunct": 16.956521739130434,
        "std_pred_length-nopunct": 6.463800610823629,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.28307692307692306,
        "vocab_size-1-nopunct": 552,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.508686829217072,
        "distinct-2-nopunct": 0.5340599455040872,
        "vocab_size-2-nopunct": 980,
        "unique-2-nopunct": 666,
        "entropy-2-nopunct": 9.379731610045043,
        "cond_entropy-2-nopunct": 1.9999000614511386,
        "distinct-3-nopunct": 0.6953488372093023,
        "vocab_size-3-nopunct": 1196,
        "unique-3-nopunct": 931,
        "entropy-3-nopunct": 9.944355108842457,
        "cond_entropy-3-nopunct": 0.6127704575099236,
        "msttr-100": 0.61773,
        "msttr-100_nopunct": 0.67053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.4050562598635725,
        "rouge1": {
            "precision": 0.65214,
            "recall": 0.66626,
            "fmeasure": 0.65123
        },
        "rouge2": {
            "precision": 0.41168,
            "recall": 0.42335,
            "fmeasure": 0.41228
        },
        "rougeL": {
            "precision": 0.54562,
            "recall": 0.56459,
            "fmeasure": 0.54801
        },
        "rougeLsum": {
            "precision": 0.54562,
            "recall": 0.56459,
            "fmeasure": 0.54801
        },
        "local_recall": {
            "1": 0.23086124401913877,
            "2": 0.5333333333333333,
            "3": 0.7541322314049587
        },
        "bleu": 38.55479,
        "nubia": {
            "semantic_relation": 3.92179,
            "contradiction": 22.88898,
            "irrelevancy": 10.0134,
            "logical_agreement": 67.09761,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.68705,
            "nubia_score": 0.64942
        },
        "meteor": 0.35630119870795646,
        "bleurt": -0.04433,
        "bertscore": {
            "precision": 0.88604,
            "recall": 0.89683,
            "f1": 0.89023
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 518,
        "total_length": 15006,
        "mean_pred_length": 28.969111969111967,
        "std_pred_length": 12.983171896468692,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 69,
        "distinct-1": 0.057710249233639876,
        "vocab_size-1": 866,
        "unique-1": 244,
        "entropy-1": 7.627490301076115,
        "distinct-2": 0.16102981778023193,
        "vocab_size-2": 2333,
        "unique-2": 953,
        "entropy-2": 9.989262009633178,
        "cond_entropy-2": 2.2331900084026786,
        "distinct-3": 0.24982104509663564,
        "vocab_size-3": 3490,
        "unique-3": 1764,
        "entropy-3": 10.733604433702007,
        "cond_entropy-3": 0.7879047924628426,
        "total_length-nopunct": 13260,
        "mean_pred_length-nopunct": 25.598455598455597,
        "std_pred_length-nopunct": 11.503942480537656,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.06463046757164405,
        "vocab_size-1-nopunct": 857,
        "unique-1-nopunct": 243,
        "entropy-1-nopunct": 7.882378464879004,
        "distinct-2-nopunct": 0.17014597394443573,
        "vocab_size-2-nopunct": 2168,
        "unique-2-nopunct": 923,
        "entropy-2-nopunct": 9.8735443660071,
        "cond_entropy-2-nopunct": 2.0777940854119854,
        "distinct-3-nopunct": 0.26169829842931935,
        "vocab_size-3-nopunct": 3199,
        "unique-3-nopunct": 1676,
        "entropy-3-nopunct": 10.585816120083958,
        "cond_entropy-3-nopunct": 0.7445175907721331,
        "msttr-100": 0.64887,
        "msttr-100_nopunct": 0.69265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 9.122441127217868,
        "rouge1": {
            "precision": 0.82539,
            "recall": 0.78534,
            "fmeasure": 0.7996
        },
        "rouge2": {
            "precision": 0.5979,
            "recall": 0.57021,
            "fmeasure": 0.57927
        },
        "rougeL": {
            "precision": 0.66684,
            "recall": 0.63703,
            "fmeasure": 0.64697
        },
        "rougeLsum": {
            "precision": 0.66684,
            "recall": 0.63703,
            "fmeasure": 0.64697
        },
        "local_recall": {
            "1": 0.25048135830561874,
            "2": 0.6389370306181398,
            "3": 0.9074021148899686,
            "4": 0.9736842105263158
        },
        "bleu": 59.31741,
        "nubia": {
            "semantic_relation": 4.58799,
            "contradiction": 3.78251,
            "irrelevancy": 5.14886,
            "logical_agreement": 91.06863,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.20497,
            "nubia_score": 0.85766
        },
        "meteor": 0.4175004924373862,
        "bleurt": 0.31979,
        "bertscore": {
            "precision": 0.94609,
            "recall": 0.93759,
            "f1": 0.94082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 39,
        "total_length": 680,
        "mean_pred_length": 17.435897435897434,
        "std_pred_length": 7.434482624024116,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.5441176470588235,
        "vocab_size-1": 370,
        "unique-1": 307,
        "entropy-1": 7.454640286516079,
        "distinct-2": 0.9173166926677067,
        "vocab_size-2": 588,
        "unique-2": 549,
        "entropy-2": 9.125906624731439,
        "cond_entropy-2": 1.4621164097393278,
        "distinct-3": 0.978405315614618,
        "vocab_size-3": 589,
        "unique-3": 576,
        "entropy-3": 9.190430307988965,
        "cond_entropy-3": 0.07404641241637779,
        "total_length-nopunct": 571,
        "mean_pred_length-nopunct": 14.64102564102564,
        "std_pred_length-nopunct": 5.855031496060064,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.637478108581436,
        "vocab_size-1-nopunct": 364,
        "unique-1-nopunct": 306,
        "entropy-1-nopunct": 7.775678727910933,
        "distinct-2-nopunct": 0.9323308270676691,
        "vocab_size-2-nopunct": 496,
        "unique-2-nopunct": 470,
        "entropy-2-nopunct": 8.888498495739631,
        "cond_entropy-2-nopunct": 1.1909122679934843,
        "distinct-3-nopunct": 0.9878296146044625,
        "vocab_size-3-nopunct": 487,
        "unique-3-nopunct": 481,
        "entropy-3-nopunct": 8.921103065586868,
        "cond_entropy-3-nopunct": 0.03971323850998848,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.866237887473169,
        "rouge1": {
            "precision": 0.79061,
            "recall": 0.69344,
            "fmeasure": 0.73019
        },
        "rouge2": {
            "precision": 0.53307,
            "recall": 0.47743,
            "fmeasure": 0.49746
        },
        "rougeL": {
            "precision": 0.67168,
            "recall": 0.59531,
            "fmeasure": 0.62366
        },
        "rougeLsum": {
            "precision": 0.67168,
            "recall": 0.59531,
            "fmeasure": 0.62366
        },
        "local_recall": {
            "1": 0.16541353383458646,
            "2": 0.6402116402116402,
            "3": 0.7196029776674938
        },
        "bleu": 45.29421,
        "nubia": {
            "semantic_relation": 4.16309,
            "contradiction": 7.8099,
            "irrelevancy": 27.31758,
            "logical_agreement": 64.87253,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.27323,
            "nubia_score": 0.73058
        },
        "meteor": 0.38638614957490863,
        "bleurt": 0.31563,
        "bertscore": {
            "precision": 0.93355,
            "recall": 0.91659,
            "f1": 0.92425
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 125,
        "total_length": 3962,
        "mean_pred_length": 31.696,
        "std_pred_length": 9.89805960782213,
        "median_pred_length": 31.0,
        "min_pred_length": 9,
        "max_pred_length": 57,
        "distinct-1": 0.14209994952044422,
        "vocab_size-1": 563,
        "unique-1": 225,
        "entropy-1": 6.964811164216951,
        "distinct-2": 0.3518373729476153,
        "vocab_size-2": 1350,
        "unique-2": 741,
        "entropy-2": 9.506997182933238,
        "cond_entropy-2": 2.4524588560328935,
        "distinct-3": 0.5212823275862069,
        "vocab_size-3": 1935,
        "unique-3": 1273,
        "entropy-3": 10.397487946513229,
        "cond_entropy-3": 0.9353670018080666,
        "total_length-nopunct": 3485,
        "mean_pred_length-nopunct": 27.88,
        "std_pred_length-nopunct": 8.965355542308401,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.15954088952654233,
        "vocab_size-1-nopunct": 556,
        "unique-1-nopunct": 224,
        "entropy-1-nopunct": 7.140048681447317,
        "distinct-2-nopunct": 0.368452380952381,
        "vocab_size-2-nopunct": 1238,
        "unique-2-nopunct": 700,
        "entropy-2-nopunct": 9.401028554465686,
        "cond_entropy-2-nopunct": 2.3619124919831207,
        "distinct-3-nopunct": 0.5353941267387944,
        "vocab_size-3-nopunct": 1732,
        "unique-3-nopunct": 1165,
        "entropy-3-nopunct": 10.23568023540302,
        "cond_entropy-3-nopunct": 0.869335582587638,
        "msttr-100": 0.47026,
        "msttr-100_nopunct": 0.49853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.758837211185114,
        "rouge1": {
            "precision": 0.50865,
            "recall": 0.52772,
            "fmeasure": 0.50912
        },
        "rouge2": {
            "precision": 0.24117,
            "recall": 0.25139,
            "fmeasure": 0.24069
        },
        "rougeL": {
            "precision": 0.38835,
            "recall": 0.40691,
            "fmeasure": 0.3896
        },
        "rougeLsum": {
            "precision": 0.38835,
            "recall": 0.40691,
            "fmeasure": 0.3896
        },
        "local_recall": {
            "1": 0.1846553966189857,
            "2": 0.41697877652933835,
            "3": 0.5672619047619047
        },
        "bleu": 21.18716,
        "nubia": {
            "semantic_relation": 2.78322,
            "contradiction": 64.66928,
            "irrelevancy": 12.43454,
            "logical_agreement": 22.89618,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.6153,
            "nubia_score": 0.38028
        },
        "meteor": 0.22909272750618093,
        "bleurt": -0.60273,
        "bertscore": {
            "precision": 0.83158,
            "recall": 0.83288,
            "f1": 0.83062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 78,
        "total_length": 1250,
        "mean_pred_length": 16.025641025641026,
        "std_pred_length": 6.27770650381654,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.472,
        "vocab_size-1": 590,
        "unique-1": 439,
        "entropy-1": 7.996578870744414,
        "distinct-2": 0.8447098976109215,
        "vocab_size-2": 990,
        "unique-2": 877,
        "entropy-2": 9.791495354193506,
        "cond_entropy-2": 1.5290863133257937,
        "distinct-3": 0.9414990859232175,
        "vocab_size-3": 1030,
        "unique-3": 976,
        "entropy-3": 9.969817426828046,
        "cond_entropy-3": 0.1887922710055384,
        "total_length-nopunct": 1096,
        "mean_pred_length-nopunct": 14.051282051282051,
        "std_pred_length-nopunct": 5.467614292234979,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5291970802919708,
        "vocab_size-1-nopunct": 580,
        "unique-1-nopunct": 437,
        "entropy-1-nopunct": 8.214868142838656,
        "distinct-2-nopunct": 0.8467583497053045,
        "vocab_size-2-nopunct": 862,
        "unique-2-nopunct": 769,
        "entropy-2-nopunct": 9.583749053085715,
        "cond_entropy-2-nopunct": 1.4608233924172254,
        "distinct-3-nopunct": 0.9414893617021277,
        "vocab_size-3-nopunct": 885,
        "unique-3-nopunct": 837,
        "entropy-3-nopunct": 9.751921823715398,
        "cond_entropy-3-nopunct": 0.1928762976003536,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.146172172071699,
        "rouge1": {
            "precision": 0.77526,
            "recall": 0.71444,
            "fmeasure": 0.73328
        },
        "rouge2": {
            "precision": 0.54091,
            "recall": 0.49998,
            "fmeasure": 0.51113
        },
        "rougeL": {
            "precision": 0.68846,
            "recall": 0.63469,
            "fmeasure": 0.65091
        },
        "rougeLsum": {
            "precision": 0.68846,
            "recall": 0.63469,
            "fmeasure": 0.65091
        },
        "local_recall": {
            "1": 0.20600858369098712,
            "2": 0.46808510638297873,
            "3": 0.7554744525547445
        },
        "bleu": 45.11668,
        "nubia": {
            "semantic_relation": 4.31169,
            "contradiction": 5.01085,
            "irrelevancy": 28.36125,
            "logical_agreement": 66.6279,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.71105,
            "nubia_score": 0.75187
        },
        "meteor": 0.3936684436694408,
        "bleurt": 0.29186,
        "bertscore": {
            "precision": 0.93069,
            "recall": 0.92295,
            "f1": 0.92531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 280,
        "mean_pred_length": 15.555555555555555,
        "std_pred_length": 6.668518261388293,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5571428571428572,
        "vocab_size-1": 156,
        "unique-1": 114,
        "entropy-1": 6.6236091582783,
        "distinct-2": 0.9007633587786259,
        "vocab_size-2": 236,
        "unique-2": 219,
        "entropy-2": 7.792349492153012,
        "cond_entropy-2": 0.9857001790275122,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 236,
        "unique-3": 229,
        "entropy-3": 7.862069765832669,
        "cond_entropy-3": 0.08750438502775798,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 14.055555555555555,
        "std_pred_length-nopunct": 6.728647067429283,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6047430830039525,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.708171320146038,
        "distinct-2-nopunct": 0.8978723404255319,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.627979193558318,
        "cond_entropy-2-nopunct": 0.975296852077213,
        "distinct-3-nopunct": 0.9723502304147466,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 205,
        "entropy-3-nopunct": 7.706251693273984,
        "cond_entropy-3-nopunct": 0.08045535480374967,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.5058788143826325,
        "rouge1": {
            "precision": 0.72244,
            "recall": 0.69471,
            "fmeasure": 0.70068
        },
        "rouge2": {
            "precision": 0.44114,
            "recall": 0.42843,
            "fmeasure": 0.42922
        },
        "rougeL": {
            "precision": 0.59502,
            "recall": 0.57298,
            "fmeasure": 0.57675
        },
        "rougeLsum": {
            "precision": 0.59502,
            "recall": 0.57298,
            "fmeasure": 0.57675
        },
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.48214285714285715,
            "3": 0.7529411764705882
        },
        "bleu": 35.84272,
        "nubia": {
            "semantic_relation": 4.16513,
            "contradiction": 7.11694,
            "irrelevancy": 30.86155,
            "logical_agreement": 62.02151,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.70713,
            "nubia_score": 0.74289
        },
        "meteor": 0.3599491971386623,
        "bleurt": 0.27165,
        "bertscore": {
            "precision": 0.92583,
            "recall": 0.91534,
            "f1": 0.9194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 22,
        "total_length": 315,
        "mean_pred_length": 14.318181818181818,
        "std_pred_length": 4.50642333116513,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.5936507936507937,
        "vocab_size-1": 187,
        "unique-1": 156,
        "entropy-1": 6.725875700701253,
        "distinct-2": 0.9351535836177475,
        "vocab_size-2": 274,
        "unique-2": 262,
        "entropy-2": 8.033796924529014,
        "cond_entropy-2": 1.091217522049785,
        "distinct-3": 0.988929889298893,
        "vocab_size-3": 268,
        "unique-3": 265,
        "entropy-3": 8.060008819951623,
        "cond_entropy-3": 0.03927875320000068,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 12.409090909090908,
        "std_pred_length-nopunct": 4.108296383363026,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.663003663003663,
        "vocab_size-1-nopunct": 181,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 6.858732138989638,
        "distinct-2-nopunct": 0.9362549800796812,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 226,
        "entropy-2-nopunct": 7.807554472441881,
        "cond_entropy-2-nopunct": 1.037063568681169,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 229,
        "unique-3-nopunct": 229,
        "entropy-3-nopunct": 7.839203788096948,
        "cond_entropy-3-nopunct": 0.04740372523232984,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.036420843382496,
        "rouge1": {
            "precision": 0.74641,
            "recall": 0.75654,
            "fmeasure": 0.74203
        },
        "rouge2": {
            "precision": 0.52732,
            "recall": 0.52906,
            "fmeasure": 0.521
        },
        "rougeL": {
            "precision": 0.64893,
            "recall": 0.66363,
            "fmeasure": 0.64681
        },
        "rougeLsum": {
            "precision": 0.64893,
            "recall": 0.66363,
            "fmeasure": 0.64681
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.5454545454545454,
            "3": 0.782608695652174
        },
        "bleu": 46.87263,
        "nubia": {
            "semantic_relation": 4.2921,
            "contradiction": 4.68257,
            "irrelevancy": 29.81885,
            "logical_agreement": 65.49858,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.12582,
            "nubia_score": 0.74231
        },
        "meteor": 0.39397654051092423,
        "bleurt": 0.22692,
        "bertscore": {
            "precision": 0.91604,
            "recall": 0.92742,
            "f1": 0.92083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 79,
        "total_length": 1260,
        "mean_pred_length": 15.949367088607595,
        "std_pred_length": 6.746586073715807,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.4976190476190476,
        "vocab_size-1": 627,
        "unique-1": 502,
        "entropy-1": 8.004056502905454,
        "distinct-2": 0.8679085520745131,
        "vocab_size-2": 1025,
        "unique-2": 939,
        "entropy-2": 9.85696533112113,
        "cond_entropy-2": 1.58234898020162,
        "distinct-3": 0.9600725952813067,
        "vocab_size-3": 1058,
        "unique-3": 1018,
        "entropy-3": 10.022868785336879,
        "cond_entropy-3": 0.15618725007515308,
        "total_length-nopunct": 1088,
        "mean_pred_length-nopunct": 13.772151898734178,
        "std_pred_length-nopunct": 5.9341307727045995,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5716911764705882,
        "vocab_size-1-nopunct": 622,
        "unique-1-nopunct": 502,
        "entropy-1-nopunct": 8.310053805036034,
        "distinct-2-nopunct": 0.8919722497522299,
        "vocab_size-2-nopunct": 900,
        "unique-2-nopunct": 836,
        "entropy-2-nopunct": 9.68936209140028,
        "cond_entropy-2-nopunct": 1.4715858398553654,
        "distinct-3-nopunct": 0.9720430107526882,
        "vocab_size-3-nopunct": 904,
        "unique-3-nopunct": 879,
        "entropy-3-nopunct": 9.804361220509236,
        "cond_entropy-3-nopunct": 0.12478798238496991,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.9543783738902425,
        "rouge1": {
            "precision": 0.75138,
            "recall": 0.68674,
            "fmeasure": 0.70023
        },
        "rouge2": {
            "precision": 0.51404,
            "recall": 0.46578,
            "fmeasure": 0.47478
        },
        "rougeL": {
            "precision": 0.65345,
            "recall": 0.59836,
            "fmeasure": 0.60896
        },
        "rougeLsum": {
            "precision": 0.65345,
            "recall": 0.59836,
            "fmeasure": 0.60896
        },
        "local_recall": {
            "1": 0.2508038585209003,
            "2": 0.4589041095890411,
            "3": 0.7338603425559947
        },
        "bleu": 41.35884,
        "nubia": {
            "semantic_relation": 4.09206,
            "contradiction": 10.46842,
            "irrelevancy": 29.47638,
            "logical_agreement": 60.05519,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.98299,
            "nubia_score": 0.67819
        },
        "meteor": 0.3694042771020052,
        "bleurt": 0.15638,
        "bertscore": {
            "precision": 0.92342,
            "recall": 0.91484,
            "f1": 0.91745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 90,
        "mean_pred_length": 18.0,
        "std_pred_length": 11.349008767288886,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.7,
        "vocab_size-1": 63,
        "unique-1": 50,
        "entropy-1": 5.701924385998547,
        "distinct-2": 0.9176470588235294,
        "vocab_size-2": 78,
        "unique-2": 72,
        "entropy-2": 6.235804024347549,
        "cond_entropy-2": 0.44376202749273974,
        "distinct-3": 0.95,
        "vocab_size-3": 76,
        "unique-3": 72,
        "entropy-3": 6.2219280948873585,
        "cond_entropy-3": -0.003026747473295994,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 6.711184694225007,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.782243907394997,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.882041828261823,
        "cond_entropy-2-nopunct": 0.09227561402994955,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.789015477886191,
        "cond_entropy-3-nopunct": -0.10205754906199971,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.51597681153098,
        "rouge1": {
            "precision": 0.78302,
            "recall": 0.82422,
            "fmeasure": 0.79691
        },
        "rouge2": {
            "precision": 0.60333,
            "recall": 0.63369,
            "fmeasure": 0.61177
        },
        "rougeL": {
            "precision": 0.75186,
            "recall": 0.79264,
            "fmeasure": 0.76559
        },
        "rougeLsum": {
            "precision": 0.75186,
            "recall": 0.79264,
            "fmeasure": 0.76559
        },
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.65,
            "3": 0.8260869565217391
        },
        "bleu": 60.35644,
        "nubia": {
            "semantic_relation": 4.24892,
            "contradiction": 10.72705,
            "irrelevancy": 31.1151,
            "logical_agreement": 58.15785,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.61206,
            "nubia_score": 0.78358
        },
        "meteor": 0.4412358162745265,
        "bleurt": 0.44712,
        "bertscore": {
            "precision": 0.94854,
            "recall": 0.95373,
            "f1": 0.95039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 11.5,
        "median_pred_length": 22.5,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 26,
        "entropy-1": 4.8528555962815965,
        "distinct-2": 0.9069767441860465,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.2226627197680635,
        "cond_entropy-2": 0.3530163095352141,
        "distinct-3": 0.9512195121951219,
        "vocab_size-3": 39,
        "unique-3": 37,
        "entropy-3": 5.259991029008325,
        "cond_entropy-3": 0.047260115822411755,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8125,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.10689059560851855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.943666459084587,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.713,
            "fmeasure": 0.75222
        },
        "rouge2": {
            "precision": 0.53968,
            "recall": 0.4642,
            "fmeasure": 0.49758
        },
        "rougeL": {
            "precision": 0.71667,
            "recall": 0.68799,
            "fmeasure": 0.69973
        },
        "rougeLsum": {
            "precision": 0.71667,
            "recall": 0.68799,
            "fmeasure": 0.69973
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bleu": 67.85684,
        "nubia": {
            "semantic_relation": 4.4136,
            "contradiction": 1.48543,
            "irrelevancy": 12.06542,
            "logical_agreement": 86.44914,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.46441,
            "nubia_score": 0.76137
        },
        "meteor": 0.38465233438061086,
        "bleurt": 0.31138,
        "bertscore": {
            "precision": 0.94405,
            "recall": 0.90748,
            "f1": 0.92536
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 36,
        "total_length": 643,
        "mean_pred_length": 17.86111111111111,
        "std_pred_length": 5.935546299755669,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.5505443234836703,
        "vocab_size-1": 354,
        "unique-1": 292,
        "entropy-1": 7.424299853633394,
        "distinct-2": 0.9242174629324547,
        "vocab_size-2": 561,
        "unique-2": 533,
        "entropy-2": 9.046386556355216,
        "cond_entropy-2": 1.4284132308948834,
        "distinct-3": 0.9859894921190894,
        "vocab_size-3": 563,
        "unique-3": 555,
        "entropy-3": 9.12932591960103,
        "cond_entropy-3": 0.07516412843315753,
        "total_length-nopunct": 548,
        "mean_pred_length-nopunct": 15.222222222222221,
        "std_pred_length-nopunct": 4.702901652237402,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6332116788321168,
        "vocab_size-1-nopunct": 347,
        "unique-1-nopunct": 290,
        "entropy-1-nopunct": 7.662653528618585,
        "distinct-2-nopunct": 0.935546875,
        "vocab_size-2-nopunct": 479,
        "unique-2-nopunct": 458,
        "entropy-2-nopunct": 8.827091162084022,
        "cond_entropy-2-nopunct": 1.247966417373102,
        "distinct-3-nopunct": 0.9873949579831933,
        "vocab_size-3-nopunct": 470,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 8.869607679274402,
        "cond_entropy-3-nopunct": 0.05016306270344714,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.280030827255583,
        "rouge1": {
            "precision": 0.75385,
            "recall": 0.67363,
            "fmeasure": 0.7008
        },
        "rouge2": {
            "precision": 0.45874,
            "recall": 0.40798,
            "fmeasure": 0.42634
        },
        "rougeL": {
            "precision": 0.64103,
            "recall": 0.57562,
            "fmeasure": 0.59735
        },
        "rougeLsum": {
            "precision": 0.64103,
            "recall": 0.57562,
            "fmeasure": 0.59735
        },
        "local_recall": {
            "1": 0.23931623931623933,
            "2": 0.4852941176470588,
            "3": 0.7311557788944724
        },
        "bleu": 35.37319,
        "nubia": {
            "semantic_relation": 4.08561,
            "contradiction": 14.64694,
            "irrelevancy": 30.6082,
            "logical_agreement": 54.74486,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.95117,
            "nubia_score": 0.6669
        },
        "meteor": 0.3479890816875044,
        "bleurt": 0.18647,
        "bertscore": {
            "precision": 0.92336,
            "recall": 0.911,
            "f1": 0.91613
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 3.2691742076555053,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.0306333740593745,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.17679372541434707,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.14809863898913406,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.918780730435346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.16084643561324524,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.18641312423088147,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.465156458822608,
        "rouge1": {
            "precision": 0.81111,
            "recall": 0.77559,
            "fmeasure": 0.78861
        },
        "rouge2": {
            "precision": 0.63564,
            "recall": 0.60861,
            "fmeasure": 0.6194
        },
        "rougeL": {
            "precision": 0.75972,
            "recall": 0.72837,
            "fmeasure": 0.74013
        },
        "rougeLsum": {
            "precision": 0.75972,
            "recall": 0.72837,
            "fmeasure": 0.74013
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bleu": 49.27674,
        "nubia": {
            "semantic_relation": 4.4713,
            "contradiction": 5.73294,
            "irrelevancy": 28.66993,
            "logical_agreement": 65.59713,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.32619,
            "nubia_score": 0.67546
        },
        "meteor": 0.4141089149253812,
        "bleurt": 0.31826,
        "bertscore": {
            "precision": 0.94643,
            "recall": 0.95809,
            "f1": 0.952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 549,
        "mean_pred_length": 17.70967741935484,
        "std_pred_length": 6.248579443140021,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5919854280510018,
        "vocab_size-1": 325,
        "unique-1": 270,
        "entropy-1": 7.568796039422828,
        "distinct-2": 0.9015444015444015,
        "vocab_size-2": 467,
        "unique-2": 434,
        "entropy-2": 8.779318808905293,
        "cond_entropy-2": 1.005711514009714,
        "distinct-3": 0.9671457905544147,
        "vocab_size-3": 471,
        "unique-3": 457,
        "entropy-3": 8.857962767010472,
        "cond_entropy-3": 0.08399772882390065,
        "total_length-nopunct": 471,
        "mean_pred_length-nopunct": 15.193548387096774,
        "std_pred_length-nopunct": 5.330492653130483,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.673036093418259,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.773705425109694,
        "distinct-2-nopunct": 0.9204545454545454,
        "vocab_size-2-nopunct": 405,
        "unique-2-nopunct": 383,
        "entropy-2-nopunct": 8.58530366237358,
        "cond_entropy-2-nopunct": 0.8768192601249871,
        "distinct-3-nopunct": 0.9779951100244498,
        "vocab_size-3-nopunct": 400,
        "unique-3-nopunct": 391,
        "entropy-3-nopunct": 8.63194725299069,
        "cond_entropy-3-nopunct": 0.055183383000877655,
        "msttr-100": 0.738,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.244396421755135,
        "rouge1": {
            "precision": 0.81658,
            "recall": 0.79705,
            "fmeasure": 0.7946
        },
        "rouge2": {
            "precision": 0.60928,
            "recall": 0.59674,
            "fmeasure": 0.59358
        },
        "rougeL": {
            "precision": 0.706,
            "recall": 0.69965,
            "fmeasure": 0.69445
        },
        "rougeLsum": {
            "precision": 0.706,
            "recall": 0.69965,
            "fmeasure": 0.69445
        },
        "local_recall": {
            "1": 0.20353982300884957,
            "2": 0.5,
            "3": 0.8264462809917356
        },
        "bleu": 55.13668,
        "nubia": {
            "semantic_relation": 4.27412,
            "contradiction": 17.11088,
            "irrelevancy": 19.43641,
            "logical_agreement": 63.45271,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.76148,
            "nubia_score": 0.7433
        },
        "meteor": 0.4414133410153574,
        "bleurt": 0.39071,
        "bertscore": {
            "precision": 0.94452,
            "recall": 0.93903,
            "f1": 0.9406
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 112,
        "total_length": 1703,
        "mean_pred_length": 15.205357142857142,
        "std_pred_length": 5.7804139632672245,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.43041691133294185,
        "vocab_size-1": 733,
        "unique-1": 605,
        "entropy-1": 7.872372289063066,
        "distinct-2": 0.7837837837837838,
        "vocab_size-2": 1247,
        "unique-2": 1140,
        "entropy-2": 9.917276789642951,
        "cond_entropy-2": 1.7662287522695082,
        "distinct-3": 0.8864097363083164,
        "vocab_size-3": 1311,
        "unique-3": 1259,
        "entropy-3": 10.16779693490141,
        "cond_entropy-3": 0.271781726751973,
        "total_length-nopunct": 1467,
        "mean_pred_length-nopunct": 13.098214285714286,
        "std_pred_length-nopunct": 5.042603886295416,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.49216087252897067,
        "vocab_size-1-nopunct": 722,
        "unique-1-nopunct": 600,
        "entropy-1-nopunct": 8.147705019041757,
        "distinct-2-nopunct": 0.796309963099631,
        "vocab_size-2-nopunct": 1079,
        "unique-2-nopunct": 1001,
        "entropy-2-nopunct": 9.705015996841807,
        "cond_entropy-2-nopunct": 1.6905995146013748,
        "distinct-3-nopunct": 0.8930008045052292,
        "vocab_size-3-nopunct": 1110,
        "unique-3-nopunct": 1070,
        "entropy-3-nopunct": 9.936240097119445,
        "cond_entropy-3-nopunct": 0.2829205395376488,
        "msttr-100": 0.68118,
        "msttr-100_nopunct": 0.73214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.19674043705976,
        "rouge1": {
            "precision": 0.77618,
            "recall": 0.71059,
            "fmeasure": 0.72858
        },
        "rouge2": {
            "precision": 0.52068,
            "recall": 0.47696,
            "fmeasure": 0.48985
        },
        "rougeL": {
            "precision": 0.64884,
            "recall": 0.59431,
            "fmeasure": 0.60968
        },
        "rougeLsum": {
            "precision": 0.64884,
            "recall": 0.59431,
            "fmeasure": 0.60968
        },
        "local_recall": {
            "1": 0.20771513353115728,
            "2": 0.42948717948717946,
            "3": 0.7567804024496938
        },
        "bleu": 41.61279,
        "nubia": {
            "semantic_relation": 4.14799,
            "contradiction": 9.87966,
            "irrelevancy": 23.5938,
            "logical_agreement": 66.52654,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.71261,
            "nubia_score": 0.71904
        },
        "meteor": 0.3738531021477588,
        "bleurt": 0.27922,
        "bertscore": {
            "precision": 0.92843,
            "recall": 0.91675,
            "f1": 0.92108
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 309,
        "mean_pred_length": 22.071428571428573,
        "std_pred_length": 24.725534186672824,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 109,
        "distinct-1": 0.47896440129449835,
        "vocab_size-1": 148,
        "unique-1": 115,
        "entropy-1": 6.215583690460338,
        "distinct-2": 0.7559322033898305,
        "vocab_size-2": 223,
        "unique-2": 197,
        "entropy-2": 7.455564335495391,
        "cond_entropy-2": 1.1710877446567116,
        "distinct-3": 0.8220640569395018,
        "vocab_size-3": 231,
        "unique-3": 207,
        "entropy-3": 7.658775633934022,
        "cond_entropy-3": 0.22273476933736286,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 17.428571428571427,
        "std_pred_length-nopunct": 15.855212237685144,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.5860655737704918,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.387650714089725,
        "distinct-2-nopunct": 0.8304347826086956,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.386542323220406,
        "cond_entropy-2-nopunct": 1.0754273166464332,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 192,
        "unique-3-nopunct": 176,
        "entropy-3-nopunct": 7.489983423696457,
        "cond_entropy-3-nopunct": 0.11929882356926655,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.453199070055859,
        "rouge1": {
            "precision": 0.76569,
            "recall": 0.69657,
            "fmeasure": 0.71872
        },
        "rouge2": {
            "precision": 0.56337,
            "recall": 0.50162,
            "fmeasure": 0.52386
        },
        "rougeL": {
            "precision": 0.66382,
            "recall": 0.61075,
            "fmeasure": 0.62744
        },
        "rougeLsum": {
            "precision": 0.66382,
            "recall": 0.61075,
            "fmeasure": 0.62744
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.37037037037037035,
            "3": 0.711764705882353
        },
        "bleu": 32.84544,
        "nubia": {
            "semantic_relation": 4.40528,
            "contradiction": 19.75577,
            "irrelevancy": 8.23037,
            "logical_agreement": 72.01386,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.9115,
            "nubia_score": 0.74667
        },
        "meteor": 0.36328980318801757,
        "bleurt": 0.38108,
        "bertscore": {
            "precision": 0.93911,
            "recall": 0.93507,
            "f1": 0.93574
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 50,
        "total_length": 854,
        "mean_pred_length": 17.08,
        "std_pred_length": 9.63086704300293,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 67,
        "distinct-1": 0.4953161592505855,
        "vocab_size-1": 423,
        "unique-1": 334,
        "entropy-1": 7.568496667721119,
        "distinct-2": 0.8482587064676617,
        "vocab_size-2": 682,
        "unique-2": 614,
        "entropy-2": 9.258333162671434,
        "cond_entropy-2": 1.4737755124953367,
        "distinct-3": 0.9456233421750663,
        "vocab_size-3": 713,
        "unique-3": 681,
        "entropy-3": 9.44000663831479,
        "cond_entropy-3": 0.18649565923148334,
        "total_length-nopunct": 726,
        "mean_pred_length-nopunct": 14.52,
        "std_pred_length-nopunct": 6.8621862405504555,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.5757575757575758,
        "vocab_size-1-nopunct": 418,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.871406039812393,
        "distinct-2-nopunct": 0.8890532544378699,
        "vocab_size-2-nopunct": 601,
        "unique-2-nopunct": 559,
        "entropy-2-nopunct": 9.113571877872964,
        "cond_entropy-2-nopunct": 1.325784547238109,
        "distinct-3-nopunct": 0.9712460063897763,
        "vocab_size-3-nopunct": 608,
        "unique-3-nopunct": 594,
        "entropy-3-nopunct": 9.227687297397898,
        "cond_entropy-3-nopunct": 0.1306735312191854,
        "msttr-100": 0.67875,
        "msttr-100_nopunct": 0.74143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.472356103691162,
        "rouge1": {
            "precision": 0.76122,
            "recall": 0.68354,
            "fmeasure": 0.70972
        },
        "rouge2": {
            "precision": 0.51802,
            "recall": 0.46918,
            "fmeasure": 0.48431
        },
        "rougeL": {
            "precision": 0.65782,
            "recall": 0.60538,
            "fmeasure": 0.62066
        },
        "rougeLsum": {
            "precision": 0.65782,
            "recall": 0.60538,
            "fmeasure": 0.62066
        },
        "local_recall": {
            "1": 0.24666666666666667,
            "2": 0.4968553459119497,
            "3": 0.698905109489051
        },
        "bleu": 40.231,
        "nubia": {
            "semantic_relation": 4.10046,
            "contradiction": 7.33253,
            "irrelevancy": 25.99722,
            "logical_agreement": 66.67024,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.82558,
            "nubia_score": 0.68368
        },
        "meteor": 0.3514284075089525,
        "bleurt": 0.16825,
        "bertscore": {
            "precision": 0.92065,
            "recall": 0.90712,
            "f1": 0.91226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 124,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 9.428090415820634,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 37,
        "distinct-1": 0.6532258064516129,
        "vocab_size-1": 81,
        "unique-1": 64,
        "entropy-1": 5.974357956464547,
        "distinct-2": 0.940677966101695,
        "vocab_size-2": 111,
        "unique-2": 105,
        "entropy-2": 6.7576016298519725,
        "cond_entropy-2": 0.7016271913468047,
        "distinct-3": 0.9910714285714286,
        "vocab_size-3": 111,
        "unique-3": 110,
        "entropy-3": 6.789497779200449,
        "cond_entropy-3": 0.0207376539650794,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 6.574360974438673,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.952243595187433,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.46145175059078,
        "cond_entropy-2-nopunct": 0.5364923369650985,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.459431618637305,
        "cond_entropy-3-nopunct": 0.0043301249387899966,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.834957243694883,
        "rouge1": {
            "precision": 0.8696,
            "recall": 0.81354,
            "fmeasure": 0.83554
        },
        "rouge2": {
            "precision": 0.70532,
            "recall": 0.65258,
            "fmeasure": 0.67424
        },
        "rougeL": {
            "precision": 0.8383,
            "recall": 0.77935,
            "fmeasure": 0.80335
        },
        "rougeLsum": {
            "precision": 0.8383,
            "recall": 0.77935,
            "fmeasure": 0.80335
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5833333333333334,
            "3": 0.8765432098765432
        },
        "bleu": 55.26253,
        "nubia": {
            "semantic_relation": 4.63762,
            "contradiction": 1.48888,
            "irrelevancy": 23.43035,
            "logical_agreement": 75.08077,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.94732,
            "nubia_score": 0.86202
        },
        "meteor": 0.4301796905111032,
        "bleurt": 0.48982,
        "bertscore": {
            "precision": 0.9597,
            "recall": 0.95241,
            "f1": 0.9557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 91,
        "total_length": 1406,
        "mean_pred_length": 15.45054945054945,
        "std_pred_length": 6.869687735859176,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.3961593172119488,
        "vocab_size-1": 557,
        "unique-1": 431,
        "entropy-1": 7.6062697316951144,
        "distinct-2": 0.7254752851711027,
        "vocab_size-2": 954,
        "unique-2": 836,
        "entropy-2": 9.482398465556019,
        "cond_entropy-2": 1.6209102263328516,
        "distinct-3": 0.8390522875816994,
        "vocab_size-3": 1027,
        "unique-3": 948,
        "entropy-3": 9.77684693596081,
        "cond_entropy-3": 0.3083741005560554,
        "total_length-nopunct": 1217,
        "mean_pred_length-nopunct": 13.373626373626374,
        "std_pred_length-nopunct": 5.850985362018708,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.4527526705012325,
        "vocab_size-1-nopunct": 551,
        "unique-1-nopunct": 430,
        "entropy-1-nopunct": 7.854236350613477,
        "distinct-2-nopunct": 0.7406749555950266,
        "vocab_size-2-nopunct": 834,
        "unique-2-nopunct": 740,
        "entropy-2-nopunct": 9.297553536227108,
        "cond_entropy-2-nopunct": 1.5520025521695733,
        "distinct-3-nopunct": 0.8473429951690822,
        "vocab_size-3-nopunct": 877,
        "unique-3-nopunct": 816,
        "entropy-3-nopunct": 9.559779318482695,
        "cond_entropy-3-nopunct": 0.31049074060793946,
        "msttr-100": 0.68714,
        "msttr-100_nopunct": 0.7475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.630285389016349,
        "rouge1": {
            "precision": 0.80599,
            "recall": 0.74378,
            "fmeasure": 0.76359
        },
        "rouge2": {
            "precision": 0.59397,
            "recall": 0.5522,
            "fmeasure": 0.56545
        },
        "rougeL": {
            "precision": 0.71382,
            "recall": 0.66408,
            "fmeasure": 0.67965
        },
        "rougeLsum": {
            "precision": 0.71382,
            "recall": 0.66408,
            "fmeasure": 0.67965
        },
        "local_recall": {
            "1": 0.22072072072072071,
            "2": 0.4548872180451128,
            "3": 0.7762605042016807
        },
        "bleu": 52.99214,
        "nubia": {
            "semantic_relation": 4.17291,
            "contradiction": 8.17461,
            "irrelevancy": 20.38433,
            "logical_agreement": 71.44105,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.41477,
            "nubia_score": 0.74377
        },
        "meteor": 0.4080724545462471,
        "bleurt": 0.31995,
        "bertscore": {
            "precision": 0.93708,
            "recall": 0.92464,
            "f1": 0.92947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 189,
        "mean_pred_length": 17.181818181818183,
        "std_pred_length": 6.278653327211639,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.6507936507936508,
        "vocab_size-1": 123,
        "unique-1": 99,
        "entropy-1": 6.515669123867296,
        "distinct-2": 0.949438202247191,
        "vocab_size-2": 169,
        "unique-2": 160,
        "entropy-2": 7.3746098354607525,
        "cond_entropy-2": 0.70983148967709,
        "distinct-3": 0.9700598802395209,
        "vocab_size-3": 162,
        "unique-3": 157,
        "entropy-3": 7.3238240529530705,
        "cond_entropy-3": -0.04412494687557936,
        "total_length-nopunct": 165,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.52679423766206,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7212121212121212,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.595296269101122,
        "distinct-2-nopunct": 0.948051948051948,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.1628904367988175,
        "cond_entropy-2-nopunct": 0.6010964878386065,
        "distinct-3-nopunct": 0.965034965034965,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.089941266848326,
        "cond_entropy-3-nopunct": -0.07195016895147689,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.955072623232878,
        "rouge1": {
            "precision": 0.81799,
            "recall": 0.74429,
            "fmeasure": 0.77122
        },
        "rouge2": {
            "precision": 0.57924,
            "recall": 0.53202,
            "fmeasure": 0.54683
        },
        "rougeL": {
            "precision": 0.68692,
            "recall": 0.61847,
            "fmeasure": 0.64199
        },
        "rougeLsum": {
            "precision": 0.68692,
            "recall": 0.61847,
            "fmeasure": 0.64199
        },
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.42105263157894735,
            "3": 0.7573529411764706
        },
        "bleu": 43.68308,
        "nubia": {
            "semantic_relation": 4.20435,
            "contradiction": 19.11374,
            "irrelevancy": 29.75685,
            "logical_agreement": 51.12941,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.56909,
            "nubia_score": 0.68566
        },
        "meteor": 0.4094599602787328,
        "bleurt": 0.21762,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.92518,
            "f1": 0.92171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 62,
        "total_length": 1080,
        "mean_pred_length": 17.419354838709676,
        "std_pred_length": 8.063354755084731,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.4537037037037037,
        "vocab_size-1": 490,
        "unique-1": 366,
        "entropy-1": 7.781423905527194,
        "distinct-2": 0.825147347740668,
        "vocab_size-2": 840,
        "unique-2": 737,
        "entropy-2": 9.543781423523772,
        "cond_entropy-2": 1.5467772697480362,
        "distinct-3": 0.9215481171548117,
        "vocab_size-3": 881,
        "unique-3": 826,
        "entropy-3": 9.724540003555832,
        "cond_entropy-3": 0.16808661687023502,
        "total_length-nopunct": 915,
        "mean_pred_length-nopunct": 14.758064516129032,
        "std_pred_length-nopunct": 6.226078048563591,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5256830601092897,
        "vocab_size-1-nopunct": 481,
        "unique-1-nopunct": 362,
        "entropy-1-nopunct": 8.057904393507819,
        "distinct-2-nopunct": 0.8487690504103166,
        "vocab_size-2-nopunct": 724,
        "unique-2-nopunct": 652,
        "entropy-2-nopunct": 9.339091383641502,
        "cond_entropy-2-nopunct": 1.343750761259656,
        "distinct-3-nopunct": 0.934260429835651,
        "vocab_size-3-nopunct": 739,
        "unique-3-nopunct": 700,
        "entropy-3-nopunct": 9.482408742223196,
        "cond_entropy-3-nopunct": 0.14052231992634975,
        "msttr-100": 0.702,
        "msttr-100_nopunct": 0.76111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.377459851598644,
        "rouge1": {
            "precision": 0.78787,
            "recall": 0.76967,
            "fmeasure": 0.76702
        },
        "rouge2": {
            "precision": 0.56593,
            "recall": 0.56431,
            "fmeasure": 0.55781
        },
        "rougeL": {
            "precision": 0.68806,
            "recall": 0.67425,
            "fmeasure": 0.67081
        },
        "rougeLsum": {
            "precision": 0.68806,
            "recall": 0.67425,
            "fmeasure": 0.67081
        },
        "local_recall": {
            "1": 0.16279069767441862,
            "2": 0.4180790960451977,
            "3": 0.8221574344023324
        },
        "bleu": 50.76239,
        "nubia": {
            "semantic_relation": 4.26981,
            "contradiction": 4.94418,
            "irrelevancy": 27.59911,
            "logical_agreement": 67.45671,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.44049,
            "nubia_score": 0.76311
        },
        "meteor": 0.40996436244129747,
        "bleurt": 0.30666,
        "bertscore": {
            "precision": 0.93016,
            "recall": 0.92661,
            "f1": 0.92596
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 105,
        "total_length": 1718,
        "mean_pred_length": 16.36190476190476,
        "std_pred_length": 11.033389851264086,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 109,
        "distinct-1": 0.44062863795110596,
        "vocab_size-1": 757,
        "unique-1": 598,
        "entropy-1": 7.920292591310023,
        "distinct-2": 0.8214507129572226,
        "vocab_size-2": 1325,
        "unique-2": 1206,
        "entropy-2": 10.099970672779985,
        "cond_entropy-2": 1.9301255382548748,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 1404,
        "unique-3": 1350,
        "entropy-3": 10.379852575477338,
        "cond_entropy-3": 0.2983328511624009,
        "total_length-nopunct": 1467,
        "mean_pred_length-nopunct": 13.971428571428572,
        "std_pred_length-nopunct": 8.038546590803403,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.5105657805044308,
        "vocab_size-1-nopunct": 749,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 8.269645940740627,
        "distinct-2-nopunct": 0.8546255506607929,
        "vocab_size-2-nopunct": 1164,
        "unique-2-nopunct": 1076,
        "entropy-2-nopunct": 9.95193407429881,
        "cond_entropy-2-nopunct": 1.8025621542692618,
        "distinct-3-nopunct": 0.9705648369132857,
        "vocab_size-3-nopunct": 1220,
        "unique-3-nopunct": 1192,
        "entropy-3-nopunct": 10.228963708922397,
        "cond_entropy-3-nopunct": 0.29793520026895765,
        "msttr-100": 0.68235,
        "msttr-100_nopunct": 0.75143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.460989381846608,
        "rouge1": {
            "precision": 0.80729,
            "recall": 0.74942,
            "fmeasure": 0.76852
        },
        "rouge2": {
            "precision": 0.55202,
            "recall": 0.50762,
            "fmeasure": 0.52221
        },
        "rougeL": {
            "precision": 0.69179,
            "recall": 0.64267,
            "fmeasure": 0.6586
        },
        "rougeLsum": {
            "precision": 0.69179,
            "recall": 0.64267,
            "fmeasure": 0.6586
        },
        "local_recall": {
            "1": 0.1962025316455696,
            "2": 0.3305084745762712,
            "3": 0.7771135781383433
        },
        "bleu": 43.86183,
        "nubia": {
            "semantic_relation": 4.4141,
            "contradiction": 6.85759,
            "irrelevancy": 24.0253,
            "logical_agreement": 69.11711,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.05398,
            "nubia_score": 0.77983
        },
        "meteor": 0.3893801111477805,
        "bleurt": 0.34678,
        "bertscore": {
            "precision": 0.93673,
            "recall": 0.93049,
            "f1": 0.93265
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 291,
        "mean_pred_length": 17.11764705882353,
        "std_pred_length": 8.043136298888099,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.5429553264604811,
        "vocab_size-1": 158,
        "unique-1": 124,
        "entropy-1": 6.535845488683413,
        "distinct-2": 0.8832116788321168,
        "vocab_size-2": 242,
        "unique-2": 223,
        "entropy-2": 7.810911519226701,
        "cond_entropy-2": 1.1186601272488172,
        "distinct-3": 0.9571984435797666,
        "vocab_size-3": 246,
        "unique-3": 238,
        "entropy-3": 7.911209519985771,
        "cond_entropy-3": 0.11150831042232637,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 15.058823529411764,
        "std_pred_length-nopunct": 7.0666623142029215,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.59765625,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.614440151493586,
        "distinct-2-nopunct": 0.891213389121339,
        "vocab_size-2-nopunct": 213,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.625067029901741,
        "cond_entropy-2-nopunct": 1.0785456622144778,
        "distinct-3-nopunct": 0.963963963963964,
        "vocab_size-3-nopunct": 214,
        "unique-3-nopunct": 208,
        "entropy-3-nopunct": 7.715543005970242,
        "cond_entropy-3-nopunct": 0.11159577889443245,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.549272199447519,
        "rouge1": {
            "precision": 0.67926,
            "recall": 0.61351,
            "fmeasure": 0.62931
        },
        "rouge2": {
            "precision": 0.46746,
            "recall": 0.4198,
            "fmeasure": 0.43289
        },
        "rougeL": {
            "precision": 0.59284,
            "recall": 0.54339,
            "fmeasure": 0.55368
        },
        "rougeLsum": {
            "precision": 0.59284,
            "recall": 0.54339,
            "fmeasure": 0.55368
        },
        "local_recall": {
            "1": 0.18421052631578946,
            "2": 0.4375,
            "3": 0.7309941520467836
        },
        "bleu": 48.25555,
        "nubia": {
            "semantic_relation": 3.88567,
            "contradiction": 12.08596,
            "irrelevancy": 18.47831,
            "logical_agreement": 69.43573,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.33869,
            "nubia_score": 0.64164
        },
        "meteor": 0.3581393700720585,
        "bleurt": 0.17392,
        "bertscore": {
            "precision": 0.90719,
            "recall": 0.8913,
            "f1": 0.89825
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 232,
        "mean_pred_length": 16.571428571428573,
        "std_pred_length": 7.41344614018807,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.6508620689655172,
        "vocab_size-1": 151,
        "unique-1": 126,
        "entropy-1": 6.745193423298718,
        "distinct-2": 0.963302752293578,
        "vocab_size-2": 210,
        "unique-2": 203,
        "entropy-2": 7.691327042656898,
        "cond_entropy-2": 0.7730880097104642,
        "distinct-3": 0.9950980392156863,
        "vocab_size-3": 203,
        "unique-3": 202,
        "entropy-3": 7.662621420402869,
        "cond_entropy-3": -0.023431102892864823,
        "total_length-nopunct": 203,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 6.400334812670796,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7192118226600985,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.853463996246879,
        "distinct-2-nopunct": 0.9682539682539683,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.494756246960957,
        "cond_entropy-2-nopunct": 0.6877538612559498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 175,
        "unique-3-nopunct": 175,
        "entropy-3-nopunct": 7.451211111832307,
        "cond_entropy-3-nopunct": -0.04386052666209574,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.711616525990231,
        "rouge1": {
            "precision": 0.74717,
            "recall": 0.65071,
            "fmeasure": 0.67928
        },
        "rouge2": {
            "precision": 0.47879,
            "recall": 0.41395,
            "fmeasure": 0.42946
        },
        "rougeL": {
            "precision": 0.65264,
            "recall": 0.58111,
            "fmeasure": 0.59836
        },
        "rougeLsum": {
            "precision": 0.65264,
            "recall": 0.58111,
            "fmeasure": 0.59836
        },
        "local_recall": {
            "1": 0.15254237288135594,
            "2": 0.2391304347826087,
            "3": 0.6848484848484848
        },
        "bleu": 31.20349,
        "nubia": {
            "semantic_relation": 3.80697,
            "contradiction": 13.96438,
            "irrelevancy": 24.74353,
            "logical_agreement": 61.2921,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.64936,
            "nubia_score": 0.61133
        },
        "meteor": 0.31077218653375,
        "bleurt": 0.08875,
        "bertscore": {
            "precision": 0.90528,
            "recall": 0.89635,
            "f1": 0.89707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 3.3135467156409146,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6442307692307693,
        "vocab_size-1": 67,
        "unique-1": 51,
        "entropy-1": 5.739553570142087,
        "distinct-2": 0.9381443298969072,
        "vocab_size-2": 91,
        "unique-2": 85,
        "entropy-2": 6.476201501980956,
        "cond_entropy-2": 0.6033976079377257,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 88,
        "unique-3": 86,
        "entropy-3": 6.447408651885219,
        "cond_entropy-3": -0.019170856968564305,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 3.238795442501324,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6989247311827957,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.761947252640359,
        "distinct-2-nopunct": 0.9418604651162791,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.309985684934657,
        "cond_entropy-2-nopunct": 0.6112998382160887,
        "distinct-3-nopunct": 0.9746835443037974,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.2531478367847,
        "cond_entropy-3-nopunct": -0.04653463943638748,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.59937704525649,
        "rouge1": {
            "precision": 0.6621,
            "recall": 0.65309,
            "fmeasure": 0.65256
        },
        "rouge2": {
            "precision": 0.37559,
            "recall": 0.35114,
            "fmeasure": 0.36036
        },
        "rougeL": {
            "precision": 0.54994,
            "recall": 0.53315,
            "fmeasure": 0.53799
        },
        "rougeLsum": {
            "precision": 0.54994,
            "recall": 0.53315,
            "fmeasure": 0.53799
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.23076923076923078,
            "3": 0.6133333333333333
        },
        "bleu": 22.70197,
        "nubia": {
            "semantic_relation": 4.11864,
            "contradiction": 4.20322,
            "irrelevancy": 31.25522,
            "logical_agreement": 64.54157,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.46183,
            "nubia_score": 0.71037
        },
        "meteor": 0.28779595094882693,
        "bleurt": 0.16453,
        "bertscore": {
            "precision": 0.89478,
            "recall": 0.88852,
            "f1": 0.88839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 48,
        "total_length": 732,
        "mean_pred_length": 15.25,
        "std_pred_length": 6.115213269652444,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5368852459016393,
        "vocab_size-1": 393,
        "unique-1": 322,
        "entropy-1": 7.518847415710139,
        "distinct-2": 0.8976608187134503,
        "vocab_size-2": 614,
        "unique-2": 570,
        "entropy-2": 9.153873933197334,
        "cond_entropy-2": 1.3832293190206189,
        "distinct-3": 0.9748427672955975,
        "vocab_size-3": 620,
        "unique-3": 606,
        "entropy-3": 9.2601946298057,
        "cond_entropy-3": 0.11247806204703788,
        "total_length-nopunct": 635,
        "mean_pred_length-nopunct": 13.229166666666666,
        "std_pred_length-nopunct": 5.420791698533424,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6110236220472441,
        "vocab_size-1-nopunct": 388,
        "unique-1-nopunct": 321,
        "entropy-1-nopunct": 7.791336168283215,
        "distinct-2-nopunct": 0.9028960817717206,
        "vocab_size-2-nopunct": 530,
        "unique-2-nopunct": 496,
        "entropy-2-nopunct": 8.937767481238758,
        "cond_entropy-2-nopunct": 1.23813581029275,
        "distinct-3-nopunct": 0.9851576994434137,
        "vocab_size-3-nopunct": 531,
        "unique-3-nopunct": 524,
        "entropy-3-nopunct": 9.0430563282401,
        "cond_entropy-3-nopunct": 0.11726206067461273,
        "msttr-100": 0.70857,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.801486778055978,
        "rouge1": {
            "precision": 0.79139,
            "recall": 0.71591,
            "fmeasure": 0.73898
        },
        "rouge2": {
            "precision": 0.52366,
            "recall": 0.48811,
            "fmeasure": 0.49685
        },
        "rougeL": {
            "precision": 0.63317,
            "recall": 0.56988,
            "fmeasure": 0.59005
        },
        "rougeLsum": {
            "precision": 0.63317,
            "recall": 0.56988,
            "fmeasure": 0.59005
        },
        "local_recall": {
            "1": 0.1610738255033557,
            "2": 0.3625,
            "3": 0.7643564356435644
        },
        "bleu": 41.8806,
        "nubia": {
            "semantic_relation": 4.14913,
            "contradiction": 11.30452,
            "irrelevancy": 18.98184,
            "logical_agreement": 69.71364,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.99197,
            "nubia_score": 0.70099
        },
        "meteor": 0.3752850856309424,
        "bleurt": 0.22721,
        "bertscore": {
            "precision": 0.92494,
            "recall": 0.91637,
            "f1": 0.91947
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 79,
        "total_length": 1309,
        "mean_pred_length": 16.569620253164558,
        "std_pred_length": 4.900745343219078,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.4514896867838044,
        "vocab_size-1": 591,
        "unique-1": 459,
        "entropy-1": 7.854730013685217,
        "distinct-2": 0.8357723577235773,
        "vocab_size-2": 1028,
        "unique-2": 935,
        "entropy-2": 9.801973805188688,
        "cond_entropy-2": 1.7029050524681735,
        "distinct-3": 0.952215464813206,
        "vocab_size-3": 1096,
        "unique-3": 1058,
        "entropy-3": 10.059933181992932,
        "cond_entropy-3": 0.26514475673616145,
        "total_length-nopunct": 1139,
        "mean_pred_length-nopunct": 14.417721518987342,
        "std_pred_length-nopunct": 4.510487343330769,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5136084284460053,
        "vocab_size-1-nopunct": 585,
        "unique-1-nopunct": 459,
        "entropy-1-nopunct": 8.148653245552323,
        "distinct-2-nopunct": 0.8537735849056604,
        "vocab_size-2-nopunct": 905,
        "unique-2-nopunct": 839,
        "entropy-2-nopunct": 9.620057759893657,
        "cond_entropy-2-nopunct": 1.5521762224980309,
        "distinct-3-nopunct": 0.9622833843017329,
        "vocab_size-3-nopunct": 944,
        "unique-3-nopunct": 917,
        "entropy-3-nopunct": 9.853981573912563,
        "cond_entropy-3-nopunct": 0.25205179299283914,
        "msttr-100": 0.70923,
        "msttr-100_nopunct": 0.76636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.517937960339714,
        "rouge1": {
            "precision": 0.8253,
            "recall": 0.77412,
            "fmeasure": 0.79094
        },
        "rouge2": {
            "precision": 0.60399,
            "recall": 0.57024,
            "fmeasure": 0.58014
        },
        "rougeL": {
            "precision": 0.69033,
            "recall": 0.64681,
            "fmeasure": 0.66115
        },
        "rougeLsum": {
            "precision": 0.69033,
            "recall": 0.64681,
            "fmeasure": 0.66115
        },
        "local_recall": {
            "1": 0.16287878787878787,
            "2": 0.4223300970873786,
            "3": 0.7810140237324703
        },
        "bleu": 44.72762,
        "nubia": {
            "semantic_relation": 4.38622,
            "contradiction": 12.00177,
            "irrelevancy": 21.73488,
            "logical_agreement": 66.26335,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.92902,
            "nubia_score": 0.75524
        },
        "meteor": 0.402764689224916,
        "bleurt": 0.3348,
        "bertscore": {
            "precision": 0.93917,
            "recall": 0.93408,
            "f1": 0.93545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 57,
        "total_length": 1000,
        "mean_pred_length": 17.54385964912281,
        "std_pred_length": 10.45637583627446,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 75,
        "distinct-1": 0.473,
        "vocab_size-1": 473,
        "unique-1": 366,
        "entropy-1": 7.6804855186928185,
        "distinct-2": 0.8377518557794273,
        "vocab_size-2": 790,
        "unique-2": 715,
        "entropy-2": 9.427821062621485,
        "cond_entropy-2": 1.5329000177917493,
        "distinct-3": 0.9356659142212189,
        "vocab_size-3": 829,
        "unique-3": 791,
        "entropy-3": 9.636447982889532,
        "cond_entropy-3": 0.22565040524197585,
        "total_length-nopunct": 872,
        "mean_pred_length-nopunct": 15.298245614035087,
        "std_pred_length-nopunct": 7.9889505102649885,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.533256880733945,
        "vocab_size-1-nopunct": 465,
        "unique-1-nopunct": 362,
        "entropy-1-nopunct": 7.881373396372318,
        "distinct-2-nopunct": 0.8576687116564418,
        "vocab_size-2-nopunct": 699,
        "unique-2-nopunct": 640,
        "entropy-2-nopunct": 9.275203557823104,
        "cond_entropy-2-nopunct": 1.49147312623113,
        "distinct-3-nopunct": 0.9485488126649076,
        "vocab_size-3-nopunct": 719,
        "unique-3-nopunct": 688,
        "entropy-3-nopunct": 9.453891043436684,
        "cond_entropy-3-nopunct": 0.2050144525044489,
        "msttr-100": 0.666,
        "msttr-100_nopunct": 0.71875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.447869615774371,
        "rouge1": {
            "precision": 0.73569,
            "recall": 0.73441,
            "fmeasure": 0.72225
        },
        "rouge2": {
            "precision": 0.51351,
            "recall": 0.51695,
            "fmeasure": 0.50488
        },
        "rougeL": {
            "precision": 0.6284,
            "recall": 0.62591,
            "fmeasure": 0.61615
        },
        "rougeLsum": {
            "precision": 0.6284,
            "recall": 0.62591,
            "fmeasure": 0.61615
        },
        "local_recall": {
            "1": 0.2350230414746544,
            "2": 0.4634146341463415,
            "3": 0.7855787476280834
        },
        "bleu": 40.17334,
        "nubia": {
            "semantic_relation": 4.05971,
            "contradiction": 17.77974,
            "irrelevancy": 28.97279,
            "logical_agreement": 53.24747,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.73223,
            "nubia_score": 0.68322
        },
        "meteor": 0.3792526784847148,
        "bleurt": 0.12973,
        "bertscore": {
            "precision": 0.91339,
            "recall": 0.91527,
            "f1": 0.9118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4095441336664445,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rouge2": {
            "precision": 0.57576,
            "recall": 0.7037,
            "fmeasure": 0.63333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.75
        },
        "bleu": 37.59664,
        "nubia": {
            "semantic_relation": 3.8676,
            "contradiction": 0.39743,
            "irrelevancy": 97.60153,
            "logical_agreement": 2.00104,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.9179,
            "nubia_score": 0.54045
        },
        "meteor": 0.37720889387522405,
        "bleurt": -0.20728,
        "bertscore": {
            "precision": 0.87773,
            "recall": 0.89635,
            "f1": 0.88694
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 24,
        "total_length": 420,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 245,
        "unique-1": 203,
        "entropy-1": 7.062837445296318,
        "distinct-2": 0.9141414141414141,
        "vocab_size-2": 362,
        "unique-2": 344,
        "entropy-2": 8.407159193609875,
        "cond_entropy-2": 1.1665305708376397,
        "distinct-3": 0.9704301075268817,
        "vocab_size-3": 361,
        "unique-3": 354,
        "entropy-3": 8.468286424074202,
        "cond_entropy-3": 0.07008620421508957,
        "total_length-nopunct": 356,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 4.258977446393546,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6685393258426966,
        "vocab_size-1-nopunct": 238,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 7.294659190090899,
        "distinct-2-nopunct": 0.9186746987951807,
        "vocab_size-2-nopunct": 305,
        "unique-2-nopunct": 289,
        "entropy-2-nopunct": 8.171648505336877,
        "cond_entropy-2-nopunct": 0.9377599681965321,
        "distinct-3-nopunct": 0.9837662337662337,
        "vocab_size-3-nopunct": 303,
        "unique-3-nopunct": 298,
        "entropy-3-nopunct": 8.234319008227327,
        "cond_entropy-3-nopunct": 0.07527239322891982,
        "msttr-100": 0.6975,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.322005653743131,
        "rouge1": {
            "precision": 0.76787,
            "recall": 0.72333,
            "fmeasure": 0.73528
        },
        "rouge2": {
            "precision": 0.49643,
            "recall": 0.46141,
            "fmeasure": 0.4725
        },
        "rougeL": {
            "precision": 0.66736,
            "recall": 0.62989,
            "fmeasure": 0.64074
        },
        "rougeLsum": {
            "precision": 0.66736,
            "recall": 0.62989,
            "fmeasure": 0.64074
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.40860215053763443,
            "3": 0.8189300411522634
        },
        "bleu": 42.0173,
        "nubia": {
            "semantic_relation": 4.23075,
            "contradiction": 4.0833,
            "irrelevancy": 32.96012,
            "logical_agreement": 62.95658,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.70902,
            "nubia_score": 0.73289
        },
        "meteor": 0.38767421510666705,
        "bleurt": 0.15446,
        "bertscore": {
            "precision": 0.92201,
            "recall": 0.91849,
            "f1": 0.91893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 20,
        "total_length": 307,
        "mean_pred_length": 15.35,
        "std_pred_length": 4.714604967545001,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6188925081433225,
        "vocab_size-1": 190,
        "unique-1": 159,
        "entropy-1": 6.859443026913882,
        "distinct-2": 0.9303135888501742,
        "vocab_size-2": 267,
        "unique-2": 256,
        "entropy-2": 7.976617379577019,
        "cond_entropy-2": 0.9088352861598425,
        "distinct-3": 0.9775280898876404,
        "vocab_size-3": 261,
        "unique-3": 256,
        "entropy-3": 8.012924817447207,
        "cond_entropy-3": 0.05041152379517824,
        "total_length-nopunct": 268,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 4.57602447545902,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6902985074626866,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 159,
        "entropy-1-nopunct": 6.970393718687144,
        "distinct-2-nopunct": 0.9314516129032258,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.760490261930012,
        "cond_entropy-2-nopunct": 0.8720681034633527,
        "distinct-3-nopunct": 0.9868421052631579,
        "vocab_size-3-nopunct": 225,
        "unique-3-nopunct": 223,
        "entropy-3-nopunct": 7.803263314593884,
        "cond_entropy-3-nopunct": 0.052813221384985294,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.682154243260232,
        "rouge1": {
            "precision": 0.72148,
            "recall": 0.70697,
            "fmeasure": 0.70503
        },
        "rouge2": {
            "precision": 0.51305,
            "recall": 0.49864,
            "fmeasure": 0.50027
        },
        "rougeL": {
            "precision": 0.64895,
            "recall": 0.63898,
            "fmeasure": 0.63533
        },
        "rougeLsum": {
            "precision": 0.64895,
            "recall": 0.63898,
            "fmeasure": 0.63533
        },
        "local_recall": {
            "1": 0.28,
            "2": 0.5245901639344263,
            "3": 0.6963350785340314
        },
        "bleu": 46.87503,
        "nubia": {
            "semantic_relation": 4.11745,
            "contradiction": 14.11145,
            "irrelevancy": 27.82107,
            "logical_agreement": 58.06748,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.52016,
            "nubia_score": 0.72737
        },
        "meteor": 0.3769526638102301,
        "bleurt": 0.25774,
        "bertscore": {
            "precision": 0.92116,
            "recall": 0.92148,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 29,
        "total_length": 474,
        "mean_pred_length": 16.344827586206897,
        "std_pred_length": 6.326059197499932,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.5822784810126582,
        "vocab_size-1": 276,
        "unique-1": 228,
        "entropy-1": 7.285259080625799,
        "distinct-2": 0.9191011235955057,
        "vocab_size-2": 409,
        "unique-2": 384,
        "entropy-2": 8.613079580938184,
        "cond_entropy-2": 1.1125423286432854,
        "distinct-3": 0.9663461538461539,
        "vocab_size-3": 402,
        "unique-3": 389,
        "entropy-3": 8.63131739241473,
        "cond_entropy-3": 0.02629761052111618,
        "total_length-nopunct": 401,
        "mean_pred_length-nopunct": 13.827586206896552,
        "std_pred_length-nopunct": 4.586855022909386,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6758104738154613,
        "vocab_size-1-nopunct": 271,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.535869828326187,
        "distinct-2-nopunct": 0.9381720430107527,
        "vocab_size-2-nopunct": 349,
        "unique-2-nopunct": 332,
        "entropy-2-nopunct": 8.399711760084074,
        "cond_entropy-2-nopunct": 0.9296515603695356,
        "distinct-3-nopunct": 0.9854227405247813,
        "vocab_size-3-nopunct": 338,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 8.392910247222346,
        "cond_entropy-3-nopunct": -0.0071687447034846545,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.280979000672057,
        "rouge1": {
            "precision": 0.76573,
            "recall": 0.7302,
            "fmeasure": 0.7349
        },
        "rouge2": {
            "precision": 0.52836,
            "recall": 0.49277,
            "fmeasure": 0.50224
        },
        "rougeL": {
            "precision": 0.67817,
            "recall": 0.63971,
            "fmeasure": 0.64782
        },
        "rougeLsum": {
            "precision": 0.67817,
            "recall": 0.63971,
            "fmeasure": 0.64782
        },
        "local_recall": {
            "1": 0.18446601941747573,
            "2": 0.38372093023255816,
            "3": 0.7715231788079471
        },
        "bleu": 42.46448,
        "nubia": {
            "semantic_relation": 4.19419,
            "contradiction": 7.28652,
            "irrelevancy": 31.54999,
            "logical_agreement": 61.16349,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.67286,
            "nubia_score": 0.71562
        },
        "meteor": 0.3797562157003763,
        "bleurt": 0.24819,
        "bertscore": {
            "precision": 0.93026,
            "recall": 0.92756,
            "f1": 0.92767
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 169,
        "total_length": 2855,
        "mean_pred_length": 16.893491124260354,
        "std_pred_length": 7.426994916689035,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 58,
        "distinct-1": 0.3908931698774081,
        "vocab_size-1": 1116,
        "unique-1": 838,
        "entropy-1": 8.346758275686376,
        "distinct-2": 0.7598659717051377,
        "vocab_size-2": 2041,
        "unique-2": 1797,
        "entropy-2": 10.61071399142365,
        "cond_entropy-2": 1.9979415699799346,
        "distinct-3": 0.8816050854191498,
        "vocab_size-3": 2219,
        "unique-3": 2078,
        "entropy-3": 10.954761846248882,
        "cond_entropy-3": 0.3546857827305459,
        "total_length-nopunct": 2485,
        "mean_pred_length-nopunct": 14.70414201183432,
        "std_pred_length-nopunct": 6.716229174397484,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.4450704225352113,
        "vocab_size-1-nopunct": 1106,
        "unique-1-nopunct": 837,
        "entropy-1-nopunct": 8.63468119369769,
        "distinct-2-nopunct": 0.7772020725388601,
        "vocab_size-2-nopunct": 1800,
        "unique-2-nopunct": 1611,
        "entropy-2-nopunct": 10.436229637534266,
        "cond_entropy-2-nopunct": 1.9244801068226562,
        "distinct-3-nopunct": 0.8886818816953889,
        "vocab_size-3-nopunct": 1908,
        "unique-3-nopunct": 1801,
        "entropy-3-nopunct": 10.739688278786405,
        "cond_entropy-3-nopunct": 0.3424556790719116,
        "msttr-100": 0.68679,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.860241293165397,
        "rouge1": {
            "precision": 0.76744,
            "recall": 0.73868,
            "fmeasure": 0.74367
        },
        "rouge2": {
            "precision": 0.54182,
            "recall": 0.52121,
            "fmeasure": 0.52486
        },
        "rougeL": {
            "precision": 0.67084,
            "recall": 0.64584,
            "fmeasure": 0.65022
        },
        "rougeLsum": {
            "precision": 0.67084,
            "recall": 0.64584,
            "fmeasure": 0.65022
        },
        "local_recall": {
            "1": 0.2301255230125523,
            "2": 0.4157303370786517,
            "3": 0.7697649572649573
        },
        "bleu": 45.50658,
        "nubia": {
            "semantic_relation": 4.14617,
            "contradiction": 11.56428,
            "irrelevancy": 29.96091,
            "logical_agreement": 58.47481,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.66307,
            "nubia_score": 0.71759
        },
        "meteor": 0.38965883127519624,
        "bleurt": 0.29993,
        "bertscore": {
            "precision": 0.93144,
            "recall": 0.92435,
            "f1": 0.92675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 624,
        "mean_pred_length": 20.129032258064516,
        "std_pred_length": 7.5209039242413604,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.5448717948717948,
        "vocab_size-1": 340,
        "unique-1": 259,
        "entropy-1": 7.607295293703975,
        "distinct-2": 0.8684654300168634,
        "vocab_size-2": 515,
        "unique-2": 463,
        "entropy-2": 8.909319697577045,
        "cond_entropy-2": 1.141509390064686,
        "distinct-3": 0.9448398576512456,
        "vocab_size-3": 531,
        "unique-3": 507,
        "entropy-3": 9.013831235682167,
        "cond_entropy-3": 0.1091818922044267,
        "total_length-nopunct": 538,
        "mean_pred_length-nopunct": 17.35483870967742,
        "std_pred_length-nopunct": 6.67952281034996,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.620817843866171,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 7.820768397120806,
        "distinct-2-nopunct": 0.8856015779092702,
        "vocab_size-2-nopunct": 449,
        "unique-2-nopunct": 411,
        "entropy-2-nopunct": 8.719779110594013,
        "cond_entropy-2-nopunct": 0.9483531699353747,
        "distinct-3-nopunct": 0.9558823529411765,
        "vocab_size-3-nopunct": 455,
        "unique-3-nopunct": 439,
        "entropy-3-nopunct": 8.797623094176732,
        "cond_entropy-3-nopunct": 0.08676824328588593,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.792,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.953707188995476,
        "rouge1": {
            "precision": 0.805,
            "recall": 0.74462,
            "fmeasure": 0.76505
        },
        "rouge2": {
            "precision": 0.5924,
            "recall": 0.5522,
            "fmeasure": 0.56533
        },
        "rougeL": {
            "precision": 0.70869,
            "recall": 0.65182,
            "fmeasure": 0.6711
        },
        "rougeLsum": {
            "precision": 0.70869,
            "recall": 0.65182,
            "fmeasure": 0.6711
        },
        "local_recall": {
            "1": 0.2897196261682243,
            "2": 0.3291139240506329,
            "3": 0.7762237762237763
        },
        "bleu": 49.53313,
        "nubia": {
            "semantic_relation": 4.20205,
            "contradiction": 9.34751,
            "irrelevancy": 19.68665,
            "logical_agreement": 70.96584,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.66373,
            "nubia_score": 0.73285
        },
        "meteor": 0.40811699823552794,
        "bleurt": 0.31351,
        "bertscore": {
            "precision": 0.93633,
            "recall": 0.93001,
            "f1": 0.93202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 48,
        "total_length": 801,
        "mean_pred_length": 16.6875,
        "std_pred_length": 6.8773670167683605,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.5081148564294632,
        "vocab_size-1": 407,
        "unique-1": 316,
        "entropy-1": 7.617106422001127,
        "distinct-2": 0.8871181938911022,
        "vocab_size-2": 668,
        "unique-2": 610,
        "entropy-2": 9.288228141699344,
        "cond_entropy-2": 1.44441826214836,
        "distinct-3": 0.9659574468085106,
        "vocab_size-3": 681,
        "unique-3": 657,
        "entropy-3": 9.393394340903168,
        "cond_entropy-3": 0.11385052873646959,
        "total_length-nopunct": 693,
        "mean_pred_length-nopunct": 14.4375,
        "std_pred_length-nopunct": 5.919270260485381,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5800865800865801,
        "vocab_size-1-nopunct": 402,
        "unique-1-nopunct": 316,
        "entropy-1-nopunct": 7.8514582555136325,
        "distinct-2-nopunct": 0.889922480620155,
        "vocab_size-2-nopunct": 574,
        "unique-2-nopunct": 526,
        "entropy-2-nopunct": 9.068808848816037,
        "cond_entropy-2-nopunct": 1.3006875045505897,
        "distinct-3-nopunct": 0.9681742043551089,
        "vocab_size-3-nopunct": 578,
        "unique-3-nopunct": 559,
        "entropy-3-nopunct": 9.157935529975083,
        "cond_entropy-3-nopunct": 0.10703058747683185,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.151147159168931,
        "rouge1": {
            "precision": 0.74906,
            "recall": 0.66402,
            "fmeasure": 0.69442
        },
        "rouge2": {
            "precision": 0.48967,
            "recall": 0.43871,
            "fmeasure": 0.45593
        },
        "rougeL": {
            "precision": 0.62061,
            "recall": 0.56416,
            "fmeasure": 0.58182
        },
        "rougeLsum": {
            "precision": 0.62061,
            "recall": 0.56416,
            "fmeasure": 0.58182
        },
        "local_recall": {
            "1": 0.2046783625730994,
            "2": 0.5641025641025641,
            "3": 0.6640926640926641
        },
        "bleu": 34.82253,
        "nubia": {
            "semantic_relation": 4.00776,
            "contradiction": 11.48318,
            "irrelevancy": 36.95063,
            "logical_agreement": 51.56619,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.63475,
            "nubia_score": 0.68192
        },
        "meteor": 0.34245431986970426,
        "bleurt": 0.12359,
        "bertscore": {
            "precision": 0.91555,
            "recall": 0.89964,
            "f1": 0.90547
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 36,
        "total_length": 573,
        "mean_pred_length": 15.916666666666666,
        "std_pred_length": 6.043246919771965,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 39,
        "distinct-1": 0.5497382198952879,
        "vocab_size-1": 315,
        "unique-1": 262,
        "entropy-1": 7.318473847822382,
        "distinct-2": 0.9050279329608939,
        "vocab_size-2": 486,
        "unique-2": 464,
        "entropy-2": 8.810100688747884,
        "cond_entropy-2": 1.2686542697182512,
        "distinct-3": 0.9600798403193613,
        "vocab_size-3": 481,
        "unique-3": 475,
        "entropy-3": 8.852421621623218,
        "cond_entropy-3": 0.052924512142045424,
        "total_length-nopunct": 495,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 5.084699270032267,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6242424242424243,
        "vocab_size-1-nopunct": 309,
        "unique-1-nopunct": 260,
        "entropy-1-nopunct": 7.537100032731742,
        "distinct-2-nopunct": 0.9084967320261438,
        "vocab_size-2-nopunct": 417,
        "unique-2-nopunct": 399,
        "entropy-2-nopunct": 8.592578659505202,
        "cond_entropy-2-nopunct": 1.1317658398390935,
        "distinct-3-nopunct": 0.9645390070921985,
        "vocab_size-3-nopunct": 408,
        "unique-3-nopunct": 403,
        "entropy-3-nopunct": 8.623499536445689,
        "cond_entropy-3-nopunct": 0.049813975334731926,
        "msttr-100": 0.688,
        "msttr-100_nopunct": 0.7325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.344156477287857,
        "rouge1": {
            "precision": 0.71424,
            "recall": 0.71987,
            "fmeasure": 0.70179
        },
        "rouge2": {
            "precision": 0.47928,
            "recall": 0.49009,
            "fmeasure": 0.47228
        },
        "rougeL": {
            "precision": 0.59655,
            "recall": 0.60827,
            "fmeasure": 0.58915
        },
        "rougeLsum": {
            "precision": 0.59655,
            "recall": 0.60827,
            "fmeasure": 0.58915
        },
        "local_recall": {
            "1": 0.1728395061728395,
            "2": 0.5084745762711864,
            "3": 0.7507692307692307
        },
        "bleu": 42.51775,
        "nubia": {
            "semantic_relation": 4.16014,
            "contradiction": 6.21463,
            "irrelevancy": 39.9511,
            "logical_agreement": 53.83426,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.4022,
            "nubia_score": 0.72655
        },
        "meteor": 0.38625033916760704,
        "bleurt": 0.23548,
        "bertscore": {
            "precision": 0.92018,
            "recall": 0.91928,
            "f1": 0.9173
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1510,
        "total_length": 36703,
        "mean_pred_length": 24.306622516556292,
        "std_pred_length": 12.391383295796079,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 89,
        "distinct-1": 0.05642590523935373,
        "vocab_size-1": 2071,
        "unique-1": 731,
        "entropy-1": 7.899483194964684,
        "distinct-2": 0.18364447475350212,
        "vocab_size-2": 6463,
        "unique-2": 3104,
        "entropy-2": 11.124143519557519,
        "cond_entropy-2": 3.0592664613978604,
        "distinct-3": 0.32292254252887215,
        "vocab_size-3": 10877,
        "unique-3": 6403,
        "entropy-3": 12.337983035868035,
        "cond_entropy-3": 1.28473083498564,
        "total_length-nopunct": 32316,
        "mean_pred_length-nopunct": 21.40132450331126,
        "std_pred_length-nopunct": 11.131448123157142,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.06377645748236167,
        "vocab_size-1-nopunct": 2061,
        "unique-1-nopunct": 730,
        "entropy-1-nopunct": 8.19609495221851,
        "distinct-2-nopunct": 0.19551386093618126,
        "vocab_size-2-nopunct": 6023,
        "unique-2-nopunct": 3052,
        "entropy-2-nopunct": 11.0238359868231,
        "cond_entropy-2-nopunct": 2.9825235696942594,
        "distinct-3-nopunct": 0.3373498088476242,
        "vocab_size-3-nopunct": 9883,
        "unique-3-nopunct": 6042,
        "entropy-3-nopunct": 12.194238274975973,
        "cond_entropy-3-nopunct": 1.248560727524528,
        "msttr-100": 0.49662,
        "msttr-100_nopunct": 0.51105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.422923926193906,
        "rouge1": {
            "precision": 0.64364,
            "recall": 0.64792,
            "fmeasure": 0.63823
        },
        "rouge2": {
            "precision": 0.39013,
            "recall": 0.39045,
            "fmeasure": 0.3853
        },
        "rougeL": {
            "precision": 0.5198,
            "recall": 0.52719,
            "fmeasure": 0.51684
        },
        "rougeLsum": {
            "precision": 0.5198,
            "recall": 0.52719,
            "fmeasure": 0.51684
        },
        "local_recall": {
            "1": 0.22687161969826358,
            "2": 0.5471809389006841,
            "3": 0.7273074231919089,
            "4": 0.9411764705882353,
            "5": 0.42857142857142855
        },
        "bleu": 39.3912,
        "nubia": {
            "semantic_relation": 3.6058,
            "contradiction": 36.69161,
            "irrelevancy": 9.47479,
            "logical_agreement": 53.8336,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.71242,
            "nubia_score": 0.56883
        },
        "meteor": 0.324987575772061,
        "bleurt": -0.16102,
        "bertscore": {
            "precision": 0.88327,
            "recall": 0.88595,
            "f1": 0.88343
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 269,
        "total_length": 9169,
        "mean_pred_length": 34.08550185873606,
        "std_pred_length": 10.392847386195347,
        "median_pred_length": 33.0,
        "min_pred_length": 12,
        "max_pred_length": 76,
        "distinct-1": 0.11844257825280838,
        "vocab_size-1": 1086,
        "unique-1": 488,
        "entropy-1": 7.302999373515008,
        "distinct-2": 0.3350561797752809,
        "vocab_size-2": 2982,
        "unique-2": 1784,
        "entropy-2": 10.357181756641689,
        "cond_entropy-2": 2.9624422466886324,
        "distinct-3": 0.5451280268798517,
        "vocab_size-3": 4705,
        "unique-3": 3358,
        "entropy-3": 11.618747027419671,
        "cond_entropy-3": 1.3097866109140985,
        "total_length-nopunct": 8052,
        "mean_pred_length-nopunct": 29.933085501858734,
        "std_pred_length-nopunct": 9.40513099285116,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.13375558867362147,
        "vocab_size-1-nopunct": 1077,
        "unique-1-nopunct": 487,
        "entropy-1-nopunct": 7.524118202238153,
        "distinct-2-nopunct": 0.35808814081973533,
        "vocab_size-2-nopunct": 2787,
        "unique-2-nopunct": 1749,
        "entropy-2-nopunct": 10.306200533034596,
        "cond_entropy-2-nopunct": 2.8920213799297434,
        "distinct-3-nopunct": 0.5645461804631354,
        "vocab_size-3-nopunct": 4242,
        "unique-3-nopunct": 3113,
        "entropy-3-nopunct": 11.485597535959332,
        "cond_entropy-3-nopunct": 1.2253786571053313,
        "msttr-100": 0.51495,
        "msttr-100_nopunct": 0.5455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.717258495602686,
        "rouge1": {
            "precision": 0.49056,
            "recall": 0.51439,
            "fmeasure": 0.49261
        },
        "rouge2": {
            "precision": 0.21067,
            "recall": 0.22638,
            "fmeasure": 0.21367
        },
        "rougeL": {
            "precision": 0.35385,
            "recall": 0.37807,
            "fmeasure": 0.35798
        },
        "rougeLsum": {
            "precision": 0.35385,
            "recall": 0.37807,
            "fmeasure": 0.35798
        },
        "local_recall": {
            "1": 0.18033757773171455,
            "2": 0.42495876855415066,
            "3": 0.5337390844138661,
            "4": 0.25,
            "5": 0.625
        },
        "bleu": 17.68326,
        "nubia": {
            "semantic_relation": 2.78755,
            "contradiction": 55.85423,
            "irrelevancy": 17.08645,
            "logical_agreement": 27.05933,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.56608,
            "nubia_score": 0.36505
        },
        "meteor": 0.21999430480116353,
        "bleurt": -0.66241,
        "bertscore": {
            "precision": 0.82112,
            "recall": 0.82645,
            "f1": 0.82266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.793345194191515,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.10003715874966056,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.026442737724814758,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.7068905956085185,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.043321469306228495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0293057523343245,
        "rouge1": {
            "precision": 0.73148,
            "recall": 0.71795,
            "fmeasure": 0.72194
        },
        "rouge2": {
            "precision": 0.47148,
            "recall": 0.46531,
            "fmeasure": 0.46613
        },
        "rougeL": {
            "precision": 0.64352,
            "recall": 0.62963,
            "fmeasure": 0.63415
        },
        "rougeLsum": {
            "precision": 0.64352,
            "recall": 0.62963,
            "fmeasure": 0.63415
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "bleu": 46.62769,
        "nubia": {
            "semantic_relation": 4.17796,
            "contradiction": 0.19646,
            "irrelevancy": 50.10327,
            "logical_agreement": 49.70027,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.2394,
            "nubia_score": 0.70826
        },
        "meteor": 0.3399137956998184,
        "bleurt": 0.28162,
        "bertscore": {
            "precision": 0.87413,
            "recall": 0.90799,
            "f1": 0.88882
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.4565647621309536,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.3829562908893333,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.41269152701913925,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4802218813600216,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.31579,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.45,
            "fmeasure": 0.51429
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "bleu": 24.2812,
        "nubia": {
            "semantic_relation": 3.47895,
            "contradiction": 0.28155,
            "irrelevancy": 51.59638,
            "logical_agreement": 48.12207,
            "grammar_ref": 4.8547,
            "grammar_hyp": 4.55506,
            "nubia_score": 0.49468
        },
        "meteor": 0.21435876958067684,
        "bleurt": -0.4234,
        "bertscore": {
            "precision": 0.89867,
            "recall": 0.84797,
            "f1": 0.86935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 43,
        "total_length": 713,
        "mean_pred_length": 16.58139534883721,
        "std_pred_length": 5.524712170297158,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5133239831697055,
        "vocab_size-1": 366,
        "unique-1": 291,
        "entropy-1": 7.409671860298764,
        "distinct-2": 0.8835820895522388,
        "vocab_size-2": 592,
        "unique-2": 547,
        "entropy-2": 9.07674609752994,
        "cond_entropy-2": 1.4494207385190025,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 608,
        "unique-3": 591,
        "entropy-3": 9.228525779532625,
        "cond_entropy-3": 0.15142086318539855,
        "total_length-nopunct": 620,
        "mean_pred_length-nopunct": 14.418604651162791,
        "std_pred_length-nopunct": 5.012693460348461,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.582258064516129,
        "vocab_size-1-nopunct": 361,
        "unique-1-nopunct": 290,
        "entropy-1-nopunct": 7.609533894554702,
        "distinct-2-nopunct": 0.8908145580589255,
        "vocab_size-2-nopunct": 514,
        "unique-2-nopunct": 480,
        "entropy-2-nopunct": 8.870543335578464,
        "cond_entropy-2-nopunct": 1.3596376983180842,
        "distinct-3-nopunct": 0.9719101123595506,
        "vocab_size-3-nopunct": 519,
        "unique-3-nopunct": 506,
        "entropy-3-nopunct": 9.000770838054606,
        "cond_entropy-3-nopunct": 0.15079120929600656,
        "msttr-100": 0.70143,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.207304301968247,
        "rouge1": {
            "precision": 0.80679,
            "recall": 0.7539,
            "fmeasure": 0.76534
        },
        "rouge2": {
            "precision": 0.56485,
            "recall": 0.53084,
            "fmeasure": 0.53672
        },
        "rougeL": {
            "precision": 0.69498,
            "recall": 0.65282,
            "fmeasure": 0.66298
        },
        "rougeLsum": {
            "precision": 0.69498,
            "recall": 0.65282,
            "fmeasure": 0.66298
        },
        "local_recall": {
            "1": 0.3023255813953488,
            "2": 0.6120689655172413,
            "3": 0.7925764192139738
        },
        "bleu": 47.50426,
        "nubia": {
            "semantic_relation": 4.4192,
            "contradiction": 2.29752,
            "irrelevancy": 26.36876,
            "logical_agreement": 71.33371,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.60075,
            "nubia_score": 0.79787
        },
        "meteor": 0.4181023273604091,
        "bleurt": 0.34928,
        "bertscore": {
            "precision": 0.94094,
            "recall": 0.92972,
            "f1": 0.93369
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1177,
        "total_length": 29838,
        "mean_pred_length": 25.35089209855565,
        "std_pred_length": 12.084455056166165,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 89,
        "distinct-1": 0.06042630203096722,
        "vocab_size-1": 1803,
        "unique-1": 687,
        "entropy-1": 7.466197676728813,
        "distinct-2": 0.20187711524371096,
        "vocab_size-2": 5786,
        "unique-2": 2999,
        "entropy-2": 10.811126815581217,
        "cond_entropy-2": 3.2083482640531846,
        "distinct-3": 0.37090670935817205,
        "vocab_size-3": 10194,
        "unique-3": 6408,
        "entropy-3": 12.267022480396314,
        "cond_entropy-3": 1.5317019464118704,
        "total_length-nopunct": 26224,
        "mean_pred_length-nopunct": 22.2803738317757,
        "std_pred_length-nopunct": 10.907484457584632,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.06841061622940818,
        "vocab_size-1-nopunct": 1794,
        "unique-1-nopunct": 687,
        "entropy-1-nopunct": 7.706384704014924,
        "distinct-2-nopunct": 0.21799017846448676,
        "vocab_size-2-nopunct": 5460,
        "unique-2-nopunct": 2989,
        "entropy-2-nopunct": 10.73298802202484,
        "cond_entropy-2-nopunct": 3.1909205893159966,
        "distinct-3-nopunct": 0.3897779639715124,
        "vocab_size-3-nopunct": 9304,
        "unique-3-nopunct": 6072,
        "entropy-3-nopunct": 12.136898948440844,
        "cond_entropy-3-nopunct": 1.4900201041085115,
        "msttr-100": 0.57768,
        "msttr-100_nopunct": 0.61439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.0776619622478085,
        "rouge1": {
            "precision": 0.52431,
            "recall": 0.55445,
            "fmeasure": 0.53057
        },
        "rouge2": {
            "precision": 0.25271,
            "recall": 0.27038,
            "fmeasure": 0.25657
        },
        "rougeL": {
            "precision": 0.4114,
            "recall": 0.44094,
            "fmeasure": 0.4185
        },
        "rougeLsum": {
            "precision": 0.4114,
            "recall": 0.44094,
            "fmeasure": 0.4185
        },
        "local_recall": {
            "1": 0.20279782589325493,
            "2": 0.4631241410902428,
            "3": 0.5630634356132661,
            "4": 0.5,
            "5": 0.4827586206896552
        },
        "bleu": 20.14258,
        "nubia": {
            "semantic_relation": 2.97608,
            "contradiction": 56.35781,
            "irrelevancy": 12.99286,
            "logical_agreement": 30.64934,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.85856,
            "nubia_score": 0.39565
        },
        "meteor": 0.24108018512155507,
        "bleurt": -0.49412,
        "bertscore": {
            "precision": 0.84033,
            "recall": 0.84857,
            "f1": 0.84321
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 56,
        "total_length": 731,
        "mean_pred_length": 13.053571428571429,
        "std_pred_length": 6.057520835578644,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.3009575923392613,
        "vocab_size-1": 220,
        "unique-1": 151,
        "entropy-1": 6.085267562680735,
        "distinct-2": 0.5896296296296296,
        "vocab_size-2": 398,
        "unique-2": 305,
        "entropy-2": 8.122708371248422,
        "cond_entropy-2": 1.8379621731157112,
        "distinct-3": 0.7544426494345718,
        "vocab_size-3": 467,
        "unique-3": 391,
        "entropy-3": 8.633632280621308,
        "cond_entropy-3": 0.5502430733145245,
        "total_length-nopunct": 623,
        "mean_pred_length-nopunct": 11.125,
        "std_pred_length-nopunct": 5.2408508714847875,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.3467094703049759,
        "vocab_size-1-nopunct": 216,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.219422418055494,
        "distinct-2-nopunct": 0.6031746031746031,
        "vocab_size-2-nopunct": 342,
        "unique-2-nopunct": 266,
        "entropy-2-nopunct": 7.914000542160316,
        "cond_entropy-2-nopunct": 1.8588980340475745,
        "distinct-3-nopunct": 0.7749510763209393,
        "vocab_size-3-nopunct": 396,
        "unique-3-nopunct": 336,
        "entropy-3-nopunct": 8.419356827807695,
        "cond_entropy-3-nopunct": 0.5397438799945938,
        "msttr-100": 0.53286,
        "msttr-100_nopunct": 0.58667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.213744653371704,
        "rouge1": {
            "precision": 0.65717,
            "recall": 0.65085,
            "fmeasure": 0.64521
        },
        "rouge2": {
            "precision": 0.40566,
            "recall": 0.40044,
            "fmeasure": 0.39782
        },
        "rougeL": {
            "precision": 0.55142,
            "recall": 0.55106,
            "fmeasure": 0.54423
        },
        "rougeLsum": {
            "precision": 0.55142,
            "recall": 0.55106,
            "fmeasure": 0.54423
        },
        "local_recall": {
            "1": 0.20809248554913296,
            "2": 0.546875,
            "3": 0.6594202898550725
        },
        "bleu": 33.80039,
        "nubia": {
            "semantic_relation": 3.72266,
            "contradiction": 21.54885,
            "irrelevancy": 14.53743,
            "logical_agreement": 63.91371,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.40962,
            "nubia_score": 0.55637
        },
        "meteor": 0.3275040857585815,
        "bleurt": -0.17462,
        "bertscore": {
            "precision": 0.88107,
            "recall": 0.89159,
            "f1": 0.88532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 36,
        "total_length": 636,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 7.438637868140465,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.5267295597484277,
        "vocab_size-1": 335,
        "unique-1": 272,
        "entropy-1": 7.268685922500756,
        "distinct-2": 0.885,
        "vocab_size-2": 531,
        "unique-2": 491,
        "entropy-2": 8.90728240841985,
        "cond_entropy-2": 1.4510528077994875,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 540,
        "unique-3": 516,
        "entropy-3": 9.054444969419972,
        "cond_entropy-3": 0.1605939548916144,
        "total_length-nopunct": 551,
        "mean_pred_length-nopunct": 15.305555555555555,
        "std_pred_length-nopunct": 7.1134436278720585,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5952813067150635,
        "vocab_size-1-nopunct": 328,
        "unique-1-nopunct": 272,
        "entropy-1-nopunct": 7.422047174576802,
        "distinct-2-nopunct": 0.883495145631068,
        "vocab_size-2-nopunct": 455,
        "unique-2-nopunct": 422,
        "entropy-2-nopunct": 8.67170630315544,
        "cond_entropy-2-nopunct": 1.3526378577496498,
        "distinct-3-nopunct": 0.9582463465553236,
        "vocab_size-3-nopunct": 459,
        "unique-3-nopunct": 439,
        "entropy-3-nopunct": 8.820374538846819,
        "cond_entropy-3-nopunct": 0.17397513231132242,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.779332327703194,
        "rouge1": {
            "precision": 0.78864,
            "recall": 0.71684,
            "fmeasure": 0.73895
        },
        "rouge2": {
            "precision": 0.55035,
            "recall": 0.48872,
            "fmeasure": 0.50914
        },
        "rougeL": {
            "precision": 0.67244,
            "recall": 0.61291,
            "fmeasure": 0.63093
        },
        "rougeLsum": {
            "precision": 0.67244,
            "recall": 0.61291,
            "fmeasure": 0.63093
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.3146067415730337,
            "3": 0.7796610169491526
        },
        "bleu": 44.72477,
        "nubia": {
            "semantic_relation": 4.26105,
            "contradiction": 7.88342,
            "irrelevancy": 25.87576,
            "logical_agreement": 66.24082,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.86941,
            "nubia_score": 0.72207
        },
        "meteor": 0.3716560617010161,
        "bleurt": 0.26286,
        "bertscore": {
            "precision": 0.93531,
            "recall": 0.9226,
            "f1": 0.92687
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 28,
        "total_length": 297,
        "mean_pred_length": 10.607142857142858,
        "std_pred_length": 4.186195730478635,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.38047138047138046,
        "vocab_size-1": 113,
        "unique-1": 71,
        "entropy-1": 5.689369810158398,
        "distinct-2": 0.7286245353159851,
        "vocab_size-2": 196,
        "unique-2": 154,
        "entropy-2": 7.404703082124294,
        "cond_entropy-2": 1.4724898252537173,
        "distinct-3": 0.8464730290456431,
        "vocab_size-3": 204,
        "unique-3": 179,
        "entropy-3": 7.556564427595434,
        "cond_entropy-3": 0.21687902120596866,
        "total_length-nopunct": 261,
        "mean_pred_length-nopunct": 9.321428571428571,
        "std_pred_length-nopunct": 3.391729135796702,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.41762452107279696,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 5.738944862747462,
        "distinct-2-nopunct": 0.6995708154506438,
        "vocab_size-2-nopunct": 163,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 7.120159335914854,
        "cond_entropy-2-nopunct": 1.5855022785351685,
        "distinct-3-nopunct": 0.8292682926829268,
        "vocab_size-3-nopunct": 170,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.280093255696035,
        "cond_entropy-3-nopunct": 0.23431337414210654,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.414125308939451,
        "rouge1": {
            "precision": 0.79997,
            "recall": 0.74585,
            "fmeasure": 0.7653
        },
        "rouge2": {
            "precision": 0.56755,
            "recall": 0.51575,
            "fmeasure": 0.53429
        },
        "rougeL": {
            "precision": 0.69892,
            "recall": 0.64061,
            "fmeasure": 0.66246
        },
        "rougeLsum": {
            "precision": 0.69892,
            "recall": 0.64061,
            "fmeasure": 0.66246
        },
        "local_recall": {
            "1": 0.12244897959183673,
            "2": 0.6595744680851063,
            "3": 0.8222222222222222,
            "4": 1.0
        },
        "bleu": 55.60113,
        "nubia": {
            "semantic_relation": 3.81147,
            "contradiction": 33.21096,
            "irrelevancy": 4.62094,
            "logical_agreement": 62.1681,
            "grammar_ref": 4.67502,
            "grammar_hyp": 5.15664,
            "nubia_score": 0.57204
        },
        "meteor": 0.40130295194565263,
        "bleurt": 0.15645,
        "bertscore": {
            "precision": 0.93335,
            "recall": 0.91947,
            "f1": 0.92462
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 89,
        "mean_pred_length": 14.833333333333334,
        "std_pred_length": 6.282692274990255,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6404494382022472,
        "vocab_size-1": 57,
        "unique-1": 40,
        "entropy-1": 5.552823706388678,
        "distinct-2": 0.927710843373494,
        "vocab_size-2": 77,
        "unique-2": 71,
        "entropy-2": 6.23046111809392,
        "cond_entropy-2": 0.5574890182490898,
        "distinct-3": 0.961038961038961,
        "vocab_size-3": 74,
        "unique-3": 71,
        "entropy-3": 6.188864462772827,
        "cond_entropy-3": -0.030330812729945467,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 5.2094998693625945,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.602898027983686,
        "distinct-2-nopunct": 0.9295774647887324,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.008902049082142,
        "cond_entropy-2-nopunct": 0.42569935314840873,
        "distinct-3-nopunct": 0.9692307692307692,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.960829351489997,
        "cond_entropy-3-nopunct": -0.05045622955315075,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.147912599328558,
        "rouge1": {
            "precision": 0.68259,
            "recall": 0.5157,
            "fmeasure": 0.57678
        },
        "rouge2": {
            "precision": 0.3172,
            "recall": 0.24282,
            "fmeasure": 0.26993
        },
        "rougeL": {
            "precision": 0.53326,
            "recall": 0.4044,
            "fmeasure": 0.45008
        },
        "rougeLsum": {
            "precision": 0.53326,
            "recall": 0.4044,
            "fmeasure": 0.45008
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.46153846153846156,
            "3": 0.5862068965517241
        },
        "bleu": 28.37905,
        "nubia": {
            "semantic_relation": 3.74241,
            "contradiction": 0.66673,
            "irrelevancy": 55.64267,
            "logical_agreement": 43.69061,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.34405,
            "nubia_score": 0.61135
        },
        "meteor": 0.2795308330608764,
        "bleurt": 0.06997,
        "bertscore": {
            "precision": 0.91032,
            "recall": 0.85992,
            "f1": 0.88422
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 24,
        "total_length": 374,
        "mean_pred_length": 15.583333333333334,
        "std_pred_length": 5.415384463626649,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5802139037433155,
        "vocab_size-1": 217,
        "unique-1": 179,
        "entropy-1": 6.9787839212072065,
        "distinct-2": 0.94,
        "vocab_size-2": 329,
        "unique-2": 316,
        "entropy-2": 8.308713103315416,
        "cond_entropy-2": 1.1230593332824959,
        "distinct-3": 1.0,
        "vocab_size-3": 326,
        "unique-3": 326,
        "entropy-3": 8.348728154231113,
        "cond_entropy-3": 0.050505701849445715,
        "total_length-nopunct": 331,
        "mean_pred_length-nopunct": 13.791666666666666,
        "std_pred_length-nopunct": 4.957983180913608,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6435045317220544,
        "vocab_size-1-nopunct": 213,
        "unique-1-nopunct": 179,
        "entropy-1-nopunct": 7.120443048755732,
        "distinct-2-nopunct": 0.9315960912052117,
        "vocab_size-2-nopunct": 286,
        "unique-2-nopunct": 273,
        "entropy-2-nopunct": 8.099637832402951,
        "cond_entropy-2-nopunct": 1.0573897823222551,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 283,
        "unique-3-nopunct": 283,
        "entropy-3-nopunct": 8.14465824283186,
        "cond_entropy-3-nopunct": 0.05526411470879554,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.585321644904017,
        "rouge1": {
            "precision": 0.73732,
            "recall": 0.71141,
            "fmeasure": 0.70598
        },
        "rouge2": {
            "precision": 0.48788,
            "recall": 0.46427,
            "fmeasure": 0.46621
        },
        "rougeL": {
            "precision": 0.67888,
            "recall": 0.64606,
            "fmeasure": 0.64631
        },
        "rougeLsum": {
            "precision": 0.67888,
            "recall": 0.64606,
            "fmeasure": 0.64631
        },
        "local_recall": {
            "1": 0.06382978723404255,
            "2": 0.37209302325581395,
            "3": 0.7468354430379747
        },
        "bleu": 37.22659,
        "nubia": {
            "semantic_relation": 4.02705,
            "contradiction": 14.46489,
            "irrelevancy": 36.92005,
            "logical_agreement": 48.61506,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.71216,
            "nubia_score": 0.64034
        },
        "meteor": 0.36134675345112444,
        "bleurt": 0.16592,
        "bertscore": {
            "precision": 0.91814,
            "recall": 0.91731,
            "f1": 0.9159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 51,
        "total_length": 863,
        "mean_pred_length": 16.92156862745098,
        "std_pred_length": 7.561105680258369,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 56,
        "distinct-1": 0.52954808806489,
        "vocab_size-1": 457,
        "unique-1": 377,
        "entropy-1": 7.666818165540643,
        "distinct-2": 0.9027093596059114,
        "vocab_size-2": 733,
        "unique-2": 679,
        "entropy-2": 9.419045970240132,
        "cond_entropy-2": 1.5269970600258416,
        "distinct-3": 0.9750328515111695,
        "vocab_size-3": 742,
        "unique-3": 723,
        "entropy-3": 9.521818346525977,
        "cond_entropy-3": 0.10139411980712851,
        "total_length-nopunct": 745,
        "mean_pred_length-nopunct": 14.607843137254902,
        "std_pred_length-nopunct": 5.851356240885273,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6067114093959731,
        "vocab_size-1-nopunct": 452,
        "unique-1-nopunct": 376,
        "entropy-1-nopunct": 7.923323324194092,
        "distinct-2-nopunct": 0.9135446685878963,
        "vocab_size-2-nopunct": 634,
        "unique-2-nopunct": 594,
        "entropy-2-nopunct": 9.213463615625832,
        "cond_entropy-2-nopunct": 1.3738431332892067,
        "distinct-3-nopunct": 0.9797822706065319,
        "vocab_size-3-nopunct": 630,
        "unique-3-nopunct": 617,
        "entropy-3-nopunct": 9.288239468540914,
        "cond_entropy-3-nopunct": 0.09018297201908672,
        "msttr-100": 0.71125,
        "msttr-100_nopunct": 0.76571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.311048747440855,
        "rouge1": {
            "precision": 0.77979,
            "recall": 0.74889,
            "fmeasure": 0.75311
        },
        "rouge2": {
            "precision": 0.534,
            "recall": 0.51899,
            "fmeasure": 0.51841
        },
        "rougeL": {
            "precision": 0.65863,
            "recall": 0.64003,
            "fmeasure": 0.63918
        },
        "rougeLsum": {
            "precision": 0.65863,
            "recall": 0.64003,
            "fmeasure": 0.63918
        },
        "local_recall": {
            "1": 0.2708333333333333,
            "2": 0.47101449275362317,
            "3": 0.7721518987341772
        },
        "bleu": 49.29247,
        "nubia": {
            "semantic_relation": 4.24105,
            "contradiction": 4.99681,
            "irrelevancy": 28.87757,
            "logical_agreement": 66.12562,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.79911,
            "nubia_score": 0.72665
        },
        "meteor": 0.3996913440387553,
        "bleurt": 0.29294,
        "bertscore": {
            "precision": 0.93568,
            "recall": 0.93183,
            "f1": 0.93252
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 156,
        "mean_pred_length": 14.181818181818182,
        "std_pred_length": 3.5628941713209863,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6730769230769231,
        "vocab_size-1": 105,
        "unique-1": 89,
        "entropy-1": 6.25213827197266,
        "distinct-2": 0.9724137931034482,
        "vocab_size-2": 141,
        "unique-2": 138,
        "entropy-2": 7.119530555517278,
        "cond_entropy-2": 0.6833381843085755,
        "distinct-3": 1.0,
        "vocab_size-3": 134,
        "unique-3": 134,
        "entropy-3": 7.06608919045778,
        "cond_entropy-3": -0.048484918197733005,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 12.454545454545455,
        "std_pred_length-nopunct": 3.312884937870654,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7518248175182481,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.374415820845425,
        "distinct-2-nopunct": 0.9682539682539683,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.907796689355771,
        "cond_entropy-2-nopunct": 0.5886172088537049,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.84549005094439,
        "cond_entropy-3-nopunct": -0.06435606818890273,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.048911303871835,
        "rouge1": {
            "precision": 0.82856,
            "recall": 0.734,
            "fmeasure": 0.76734
        },
        "rouge2": {
            "precision": 0.59577,
            "recall": 0.52646,
            "fmeasure": 0.55047
        },
        "rougeL": {
            "precision": 0.71179,
            "recall": 0.63056,
            "fmeasure": 0.65878
        },
        "rougeLsum": {
            "precision": 0.71179,
            "recall": 0.63056,
            "fmeasure": 0.65878
        },
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.3181818181818182,
            "3": 0.7301587301587301
        },
        "bleu": 38.2749,
        "nubia": {
            "semantic_relation": 4.31358,
            "contradiction": 9.22212,
            "irrelevancy": 27.54915,
            "logical_agreement": 63.22873,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.57874,
            "nubia_score": 0.75994
        },
        "meteor": 0.39762221914302165,
        "bleurt": 0.21602,
        "bertscore": {
            "precision": 0.92256,
            "recall": 0.92044,
            "f1": 0.91983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4420716805709772,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45363
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.275,
            "fmeasure": 0.30075
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.275,
            "fmeasure": 0.30075
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.375
        },
        "bleu": 6.17579,
        "nubia": {
            "semantic_relation": 3.16555,
            "contradiction": 0.76602,
            "irrelevancy": 1.08894,
            "logical_agreement": 98.14504,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.29167,
            "nubia_score": 0.38239
        },
        "meteor": 0.24054916913817062,
        "bleurt": -0.40049,
        "bertscore": {
            "precision": 0.86158,
            "recall": 0.79596,
            "f1": 0.82747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 119,
        "mean_pred_length": 10.818181818181818,
        "std_pred_length": 2.0810042076835633,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.6470588235294118,
        "vocab_size-1": 77,
        "unique-1": 57,
        "entropy-1": 5.920849534425804,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 96,
        "unique-2": 85,
        "entropy-2": 6.52567558084713,
        "cond_entropy-2": 0.35167699746479175,
        "distinct-3": 0.9278350515463918,
        "vocab_size-3": 90,
        "unique-3": 83,
        "entropy-3": 6.455582945279925,
        "cond_entropy-3": -0.0853366444901196,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 9.545454545454545,
        "std_pred_length-nopunct": 1.9241827716833386,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6952380952380952,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.972831504028361,
        "distinct-2-nopunct": 0.8936170212765957,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.333792176122693,
        "cond_entropy-2-nopunct": 0.3670307960230008,
        "distinct-3-nopunct": 0.9156626506024096,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.2063647325517515,
        "cond_entropy-3-nopunct": -0.09816523355765898,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.482699974673625,
        "rouge1": {
            "precision": 0.72373,
            "recall": 0.64549,
            "fmeasure": 0.66704
        },
        "rouge2": {
            "precision": 0.48034,
            "recall": 0.44537,
            "fmeasure": 0.45044
        },
        "rougeL": {
            "precision": 0.67479,
            "recall": 0.63156,
            "fmeasure": 0.63607
        },
        "rougeLsum": {
            "precision": 0.67479,
            "recall": 0.63156,
            "fmeasure": 0.63607
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.1724137931034483,
            "3": 0.6881720430107527
        },
        "bleu": 40.6271,
        "nubia": {
            "semantic_relation": 4.17451,
            "contradiction": 1.46097,
            "irrelevancy": 35.66957,
            "logical_agreement": 62.86946,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.70854,
            "nubia_score": 0.74397
        },
        "meteor": 0.35620129693039576,
        "bleurt": 0.32158,
        "bertscore": {
            "precision": 0.91876,
            "recall": 0.90489,
            "f1": 0.91018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 81,
        "total_length": 1372,
        "mean_pred_length": 16.938271604938272,
        "std_pred_length": 7.144618416773039,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.45626822157434405,
        "vocab_size-1": 626,
        "unique-1": 480,
        "entropy-1": 8.004119367729501,
        "distinct-2": 0.8412083656080558,
        "vocab_size-2": 1086,
        "unique-2": 979,
        "entropy-2": 9.916012332833796,
        "cond_entropy-2": 1.6625326754289593,
        "distinct-3": 0.9289256198347108,
        "vocab_size-3": 1124,
        "unique-3": 1066,
        "entropy-3": 10.079148377584465,
        "cond_entropy-3": 0.16199390609033876,
        "total_length-nopunct": 1174,
        "mean_pred_length-nopunct": 14.493827160493828,
        "std_pred_length-nopunct": 6.1244772148577455,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5255536626916525,
        "vocab_size-1-nopunct": 617,
        "unique-1-nopunct": 477,
        "entropy-1-nopunct": 8.301127191304438,
        "distinct-2-nopunct": 0.8536139066788655,
        "vocab_size-2-nopunct": 933,
        "unique-2-nopunct": 852,
        "entropy-2-nopunct": 9.70346530945682,
        "cond_entropy-2-nopunct": 1.5047889298054342,
        "distinct-3-nopunct": 0.9318181818181818,
        "vocab_size-3-nopunct": 943,
        "unique-3-nopunct": 897,
        "entropy-3-nopunct": 9.828020168037433,
        "cond_entropy-3-nopunct": 0.14791414956231488,
        "msttr-100": 0.71923,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.599916502111854,
        "rouge1": {
            "precision": 0.78043,
            "recall": 0.72587,
            "fmeasure": 0.73884
        },
        "rouge2": {
            "precision": 0.55382,
            "recall": 0.52211,
            "fmeasure": 0.52918
        },
        "rougeL": {
            "precision": 0.67682,
            "recall": 0.63411,
            "fmeasure": 0.64331
        },
        "rougeLsum": {
            "precision": 0.67682,
            "recall": 0.63411,
            "fmeasure": 0.64331
        },
        "local_recall": {
            "1": 0.20136518771331058,
            "2": 0.4728682170542636,
            "3": 0.7915690866510539
        },
        "bleu": 50.8304,
        "nubia": {
            "semantic_relation": 4.12843,
            "contradiction": 8.52495,
            "irrelevancy": 25.85008,
            "logical_agreement": 65.62498,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.63418,
            "nubia_score": 0.7152
        },
        "meteor": 0.4019193025039439,
        "bleurt": 0.26017,
        "bertscore": {
            "precision": 0.93296,
            "recall": 0.92307,
            "f1": 0.92617
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6442,
        "mean_pred_length": 12.884,
        "std_pred_length": 7.311534996155048,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 43,
        "distinct-1": 0.14622787954051536,
        "vocab_size-1": 942,
        "unique-1": 525,
        "entropy-1": 7.734531332306215,
        "distinct-2": 0.42527768428138674,
        "vocab_size-2": 2527,
        "unique-2": 1683,
        "entropy-2": 10.389698703539171,
        "cond_entropy-2": 2.4272761172818345,
        "distinct-3": 0.6148474825431827,
        "vocab_size-3": 3346,
        "unique-3": 2592,
        "entropy-3": 11.168877824950567,
        "cond_entropy-3": 0.8062589002077293,
        "total_length-nopunct": 5661,
        "mean_pred_length-nopunct": 11.322,
        "std_pred_length-nopunct": 6.711059230851714,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.16392863451686981,
        "vocab_size-1-nopunct": 928,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 7.898618190028181,
        "distinct-2-nopunct": 0.43964347994574693,
        "vocab_size-2-nopunct": 2269,
        "unique-2-nopunct": 1543,
        "entropy-2-nopunct": 10.233389215787906,
        "cond_entropy-2-nopunct": 2.4617179197571986,
        "distinct-3-nopunct": 0.6323466323466324,
        "vocab_size-3-nopunct": 2948,
        "unique-3-nopunct": 2325,
        "entropy-3-nopunct": 11.004171490779779,
        "cond_entropy-3-nopunct": 0.813097038075227,
        "msttr-100": 0.67469,
        "msttr-100_nopunct": 0.69786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.174471477033371,
        "rouge1": {
            "precision": 0.59246,
            "recall": 0.55891,
            "fmeasure": 0.56357
        },
        "rouge2": {
            "precision": 0.3755,
            "recall": 0.35097,
            "fmeasure": 0.35487
        },
        "rougeL": {
            "precision": 0.53122,
            "recall": 0.50055,
            "fmeasure": 0.50516
        },
        "rougeLsum": {
            "precision": 0.53122,
            "recall": 0.50055,
            "fmeasure": 0.50516
        },
        "local_recall": {
            "1": 0.5663238626459822
        },
        "bleu": 32.0106,
        "nubia": {
            "semantic_relation": 3.64666,
            "contradiction": 8.03579,
            "irrelevancy": 19.11964,
            "logical_agreement": 72.84457,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.56688,
            "nubia_score": 0.65255
        },
        "meteor": 0.3146156821687069,
        "bleurt": -0.06869,
        "bertscore": {
            "precision": 0.87622,
            "recall": 0.86506,
            "f1": 0.87011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 215,
        "mean_pred_length": 15.357142857142858,
        "std_pred_length": 6.113300988794174,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.6,
        "vocab_size-1": 129,
        "unique-1": 98,
        "entropy-1": 6.493447248754992,
        "distinct-2": 0.9253731343283582,
        "vocab_size-2": 186,
        "unique-2": 175,
        "entropy-2": 7.480083890300331,
        "cond_entropy-2": 0.8088429574800243,
        "distinct-3": 0.983957219251337,
        "vocab_size-3": 184,
        "unique-3": 181,
        "entropy-3": 7.514808898390291,
        "cond_entropy-3": 0.03682954933223886,
        "total_length-nopunct": 188,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 5.434207600460066,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6648936170212766,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.558279937784709,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 162,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.2799289672475584,
        "cond_entropy-2-nopunct": 0.7720996029862032,
        "distinct-3-nopunct": 0.9875,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.296928094887368,
        "cond_entropy-3-nopunct": 0.011450867633371123,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.219972399923584,
        "rouge1": {
            "precision": 0.7931,
            "recall": 0.69288,
            "fmeasure": 0.72929
        },
        "rouge2": {
            "precision": 0.5382,
            "recall": 0.47231,
            "fmeasure": 0.49513
        },
        "rougeL": {
            "precision": 0.66092,
            "recall": 0.57356,
            "fmeasure": 0.60506
        },
        "rougeLsum": {
            "precision": 0.66092,
            "recall": 0.57356,
            "fmeasure": 0.60506
        },
        "local_recall": {
            "1": 0.14754098360655737,
            "2": 0.45714285714285713,
            "3": 0.6855345911949685
        },
        "bleu": 40.24515,
        "nubia": {
            "semantic_relation": 4.12268,
            "contradiction": 4.29373,
            "irrelevancy": 38.92936,
            "logical_agreement": 56.77691,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.65462,
            "nubia_score": 0.71959
        },
        "meteor": 0.3736774650902939,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.92985,
            "recall": 0.9169,
            "f1": 0.92164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.962354330501408,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.83333,
            "fmeasure": 0.78431
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.42857,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 39.45881,
        "nubia": {
            "semantic_relation": 4.57094,
            "contradiction": 1.36367,
            "irrelevancy": 5.93132,
            "logical_agreement": 92.70501,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.66571,
            "nubia_score": 0.79541
        },
        "meteor": 0.3938951655206609,
        "bleurt": 0.0169,
        "bertscore": {
            "precision": 0.90593,
            "recall": 0.89988,
            "f1": 0.9029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 56,
        "total_length": 859,
        "mean_pred_length": 15.339285714285714,
        "std_pred_length": 5.2279359000957735,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.509895227008149,
        "vocab_size-1": 438,
        "unique-1": 347,
        "entropy-1": 7.734895556627696,
        "distinct-2": 0.8916562889165629,
        "vocab_size-2": 716,
        "unique-2": 659,
        "entropy-2": 9.391813902409814,
        "cond_entropy-2": 1.3904286944986488,
        "distinct-3": 0.9678714859437751,
        "vocab_size-3": 723,
        "unique-3": 705,
        "entropy-3": 9.474644051245862,
        "cond_entropy-3": 0.09409757508234685,
        "total_length-nopunct": 748,
        "mean_pred_length-nopunct": 13.357142857142858,
        "std_pred_length-nopunct": 4.786247305071702,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5748663101604278,
        "vocab_size-1-nopunct": 430,
        "unique-1-nopunct": 345,
        "entropy-1-nopunct": 7.95730476349432,
        "distinct-2-nopunct": 0.8930635838150289,
        "vocab_size-2-nopunct": 618,
        "unique-2-nopunct": 570,
        "entropy-2-nopunct": 9.177826787025925,
        "cond_entropy-2-nopunct": 1.3156338019320768,
        "distinct-3-nopunct": 0.9685534591194969,
        "vocab_size-3-nopunct": 616,
        "unique-3-nopunct": 600,
        "entropy-3-nopunct": 9.2452421533838,
        "cond_entropy-3-nopunct": 0.08596240751137273,
        "msttr-100": 0.74125,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.586743361102244,
        "rouge1": {
            "precision": 0.79526,
            "recall": 0.69145,
            "fmeasure": 0.72767
        },
        "rouge2": {
            "precision": 0.54551,
            "recall": 0.47119,
            "fmeasure": 0.49638
        },
        "rougeL": {
            "precision": 0.70233,
            "recall": 0.60711,
            "fmeasure": 0.64052
        },
        "rougeLsum": {
            "precision": 0.70233,
            "recall": 0.60711,
            "fmeasure": 0.64052
        },
        "local_recall": {
            "1": 0.15873015873015872,
            "2": 0.3987341772151899,
            "3": 0.7398753894080997
        },
        "bleu": 43.029,
        "nubia": {
            "semantic_relation": 4.22065,
            "contradiction": 5.71609,
            "irrelevancy": 27.12512,
            "logical_agreement": 67.15879,
            "grammar_ref": 4.75668,
            "grammar_hyp": 5.00751,
            "nubia_score": 0.70235
        },
        "meteor": 0.38062265645683185,
        "bleurt": 0.25142,
        "bertscore": {
            "precision": 0.93359,
            "recall": 0.91542,
            "f1": 0.92289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 228,
        "mean_pred_length": 13.411764705882353,
        "std_pred_length": 4.257295793581701,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6052631578947368,
        "vocab_size-1": 138,
        "unique-1": 112,
        "entropy-1": 6.459530494172333,
        "distinct-2": 0.943127962085308,
        "vocab_size-2": 199,
        "unique-2": 192,
        "entropy-2": 7.57766476924517,
        "cond_entropy-2": 0.8994624435022921,
        "distinct-3": 0.9948453608247423,
        "vocab_size-3": 193,
        "unique-3": 192,
        "entropy-3": 7.589603563836587,
        "cond_entropy-3": 0.024507790111336403,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 11.882352941176471,
        "std_pred_length-nopunct": 3.9982695218744535,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6732673267326733,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.593311595405055,
        "distinct-2-nopunct": 0.9405405405405406,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.378599501021759,
        "cond_entropy-2-nopunct": 0.8583599898554674,
        "distinct-3-nopunct": 0.9940476190476191,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 166,
        "entropy-3-nopunct": 7.380412660874029,
        "cond_entropy-3-nopunct": 0.011320858134414972,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.75640223091557,
        "rouge1": {
            "precision": 0.68052,
            "recall": 0.59683,
            "fmeasure": 0.62856
        },
        "rouge2": {
            "precision": 0.3718,
            "recall": 0.33348,
            "fmeasure": 0.34776
        },
        "rougeL": {
            "precision": 0.56857,
            "recall": 0.49978,
            "fmeasure": 0.5266
        },
        "rougeLsum": {
            "precision": 0.56857,
            "recall": 0.49978,
            "fmeasure": 0.5266
        },
        "local_recall": {
            "1": 0.18055555555555555,
            "2": 0.29508196721311475,
            "3": 0.6459627329192547
        },
        "bleu": 31.1645,
        "nubia": {
            "semantic_relation": 3.97666,
            "contradiction": 5.82261,
            "irrelevancy": 35.76862,
            "logical_agreement": 58.40877,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.82122,
            "nubia_score": 0.6513
        },
        "meteor": 0.31164172871806106,
        "bleurt": 0.17325,
        "bertscore": {
            "precision": 0.91432,
            "recall": 0.89813,
            "f1": 0.90552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 345,
        "mean_pred_length": 19.166666666666668,
        "std_pred_length": 10.199400853862826,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 53,
        "distinct-1": 0.527536231884058,
        "vocab_size-1": 182,
        "unique-1": 142,
        "entropy-1": 6.679942446414443,
        "distinct-2": 0.8470948012232415,
        "vocab_size-2": 277,
        "unique-2": 249,
        "entropy-2": 7.9684665504466,
        "cond_entropy-2": 1.1553453024069686,
        "distinct-3": 0.9288025889967637,
        "vocab_size-3": 287,
        "unique-3": 269,
        "entropy-3": 8.114943519889474,
        "cond_entropy-3": 0.16241303724519407,
        "total_length-nopunct": 294,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 7.007932013876213,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5952380952380952,
        "vocab_size-1-nopunct": 175,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.73196312386396,
        "distinct-2-nopunct": 0.8442028985507246,
        "vocab_size-2-nopunct": 233,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.710732971481681,
        "cond_entropy-2-nopunct": 1.0458418598709673,
        "distinct-3-nopunct": 0.9263565891472868,
        "vocab_size-3-nopunct": 239,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.847023658614694,
        "cond_entropy-3-nopunct": 0.14466373649477673,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.401142371385337,
        "rouge1": {
            "precision": 0.75622,
            "recall": 0.74387,
            "fmeasure": 0.74049
        },
        "rouge2": {
            "precision": 0.56167,
            "recall": 0.55059,
            "fmeasure": 0.54729
        },
        "rougeL": {
            "precision": 0.72368,
            "recall": 0.70796,
            "fmeasure": 0.70626
        },
        "rougeLsum": {
            "precision": 0.72368,
            "recall": 0.70796,
            "fmeasure": 0.70626
        },
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.20588235294117646,
            "3": 0.7903930131004366
        },
        "bleu": 55.5501,
        "nubia": {
            "semantic_relation": 4.29001,
            "contradiction": 6.23329,
            "irrelevancy": 35.41188,
            "logical_agreement": 58.35483,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.26487,
            "nubia_score": 0.7771
        },
        "meteor": 0.42647450811423243,
        "bleurt": 0.31612,
        "bertscore": {
            "precision": 0.93289,
            "recall": 0.93072,
            "f1": 0.93098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 23,
        "total_length": 386,
        "mean_pred_length": 16.782608695652176,
        "std_pred_length": 4.818050496415676,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5673575129533679,
        "vocab_size-1": 219,
        "unique-1": 171,
        "entropy-1": 7.026222787524832,
        "distinct-2": 0.9035812672176309,
        "vocab_size-2": 328,
        "unique-2": 303,
        "entropy-2": 8.280631385354853,
        "cond_entropy-2": 1.067029707347295,
        "distinct-3": 0.9735294117647059,
        "vocab_size-3": 331,
        "unique-3": 323,
        "entropy-3": 8.354229502307788,
        "cond_entropy-3": 0.08869655845515817,
        "total_length-nopunct": 342,
        "mean_pred_length-nopunct": 14.869565217391305,
        "std_pred_length-nopunct": 4.627933596777451,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6257309941520468,
        "vocab_size-1-nopunct": 214,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 7.153161007834501,
        "distinct-2-nopunct": 0.8996865203761756,
        "vocab_size-2-nopunct": 287,
        "unique-2-nopunct": 265,
        "entropy-2-nopunct": 8.082241610603003,
        "cond_entropy-2-nopunct": 0.9905102315015162,
        "distinct-3-nopunct": 0.9763513513513513,
        "vocab_size-3-nopunct": 289,
        "unique-3-nopunct": 283,
        "entropy-3-nopunct": 8.159605772716196,
        "cond_entropy-3-nopunct": 0.0801478464781659,
        "msttr-100": 0.74667,
        "msttr-100_nopunct": 0.78667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.499332231459743,
        "rouge1": {
            "precision": 0.77348,
            "recall": 0.76773,
            "fmeasure": 0.76571
        },
        "rouge2": {
            "precision": 0.57157,
            "recall": 0.57006,
            "fmeasure": 0.56675
        },
        "rougeL": {
            "precision": 0.68517,
            "recall": 0.68992,
            "fmeasure": 0.68266
        },
        "rougeLsum": {
            "precision": 0.68517,
            "recall": 0.68992,
            "fmeasure": 0.68266
        },
        "local_recall": {
            "1": 0.22077922077922077,
            "2": 0.4782608695652174,
            "3": 0.868421052631579
        },
        "bleu": 50.32116,
        "nubia": {
            "semantic_relation": 4.3564,
            "contradiction": 8.08048,
            "irrelevancy": 24.47977,
            "logical_agreement": 67.43975,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.71502,
            "nubia_score": 0.77659
        },
        "meteor": 0.43259067745604873,
        "bleurt": 0.23801,
        "bertscore": {
            "precision": 0.93187,
            "recall": 0.93829,
            "f1": 0.93423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 103,
        "mean_pred_length": 12.875,
        "std_pred_length": 2.9764702249476644,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.6699029126213593,
        "vocab_size-1": 69,
        "unique-1": 58,
        "entropy-1": 5.701219522762219,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 90,
        "unique-2": 85,
        "entropy-2": 6.464592450436211,
        "cond_entropy-2": 0.5937123806778765,
        "distinct-3": 0.9885057471264368,
        "vocab_size-3": 86,
        "unique-3": 85,
        "entropy-3": 6.419954990101596,
        "cond_entropy-3": -0.03495808949371389,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 11.125,
        "std_pred_length-nopunct": 3.059309562630104,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7528089887640449,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.779394459606441,
        "distinct-2-nopunct": 0.9506172839506173,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.241084570785849,
        "cond_entropy-2-nopunct": 0.5304643305730061,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.04043640290871709,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.433741075556293,
        "rouge1": {
            "precision": 0.77904,
            "recall": 0.70352,
            "fmeasure": 0.73476
        },
        "rouge2": {
            "precision": 0.54856,
            "recall": 0.52141,
            "fmeasure": 0.52968
        },
        "rougeL": {
            "precision": 0.64678,
            "recall": 0.60744,
            "fmeasure": 0.62166
        },
        "rougeLsum": {
            "precision": 0.64678,
            "recall": 0.60744,
            "fmeasure": 0.62166
        },
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2,
            "3": 0.7261904761904762
        },
        "bleu": 47.32572,
        "nubia": {
            "semantic_relation": 3.82969,
            "contradiction": 48.70942,
            "irrelevancy": 9.58576,
            "logical_agreement": 41.70482,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.15739,
            "nubia_score": 0.59073
        },
        "meteor": 0.40529531995604534,
        "bleurt": 0.28342,
        "bertscore": {
            "precision": 0.93291,
            "recall": 0.91694,
            "f1": 0.92382
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 561,
        "mean_pred_length": 18.096774193548388,
        "std_pred_length": 7.621509624018818,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5472370766488414,
        "vocab_size-1": 307,
        "unique-1": 234,
        "entropy-1": 7.446389896515634,
        "distinct-2": 0.8943396226415095,
        "vocab_size-2": 474,
        "unique-2": 426,
        "entropy-2": 8.824595572119899,
        "cond_entropy-2": 1.1843367680324028,
        "distinct-3": 0.9438877755511023,
        "vocab_size-3": 471,
        "unique-3": 444,
        "entropy-3": 8.849158755833864,
        "cond_entropy-3": 0.038556855652411834,
        "total_length-nopunct": 488,
        "mean_pred_length-nopunct": 15.741935483870968,
        "std_pred_length-nopunct": 6.763124597286251,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6209016393442623,
        "vocab_size-1-nopunct": 303,
        "unique-1-nopunct": 234,
        "entropy-1-nopunct": 7.683303615461688,
        "distinct-2-nopunct": 0.899343544857768,
        "vocab_size-2-nopunct": 411,
        "unique-2-nopunct": 371,
        "entropy-2-nopunct": 8.62188339011078,
        "cond_entropy-2-nopunct": 0.998755968048903,
        "distinct-3-nopunct": 0.9413145539906104,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 376,
        "entropy-3-nopunct": 8.617338728207029,
        "cond_entropy-3-nopunct": 0.001650586719240872,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.853163279037581,
        "rouge1": {
            "precision": 0.77411,
            "recall": 0.73327,
            "fmeasure": 0.74635
        },
        "rouge2": {
            "precision": 0.55384,
            "recall": 0.51839,
            "fmeasure": 0.53175
        },
        "rougeL": {
            "precision": 0.68408,
            "recall": 0.64141,
            "fmeasure": 0.65784
        },
        "rougeLsum": {
            "precision": 0.68408,
            "recall": 0.64141,
            "fmeasure": 0.65784
        },
        "local_recall": {
            "1": 0.25225225225225223,
            "2": 0.39759036144578314,
            "3": 0.7706666666666667
        },
        "bleu": 50.08167,
        "nubia": {
            "semantic_relation": 4.18793,
            "contradiction": 9.02562,
            "irrelevancy": 20.85602,
            "logical_agreement": 70.11835,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.79606,
            "nubia_score": 0.75047
        },
        "meteor": 0.39581147408365713,
        "bleurt": 0.34257,
        "bertscore": {
            "precision": 0.93868,
            "recall": 0.92813,
            "f1": 0.93257
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 23,
        "total_length": 380,
        "mean_pred_length": 16.52173913043478,
        "std_pred_length": 7.626438938880243,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.6078947368421053,
        "vocab_size-1": 231,
        "unique-1": 198,
        "entropy-1": 7.081433097373487,
        "distinct-2": 0.9243697478991597,
        "vocab_size-2": 330,
        "unique-2": 314,
        "entropy-2": 8.301140383046478,
        "cond_entropy-2": 1.0241660889298245,
        "distinct-3": 0.9820359281437125,
        "vocab_size-3": 328,
        "unique-3": 324,
        "entropy-3": 8.343255864317332,
        "cond_entropy-3": 0.04842900600929507,
        "total_length-nopunct": 317,
        "mean_pred_length-nopunct": 13.782608695652174,
        "std_pred_length-nopunct": 4.763598582539944,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7129337539432177,
        "vocab_size-1-nopunct": 226,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 7.319509857350024,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 280,
        "unique-2-nopunct": 272,
        "entropy-2-nopunct": 8.085693518290988,
        "cond_entropy-2-nopunct": 0.8211432135717707,
        "distinct-3-nopunct": 0.992619926199262,
        "vocab_size-3-nopunct": 269,
        "unique-3-nopunct": 268,
        "entropy-3-nopunct": 8.06460333101375,
        "cond_entropy-3-nopunct": -0.011416707533550105,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.929862521667814,
        "rouge1": {
            "precision": 0.76298,
            "recall": 0.68073,
            "fmeasure": 0.70226
        },
        "rouge2": {
            "precision": 0.51998,
            "recall": 0.47078,
            "fmeasure": 0.48267
        },
        "rougeL": {
            "precision": 0.64221,
            "recall": 0.58687,
            "fmeasure": 0.59926
        },
        "rougeLsum": {
            "precision": 0.64221,
            "recall": 0.58687,
            "fmeasure": 0.59926
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.30120481927710846,
            "3": 0.720164609053498
        },
        "bleu": 39.52625,
        "nubia": {
            "semantic_relation": 4.00787,
            "contradiction": 13.18039,
            "irrelevancy": 31.38195,
            "logical_agreement": 55.43766,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.56411,
            "nubia_score": 0.65548
        },
        "meteor": 0.35081688781271264,
        "bleurt": 0.09055,
        "bertscore": {
            "precision": 0.91924,
            "recall": 0.90033,
            "f1": 0.9073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 446,
        "mean_pred_length": 14.387096774193548,
        "std_pred_length": 5.31387362115458,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5426008968609866,
        "vocab_size-1": 242,
        "unique-1": 191,
        "entropy-1": 7.052413304795533,
        "distinct-2": 0.8891566265060241,
        "vocab_size-2": 369,
        "unique-2": 345,
        "entropy-2": 8.401980440873087,
        "cond_entropy-2": 1.1101044826483317,
        "distinct-3": 0.96875,
        "vocab_size-3": 372,
        "unique-3": 363,
        "entropy-3": 8.516564942110577,
        "cond_entropy-3": 0.12798189614942448,
        "total_length-nopunct": 391,
        "mean_pred_length-nopunct": 12.612903225806452,
        "std_pred_length-nopunct": 4.7497193082079905,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6061381074168798,
        "vocab_size-1-nopunct": 237,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 7.2114127960335255,
        "distinct-2-nopunct": 0.8861111111111111,
        "vocab_size-2-nopunct": 319,
        "unique-2-nopunct": 300,
        "entropy-2-nopunct": 8.179576317371568,
        "cond_entropy-2-nopunct": 1.0388945200488946,
        "distinct-3-nopunct": 0.9635258358662614,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 8.282111972803676,
        "cond_entropy-3-nopunct": 0.12106336864477708,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.943269329748479,
        "rouge1": {
            "precision": 0.78549,
            "recall": 0.70046,
            "fmeasure": 0.72738
        },
        "rouge2": {
            "precision": 0.51331,
            "recall": 0.46092,
            "fmeasure": 0.47686
        },
        "rougeL": {
            "precision": 0.64511,
            "recall": 0.57817,
            "fmeasure": 0.59828
        },
        "rougeLsum": {
            "precision": 0.64511,
            "recall": 0.57817,
            "fmeasure": 0.59828
        },
        "local_recall": {
            "1": 0.25510204081632654,
            "2": 0.41237113402061853,
            "3": 0.7416107382550335
        },
        "bleu": 39.23937,
        "nubia": {
            "semantic_relation": 4.15859,
            "contradiction": 8.72785,
            "irrelevancy": 26.93586,
            "logical_agreement": 64.33629,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.49963,
            "nubia_score": 0.72495
        },
        "meteor": 0.37450956006993186,
        "bleurt": 0.25946,
        "bertscore": {
            "precision": 0.92838,
            "recall": 0.9171,
            "f1": 0.92111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 222,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 5.767608353767529,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6216216216216216,
        "vocab_size-1": 138,
        "unique-1": 113,
        "entropy-1": 6.441360229280033,
        "distinct-2": 0.9278846153846154,
        "vocab_size-2": 193,
        "unique-2": 184,
        "entropy-2": 7.525610256715106,
        "cond_entropy-2": 0.9190568063301595,
        "distinct-3": 0.9896907216494846,
        "vocab_size-3": 192,
        "unique-3": 190,
        "entropy-3": 7.579294285486071,
        "cond_entropy-3": 0.05599130949242873,
        "total_length-nopunct": 200,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 5.611576954686388,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.68,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.528479277170994,
        "distinct-2-nopunct": 0.9247311827956989,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 164,
        "entropy-2-nopunct": 7.35440328435213,
        "cond_entropy-2-nopunct": 0.8937480758717404,
        "distinct-3-nopunct": 0.9883720930232558,
        "vocab_size-3-nopunct": 170,
        "unique-3-nopunct": 168,
        "entropy-3-nopunct": 7.4030089407485775,
        "cond_entropy-3-nopunct": 0.06364389694639375,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.976340303855254,
        "rouge1": {
            "precision": 0.70449,
            "recall": 0.69418,
            "fmeasure": 0.68404
        },
        "rouge2": {
            "precision": 0.47518,
            "recall": 0.46577,
            "fmeasure": 0.46211
        },
        "rougeL": {
            "precision": 0.57347,
            "recall": 0.56943,
            "fmeasure": 0.55802
        },
        "rougeLsum": {
            "precision": 0.57347,
            "recall": 0.56943,
            "fmeasure": 0.55802
        },
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.3076923076923077,
            "3": 0.7857142857142857
        },
        "bleu": 39.16284,
        "nubia": {
            "semantic_relation": 4.07386,
            "contradiction": 15.56374,
            "irrelevancy": 41.53128,
            "logical_agreement": 42.90498,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.87767,
            "nubia_score": 0.67561
        },
        "meteor": 0.3606501182167337,
        "bleurt": 0.03436,
        "bertscore": {
            "precision": 0.90078,
            "recall": 0.90688,
            "f1": 0.90266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.1911063109464317,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765374,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8815640006923098,
        "rouge1": {
            "precision": 0.43939,
            "recall": 0.66369,
            "fmeasure": 0.52827
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.22051,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.31818,
            "recall": 0.47917,
            "fmeasure": 0.38207
        },
        "rougeLsum": {
            "precision": 0.31818,
            "recall": 0.47917,
            "fmeasure": 0.38207
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 9.22636,
        "nubia": {
            "semantic_relation": 3.24452,
            "contradiction": 92.90151,
            "irrelevancy": 6.14533,
            "logical_agreement": 0.95316,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.11467,
            "nubia_score": 0.55633
        },
        "meteor": 0.28241184850244283,
        "bleurt": -0.08487,
        "bertscore": {
            "precision": 0.82678,
            "recall": 0.88859,
            "f1": 0.85657
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.489020727131909,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.73529,
            "fmeasure": 0.69916
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.48889,
            "fmeasure": 0.44691
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5875,
            "fmeasure": 0.54011
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5875,
            "fmeasure": 0.54011
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "bleu": 20.94841,
        "nubia": {
            "semantic_relation": 3.8027,
            "contradiction": 99.039,
            "irrelevancy": 0.42223,
            "logical_agreement": 0.53876,
            "grammar_ref": 5.18542,
            "grammar_hyp": 4.52592,
            "nubia_score": 0.6363
        },
        "meteor": 0.3338209051597352,
        "bleurt": 0.2913,
        "bertscore": {
            "precision": 0.89331,
            "recall": 0.93275,
            "f1": 0.9126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 19,
        "total_length": 289,
        "mean_pred_length": 15.210526315789474,
        "std_pred_length": 5.5019513033145175,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5536332179930796,
        "vocab_size-1": 160,
        "unique-1": 126,
        "entropy-1": 6.660179874990236,
        "distinct-2": 0.8629629629629629,
        "vocab_size-2": 233,
        "unique-2": 212,
        "entropy-2": 7.750744856245999,
        "cond_entropy-2": 0.8982299723197023,
        "distinct-3": 0.9362549800796812,
        "vocab_size-3": 235,
        "unique-3": 226,
        "entropy-3": 7.821047786975398,
        "cond_entropy-3": 0.0870174489576716,
        "total_length-nopunct": 259,
        "mean_pred_length-nopunct": 13.631578947368421,
        "std_pred_length-nopunct": 5.080515165712082,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5984555984555985,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.7308974165858135,
        "distinct-2-nopunct": 0.8583333333333333,
        "vocab_size-2-nopunct": 206,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.568206376795457,
        "cond_entropy-2-nopunct": 0.9182769041717268,
        "distinct-3-nopunct": 0.9366515837104072,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.638492830845467,
        "cond_entropy-3-nopunct": 0.09487921494350282,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.071005878700604,
        "rouge1": {
            "precision": 0.76183,
            "recall": 0.65639,
            "fmeasure": 0.68949
        },
        "rouge2": {
            "precision": 0.54742,
            "recall": 0.48367,
            "fmeasure": 0.50312
        },
        "rougeL": {
            "precision": 0.68283,
            "recall": 0.58202,
            "fmeasure": 0.61577
        },
        "rougeLsum": {
            "precision": 0.68283,
            "recall": 0.58202,
            "fmeasure": 0.61577
        },
        "local_recall": {
            "1": 0.22077922077922077,
            "2": 0.2549019607843137,
            "3": 0.6637931034482759
        },
        "bleu": 41.87573,
        "nubia": {
            "semantic_relation": 4.03971,
            "contradiction": 9.87202,
            "irrelevancy": 27.66906,
            "logical_agreement": 62.45892,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.74767,
            "nubia_score": 0.65627
        },
        "meteor": 0.3669081810688103,
        "bleurt": 0.18954,
        "bertscore": {
            "precision": 0.91849,
            "recall": 0.897,
            "f1": 0.90581
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 15,
        "total_length": 256,
        "mean_pred_length": 17.066666666666666,
        "std_pred_length": 6.80653280965345,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5234375,
        "vocab_size-1": 134,
        "unique-1": 91,
        "entropy-1": 6.4797977188889995,
        "distinct-2": 0.8630705394190872,
        "vocab_size-2": 208,
        "unique-2": 179,
        "entropy-2": 7.62446703330747,
        "cond_entropy-2": 0.9961202492007583,
        "distinct-3": 0.9336283185840708,
        "vocab_size-3": 211,
        "unique-3": 196,
        "entropy-3": 7.687435599583356,
        "cond_entropy-3": 0.082111639478708,
        "total_length-nopunct": 229,
        "mean_pred_length-nopunct": 15.266666666666667,
        "std_pred_length-nopunct": 6.4442911859171055,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5676855895196506,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.517944290148085,
        "distinct-2-nopunct": 0.8598130841121495,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.444692336848188,
        "cond_entropy-2-nopunct": 1.011953326926822,
        "distinct-3-nopunct": 0.9346733668341709,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 173,
        "entropy-3-nopunct": 7.505971354212,
        "cond_entropy-3-nopunct": 0.08364896582253678,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.445157314433721,
        "rouge1": {
            "precision": 0.76748,
            "recall": 0.66482,
            "fmeasure": 0.70508
        },
        "rouge2": {
            "precision": 0.49063,
            "recall": 0.4234,
            "fmeasure": 0.45062
        },
        "rougeL": {
            "precision": 0.65152,
            "recall": 0.57558,
            "fmeasure": 0.60389
        },
        "rougeLsum": {
            "precision": 0.65152,
            "recall": 0.57558,
            "fmeasure": 0.60389
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.3,
            "3": 0.7192982456140351
        },
        "bleu": 45.2341,
        "nubia": {
            "semantic_relation": 4.03112,
            "contradiction": 11.06082,
            "irrelevancy": 39.50819,
            "logical_agreement": 49.43099,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.77102,
            "nubia_score": 0.64782
        },
        "meteor": 0.35242905946035696,
        "bleurt": 0.12833,
        "bertscore": {
            "precision": 0.90428,
            "recall": 0.90555,
            "f1": 0.90403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 104,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 12.202003478482084,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 43,
        "distinct-1": 0.7115384615384616,
        "vocab_size-1": 74,
        "unique-1": 62,
        "entropy-1": 5.919109131927815,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 94,
        "unique-2": 90,
        "entropy-2": 6.5330771910539935,
        "cond_entropy-2": 0.5035416153807943,
        "distinct-3": 0.9891304347826086,
        "vocab_size-3": 91,
        "unique-3": 90,
        "entropy-3": 6.501822825622244,
        "cond_entropy-3": -0.025930496753847572,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 11.206396982676159,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.957019397264836,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.373977978607343,
        "cond_entropy-2-nopunct": 0.45710612712480814,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.8104077257629685,
        "rouge1": {
            "precision": 0.76112,
            "recall": 0.56636,
            "fmeasure": 0.62456
        },
        "rouge2": {
            "precision": 0.46511,
            "recall": 0.36362,
            "fmeasure": 0.38793
        },
        "rougeL": {
            "precision": 0.65591,
            "recall": 0.5003,
            "fmeasure": 0.54847
        },
        "rougeLsum": {
            "precision": 0.65591,
            "recall": 0.5003,
            "fmeasure": 0.54847
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.2777777777777778,
            "3": 0.6623376623376623
        },
        "bleu": 36.72559,
        "nubia": {
            "semantic_relation": 3.65349,
            "contradiction": 4.34222,
            "irrelevancy": 40.77024,
            "logical_agreement": 54.88755,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.3193,
            "nubia_score": 0.53402
        },
        "meteor": 0.3209059107880208,
        "bleurt": -0.14535,
        "bertscore": {
            "precision": 0.89668,
            "recall": 0.85205,
            "f1": 0.86774
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7441860465116279,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.766624569199766,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.4859043520461842,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.11247472925841272,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.683293289103912,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.3585182478811835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.440144673500262,
        "rouge1": {
            "precision": 0.89669,
            "recall": 0.75955,
            "fmeasure": 0.82043
        },
        "rouge2": {
            "precision": 0.68056,
            "recall": 0.57102,
            "fmeasure": 0.61926
        },
        "rougeL": {
            "precision": 0.78168,
            "recall": 0.66761,
            "fmeasure": 0.71857
        },
        "rougeLsum": {
            "precision": 0.78168,
            "recall": 0.66761,
            "fmeasure": 0.71857
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "bleu": 51.67841,
        "nubia": {
            "semantic_relation": 4.76354,
            "contradiction": 1.36081,
            "irrelevancy": 20.97392,
            "logical_agreement": 77.66527,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.59374,
            "nubia_score": 0.85575
        },
        "meteor": 0.4786056166189525,
        "bleurt": 0.49756,
        "bertscore": {
            "precision": 0.97046,
            "recall": 0.96522,
            "f1": 0.96755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 284,
        "mean_pred_length": 16.705882352941178,
        "std_pred_length": 6.5328554776637695,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.6126760563380281,
        "vocab_size-1": 174,
        "unique-1": 143,
        "entropy-1": 6.833561119018438,
        "distinct-2": 0.9026217228464419,
        "vocab_size-2": 241,
        "unique-2": 219,
        "entropy-2": 7.852794152645099,
        "cond_entropy-2": 0.8427846954507218,
        "distinct-3": 0.964,
        "vocab_size-3": 241,
        "unique-3": 232,
        "entropy-3": 7.893784284662099,
        "cond_entropy-3": 0.036107902983186835,
        "total_length-nopunct": 236,
        "mean_pred_length-nopunct": 13.882352941176471,
        "std_pred_length-nopunct": 4.663782268921129,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7161016949152542,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 142,
        "entropy-1-nopunct": 7.022443952209129,
        "distinct-2-nopunct": 0.9315068493150684,
        "vocab_size-2-nopunct": 204,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.62522136324427,
        "cond_entropy-2-nopunct": 0.6695508569328128,
        "distinct-3-nopunct": 0.9702970297029703,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 190,
        "entropy-3-nopunct": 7.598805542157707,
        "cond_entropy-3-nopunct": -0.013828609016886345,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.364557635710417,
        "rouge1": {
            "precision": 0.8151,
            "recall": 0.75622,
            "fmeasure": 0.77752
        },
        "rouge2": {
            "precision": 0.62988,
            "recall": 0.58076,
            "fmeasure": 0.59896
        },
        "rougeL": {
            "precision": 0.69876,
            "recall": 0.63719,
            "fmeasure": 0.66056
        },
        "rougeLsum": {
            "precision": 0.69876,
            "recall": 0.63719,
            "fmeasure": 0.66056
        },
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.18421052631578946,
            "3": 0.8110599078341014
        },
        "bleu": 60.42582,
        "nubia": {
            "semantic_relation": 4.29768,
            "contradiction": 7.80306,
            "irrelevancy": 11.74412,
            "logical_agreement": 80.45282,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.53594,
            "nubia_score": 0.77726
        },
        "meteor": 0.44713120112145377,
        "bleurt": 0.40756,
        "bertscore": {
            "precision": 0.95202,
            "recall": 0.94073,
            "f1": 0.94314
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 42,
        "total_length": 650,
        "mean_pred_length": 15.476190476190476,
        "std_pred_length": 4.425241963995788,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5446153846153846,
        "vocab_size-1": 354,
        "unique-1": 280,
        "entropy-1": 7.545944836950502,
        "distinct-2": 0.8865131578947368,
        "vocab_size-2": 539,
        "unique-2": 492,
        "entropy-2": 8.973637783228899,
        "cond_entropy-2": 1.1794255338177275,
        "distinct-3": 0.9664310954063604,
        "vocab_size-3": 547,
        "unique-3": 529,
        "entropy-3": 9.076186710142581,
        "cond_entropy-3": 0.10876830618749143,
        "total_length-nopunct": 580,
        "mean_pred_length-nopunct": 13.80952380952381,
        "std_pred_length-nopunct": 3.9354197164560736,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 348,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.71781891333725,
        "distinct-2-nopunct": 0.8884758364312267,
        "vocab_size-2-nopunct": 478,
        "unique-2-nopunct": 439,
        "entropy-2-nopunct": 8.796344763173112,
        "cond_entropy-2-nopunct": 1.1700460402057433,
        "distinct-3-nopunct": 0.9758064516129032,
        "vocab_size-3-nopunct": 484,
        "unique-3-nopunct": 472,
        "entropy-3-nopunct": 8.905809213612573,
        "cond_entropy-3-nopunct": 0.11628907578771637,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.044130508537388,
        "rouge1": {
            "precision": 0.77845,
            "recall": 0.753,
            "fmeasure": 0.76004
        },
        "rouge2": {
            "precision": 0.53812,
            "recall": 0.52245,
            "fmeasure": 0.52518
        },
        "rougeL": {
            "precision": 0.65746,
            "recall": 0.63695,
            "fmeasure": 0.64178
        },
        "rougeLsum": {
            "precision": 0.65746,
            "recall": 0.63695,
            "fmeasure": 0.64178
        },
        "local_recall": {
            "1": 0.28448275862068967,
            "2": 0.42452830188679247,
            "3": 0.7865168539325843
        },
        "bleu": 44.84289,
        "nubia": {
            "semantic_relation": 4.27122,
            "contradiction": 10.4253,
            "irrelevancy": 26.89791,
            "logical_agreement": 62.67679,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.75309,
            "nubia_score": 0.73533
        },
        "meteor": 0.40730039107076016,
        "bleurt": 0.25664,
        "bertscore": {
            "precision": 0.9355,
            "recall": 0.93011,
            "f1": 0.93143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 277,
        "mean_pred_length": 15.38888888888889,
        "std_pred_length": 5.15470538967272,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5631768953068592,
        "vocab_size-1": 156,
        "unique-1": 125,
        "entropy-1": 6.522392153851409,
        "distinct-2": 0.888030888030888,
        "vocab_size-2": 230,
        "unique-2": 212,
        "entropy-2": 7.727642832128295,
        "cond_entropy-2": 1.0206236704683458,
        "distinct-3": 0.966804979253112,
        "vocab_size-3": 233,
        "unique-3": 225,
        "entropy-3": 7.8464992947362155,
        "cond_entropy-3": 0.14045388252507113,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 13.555555555555555,
        "std_pred_length-nopunct": 4.560972389283065,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6311475409836066,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.67339978955239,
        "distinct-2-nopunct": 0.8849557522123894,
        "vocab_size-2-nopunct": 200,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.515338904939189,
        "cond_entropy-2-nopunct": 0.9306431568180268,
        "distinct-3-nopunct": 0.9711538461538461,
        "vocab_size-3-nopunct": 202,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.64274741044876,
        "cond_entropy-3-nopunct": 0.14898120279119725,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.783204508094087,
        "rouge1": {
            "precision": 0.74868,
            "recall": 0.71258,
            "fmeasure": 0.71739
        },
        "rouge2": {
            "precision": 0.48088,
            "recall": 0.45322,
            "fmeasure": 0.45872
        },
        "rougeL": {
            "precision": 0.60807,
            "recall": 0.57926,
            "fmeasure": 0.58312
        },
        "rougeLsum": {
            "precision": 0.60807,
            "recall": 0.57926,
            "fmeasure": 0.58312
        },
        "local_recall": {
            "1": 0.17045454545454544,
            "2": 0.4576271186440678,
            "3": 0.7577639751552795
        },
        "bleu": 38.13482,
        "nubia": {
            "semantic_relation": 4.39837,
            "contradiction": 3.76003,
            "irrelevancy": 27.62399,
            "logical_agreement": 68.61598,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.8121,
            "nubia_score": 0.78171
        },
        "meteor": 0.3770696409528045,
        "bleurt": 0.23865,
        "bertscore": {
            "precision": 0.92336,
            "recall": 0.91809,
            "f1": 0.91833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 32,
        "total_length": 637,
        "mean_pred_length": 19.90625,
        "std_pred_length": 8.592727211863531,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.4897959183673469,
        "vocab_size-1": 312,
        "unique-1": 229,
        "entropy-1": 7.291835873504332,
        "distinct-2": 0.8,
        "vocab_size-2": 484,
        "unique-2": 411,
        "entropy-2": 8.731737418440577,
        "cond_entropy-2": 1.2824569797132723,
        "distinct-3": 0.893542757417103,
        "vocab_size-3": 512,
        "unique-3": 456,
        "entropy-3": 8.94288969261237,
        "cond_entropy-3": 0.2111960136701906,
        "total_length-nopunct": 553,
        "mean_pred_length-nopunct": 17.28125,
        "std_pred_length-nopunct": 6.951773042720828,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5533453887884268,
        "vocab_size-1-nopunct": 306,
        "unique-1-nopunct": 228,
        "entropy-1-nopunct": 7.465012046123821,
        "distinct-2-nopunct": 0.8061420345489443,
        "vocab_size-2-nopunct": 420,
        "unique-2-nopunct": 360,
        "entropy-2-nopunct": 8.52570927381282,
        "cond_entropy-2-nopunct": 1.1229070040134956,
        "distinct-3-nopunct": 0.8977505112474438,
        "vocab_size-3-nopunct": 439,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.723016728554164,
        "cond_entropy-3-nopunct": 0.2006651627740666,
        "msttr-100": 0.65667,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.22011240342711,
        "rouge1": {
            "precision": 0.7377,
            "recall": 0.71349,
            "fmeasure": 0.71071
        },
        "rouge2": {
            "precision": 0.51516,
            "recall": 0.51707,
            "fmeasure": 0.50357
        },
        "rougeL": {
            "precision": 0.65438,
            "recall": 0.6459,
            "fmeasure": 0.6351
        },
        "rougeLsum": {
            "precision": 0.65438,
            "recall": 0.6459,
            "fmeasure": 0.6351
        },
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.3855421686746988,
            "3": 0.7448979591836735
        },
        "bleu": 41.4039,
        "nubia": {
            "semantic_relation": 4.14247,
            "contradiction": 14.1269,
            "irrelevancy": 30.77753,
            "logical_agreement": 55.09557,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.28491,
            "nubia_score": 0.70611
        },
        "meteor": 0.3587569697598088,
        "bleurt": 0.13975,
        "bertscore": {
            "precision": 0.91561,
            "recall": 0.90966,
            "f1": 0.91043
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 35,
        "total_length": 549,
        "mean_pred_length": 15.685714285714285,
        "std_pred_length": 5.951093194034322,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.5409836065573771,
        "vocab_size-1": 297,
        "unique-1": 231,
        "entropy-1": 7.3078769594299935,
        "distinct-2": 0.896887159533074,
        "vocab_size-2": 461,
        "unique-2": 421,
        "entropy-2": 8.77014680125683,
        "cond_entropy-2": 1.235076422939793,
        "distinct-3": 0.9498956158663883,
        "vocab_size-3": 455,
        "unique-3": 433,
        "entropy-3": 8.800521146353452,
        "cond_entropy-3": 0.035054347555518534,
        "total_length-nopunct": 483,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 5.465737435542043,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6004140786749482,
        "vocab_size-1-nopunct": 290,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.494310304199403,
        "distinct-2-nopunct": 0.8928571428571429,
        "vocab_size-2-nopunct": 400,
        "unique-2-nopunct": 365,
        "entropy-2-nopunct": 8.559507684469056,
        "cond_entropy-2-nopunct": 1.1321617331940157,
        "distinct-3-nopunct": 0.9491525423728814,
        "vocab_size-3-nopunct": 392,
        "unique-3-nopunct": 373,
        "entropy-3-nopunct": 8.584647426614785,
        "cond_entropy-3-nopunct": 0.03887982281300453,
        "msttr-100": 0.704,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.407517418873459,
        "rouge1": {
            "precision": 0.75894,
            "recall": 0.6567,
            "fmeasure": 0.69626
        },
        "rouge2": {
            "precision": 0.49297,
            "recall": 0.4265,
            "fmeasure": 0.45224
        },
        "rougeL": {
            "precision": 0.65007,
            "recall": 0.56446,
            "fmeasure": 0.59779
        },
        "rougeLsum": {
            "precision": 0.65007,
            "recall": 0.56446,
            "fmeasure": 0.59779
        },
        "local_recall": {
            "1": 0.2422680412371134,
            "2": 0.43243243243243246,
            "3": 0.7094972067039106
        },
        "bleu": 43.83444,
        "nubia": {
            "semantic_relation": 3.81651,
            "contradiction": 9.34516,
            "irrelevancy": 35.90495,
            "logical_agreement": 54.74989,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.58867,
            "nubia_score": 0.63151
        },
        "meteor": 0.3459960517219928,
        "bleurt": 0.1363,
        "bertscore": {
            "precision": 0.92801,
            "recall": 0.90375,
            "f1": 0.91442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.760647923290102,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.04171571922345565,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4260379216279915,
        "rouge1": {
            "precision": 0.66342,
            "recall": 0.49,
            "fmeasure": 0.54057
        },
        "rouge2": {
            "precision": 0.40385,
            "recall": 0.33056,
            "fmeasure": 0.3496
        },
        "rougeL": {
            "precision": 0.6039,
            "recall": 0.46312,
            "fmeasure": 0.50354
        },
        "rougeLsum": {
            "precision": 0.6039,
            "recall": 0.46312,
            "fmeasure": 0.50354
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.6363636363636364,
            "3": 0.34615384615384615
        },
        "bleu": 15.90422,
        "nubia": {
            "semantic_relation": 3.35705,
            "contradiction": 49.71218,
            "irrelevancy": 49.8295,
            "logical_agreement": 0.45832,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.80127,
            "nubia_score": 0.27433
        },
        "meteor": 0.2346564611876186,
        "bleurt": -0.56102,
        "bertscore": {
            "precision": 0.88706,
            "recall": 0.84629,
            "f1": 0.86363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 13,
        "total_length": 197,
        "mean_pred_length": 15.153846153846153,
        "std_pred_length": 3.977748761183968,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.6294416243654822,
        "vocab_size-1": 124,
        "unique-1": 102,
        "entropy-1": 6.476221234285712,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 176,
        "unique-2": 171,
        "entropy-2": 7.421633219632224,
        "cond_entropy-2": 0.7649232966039966,
        "distinct-3": 1.0,
        "vocab_size-3": 171,
        "unique-3": 171,
        "entropy-3": 7.417852514885889,
        "cond_entropy-3": 0.003968263519899495,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 13.307692307692308,
        "std_pred_length-nopunct": 3.7082987055981382,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6994219653179191,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.59992517564882,
        "distinct-2-nopunct": 0.95625,
        "vocab_size-2-nopunct": 153,
        "unique-2-nopunct": 149,
        "entropy-2-nopunct": 7.2172100479988455,
        "cond_entropy-2-nopunct": 0.6726044953240403,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.199672344836354,
        "cond_entropy-3-nopunct": -0.008276923505668044,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.4943222754137215,
        "rouge1": {
            "precision": 0.87761,
            "recall": 0.87287,
            "fmeasure": 0.87136
        },
        "rouge2": {
            "precision": 0.67819,
            "recall": 0.66947,
            "fmeasure": 0.67064
        },
        "rougeL": {
            "precision": 0.74538,
            "recall": 0.74354,
            "fmeasure": 0.74051
        },
        "rougeLsum": {
            "precision": 0.74538,
            "recall": 0.74354,
            "fmeasure": 0.74051
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.18181818181818182,
            "3": 0.8881578947368421
        },
        "bleu": 58.13759,
        "nubia": {
            "semantic_relation": 4.70502,
            "contradiction": 0.46444,
            "irrelevancy": 13.77002,
            "logical_agreement": 85.76554,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.26457,
            "nubia_score": 0.86818
        },
        "meteor": 0.487068609886268,
        "bleurt": 0.56032,
        "bertscore": {
            "precision": 0.9572,
            "recall": 0.96341,
            "f1": 0.95984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 67,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 28,
        "distinct-1": 0.6865671641791045,
        "vocab_size-1": 46,
        "unique-1": 34,
        "entropy-1": 5.303112840028461,
        "distinct-2": 0.90625,
        "vocab_size-2": 58,
        "unique-2": 54,
        "entropy-2": 5.788909765557392,
        "cond_entropy-2": 0.4472663247339982,
        "distinct-3": 1.0,
        "vocab_size-3": 61,
        "unique-3": 61,
        "entropy-3": 5.930737337562883,
        "cond_entropy-3": 0.15220905894529504,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.2674817959985125,
        "distinct-2-nopunct": 0.9298245614035088,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.679295496582922,
        "cond_entropy-2-nopunct": 0.42792293565160616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": 0.08412503433508738,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.470082743909732,
        "rouge1": {
            "precision": 0.58699,
            "recall": 0.68989,
            "fmeasure": 0.62476
        },
        "rouge2": {
            "precision": 0.39518,
            "recall": 0.46474,
            "fmeasure": 0.4221
        },
        "rougeL": {
            "precision": 0.45829,
            "recall": 0.54948,
            "fmeasure": 0.49254
        },
        "rougeLsum": {
            "precision": 0.45829,
            "recall": 0.54948,
            "fmeasure": 0.49254
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.8055555555555556
        },
        "bleu": 32.6489,
        "nubia": {
            "semantic_relation": 3.8543,
            "contradiction": 3.57281,
            "irrelevancy": 73.18225,
            "logical_agreement": 23.24494,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.02437,
            "nubia_score": 0.65784
        },
        "meteor": 0.38857453483568977,
        "bleurt": 0.00709,
        "bertscore": {
            "precision": 0.87936,
            "recall": 0.9252,
            "f1": 0.90113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 47,
        "total_length": 793,
        "mean_pred_length": 16.872340425531913,
        "std_pred_length": 6.296290773235599,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.5006305170239597,
        "vocab_size-1": 397,
        "unique-1": 308,
        "entropy-1": 7.494227462536245,
        "distinct-2": 0.8739946380697051,
        "vocab_size-2": 652,
        "unique-2": 582,
        "entropy-2": 9.249941735919926,
        "cond_entropy-2": 1.5366060538201214,
        "distinct-3": 0.944206008583691,
        "vocab_size-3": 660,
        "unique-3": 622,
        "entropy-3": 9.336480709034857,
        "cond_entropy-3": 0.08691874272764362,
        "total_length-nopunct": 683,
        "mean_pred_length-nopunct": 14.53191489361702,
        "std_pred_length-nopunct": 5.546135567892093,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5739385065885798,
        "vocab_size-1-nopunct": 392,
        "unique-1-nopunct": 308,
        "entropy-1-nopunct": 7.787357357485046,
        "distinct-2-nopunct": 0.8836477987421384,
        "vocab_size-2-nopunct": 562,
        "unique-2-nopunct": 508,
        "entropy-2-nopunct": 9.036741991596427,
        "cond_entropy-2-nopunct": 1.3225760808371252,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 558,
        "unique-3-nopunct": 527,
        "entropy-3-nopunct": 9.09686066593577,
        "cond_entropy-3-nopunct": 0.07366472746875441,
        "msttr-100": 0.67857,
        "msttr-100_nopunct": 0.75667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.909051339133981,
        "rouge1": {
            "precision": 0.79074,
            "recall": 0.72363,
            "fmeasure": 0.74338
        },
        "rouge2": {
            "precision": 0.57218,
            "recall": 0.53268,
            "fmeasure": 0.54194
        },
        "rougeL": {
            "precision": 0.70368,
            "recall": 0.65171,
            "fmeasure": 0.66565
        },
        "rougeLsum": {
            "precision": 0.70368,
            "recall": 0.65171,
            "fmeasure": 0.66565
        },
        "local_recall": {
            "1": 0.1953125,
            "2": 0.34108527131782945,
            "3": 0.7727272727272727
        },
        "bleu": 49.6003,
        "nubia": {
            "semantic_relation": 4.11906,
            "contradiction": 8.76876,
            "irrelevancy": 30.6767,
            "logical_agreement": 60.55454,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.38847,
            "nubia_score": 0.71013
        },
        "meteor": 0.4002876694223292,
        "bleurt": 0.27737,
        "bertscore": {
            "precision": 0.93264,
            "recall": 0.92006,
            "f1": 0.92418
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 29,
        "total_length": 423,
        "mean_pred_length": 14.586206896551724,
        "std_pred_length": 4.3669388108700895,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5886524822695035,
        "vocab_size-1": 249,
        "unique-1": 203,
        "entropy-1": 7.2032893875946895,
        "distinct-2": 0.9390862944162437,
        "vocab_size-2": 370,
        "unique-2": 353,
        "entropy-2": 8.479248107511012,
        "cond_entropy-2": 1.0267599438441184,
        "distinct-3": 0.9917808219178083,
        "vocab_size-3": 362,
        "unique-3": 359,
        "entropy-3": 8.495314297603002,
        "cond_entropy-3": 0.014385149391350821,
        "total_length-nopunct": 361,
        "mean_pred_length-nopunct": 12.448275862068966,
        "std_pred_length-nopunct": 3.567924219240782,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6731301939058172,
        "vocab_size-1-nopunct": 243,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 7.42651274109616,
        "distinct-2-nopunct": 0.9427710843373494,
        "vocab_size-2-nopunct": 313,
        "unique-2-nopunct": 300,
        "entropy-2-nopunct": 8.237961795791708,
        "cond_entropy-2-nopunct": 0.8832592995344275,
        "distinct-3-nopunct": 0.9900990099009901,
        "vocab_size-3-nopunct": 300,
        "unique-3-nopunct": 297,
        "entropy-3-nopunct": 8.223372003274934,
        "cond_entropy-3-nopunct": -0.00807081089599703,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.81667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.727635304974794,
        "rouge1": {
            "precision": 0.83224,
            "recall": 0.74851,
            "fmeasure": 0.77919
        },
        "rouge2": {
            "precision": 0.60525,
            "recall": 0.5562,
            "fmeasure": 0.56806
        },
        "rougeL": {
            "precision": 0.72042,
            "recall": 0.65284,
            "fmeasure": 0.67268
        },
        "rougeLsum": {
            "precision": 0.72042,
            "recall": 0.65284,
            "fmeasure": 0.67268
        },
        "local_recall": {
            "1": 0.18461538461538463,
            "2": 0.24489795918367346,
            "3": 0.7731343283582089
        },
        "bleu": 50.18652,
        "nubia": {
            "semantic_relation": 4.51906,
            "contradiction": 5.80439,
            "irrelevancy": 15.41108,
            "logical_agreement": 78.78452,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.73467,
            "nubia_score": 0.81711
        },
        "meteor": 0.41654724700271256,
        "bleurt": 0.42215,
        "bertscore": {
            "precision": 0.9482,
            "recall": 0.93359,
            "f1": 0.93863
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.456256577559485,
        "rouge1": {
            "precision": 0.98333,
            "recall": 0.85714,
            "fmeasure": 0.90789
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.82532,
            "fmeasure": 0.87968
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 0.85714,
            "fmeasure": 0.90789
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 0.85714,
            "fmeasure": 0.90789
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8260869565217391
        },
        "bleu": 76.29824,
        "nubia": {
            "semantic_relation": 4.6451,
            "contradiction": 0.73399,
            "irrelevancy": 0.58772,
            "logical_agreement": 98.67828,
            "grammar_ref": 4.84371,
            "grammar_hyp": 5.22655,
            "nubia_score": 0.8069
        },
        "meteor": 0.5421659494035084,
        "bleurt": 0.70829,
        "bertscore": {
            "precision": 0.98821,
            "recall": 0.95593,
            "f1": 0.97152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 83,
        "mean_pred_length": 16.6,
        "std_pred_length": 5.4626001134990645,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7710843373493976,
        "vocab_size-1": 64,
        "unique-1": 57,
        "entropy-1": 5.750047829167084,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 76,
        "unique-2": 74,
        "entropy-2": 6.234120167580205,
        "cond_entropy-2": 0.37529435811135403,
        "distinct-3": 1.0,
        "vocab_size-3": 73,
        "unique-3": 73,
        "entropy-3": 6.189824558880028,
        "cond_entropy-3": -0.04078313943428607,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.8166378315169185,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8266666666666667,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.755355023771529,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.072140159802115,
        "cond_entropy-2-nopunct": 0.3363182550823275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.045376742378050665,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9949784868026876,
        "rouge1": {
            "precision": 0.75063,
            "recall": 0.66198,
            "fmeasure": 0.70043
        },
        "rouge2": {
            "precision": 0.47737,
            "recall": 0.42528,
            "fmeasure": 0.44767
        },
        "rougeL": {
            "precision": 0.58302,
            "recall": 0.51716,
            "fmeasure": 0.54567
        },
        "rougeLsum": {
            "precision": 0.58302,
            "recall": 0.51716,
            "fmeasure": 0.54567
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "bleu": 32.48502,
        "nubia": {
            "semantic_relation": 4.42535,
            "contradiction": 0.21,
            "irrelevancy": 20.71272,
            "logical_agreement": 79.07728,
            "grammar_ref": 4.6156,
            "grammar_hyp": 5.25706,
            "nubia_score": 0.72846
        },
        "meteor": 0.3454398653084225,
        "bleurt": 0.12781,
        "bertscore": {
            "precision": 0.91216,
            "recall": 0.90517,
            "f1": 0.90841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 520,
        "mean_pred_length": 16.774193548387096,
        "std_pred_length": 6.1942203936508164,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.55,
        "vocab_size-1": 286,
        "unique-1": 238,
        "entropy-1": 7.187221665978554,
        "distinct-2": 0.885480572597137,
        "vocab_size-2": 433,
        "unique-2": 396,
        "entropy-2": 8.649911194889839,
        "cond_entropy-2": 1.2649583324625888,
        "distinct-3": 0.9563318777292577,
        "vocab_size-3": 438,
        "unique-3": 418,
        "entropy-3": 8.751867543555479,
        "cond_entropy-3": 0.1167973164864325,
        "total_length-nopunct": 461,
        "mean_pred_length-nopunct": 14.870967741935484,
        "std_pred_length-nopunct": 5.729054054012593,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6095444685466378,
        "vocab_size-1-nopunct": 281,
        "unique-1-nopunct": 236,
        "entropy-1-nopunct": 7.3477572173219725,
        "distinct-2-nopunct": 0.8883720930232558,
        "vocab_size-2-nopunct": 382,
        "unique-2-nopunct": 350,
        "entropy-2-nopunct": 8.471080022854435,
        "cond_entropy-2-nopunct": 1.2115597239408662,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 380,
        "unique-3-nopunct": 361,
        "entropy-3-nopunct": 8.545006840984227,
        "cond_entropy-3-nopunct": 0.08292555905411779,
        "msttr-100": 0.694,
        "msttr-100_nopunct": 0.7525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.986369775666685,
        "rouge1": {
            "precision": 0.72733,
            "recall": 0.67345,
            "fmeasure": 0.68703
        },
        "rouge2": {
            "precision": 0.50744,
            "recall": 0.4574,
            "fmeasure": 0.47312
        },
        "rougeL": {
            "precision": 0.62186,
            "recall": 0.56443,
            "fmeasure": 0.58151
        },
        "rougeLsum": {
            "precision": 0.62186,
            "recall": 0.56443,
            "fmeasure": 0.58151
        },
        "local_recall": {
            "1": 0.20253164556962025,
            "2": 0.4444444444444444,
            "3": 0.6845070422535211
        },
        "bleu": 39.3885,
        "nubia": {
            "semantic_relation": 4.02357,
            "contradiction": 13.90011,
            "irrelevancy": 27.35309,
            "logical_agreement": 58.7468,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.57555,
            "nubia_score": 0.66906
        },
        "meteor": 0.35509661271446474,
        "bleurt": 0.16922,
        "bertscore": {
            "precision": 0.91655,
            "recall": 0.89791,
            "f1": 0.90551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 16,
        "total_length": 276,
        "mean_pred_length": 17.25,
        "std_pred_length": 5.202163011671203,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6086956521739131,
        "vocab_size-1": 168,
        "unique-1": 132,
        "entropy-1": 6.834573928292045,
        "distinct-2": 0.9346153846153846,
        "vocab_size-2": 243,
        "unique-2": 231,
        "entropy-2": 7.870023041972927,
        "cond_entropy-2": 0.8676922231261566,
        "distinct-3": 0.9877049180327869,
        "vocab_size-3": 241,
        "unique-3": 238,
        "entropy-3": 7.906147173628416,
        "cond_entropy-3": 0.03791723139687747,
        "total_length-nopunct": 245,
        "mean_pred_length-nopunct": 15.3125,
        "std_pred_length-nopunct": 4.946194875861646,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6653061224489796,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.914633592417732,
        "distinct-2-nopunct": 0.9388646288209607,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.692436799125607,
        "cond_entropy-2-nopunct": 0.8335547658547773,
        "distinct-3-nopunct": 0.9859154929577465,
        "vocab_size-3-nopunct": 210,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.706540606141372,
        "cond_entropy-3-nopunct": 0.025128557360992062,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.318684662640762,
        "rouge1": {
            "precision": 0.79259,
            "recall": 0.79768,
            "fmeasure": 0.78695
        },
        "rouge2": {
            "precision": 0.55916,
            "recall": 0.57569,
            "fmeasure": 0.55979
        },
        "rougeL": {
            "precision": 0.68356,
            "recall": 0.69691,
            "fmeasure": 0.68281
        },
        "rougeLsum": {
            "precision": 0.68356,
            "recall": 0.69691,
            "fmeasure": 0.68281
        },
        "local_recall": {
            "1": 0.20454545454545456,
            "2": 0.275,
            "3": 0.8556149732620321
        },
        "bleu": 49.63186,
        "nubia": {
            "semantic_relation": 4.22987,
            "contradiction": 6.01934,
            "irrelevancy": 28.84126,
            "logical_agreement": 65.1394,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.69709,
            "nubia_score": 0.748
        },
        "meteor": 0.417222336115747,
        "bleurt": 0.31551,
        "bertscore": {
            "precision": 0.93333,
            "recall": 0.93651,
            "f1": 0.93356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 136,
        "mean_pred_length": 13.6,
        "std_pred_length": 5.141984052872976,
        "median_pred_length": 12.5,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.5514705882352942,
        "vocab_size-1": 75,
        "unique-1": 54,
        "entropy-1": 5.725597929894577,
        "distinct-2": 0.8174603174603174,
        "vocab_size-2": 103,
        "unique-2": 87,
        "entropy-2": 6.535601475449104,
        "cond_entropy-2": 0.6544429754329577,
        "distinct-3": 0.896551724137931,
        "vocab_size-3": 104,
        "unique-3": 94,
        "entropy-3": 6.633843064093075,
        "cond_entropy-3": 0.06735179968285575,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.560701700396552,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6083333333333333,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.769519162348676,
        "distinct-2-nopunct": 0.8363636363636363,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.366346218484637,
        "cond_entropy-2-nopunct": 0.5774083227566147,
        "distinct-3-nopunct": 0.91,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.443856189774738,
        "cond_entropy-3-nopunct": 0.04901132079409728,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.503610002635261,
        "rouge1": {
            "precision": 0.695,
            "recall": 0.61198,
            "fmeasure": 0.6009
        },
        "rouge2": {
            "precision": 0.42945,
            "recall": 0.37828,
            "fmeasure": 0.36193
        },
        "rougeL": {
            "precision": 0.5264,
            "recall": 0.4841,
            "fmeasure": 0.46532
        },
        "rougeLsum": {
            "precision": 0.5264,
            "recall": 0.4841,
            "fmeasure": 0.46532
        },
        "local_recall": {
            "1": 0.06779661016949153,
            "2": 0.15384615384615385,
            "3": 0.6176470588235294
        },
        "bleu": 21.06396,
        "nubia": {
            "semantic_relation": 3.77719,
            "contradiction": 11.47266,
            "irrelevancy": 44.66974,
            "logical_agreement": 43.8576,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.86475,
            "nubia_score": 0.56936
        },
        "meteor": 0.2890786251462277,
        "bleurt": 0.07382,
        "bertscore": {
            "precision": 0.89282,
            "recall": 0.88206,
            "f1": 0.88404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1074954636563787,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.09091,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "bleu": 7.68785,
        "nubia": {
            "semantic_relation": 2.42531,
            "contradiction": 6.57438,
            "irrelevancy": 93.22366,
            "logical_agreement": 0.20196,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.65364,
            "nubia_score": 0.11927
        },
        "meteor": 0.1591575311673776,
        "bleurt": -0.85128,
        "bertscore": {
            "precision": 0.84187,
            "recall": 0.84277,
            "f1": 0.84232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 64,
        "mean_pred_length": 12.8,
        "std_pred_length": 3.249615361854384,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.578125,
        "vocab_size-1": 37,
        "unique-1": 25,
        "entropy-1": 4.900957868318166,
        "distinct-2": 0.8135593220338984,
        "vocab_size-2": 48,
        "unique-2": 41,
        "entropy-2": 5.441965083260142,
        "cond_entropy-2": 0.43737281128049493,
        "distinct-3": 0.9259259259259259,
        "vocab_size-3": 50,
        "unique-3": 48,
        "entropy-3": 5.569702316978282,
        "cond_entropy-3": 0.02039260094977548,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 11.4,
        "std_pred_length-nopunct": 2.870540018881465,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6140350877192983,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.837643418494553,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.354285871987249,
        "cond_entropy-2-nopunct": 0.45849308769174596,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.512035660188278,
        "cond_entropy-3-nopunct": 0.024361899493992256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4791821694346328,
        "rouge1": {
            "precision": 0.80624,
            "recall": 0.73678,
            "fmeasure": 0.7579
        },
        "rouge2": {
            "precision": 0.63427,
            "recall": 0.59718,
            "fmeasure": 0.60409
        },
        "rougeL": {
            "precision": 0.69836,
            "recall": 0.64547,
            "fmeasure": 0.65958
        },
        "rougeLsum": {
            "precision": 0.69836,
            "recall": 0.64547,
            "fmeasure": 0.65958
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7380952380952381
        },
        "bleu": 36.62349,
        "nubia": {
            "semantic_relation": 4.28182,
            "contradiction": 0.68829,
            "irrelevancy": 15.24636,
            "logical_agreement": 84.06535,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.97887,
            "nubia_score": 0.77804
        },
        "meteor": 0.35871480893355134,
        "bleurt": 0.07301,
        "bertscore": {
            "precision": 0.91998,
            "recall": 0.91532,
            "f1": 0.91701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 28,
        "total_length": 465,
        "mean_pred_length": 16.607142857142858,
        "std_pred_length": 6.763025980148477,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.5763440860215053,
        "vocab_size-1": 268,
        "unique-1": 212,
        "entropy-1": 7.2591897703190895,
        "distinct-2": 0.8993135011441648,
        "vocab_size-2": 393,
        "unique-2": 368,
        "entropy-2": 8.510679015379175,
        "cond_entropy-2": 1.0461052221340716,
        "distinct-3": 0.9779951100244498,
        "vocab_size-3": 400,
        "unique-3": 391,
        "entropy-3": 8.63194725299069,
        "cond_entropy-3": 0.1342332564754702,
        "total_length-nopunct": 411,
        "mean_pred_length-nopunct": 14.678571428571429,
        "std_pred_length-nopunct": 5.80057615013107,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6423357664233577,
        "vocab_size-1-nopunct": 264,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 7.446574304699101,
        "distinct-2-nopunct": 0.9190600522193212,
        "vocab_size-2-nopunct": 352,
        "unique-2-nopunct": 335,
        "entropy-2-nopunct": 8.363917864042744,
        "cond_entropy-2-nopunct": 0.9894578356139127,
        "distinct-3-nopunct": 0.9859154929577465,
        "vocab_size-3-nopunct": 350,
        "unique-3-nopunct": 345,
        "entropy-3-nopunct": 8.443506200307578,
        "cond_entropy-3-nopunct": 0.09390922668926603,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.204246957545476,
        "rouge1": {
            "precision": 0.79928,
            "recall": 0.68046,
            "fmeasure": 0.72212
        },
        "rouge2": {
            "precision": 0.55708,
            "recall": 0.49355,
            "fmeasure": 0.51383
        },
        "rougeL": {
            "precision": 0.6675,
            "recall": 0.58712,
            "fmeasure": 0.61343
        },
        "rougeLsum": {
            "precision": 0.6675,
            "recall": 0.58712,
            "fmeasure": 0.61343
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.49333333333333335,
            "3": 0.716374269005848
        },
        "bleu": 46.11373,
        "nubia": {
            "semantic_relation": 4.03291,
            "contradiction": 8.06509,
            "irrelevancy": 29.60833,
            "logical_agreement": 62.32658,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.6523,
            "nubia_score": 0.65396
        },
        "meteor": 0.37384377634860627,
        "bleurt": 0.22017,
        "bertscore": {
            "precision": 0.92919,
            "recall": 0.91257,
            "f1": 0.91828
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 9,
        "total_length": 128,
        "mean_pred_length": 14.222222222222221,
        "std_pred_length": 4.236816881097249,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6953125,
        "vocab_size-1": 89,
        "unique-1": 77,
        "entropy-1": 6.0382062784312165,
        "distinct-2": 0.9747899159663865,
        "vocab_size-2": 116,
        "unique-2": 113,
        "entropy-2": 6.844397595240715,
        "cond_entropy-2": 0.6276937591635566,
        "distinct-3": 1.0,
        "vocab_size-3": 110,
        "unique-3": 110,
        "entropy-3": 6.781359713524669,
        "cond_entropy-3": -0.05891259523782931,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 12.222222222222221,
        "std_pred_length-nopunct": 3.9938223901358727,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.105172982546449,
        "distinct-2-nopunct": 0.9702970297029703,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.598805542157719,
        "cond_entropy-2-nopunct": 0.512600436614872,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.523561956057027,
        "cond_entropy-3-nopunct": -0.06943213539043404,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.725321685084548,
        "rouge1": {
            "precision": 0.72833,
            "recall": 0.67649,
            "fmeasure": 0.69193
        },
        "rouge2": {
            "precision": 0.47039,
            "recall": 0.43889,
            "fmeasure": 0.44735
        },
        "rougeL": {
            "precision": 0.6291,
            "recall": 0.5844,
            "fmeasure": 0.59741
        },
        "rougeLsum": {
            "precision": 0.6291,
            "recall": 0.5844,
            "fmeasure": 0.59741
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.4090909090909091,
            "3": 0.7910447761194029
        },
        "bleu": 30.22353,
        "nubia": {
            "semantic_relation": 4.01627,
            "contradiction": 11.20629,
            "irrelevancy": 29.15961,
            "logical_agreement": 59.6341,
            "grammar_ref": 5.14381,
            "grammar_hyp": 5.18449,
            "nubia_score": 0.66167
        },
        "meteor": 0.3446596561494239,
        "bleurt": 0.09629,
        "bertscore": {
            "precision": 0.90965,
            "recall": 0.91394,
            "f1": 0.91004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 20,
        "total_length": 354,
        "mean_pred_length": 17.7,
        "std_pred_length": 8.69540108333135,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.5734463276836158,
        "vocab_size-1": 203,
        "unique-1": 158,
        "entropy-1": 7.013422249068839,
        "distinct-2": 0.8892215568862275,
        "vocab_size-2": 297,
        "unique-2": 271,
        "entropy-2": 8.137285841803955,
        "cond_entropy-2": 0.9521423475930211,
        "distinct-3": 0.9426751592356688,
        "vocab_size-3": 296,
        "unique-3": 284,
        "entropy-3": 8.165546465410818,
        "cond_entropy-3": 0.028813112496090205,
        "total_length-nopunct": 296,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 6.185466837676846,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6655405405405406,
        "vocab_size-1-nopunct": 197,
        "unique-1-nopunct": 158,
        "entropy-1-nopunct": 7.191296474579841,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 253,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.928182291883866,
        "cond_entropy-2-nopunct": 0.7686908003484573,
        "distinct-3-nopunct": 0.95703125,
        "vocab_size-3-nopunct": 245,
        "unique-3-nopunct": 237,
        "entropy-3-nopunct": 7.905216162084022,
        "cond_entropy-3-nopunct": -0.012783148167516998,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.562438494151636,
        "rouge1": {
            "precision": 0.81088,
            "recall": 0.79892,
            "fmeasure": 0.80154
        },
        "rouge2": {
            "precision": 0.63829,
            "recall": 0.631,
            "fmeasure": 0.63217
        },
        "rougeL": {
            "precision": 0.67882,
            "recall": 0.67192,
            "fmeasure": 0.67251
        },
        "rougeLsum": {
            "precision": 0.67882,
            "recall": 0.67192,
            "fmeasure": 0.67251
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5185185185185185,
            "3": 0.8666666666666667
        },
        "bleu": 57.28403,
        "nubia": {
            "semantic_relation": 4.45427,
            "contradiction": 1.56569,
            "irrelevancy": 27.47819,
            "logical_agreement": 70.95612,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.59988,
            "nubia_score": 0.81711
        },
        "meteor": 0.4408332257202641,
        "bleurt": 0.44902,
        "bertscore": {
            "precision": 0.94344,
            "recall": 0.94392,
            "f1": 0.94264
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 1322,
        "total_length": 31026,
        "mean_pred_length": 23.468986384266262,
        "std_pred_length": 11.942095178314547,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 89,
        "distinct-1": 0.06343067105008703,
        "vocab_size-1": 1968,
        "unique-1": 721,
        "entropy-1": 7.7646740982310885,
        "distinct-2": 0.20377726905467278,
        "vocab_size-2": 6053,
        "unique-2": 3022,
        "entropy-2": 11.048058475465044,
        "cond_entropy-2": 3.117850255795842,
        "distinct-3": 0.35846663378197446,
        "vocab_size-3": 10174,
        "unique-3": 6130,
        "entropy-3": 12.339159131902504,
        "cond_entropy-3": 1.3629680492064438,
        "total_length-nopunct": 27287,
        "mean_pred_length-nopunct": 20.640695915279878,
        "std_pred_length-nopunct": 10.776519923609946,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 83,
        "distinct-1-nopunct": 0.07179242862901748,
        "vocab_size-1-nopunct": 1959,
        "unique-1-nopunct": 721,
        "entropy-1-nopunct": 8.044913473714228,
        "distinct-2-nopunct": 0.21706142884652416,
        "vocab_size-2-nopunct": 5636,
        "unique-2-nopunct": 2949,
        "entropy-2-nopunct": 10.9561897099626,
        "cond_entropy-2-nopunct": 3.0762645970627287,
        "distinct-3-nopunct": 0.37357464594408146,
        "vocab_size-3-nopunct": 9206,
        "unique-3-nopunct": 5739,
        "entropy-3-nopunct": 12.19729636041677,
        "cond_entropy-3-nopunct": 1.3238121518587085,
        "msttr-100": 0.50571,
        "msttr-100_nopunct": 0.52507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.525534872714949,
        "rouge1": {
            "precision": 0.61079,
            "recall": 0.62325,
            "fmeasure": 0.60913
        },
        "rouge2": {
            "precision": 0.35386,
            "recall": 0.35964,
            "fmeasure": 0.35183
        },
        "rougeL": {
            "precision": 0.49736,
            "recall": 0.51067,
            "fmeasure": 0.49706
        },
        "rougeLsum": {
            "precision": 0.49736,
            "recall": 0.51067,
            "fmeasure": 0.49706
        },
        "local_recall": {
            "1": 0.21628714128502496,
            "2": 0.5062543921293042,
            "3": 0.6606205966122021,
            "4": 0.9411764705882353,
            "5": 0.42857142857142855
        },
        "bleu": 32.38546,
        "nubia": {
            "semantic_relation": 3.41653,
            "contradiction": 43.56475,
            "irrelevancy": 10.37332,
            "logical_agreement": 46.06193,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.79621,
            "nubia_score": 0.51633
        },
        "meteor": 0.29247253150221064,
        "bleurt": -0.24504,
        "bertscore": {
            "precision": 0.87081,
            "recall": 0.87544,
            "f1": 0.87192
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "total_length": 12802,
        "mean_pred_length": 25.604,
        "std_pred_length": 12.42027310488783,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.11263865021090455,
        "vocab_size-1": 1442,
        "unique-1": 559,
        "entropy-1": 7.780130132327112,
        "distinct-2": 0.32563810762477646,
        "vocab_size-2": 4006,
        "unique-2": 2205,
        "entropy-2": 10.901725514615013,
        "cond_entropy-2": 2.9698273348479796,
        "distinct-3": 0.5156753092696154,
        "vocab_size-3": 6086,
        "unique-3": 4120,
        "entropy-3": 11.990459325122115,
        "cond_entropy-3": 1.14431907813906,
        "total_length-nopunct": 11286,
        "mean_pred_length-nopunct": 22.572,
        "std_pred_length-nopunct": 11.260764450071761,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.12697146907673224,
        "vocab_size-1-nopunct": 1433,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.059893445136556,
        "distinct-2-nopunct": 0.34303727053587985,
        "vocab_size-2-nopunct": 3700,
        "unique-2-nopunct": 2150,
        "entropy-2-nopunct": 10.80437385093386,
        "cond_entropy-2-nopunct": 2.8825338176312583,
        "distinct-3-nopunct": 0.5288741979389462,
        "vocab_size-3-nopunct": 5440,
        "unique-3-nopunct": 3792,
        "entropy-3-nopunct": 11.82884027434763,
        "cond_entropy-3-nopunct": 1.0846128517552356,
        "msttr-100": 0.50727,
        "msttr-100_nopunct": 0.52955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "nist": 6.845693565308636,
        "rouge1": {
            "precision": 0.61308,
            "recall": 0.6262,
            "fmeasure": 0.6112
        },
        "rouge2": {
            "precision": 0.35676,
            "recall": 0.36206,
            "fmeasure": 0.35422
        },
        "rougeL": {
            "precision": 0.48538,
            "recall": 0.49642,
            "fmeasure": 0.48392
        },
        "rougeLsum": {
            "precision": 0.48538,
            "recall": 0.49642,
            "fmeasure": 0.48392
        },
        "local_recall": {
            "1": 0.21624827040917177,
            "2": 0.5123854767560231,
            "3": 0.68754674644727,
            "4": 0.4,
            "5": 0.5555555555555556
        },
        "bleu": 34.5319,
        "nubia": {
            "semantic_relation": 3.52152,
            "contradiction": 38.45761,
            "irrelevancy": 11.51934,
            "logical_agreement": 50.02305,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.69689,
            "nubia_score": 0.54267
        },
        "meteor": 0.3001189309115856,
        "bleurt": -0.23576,
        "bertscore": {
            "precision": 0.87171,
            "recall": 0.87678,
            "f1": 0.8731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 273,
        "mean_pred_length": 16.058823529411764,
        "std_pred_length": 6.033929440942271,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5604395604395604,
        "vocab_size-1": 153,
        "unique-1": 120,
        "entropy-1": 6.537849130014864,
        "distinct-2": 0.90234375,
        "vocab_size-2": 231,
        "unique-2": 210,
        "entropy-2": 7.792892382778696,
        "cond_entropy-2": 1.0868657835611912,
        "distinct-3": 0.9748953974895398,
        "vocab_size-3": 233,
        "unique-3": 227,
        "entropy-3": 7.850657602959876,
        "cond_entropy-3": 0.052601797547654254,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 13.176470588235293,
        "std_pred_length-nopunct": 4.090667917814991,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6651785714285714,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.7468865882656175,
        "distinct-2-nopunct": 0.9371980676328503,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.56058949371028,
        "cond_entropy-2-nopunct": 0.8766399183647778,
        "distinct-3-nopunct": 0.9894736842105263,
        "vocab_size-3-nopunct": 188,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.548802976752012,
        "cond_entropy-3-nopunct": -0.01568516493507769,
        "msttr-100": 0.605,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.687840496015899,
        "rouge1": {
            "precision": 0.82104,
            "recall": 0.73521,
            "fmeasure": 0.77062
        },
        "rouge2": {
            "precision": 0.5819,
            "recall": 0.50145,
            "fmeasure": 0.53505
        },
        "rougeL": {
            "precision": 0.74088,
            "recall": 0.64833,
            "fmeasure": 0.68709
        },
        "rougeLsum": {
            "precision": 0.74088,
            "recall": 0.64833,
            "fmeasure": 0.68709
        },
        "local_recall": {
            "1": 0.041666666666666664,
            "2": 0.2916666666666667,
            "3": 0.7464114832535885
        },
        "bleu": 48.65949,
        "nubia": {
            "semantic_relation": 4.07997,
            "contradiction": 6.4646,
            "irrelevancy": 22.28856,
            "logical_agreement": 71.24684,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.6909,
            "nubia_score": 0.66963
        },
        "meteor": 0.38969001130512704,
        "bleurt": 0.28498,
        "bertscore": {
            "precision": 0.94112,
            "recall": 0.9237,
            "f1": 0.93193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 146,
        "mean_pred_length": 18.25,
        "std_pred_length": 11.464619487798101,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 47,
        "distinct-1": 0.6506849315068494,
        "vocab_size-1": 95,
        "unique-1": 79,
        "entropy-1": 6.133791617322594,
        "distinct-2": 0.9202898550724637,
        "vocab_size-2": 127,
        "unique-2": 120,
        "entropy-2": 6.927223369758936,
        "cond_entropy-2": 0.6807380099179351,
        "distinct-3": 0.9692307692307692,
        "vocab_size-3": 126,
        "unique-3": 123,
        "entropy-3": 6.955022524550275,
        "cond_entropy-3": 0.038956144761750036,
        "total_length-nopunct": 124,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 8.717797887081348,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.7338709677419355,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.17459119374931,
        "distinct-2-nopunct": 0.9568965517241379,
        "vocab_size-2-nopunct": 111,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.765266447695114,
        "cond_entropy-2-nopunct": 0.6444411240587445,
        "distinct-3-nopunct": 0.9907407407407407,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.736368983644939,
        "cond_entropy-3-nopunct": -0.022029719795923147,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.521881567228456,
        "rouge1": {
            "precision": 0.72821,
            "recall": 0.62993,
            "fmeasure": 0.6666
        },
        "rouge2": {
            "precision": 0.50588,
            "recall": 0.42364,
            "fmeasure": 0.45232
        },
        "rougeL": {
            "precision": 0.6071,
            "recall": 0.5277,
            "fmeasure": 0.55468
        },
        "rougeLsum": {
            "precision": 0.6071,
            "recall": 0.5277,
            "fmeasure": 0.55468
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.41025641025641024,
            "3": 0.6896551724137931
        },
        "bleu": 32.33041,
        "nubia": {
            "semantic_relation": 3.83383,
            "contradiction": 4.30327,
            "irrelevancy": 37.01222,
            "logical_agreement": 58.68451,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.48417,
            "nubia_score": 0.60065
        },
        "meteor": 0.3394703391411733,
        "bleurt": 0.09511,
        "bertscore": {
            "precision": 0.91325,
            "recall": 0.8971,
            "f1": 0.90204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 46,
        "total_length": 717,
        "mean_pred_length": 15.58695652173913,
        "std_pred_length": 5.803207834639621,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5397489539748954,
        "vocab_size-1": 387,
        "unique-1": 315,
        "entropy-1": 7.578367335358105,
        "distinct-2": 0.9001490312965723,
        "vocab_size-2": 604,
        "unique-2": 558,
        "entropy-2": 9.143113162592485,
        "cond_entropy-2": 1.3168462755132881,
        "distinct-3": 0.9648,
        "vocab_size-3": 603,
        "unique-3": 581,
        "entropy-3": 9.217312379549439,
        "cond_entropy-3": 0.07638252336657395,
        "total_length-nopunct": 630,
        "mean_pred_length-nopunct": 13.695652173913043,
        "std_pred_length-nopunct": 5.266256674078646,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6047619047619047,
        "vocab_size-1-nopunct": 381,
        "unique-1-nopunct": 314,
        "entropy-1-nopunct": 7.793875213560815,
        "distinct-2-nopunct": 0.9075342465753424,
        "vocab_size-2-nopunct": 530,
        "unique-2-nopunct": 495,
        "entropy-2-nopunct": 8.953909426155933,
        "cond_entropy-2-nopunct": 1.2368262765165077,
        "distinct-3-nopunct": 0.9628252788104089,
        "vocab_size-3-nopunct": 518,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.997112920177479,
        "cond_entropy-3-nopunct": 0.05593973213537487,
        "msttr-100": 0.71143,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.226063972260974,
        "rouge1": {
            "precision": 0.79123,
            "recall": 0.71661,
            "fmeasure": 0.74042
        },
        "rouge2": {
            "precision": 0.55677,
            "recall": 0.51559,
            "fmeasure": 0.52669
        },
        "rougeL": {
            "precision": 0.70454,
            "recall": 0.65021,
            "fmeasure": 0.66606
        },
        "rougeLsum": {
            "precision": 0.70454,
            "recall": 0.65021,
            "fmeasure": 0.66606
        },
        "local_recall": {
            "1": 0.17272727272727273,
            "2": 0.34306569343065696,
            "3": 0.7233201581027668
        },
        "bleu": 43.00473,
        "nubia": {
            "semantic_relation": 4.21797,
            "contradiction": 10.865,
            "irrelevancy": 29.81887,
            "logical_agreement": 59.31613,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.72668,
            "nubia_score": 0.71253
        },
        "meteor": 0.3683389013734863,
        "bleurt": 0.27992,
        "bertscore": {
            "precision": 0.93046,
            "recall": 0.91691,
            "f1": 0.92236
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 191,
        "mean_pred_length": 17.363636363636363,
        "std_pred_length": 8.626309937655606,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.6701570680628273,
        "vocab_size-1": 128,
        "unique-1": 107,
        "entropy-1": 6.532069175091533,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 172,
        "unique-2": 165,
        "entropy-2": 7.3987703879843085,
        "cond_entropy-2": 0.704446320019648,
        "distinct-3": 0.9940828402366864,
        "vocab_size-3": 168,
        "unique-3": 167,
        "entropy-3": 7.389045116755549,
        "cond_entropy-3": -0.003666633407469696,
        "total_length-nopunct": 165,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 7.954415583355403,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7454545454545455,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.649117993472251,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.170975582888663,
        "cond_entropy-2-nopunct": 0.573086462328786,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.159871336778397,
        "cond_entropy-3-nopunct": -0.003734172432851247,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.771932464370609,
        "rouge1": {
            "precision": 0.71095,
            "recall": 0.60548,
            "fmeasure": 0.62946
        },
        "rouge2": {
            "precision": 0.44669,
            "recall": 0.37442,
            "fmeasure": 0.39185
        },
        "rougeL": {
            "precision": 0.60465,
            "recall": 0.48575,
            "fmeasure": 0.51953
        },
        "rougeLsum": {
            "precision": 0.60465,
            "recall": 0.48575,
            "fmeasure": 0.51953
        },
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.4,
            "3": 0.7058823529411765
        },
        "bleu": 38.36589,
        "nubia": {
            "semantic_relation": 3.55367,
            "contradiction": 9.77513,
            "irrelevancy": 38.47161,
            "logical_agreement": 51.75325,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.26789,
            "nubia_score": 0.50645
        },
        "meteor": 0.3171368523393559,
        "bleurt": -0.12429,
        "bertscore": {
            "precision": 0.90065,
            "recall": 0.87602,
            "f1": 0.8871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 15,
        "total_length": 247,
        "mean_pred_length": 16.466666666666665,
        "std_pred_length": 8.875935005520386,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.582995951417004,
        "vocab_size-1": 144,
        "unique-1": 110,
        "entropy-1": 6.586869356468891,
        "distinct-2": 0.8620689655172413,
        "vocab_size-2": 200,
        "unique-2": 176,
        "entropy-2": 7.549749206315802,
        "cond_entropy-2": 0.798307044642673,
        "distinct-3": 0.9354838709677419,
        "vocab_size-3": 203,
        "unique-3": 189,
        "entropy-3": 7.632518974379976,
        "cond_entropy-3": 0.05799316360412821,
        "total_length-nopunct": 206,
        "mean_pred_length-nopunct": 13.733333333333333,
        "std_pred_length-nopunct": 6.475252032846975,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6747572815533981,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.690872202933098,
        "distinct-2-nopunct": 0.8900523560209425,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.332638841113428,
        "cond_entropy-2-nopunct": 0.682418469920172,
        "distinct-3-nopunct": 0.9488636363636364,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.35715889136458,
        "cond_entropy-3-nopunct": 0.01600825935564603,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.436004729736812,
        "rouge1": {
            "precision": 0.75788,
            "recall": 0.69078,
            "fmeasure": 0.71098
        },
        "rouge2": {
            "precision": 0.49602,
            "recall": 0.45549,
            "fmeasure": 0.46844
        },
        "rougeL": {
            "precision": 0.64445,
            "recall": 0.58265,
            "fmeasure": 0.60214
        },
        "rougeLsum": {
            "precision": 0.64445,
            "recall": 0.58265,
            "fmeasure": 0.60214
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.29545454545454547,
            "3": 0.7707006369426752
        },
        "bleu": 42.12049,
        "nubia": {
            "semantic_relation": 4.18448,
            "contradiction": 8.56203,
            "irrelevancy": 43.77861,
            "logical_agreement": 47.65936,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.72921,
            "nubia_score": 0.68792
        },
        "meteor": 0.3545737221322077,
        "bleurt": 0.20452,
        "bertscore": {
            "precision": 0.91709,
            "recall": 0.91176,
            "f1": 0.91382
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 275,
        "mean_pred_length": 16.176470588235293,
        "std_pred_length": 4.889788809557743,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.5709090909090909,
        "vocab_size-1": 157,
        "unique-1": 123,
        "entropy-1": 6.549783354747344,
        "distinct-2": 0.875968992248062,
        "vocab_size-2": 226,
        "unique-2": 204,
        "entropy-2": 7.724892747745211,
        "cond_entropy-2": 1.0081431426531113,
        "distinct-3": 0.941908713692946,
        "vocab_size-3": 227,
        "unique-3": 216,
        "entropy-3": 7.785275695142178,
        "cond_entropy-3": 0.08058081723311288,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.764705882352942,
        "std_pred_length-nopunct": 4.037025867476116,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6538461538461539,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.703020995539621,
        "distinct-2-nopunct": 0.8986175115207373,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 7.522499144974784,
        "cond_entropy-2-nopunct": 0.9017124503970931,
        "distinct-3-nopunct": 0.955,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.550081752263924,
        "cond_entropy-3-nopunct": 0.04290203472406409,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.936457622769197,
        "rouge1": {
            "precision": 0.80423,
            "recall": 0.75033,
            "fmeasure": 0.76769
        },
        "rouge2": {
            "precision": 0.56356,
            "recall": 0.53866,
            "fmeasure": 0.54407
        },
        "rougeL": {
            "precision": 0.65771,
            "recall": 0.62884,
            "fmeasure": 0.63613
        },
        "rougeLsum": {
            "precision": 0.65771,
            "recall": 0.62884,
            "fmeasure": 0.63613
        },
        "local_recall": {
            "1": 0.12307692307692308,
            "2": 0.45614035087719296,
            "3": 0.8081395348837209
        },
        "bleu": 40.20631,
        "nubia": {
            "semantic_relation": 4.20851,
            "contradiction": 11.96092,
            "irrelevancy": 26.35812,
            "logical_agreement": 61.68096,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.90863,
            "nubia_score": 0.71172
        },
        "meteor": 0.38842986576856725,
        "bleurt": 0.22988,
        "bertscore": {
            "precision": 0.93915,
            "recall": 0.93266,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8754507884479708,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.7,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.37778,
            "fmeasure": 0.33766
        },
        "rougeL": {
            "precision": 0.51282,
            "recall": 0.62424,
            "fmeasure": 0.5628
        },
        "rougeLsum": {
            "precision": 0.51282,
            "recall": 0.62424,
            "fmeasure": 0.5628
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "bleu": 20.44801,
        "nubia": {
            "semantic_relation": 3.31294,
            "contradiction": 0.28774,
            "irrelevancy": 25.67606,
            "logical_agreement": 74.03621,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.43569,
            "nubia_score": 0.48812
        },
        "meteor": 0.30876893976261716,
        "bleurt": -0.11464,
        "bertscore": {
            "precision": 0.86753,
            "recall": 0.85639,
            "f1": 0.86192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 26,
        "total_length": 461,
        "mean_pred_length": 17.73076923076923,
        "std_pred_length": 5.939163968022204,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5509761388286334,
        "vocab_size-1": 254,
        "unique-1": 202,
        "entropy-1": 7.156397261869144,
        "distinct-2": 0.8758620689655172,
        "vocab_size-2": 381,
        "unique-2": 346,
        "entropy-2": 8.466828509145838,
        "cond_entropy-2": 1.1306299483592805,
        "distinct-3": 0.9584352078239609,
        "vocab_size-3": 392,
        "unique-3": 377,
        "entropy-3": 8.589136067161041,
        "cond_entropy-3": 0.12962842016471565,
        "total_length-nopunct": 405,
        "mean_pred_length-nopunct": 15.576923076923077,
        "std_pred_length-nopunct": 5.024348996659834,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6123456790123457,
        "vocab_size-1-nopunct": 248,
        "unique-1-nopunct": 201,
        "entropy-1-nopunct": 7.257266495981893,
        "distinct-2-nopunct": 0.8865435356200527,
        "vocab_size-2-nopunct": 336,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 8.286003997307157,
        "cond_entropy-2-nopunct": 1.0978072945802881,
        "distinct-3-nopunct": 0.9660056657223796,
        "vocab_size-3-nopunct": 341,
        "unique-3-nopunct": 330,
        "entropy-3-nopunct": 8.393397213208356,
        "cond_entropy-3-nopunct": 0.12518726990250764,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.7225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.428032674175979,
        "rouge1": {
            "precision": 0.74603,
            "recall": 0.72356,
            "fmeasure": 0.72406
        },
        "rouge2": {
            "precision": 0.51112,
            "recall": 0.50532,
            "fmeasure": 0.50063
        },
        "rougeL": {
            "precision": 0.60935,
            "recall": 0.60759,
            "fmeasure": 0.59995
        },
        "rougeLsum": {
            "precision": 0.60935,
            "recall": 0.60759,
            "fmeasure": 0.59995
        },
        "local_recall": {
            "1": 0.25882352941176473,
            "2": 0.5597014925373134,
            "3": 0.7283464566929134
        },
        "bleu": 44.95806,
        "nubia": {
            "semantic_relation": 4.14018,
            "contradiction": 13.09308,
            "irrelevancy": 39.6932,
            "logical_agreement": 47.21372,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.47839,
            "nubia_score": 0.72037
        },
        "meteor": 0.39405031415818026,
        "bleurt": 0.17756,
        "bertscore": {
            "precision": 0.92293,
            "recall": 0.9238,
            "f1": 0.92137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 166,
        "mean_pred_length": 13.833333333333334,
        "std_pred_length": 5.193478816960961,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.608433734939759,
        "vocab_size-1": 101,
        "unique-1": 78,
        "entropy-1": 6.1126968107346595,
        "distinct-2": 0.961038961038961,
        "vocab_size-2": 148,
        "unique-2": 145,
        "entropy-2": 7.165425238912864,
        "cond_entropy-2": 0.8717450608969639,
        "distinct-3": 1.0,
        "vocab_size-3": 142,
        "unique-3": 142,
        "entropy-3": 7.149747119504689,
        "cond_entropy-3": -0.007112375595593694,
        "total_length-nopunct": 146,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.86198404860494,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6643835616438356,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.15544407936869,
        "distinct-2-nopunct": 0.9552238805970149,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 6.949599336170938,
        "cond_entropy-2-nopunct": 0.8718609713853452,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.930737337562902,
        "cond_entropy-3-nopunct": -0.007403980153600978,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.889464247966087,
        "rouge1": {
            "precision": 0.78221,
            "recall": 0.68416,
            "fmeasure": 0.7151
        },
        "rouge2": {
            "precision": 0.48964,
            "recall": 0.40123,
            "fmeasure": 0.42813
        },
        "rougeL": {
            "precision": 0.64725,
            "recall": 0.55758,
            "fmeasure": 0.58576
        },
        "rougeLsum": {
            "precision": 0.64725,
            "recall": 0.55758,
            "fmeasure": 0.58576
        },
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.42857142857142855,
            "3": 0.6635514018691588
        },
        "bleu": 33.87476,
        "nubia": {
            "semantic_relation": 3.9577,
            "contradiction": 18.82137,
            "irrelevancy": 25.78009,
            "logical_agreement": 55.39854,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.39889,
            "nubia_score": 0.59801
        },
        "meteor": 0.34886014243782404,
        "bleurt": -0.11252,
        "bertscore": {
            "precision": 0.89351,
            "recall": 0.88525,
            "f1": 0.88698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 5.816935163286381,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 78,
        "unique-1": 59,
        "entropy-1": 6.04873208316843,
        "distinct-2": 0.9423076923076923,
        "vocab_size-2": 98,
        "unique-2": 92,
        "entropy-2": 6.585055102756483,
        "cond_entropy-2": 0.3975566929329452,
        "distinct-3": 0.9690721649484536,
        "vocab_size-3": 94,
        "unique-3": 91,
        "entropy-3": 6.538057172084048,
        "cond_entropy-3": -0.03867120585087167,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 13.571428571428571,
        "std_pred_length-nopunct": 5.260557897006277,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7684210526315789,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.031756498028171,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.368522527728214,
        "cond_entropy-2-nopunct": 0.3682057316559377,
        "distinct-3-nopunct": 0.9876543209876543,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.315158644859922,
        "cond_entropy-3-nopunct": -0.04550754167859832,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.844030397671824,
        "rouge1": {
            "precision": 0.75068,
            "recall": 0.76053,
            "fmeasure": 0.74894
        },
        "rouge2": {
            "precision": 0.55641,
            "recall": 0.56041,
            "fmeasure": 0.55415
        },
        "rougeL": {
            "precision": 0.69842,
            "recall": 0.71434,
            "fmeasure": 0.70112
        },
        "rougeLsum": {
            "precision": 0.69842,
            "recall": 0.71434,
            "fmeasure": 0.70112
        },
        "local_recall": {
            "1": 0.10256410256410256,
            "2": 0.4444444444444444,
            "3": 0.8412698412698413
        },
        "bleu": 45.87013,
        "nubia": {
            "semantic_relation": 4.36729,
            "contradiction": 28.17723,
            "irrelevancy": 4.87027,
            "logical_agreement": 66.9525,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.3917,
            "nubia_score": 0.80434
        },
        "meteor": 0.4212839601112543,
        "bleurt": 0.3537,
        "bertscore": {
            "precision": 0.93468,
            "recall": 0.94881,
            "f1": 0.94018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 260,
        "mean_pred_length": 15.294117647058824,
        "std_pred_length": 4.402735859097466,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.5923076923076923,
        "vocab_size-1": 154,
        "unique-1": 118,
        "entropy-1": 6.712999221724038,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 225,
        "unique-2": 208,
        "entropy-2": 7.773557822526903,
        "cond_entropy-2": 0.8662063281729214,
        "distinct-3": 0.9690265486725663,
        "vocab_size-3": 219,
        "unique-3": 212,
        "entropy-3": 7.7582320597603465,
        "cond_entropy-3": -0.012797755782789936,
        "total_length-nopunct": 230,
        "mean_pred_length-nopunct": 13.529411764705882,
        "std_pred_length-nopunct": 4.340203940163933,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6478260869565218,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.789190201214406,
        "distinct-2-nopunct": 0.9248826291079812,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.580930805661726,
        "cond_entropy-2-nopunct": 0.8319508392953132,
        "distinct-3-nopunct": 0.9744897959183674,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.563689435951929,
        "cond_entropy-3-nopunct": -0.01920953375265299,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.078493576453362,
        "rouge1": {
            "precision": 0.76882,
            "recall": 0.74413,
            "fmeasure": 0.74933
        },
        "rouge2": {
            "precision": 0.56226,
            "recall": 0.55613,
            "fmeasure": 0.55373
        },
        "rougeL": {
            "precision": 0.66653,
            "recall": 0.63782,
            "fmeasure": 0.64521
        },
        "rougeLsum": {
            "precision": 0.66653,
            "recall": 0.63782,
            "fmeasure": 0.64521
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4489795918367347,
            "3": 0.7741935483870968
        },
        "bleu": 49.22542,
        "nubia": {
            "semantic_relation": 4.28606,
            "contradiction": 9.11026,
            "irrelevancy": 35.11355,
            "logical_agreement": 55.77619,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.18753,
            "nubia_score": 0.74867
        },
        "meteor": 0.3927787423665836,
        "bleurt": 0.28021,
        "bertscore": {
            "precision": 0.92839,
            "recall": 0.92703,
            "f1": 0.92655
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 898,
        "total_length": 9769,
        "mean_pred_length": 10.878619153674833,
        "std_pred_length": 3.8266690301216193,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 34,
        "distinct-1": 0.3247005834783499,
        "vocab_size-1": 3172,
        "unique-1": 2372,
        "entropy-1": 8.941929511087164,
        "distinct-2": 0.65652124901364,
        "vocab_size-2": 5824,
        "unique-2": 4999,
        "entropy-2": 11.762185081705828,
        "cond_entropy-2": 2.2631617553981953,
        "distinct-3": 0.8059701492537313,
        "vocab_size-3": 6426,
        "unique-3": 5817,
        "entropy-3": 12.373223532765975,
        "cond_entropy-3": 0.5847003231315072,
        "total_length-nopunct": 8506,
        "mean_pred_length-nopunct": 9.47216035634744,
        "std_pred_length-nopunct": 3.3695551656524234,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3715024688455208,
        "vocab_size-1-nopunct": 3160,
        "unique-1-nopunct": 2370,
        "entropy-1-nopunct": 9.408630378758847,
        "distinct-2-nopunct": 0.6804679284963197,
        "vocab_size-2-nopunct": 5177,
        "unique-2-nopunct": 4513,
        "entropy-2-nopunct": 11.615240456706552,
        "cond_entropy-2-nopunct": 2.41529272412439,
        "distinct-3-nopunct": 0.8152011922503726,
        "vocab_size-3-nopunct": 5470,
        "unique-3-nopunct": 4972,
        "entropy-3-nopunct": 12.154984056080485,
        "cond_entropy-3-nopunct": 0.6249996480668838,
        "msttr-100": 0.69577,
        "msttr-100_nopunct": 0.74812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.553907979288427,
        "rouge1": {
            "precision": 0.74582,
            "recall": 0.70874,
            "fmeasure": 0.71011
        },
        "rouge2": {
            "precision": 0.55002,
            "recall": 0.52722,
            "fmeasure": 0.52591
        },
        "rougeL": {
            "precision": 0.70701,
            "recall": 0.67497,
            "fmeasure": 0.67507
        },
        "rougeLsum": {
            "precision": 0.70701,
            "recall": 0.67497,
            "fmeasure": 0.67507
        },
        "local_recall": {
            "1": 0.2306464485235435,
            "2": 0.5287846481876333,
            "3": 0.7351581283521361
        },
        "bleu": 48.73409,
        "nubia": {
            "semantic_relation": 4.05769,
            "contradiction": 10.2061,
            "irrelevancy": 31.56082,
            "logical_agreement": 58.23308,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.12944,
            "nubia_score": 0.68857
        },
        "meteor": 0.3941055529953211,
        "bleurt": 0.28304,
        "bertscore": {
            "precision": 0.92653,
            "recall": 0.92047,
            "f1": 0.92195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 285,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 5.890199015690763,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.624561403508772,
        "vocab_size-1": 178,
        "unique-1": 150,
        "entropy-1": 6.848372561513184,
        "distinct-2": 0.947565543071161,
        "vocab_size-2": 253,
        "unique-2": 246,
        "entropy-2": 7.929162540381286,
        "cond_entropy-2": 0.8877464201780327,
        "distinct-3": 1.0,
        "vocab_size-3": 249,
        "unique-3": 249,
        "entropy-3": 7.960001932068083,
        "cond_entropy-3": 0.03231570109845391,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 13.722222222222221,
        "std_pred_length-nopunct": 4.568072235704825,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6963562753036437,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 6.9359824134723125,
        "distinct-2-nopunct": 0.9519650655021834,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.71534122051354,
        "cond_entropy-2-nopunct": 0.850201281827375,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.721099188707212,
        "cond_entropy-3-nopunct": 0.01632444315337008,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.609681616649852,
        "rouge1": {
            "precision": 0.72929,
            "recall": 0.67435,
            "fmeasure": 0.69058
        },
        "rouge2": {
            "precision": 0.50231,
            "recall": 0.45941,
            "fmeasure": 0.47195
        },
        "rougeL": {
            "precision": 0.64023,
            "recall": 0.61674,
            "fmeasure": 0.61548
        },
        "rougeLsum": {
            "precision": 0.64023,
            "recall": 0.61674,
            "fmeasure": 0.61548
        },
        "local_recall": {
            "1": 0.17777777777777778,
            "2": 0.2,
            "3": 0.702020202020202
        },
        "bleu": 42.32131,
        "nubia": {
            "semantic_relation": 4.1155,
            "contradiction": 8.1707,
            "irrelevancy": 29.47573,
            "logical_agreement": 62.35357,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.41545,
            "nubia_score": 0.69662
        },
        "meteor": 0.38000514171926386,
        "bleurt": 0.20096,
        "bertscore": {
            "precision": 0.91616,
            "recall": 0.9098,
            "f1": 0.90833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 346,
        "mean_pred_length": 20.352941176470587,
        "std_pred_length": 9.361631183095417,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 51,
        "distinct-1": 0.5086705202312138,
        "vocab_size-1": 176,
        "unique-1": 123,
        "entropy-1": 6.804730173008918,
        "distinct-2": 0.8389057750759878,
        "vocab_size-2": 276,
        "unique-2": 231,
        "entropy-2": 8.019909351203404,
        "cond_entropy-2": 1.0881925478826553,
        "distinct-3": 0.9006410256410257,
        "vocab_size-3": 281,
        "unique-3": 253,
        "entropy-3": 8.079425736469604,
        "cond_entropy-3": 0.07174261982729685,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 17.58823529411765,
        "std_pred_length-nopunct": 7.211582379424429,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5719063545150501,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.879067427768309,
        "distinct-2-nopunct": 0.8404255319148937,
        "vocab_size-2-nopunct": 237,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.797248781430804,
        "cond_entropy-2-nopunct": 0.9702875848250823,
        "distinct-3-nopunct": 0.9018867924528302,
        "vocab_size-3-nopunct": 239,
        "unique-3-nopunct": 216,
        "entropy-3-nopunct": 7.84507623810527,
        "cond_entropy-3-nopunct": 0.05846573481210941,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.4737706594378714,
        "rouge1": {
            "precision": 0.69034,
            "recall": 0.74598,
            "fmeasure": 0.7079
        },
        "rouge2": {
            "precision": 0.45874,
            "recall": 0.50694,
            "fmeasure": 0.47369
        },
        "rougeL": {
            "precision": 0.56925,
            "recall": 0.62472,
            "fmeasure": 0.5874
        },
        "rougeLsum": {
            "precision": 0.56925,
            "recall": 0.62472,
            "fmeasure": 0.5874
        },
        "local_recall": {
            "1": 0.22,
            "2": 0.5,
            "3": 0.7735849056603774
        },
        "bleu": 38.64561,
        "nubia": {
            "semantic_relation": 3.81017,
            "contradiction": 26.82379,
            "irrelevancy": 37.91375,
            "logical_agreement": 35.26246,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.33703,
            "nubia_score": 0.62641
        },
        "meteor": 0.39138241258890666,
        "bleurt": 0.07509,
        "bertscore": {
            "precision": 0.90504,
            "recall": 0.92189,
            "f1": 0.90952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 271,
        "mean_pred_length": 15.055555555555555,
        "std_pred_length": 10.069051716479352,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 54,
        "distinct-1": 0.5719557195571956,
        "vocab_size-1": 155,
        "unique-1": 122,
        "entropy-1": 6.621195998920536,
        "distinct-2": 0.8656126482213439,
        "vocab_size-2": 219,
        "unique-2": 195,
        "entropy-2": 7.674538633914411,
        "cond_entropy-2": 0.8606094521394916,
        "distinct-3": 0.9106382978723404,
        "vocab_size-3": 214,
        "unique-3": 198,
        "entropy-3": 7.6817321060934285,
        "cond_entropy-3": 0.013798531472776255,
        "total_length-nopunct": 235,
        "mean_pred_length-nopunct": 13.055555555555555,
        "std_pred_length-nopunct": 7.968495063702236,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.6425531914893617,
        "vocab_size-1-nopunct": 151,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.709153970137388,
        "distinct-2-nopunct": 0.8755760368663594,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.466440172456892,
        "cond_entropy-2-nopunct": 0.8218600897651038,
        "distinct-3-nopunct": 0.9195979899497487,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 172,
        "entropy-3-nopunct": 7.456853577775731,
        "cond_entropy-3-nopunct": 0.0020314911468600977,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.715,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.75800005988437,
        "rouge1": {
            "precision": 0.79727,
            "recall": 0.74925,
            "fmeasure": 0.76006
        },
        "rouge2": {
            "precision": 0.5192,
            "recall": 0.48662,
            "fmeasure": 0.49267
        },
        "rougeL": {
            "precision": 0.67512,
            "recall": 0.6332,
            "fmeasure": 0.64263
        },
        "rougeLsum": {
            "precision": 0.67512,
            "recall": 0.6332,
            "fmeasure": 0.64263
        },
        "local_recall": {
            "1": 0.17307692307692307,
            "2": 0.3448275862068966,
            "3": 0.7880434782608695
        },
        "bleu": 37.90943,
        "nubia": {
            "semantic_relation": 4.31874,
            "contradiction": 6.40931,
            "irrelevancy": 22.2302,
            "logical_agreement": 71.36049,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.81122,
            "nubia_score": 0.74664
        },
        "meteor": 0.4059220269118887,
        "bleurt": 0.20549,
        "bertscore": {
            "precision": 0.92848,
            "recall": 0.92227,
            "f1": 0.92455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 19,
        "total_length": 338,
        "mean_pred_length": 17.789473684210527,
        "std_pred_length": 6.661586245177575,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5650887573964497,
        "vocab_size-1": 191,
        "unique-1": 155,
        "entropy-1": 6.853978908655948,
        "distinct-2": 0.890282131661442,
        "vocab_size-2": 284,
        "unique-2": 259,
        "entropy-2": 8.064969588645868,
        "cond_entropy-2": 1.0457069063912026,
        "distinct-3": 0.9566666666666667,
        "vocab_size-3": 287,
        "unique-3": 274,
        "entropy-3": 8.14215202382927,
        "cond_entropy-3": 0.07065420176706931,
        "total_length-nopunct": 286,
        "mean_pred_length-nopunct": 15.052631578947368,
        "std_pred_length-nopunct": 5.124489029321299,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6503496503496503,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.999306627907261,
        "distinct-2-nopunct": 0.9176029962546817,
        "vocab_size-2-nopunct": 245,
        "unique-2-nopunct": 230,
        "entropy-2-nopunct": 7.86494813203774,
        "cond_entropy-2-nopunct": 0.9107753223648247,
        "distinct-3-nopunct": 0.9556451612903226,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 226,
        "entropy-3-nopunct": 7.865486632967544,
        "cond_entropy-3-nopunct": 0.002753352509999014,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.568444999587056,
        "rouge1": {
            "precision": 0.70939,
            "recall": 0.68301,
            "fmeasure": 0.68452
        },
        "rouge2": {
            "precision": 0.44903,
            "recall": 0.42945,
            "fmeasure": 0.42954
        },
        "rougeL": {
            "precision": 0.59896,
            "recall": 0.591,
            "fmeasure": 0.58515
        },
        "rougeLsum": {
            "precision": 0.59896,
            "recall": 0.591,
            "fmeasure": 0.58515
        },
        "local_recall": {
            "1": 0.21311475409836064,
            "2": 0.3728813559322034,
            "3": 0.7198067632850241
        },
        "bleu": 39.88413,
        "nubia": {
            "semantic_relation": 3.87538,
            "contradiction": 9.16352,
            "irrelevancy": 43.89082,
            "logical_agreement": 46.94566,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.40595,
            "nubia_score": 0.64555
        },
        "meteor": 0.35639618939596557,
        "bleurt": 0.07688,
        "bertscore": {
            "precision": 0.90697,
            "recall": 0.9045,
            "f1": 0.90402
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 325,
        "mean_pred_length": 18.055555555555557,
        "std_pred_length": 7.670087803511786,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.6030769230769231,
        "vocab_size-1": 196,
        "unique-1": 161,
        "entropy-1": 6.957841379504415,
        "distinct-2": 0.9348534201954397,
        "vocab_size-2": 287,
        "unique-2": 270,
        "entropy-2": 8.122828110835412,
        "cond_entropy-2": 1.001786508156546,
        "distinct-3": 0.9792387543252595,
        "vocab_size-3": 283,
        "unique-3": 277,
        "entropy-3": 8.133403191151178,
        "cond_entropy-3": 0.019249132985736342,
        "total_length-nopunct": 288,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.847546194724712,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.65625,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 7.051049644501571,
        "distinct-2-nopunct": 0.9407407407407408,
        "vocab_size-2-nopunct": 254,
        "unique-2-nopunct": 241,
        "entropy-2-nopunct": 7.948093791487276,
        "cond_entropy-2-nopunct": 0.9642284300409771,
        "distinct-3-nopunct": 0.9801587301587301,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 242,
        "entropy-3-nopunct": 7.937597383817388,
        "cond_entropy-3-nopunct": -0.001301992986773662,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.505869620399953,
        "rouge1": {
            "precision": 0.71312,
            "recall": 0.69072,
            "fmeasure": 0.69343
        },
        "rouge2": {
            "precision": 0.47469,
            "recall": 0.45924,
            "fmeasure": 0.45979
        },
        "rougeL": {
            "precision": 0.60586,
            "recall": 0.60164,
            "fmeasure": 0.59374
        },
        "rougeLsum": {
            "precision": 0.60586,
            "recall": 0.60164,
            "fmeasure": 0.59374
        },
        "local_recall": {
            "1": 0.27941176470588236,
            "2": 0.5211267605633803,
            "3": 0.6935483870967742
        },
        "bleu": 33.31936,
        "nubia": {
            "semantic_relation": 3.76662,
            "contradiction": 26.42239,
            "irrelevancy": 29.88822,
            "logical_agreement": 43.68939,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.41515,
            "nubia_score": 0.6032
        },
        "meteor": 0.36428238182433736,
        "bleurt": 0.13541,
        "bertscore": {
            "precision": 0.91608,
            "recall": 0.91331,
            "f1": 0.91366
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 457,
        "total_length": 14846,
        "mean_pred_length": 32.48577680525164,
        "std_pred_length": 12.071827117489732,
        "median_pred_length": 31.0,
        "min_pred_length": 8,
        "max_pred_length": 76,
        "distinct-1": 0.08898019668597602,
        "vocab_size-1": 1321,
        "unique-1": 548,
        "entropy-1": 7.646744187043293,
        "distinct-2": 0.25234554173326845,
        "vocab_size-2": 3631,
        "unique-2": 2025,
        "entropy-2": 10.496342093525987,
        "cond_entropy-2": 2.7395033965244493,
        "distinct-3": 0.40015790984783234,
        "vocab_size-3": 5575,
        "unique-3": 3723,
        "entropy-3": 11.517813153846074,
        "cond_entropy-3": 1.0687789162761765,
        "total_length-nopunct": 13081,
        "mean_pred_length-nopunct": 28.62363238512035,
        "std_pred_length-nopunct": 10.702590206767981,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.10022169558902225,
        "vocab_size-1-nopunct": 1311,
        "unique-1-nopunct": 546,
        "entropy-1-nopunct": 7.909645442304916,
        "distinct-2-nopunct": 0.26655576679340937,
        "vocab_size-2-nopunct": 3365,
        "unique-2-nopunct": 1933,
        "entropy-2-nopunct": 10.407264206520551,
        "cond_entropy-2-nopunct": 2.5963867178680347,
        "distinct-3-nopunct": 0.41341333114161255,
        "vocab_size-3-nopunct": 5030,
        "unique-3-nopunct": 3425,
        "entropy-3-nopunct": 11.376550755803422,
        "cond_entropy-3-nopunct": 1.0138057804361749,
        "msttr-100": 0.47365,
        "msttr-100_nopunct": 0.48515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.33128578345423,
        "rouge1": {
            "precision": 0.64858,
            "recall": 0.64067,
            "fmeasure": 0.63668
        },
        "rouge2": {
            "precision": 0.3894,
            "recall": 0.383,
            "fmeasure": 0.3811
        },
        "rougeL": {
            "precision": 0.48704,
            "recall": 0.48721,
            "fmeasure": 0.48056
        },
        "rougeLsum": {
            "precision": 0.48704,
            "recall": 0.48721,
            "fmeasure": 0.48056
        },
        "local_recall": {
            "1": 0.22115384615384615,
            "2": 0.5688246385920804,
            "3": 0.7530042221500487,
            "4": 0.25,
            "5": 0.625
        },
        "bleu": 41.01845,
        "nubia": {
            "semantic_relation": 3.67168,
            "contradiction": 28.08867,
            "irrelevancy": 11.35591,
            "logical_agreement": 60.55542,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.3839,
            "nubia_score": 0.60074
        },
        "meteor": 0.328312673478831,
        "bleurt": -0.21309,
        "bertscore": {
            "precision": 0.88273,
            "recall": 0.88136,
            "f1": 0.88096
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 5,
        "total_length": 67,
        "mean_pred_length": 13.4,
        "std_pred_length": 2.65329983228432,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.5074626865671642,
        "vocab_size-1": 34,
        "unique-1": 15,
        "entropy-1": 4.85573719150552,
        "distinct-2": 0.6774193548387096,
        "vocab_size-2": 42,
        "unique-2": 23,
        "entropy-2": 5.296859415190695,
        "cond_entropy-2": 0.351478990142015,
        "distinct-3": 0.7192982456140351,
        "vocab_size-3": 41,
        "unique-3": 25,
        "entropy-3": 5.271486505392815,
        "cond_entropy-3": -0.002799497938563933,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 12.4,
        "std_pred_length-nopunct": 2.65329983228432,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.532258064516129,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.833487544977779,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 5.152979707109244,
        "cond_entropy-2-nopunct": 0.35490586961083825,
        "distinct-3-nopunct": 0.7115384615384616,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 5.123516641218013,
        "cond_entropy-3-nopunct": -0.0025486132897368048,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 2.3078939699869614,
        "rouge1": {
            "precision": 0.48965,
            "recall": 0.55535,
            "fmeasure": 0.50482
        },
        "rouge2": {
            "precision": 0.19619,
            "recall": 0.21818,
            "fmeasure": 0.19905
        },
        "rougeL": {
            "precision": 0.42942,
            "recall": 0.49977,
            "fmeasure": 0.44705
        },
        "rougeLsum": {
            "precision": 0.42942,
            "recall": 0.49977,
            "fmeasure": 0.44705
        },
        "local_recall": {
            "1": 0.4642857142857143
        },
        "bleu": 11.66431,
        "nubia": {
            "semantic_relation": 3.22347,
            "contradiction": 0.09124,
            "irrelevancy": 60.19616,
            "logical_agreement": 39.7126,
            "grammar_ref": 5.06674,
            "grammar_hyp": 4.84082,
            "nubia_score": 0.50882
        },
        "meteor": 0.2132632878610439,
        "bleurt": -0.34906,
        "bertscore": {
            "precision": 0.86635,
            "recall": 0.84941,
            "f1": 0.85764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 44,
        "total_length": 657,
        "mean_pred_length": 14.931818181818182,
        "std_pred_length": 5.6221870836273125,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5205479452054794,
        "vocab_size-1": 342,
        "unique-1": 271,
        "entropy-1": 7.482466734908297,
        "distinct-2": 0.8548123980424144,
        "vocab_size-2": 524,
        "unique-2": 471,
        "entropy-2": 8.902472485667895,
        "cond_entropy-2": 1.1628857721269965,
        "distinct-3": 0.9226713532513181,
        "vocab_size-3": 525,
        "unique-3": 495,
        "entropy-3": 8.978192311505358,
        "cond_entropy-3": 0.08928733767041301,
        "total_length-nopunct": 580,
        "mean_pred_length-nopunct": 13.181818181818182,
        "std_pred_length-nopunct": 5.262529323056838,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5793103448275863,
        "vocab_size-1-nopunct": 336,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.674533400208521,
        "distinct-2-nopunct": 0.8544776119402985,
        "vocab_size-2-nopunct": 458,
        "unique-2-nopunct": 415,
        "entropy-2-nopunct": 8.699947213917001,
        "cond_entropy-2-nopunct": 1.1003991424997142,
        "distinct-3-nopunct": 0.9207317073170732,
        "vocab_size-3-nopunct": 453,
        "unique-3-nopunct": 428,
        "entropy-3-nopunct": 8.761500989026217,
        "cond_entropy-3-nopunct": 0.08379020187022353,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.748637891650182,
        "rouge1": {
            "precision": 0.76894,
            "recall": 0.69819,
            "fmeasure": 0.71918
        },
        "rouge2": {
            "precision": 0.56404,
            "recall": 0.51983,
            "fmeasure": 0.53019
        },
        "rougeL": {
            "precision": 0.68918,
            "recall": 0.64426,
            "fmeasure": 0.65249
        },
        "rougeLsum": {
            "precision": 0.68918,
            "recall": 0.64426,
            "fmeasure": 0.65249
        },
        "local_recall": {
            "1": 0.22142857142857142,
            "2": 0.5833333333333334,
            "3": 0.7198067632850241
        },
        "bleu": 47.04684,
        "nubia": {
            "semantic_relation": 4.19838,
            "contradiction": 4.0308,
            "irrelevancy": 36.32662,
            "logical_agreement": 59.64258,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.71499,
            "nubia_score": 0.70467
        },
        "meteor": 0.39058255516203827,
        "bleurt": 0.24978,
        "bertscore": {
            "precision": 0.92932,
            "recall": 0.91926,
            "f1": 0.9221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.905692346441835,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.3276238121865623,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.05699291222712946,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.831687083026442,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.36346149978042,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.06316699496684555,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7409569303784065,
        "rouge1": {
            "precision": 0.58875,
            "recall": 0.51906,
            "fmeasure": 0.53758
        },
        "rouge2": {
            "precision": 0.40972,
            "recall": 0.38743,
            "fmeasure": 0.38628
        },
        "rougeL": {
            "precision": 0.51873,
            "recall": 0.46615,
            "fmeasure": 0.47731
        },
        "rougeLsum": {
            "precision": 0.51873,
            "recall": 0.46615,
            "fmeasure": 0.47731
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.625
        },
        "bleu": 25.4602,
        "nubia": {
            "semantic_relation": 3.85017,
            "contradiction": 29.94057,
            "irrelevancy": 46.56862,
            "logical_agreement": 23.49081,
            "grammar_ref": 4.07664,
            "grammar_hyp": 4.20402,
            "nubia_score": 0.63498
        },
        "meteor": 0.2558831952455011,
        "bleurt": 0.01965,
        "bertscore": {
            "precision": 0.8783,
            "recall": 0.87855,
            "f1": 0.8628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 15,
        "total_length": 274,
        "mean_pred_length": 18.266666666666666,
        "std_pred_length": 5.813394495091104,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6094890510948905,
        "vocab_size-1": 167,
        "unique-1": 135,
        "entropy-1": 6.790239644528999,
        "distinct-2": 0.9536679536679536,
        "vocab_size-2": 247,
        "unique-2": 237,
        "entropy-2": 7.918314947901475,
        "cond_entropy-2": 0.9775483830726535,
        "distinct-3": 0.9918032786885246,
        "vocab_size-3": 242,
        "unique-3": 240,
        "entropy-3": 7.9143438949398925,
        "cond_entropy-3": 0.0020838654678360206,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 16.466666666666665,
        "std_pred_length-nopunct": 5.702241274758159,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.659919028340081,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.869369303458262,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.748025068384765,
        "cond_entropy-2-nopunct": 0.9243454477764349,
        "distinct-3-nopunct": 0.9907834101382489,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.743118052720991,
        "cond_entropy-3-nopunct": -0.006522965428129986,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.1404198732083834,
        "rouge1": {
            "precision": 0.78429,
            "recall": 0.75837,
            "fmeasure": 0.76247
        },
        "rouge2": {
            "precision": 0.57815,
            "recall": 0.55833,
            "fmeasure": 0.55974
        },
        "rougeL": {
            "precision": 0.70874,
            "recall": 0.6842,
            "fmeasure": 0.68696
        },
        "rougeLsum": {
            "precision": 0.70874,
            "recall": 0.6842,
            "fmeasure": 0.68696
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.38461538461538464,
            "3": 0.8177083333333334
        },
        "bleu": 49.90633,
        "nubia": {
            "semantic_relation": 4.30635,
            "contradiction": 10.85013,
            "irrelevancy": 28.75815,
            "logical_agreement": 60.39172,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.44139,
            "nubia_score": 0.73481
        },
        "meteor": 0.4043569637215744,
        "bleurt": 0.36817,
        "bertscore": {
            "precision": 0.93427,
            "recall": 0.9341,
            "f1": 0.9321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 25,
        "total_length": 409,
        "mean_pred_length": 16.36,
        "std_pred_length": 6.9217338868234455,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.60880195599022,
        "vocab_size-1": 249,
        "unique-1": 215,
        "entropy-1": 7.167042635635628,
        "distinct-2": 0.9140625,
        "vocab_size-2": 351,
        "unique-2": 331,
        "entropy-2": 8.376267278097739,
        "cond_entropy-2": 1.0051268695148963,
        "distinct-3": 0.9805013927576601,
        "vocab_size-3": 352,
        "unique-3": 346,
        "entropy-3": 8.446740068635982,
        "cond_entropy-3": 0.08500588403575064,
        "total_length-nopunct": 355,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 6.079473661428265,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6873239436619718,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 215,
        "entropy-1-nopunct": 7.36128873371135,
        "distinct-2-nopunct": 0.9242424242424242,
        "vocab_size-2-nopunct": 305,
        "unique-2-nopunct": 292,
        "entropy-2-nopunct": 8.174249250654182,
        "cond_entropy-2-nopunct": 0.8910200988125803,
        "distinct-3-nopunct": 0.9901639344262295,
        "vocab_size-3-nopunct": 302,
        "unique-3-nopunct": 300,
        "entropy-3-nopunct": 8.230518260311962,
        "cond_entropy-3-nopunct": 0.07201269519817279,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.1583099481810955,
        "rouge1": {
            "precision": 0.85716,
            "recall": 0.80647,
            "fmeasure": 0.82502
        },
        "rouge2": {
            "precision": 0.65434,
            "recall": 0.63572,
            "fmeasure": 0.64153
        },
        "rougeL": {
            "precision": 0.7216,
            "recall": 0.68369,
            "fmeasure": 0.69692
        },
        "rougeLsum": {
            "precision": 0.7216,
            "recall": 0.68369,
            "fmeasure": 0.69692
        },
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.32558139534883723,
            "3": 0.8766233766233766
        },
        "bleu": 59.32975,
        "nubia": {
            "semantic_relation": 4.44349,
            "contradiction": 4.57423,
            "irrelevancy": 19.46158,
            "logical_agreement": 75.96418,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.10327,
            "nubia_score": 0.77438
        },
        "meteor": 0.46199802989078925,
        "bleurt": 0.47265,
        "bertscore": {
            "precision": 0.95397,
            "recall": 0.94799,
            "f1": 0.95056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 75,
        "unique-1": 63,
        "entropy-1": 6.009315428309374,
        "distinct-2": 0.989247311827957,
        "vocab_size-2": 92,
        "unique-2": 91,
        "entropy-2": 6.517653434763951,
        "cond_entropy-2": 0.381568889748069,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.07322680951217658,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.448026810929534,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8255813953488372,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.994643644483916,
        "distinct-2-nopunct": 0.9875,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.296928094887356,
        "cond_entropy-2-nopunct": 0.3221560336698112,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.09896121574489923,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.385266758182324,
        "rouge1": {
            "precision": 0.79779,
            "recall": 0.82059,
            "fmeasure": 0.80278
        },
        "rouge2": {
            "precision": 0.62044,
            "recall": 0.60483,
            "fmeasure": 0.60927
        },
        "rougeL": {
            "precision": 0.68839,
            "recall": 0.70719,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.68839,
            "recall": 0.70719,
            "fmeasure": 0.69231
        },
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.4,
            "3": 0.8333333333333334
        },
        "bleu": 57.56829,
        "nubia": {
            "semantic_relation": 4.41671,
            "contradiction": 0.30536,
            "irrelevancy": 18.60792,
            "logical_agreement": 81.08672,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.51245,
            "nubia_score": 0.81456
        },
        "meteor": 0.44608142413009755,
        "bleurt": 0.4057,
        "bertscore": {
            "precision": 0.95058,
            "recall": 0.94915,
            "f1": 0.94748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 195,
        "mean_pred_length": 17.727272727272727,
        "std_pred_length": 7.224842358656556,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.6974358974358974,
        "vocab_size-1": 136,
        "unique-1": 117,
        "entropy-1": 6.633442774761436,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 180,
        "unique-2": 177,
        "entropy-2": 7.475981045719181,
        "cond_entropy-2": 0.6939459618483013,
        "distinct-3": 1.0,
        "vocab_size-3": 173,
        "unique-3": 173,
        "entropy-3": 7.4346282276367255,
        "cond_entropy-3": -0.03832744228061486,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 15.818181818181818,
        "std_pred_length-nopunct": 6.779892487994211,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.7081485401148715,
        "distinct-2-nopunct": 0.9754601226993865,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.295017187960161,
        "cond_entropy-2-nopunct": 0.6144624025222509,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 152,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.247927513443566,
        "cond_entropy-3-nopunct": -0.04320269669431101,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.160875884719443,
        "rouge1": {
            "precision": 0.75642,
            "recall": 0.77359,
            "fmeasure": 0.7378
        },
        "rouge2": {
            "precision": 0.51733,
            "recall": 0.54162,
            "fmeasure": 0.50941
        },
        "rougeL": {
            "precision": 0.64086,
            "recall": 0.64806,
            "fmeasure": 0.61967
        },
        "rougeLsum": {
            "precision": 0.64086,
            "recall": 0.64806,
            "fmeasure": 0.61967
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.42105263157894735,
            "3": 0.7642857142857142
        },
        "bleu": 40.62211,
        "nubia": {
            "semantic_relation": 4.05783,
            "contradiction": 24.65802,
            "irrelevancy": 32.2769,
            "logical_agreement": 43.06507,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.55986,
            "nubia_score": 0.63526
        },
        "meteor": 0.4063578063441316,
        "bleurt": 0.12115,
        "bertscore": {
            "precision": 0.90401,
            "recall": 0.91596,
            "f1": 0.90846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 177,
        "mean_pred_length": 17.7,
        "std_pred_length": 5.060632371551998,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.632768361581921,
        "vocab_size-1": 112,
        "unique-1": 92,
        "entropy-1": 6.299893555759921,
        "distinct-2": 0.9640718562874252,
        "vocab_size-2": 161,
        "unique-2": 156,
        "entropy-2": 7.30732772060479,
        "cond_entropy-2": 0.8784391887632002,
        "distinct-3": 0.9872611464968153,
        "vocab_size-3": 155,
        "unique-3": 153,
        "entropy-3": 7.269143041885254,
        "cond_entropy-3": -0.03331992891896373,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 15.7,
        "std_pred_length-nopunct": 3.7429934544425802,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7006369426751592,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.401331187761445,
        "distinct-2-nopunct": 0.9591836734693877,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 136,
        "entropy-2-nopunct": 7.112904402644767,
        "cond_entropy-2-nopunct": 0.7655384911506878,
        "distinct-3-nopunct": 0.9854014598540146,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.068835002668541,
        "cond_entropy-3-nopunct": -0.03773597353887808,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.330489275051434,
        "rouge1": {
            "precision": 0.7089,
            "recall": 0.72231,
            "fmeasure": 0.70204
        },
        "rouge2": {
            "precision": 0.48939,
            "recall": 0.48345,
            "fmeasure": 0.4782
        },
        "rougeL": {
            "precision": 0.60792,
            "recall": 0.60198,
            "fmeasure": 0.59558
        },
        "rougeLsum": {
            "precision": 0.60792,
            "recall": 0.60198,
            "fmeasure": 0.59558
        },
        "local_recall": {
            "1": 0.45161290322580644,
            "2": 0.3,
            "3": 0.7117117117117117
        },
        "bleu": 40.79778,
        "nubia": {
            "semantic_relation": 3.86872,
            "contradiction": 8.4999,
            "irrelevancy": 59.39879,
            "logical_agreement": 32.10132,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.60935,
            "nubia_score": 0.60826
        },
        "meteor": 0.35294114504276713,
        "bleurt": 0.08047,
        "bertscore": {
            "precision": 0.91652,
            "recall": 0.91113,
            "f1": 0.91225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 189,
        "mean_pred_length": 18.9,
        "std_pred_length": 5.957348403442592,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6825396825396826,
        "vocab_size-1": 129,
        "unique-1": 109,
        "entropy-1": 6.595880207546816,
        "distinct-2": 0.9608938547486033,
        "vocab_size-2": 172,
        "unique-2": 167,
        "entropy-2": 7.397168989530578,
        "cond_entropy-2": 0.6696929228657235,
        "distinct-3": 0.9940828402366864,
        "vocab_size-3": 168,
        "unique-3": 167,
        "entropy-3": 7.3890451167555495,
        "cond_entropy-3": -0.0029968439150486236,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 5.043808085167397,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7469879518072289,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.643574503620639,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.198801097039657,
        "cond_entropy-2-nopunct": 0.6021153708373428,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": -0.0030449544731426053,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.192027821864957,
        "rouge1": {
            "precision": 0.70373,
            "recall": 0.72189,
            "fmeasure": 0.70358
        },
        "rouge2": {
            "precision": 0.47762,
            "recall": 0.47187,
            "fmeasure": 0.47074
        },
        "rougeL": {
            "precision": 0.57786,
            "recall": 0.58374,
            "fmeasure": 0.57425
        },
        "rougeLsum": {
            "precision": 0.57786,
            "recall": 0.58374,
            "fmeasure": 0.57425
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5789473684210527,
            "3": 0.8118811881188119
        },
        "bleu": 44.7352,
        "nubia": {
            "semantic_relation": 4.36718,
            "contradiction": 6.59046,
            "irrelevancy": 32.14672,
            "logical_agreement": 61.26282,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.45607,
            "nubia_score": 0.80996
        },
        "meteor": 0.40978250793829596,
        "bleurt": 0.30079,
        "bertscore": {
            "precision": 0.91336,
            "recall": 0.91502,
            "f1": 0.91349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 9.499473669630333,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 36,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 66,
        "unique-1": 58,
        "entropy-1": 5.78554752573481,
        "distinct-2": 1.0,
        "vocab_size-2": 82,
        "unique-2": 82,
        "entropy-2": 6.357552004618087,
        "cond_entropy-2": 0.47050861761659857,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.09076546392318265,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 8.593020423576334,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8311688311688312,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.825563573798318,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.1699250014423175,
        "cond_entropy-2-nopunct": 0.3750019114562597,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.10383581098453984,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.129955547028494,
        "rouge1": {
            "precision": 0.75314,
            "recall": 0.66338,
            "fmeasure": 0.69811
        },
        "rouge2": {
            "precision": 0.46034,
            "recall": 0.41751,
            "fmeasure": 0.43196
        },
        "rougeL": {
            "precision": 0.55319,
            "recall": 0.53174,
            "fmeasure": 0.52873
        },
        "rougeLsum": {
            "precision": 0.55319,
            "recall": 0.53174,
            "fmeasure": 0.52873
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.3125,
            "3": 0.725
        },
        "bleu": 36.67112,
        "nubia": {
            "semantic_relation": 3.65345,
            "contradiction": 30.18555,
            "irrelevancy": 26.78285,
            "logical_agreement": 43.0316,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.73107,
            "nubia_score": 0.53437
        },
        "meteor": 0.34512926635565566,
        "bleurt": -0.08097,
        "bertscore": {
            "precision": 0.93013,
            "recall": 0.91285,
            "f1": 0.91658
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 240,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.183318209303941,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 38,
        "distinct-1": 0.5791666666666667,
        "vocab_size-1": 139,
        "unique-1": 110,
        "entropy-1": 6.482953851471654,
        "distinct-2": 0.9342105263157895,
        "vocab_size-2": 213,
        "unique-2": 203,
        "entropy-2": 7.678857490135108,
        "cond_entropy-2": 1.0821654409484818,
        "distinct-3": 0.9907407407407407,
        "vocab_size-3": 214,
        "unique-3": 212,
        "entropy-3": 7.736368983644945,
        "cond_entropy-3": 0.0660688559559663,
        "total_length-nopunct": 205,
        "mean_pred_length-nopunct": 17.083333333333332,
        "std_pred_length-nopunct": 7.454957336490189,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6585365853658537,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.607633146926821,
        "distinct-2-nopunct": 0.9481865284974094,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.4662159596690945,
        "cond_entropy-2-nopunct": 0.9066512113444689,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 181,
        "entropy-3-nopunct": 7.499845887083174,
        "cond_entropy-3-nopunct": 0.0364746397410935,
        "msttr-100": 0.625,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.203247991480113,
        "rouge1": {
            "precision": 0.7746,
            "recall": 0.68312,
            "fmeasure": 0.71923
        },
        "rouge2": {
            "precision": 0.53338,
            "recall": 0.45196,
            "fmeasure": 0.48174
        },
        "rougeL": {
            "precision": 0.69499,
            "recall": 0.60645,
            "fmeasure": 0.64058
        },
        "rougeLsum": {
            "precision": 0.69499,
            "recall": 0.60645,
            "fmeasure": 0.64058
        },
        "local_recall": {
            "1": 0.06,
            "2": 0.19230769230769232,
            "3": 0.7176470588235294
        },
        "bleu": 32.92462,
        "nubia": {
            "semantic_relation": 4.08574,
            "contradiction": 7.20079,
            "irrelevancy": 36.32182,
            "logical_agreement": 56.47739,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.33373,
            "nubia_score": 0.70845
        },
        "meteor": 0.3352452303531048,
        "bleurt": 0.2135,
        "bertscore": {
            "precision": 0.92544,
            "recall": 0.90033,
            "f1": 0.91081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 75,
        "total_length": 1222,
        "mean_pred_length": 16.293333333333333,
        "std_pred_length": 5.114093815677959,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.47381342062193127,
        "vocab_size-1": 579,
        "unique-1": 446,
        "entropy-1": 7.890847942390622,
        "distinct-2": 0.8352223190932868,
        "vocab_size-2": 958,
        "unique-2": 860,
        "entropy-2": 9.713788541586261,
        "cond_entropy-2": 1.568990279709148,
        "distinct-3": 0.9244402985074627,
        "vocab_size-3": 991,
        "unique-3": 941,
        "entropy-3": 9.886174991352675,
        "cond_entropy-3": 0.1737623103780317,
        "total_length-nopunct": 1058,
        "mean_pred_length-nopunct": 14.106666666666667,
        "std_pred_length-nopunct": 4.126575120147726,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5396975425330813,
        "vocab_size-1-nopunct": 571,
        "unique-1-nopunct": 445,
        "entropy-1-nopunct": 8.154501020874008,
        "distinct-2-nopunct": 0.8474059003051883,
        "vocab_size-2-nopunct": 833,
        "unique-2-nopunct": 762,
        "entropy-2-nopunct": 9.506692396593117,
        "cond_entropy-2-nopunct": 1.4461305459464289,
        "distinct-3-nopunct": 0.9306167400881057,
        "vocab_size-3-nopunct": 845,
        "unique-3-nopunct": 810,
        "entropy-3-nopunct": 9.656820366213339,
        "cond_entropy-3-nopunct": 0.16975545115002916,
        "msttr-100": 0.69917,
        "msttr-100_nopunct": 0.763,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.341083983776121,
        "rouge1": {
            "precision": 0.78304,
            "recall": 0.74699,
            "fmeasure": 0.75158
        },
        "rouge2": {
            "precision": 0.56865,
            "recall": 0.55212,
            "fmeasure": 0.55091
        },
        "rougeL": {
            "precision": 0.66976,
            "recall": 0.6487,
            "fmeasure": 0.6484
        },
        "rougeLsum": {
            "precision": 0.66976,
            "recall": 0.6487,
            "fmeasure": 0.6484
        },
        "local_recall": {
            "1": 0.22264150943396227,
            "2": 0.4398148148148148,
            "3": 0.7643312101910829
        },
        "bleu": 45.88981,
        "nubia": {
            "semantic_relation": 4.13516,
            "contradiction": 9.01914,
            "irrelevancy": 35.09205,
            "logical_agreement": 55.8888,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.96228,
            "nubia_score": 0.68338
        },
        "meteor": 0.38343085517761016,
        "bleurt": 0.18146,
        "bertscore": {
            "precision": 0.92326,
            "recall": 0.92104,
            "f1": 0.92024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 165,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.264014327112209,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6727272727272727,
        "vocab_size-1": 111,
        "unique-1": 90,
        "entropy-1": 6.382756728928208,
        "distinct-2": 0.9675324675324676,
        "vocab_size-2": 149,
        "unique-2": 145,
        "entropy-2": 7.19694960886269,
        "cond_entropy-2": 0.6373452989830514,
        "distinct-3": 0.993006993006993,
        "vocab_size-3": 142,
        "unique-3": 141,
        "entropy-3": 7.145885322792383,
        "cond_entropy-3": -0.0456922143908932,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 13.090909090909092,
        "std_pred_length-nopunct": 4.294913385824624,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7291666666666666,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.390518353717365,
        "distinct-2-nopunct": 0.9624060150375939,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.974418619695457,
        "cond_entropy-2-nopunct": 0.6408436729327932,
        "distinct-3-nopunct": 0.9918032786885246,
        "vocab_size-3-nopunct": 121,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.914343894939951,
        "cond_entropy-3-nopunct": -0.060980446281226015,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.367841653400157,
        "rouge1": {
            "precision": 0.70776,
            "recall": 0.67608,
            "fmeasure": 0.68138
        },
        "rouge2": {
            "precision": 0.45228,
            "recall": 0.44945,
            "fmeasure": 0.44361
        },
        "rougeL": {
            "precision": 0.60934,
            "recall": 0.60169,
            "fmeasure": 0.59729
        },
        "rougeLsum": {
            "precision": 0.60934,
            "recall": 0.60169,
            "fmeasure": 0.59729
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.23809523809523808,
            "3": 0.6456692913385826
        },
        "bleu": 33.98298,
        "nubia": {
            "semantic_relation": 3.9587,
            "contradiction": 21.84182,
            "irrelevancy": 35.60507,
            "logical_agreement": 42.55311,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.48523,
            "nubia_score": 0.64262
        },
        "meteor": 0.32917257982483306,
        "bleurt": 0.16339,
        "bertscore": {
            "precision": 0.91044,
            "recall": 0.90968,
            "f1": 0.90696
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.3541019662496847,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.8,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.148758439731457,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.2439424511119288,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.391164991562634,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.124093266315398,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.2313686638041515,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.511361182439014,
        "rouge1": {
            "precision": 0.73584,
            "recall": 0.68012,
            "fmeasure": 0.69641
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.37149,
            "fmeasure": 0.36288
        },
        "rougeL": {
            "precision": 0.59355,
            "recall": 0.59847,
            "fmeasure": 0.58743
        },
        "rougeLsum": {
            "precision": 0.59355,
            "recall": 0.59847,
            "fmeasure": 0.58743
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.2857142857142857,
            "3": 0.6486486486486487
        },
        "bleu": 33.23277,
        "nubia": {
            "semantic_relation": 3.56453,
            "contradiction": 27.03707,
            "irrelevancy": 32.45348,
            "logical_agreement": 40.50945,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.42674,
            "nubia_score": 0.5947
        },
        "meteor": 0.3173917277930784,
        "bleurt": 0.19812,
        "bertscore": {
            "precision": 0.90279,
            "recall": 0.90232,
            "f1": 0.90033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.041522986797286,
        "median_pred_length": 19.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 60,
        "unique-1": 49,
        "entropy-1": 5.770760901516085,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 70,
        "unique-2": 68,
        "entropy-2": 6.114369445886762,
        "cond_entropy-2": 0.25900668947776045,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 5.356071321407137,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.835820895522388,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.715197026214083,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.2526157331108259,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.882643049361836,
        "cond_entropy-3-nopunct": -0.060738569053329465,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.223592231130229,
        "rouge1": {
            "precision": 0.7819,
            "recall": 0.81598,
            "fmeasure": 0.7957
        },
        "rouge2": {
            "precision": 0.59246,
            "recall": 0.60908,
            "fmeasure": 0.59837
        },
        "rougeL": {
            "precision": 0.70636,
            "recall": 0.72962,
            "fmeasure": 0.7158
        },
        "rougeLsum": {
            "precision": 0.70636,
            "recall": 0.72962,
            "fmeasure": 0.7158
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bleu": 46.4078,
        "nubia": {
            "semantic_relation": 3.97916,
            "contradiction": 12.18551,
            "irrelevancy": 29.9727,
            "logical_agreement": 57.84179,
            "grammar_ref": 5.56433,
            "grammar_hyp": 5.16104,
            "nubia_score": 0.70976
        },
        "meteor": 0.40363972960451044,
        "bleurt": 0.27656,
        "bertscore": {
            "precision": 0.94177,
            "recall": 0.90815,
            "f1": 0.92232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 194,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 3.7379435820009674,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.5876288659793815,
        "vocab_size-1": 114,
        "unique-1": 92,
        "entropy-1": 6.2220970860329246,
        "distinct-2": 0.9010989010989011,
        "vocab_size-2": 164,
        "unique-2": 153,
        "entropy-2": 7.27356831886305,
        "cond_entropy-2": 0.9059450738476598,
        "distinct-3": 0.9588235294117647,
        "vocab_size-3": 163,
        "unique-3": 157,
        "entropy-3": 7.322597480242597,
        "cond_entropy-3": 0.0655627840621068,
        "total_length-nopunct": 168,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.1622776601683795,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6547619047619048,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.278880364824104,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 140,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.042618225394781,
        "cond_entropy-2-nopunct": 0.8365663522082196,
        "distinct-3-nopunct": 0.9652777777777778,
        "vocab_size-3-nopunct": 139,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.100480556997885,
        "cond_entropy-3-nopunct": 0.07114988661428093,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.667507125342832,
        "rouge1": {
            "precision": 0.78505,
            "recall": 0.76274,
            "fmeasure": 0.76798
        },
        "rouge2": {
            "precision": 0.54902,
            "recall": 0.52413,
            "fmeasure": 0.53196
        },
        "rougeL": {
            "precision": 0.73455,
            "recall": 0.70208,
            "fmeasure": 0.71155
        },
        "rougeLsum": {
            "precision": 0.73455,
            "recall": 0.70208,
            "fmeasure": 0.71155
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.3448275862068966,
            "3": 0.7768595041322314
        },
        "bleu": 45.90486,
        "nubia": {
            "semantic_relation": 4.50266,
            "contradiction": 7.25501,
            "irrelevancy": 20.18632,
            "logical_agreement": 72.55867,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.402,
            "nubia_score": 0.81275
        },
        "meteor": 0.3847360422988668,
        "bleurt": 0.31608,
        "bertscore": {
            "precision": 0.93324,
            "recall": 0.93232,
            "f1": 0.93069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 7.408703590297623,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.7551020408163265,
        "vocab_size-1": 37,
        "unique-1": 29,
        "entropy-1": 5.063290456183497,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.3928665142568132,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 7.408703590297623,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.019060684834029,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.3334077152934376,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1499466549057624,
        "rouge1": {
            "precision": 0.58454,
            "recall": 0.66918,
            "fmeasure": 0.61859
        },
        "rouge2": {
            "precision": 0.38131,
            "recall": 0.40222,
            "fmeasure": 0.38992
        },
        "rougeL": {
            "precision": 0.49461,
            "recall": 0.6038,
            "fmeasure": 0.53695
        },
        "rougeLsum": {
            "precision": 0.49461,
            "recall": 0.6038,
            "fmeasure": 0.53695
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4444444444444444,
            "3": 0.7727272727272727
        },
        "bleu": 34.2098,
        "nubia": {
            "semantic_relation": 3.94354,
            "contradiction": 0.16471,
            "irrelevancy": 65.7591,
            "logical_agreement": 34.07618,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.43886,
            "nubia_score": 0.6931
        },
        "meteor": 0.3230648981878935,
        "bleurt": 0.0466,
        "bertscore": {
            "precision": 0.85477,
            "recall": 0.89274,
            "f1": 0.8732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 21,
        "total_length": 320,
        "mean_pred_length": 15.238095238095237,
        "std_pred_length": 3.0222155528804633,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.63125,
        "vocab_size-1": 202,
        "unique-1": 170,
        "entropy-1": 6.981081105349684,
        "distinct-2": 0.9431438127090301,
        "vocab_size-2": 282,
        "unique-2": 273,
        "entropy-2": 8.080123580523633,
        "cond_entropy-2": 0.884725153775767,
        "distinct-3": 0.9892086330935251,
        "vocab_size-3": 275,
        "unique-3": 273,
        "entropy-3": 8.09464291624086,
        "cond_entropy-3": 0.025387824807741877,
        "total_length-nopunct": 280,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 2.9814239699997196,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7035714285714286,
        "vocab_size-1-nopunct": 197,
        "unique-1-nopunct": 167,
        "entropy-1-nopunct": 7.154881692753206,
        "distinct-2-nopunct": 0.9459459459459459,
        "vocab_size-2-nopunct": 245,
        "unique-2-nopunct": 238,
        "entropy-2-nopunct": 7.8767902857309595,
        "cond_entropy-2-nopunct": 0.7842271246887605,
        "distinct-3-nopunct": 0.9957983193277311,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 236,
        "entropy-3-nopunct": 7.886414401963453,
        "cond_entropy-3-nopunct": 0.021978645816727597,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.645321442236462,
        "rouge1": {
            "precision": 0.68771,
            "recall": 0.62694,
            "fmeasure": 0.64619
        },
        "rouge2": {
            "precision": 0.42974,
            "recall": 0.40469,
            "fmeasure": 0.40963
        },
        "rougeL": {
            "precision": 0.55344,
            "recall": 0.51982,
            "fmeasure": 0.52736
        },
        "rougeLsum": {
            "precision": 0.55344,
            "recall": 0.51982,
            "fmeasure": 0.52736
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.425531914893617,
            "3": 0.6701030927835051
        },
        "bleu": 35.06851,
        "nubia": {
            "semantic_relation": 3.84174,
            "contradiction": 13.47396,
            "irrelevancy": 35.43385,
            "logical_agreement": 51.09218,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.80902,
            "nubia_score": 0.62209
        },
        "meteor": 0.3399021030450663,
        "bleurt": 0.11774,
        "bertscore": {
            "precision": 0.9146,
            "recall": 0.90341,
            "f1": 0.90709
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 16,
        "total_length": 223,
        "mean_pred_length": 13.9375,
        "std_pred_length": 3.4725485957722753,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6143497757847534,
        "vocab_size-1": 137,
        "unique-1": 109,
        "entropy-1": 6.508073434458172,
        "distinct-2": 0.9227053140096618,
        "vocab_size-2": 191,
        "unique-2": 178,
        "entropy-2": 7.525588950242475,
        "cond_entropy-2": 0.8082653875108681,
        "distinct-3": 0.9581151832460733,
        "vocab_size-3": 183,
        "unique-3": 175,
        "entropy-3": 7.493659194527895,
        "cond_entropy-3": -0.017865001179998286,
        "total_length-nopunct": 194,
        "mean_pred_length-nopunct": 12.125,
        "std_pred_length-nopunct": 3.07967124868873,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6855670103092784,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.611402652573323,
        "distinct-2-nopunct": 0.9157303370786517,
        "vocab_size-2-nopunct": 163,
        "unique-2-nopunct": 151,
        "entropy-2-nopunct": 7.291717209044107,
        "cond_entropy-2-nopunct": 0.7523154723911383,
        "distinct-3-nopunct": 0.9567901234567902,
        "vocab_size-3-nopunct": 155,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.2534302497981855,
        "cond_entropy-3-nopunct": -0.026285357080763936,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.678596777144529,
        "rouge1": {
            "precision": 0.75841,
            "recall": 0.73432,
            "fmeasure": 0.74334
        },
        "rouge2": {
            "precision": 0.50466,
            "recall": 0.49395,
            "fmeasure": 0.49721
        },
        "rougeL": {
            "precision": 0.65399,
            "recall": 0.63533,
            "fmeasure": 0.64218
        },
        "rougeLsum": {
            "precision": 0.65399,
            "recall": 0.63533,
            "fmeasure": 0.64218
        },
        "local_recall": {
            "1": 0.24390243902439024,
            "2": 0.34782608695652173,
            "3": 0.7195121951219512
        },
        "bleu": 41.1587,
        "nubia": {
            "semantic_relation": 4.46827,
            "contradiction": 5.55913,
            "irrelevancy": 32.02635,
            "logical_agreement": 62.41452,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.44529,
            "nubia_score": 0.80872
        },
        "meteor": 0.37986602378966156,
        "bleurt": 0.32885,
        "bertscore": {
            "precision": 0.92406,
            "recall": 0.92386,
            "f1": 0.92298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 9,
        "total_length": 173,
        "mean_pred_length": 19.22222222222222,
        "std_pred_length": 7.45024649521787,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.6358381502890174,
        "vocab_size-1": 110,
        "unique-1": 93,
        "entropy-1": 6.18722375106154,
        "distinct-2": 0.9329268292682927,
        "vocab_size-2": 153,
        "unique-2": 145,
        "entropy-2": 7.2066075686293,
        "cond_entropy-2": 0.9138796424225974,
        "distinct-3": 0.9806451612903225,
        "vocab_size-3": 152,
        "unique-3": 149,
        "entropy-3": 7.237414727854901,
        "cond_entropy-3": 0.03957167486365998,
        "total_length-nopunct": 153,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.497862896539309,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6993464052287581,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.250509617296216,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.025793838232861,
        "cond_entropy-2-nopunct": 0.8312696655794458,
        "distinct-3-nopunct": 0.9851851851851852,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.047185967421224,
        "cond_entropy-3-nopunct": 0.0310008734023217,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.52040088629471,
        "rouge1": {
            "precision": 0.76427,
            "recall": 0.75097,
            "fmeasure": 0.75358
        },
        "rouge2": {
            "precision": 0.48931,
            "recall": 0.50002,
            "fmeasure": 0.49093
        },
        "rougeL": {
            "precision": 0.62413,
            "recall": 0.62928,
            "fmeasure": 0.6225
        },
        "rougeLsum": {
            "precision": 0.62413,
            "recall": 0.62928,
            "fmeasure": 0.6225
        },
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.4375,
            "3": 0.7478260869565218
        },
        "bleu": 33.2352,
        "nubia": {
            "semantic_relation": 4.35018,
            "contradiction": 0.77569,
            "irrelevancy": 28.685,
            "logical_agreement": 70.53931,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.36481,
            "nubia_score": 0.80587
        },
        "meteor": 0.37658168338923786,
        "bleurt": 0.30151,
        "bertscore": {
            "precision": 0.92802,
            "recall": 0.92411,
            "f1": 0.92568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 23,
        "total_length": 364,
        "mean_pred_length": 15.826086956521738,
        "std_pred_length": 4.851285566178565,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.554945054945055,
        "vocab_size-1": 202,
        "unique-1": 158,
        "entropy-1": 6.9230538296324955,
        "distinct-2": 0.8797653958944281,
        "vocab_size-2": 300,
        "unique-2": 272,
        "entropy-2": 8.12169574421001,
        "cond_entropy-2": 0.9962809208133923,
        "distinct-3": 0.9559748427672956,
        "vocab_size-3": 304,
        "unique-3": 291,
        "entropy-3": 8.222458780749268,
        "cond_entropy-3": 0.10692515210077302,
        "total_length-nopunct": 323,
        "mean_pred_length-nopunct": 14.043478260869565,
        "std_pred_length-nopunct": 4.37858683644735,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6130030959752322,
        "vocab_size-1-nopunct": 198,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 7.061385444105752,
        "distinct-2-nopunct": 0.8833333333333333,
        "vocab_size-2-nopunct": 265,
        "unique-2-nopunct": 241,
        "entropy-2-nopunct": 7.942021690438243,
        "cond_entropy-2-nopunct": 0.9244859397277443,
        "distinct-3-nopunct": 0.9638989169675091,
        "vocab_size-3-nopunct": 267,
        "unique-3-nopunct": 257,
        "entropy-3-nopunct": 8.041539999984254,
        "cond_entropy-3-nopunct": 0.10044423372812014,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.306161149627619,
        "rouge1": {
            "precision": 0.78073,
            "recall": 0.75946,
            "fmeasure": 0.76247
        },
        "rouge2": {
            "precision": 0.55076,
            "recall": 0.53727,
            "fmeasure": 0.53789
        },
        "rougeL": {
            "precision": 0.67031,
            "recall": 0.66237,
            "fmeasure": 0.66043
        },
        "rougeLsum": {
            "precision": 0.67031,
            "recall": 0.66237,
            "fmeasure": 0.66043
        },
        "local_recall": {
            "1": 0.28,
            "2": 0.5409836065573771,
            "3": 0.7584745762711864
        },
        "bleu": 44.0672,
        "nubia": {
            "semantic_relation": 4.36263,
            "contradiction": 8.24767,
            "irrelevancy": 24.47218,
            "logical_agreement": 67.28016,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.17461,
            "nubia_score": 0.79523
        },
        "meteor": 0.3979078561566624,
        "bleurt": 0.2833,
        "bertscore": {
            "precision": 0.9248,
            "recall": 0.92413,
            "f1": 0.92321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 140,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.219004621945797,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6071428571428571,
        "vocab_size-1": 85,
        "unique-1": 70,
        "entropy-1": 5.780968690794263,
        "distinct-2": 0.9076923076923077,
        "vocab_size-2": 118,
        "unique-2": 110,
        "entropy-2": 6.795369543764402,
        "cond_entropy-2": 0.8625844092211706,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 116,
        "unique-3": 112,
        "entropy-3": 6.840223928941868,
        "cond_entropy-3": 0.06377090761612193,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 12.1,
        "std_pred_length-nopunct": 3.7269290307168452,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6694214876033058,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.795778607044661,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.582616091536364,
        "cond_entropy-2-nopunct": 0.8880162800079046,
        "distinct-3-nopunct": 0.9900990099009901,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.638409502553759,
        "cond_entropy-3-nopunct": 0.07676368575146027,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.614893025727551,
        "rouge1": {
            "precision": 0.80492,
            "recall": 0.72054,
            "fmeasure": 0.75418
        },
        "rouge2": {
            "precision": 0.50333,
            "recall": 0.46249,
            "fmeasure": 0.4751
        },
        "rougeL": {
            "precision": 0.69669,
            "recall": 0.64186,
            "fmeasure": 0.65957
        },
        "rougeLsum": {
            "precision": 0.69669,
            "recall": 0.64186,
            "fmeasure": 0.65957
        },
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.23529411764705882,
            "3": 0.7735849056603774
        },
        "bleu": 42.34339,
        "nubia": {
            "semantic_relation": 4.55555,
            "contradiction": 10.64659,
            "irrelevancy": 14.8886,
            "logical_agreement": 74.46481,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.52404,
            "nubia_score": 0.79013
        },
        "meteor": 0.3950428994816346,
        "bleurt": 0.33103,
        "bertscore": {
            "precision": 0.93499,
            "recall": 0.92552,
            "f1": 0.93001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 190,
        "mean_pred_length": 13.571428571428571,
        "std_pred_length": 3.6977654587270816,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.5894736842105263,
        "vocab_size-1": 112,
        "unique-1": 91,
        "entropy-1": 6.178789617624524,
        "distinct-2": 0.9261363636363636,
        "vocab_size-2": 163,
        "unique-2": 155,
        "entropy-2": 7.284687939647744,
        "cond_entropy-2": 0.9136935206657357,
        "distinct-3": 1.0,
        "vocab_size-3": 162,
        "unique-3": 162,
        "entropy-3": 7.339850002884606,
        "cond_entropy-3": 0.05791768981623764,
        "total_length-nopunct": 170,
        "mean_pred_length-nopunct": 12.142857142857142,
        "std_pred_length-nopunct": 3.2919196062294036,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6470588235294118,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.259450969543045,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.101076016925318,
        "cond_entropy-2-nopunct": 0.8962032334822649,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.149747119504689,
        "cond_entropy-3-nopunct": 0.059801854883021345,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.453495629285367,
        "rouge1": {
            "precision": 0.73789,
            "recall": 0.73949,
            "fmeasure": 0.72418
        },
        "rouge2": {
            "precision": 0.53869,
            "recall": 0.5248,
            "fmeasure": 0.52053
        },
        "rougeL": {
            "precision": 0.66949,
            "recall": 0.66216,
            "fmeasure": 0.65291
        },
        "rougeLsum": {
            "precision": 0.66949,
            "recall": 0.66216,
            "fmeasure": 0.65291
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.43333333333333335,
            "3": 0.7421875
        },
        "bleu": 42.80792,
        "nubia": {
            "semantic_relation": 4.22224,
            "contradiction": 5.90829,
            "irrelevancy": 23.34011,
            "logical_agreement": 70.7516,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.22135,
            "nubia_score": 0.74501
        },
        "meteor": 0.4075564023883162,
        "bleurt": 0.27005,
        "bertscore": {
            "precision": 0.9318,
            "recall": 0.92392,
            "f1": 0.92652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0052535157554314,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "bleu": 16.51582,
        "nubia": {
            "semantic_relation": 3.12986,
            "contradiction": 71.68311,
            "irrelevancy": 20.1839,
            "logical_agreement": 8.133,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.78582,
            "nubia_score": 0.30685
        },
        "meteor": 0.31253823342571707,
        "bleurt": -0.06824,
        "bertscore": {
            "precision": 0.87519,
            "recall": 0.87347,
            "f1": 0.87433
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 4.389226141639205,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 75,
        "unique-1": 62,
        "entropy-1": 5.872068655470802,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 96,
        "unique-2": 89,
        "entropy-2": 6.539335030620297,
        "cond_entropy-2": 0.5403908561278805,
        "distinct-3": 0.9690721649484536,
        "vocab_size-3": 94,
        "unique-3": 91,
        "entropy-3": 6.538057172084047,
        "cond_entropy-3": -0.010270303766712183,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 4.257046978786097,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7319587628865979,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.866722991890602,
        "distinct-2-nopunct": 0.9222222222222223,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.327909901861181,
        "cond_entropy-2-nopunct": 0.4959905649936608,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.326846660262594,
        "cond_entropy-3-nopunct": -0.011333092667527305,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.823146399536489,
        "rouge1": {
            "precision": 0.7074,
            "recall": 0.73829,
            "fmeasure": 0.71794
        },
        "rouge2": {
            "precision": 0.47896,
            "recall": 0.48465,
            "fmeasure": 0.47462
        },
        "rougeL": {
            "precision": 0.63558,
            "recall": 0.64395,
            "fmeasure": 0.63152
        },
        "rougeLsum": {
            "precision": 0.63558,
            "recall": 0.64395,
            "fmeasure": 0.63152
        },
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.45,
            "3": 0.8153846153846154
        },
        "bleu": 42.25956,
        "nubia": {
            "semantic_relation": 4.15347,
            "contradiction": 13.9928,
            "irrelevancy": 43.46253,
            "logical_agreement": 42.54467,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.87393,
            "nubia_score": 0.70401
        },
        "meteor": 0.37506729071529943,
        "bleurt": 0.08977,
        "bertscore": {
            "precision": 0.89581,
            "recall": 0.92099,
            "f1": 0.90728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 37,
        "total_length": 675,
        "mean_pred_length": 18.243243243243242,
        "std_pred_length": 7.4594594594594605,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.5362962962962963,
        "vocab_size-1": 362,
        "unique-1": 290,
        "entropy-1": 7.530584695422568,
        "distinct-2": 0.8746081504702194,
        "vocab_size-2": 558,
        "unique-2": 519,
        "entropy-2": 8.987135979168356,
        "cond_entropy-2": 1.260545899535288,
        "distinct-3": 0.9417637271214643,
        "vocab_size-3": 566,
        "unique-3": 542,
        "entropy-3": 9.093402675847166,
        "cond_entropy-3": 0.1265998671946873,
        "total_length-nopunct": 593,
        "mean_pred_length-nopunct": 16.027027027027028,
        "std_pred_length-nopunct": 6.288068867335235,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6003372681281619,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.751586436061982,
        "distinct-2-nopunct": 0.8669064748201439,
        "vocab_size-2-nopunct": 482,
        "unique-2-nopunct": 447,
        "entropy-2-nopunct": 8.76513443086628,
        "cond_entropy-2-nopunct": 1.0919144285188058,
        "distinct-3-nopunct": 0.9364161849710982,
        "vocab_size-3-nopunct": 486,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 8.8677045599122,
        "cond_entropy-3-nopunct": 0.12139270641353567,
        "msttr-100": 0.67833,
        "msttr-100_nopunct": 0.764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.964270995005464,
        "rouge1": {
            "precision": 0.69478,
            "recall": 0.71998,
            "fmeasure": 0.69132
        },
        "rouge2": {
            "precision": 0.49997,
            "recall": 0.50815,
            "fmeasure": 0.49084
        },
        "rougeL": {
            "precision": 0.61893,
            "recall": 0.63193,
            "fmeasure": 0.61035
        },
        "rougeLsum": {
            "precision": 0.61893,
            "recall": 0.63193,
            "fmeasure": 0.61035
        },
        "local_recall": {
            "1": 0.21323529411764705,
            "2": 0.3877551020408163,
            "3": 0.7294685990338164
        },
        "bleu": 40.30781,
        "nubia": {
            "semantic_relation": 3.94681,
            "contradiction": 16.36734,
            "irrelevancy": 33.80402,
            "logical_agreement": 49.82864,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.70163,
            "nubia_score": 0.67166
        },
        "meteor": 0.3736289153519164,
        "bleurt": 0.08174,
        "bertscore": {
            "precision": 0.90696,
            "recall": 0.91093,
            "f1": 0.9073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 20,
        "total_length": 285,
        "mean_pred_length": 14.25,
        "std_pred_length": 5.223743868146676,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.6385964912280702,
        "vocab_size-1": 182,
        "unique-1": 149,
        "entropy-1": 6.970229488247602,
        "distinct-2": 0.9471698113207547,
        "vocab_size-2": 251,
        "unique-2": 239,
        "entropy-2": 7.938490907924752,
        "cond_entropy-2": 0.7314810820105765,
        "distinct-3": 0.9714285714285714,
        "vocab_size-3": 238,
        "unique-3": 231,
        "entropy-3": 7.879495081859744,
        "cond_entropy-3": -0.04990540634869736,
        "total_length-nopunct": 242,
        "mean_pred_length-nopunct": 12.1,
        "std_pred_length-nopunct": 4.437341546466759,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7231404958677686,
        "vocab_size-1-nopunct": 175,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 7.1008883856933345,
        "distinct-2-nopunct": 0.9369369369369369,
        "vocab_size-2-nopunct": 208,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.661488951916188,
        "cond_entropy-2-nopunct": 0.6252829852842441,
        "distinct-3-nopunct": 0.9653465346534653,
        "vocab_size-3-nopunct": 195,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.588904552058696,
        "cond_entropy-3-nopunct": -0.0643738142699601,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.702035845887912,
        "rouge1": {
            "precision": 0.79683,
            "recall": 0.6512,
            "fmeasure": 0.70555
        },
        "rouge2": {
            "precision": 0.55053,
            "recall": 0.45693,
            "fmeasure": 0.49136
        },
        "rougeL": {
            "precision": 0.69757,
            "recall": 0.56999,
            "fmeasure": 0.61696
        },
        "rougeLsum": {
            "precision": 0.69757,
            "recall": 0.56999,
            "fmeasure": 0.61696
        },
        "local_recall": {
            "1": 0.1590909090909091,
            "2": 0.3939393939393939,
            "3": 0.7378640776699029
        },
        "bleu": 45.97532,
        "nubia": {
            "semantic_relation": 4.05366,
            "contradiction": 18.81097,
            "irrelevancy": 20.85303,
            "logical_agreement": 60.336,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.93686,
            "nubia_score": 0.65687
        },
        "meteor": 0.3837905873207304,
        "bleurt": 0.18612,
        "bertscore": {
            "precision": 0.92613,
            "recall": 0.90777,
            "f1": 0.91426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 23,
        "total_length": 357,
        "mean_pred_length": 15.521739130434783,
        "std_pred_length": 5.9407916703986094,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6022408963585434,
        "vocab_size-1": 215,
        "unique-1": 185,
        "entropy-1": 6.961002022884544,
        "distinct-2": 0.9341317365269461,
        "vocab_size-2": 312,
        "unique-2": 294,
        "entropy-2": 8.238900316496157,
        "cond_entropy-2": 1.0709820497704239,
        "distinct-3": 0.9903536977491961,
        "vocab_size-3": 308,
        "unique-3": 305,
        "entropy-3": 8.261478165629004,
        "cond_entropy-3": 0.017997797510044964,
        "total_length-nopunct": 301,
        "mean_pred_length-nopunct": 13.08695652173913,
        "std_pred_length-nopunct": 5.020939142000714,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6943521594684385,
        "vocab_size-1-nopunct": 209,
        "unique-1-nopunct": 183,
        "entropy-1-nopunct": 7.1615134964537654,
        "distinct-2-nopunct": 0.9460431654676259,
        "vocab_size-2-nopunct": 263,
        "unique-2-nopunct": 251,
        "entropy-2-nopunct": 7.998043085405345,
        "cond_entropy-2-nopunct": 0.9066321686120118,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 255,
        "unique-3-nopunct": 255,
        "entropy-3-nopunct": 7.994353436858871,
        "cond_entropy-3-nopunct": 0.007214875799808699,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.106454427293025,
        "rouge1": {
            "precision": 0.79846,
            "recall": 0.71509,
            "fmeasure": 0.74029
        },
        "rouge2": {
            "precision": 0.57558,
            "recall": 0.51203,
            "fmeasure": 0.53271
        },
        "rougeL": {
            "precision": 0.68241,
            "recall": 0.61749,
            "fmeasure": 0.63665
        },
        "rougeLsum": {
            "precision": 0.68241,
            "recall": 0.61749,
            "fmeasure": 0.63665
        },
        "local_recall": {
            "1": 0.1780821917808219,
            "2": 0.29069767441860467,
            "3": 0.8034188034188035
        },
        "bleu": 49.21897,
        "nubia": {
            "semantic_relation": 4.21259,
            "contradiction": 11.21312,
            "irrelevancy": 15.76681,
            "logical_agreement": 73.02008,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.67366,
            "nubia_score": 0.71555
        },
        "meteor": 0.38632671967129645,
        "bleurt": 0.32134,
        "bertscore": {
            "precision": 0.93371,
            "recall": 0.9164,
            "f1": 0.92154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 18,
        "total_length": 260,
        "mean_pred_length": 14.444444444444445,
        "std_pred_length": 4.991350543381379,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.6346153846153846,
        "vocab_size-1": 165,
        "unique-1": 138,
        "entropy-1": 6.75652638215442,
        "distinct-2": 0.9752066115702479,
        "vocab_size-2": 236,
        "unique-2": 232,
        "entropy-2": 7.861011997605174,
        "cond_entropy-2": 0.8884793994580747,
        "distinct-3": 1.0,
        "vocab_size-3": 224,
        "unique-3": 224,
        "entropy-3": 7.807354922057568,
        "cond_entropy-3": -0.049008315216990415,
        "total_length-nopunct": 226,
        "mean_pred_length-nopunct": 12.555555555555555,
        "std_pred_length-nopunct": 4.560972389283065,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7079646017699115,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.882097660661768,
        "distinct-2-nopunct": 0.9711538461538461,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 198,
        "entropy-2-nopunct": 7.633132025833377,
        "cond_entropy-2-nopunct": 0.817791400900316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 190,
        "unique-3-nopunct": 190,
        "entropy-3-nopunct": 7.569855608330959,
        "cond_entropy-3-nopunct": -0.056899899283828236,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.661089195309658,
        "rouge1": {
            "precision": 0.73817,
            "recall": 0.70912,
            "fmeasure": 0.71678
        },
        "rouge2": {
            "precision": 0.51254,
            "recall": 0.47933,
            "fmeasure": 0.49038
        },
        "rougeL": {
            "precision": 0.6555,
            "recall": 0.61935,
            "fmeasure": 0.63212
        },
        "rougeLsum": {
            "precision": 0.6555,
            "recall": 0.61935,
            "fmeasure": 0.63212
        },
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.25,
            "3": 0.7421052631578947
        },
        "bleu": 42.44241,
        "nubia": {
            "semantic_relation": 4.10484,
            "contradiction": 7.19272,
            "irrelevancy": 21.75793,
            "logical_agreement": 71.04935,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.96159,
            "nubia_score": 0.72644
        },
        "meteor": 0.38747555835560077,
        "bleurt": 0.31196,
        "bertscore": {
            "precision": 0.91379,
            "recall": 0.90824,
            "f1": 0.90997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 9,
        "total_length": 129,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 3.858612300930075,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6124031007751938,
        "vocab_size-1": 79,
        "unique-1": 55,
        "entropy-1": 5.95255729394814,
        "distinct-2": 0.85,
        "vocab_size-2": 102,
        "unique-2": 86,
        "entropy-2": 6.594309137239143,
        "cond_entropy-2": 0.4834077152934381,
        "distinct-3": 0.8918918918918919,
        "vocab_size-3": 99,
        "unique-3": 87,
        "entropy-3": 6.5781996501339055,
        "cond_entropy-3": 0.009234955465253441,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 12.88888888888889,
        "std_pred_length-nopunct": 3.9283710065919304,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6637931034482759,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.9955749604956,
        "distinct-2-nopunct": 0.8411214953271028,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.409599930285935,
        "cond_entropy-2-nopunct": 0.4678722063481615,
        "distinct-3-nopunct": 0.8877551020408163,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.390220048196851,
        "cond_entropy-3-nopunct": 0.0008936230643361758,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.785265305224738,
        "rouge1": {
            "precision": 0.82101,
            "recall": 0.7865,
            "fmeasure": 0.78579
        },
        "rouge2": {
            "precision": 0.63082,
            "recall": 0.59409,
            "fmeasure": 0.59981
        },
        "rougeL": {
            "precision": 0.70592,
            "recall": 0.69905,
            "fmeasure": 0.68264
        },
        "rougeLsum": {
            "precision": 0.70592,
            "recall": 0.69905,
            "fmeasure": 0.68264
        },
        "local_recall": {
            "1": 0.4594594594594595,
            "2": 0.6,
            "3": 0.7764705882352941
        },
        "bleu": 52.73667,
        "nubia": {
            "semantic_relation": 4.2006,
            "contradiction": 8.46542,
            "irrelevancy": 28.29964,
            "logical_agreement": 63.23494,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.01319,
            "nubia_score": 0.67638
        },
        "meteor": 0.40539053284231036,
        "bleurt": 0.31772,
        "bertscore": {
            "precision": 0.95604,
            "recall": 0.93667,
            "f1": 0.94556
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 120,
        "total_length": 1947,
        "mean_pred_length": 16.225,
        "std_pred_length": 6.993404631031535,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.05546995377503852,
        "vocab_size-1": 108,
        "unique-1": 4,
        "entropy-1": 5.558854547097274,
        "distinct-2": 0.10454296661193213,
        "vocab_size-2": 191,
        "unique-2": 21,
        "entropy-2": 6.699576421067672,
        "cond_entropy-2": 1.0192887235045407,
        "distinct-3": 0.14411247803163443,
        "vocab_size-3": 246,
        "unique-3": 43,
        "entropy-3": 7.216741854571573,
        "cond_entropy-3": 0.5976107252837926,
        "total_length-nopunct": 1777,
        "mean_pred_length-nopunct": 14.808333333333334,
        "std_pred_length-nopunct": 6.701114127930933,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.06021384355655599,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.622321322721648,
        "distinct-2-nopunct": 0.10742305371152686,
        "vocab_size-2-nopunct": 178,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 6.573131780603156,
        "cond_entropy-2-nopunct": 1.080109131705798,
        "distinct-3-nopunct": 0.1509433962264151,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 7.118538593389392,
        "cond_entropy-3-nopunct": 0.6313001540761061,
        "msttr-100": 0.31053,
        "msttr-100_nopunct": 0.30647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 3.6159444865107333,
        "rouge1": {
            "precision": 0.61487,
            "recall": 0.63986,
            "fmeasure": 0.58968
        },
        "rouge2": {
            "precision": 0.38412,
            "recall": 0.39559,
            "fmeasure": 0.36403
        },
        "rougeL": {
            "precision": 0.50284,
            "recall": 0.52168,
            "fmeasure": 0.48013
        },
        "rougeLsum": {
            "precision": 0.50284,
            "recall": 0.52168,
            "fmeasure": 0.48013
        },
        "local_recall": {
            "1": 0.6102598267821452
        },
        "bleu": 22.93722,
        "nubia": {
            "semantic_relation": 3.76007,
            "contradiction": 8.26443,
            "irrelevancy": 48.90726,
            "logical_agreement": 42.82831,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.91706,
            "nubia_score": 0.59374
        },
        "meteor": 0.30118042577325366,
        "bleurt": -0.2272,
        "bertscore": {
            "precision": 0.88873,
            "recall": 0.88355,
            "f1": 0.88511
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.844324311457954,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.13550616686149178,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.726409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.1598736676159676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.222453087246532,
        "rouge1": {
            "precision": 0.87315,
            "recall": 0.72401,
            "fmeasure": 0.77582
        },
        "rouge2": {
            "precision": 0.55026,
            "recall": 0.46643,
            "fmeasure": 0.49008
        },
        "rougeL": {
            "precision": 0.79259,
            "recall": 0.63698,
            "fmeasure": 0.69198
        },
        "rougeLsum": {
            "precision": 0.79259,
            "recall": 0.63698,
            "fmeasure": 0.69198
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285,
            "3": 0.7857142857142857
        },
        "bleu": 35.7456,
        "nubia": {
            "semantic_relation": 4.24007,
            "contradiction": 1.56403,
            "irrelevancy": 35.43539,
            "logical_agreement": 63.00058,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.04606,
            "nubia_score": 0.71143
        },
        "meteor": 0.38497817698772896,
        "bleurt": 0.13975,
        "bertscore": {
            "precision": 0.94116,
            "recall": 0.9256,
            "f1": 0.93254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 101,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 3.131382371342656,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.6435643564356436,
        "vocab_size-1": 65,
        "unique-1": 49,
        "entropy-1": 5.692865384866958,
        "distinct-2": 0.9052631578947369,
        "vocab_size-2": 86,
        "unique-2": 77,
        "entropy-2": 6.380381924120421,
        "cond_entropy-2": 0.5852249769690542,
        "distinct-3": 0.9325842696629213,
        "vocab_size-3": 83,
        "unique-3": 77,
        "entropy-3": 6.34090197029225,
        "cond_entropy-3": -0.026706447027471304,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 2.5603819159562025,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6931818181818182,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.6596527503690774,
        "distinct-2-nopunct": 0.8902439024390244,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.138039809496138,
        "cond_entropy-2-nopunct": 0.5125172202198571,
        "distinct-3-nopunct": 0.9210526315789473,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.090032776601484,
        "cond_entropy-3-nopunct": -0.056992912227129516,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.738318052615308,
        "rouge1": {
            "precision": 0.78755,
            "recall": 0.76692,
            "fmeasure": 0.77155
        },
        "rouge2": {
            "precision": 0.60424,
            "recall": 0.59969,
            "fmeasure": 0.59632
        },
        "rougeL": {
            "precision": 0.69035,
            "recall": 0.66943,
            "fmeasure": 0.67475
        },
        "rougeLsum": {
            "precision": 0.69035,
            "recall": 0.66943,
            "fmeasure": 0.67475
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.625,
            "3": 0.7916666666666666
        },
        "bleu": 59.64305,
        "nubia": {
            "semantic_relation": 4.02219,
            "contradiction": 34.71008,
            "irrelevancy": 20.15428,
            "logical_agreement": 45.13565,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.15686,
            "nubia_score": 0.71194
        },
        "meteor": 0.42776519054215156,
        "bleurt": 0.3547,
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.93794,
            "f1": 0.93822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3208020839342967,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.5,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.14286,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.375,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.375,
            "fmeasure": 0.46154
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bleu": 12.38076,
        "nubia": {
            "semantic_relation": 4.72035,
            "contradiction": 0.20334,
            "irrelevancy": 0.53586,
            "logical_agreement": 99.2608,
            "grammar_ref": 5.02153,
            "grammar_hyp": 5.4649,
            "nubia_score": 0.88018
        },
        "meteor": 0.27874288773497435,
        "bleurt": 0.55805,
        "bertscore": {
            "precision": 0.94736,
            "recall": 0.88977,
            "f1": 0.91766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 546,
        "mean_pred_length": 17.612903225806452,
        "std_pred_length": 6.393935732545728,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5531135531135531,
        "vocab_size-1": 302,
        "unique-1": 238,
        "entropy-1": 7.433136446796475,
        "distinct-2": 0.8757281553398059,
        "vocab_size-2": 451,
        "unique-2": 405,
        "entropy-2": 8.720974058930185,
        "cond_entropy-2": 1.0895233517372809,
        "distinct-3": 0.9400826446280992,
        "vocab_size-3": 455,
        "unique-3": 428,
        "entropy-3": 8.79489629512589,
        "cond_entropy-3": 0.08250943445017984,
        "total_length-nopunct": 466,
        "mean_pred_length-nopunct": 15.03225806451613,
        "std_pred_length-nopunct": 5.373074274492133,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6373390557939914,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.665969593119929,
        "distinct-2-nopunct": 0.8942528735632184,
        "vocab_size-2-nopunct": 389,
        "unique-2-nopunct": 355,
        "entropy-2-nopunct": 8.51997659070621,
        "cond_entropy-2-nopunct": 0.921960447234209,
        "distinct-3-nopunct": 0.948019801980198,
        "vocab_size-3-nopunct": 383,
        "unique-3-nopunct": 362,
        "entropy-3-nopunct": 8.554251086712144,
        "cond_entropy-3-nopunct": 0.048115448978527535,
        "msttr-100": 0.732,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.319127485100494,
        "rouge1": {
            "precision": 0.81294,
            "recall": 0.79512,
            "fmeasure": 0.7936
        },
        "rouge2": {
            "precision": 0.60707,
            "recall": 0.61094,
            "fmeasure": 0.59989
        },
        "rougeL": {
            "precision": 0.69385,
            "recall": 0.68883,
            "fmeasure": 0.68168
        },
        "rougeLsum": {
            "precision": 0.69385,
            "recall": 0.68883,
            "fmeasure": 0.68168
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3,
            "3": 0.845945945945946
        },
        "bleu": 57.09662,
        "nubia": {
            "semantic_relation": 4.3855,
            "contradiction": 6.6442,
            "irrelevancy": 16.36046,
            "logical_agreement": 76.99534,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.63939,
            "nubia_score": 0.77794
        },
        "meteor": 0.439680030668371,
        "bleurt": 0.39996,
        "bertscore": {
            "precision": 0.94533,
            "recall": 0.94118,
            "f1": 0.94126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 67,
        "mean_pred_length": 13.4,
        "std_pred_length": 4.963869458396342,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.835820895522388,
        "vocab_size-1": 56,
        "unique-1": 48,
        "entropy-1": 5.683855750540801,
        "distinct-2": 1.0,
        "vocab_size-2": 62,
        "unique-2": 62,
        "entropy-2": 5.954196310386873,
        "cond_entropy-2": 0.11391357154200624,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.12130629622213351,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 11.6,
        "std_pred_length-nopunct": 4.2708313008125245,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.651084443403432,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.09635455377524965,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.1429579538420431,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.575960252318827,
        "rouge1": {
            "precision": 0.8168,
            "recall": 0.76868,
            "fmeasure": 0.7883
        },
        "rouge2": {
            "precision": 0.56705,
            "recall": 0.55738,
            "fmeasure": 0.55849
        },
        "rougeL": {
            "precision": 0.70952,
            "recall": 0.69759,
            "fmeasure": 0.69903
        },
        "rougeLsum": {
            "precision": 0.70952,
            "recall": 0.69759,
            "fmeasure": 0.69903
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7959183673469388
        },
        "bleu": 52.41892,
        "nubia": {
            "semantic_relation": 3.95423,
            "contradiction": 42.24178,
            "irrelevancy": 36.21672,
            "logical_agreement": 21.5415,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.60799,
            "nubia_score": 0.59111
        },
        "meteor": 0.4185704196322323,
        "bleurt": 0.35966,
        "bertscore": {
            "precision": 0.94214,
            "recall": 0.94849,
            "f1": 0.94509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 60,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.098068512058838,
        "distinct-2": 0.9107142857142857,
        "vocab_size-2": 51,
        "unique-2": 47,
        "entropy-2": 5.6153033595189745,
        "cond_entropy-2": 0.43215071057082377,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 51,
        "unique-3": 50,
        "entropy-3": 5.661978179679557,
        "cond_entropy-3": 0.06144801727893913,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.5811388300841898,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.074875775583771,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.402569011092755,
        "cond_entropy-2-nopunct": 0.3468035119570681,
        "distinct-3-nopunct": 0.9772727272727273,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.41397707318275,
        "cond_entropy-3-nopunct": -0.008032586596533789,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7588482924219457,
        "rouge1": {
            "precision": 0.89548,
            "recall": 0.7662,
            "fmeasure": 0.80155
        },
        "rouge2": {
            "precision": 0.66812,
            "recall": 0.60424,
            "fmeasure": 0.61436
        },
        "rougeL": {
            "precision": 0.74915,
            "recall": 0.65399,
            "fmeasure": 0.67957
        },
        "rougeLsum": {
            "precision": 0.74915,
            "recall": 0.65399,
            "fmeasure": 0.67957
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.375,
            "3": 0.7413793103448276
        },
        "bleu": 37.05984,
        "nubia": {
            "semantic_relation": 4.53178,
            "contradiction": 0.94394,
            "irrelevancy": 21.23765,
            "logical_agreement": 77.81841,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.50096,
            "nubia_score": 0.83069
        },
        "meteor": 0.3853878111569224,
        "bleurt": 0.32918,
        "bertscore": {
            "precision": 0.95141,
            "recall": 0.93247,
            "f1": 0.93567
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.0,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.41506101220307,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.28456745152635227,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.02999212699343525,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.286790198827111,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.2076430951702085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8645589214705423,
        "rouge1": {
            "precision": 0.66827,
            "recall": 0.83271,
            "fmeasure": 0.72008
        },
        "rouge2": {
            "precision": 0.51667,
            "recall": 0.56495,
            "fmeasure": 0.5261
        },
        "rougeL": {
            "precision": 0.55288,
            "recall": 0.61843,
            "fmeasure": 0.57008
        },
        "rougeLsum": {
            "precision": 0.55288,
            "recall": 0.61843,
            "fmeasure": 0.57008
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7894736842105263
        },
        "bleu": 36.69532,
        "nubia": {
            "semantic_relation": 4.18691,
            "contradiction": 41.09306,
            "irrelevancy": 10.58519,
            "logical_agreement": 48.32174,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.10566,
            "nubia_score": 0.6124
        },
        "meteor": 0.3584819782898789,
        "bleurt": 0.07886,
        "bertscore": {
            "precision": 0.90089,
            "recall": 0.91608,
            "f1": 0.90823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 108,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.220153254455275,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.7314814814814815,
        "vocab_size-1": 79,
        "unique-1": 67,
        "entropy-1": 6.016235302989227,
        "distinct-2": 0.99,
        "vocab_size-2": 99,
        "unique-2": 98,
        "entropy-2": 6.623856189774739,
        "cond_entropy-2": 0.4267130627194299,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.09855510328292916,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 11.875,
        "std_pred_length-nopunct": 4.7549316504025585,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.032807713503012,
        "distinct-2-nopunct": 0.9885057471264368,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.419954990101597,
        "cond_entropy-2-nopunct": 0.42503673819196275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.1138462919754231,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.75643635819027,
        "rouge1": {
            "precision": 0.7438,
            "recall": 0.65197,
            "fmeasure": 0.68866
        },
        "rouge2": {
            "precision": 0.48178,
            "recall": 0.40717,
            "fmeasure": 0.43842
        },
        "rougeL": {
            "precision": 0.61661,
            "recall": 0.55732,
            "fmeasure": 0.57774
        },
        "rougeLsum": {
            "precision": 0.61661,
            "recall": 0.55732,
            "fmeasure": 0.57774
        },
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.4166666666666667,
            "3": 0.7236842105263158
        },
        "bleu": 38.17264,
        "nubia": {
            "semantic_relation": 4.0598,
            "contradiction": 1.76807,
            "irrelevancy": 22.04447,
            "logical_agreement": 76.18746,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.85954,
            "nubia_score": 0.69747
        },
        "meteor": 0.3513724603312278,
        "bleurt": 0.16004,
        "bertscore": {
            "precision": 0.90709,
            "recall": 0.89394,
            "f1": 0.90013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 7.5,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.822000516883151,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.1804107236911675,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.7362967135428935,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.1367118399877133,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.457005245185531,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.58572,
            "fmeasure": 0.63898
        },
        "rouge2": {
            "precision": 0.58036,
            "recall": 0.32999,
            "fmeasure": 0.38737
        },
        "rougeL": {
            "precision": 0.53788,
            "recall": 0.37424,
            "fmeasure": 0.40878
        },
        "rougeLsum": {
            "precision": 0.53788,
            "recall": 0.37424,
            "fmeasure": 0.40878
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bleu": 20.23303,
        "nubia": {
            "semantic_relation": 3.98097,
            "contradiction": 0.15181,
            "irrelevancy": 43.68533,
            "logical_agreement": 56.16286,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.65021,
            "nubia_score": 0.69064
        },
        "meteor": 0.304411030101791,
        "bleurt": 0.13022,
        "bertscore": {
            "precision": 0.91673,
            "recall": 0.91495,
            "f1": 0.91339
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 109,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 7.104380495315705,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.7064220183486238,
        "vocab_size-1": 77,
        "unique-1": 64,
        "entropy-1": 5.968181026831617,
        "distinct-2": 0.970873786407767,
        "vocab_size-2": 100,
        "unique-2": 97,
        "entropy-2": 6.628248099998769,
        "cond_entropy-2": 0.5560888671801846,
        "distinct-3": 0.9896907216494846,
        "vocab_size-3": 96,
        "unique-3": 95,
        "entropy-3": 6.579294285486111,
        "cond_entropy-3": -0.04535057159402877,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 4.8876260995383936,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.776595744680851,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.943674788217835,
        "distinct-2-nopunct": 0.9886363636363636,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.436704345910033,
        "cond_entropy-2-nopunct": 0.5233191529280757,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.07748937011677476,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.817323395552395,
        "rouge1": {
            "precision": 0.83421,
            "recall": 0.82924,
            "fmeasure": 0.82558
        },
        "rouge2": {
            "precision": 0.61235,
            "recall": 0.61103,
            "fmeasure": 0.60844
        },
        "rougeL": {
            "precision": 0.73811,
            "recall": 0.75311,
            "fmeasure": 0.73769
        },
        "rougeLsum": {
            "precision": 0.73811,
            "recall": 0.75311,
            "fmeasure": 0.73769
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.8194444444444444
        },
        "bleu": 53.51262,
        "nubia": {
            "semantic_relation": 4.39186,
            "contradiction": 14.1819,
            "irrelevancy": 25.65232,
            "logical_agreement": 60.16579,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.26877,
            "nubia_score": 0.66803
        },
        "meteor": 0.42405244509060225,
        "bleurt": 0.01016,
        "bertscore": {
            "precision": 0.93207,
            "recall": 0.93918,
            "f1": 0.93348
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 16,
        "total_length": 297,
        "mean_pred_length": 18.5625,
        "std_pred_length": 7.984115088724611,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 43,
        "distinct-1": 0.5723905723905723,
        "vocab_size-1": 170,
        "unique-1": 134,
        "entropy-1": 6.797399477520287,
        "distinct-2": 0.8754448398576512,
        "vocab_size-2": 246,
        "unique-2": 221,
        "entropy-2": 7.847845092416727,
        "cond_entropy-2": 0.9033663063287968,
        "distinct-3": 0.9169811320754717,
        "vocab_size-3": 243,
        "unique-3": 224,
        "entropy-3": 7.875264917350554,
        "cond_entropy-3": 0.04472284246167457,
        "total_length-nopunct": 248,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.636809247747852,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6693548387096774,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 134,
        "entropy-1-nopunct": 6.989122658156838,
        "distinct-2-nopunct": 0.8922413793103449,
        "vocab_size-2-nopunct": 207,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.627335413212352,
        "cond_entropy-2-nopunct": 0.7004592138300332,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 185,
        "entropy-3-nopunct": 7.603244504468264,
        "cond_entropy-3-nopunct": -0.007006050824457697,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.469421618372728,
        "rouge1": {
            "precision": 0.77514,
            "recall": 0.81159,
            "fmeasure": 0.78575
        },
        "rouge2": {
            "precision": 0.56271,
            "recall": 0.59392,
            "fmeasure": 0.57322
        },
        "rougeL": {
            "precision": 0.70817,
            "recall": 0.74316,
            "fmeasure": 0.71892
        },
        "rougeLsum": {
            "precision": 0.70817,
            "recall": 0.74316,
            "fmeasure": 0.71892
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.36585365853658536,
            "3": 0.8486486486486486
        },
        "bleu": 52.84529,
        "nubia": {
            "semantic_relation": 4.41538,
            "contradiction": 1.21673,
            "irrelevancy": 37.65632,
            "logical_agreement": 61.12695,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.28922,
            "nubia_score": 0.81485
        },
        "meteor": 0.4394877982274869,
        "bleurt": 0.45208,
        "bertscore": {
            "precision": 0.94165,
            "recall": 0.95429,
            "f1": 0.94576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 25,
        "total_length": 442,
        "mean_pred_length": 17.68,
        "std_pred_length": 7.2758229775057055,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.5723981900452488,
        "vocab_size-1": 253,
        "unique-1": 210,
        "entropy-1": 7.216562942026188,
        "distinct-2": 0.9088729016786571,
        "vocab_size-2": 379,
        "unique-2": 366,
        "entropy-2": 8.441553236714999,
        "cond_entropy-2": 1.0373943653857123,
        "distinct-3": 0.9566326530612245,
        "vocab_size-3": 375,
        "unique-3": 371,
        "entropy-3": 8.480344960280913,
        "cond_entropy-3": 0.055523250142995244,
        "total_length-nopunct": 391,
        "mean_pred_length-nopunct": 15.64,
        "std_pred_length-nopunct": 6.285729870110551,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6342710997442456,
        "vocab_size-1-nopunct": 248,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.334821009790634,
        "distinct-2-nopunct": 0.8961748633879781,
        "vocab_size-2-nopunct": 328,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 8.216792487419905,
        "cond_entropy-2-nopunct": 0.9582149057384277,
        "distinct-3-nopunct": 0.9501466275659824,
        "vocab_size-3-nopunct": 324,
        "unique-3-nopunct": 320,
        "entropy-3-nopunct": 8.259167417402313,
        "cond_entropy-3-nopunct": 0.06428895863807885,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.4661048599208595,
        "rouge1": {
            "precision": 0.76621,
            "recall": 0.78088,
            "fmeasure": 0.76195
        },
        "rouge2": {
            "precision": 0.55835,
            "recall": 0.56161,
            "fmeasure": 0.55096
        },
        "rougeL": {
            "precision": 0.66416,
            "recall": 0.67003,
            "fmeasure": 0.65599
        },
        "rougeLsum": {
            "precision": 0.66416,
            "recall": 0.67003,
            "fmeasure": 0.65599
        },
        "local_recall": {
            "1": 0.15217391304347827,
            "2": 0.40625,
            "3": 0.8207885304659498
        },
        "bleu": 47.5397,
        "nubia": {
            "semantic_relation": 4.21208,
            "contradiction": 8.3486,
            "irrelevancy": 27.53153,
            "logical_agreement": 64.11987,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.58061,
            "nubia_score": 0.74807
        },
        "meteor": 0.41125845115861,
        "bleurt": 0.27825,
        "bertscore": {
            "precision": 0.93084,
            "recall": 0.93193,
            "f1": 0.92996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 136,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.338539126015656,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6617647058823529,
        "vocab_size-1": 90,
        "unique-1": 68,
        "entropy-1": 6.192252503295522,
        "distinct-2": 0.8828125,
        "vocab_size-2": 113,
        "unique-2": 100,
        "entropy-2": 6.75,
        "cond_entropy-2": 0.42619814282664764,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 112,
        "unique-3": 104,
        "entropy-3": 6.773557262275202,
        "cond_entropy-3": 0.040223928941851825,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7327586206896551,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.197384525445744,
        "distinct-2-nopunct": 0.8796296296296297,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.495628242904199,
        "cond_entropy-2-nopunct": 0.3471767892867361,
        "distinct-3-nopunct": 0.94,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.5238561897747385,
        "cond_entropy-3-nopunct": 0.04896868761125614,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.32693460350482,
        "rouge1": {
            "precision": 0.8404,
            "recall": 0.79557,
            "fmeasure": 0.79863
        },
        "rouge2": {
            "precision": 0.65943,
            "recall": 0.6354,
            "fmeasure": 0.63244
        },
        "rougeL": {
            "precision": 0.71252,
            "recall": 0.71419,
            "fmeasure": 0.69737
        },
        "rougeLsum": {
            "precision": 0.71252,
            "recall": 0.71419,
            "fmeasure": 0.69737
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.5,
            "3": 0.7623762376237624
        },
        "bleu": 52.1236,
        "nubia": {
            "semantic_relation": 4.5184,
            "contradiction": 2.37449,
            "irrelevancy": 30.49836,
            "logical_agreement": 67.12715,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.53251,
            "nubia_score": 0.83783
        },
        "meteor": 0.4235574531305292,
        "bleurt": 0.42351,
        "bertscore": {
            "precision": 0.93602,
            "recall": 0.93027,
            "f1": 0.93177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 42,
        "total_length": 719,
        "mean_pred_length": 17.11904761904762,
        "std_pred_length": 5.3193375032914485,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5549374130737135,
        "vocab_size-1": 399,
        "unique-1": 330,
        "entropy-1": 7.667784798849718,
        "distinct-2": 0.912850812407681,
        "vocab_size-2": 618,
        "unique-2": 581,
        "entropy-2": 9.184771837516015,
        "cond_entropy-2": 1.293388121516092,
        "distinct-3": 0.9779527559055118,
        "vocab_size-3": 621,
        "unique-3": 609,
        "entropy-3": 9.264140695038478,
        "cond_entropy-3": 0.09380364148221117,
        "total_length-nopunct": 635,
        "mean_pred_length-nopunct": 15.119047619047619,
        "std_pred_length-nopunct": 4.766961600694338,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6204724409448819,
        "vocab_size-1-nopunct": 394,
        "unique-1-nopunct": 330,
        "entropy-1-nopunct": 7.885173501173363,
        "distinct-2-nopunct": 0.9106239460370995,
        "vocab_size-2-nopunct": 540,
        "unique-2-nopunct": 509,
        "entropy-2-nopunct": 8.982969903379251,
        "cond_entropy-2-nopunct": 1.1816050443289585,
        "distinct-3-nopunct": 0.9764065335753176,
        "vocab_size-3-nopunct": 538,
        "unique-3-nopunct": 527,
        "entropy-3-nopunct": 9.055981512193014,
        "cond_entropy-3-nopunct": 0.08864604153427902,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.833773974879185,
        "rouge1": {
            "precision": 0.77896,
            "recall": 0.78025,
            "fmeasure": 0.77138
        },
        "rouge2": {
            "precision": 0.5692,
            "recall": 0.57021,
            "fmeasure": 0.56357
        },
        "rougeL": {
            "precision": 0.69024,
            "recall": 0.69286,
            "fmeasure": 0.68339
        },
        "rougeLsum": {
            "precision": 0.69024,
            "recall": 0.69286,
            "fmeasure": 0.68339
        },
        "local_recall": {
            "1": 0.1565217391304348,
            "2": 0.5698924731182796,
            "3": 0.7851239669421488
        },
        "bleu": 47.76404,
        "nubia": {
            "semantic_relation": 4.34808,
            "contradiction": 18.23373,
            "irrelevancy": 29.12682,
            "logical_agreement": 52.63946,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.57367,
            "nubia_score": 0.75897
        },
        "meteor": 0.41437716796662616,
        "bleurt": 0.33758,
        "bertscore": {
            "precision": 0.93732,
            "recall": 0.94094,
            "f1": 0.93796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.492987572583879,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.81871,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.46187,
            "fmeasure": 0.42864
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "bleu": 7.63264,
        "nubia": {
            "semantic_relation": 4.94988,
            "contradiction": 0.13218,
            "irrelevancy": 2.70518,
            "logical_agreement": 97.16264,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.47348,
            "nubia_score": 0.96968
        },
        "meteor": 0.3334542336538618,
        "bleurt": 0.35816,
        "bertscore": {
            "precision": 0.88546,
            "recall": 0.91538,
            "f1": 0.89971
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.875,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.726409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.23661203626311622,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.04730571477835684,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 29.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.13401410555297188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.05246741989413545,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6455874136959978,
        "rouge1": {
            "precision": 0.37255,
            "recall": 0.47483,
            "fmeasure": 0.41749
        },
        "rouge2": {
            "precision": 0.21212,
            "recall": 0.28,
            "fmeasure": 0.24138
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.46154,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.46154,
            "fmeasure": 0.4
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.47058823529411764
        },
        "bleu": 17.99582,
        "nubia": {
            "semantic_relation": 2.79869,
            "contradiction": 1.27591,
            "irrelevancy": 97.71719,
            "logical_agreement": 1.0069,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.57379,
            "nubia_score": 0.33567
        },
        "meteor": 0.2526831626277051,
        "bleurt": -0.70422,
        "bertscore": {
            "precision": 0.83468,
            "recall": 0.87092,
            "f1": 0.85231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 19,
        "total_length": 390,
        "mean_pred_length": 20.526315789473685,
        "std_pred_length": 16.184360290278395,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 82,
        "distinct-1": 0.49743589743589745,
        "vocab_size-1": 194,
        "unique-1": 156,
        "entropy-1": 6.601235844227117,
        "distinct-2": 0.7681940700808625,
        "vocab_size-2": 285,
        "unique-2": 262,
        "entropy-2": 7.761683157637197,
        "cond_entropy-2": 1.0608708845556156,
        "distinct-3": 0.8153409090909091,
        "vocab_size-3": 287,
        "unique-3": 276,
        "entropy-3": 7.812154761295881,
        "cond_entropy-3": 0.08654618366061408,
        "total_length-nopunct": 335,
        "mean_pred_length-nopunct": 17.63157894736842,
        "std_pred_length-nopunct": 13.071505878359151,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.5671641791044776,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.812514934614557,
        "distinct-2-nopunct": 0.7911392405063291,
        "vocab_size-2-nopunct": 250,
        "unique-2-nopunct": 232,
        "entropy-2-nopunct": 7.612857714063687,
        "cond_entropy-2-nopunct": 0.885578680284195,
        "distinct-3-nopunct": 0.8417508417508418,
        "vocab_size-3-nopunct": 250,
        "unique-3-nopunct": 242,
        "entropy-3-nopunct": 7.664110385981595,
        "cond_entropy-3-nopunct": 0.09208613201269963,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.63667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.260052387050456,
        "rouge1": {
            "precision": 0.66626,
            "recall": 0.65013,
            "fmeasure": 0.64072
        },
        "rouge2": {
            "precision": 0.43761,
            "recall": 0.43175,
            "fmeasure": 0.42235
        },
        "rougeL": {
            "precision": 0.57214,
            "recall": 0.57021,
            "fmeasure": 0.5558
        },
        "rougeLsum": {
            "precision": 0.57214,
            "recall": 0.57021,
            "fmeasure": 0.5558
        },
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.37362637362637363,
            "3": 0.7109826589595376
        },
        "bleu": 28.70555,
        "nubia": {
            "semantic_relation": 3.91689,
            "contradiction": 14.94069,
            "irrelevancy": 36.65637,
            "logical_agreement": 48.40294,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.47152,
            "nubia_score": 0.60626
        },
        "meteor": 0.3025385974471359,
        "bleurt": 0.02495,
        "bertscore": {
            "precision": 0.88237,
            "recall": 0.886,
            "f1": 0.8822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 58,
        "mean_pred_length": 11.6,
        "std_pred_length": 4.223742416388575,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 46,
        "unique-1": 38,
        "entropy-1": 5.368937409324118,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.18606941230663604,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.1429579538420431,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.5777087639996634,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.403856189774728,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.09244135099939446,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.16992500144231248,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8464961269174305,
        "rouge1": {
            "precision": 0.7387,
            "recall": 0.73481,
            "fmeasure": 0.73484
        },
        "rouge2": {
            "precision": 0.44253,
            "recall": 0.44452,
            "fmeasure": 0.44027
        },
        "rougeL": {
            "precision": 0.70954,
            "recall": 0.70386,
            "fmeasure": 0.70495
        },
        "rougeLsum": {
            "precision": 0.70954,
            "recall": 0.70386,
            "fmeasure": 0.70495
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7631578947368421
        },
        "bleu": 32.47929,
        "nubia": {
            "semantic_relation": 4.31111,
            "contradiction": 0.67735,
            "irrelevancy": 43.13105,
            "logical_agreement": 56.1916,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.20411,
            "nubia_score": 0.84071
        },
        "meteor": 0.4168307557608984,
        "bleurt": 0.31044,
        "bertscore": {
            "precision": 0.92703,
            "recall": 0.9261,
            "f1": 0.92647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 118,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 7.295356209413097,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.6610169491525424,
        "vocab_size-1": 78,
        "unique-1": 64,
        "entropy-1": 5.86222373699207,
        "distinct-2": 0.9107142857142857,
        "vocab_size-2": 102,
        "unique-2": 97,
        "entropy-2": 6.590706149678215,
        "cond_entropy-2": 0.6446675990244677,
        "distinct-3": 0.9433962264150944,
        "vocab_size-3": 100,
        "unique-3": 96,
        "entropy-3": 6.600469746975194,
        "cond_entropy-3": 0.022026735356193806,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 17.833333333333332,
        "std_pred_length-nopunct": 6.841458583924597,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6915887850467289,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.805534123287664,
        "distinct-2-nopunct": 0.900990099009901,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.417967299519201,
        "cond_entropy-2-nopunct": 0.658132158198682,
        "distinct-3-nopunct": 0.9368421052631579,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.427647450390664,
        "cond_entropy-3-nopunct": 0.02485346770718973,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4453860491296093,
        "rouge1": {
            "precision": 0.60585,
            "recall": 0.7445,
            "fmeasure": 0.62934
        },
        "rouge2": {
            "precision": 0.38952,
            "recall": 0.48003,
            "fmeasure": 0.40039
        },
        "rougeL": {
            "precision": 0.54146,
            "recall": 0.67785,
            "fmeasure": 0.5654
        },
        "rougeLsum": {
            "precision": 0.54146,
            "recall": 0.67785,
            "fmeasure": 0.5654
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.4166666666666667,
            "3": 0.8333333333333334
        },
        "bleu": 27.61161,
        "nubia": {
            "semantic_relation": 3.90243,
            "contradiction": 13.8581,
            "irrelevancy": 56.87171,
            "logical_agreement": 29.2702,
            "grammar_ref": 4.25456,
            "grammar_hyp": 3.96649,
            "nubia_score": 0.59304
        },
        "meteor": 0.3796705257812352,
        "bleurt": -0.08095,
        "bertscore": {
            "precision": 0.86489,
            "recall": 0.89547,
            "f1": 0.8787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 199,
        "mean_pred_length": 16.583333333333332,
        "std_pred_length": 7.79378313500931,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.6080402010050251,
        "vocab_size-1": 121,
        "unique-1": 97,
        "entropy-1": 6.325132126851206,
        "distinct-2": 0.9358288770053476,
        "vocab_size-2": 175,
        "unique-2": 165,
        "entropy-2": 7.407857026732539,
        "cond_entropy-2": 0.9368337764356663,
        "distinct-3": 0.9771428571428571,
        "vocab_size-3": 171,
        "unique-3": 167,
        "entropy-3": 7.405496826118024,
        "cond_entropy-3": 0.007173794801834761,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 6.469479628738826,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6783625730994152,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.372541548293676,
        "distinct-2-nopunct": 0.9371069182389937,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.174518175410113,
        "cond_entropy-2-nopunct": 0.8708997032069411,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 144,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.158856018305743,
        "cond_entropy-3-nopunct": -0.004367073033024803,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.187950592449294,
        "rouge1": {
            "precision": 0.62911,
            "recall": 0.66737,
            "fmeasure": 0.63201
        },
        "rouge2": {
            "precision": 0.41389,
            "recall": 0.43826,
            "fmeasure": 0.41445
        },
        "rougeL": {
            "precision": 0.56673,
            "recall": 0.61127,
            "fmeasure": 0.57498
        },
        "rougeLsum": {
            "precision": 0.56673,
            "recall": 0.61127,
            "fmeasure": 0.57498
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.3225806451612903,
            "3": 0.625
        },
        "bleu": 27.40367,
        "nubia": {
            "semantic_relation": 3.87139,
            "contradiction": 15.57045,
            "irrelevancy": 41.74427,
            "logical_agreement": 42.68528,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.42278,
            "nubia_score": 0.62632
        },
        "meteor": 0.3438904230583881,
        "bleurt": 0.10859,
        "bertscore": {
            "precision": 0.89048,
            "recall": 0.91139,
            "f1": 0.89641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.555121510822243,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6511627906976745,
        "vocab_size-1": 84,
        "unique-1": 67,
        "entropy-1": 5.962512429724452,
        "distinct-2": 0.9338842975206612,
        "vocab_size-2": 113,
        "unique-2": 106,
        "entropy-2": 6.780393092628622,
        "cond_entropy-2": 0.6888700728677125,
        "distinct-3": 0.9646017699115044,
        "vocab_size-3": 109,
        "unique-3": 105,
        "entropy-3": 6.749382502238214,
        "cond_entropy-3": -0.021207394309287465,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 14.125,
        "std_pred_length-nopunct": 4.728570079844435,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7256637168141593,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.047752302989145,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 94,
        "entropy-2-nopunct": 6.59277039859789,
        "cond_entropy-2-nopunct": 0.594345841088848,
        "distinct-3-nopunct": 0.979381443298969,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.558675728785079,
        "cond_entropy-3-nopunct": -0.024076103291742527,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.482092802453399,
        "rouge1": {
            "precision": 0.8029,
            "recall": 0.71936,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.54835,
            "recall": 0.48882,
            "fmeasure": 0.50812
        },
        "rougeL": {
            "precision": 0.74477,
            "recall": 0.65522,
            "fmeasure": 0.68603
        },
        "rougeLsum": {
            "precision": 0.74477,
            "recall": 0.65522,
            "fmeasure": 0.68603
        },
        "local_recall": {
            "1": 0.10714285714285714,
            "2": 0.4,
            "3": 0.7473684210526316
        },
        "bleu": 44.68176,
        "nubia": {
            "semantic_relation": 4.19842,
            "contradiction": 3.04179,
            "irrelevancy": 21.18004,
            "logical_agreement": 75.77817,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.85178,
            "nubia_score": 0.70729
        },
        "meteor": 0.370917824797272,
        "bleurt": 0.26133,
        "bertscore": {
            "precision": 0.95253,
            "recall": 0.93038,
            "f1": 0.93878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7642741174382337,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "bleu": 81.76129,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.96713,
            "irrelevancy": 0.64693,
            "logical_agreement": 98.38594,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.52299,
            "nubia_score": 1.0
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.69712,
        "bertscore": {
            "precision": 0.97871,
            "recall": 0.94782,
            "f1": 0.96301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 101,
        "mean_pred_length": 14.428571428571429,
        "std_pred_length": 4.435478484645721,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7029702970297029,
        "vocab_size-1": 71,
        "unique-1": 59,
        "entropy-1": 5.789987874120985,
        "distinct-2": 0.9361702127659575,
        "vocab_size-2": 88,
        "unique-2": 82,
        "entropy-2": 6.426929277209544,
        "cond_entropy-2": 0.49253800740784015,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 84,
        "unique-3": 81,
        "entropy-3": 6.373977978607345,
        "cond_entropy-3": -0.042679838587529696,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 12.571428571428571,
        "std_pred_length-nopunct": 3.736199094463434,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7613636363636364,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.777169118440622,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.191701854736469,
        "cond_entropy-2-nopunct": 0.473493693102979,
        "distinct-3-nopunct": 0.9594594594594594,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.128372284547874,
        "cond_entropy-3-nopunct": -0.04931555617459418,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.608383125789113,
        "rouge1": {
            "precision": 0.66719,
            "recall": 0.59752,
            "fmeasure": 0.61689
        },
        "rouge2": {
            "precision": 0.41871,
            "recall": 0.3718,
            "fmeasure": 0.38434
        },
        "rougeL": {
            "precision": 0.57648,
            "recall": 0.52788,
            "fmeasure": 0.53739
        },
        "rougeLsum": {
            "precision": 0.57648,
            "recall": 0.52788,
            "fmeasure": 0.53739
        },
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.6666666666666666,
            "3": 0.5384615384615384
        },
        "bleu": 35.04185,
        "nubia": {
            "semantic_relation": 3.94757,
            "contradiction": 26.96447,
            "irrelevancy": 26.00604,
            "logical_agreement": 47.02949,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.27852,
            "nubia_score": 0.64784
        },
        "meteor": 0.3138247070690552,
        "bleurt": 0.08157,
        "bertscore": {
            "precision": 0.912,
            "recall": 0.90197,
            "f1": 0.90619
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 97,
        "mean_pred_length": 12.125,
        "std_pred_length": 2.5708704751503917,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.5567010309278351,
        "vocab_size-1": 54,
        "unique-1": 39,
        "entropy-1": 5.339287327367609,
        "distinct-2": 0.7415730337078652,
        "vocab_size-2": 66,
        "unique-2": 56,
        "entropy-2": 5.805962189680599,
        "cond_entropy-2": 0.3103265939821588,
        "distinct-3": 0.7901234567901234,
        "vocab_size-3": 64,
        "unique-3": 57,
        "entropy-3": 5.796640126341408,
        "cond_entropy-3": 0.05682818271374317,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 10.875,
        "std_pred_length-nopunct": 2.2043990110685496,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5977011494252874,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.336269071279833,
        "distinct-2-nopunct": 0.7088607594936709,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.549228337108282,
        "cond_entropy-2-nopunct": 0.2829778392672321,
        "distinct-3-nopunct": 0.7605633802816901,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.5300288096455255,
        "cond_entropy-3-nopunct": 0.05173595547457642,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.6363096287860035,
        "rouge1": {
            "precision": 0.87195,
            "recall": 0.86064,
            "fmeasure": 0.86034
        },
        "rouge2": {
            "precision": 0.7861,
            "recall": 0.76396,
            "fmeasure": 0.77129
        },
        "rougeL": {
            "precision": 0.84828,
            "recall": 0.83455,
            "fmeasure": 0.8362
        },
        "rougeLsum": {
            "precision": 0.84828,
            "recall": 0.83455,
            "fmeasure": 0.8362
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.16666666666666666,
            "3": 0.9135802469135802
        },
        "bleu": 71.92584,
        "nubia": {
            "semantic_relation": 4.52254,
            "contradiction": 0.75899,
            "irrelevancy": 21.97898,
            "logical_agreement": 77.26203,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.97923,
            "nubia_score": 0.86407
        },
        "meteor": 0.5073171506491034,
        "bleurt": 0.63893,
        "bertscore": {
            "precision": 0.96453,
            "recall": 0.96605,
            "f1": 0.9644
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.7954545454545454,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 4.970573095811684,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.25799569091160274,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.05699291222712945,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.907071770088825,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.114369445886754,
        "cond_entropy-2-nopunct": 0.23882521319571604,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.06492482147779848,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.92924624951119,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.67369,
            "fmeasure": 0.64355
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.37685,
            "fmeasure": 0.36519
        },
        "rougeL": {
            "precision": 0.55952,
            "recall": 0.56195,
            "fmeasure": 0.54864
        },
        "rougeLsum": {
            "precision": 0.55952,
            "recall": 0.56195,
            "fmeasure": 0.54864
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.625,
            "3": 0.8666666666666667
        },
        "bleu": 39.48349,
        "nubia": {
            "semantic_relation": 3.54126,
            "contradiction": 0.36644,
            "irrelevancy": 65.33432,
            "logical_agreement": 34.29923,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.06188,
            "nubia_score": 0.51558
        },
        "meteor": 0.3739723340171924,
        "bleurt": 0.02783,
        "bertscore": {
            "precision": 0.88645,
            "recall": 0.8989,
            "f1": 0.89209
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 6.446008098673416,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7297297297297297,
        "vocab_size-1": 81,
        "unique-1": 67,
        "entropy-1": 6.06637312839396,
        "distinct-2": 0.9903846153846154,
        "vocab_size-2": 103,
        "unique-2": 102,
        "entropy-2": 6.681208948910331,
        "cond_entropy-2": 0.47488211581723727,
        "distinct-3": 1.0,
        "vocab_size-3": 97,
        "unique-3": 97,
        "entropy-3": 6.599912842187142,
        "cond_entropy-3": -0.0799083192529335,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 5.3375833406484015,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.152569011092755,
        "distinct-2-nopunct": 0.9887640449438202,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.45326152085405,
        "cond_entropy-2-nopunct": 0.32346503141745403,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.10598630439709444,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.384467123513336,
        "rouge1": {
            "precision": 0.82079,
            "recall": 0.81381,
            "fmeasure": 0.81419
        },
        "rouge2": {
            "precision": 0.65251,
            "recall": 0.64601,
            "fmeasure": 0.64674
        },
        "rougeL": {
            "precision": 0.77192,
            "recall": 0.76828,
            "fmeasure": 0.76736
        },
        "rougeLsum": {
            "precision": 0.77192,
            "recall": 0.76828,
            "fmeasure": 0.76736
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.375,
            "3": 0.810126582278481
        },
        "bleu": 56.46264,
        "nubia": {
            "semantic_relation": 4.37853,
            "contradiction": 6.22226,
            "irrelevancy": 24.31645,
            "logical_agreement": 69.46129,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.67011,
            "nubia_score": 0.7704
        },
        "meteor": 0.41624403241765917,
        "bleurt": 0.42252,
        "bertscore": {
            "precision": 0.95382,
            "recall": 0.94991,
            "f1": 0.95173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 222,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 4.867635724971663,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6396396396396397,
        "vocab_size-1": 142,
        "unique-1": 114,
        "entropy-1": 6.667350277862452,
        "distinct-2": 0.9134615384615384,
        "vocab_size-2": 190,
        "unique-2": 175,
        "entropy-2": 7.514118143611438,
        "cond_entropy-2": 0.6663637759894848,
        "distinct-3": 0.9690721649484536,
        "vocab_size-3": 188,
        "unique-3": 182,
        "entropy-3": 7.5380571720840095,
        "cond_entropy-3": 0.037384915294300866,
        "total_length-nopunct": 190,
        "mean_pred_length-nopunct": 13.571428571428571,
        "std_pred_length-nopunct": 4.271404682207444,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7157894736842105,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.769345311340019,
        "distinct-2-nopunct": 0.9147727272727273,
        "vocab_size-2-nopunct": 161,
        "unique-2-nopunct": 149,
        "entropy-2-nopunct": 7.273324303284105,
        "cond_entropy-2-nopunct": 0.5562923110229074,
        "distinct-3-nopunct": 0.9753086419753086,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 7.290467286835223,
        "cond_entropy-3-nopunct": 0.03322633179154645,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.83,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.2714487818970825,
        "rouge1": {
            "precision": 0.82702,
            "recall": 0.82354,
            "fmeasure": 0.81935
        },
        "rouge2": {
            "precision": 0.69618,
            "recall": 0.68283,
            "fmeasure": 0.68473
        },
        "rougeL": {
            "precision": 0.73878,
            "recall": 0.73095,
            "fmeasure": 0.72891
        },
        "rougeLsum": {
            "precision": 0.73878,
            "recall": 0.73095,
            "fmeasure": 0.72891
        },
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.375,
            "3": 0.9102564102564102
        },
        "bleu": 64.8134,
        "nubia": {
            "semantic_relation": 4.2542,
            "contradiction": 8.45883,
            "irrelevancy": 24.30141,
            "logical_agreement": 67.23976,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.90058,
            "nubia_score": 0.73563
        },
        "meteor": 0.4727781287455736,
        "bleurt": 0.49456,
        "bertscore": {
            "precision": 0.94844,
            "recall": 0.93507,
            "f1": 0.94106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.2381054815525046,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.306664886548115,
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "bleu": 27.09199,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        },
        "meteor": 0.4912092865802179,
        "bleurt": 0.67831,
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 68,
        "mean_pred_length": 34.0,
        "std_pred_length": 22.0,
        "median_pred_length": 34.0,
        "min_pred_length": 12,
        "max_pred_length": 56,
        "distinct-1": 0.5147058823529411,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 4.346850798091985,
        "distinct-2": 0.5909090909090909,
        "vocab_size-2": 39,
        "unique-2": 33,
        "entropy-2": 4.65669752785933,
        "cond_entropy-2": 0.3322895189539568,
        "distinct-3": 0.640625,
        "vocab_size-3": 41,
        "unique-3": 35,
        "entropy-3": 4.833307960931275,
        "cond_entropy-3": 0.2199759515562963,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 25.5,
        "std_pred_length-nopunct": 15.5,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6274509803921569,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.4359812238153875,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.713914630086277,
        "cond_entropy-2-nopunct": 0.32840051313440666,
        "distinct-3-nopunct": 0.7872340425531915,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 4.975455214467563,
        "cond_entropy-3-nopunct": 0.29987229561655654,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8568169321026478,
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.48036,
            "fmeasure": 0.478
        },
        "rouge2": {
            "precision": 0.30377,
            "recall": 0.30647,
            "fmeasure": 0.30487
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.43133,
            "fmeasure": 0.42975
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.43133,
            "fmeasure": 0.42975
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "bleu": 21.62128,
        "nubia": {
            "semantic_relation": 3.8842,
            "contradiction": 26.26847,
            "irrelevancy": 58.60492,
            "logical_agreement": 15.12661,
            "grammar_ref": 4.45404,
            "grammar_hyp": 3.86234,
            "nubia_score": 0.67596
        },
        "meteor": 0.2560186512837891,
        "bleurt": -0.17885,
        "bertscore": {
            "precision": 0.9005,
            "recall": 0.8553,
            "f1": 0.87701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 5.0,
        "median_pred_length": 21.0,
        "min_pred_length": 16,
        "max_pred_length": 26,
        "distinct-1": 0.6904761904761905,
        "vocab_size-1": 29,
        "unique-1": 20,
        "entropy-1": 4.678031708493047,
        "distinct-2": 0.875,
        "vocab_size-2": 35,
        "unique-2": 30,
        "entropy-2": 5.0719280948873635,
        "cond_entropy-2": 0.379610672108602,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 34,
        "unique-3": 30,
        "entropy-3": 5.037401197654114,
        "cond_entropy-3": -0.021369002496408343,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.625,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.706890595608519,
        "cond_entropy-2-nopunct": 0.07355726227518523,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.664497779200462,
        "cond_entropy-3-nopunct": -0.06382138783662865,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.712881259967439,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.56732,
            "fmeasure": 0.63739
        },
        "rouge2": {
            "precision": 0.35952,
            "recall": 0.27634,
            "fmeasure": 0.31247
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.35468,
            "fmeasure": 0.39843
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.35468,
            "fmeasure": 0.39843
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6470588235294118
        },
        "bleu": 31.62501,
        "nubia": {
            "semantic_relation": 3.8681,
            "contradiction": 0.75386,
            "irrelevancy": 29.05623,
            "logical_agreement": 70.1899,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.56579,
            "nubia_score": 0.64519
        },
        "meteor": 0.3317309793753958,
        "bleurt": 0.17855,
        "bertscore": {
            "precision": 0.89833,
            "recall": 0.88472,
            "f1": 0.89063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 235,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 5.771587692290217,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.625531914893617,
        "vocab_size-1": 147,
        "unique-1": 119,
        "entropy-1": 6.609431102405552,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 204,
        "unique-2": 193,
        "entropy-2": 7.605257636420371,
        "cond_entropy-2": 0.8349045109805548,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 201,
        "unique-3": 195,
        "entropy-3": 7.635515943006544,
        "cond_entropy-3": 0.042611103308861295,
        "total_length-nopunct": 209,
        "mean_pred_length-nopunct": 14.928571428571429,
        "std_pred_length-nopunct": 5.444056860654636,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6794258373205742,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.6508485100031045,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.420845554895285,
        "cond_entropy-2-nopunct": 0.8274646664735325,
        "distinct-3-nopunct": 0.9779005524861878,
        "vocab_size-3-nopunct": 177,
        "unique-3-nopunct": 173,
        "entropy-3-nopunct": 7.45564699205555,
        "cond_entropy-3-nopunct": 0.04370081077337511,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.478892870727201,
        "rouge1": {
            "precision": 0.69954,
            "recall": 0.68077,
            "fmeasure": 0.67112
        },
        "rouge2": {
            "precision": 0.42977,
            "recall": 0.43237,
            "fmeasure": 0.4177
        },
        "rougeL": {
            "precision": 0.63055,
            "recall": 0.60781,
            "fmeasure": 0.6057
        },
        "rougeLsum": {
            "precision": 0.63055,
            "recall": 0.60781,
            "fmeasure": 0.6057
        },
        "local_recall": {
            "1": 0.1896551724137931,
            "2": 0.4418604651162791,
            "3": 0.7445255474452555
        },
        "bleu": 38.96724,
        "nubia": {
            "semantic_relation": 3.95268,
            "contradiction": 23.74748,
            "irrelevancy": 33.75355,
            "logical_agreement": 42.49898,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.17099,
            "nubia_score": 0.66969
        },
        "meteor": 0.3679406477590759,
        "bleurt": 0.2319,
        "bertscore": {
            "precision": 0.9149,
            "recall": 0.90772,
            "f1": 0.90945
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 133,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.855400437691199,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6842105263157895,
        "vocab_size-1": 91,
        "unique-1": 76,
        "entropy-1": 6.126973999542336,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 123,
        "unique-2": 121,
        "entropy-2": 6.923669705228786,
        "cond_entropy-2": 0.6816017299063843,
        "distinct-3": 1.0,
        "vocab_size-3": 119,
        "unique-3": 119,
        "entropy-3": 6.894817763307943,
        "cond_entropy-3": -0.025698399669590942,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 16.571428571428573,
        "std_pred_length-nopunct": 5.260557897006277,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.169933257816138,
        "distinct-2-nopunct": 0.9724770642201835,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.706212879802939,
        "cond_entropy-2-nopunct": 0.5567509216240372,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.0295345955293184,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.316449341852083,
        "rouge1": {
            "precision": 0.76993,
            "recall": 0.68347,
            "fmeasure": 0.71911
        },
        "rouge2": {
            "precision": 0.5096,
            "recall": 0.44805,
            "fmeasure": 0.47258
        },
        "rougeL": {
            "precision": 0.67848,
            "recall": 0.61249,
            "fmeasure": 0.63863
        },
        "rougeLsum": {
            "precision": 0.67848,
            "recall": 0.61249,
            "fmeasure": 0.63863
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.8064516129032258,
            "3": 0.6790123456790124
        },
        "bleu": 44.6678,
        "nubia": {
            "semantic_relation": 4.29177,
            "contradiction": 15.30755,
            "irrelevancy": 18.92221,
            "logical_agreement": 65.77024,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.52584,
            "nubia_score": 0.74418
        },
        "meteor": 0.36940506945189555,
        "bleurt": 0.16583,
        "bertscore": {
            "precision": 0.92028,
            "recall": 0.8972,
            "f1": 0.90663
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6085,
        "mean_pred_length": 12.17,
        "std_pred_length": 6.823862542578067,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 41,
        "distinct-1": 0.14987674609695975,
        "vocab_size-1": 912,
        "unique-1": 519,
        "entropy-1": 7.650647082737011,
        "distinct-2": 0.42309758281110116,
        "vocab_size-2": 2363,
        "unique-2": 1609,
        "entropy-2": 10.211173355024028,
        "cond_entropy-2": 2.314742695913944,
        "distinct-3": 0.6047197640117994,
        "vocab_size-3": 3075,
        "unique-3": 2410,
        "entropy-3": 10.94478310166959,
        "cond_entropy-3": 0.7595429828671946,
        "total_length-nopunct": 5357,
        "mean_pred_length-nopunct": 10.714,
        "std_pred_length-nopunct": 6.278551106744294,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.16819115176404703,
        "vocab_size-1-nopunct": 901,
        "unique-1-nopunct": 516,
        "entropy-1-nopunct": 7.817221725059873,
        "distinct-2-nopunct": 0.4333950998558781,
        "vocab_size-2-nopunct": 2105,
        "unique-2-nopunct": 1454,
        "entropy-2-nopunct": 10.030102820848663,
        "cond_entropy-2-nopunct": 2.3496776246426108,
        "distinct-3-nopunct": 0.6196924489327519,
        "vocab_size-3-nopunct": 2700,
        "unique-3-nopunct": 2154,
        "entropy-3-nopunct": 10.759963004805636,
        "cond_entropy-3-nopunct": 0.7678191686061675,
        "msttr-100": 0.66733,
        "msttr-100_nopunct": 0.69472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.063316963587889,
        "rouge1": {
            "precision": 0.58697,
            "recall": 0.55106,
            "fmeasure": 0.55723
        },
        "rouge2": {
            "precision": 0.36514,
            "recall": 0.3401,
            "fmeasure": 0.34472
        },
        "rougeL": {
            "precision": 0.53416,
            "recall": 0.50174,
            "fmeasure": 0.50744
        },
        "rougeLsum": {
            "precision": 0.53416,
            "recall": 0.50174,
            "fmeasure": 0.50744
        },
        "local_recall": {
            "1": 0.5644924880908758
        },
        "bleu": 32.96505,
        "nubia": {
            "semantic_relation": 3.57784,
            "contradiction": 7.5625,
            "irrelevancy": 19.61653,
            "logical_agreement": 72.82097,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.536,
            "nubia_score": 0.63476
        },
        "meteor": 0.31487741556914745,
        "bleurt": -0.05219,
        "bertscore": {
            "precision": 0.87622,
            "recall": 0.86656,
            "f1": 0.87092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.889995180299483,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.9,
            "fmeasure": 0.81818
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.55556,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.9,
            "fmeasure": 0.81818
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.9,
            "fmeasure": 0.81818
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bleu": 32.00286,
        "nubia": {
            "semantic_relation": 4.90594,
            "contradiction": 0.24664,
            "irrelevancy": 0.45083,
            "logical_agreement": 99.30253,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.68576,
            "nubia_score": 0.92562
        },
        "meteor": 0.4448605116078899,
        "bleurt": 0.80859,
        "bertscore": {
            "precision": 0.96881,
            "recall": 0.97291,
            "f1": 0.97086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 42,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.5,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 28,
        "unique-1": 20,
        "entropy-1": 4.6061376606679545,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 34,
        "unique-2": 31,
        "entropy-2": 5.017535737070865,
        "cond_entropy-2": 0.28362752504615163,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 32,
        "unique-3": 30,
        "entropy-3": 4.969815782426809,
        "cond_entropy-3": -0.0794385691884382,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.082207001484488,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.530493056757481,
        "distinct-2-nopunct": 0.90625,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.788909765557392,
        "cond_entropy-2-nopunct": 0.23928554559044066,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629035,
        "cond_entropy-3-nopunct": -0.1360392743452117,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.404507381339073,
        "rouge1": {
            "precision": 0.86771,
            "recall": 0.71949,
            "fmeasure": 0.76943
        },
        "rouge2": {
            "precision": 0.70394,
            "recall": 0.59599,
            "fmeasure": 0.63034
        },
        "rougeL": {
            "precision": 0.86771,
            "recall": 0.71949,
            "fmeasure": 0.76943
        },
        "rougeLsum": {
            "precision": 0.86771,
            "recall": 0.71949,
            "fmeasure": 0.76943
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.7096774193548387
        },
        "bleu": 48.42915,
        "nubia": {
            "semantic_relation": 4.34238,
            "contradiction": 0.47151,
            "irrelevancy": 22.69539,
            "logical_agreement": 76.83309,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.09137,
            "nubia_score": 0.87224
        },
        "meteor": 0.39801827010721214,
        "bleurt": 0.39499,
        "bertscore": {
            "precision": 0.95889,
            "recall": 0.9412,
            "f1": 0.94949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 1.299038105676658,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8305084745762712,
        "vocab_size-1": 49,
        "unique-1": 42,
        "entropy-1": 5.496966990003134,
        "distinct-2": 0.9818181818181818,
        "vocab_size-2": 54,
        "unique-2": 53,
        "entropy-2": 5.744996077161019,
        "cond_entropy-2": 0.13062370965669948,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.06971868527865421,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.118033988749895,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.443856189774727,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.08362548565920487,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0966973253353665,
        "rouge1": {
            "precision": 0.84105,
            "recall": 0.69472,
            "fmeasure": 0.74975
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.56233,
            "fmeasure": 0.58971
        },
        "rougeL": {
            "precision": 0.7456,
            "recall": 0.63659,
            "fmeasure": 0.67762
        },
        "rougeLsum": {
            "precision": 0.7456,
            "recall": 0.63659,
            "fmeasure": 0.67762
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.2,
            "3": 0.6785714285714286
        },
        "bleu": 51.43258,
        "nubia": {
            "semantic_relation": 4.22826,
            "contradiction": 0.83067,
            "irrelevancy": 18.98803,
            "logical_agreement": 80.18131,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.61301,
            "nubia_score": 0.72529
        },
        "meteor": 0.3798119396676874,
        "bleurt": 0.36941,
        "bertscore": {
            "precision": 0.94886,
            "recall": 0.90746,
            "f1": 0.92698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.570714214271425,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 54,
        "unique-1": 46,
        "entropy-1": 5.627579346565628,
        "distinct-2": 0.9516129032258065,
        "vocab_size-2": 59,
        "unique-2": 56,
        "entropy-2": 5.857422116838486,
        "cond_entropy-2": 0.1277017878724048,
        "distinct-3": 0.9827586206896551,
        "vocab_size-3": 57,
        "unique-3": 56,
        "entropy-3": 5.823498236506881,
        "cond_entropy-3": -0.027249798017923592,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8813559322033898,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.632560210342117,
        "distinct-2-nopunct": 0.9454545454545454,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.672268804433747,
        "cond_entropy-2-nopunct": 0.057896436929426864,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.63320965569699,
        "cond_entropy-3-nopunct": -0.03050299900414441,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.632409911948847,
        "rouge1": {
            "precision": 0.86673,
            "recall": 0.84815,
            "fmeasure": 0.85182
        },
        "rouge2": {
            "precision": 0.68624,
            "recall": 0.66279,
            "fmeasure": 0.67105
        },
        "rougeL": {
            "precision": 0.71907,
            "recall": 0.7136,
            "fmeasure": 0.7104
        },
        "rougeLsum": {
            "precision": 0.71907,
            "recall": 0.7136,
            "fmeasure": 0.7104
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.9148936170212766
        },
        "bleu": 55.98745,
        "nubia": {
            "semantic_relation": 4.47243,
            "contradiction": 17.14069,
            "irrelevancy": 20.08013,
            "logical_agreement": 62.77918,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.53484,
            "nubia_score": 0.79518
        },
        "meteor": 0.467349137209568,
        "bleurt": 0.51625,
        "bertscore": {
            "precision": 0.97291,
            "recall": 0.96884,
            "f1": 0.96973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 98,
        "mean_pred_length": 12.25,
        "std_pred_length": 2.331844763272204,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 63,
        "unique-1": 51,
        "entropy-1": 5.622013798042315,
        "distinct-2": 0.8222222222222222,
        "vocab_size-2": 74,
        "unique-2": 66,
        "entropy-2": 6.063749485074322,
        "cond_entropy-2": 0.26330866890517174,
        "distinct-3": 0.8536585365853658,
        "vocab_size-3": 70,
        "unique-3": 64,
        "entropy-3": 6.009633406898807,
        "cond_entropy-3": -0.012349872199395914,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 10.375,
        "std_pred_length-nopunct": 2.2878756522153907,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6987951807228916,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.588482654056035,
        "distinct-2-nopunct": 0.8133333333333334,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.778492857018325,
        "cond_entropy-2-nopunct": 0.2739095925399816,
        "distinct-3-nopunct": 0.8507462686567164,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.711246839550046,
        "cond_entropy-3-nopunct": -0.013475768694824728,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.015012982237271,
        "rouge1": {
            "precision": 0.89947,
            "recall": 0.75534,
            "fmeasure": 0.80638
        },
        "rouge2": {
            "precision": 0.73351,
            "recall": 0.65147,
            "fmeasure": 0.68009
        },
        "rougeL": {
            "precision": 0.86796,
            "recall": 0.74127,
            "fmeasure": 0.78674
        },
        "rougeLsum": {
            "precision": 0.86796,
            "recall": 0.74127,
            "fmeasure": 0.78674
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.6808510638297872
        },
        "bleu": 47.0577,
        "nubia": {
            "semantic_relation": 4.49902,
            "contradiction": 4.61137,
            "irrelevancy": 5.38151,
            "logical_agreement": 90.00712,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.81849,
            "nubia_score": 0.83011
        },
        "meteor": 0.40212193646191097,
        "bleurt": 0.63501,
        "bertscore": {
            "precision": 0.9727,
            "recall": 0.92965,
            "f1": 0.94951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 110,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.960744879438715,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 80,
        "unique-1": 63,
        "entropy-1": 6.0802741182631745,
        "distinct-2": 0.9019607843137255,
        "vocab_size-2": 92,
        "unique-2": 83,
        "entropy-2": 6.468946052734603,
        "cond_entropy-2": 0.2083649223350742,
        "distinct-3": 0.9468085106382979,
        "vocab_size-3": 89,
        "unique-3": 84,
        "entropy-3": 6.44820587295422,
        "cond_entropy-3": -0.003422793462331799,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.640054944640259,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.07330192281737,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.269035169749084,
        "cond_entropy-2-nopunct": 0.21952057219568966,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.221928094887357,
        "cond_entropy-3-nopunct": -0.028067429972891664,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.236261504334328,
        "rouge1": {
            "precision": 0.81441,
            "recall": 0.76453,
            "fmeasure": 0.77917
        },
        "rouge2": {
            "precision": 0.53055,
            "recall": 0.48562,
            "fmeasure": 0.49889
        },
        "rougeL": {
            "precision": 0.7168,
            "recall": 0.67269,
            "fmeasure": 0.68581
        },
        "rougeLsum": {
            "precision": 0.7168,
            "recall": 0.67269,
            "fmeasure": 0.68581
        },
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.7666666666666667,
            "3": 0.8333333333333334
        },
        "bleu": 48.36963,
        "nubia": {
            "semantic_relation": 4.30877,
            "contradiction": 12.08551,
            "irrelevancy": 11.96274,
            "logical_agreement": 75.95175,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.18437,
            "nubia_score": 0.75333
        },
        "meteor": 0.41919904561809185,
        "bleurt": 0.33745,
        "bertscore": {
            "precision": 0.94168,
            "recall": 0.93482,
            "f1": 0.93643
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 90,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.6555555555555556,
        "vocab_size-1": 59,
        "unique-1": 47,
        "entropy-1": 5.524791291444586,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 76,
        "unique-2": 69,
        "entropy-2": 6.192854476324433,
        "cond_entropy-2": 0.5524988494629782,
        "distinct-3": 0.9358974358974359,
        "vocab_size-3": 73,
        "unique-3": 68,
        "entropy-3": 6.157197090657128,
        "cond_entropy-3": -0.020314082093903313,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7125,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.527855751945728,
        "distinct-2-nopunct": 0.8918918918918919,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.98303596695107,
        "cond_entropy-2-nopunct": 0.5195644590276278,
        "distinct-3-nopunct": 0.9264705882352942,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.940404017720933,
        "cond_entropy-3-nopunct": -0.0226539434644416,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.74431005402227,
        "rouge1": {
            "precision": 0.75454,
            "recall": 0.68578,
            "fmeasure": 0.70586
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.41092,
            "fmeasure": 0.41917
        },
        "rougeL": {
            "precision": 0.64513,
            "recall": 0.59038,
            "fmeasure": 0.60528
        },
        "rougeLsum": {
            "precision": 0.64513,
            "recall": 0.59038,
            "fmeasure": 0.60528
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "bleu": 38.36357,
        "nubia": {
            "semantic_relation": 4.31291,
            "contradiction": 6.16428,
            "irrelevancy": 18.24939,
            "logical_agreement": 75.58633,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.0955,
            "nubia_score": 0.7612
        },
        "meteor": 0.33975014067405135,
        "bleurt": 0.30119,
        "bertscore": {
            "precision": 0.93876,
            "recall": 0.90497,
            "f1": 0.92062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 107,
        "mean_pred_length": 13.375,
        "std_pred_length": 1.996089927833914,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7289719626168224,
        "vocab_size-1": 78,
        "unique-1": 70,
        "entropy-1": 5.887802790829979,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 96,
        "unique-2": 93,
        "entropy-2": 6.56875055947356,
        "cond_entropy-2": 0.4937751782701367,
        "distinct-3": 0.978021978021978,
        "vocab_size-3": 89,
        "unique-3": 87,
        "entropy-3": 6.463838596242658,
        "cond_entropy-3": -0.09958395790289133,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 11.125,
        "std_pred_length-nopunct": 1.7633419974582356,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8314606741573034,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.990775459520003,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.26577592881054,
        "cond_entropy-2-nopunct": 0.31055187387785854,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.135030038332083,
        "cond_entropy-3-nopunct": -0.1363268138676211,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.056359101036312,
        "rouge1": {
            "precision": 0.81228,
            "recall": 0.66714,
            "fmeasure": 0.72282
        },
        "rouge2": {
            "precision": 0.5316,
            "recall": 0.43791,
            "fmeasure": 0.47165
        },
        "rougeL": {
            "precision": 0.66273,
            "recall": 0.56264,
            "fmeasure": 0.59959
        },
        "rougeLsum": {
            "precision": 0.66273,
            "recall": 0.56264,
            "fmeasure": 0.59959
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5333333333333333,
            "3": 0.7123287671232876
        },
        "bleu": 39.59452,
        "nubia": {
            "semantic_relation": 4.01219,
            "contradiction": 24.4945,
            "irrelevancy": 18.29496,
            "logical_agreement": 57.21054,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.94738,
            "nubia_score": 0.64052
        },
        "meteor": 0.36658344434704754,
        "bleurt": 0.24286,
        "bertscore": {
            "precision": 0.92947,
            "recall": 0.91385,
            "f1": 0.91899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 20,
        "total_length": 323,
        "mean_pred_length": 16.15,
        "std_pred_length": 5.9268457040824,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5479876160990712,
        "vocab_size-1": 177,
        "unique-1": 130,
        "entropy-1": 6.8120055670448085,
        "distinct-2": 0.8679867986798679,
        "vocab_size-2": 263,
        "unique-2": 231,
        "entropy-2": 7.957598653397102,
        "cond_entropy-2": 0.9517946156600274,
        "distinct-3": 0.9469964664310954,
        "vocab_size-3": 268,
        "unique-3": 254,
        "entropy-3": 8.035983728689938,
        "cond_entropy-3": 0.08443280179998248,
        "total_length-nopunct": 287,
        "mean_pred_length-nopunct": 14.35,
        "std_pred_length-nopunct": 5.552251795442999,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6062717770034843,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.959889245613595,
        "distinct-2-nopunct": 0.8689138576779026,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.774069246245644,
        "cond_entropy-2-nopunct": 0.8544815123112991,
        "distinct-3-nopunct": 0.951417004048583,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.848145014976758,
        "cond_entropy-3-nopunct": 0.07230495378123339,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.62154404741638,
        "rouge1": {
            "precision": 0.82295,
            "recall": 0.80783,
            "fmeasure": 0.80727
        },
        "rouge2": {
            "precision": 0.64128,
            "recall": 0.63204,
            "fmeasure": 0.62872
        },
        "rougeL": {
            "precision": 0.7239,
            "recall": 0.71568,
            "fmeasure": 0.7121
        },
        "rougeLsum": {
            "precision": 0.7239,
            "recall": 0.71568,
            "fmeasure": 0.7121
        },
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.5846153846153846,
            "3": 0.8421052631578947
        },
        "bleu": 54.33912,
        "nubia": {
            "semantic_relation": 4.34647,
            "contradiction": 12.1769,
            "irrelevancy": 16.38085,
            "logical_agreement": 71.44225,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.40686,
            "nubia_score": 0.77346
        },
        "meteor": 0.43076126936239206,
        "bleurt": 0.422,
        "bertscore": {
            "precision": 0.94928,
            "recall": 0.93768,
            "f1": 0.94203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 4.549052379454474,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.68,
        "vocab_size-1": 85,
        "unique-1": 70,
        "entropy-1": 6.00846626128011,
        "distinct-2": 0.9322033898305084,
        "vocab_size-2": 110,
        "unique-2": 102,
        "entropy-2": 6.747049829022849,
        "cond_entropy-2": 0.6288356161264043,
        "distinct-3": 0.954954954954955,
        "vocab_size-3": 106,
        "unique-3": 101,
        "entropy-3": 6.70432577626003,
        "cond_entropy-3": -0.034173128957681244,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 16.428571428571427,
        "std_pred_length-nopunct": 4.865538961693257,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7130434782608696,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 5.9932007599153,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.60673935401531,
        "cond_entropy-2-nopunct": 0.6595203074074708,
        "distinct-3-nopunct": 0.9504950495049505,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.55920158176168,
        "cond_entropy-3-nopunct": -0.03727007881761442,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.188452458509143,
        "rouge1": {
            "precision": 0.76109,
            "recall": 0.72699,
            "fmeasure": 0.74147
        },
        "rouge2": {
            "precision": 0.53842,
            "recall": 0.5365,
            "fmeasure": 0.53476
        },
        "rougeL": {
            "precision": 0.6659,
            "recall": 0.67219,
            "fmeasure": 0.66462
        },
        "rougeLsum": {
            "precision": 0.6659,
            "recall": 0.67219,
            "fmeasure": 0.66462
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.42857142857142855,
            "3": 0.7666666666666667
        },
        "bleu": 42.23589,
        "nubia": {
            "semantic_relation": 3.99697,
            "contradiction": 25.12412,
            "irrelevancy": 33.7151,
            "logical_agreement": 41.16078,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.84847,
            "nubia_score": 0.65359
        },
        "meteor": 0.38307028072872706,
        "bleurt": 0.14739,
        "bertscore": {
            "precision": 0.92615,
            "recall": 0.92017,
            "f1": 0.92152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 12,
        "total_length": 192,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.011894655987543,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5989583333333334,
        "vocab_size-1": 115,
        "unique-1": 88,
        "entropy-1": 6.314547936599923,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 170,
        "unique-2": 160,
        "entropy-2": 7.38074198521855,
        "cond_entropy-2": 0.9118908528453259,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 165,
        "unique-3": 162,
        "entropy-3": 7.356603137064505,
        "cond_entropy-3": -0.01620234021758107,
        "total_length-nopunct": 169,
        "mean_pred_length-nopunct": 14.083333333333334,
        "std_pred_length-nopunct": 5.97854961972848,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6627218934911243,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.40868555844933,
        "distinct-2-nopunct": 0.9490445859872612,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.192709920866145,
        "cond_entropy-2-nopunct": 0.847121983652445,
        "distinct-3-nopunct": 0.9793103448275862,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.138529779670129,
        "cond_entropy-3-nopunct": -0.05264269335945105,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.789336217030917,
        "rouge1": {
            "precision": 0.68953,
            "recall": 0.63845,
            "fmeasure": 0.64042
        },
        "rouge2": {
            "precision": 0.49741,
            "recall": 0.46079,
            "fmeasure": 0.46156
        },
        "rougeL": {
            "precision": 0.62092,
            "recall": 0.57569,
            "fmeasure": 0.57701
        },
        "rougeLsum": {
            "precision": 0.62092,
            "recall": 0.57569,
            "fmeasure": 0.57701
        },
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.2903225806451613,
            "3": 0.648854961832061
        },
        "bleu": 38.21901,
        "nubia": {
            "semantic_relation": 3.69088,
            "contradiction": 18.92619,
            "irrelevancy": 44.13326,
            "logical_agreement": 36.94055,
            "grammar_ref": 4.5489,
            "grammar_hyp": 5.02281,
            "nubia_score": 0.53125
        },
        "meteor": 0.33725010733258537,
        "bleurt": 0.01682,
        "bertscore": {
            "precision": 0.91515,
            "recall": 0.90227,
            "f1": 0.90733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 143,
        "mean_pred_length": 14.3,
        "std_pred_length": 4.920365840057018,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.6713286713286714,
        "vocab_size-1": 96,
        "unique-1": 79,
        "entropy-1": 6.181343956154349,
        "distinct-2": 0.9624060150375939,
        "vocab_size-2": 128,
        "unique-2": 123,
        "entropy-2": 6.980094465576387,
        "cond_entropy-2": 0.6225549669962209,
        "distinct-3": 0.991869918699187,
        "vocab_size-3": 122,
        "unique-3": 121,
        "entropy-3": 6.926254342737602,
        "cond_entropy-3": -0.04772727975544598,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 12.3,
        "std_pred_length-nopunct": 4.337049688440288,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7398373983739838,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.234720602689137,
        "distinct-2-nopunct": 0.9557522123893806,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.731683387193967,
        "cond_entropy-2-nopunct": 0.54190029801366,
        "distinct-3-nopunct": 0.9902912621359223,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 101,
        "entropy-3-nopunct": 6.667083051455081,
        "cond_entropy-3-nopunct": -0.05600853231934787,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.309650741001166,
        "rouge1": {
            "precision": 0.7855,
            "recall": 0.67864,
            "fmeasure": 0.70972
        },
        "rouge2": {
            "precision": 0.55931,
            "recall": 0.47093,
            "fmeasure": 0.49726
        },
        "rougeL": {
            "precision": 0.73928,
            "recall": 0.62953,
            "fmeasure": 0.66339
        },
        "rougeLsum": {
            "precision": 0.73928,
            "recall": 0.62953,
            "fmeasure": 0.66339
        },
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.3225806451612903,
            "3": 0.7653061224489796
        },
        "bleu": 44.31697,
        "nubia": {
            "semantic_relation": 4.10943,
            "contradiction": 1.06418,
            "irrelevancy": 37.45502,
            "logical_agreement": 61.4808,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.76702,
            "nubia_score": 0.6991
        },
        "meteor": 0.3739631669624205,
        "bleurt": 0.17326,
        "bertscore": {
            "precision": 0.92469,
            "recall": 0.89588,
            "f1": 0.9062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 13,
        "total_length": 236,
        "mean_pred_length": 18.153846153846153,
        "std_pred_length": 6.825812477378159,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 33,
        "distinct-1": 0.5635593220338984,
        "vocab_size-1": 133,
        "unique-1": 98,
        "entropy-1": 6.492654843971334,
        "distinct-2": 0.8609865470852018,
        "vocab_size-2": 192,
        "unique-2": 167,
        "entropy-2": 7.491395191361326,
        "cond_entropy-2": 0.8640503488888142,
        "distinct-3": 0.9380952380952381,
        "vocab_size-3": 197,
        "unique-3": 184,
        "entropy-3": 7.590435993856587,
        "cond_entropy-3": 0.0991529987394083,
        "total_length-nopunct": 211,
        "mean_pred_length-nopunct": 16.23076923076923,
        "std_pred_length-nopunct": 6.314255497301887,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6113744075829384,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.551846965070001,
        "distinct-2-nopunct": 0.8686868686868687,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 152,
        "entropy-2-nopunct": 7.331278084682354,
        "cond_entropy-2-nopunct": 0.8069330964059166,
        "distinct-3-nopunct": 0.9405405405405406,
        "vocab_size-3-nopunct": 174,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.412462541597382,
        "cond_entropy-3-nopunct": 0.07418497561081885,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.695,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.781454785246586,
        "rouge1": {
            "precision": 0.66415,
            "recall": 0.66454,
            "fmeasure": 0.65437
        },
        "rouge2": {
            "precision": 0.35568,
            "recall": 0.37363,
            "fmeasure": 0.35965
        },
        "rougeL": {
            "precision": 0.53297,
            "recall": 0.55756,
            "fmeasure": 0.53725
        },
        "rougeLsum": {
            "precision": 0.53297,
            "recall": 0.55756,
            "fmeasure": 0.53725
        },
        "local_recall": {
            "1": 0.11267605633802817,
            "2": 0.4716981132075472,
            "3": 0.7301587301587301
        },
        "bleu": 30.50847,
        "nubia": {
            "semantic_relation": 3.89679,
            "contradiction": 21.88492,
            "irrelevancy": 47.07274,
            "logical_agreement": 31.04234,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.20005,
            "nubia_score": 0.65776
        },
        "meteor": 0.3309137250012329,
        "bleurt": 0.04176,
        "bertscore": {
            "precision": 0.89938,
            "recall": 0.89806,
            "f1": 0.89734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6519242772822396,
        "rouge1": {
            "precision": 0.72917,
            "recall": 0.56328,
            "fmeasure": 0.6316
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.40741,
            "fmeasure": 0.45887
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.45802,
            "fmeasure": 0.51732
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.45802,
            "fmeasure": 0.51732
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bleu": 38.84756,
        "nubia": {
            "semantic_relation": 3.27267,
            "contradiction": 99.35621,
            "irrelevancy": 0.55865,
            "logical_agreement": 0.08514,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.85195,
            "nubia_score": 0.26333
        },
        "meteor": 0.37132889310596084,
        "bleurt": -0.32038,
        "bertscore": {
            "precision": 0.95,
            "recall": 0.93333,
            "f1": 0.94159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 4.673328578219168,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7397260273972602,
        "vocab_size-1": 54,
        "unique-1": 44,
        "entropy-1": 5.532644169139788,
        "distinct-2": 0.9852941176470589,
        "vocab_size-2": 67,
        "unique-2": 66,
        "entropy-2": 6.058051076544463,
        "cond_entropy-2": 0.40299898790856187,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.07843688600439111,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 4.308131845707604,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.55680425036562,
        "distinct-2-nopunct": 0.9830508474576272,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.848744744277091,
        "cond_entropy-2-nopunct": 0.3294994557448968,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.09071851016133553,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.9511342085131735,
        "rouge1": {
            "precision": 0.8672,
            "recall": 0.72455,
            "fmeasure": 0.78596
        },
        "rouge2": {
            "precision": 0.7115,
            "recall": 0.58238,
            "fmeasure": 0.63731
        },
        "rougeL": {
            "precision": 0.74921,
            "recall": 0.62096,
            "fmeasure": 0.67605
        },
        "rougeLsum": {
            "precision": 0.74921,
            "recall": 0.62096,
            "fmeasure": 0.67605
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.2,
            "3": 0.8035714285714286
        },
        "bleu": 46.28385,
        "nubia": {
            "semantic_relation": 4.46371,
            "contradiction": 6.98467,
            "irrelevancy": 22.21092,
            "logical_agreement": 70.80441,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.82687,
            "nubia_score": 0.78715
        },
        "meteor": 0.4288437523299254,
        "bleurt": 0.36232,
        "bertscore": {
            "precision": 0.94932,
            "recall": 0.9279,
            "f1": 0.93834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 68,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.301162633521313,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6617647058823529,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.216591062590435,
        "distinct-2": 0.859375,
        "vocab_size-2": 55,
        "unique-2": 47,
        "entropy-2": 5.706954882778696,
        "cond_entropy-2": 0.41979330635450696,
        "distinct-3": 0.9,
        "vocab_size-3": 54,
        "unique-3": 48,
        "entropy-3": 5.706890595608518,
        "cond_entropy-3": -0.013861279355423604,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.301162633521313,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.1996987351738495,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.627642470572459,
        "cond_entropy-2-nopunct": 0.4479638197203544,
        "distinct-3-nopunct": 0.8928571428571429,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.593069207771893,
        "cond_entropy-3-nopunct": -0.01462696815513816,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.78801503344029,
        "rouge1": {
            "precision": 0.7176,
            "recall": 0.7568,
            "fmeasure": 0.72287
        },
        "rouge2": {
            "precision": 0.49666,
            "recall": 0.51442,
            "fmeasure": 0.49763
        },
        "rougeL": {
            "precision": 0.59358,
            "recall": 0.65476,
            "fmeasure": 0.61063
        },
        "rougeLsum": {
            "precision": 0.59358,
            "recall": 0.65476,
            "fmeasure": 0.61063
        },
        "local_recall": {
            "1": 0.43333333333333335,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "bleu": 36.76131,
        "nubia": {
            "semantic_relation": 4.10952,
            "contradiction": 9.96355,
            "irrelevancy": 44.05256,
            "logical_agreement": 45.98389,
            "grammar_ref": 4.84918,
            "grammar_hyp": 4.75668,
            "nubia_score": 0.67992
        },
        "meteor": 0.36696067839083135,
        "bleurt": 0.13555,
        "bertscore": {
            "precision": 0.93957,
            "recall": 0.93237,
            "f1": 0.93497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 142,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.043560250458004,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.6971830985915493,
        "vocab_size-1": 99,
        "unique-1": 84,
        "entropy-1": 6.298381957606226,
        "distinct-2": 0.9552238805970149,
        "vocab_size-2": 128,
        "unique-2": 124,
        "entropy-2": 6.9616115785174815,
        "cond_entropy-2": 0.5349529141589191,
        "distinct-3": 1.0,
        "vocab_size-3": 126,
        "unique-3": 126,
        "entropy-3": 6.977279923499926,
        "cond_entropy-3": 0.006428828280239284,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 14.875,
        "std_pred_length-nopunct": 3.370367190678191,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7815126050420168,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.312597490071437,
        "distinct-2-nopunct": 0.954954954954955,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.686307758242012,
        "cond_entropy-2-nopunct": 0.4156720896650846,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.686500527183236,
        "cond_entropy-3-nopunct": 0.00858951520204451,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.532895880054656,
        "rouge1": {
            "precision": 0.85582,
            "recall": 0.84907,
            "fmeasure": 0.84968
        },
        "rouge2": {
            "precision": 0.67891,
            "recall": 0.67136,
            "fmeasure": 0.67325
        },
        "rougeL": {
            "precision": 0.71235,
            "recall": 0.70541,
            "fmeasure": 0.70685
        },
        "rougeLsum": {
            "precision": 0.71235,
            "recall": 0.70541,
            "fmeasure": 0.70685
        },
        "local_recall": {
            "1": 0.038461538461538464,
            "2": 0.5,
            "3": 0.875
        },
        "bleu": 51.48305,
        "nubia": {
            "semantic_relation": 4.27551,
            "contradiction": 9.33926,
            "irrelevancy": 17.59048,
            "logical_agreement": 73.07026,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.04804,
            "nubia_score": 0.73144
        },
        "meteor": 0.45186279554068337,
        "bleurt": 0.36636,
        "bertscore": {
            "precision": 0.94312,
            "recall": 0.95557,
            "f1": 0.94878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1986532337201607,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0,
        "bleurt": 0.99035,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 13,
        "total_length": 198,
        "mean_pred_length": 15.23076923076923,
        "std_pred_length": 4.263509680169544,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5858585858585859,
        "vocab_size-1": 116,
        "unique-1": 89,
        "entropy-1": 6.293158636540649,
        "distinct-2": 0.918918918918919,
        "vocab_size-2": 170,
        "unique-2": 161,
        "entropy-2": 7.3237794499402655,
        "cond_entropy-2": 0.8569719474496589,
        "distinct-3": 0.9825581395348837,
        "vocab_size-3": 169,
        "unique-3": 166,
        "entropy-3": 7.391381033771833,
        "cond_entropy-3": 0.08329243346815073,
        "total_length-nopunct": 170,
        "mean_pred_length-nopunct": 13.076923076923077,
        "std_pred_length-nopunct": 3.6260073075054384,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6647058823529411,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.44963496263138,
        "distinct-2-nopunct": 0.9171974522292994,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.07547188292623,
        "cond_entropy-2-nopunct": 0.6861988798845282,
        "distinct-3-nopunct": 0.9861111111111112,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.142147223664554,
        "cond_entropy-3-nopunct": 0.07951516891573218,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.717668673014973,
        "rouge1": {
            "precision": 0.76931,
            "recall": 0.75067,
            "fmeasure": 0.75727
        },
        "rouge2": {
            "precision": 0.56968,
            "recall": 0.56309,
            "fmeasure": 0.56457
        },
        "rougeL": {
            "precision": 0.64087,
            "recall": 0.6254,
            "fmeasure": 0.63143
        },
        "rougeLsum": {
            "precision": 0.64087,
            "recall": 0.6254,
            "fmeasure": 0.63143
        },
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.11764705882352941,
            "3": 0.8235294117647058
        },
        "bleu": 48.94059,
        "nubia": {
            "semantic_relation": 4.36123,
            "contradiction": 0.95314,
            "irrelevancy": 21.5123,
            "logical_agreement": 77.53456,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.60571,
            "nubia_score": 0.8088
        },
        "meteor": 0.4222746530957899,
        "bleurt": 0.48983,
        "bertscore": {
            "precision": 0.93801,
            "recall": 0.93227,
            "f1": 0.93469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.321268397245732,
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.49559,
            "fmeasure": 0.58692
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.18773,
            "fmeasure": 0.23449
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.30864,
            "fmeasure": 0.35167
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.30864,
            "fmeasure": 0.35167
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6111111111111112
        },
        "bleu": 20.73172,
        "nubia": {
            "semantic_relation": 3.05393,
            "contradiction": 0.09356,
            "irrelevancy": 99.76951,
            "logical_agreement": 0.13694,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.54219,
            "nubia_score": 0.40852
        },
        "meteor": 0.23699358232435813,
        "bleurt": -0.20075,
        "bertscore": {
            "precision": 0.87388,
            "recall": 0.84405,
            "f1": 0.85871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 9,
        "total_length": 152,
        "mean_pred_length": 16.88888888888889,
        "std_pred_length": 6.384781288248286,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.6644736842105263,
        "vocab_size-1": 101,
        "unique-1": 83,
        "entropy-1": 6.255544685209001,
        "distinct-2": 0.9300699300699301,
        "vocab_size-2": 133,
        "unique-2": 123,
        "entropy-2": 7.020011196918256,
        "cond_entropy-2": 0.6274184029059544,
        "distinct-3": 0.9552238805970149,
        "vocab_size-3": 128,
        "unique-3": 122,
        "entropy-3": 6.976536951651809,
        "cond_entropy-3": -0.034080653783303605,
        "total_length-nopunct": 138,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 5.944184833375669,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.717391304347826,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.3063271784865895,
        "distinct-2-nopunct": 0.9302325581395349,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.87169237170231,
        "cond_entropy-2-nopunct": 0.6213324451895628,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.806890595608532,
        "cond_entropy-3-nopunct": -0.05433665981473537,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.76787288843759,
        "rouge1": {
            "precision": 0.60156,
            "recall": 0.60395,
            "fmeasure": 0.59436
        },
        "rouge2": {
            "precision": 0.35554,
            "recall": 0.38337,
            "fmeasure": 0.36446
        },
        "rougeL": {
            "precision": 0.55703,
            "recall": 0.57973,
            "fmeasure": 0.56219
        },
        "rougeLsum": {
            "precision": 0.55703,
            "recall": 0.57973,
            "fmeasure": 0.56219
        },
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.2857142857142857,
            "3": 0.7746478873239436
        },
        "bleu": 33.83731,
        "nubia": {
            "semantic_relation": 3.70038,
            "contradiction": 2.43278,
            "irrelevancy": 44.57187,
            "logical_agreement": 52.99536,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.66336,
            "nubia_score": 0.61277
        },
        "meteor": 0.33693778478937986,
        "bleurt": 0.02777,
        "bertscore": {
            "precision": 0.89397,
            "recall": 0.88901,
            "f1": 0.88925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.0,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.675,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 4.53418371977919,
        "distinct-2": 0.868421052631579,
        "vocab_size-2": 33,
        "unique-2": 28,
        "entropy-2": 4.984769618706745,
        "cond_entropy-2": 0.4394145502490374,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 33,
        "unique-3": 30,
        "entropy-3": 5.003258334775643,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.4713544870139295,
        "distinct-2-nopunct": 0.8611111111111112,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.892147223664533,
        "cond_entropy-2-nopunct": 0.46393568256336404,
        "distinct-3-nopunct": 0.9117647058823529,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.910992253015044,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.055481837970348,
        "rouge1": {
            "precision": 0.80437,
            "recall": 0.96209,
            "fmeasure": 0.8674
        },
        "rouge2": {
            "precision": 0.69224,
            "recall": 0.80626,
            "fmeasure": 0.7373
        },
        "rougeL": {
            "precision": 0.80437,
            "recall": 0.96209,
            "fmeasure": 0.8674
        },
        "rougeLsum": {
            "precision": 0.80437,
            "recall": 0.96209,
            "fmeasure": 0.8674
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bleu": 59.17895,
        "nubia": {
            "semantic_relation": 4.89617,
            "contradiction": 0.32839,
            "irrelevancy": 35.33024,
            "logical_agreement": 64.34136,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.35947,
            "nubia_score": 0.83607
        },
        "meteor": 0.5744150524777378,
        "bleurt": 0.72629,
        "bertscore": {
            "precision": 0.95808,
            "recall": 0.98604,
            "f1": 0.97164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.7711426205984715,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.18612739319226906,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.556088322639177,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.22116159970861757,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0654330407821195,
        "rouge1": {
            "precision": 0.64566,
            "recall": 0.82917,
            "fmeasure": 0.71764
        },
        "rouge2": {
            "precision": 0.34215,
            "recall": 0.41601,
            "fmeasure": 0.36639
        },
        "rougeL": {
            "precision": 0.42717,
            "recall": 0.54907,
            "fmeasure": 0.47495
        },
        "rougeLsum": {
            "precision": 0.42717,
            "recall": 0.54907,
            "fmeasure": 0.47495
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.4,
            "3": 0.7368421052631579
        },
        "bleu": 30.086,
        "nubia": {
            "semantic_relation": 3.91243,
            "contradiction": 32.51493,
            "irrelevancy": 36.1492,
            "logical_agreement": 31.33587,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.40238,
            "nubia_score": 0.63242
        },
        "meteor": 0.38746722254081567,
        "bleurt": 0.06719,
        "bertscore": {
            "precision": 0.89045,
            "recall": 0.92525,
            "f1": 0.90649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 5.2493385826745405,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.68,
        "vocab_size-1": 34,
        "unique-1": 24,
        "entropy-1": 4.886370130156179,
        "distinct-2": 0.7872340425531915,
        "vocab_size-2": 37,
        "unique-2": 27,
        "entropy-2": 5.129056936784017,
        "cond_entropy-2": 0.18986916145107763,
        "distinct-3": 0.7954545454545454,
        "vocab_size-3": 35,
        "unique-3": 26,
        "entropy-3": 5.050340709546388,
        "cond_entropy-3": -0.09515723304034028,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.706717630483576,
        "distinct-2-nopunct": 0.7804878048780488,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.918527614374182,
        "cond_entropy-2-nopunct": 0.21810612936526794,
        "distinct-3-nopunct": 0.7894736842105263,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.826874881864638,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.244378659238237,
        "rouge1": {
            "precision": 0.78543,
            "recall": 0.89646,
            "fmeasure": 0.83116
        },
        "rouge2": {
            "precision": 0.66532,
            "recall": 0.75932,
            "fmeasure": 0.70341
        },
        "rougeL": {
            "precision": 0.77749,
            "recall": 0.8872,
            "fmeasure": 0.82262
        },
        "rougeLsum": {
            "precision": 0.77749,
            "recall": 0.8872,
            "fmeasure": 0.82262
        },
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.2,
            "3": 0.9310344827586207
        },
        "bleu": 61.84033,
        "nubia": {
            "semantic_relation": 4.37328,
            "contradiction": 0.28167,
            "irrelevancy": 52.96156,
            "logical_agreement": 46.75677,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.53215,
            "nubia_score": 0.76719
        },
        "meteor": 0.541748785489022,
        "bleurt": 0.38911,
        "bertscore": {
            "precision": 0.95599,
            "recall": 0.98122,
            "f1": 0.96809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 77,
        "mean_pred_length": 19.25,
        "std_pred_length": 5.356071321407137,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.7012987012987013,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.52627290421888,
        "distinct-2": 1.0,
        "vocab_size-2": 73,
        "unique-2": 73,
        "entropy-2": 6.189824558880028,
        "cond_entropy-2": 0.5945387032351698,
        "distinct-3": 1.0,
        "vocab_size-3": 69,
        "unique-3": 69,
        "entropy-3": 6.108524456778164,
        "cond_entropy-3": -0.08130010210184817,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.380353866983808,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8032786885245902,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.446970534213261,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.832890014164737,
        "cond_entropy-2-nopunct": 0.41986802755495967,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.727920454563195,
        "cond_entropy-3-nopunct": -0.10496955960154235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.328342792551433,
        "rouge1": {
            "precision": 0.7463,
            "recall": 0.79672,
            "fmeasure": 0.76196
        },
        "rouge2": {
            "precision": 0.52835,
            "recall": 0.54816,
            "fmeasure": 0.53256
        },
        "rougeL": {
            "precision": 0.66971,
            "recall": 0.69897,
            "fmeasure": 0.67638
        },
        "rougeLsum": {
            "precision": 0.66971,
            "recall": 0.69897,
            "fmeasure": 0.67638
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5333333333333333,
            "3": 0.8205128205128205
        },
        "bleu": 54.82212,
        "nubia": {
            "semantic_relation": 4.11069,
            "contradiction": 0.8748,
            "irrelevancy": 50.88363,
            "logical_agreement": 48.24157,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.40087,
            "nubia_score": 0.73203
        },
        "meteor": 0.4481037624589032,
        "bleurt": 0.21964,
        "bertscore": {
            "precision": 0.9381,
            "recall": 0.94837,
            "f1": 0.93779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 9,
        "total_length": 128,
        "mean_pred_length": 14.222222222222221,
        "std_pred_length": 4.236816881097249,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.6875,
        "vocab_size-1": 88,
        "unique-1": 74,
        "entropy-1": 6.059548465273867,
        "distinct-2": 0.9495798319327731,
        "vocab_size-2": 113,
        "unique-2": 109,
        "entropy-2": 6.777170704484413,
        "cond_entropy-2": 0.5490065988706678,
        "distinct-3": 0.990909090909091,
        "vocab_size-3": 109,
        "unique-3": 108,
        "entropy-3": 6.76317789534285,
        "cond_entropy-3": -0.0043671406923747646,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 12.777777777777779,
        "std_pred_length-nopunct": 3.8232556742411674,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7304347826086957,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.0641989950142605,
        "distinct-2-nopunct": 0.9433962264150944,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.595844982865072,
        "cond_entropy-2-nopunct": 0.5885480586373559,
        "distinct-3-nopunct": 0.9896907216494846,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.57929428548611,
        "cond_entropy-3-nopunct": -0.004296272169886126,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.152452010816974,
        "rouge1": {
            "precision": 0.69491,
            "recall": 0.69592,
            "fmeasure": 0.67508
        },
        "rouge2": {
            "precision": 0.44844,
            "recall": 0.49583,
            "fmeasure": 0.46135
        },
        "rougeL": {
            "precision": 0.64478,
            "recall": 0.66152,
            "fmeasure": 0.63533
        },
        "rougeLsum": {
            "precision": 0.64478,
            "recall": 0.66152,
            "fmeasure": 0.63533
        },
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.25,
            "3": 0.7532467532467533
        },
        "bleu": 31.8589,
        "nubia": {
            "semantic_relation": 3.787,
            "contradiction": 30.50573,
            "irrelevancy": 12.94227,
            "logical_agreement": 56.552,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.94545,
            "nubia_score": 0.6045
        },
        "meteor": 0.3232322491218063,
        "bleurt": 0.31615,
        "bertscore": {
            "precision": 0.91249,
            "recall": 0.90587,
            "f1": 0.90765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 3.9191038516477206,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.689922480620155,
        "vocab_size-1": 89,
        "unique-1": 69,
        "entropy-1": 6.194296418328252,
        "distinct-2": 0.9173553719008265,
        "vocab_size-2": 111,
        "unique-2": 101,
        "entropy-2": 6.753573981076255,
        "cond_entropy-2": 0.41494241148154076,
        "distinct-3": 0.9469026548672567,
        "vocab_size-3": 107,
        "unique-3": 101,
        "entropy-3": 6.713984272149718,
        "cond_entropy-3": -0.027887814682415506,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7288135593220338,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.2098966257579855,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.599541531706484,
        "cond_entropy-2-nopunct": 0.42948100948331025,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 90,
        "entropy-3-nopunct": 6.554778283147971,
        "cond_entropy-3-nopunct": -0.04030692057277186,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.095128051523094,
        "rouge1": {
            "precision": 0.7553,
            "recall": 0.66976,
            "fmeasure": 0.69612
        },
        "rouge2": {
            "precision": 0.51395,
            "recall": 0.45559,
            "fmeasure": 0.47461
        },
        "rougeL": {
            "precision": 0.61035,
            "recall": 0.53141,
            "fmeasure": 0.55813
        },
        "rougeLsum": {
            "precision": 0.61035,
            "recall": 0.53141,
            "fmeasure": 0.55813
        },
        "local_recall": {
            "1": 0.08695652173913043,
            "2": 0.34615384615384615,
            "3": 0.7115384615384616
        },
        "bleu": 35.25555,
        "nubia": {
            "semantic_relation": 3.95448,
            "contradiction": 9.95064,
            "irrelevancy": 20.962,
            "logical_agreement": 69.08736,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.73476,
            "nubia_score": 0.63594
        },
        "meteor": 0.3275496972100252,
        "bleurt": 0.20875,
        "bertscore": {
            "precision": 0.92467,
            "recall": 0.90827,
            "f1": 0.91518
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 9.104333522498443,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.8,
        "vocab_size-1": 44,
        "unique-1": 38,
        "entropy-1": 5.2882794320925886,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.3491670810895153,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.08572987402588379,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 8.640987597877148,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.233905185567572,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.37846482492883327,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.09310940439148176,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5522575003353034,
        "rouge1": {
            "precision": 0.76163,
            "recall": 0.73741,
            "fmeasure": 0.73378
        },
        "rouge2": {
            "precision": 0.55199,
            "recall": 0.52406,
            "fmeasure": 0.51958
        },
        "rougeL": {
            "precision": 0.68756,
            "recall": 0.64834,
            "fmeasure": 0.65261
        },
        "rougeLsum": {
            "precision": 0.68756,
            "recall": 0.64834,
            "fmeasure": 0.65261
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4,
            "3": 0.7714285714285715
        },
        "bleu": 33.38387,
        "nubia": {
            "semantic_relation": 4.14502,
            "contradiction": 1.07703,
            "irrelevancy": 17.39476,
            "logical_agreement": 81.52822,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.25405,
            "nubia_score": 0.60963
        },
        "meteor": 0.39065187209943303,
        "bleurt": 0.00532,
        "bertscore": {
            "precision": 0.91687,
            "recall": 0.91466,
            "f1": 0.91538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 246,
        "mean_pred_length": 17.571428571428573,
        "std_pred_length": 6.433331570970116,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5609756097560976,
        "vocab_size-1": 138,
        "unique-1": 103,
        "entropy-1": 6.477356950120364,
        "distinct-2": 0.8836206896551724,
        "vocab_size-2": 205,
        "unique-2": 183,
        "entropy-2": 7.606840208461647,
        "cond_entropy-2": 0.9821372990074619,
        "distinct-3": 0.963302752293578,
        "vocab_size-3": 210,
        "unique-3": 202,
        "entropy-3": 7.694789829364071,
        "cond_entropy-3": 0.10407792830297963,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 15.357142857142858,
        "std_pred_length-nopunct": 6.0781475427156595,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6232558139534884,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.592274567073572,
        "distinct-2-nopunct": 0.8905472636815921,
        "vocab_size-2-nopunct": 179,
        "unique-2-nopunct": 161,
        "entropy-2-nopunct": 7.414684651356417,
        "cond_entropy-2-nopunct": 0.8879964323187516,
        "distinct-3-nopunct": 0.9679144385026738,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 175,
        "entropy-3-nopunct": 7.482723336892964,
        "cond_entropy-3-nopunct": 0.08038702006874514,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.220917715069547,
        "rouge1": {
            "precision": 0.80973,
            "recall": 0.83332,
            "fmeasure": 0.81531
        },
        "rouge2": {
            "precision": 0.6782,
            "recall": 0.70196,
            "fmeasure": 0.68425
        },
        "rougeL": {
            "precision": 0.72956,
            "recall": 0.75954,
            "fmeasure": 0.73808
        },
        "rougeLsum": {
            "precision": 0.72956,
            "recall": 0.75954,
            "fmeasure": 0.73808
        },
        "local_recall": {
            "1": 0.3939393939393939,
            "2": 0.5681818181818182,
            "3": 0.8428571428571429
        },
        "bleu": 59.52669,
        "nubia": {
            "semantic_relation": 4.23652,
            "contradiction": 5.14091,
            "irrelevancy": 37.46209,
            "logical_agreement": 57.397,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.61621,
            "nubia_score": 0.74724
        },
        "meteor": 0.4324414577666685,
        "bleurt": 0.41981,
        "bertscore": {
            "precision": 0.95213,
            "recall": 0.95105,
            "f1": 0.9499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 143,
        "mean_pred_length": 17.875,
        "std_pred_length": 8.207275735589734,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 99,
        "unique-1": 86,
        "entropy-1": 6.154302799662693,
        "distinct-2": 0.9481481481481482,
        "vocab_size-2": 128,
        "unique-2": 123,
        "entropy-2": 6.958297078532337,
        "cond_entropy-2": 0.6858057477357385,
        "distinct-3": 0.9921259842519685,
        "vocab_size-3": 126,
        "unique-3": 125,
        "entropy-3": 6.972936655276084,
        "cond_entropy-3": 0.02210531019377606,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 6.514407110397691,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7786885245901639,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.2154342572795835,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.7100829966208915,
        "cond_entropy-2-nopunct": 0.5448454467296134,
        "distinct-3-nopunct": 0.9905660377358491,
        "vocab_size-3-nopunct": 105,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.709052530034882,
        "cond_entropy-3-nopunct": 0.008237987568268889,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.211247649881411,
        "rouge1": {
            "precision": 0.75751,
            "recall": 0.67091,
            "fmeasure": 0.6999
        },
        "rouge2": {
            "precision": 0.53038,
            "recall": 0.4481,
            "fmeasure": 0.47865
        },
        "rougeL": {
            "precision": 0.64987,
            "recall": 0.57395,
            "fmeasure": 0.6004
        },
        "rougeLsum": {
            "precision": 0.64987,
            "recall": 0.57395,
            "fmeasure": 0.6004
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.6041666666666666,
            "3": 0.6901408450704225
        },
        "bleu": 42.08708,
        "nubia": {
            "semantic_relation": 3.92803,
            "contradiction": 27.00801,
            "irrelevancy": 39.22317,
            "logical_agreement": 33.76882,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.11869,
            "nubia_score": 0.70296
        },
        "meteor": 0.36322606970598426,
        "bleurt": 0.3126,
        "bertscore": {
            "precision": 0.92872,
            "recall": 0.92793,
            "f1": 0.92568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.73452166477975,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.2250371587496608,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.640223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6780737179384038,
        "rouge1": {
            "precision": 0.72421,
            "recall": 0.70092,
            "fmeasure": 0.71192
        },
        "rouge2": {
            "precision": 0.44773,
            "recall": 0.44103,
            "fmeasure": 0.44351
        },
        "rougeL": {
            "precision": 0.6131,
            "recall": 0.60493,
            "fmeasure": 0.60797
        },
        "rougeLsum": {
            "precision": 0.6131,
            "recall": 0.60493,
            "fmeasure": 0.60797
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6551724137931034
        },
        "bleu": 35.5286,
        "nubia": {
            "semantic_relation": 4.14027,
            "contradiction": 39.54516,
            "irrelevancy": 11.96434,
            "logical_agreement": 48.49051,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.33721,
            "nubia_score": 0.72444
        },
        "meteor": 0.3822361531208481,
        "bleurt": 0.47742,
        "bertscore": {
            "precision": 0.92245,
            "recall": 0.92333,
            "f1": 0.92285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 4.030495994190253,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7339449541284404,
        "vocab_size-1": 80,
        "unique-1": 72,
        "entropy-1": 5.926070105127186,
        "distinct-2": 0.9901960784313726,
        "vocab_size-2": 101,
        "unique-2": 100,
        "entropy-2": 6.652817498834245,
        "cond_entropy-2": 0.5918779337378794,
        "distinct-3": 1.0,
        "vocab_size-3": 95,
        "unique-3": 95,
        "entropy-3": 6.569855608330948,
        "cond_entropy-3": -0.08151710206160055,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 13.571428571428571,
        "std_pred_length-nopunct": 3.4582052676886295,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 5.932704818720624,
        "distinct-2-nopunct": 0.9886363636363636,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.436704345910033,
        "cond_entropy-2-nopunct": 0.5546819763629495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.09489025772798129,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.965896509763623,
        "rouge1": {
            "precision": 0.8456,
            "recall": 0.80544,
            "fmeasure": 0.82111
        },
        "rouge2": {
            "precision": 0.62747,
            "recall": 0.59937,
            "fmeasure": 0.60935
        },
        "rougeL": {
            "precision": 0.78089,
            "recall": 0.74445,
            "fmeasure": 0.75881
        },
        "rougeLsum": {
            "precision": 0.78089,
            "recall": 0.74445,
            "fmeasure": 0.75881
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.26666666666666666,
            "3": 0.8701298701298701
        },
        "bleu": 52.18948,
        "nubia": {
            "semantic_relation": 4.3285,
            "contradiction": 0.39531,
            "irrelevancy": 27.15728,
            "logical_agreement": 72.44742,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.73542,
            "nubia_score": 0.79577
        },
        "meteor": 0.45595047770381536,
        "bleurt": 0.36913,
        "bertscore": {
            "precision": 0.94591,
            "recall": 0.9416,
            "f1": 0.93985
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 5384,
        "mean_pred_length": 14.997214484679665,
        "std_pred_length": 7.023438121654083,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 56,
        "distinct-1": 0.42737741456166417,
        "vocab_size-1": 2301,
        "unique-1": 1833,
        "entropy-1": 9.11769955786037,
        "distinct-2": 0.8692537313432835,
        "vocab_size-2": 4368,
        "unique-2": 4089,
        "entropy-2": 11.876918430453731,
        "cond_entropy-2": 2.382706007915522,
        "distinct-3": 0.9740677239605658,
        "vocab_size-3": 4545,
        "unique-3": 4469,
        "entropy-3": 12.120402176142095,
        "cond_entropy-3": 0.2644011428910273,
        "total_length-nopunct": 4798,
        "mean_pred_length-nopunct": 13.364902506963789,
        "std_pred_length-nopunct": 6.25262012413028,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4774906210921217,
        "vocab_size-1-nopunct": 2291,
        "unique-1-nopunct": 1830,
        "entropy-1-nopunct": 9.492274764063554,
        "distinct-2-nopunct": 0.8760982203198918,
        "vocab_size-2-nopunct": 3889,
        "unique-2-nopunct": 3658,
        "entropy-2-nopunct": 11.715656823311468,
        "cond_entropy-2-nopunct": 2.400336584386711,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 4000,
        "unique-3-nopunct": 3939,
        "entropy-3-nopunct": 11.95093223208021,
        "cond_entropy-3-nopunct": 0.2649862528943525,
        "msttr-100": 0.73491,
        "msttr-100_nopunct": 0.78447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "nist": 8.204589388050254,
        "rouge1": {
            "precision": 0.72977,
            "recall": 0.62828,
            "fmeasure": 0.65703
        },
        "rouge2": {
            "precision": 0.51894,
            "recall": 0.44695,
            "fmeasure": 0.46349
        },
        "rougeL": {
            "precision": 0.69321,
            "recall": 0.60269,
            "fmeasure": 0.62619
        },
        "rougeLsum": {
            "precision": 0.69321,
            "recall": 0.60269,
            "fmeasure": 0.62619
        },
        "local_recall": {
            "1": 0.035942028985507246,
            "2": 0.11813186813186813,
            "3": 0.2063305978898007,
            "4": 0.3087818696883853,
            "5": 0.3930942895086321,
            "6": 0.4482758620689655,
            "7": 0.5365296803652968,
            "8": 0.6180555555555556,
            "9": 0.7388489208633093
        },
        "bleu": 48.51364,
        "sari": 43.41782,
        "nubia": {
            "semantic_relation": 3.60957,
            "contradiction": 6.03082,
            "irrelevancy": 24.02999,
            "logical_agreement": 69.93919,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.05933,
            "nubia_score": 0.42414
        },
        "meteor": 0.32734913321171666,
        "bleurt": -0.50053,
        "bertscore": {
            "precision": 0.89591,
            "recall": 0.89843,
            "f1": 0.89268
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 177,
        "mean_pred_length": 16.09090909090909,
        "std_pred_length": 7.1281075577864215,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.655367231638418,
        "vocab_size-1": 116,
        "unique-1": 92,
        "entropy-1": 6.47136587357168,
        "distinct-2": 0.9096385542168675,
        "vocab_size-2": 151,
        "unique-2": 138,
        "entropy-2": 7.18226834700956,
        "cond_entropy-2": 0.5476789110078666,
        "distinct-3": 0.9548387096774194,
        "vocab_size-3": 148,
        "unique-3": 141,
        "entropy-3": 7.185801824629094,
        "cond_entropy-3": 0.017214006185377544,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 6.340216645150071,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6942675159235668,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.464807532729245,
        "distinct-2-nopunct": 0.8972602739726028,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.9706464766882394,
        "cond_entropy-2-nopunct": 0.5546604876424585,
        "distinct-3-nopunct": 0.9481481481481482,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.97311189334715,
        "cond_entropy-3-nopunct": 0.012916964096739585,
        "msttr-100": 0.8,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.477530179817885,
        "rouge1": {
            "precision": 0.85874,
            "recall": 0.87897,
            "fmeasure": 0.86431
        },
        "rouge2": {
            "precision": 0.74128,
            "recall": 0.76211,
            "fmeasure": 0.74766
        },
        "rougeL": {
            "precision": 0.80416,
            "recall": 0.82948,
            "fmeasure": 0.81264
        },
        "rougeLsum": {
            "precision": 0.80416,
            "recall": 0.82948,
            "fmeasure": 0.81264
        },
        "local_recall": {
            "1": 0.21875,
            "2": 0.375,
            "3": 0.926829268292683
        },
        "bleu": 68.96507,
        "nubia": {
            "semantic_relation": 4.76623,
            "contradiction": 0.43384,
            "irrelevancy": 12.54423,
            "logical_agreement": 87.02193,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.2114,
            "nubia_score": 0.92908
        },
        "meteor": 0.5176710073970132,
        "bleurt": 0.5876,
        "bertscore": {
            "precision": 0.96525,
            "recall": 0.96844,
            "f1": 0.9666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.6181818181818182,
        "vocab_size-1": 34,
        "unique-1": 26,
        "entropy-1": 4.73543630560956,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 39,
        "unique-2": 32,
        "entropy-2": 5.118216273216784,
        "cond_entropy-2": 0.3079504309731114,
        "distinct-3": 0.8297872340425532,
        "vocab_size-3": 39,
        "unique-3": 33,
        "entropy-3": 5.182040447330259,
        "cond_entropy-3": 0.11099090336919445,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 1.7853571071357126,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6326530612244898,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.603979488292137,
        "distinct-2-nopunct": 0.7333333333333333,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.86374948507433,
        "cond_entropy-2-nopunct": 0.3273904728553562,
        "distinct-3-nopunct": 0.8048780487804879,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.930484321585717,
        "cond_entropy-3-nopunct": 0.10362299370703013,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.041048919196372,
        "rouge1": {
            "precision": 0.6496,
            "recall": 0.63949,
            "fmeasure": 0.64053
        },
        "rouge2": {
            "precision": 0.34893,
            "recall": 0.32883,
            "fmeasure": 0.33795
        },
        "rougeL": {
            "precision": 0.50227,
            "recall": 0.50356,
            "fmeasure": 0.50068
        },
        "rougeLsum": {
            "precision": 0.50227,
            "recall": 0.50356,
            "fmeasure": 0.50068
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 28.05123,
        "nubia": {
            "semantic_relation": 4.23864,
            "contradiction": 0.9481,
            "irrelevancy": 34.99897,
            "logical_agreement": 64.05293,
            "grammar_ref": 5.27719,
            "grammar_hyp": 4.78509,
            "nubia_score": 0.76471
        },
        "meteor": 0.380598762761548,
        "bleurt": 0.11833,
        "bertscore": {
            "precision": 0.91932,
            "recall": 0.9249,
            "f1": 0.92113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 172,
        "mean_pred_length": 15.636363636363637,
        "std_pred_length": 6.623274763667994,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.6337209302325582,
        "vocab_size-1": 109,
        "unique-1": 90,
        "entropy-1": 6.26716082111951,
        "distinct-2": 0.9503105590062112,
        "vocab_size-2": 153,
        "unique-2": 146,
        "entropy-2": 7.226849253877563,
        "cond_entropy-2": 0.802523187195304,
        "distinct-3": 0.98,
        "vocab_size-3": 147,
        "unique-3": 144,
        "entropy-3": 7.1888186904958635,
        "cond_entropy-3": -0.030398937604313243,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 14.181818181818182,
        "std_pred_length-nopunct": 6.644453350771493,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6858974358974359,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.325770883626652,
        "distinct-2-nopunct": 0.9448275862068966,
        "vocab_size-2-nopunct": 137,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.064358141724171,
        "cond_entropy-2-nopunct": 0.8004561007655842,
        "distinct-3-nopunct": 0.9776119402985075,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.021313071054794,
        "cond_entropy-3-nopunct": -0.03355954506340464,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.145007894292049,
        "rouge1": {
            "precision": 0.77664,
            "recall": 0.67581,
            "fmeasure": 0.71553
        },
        "rouge2": {
            "precision": 0.48833,
            "recall": 0.42953,
            "fmeasure": 0.45233
        },
        "rougeL": {
            "precision": 0.66016,
            "recall": 0.57317,
            "fmeasure": 0.6078
        },
        "rougeLsum": {
            "precision": 0.66016,
            "recall": 0.57317,
            "fmeasure": 0.6078
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.44,
            "3": 0.7021276595744681
        },
        "bleu": 37.23279,
        "nubia": {
            "semantic_relation": 4.21807,
            "contradiction": 0.69107,
            "irrelevancy": 20.89852,
            "logical_agreement": 78.41041,
            "grammar_ref": 4.70918,
            "grammar_hyp": 5.02731,
            "nubia_score": 0.71415
        },
        "meteor": 0.3640680166569368,
        "bleurt": 0.27655,
        "bertscore": {
            "precision": 0.94137,
            "recall": 0.91227,
            "f1": 0.92601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 9.701672483628368,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.552,
        "vocab_size-1": 69,
        "unique-1": 51,
        "entropy-1": 5.6187961025835955,
        "distinct-2": 0.8220338983050848,
        "vocab_size-2": 97,
        "unique-2": 86,
        "entropy-2": 6.450273981491886,
        "cond_entropy-2": 0.7448459536553023,
        "distinct-3": 0.8918918918918919,
        "vocab_size-3": 99,
        "unique-3": 92,
        "entropy-3": 6.539779267192548,
        "cond_entropy-3": 0.09875378547622372,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 8.463607567770643,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5981308411214953,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.533875740596639,
        "distinct-2-nopunct": 0.82,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.1936606896881985,
        "cond_entropy-2-nopunct": 0.6826170862834329,
        "distinct-3-nopunct": 0.8924731182795699,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.278248461575883,
        "cond_entropy-3-nopunct": 0.06288286327654469,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5035443405637166,
        "rouge1": {
            "precision": 0.64665,
            "recall": 0.6551,
            "fmeasure": 0.63368
        },
        "rouge2": {
            "precision": 0.40014,
            "recall": 0.41058,
            "fmeasure": 0.39577
        },
        "rougeL": {
            "precision": 0.59195,
            "recall": 0.60926,
            "fmeasure": 0.58603
        },
        "rougeLsum": {
            "precision": 0.59195,
            "recall": 0.60926,
            "fmeasure": 0.58603
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5294117647058824,
            "3": 0.6086956521739131
        },
        "bleu": 23.10955,
        "nubia": {
            "semantic_relation": 3.92093,
            "contradiction": 10.70894,
            "irrelevancy": 47.75865,
            "logical_agreement": 41.53241,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.05939,
            "nubia_score": 0.71009
        },
        "meteor": 0.3384941464060973,
        "bleurt": 0.091,
        "bertscore": {
            "precision": 0.89834,
            "recall": 0.89279,
            "f1": 0.8938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 107,
        "mean_pred_length": 15.285714285714286,
        "std_pred_length": 1.6659862556700857,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.6915887850467289,
        "vocab_size-1": 74,
        "unique-1": 62,
        "entropy-1": 5.877706384648148,
        "distinct-2": 0.95,
        "vocab_size-2": 95,
        "unique-2": 92,
        "entropy-2": 6.5238561897747385,
        "cond_entropy-2": 0.5100982027052471,
        "distinct-3": 0.989247311827957,
        "vocab_size-3": 92,
        "unique-3": 91,
        "entropy-3": 6.51765343476395,
        "cond_entropy-3": 0.002829503053736609,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 1.2936264483053452,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7553191489361702,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.886813320473724,
        "distinct-2-nopunct": 0.9425287356321839,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.3050124613659655,
        "cond_entropy-2-nopunct": 0.4719282066212866,
        "distinct-3-nopunct": 0.9875,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.296928094887357,
        "cond_entropy-3-nopunct": 0.003984599038633847,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.221859675749645,
        "rouge1": {
            "precision": 0.91795,
            "recall": 0.87982,
            "fmeasure": 0.89487
        },
        "rouge2": {
            "precision": 0.71599,
            "recall": 0.69125,
            "fmeasure": 0.70074
        },
        "rougeL": {
            "precision": 0.75067,
            "recall": 0.72364,
            "fmeasure": 0.73407
        },
        "rougeLsum": {
            "precision": 0.75067,
            "recall": 0.72364,
            "fmeasure": 0.73407
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.16666666666666666,
            "3": 0.8901098901098901
        },
        "bleu": 62.2918,
        "nubia": {
            "semantic_relation": 4.72267,
            "contradiction": 3.22325,
            "irrelevancy": 5.79596,
            "logical_agreement": 90.98079,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.19515,
            "nubia_score": 0.86604
        },
        "meteor": 0.46999569206222414,
        "bleurt": 0.58128,
        "bertscore": {
            "precision": 0.97822,
            "recall": 0.97249,
            "f1": 0.97524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 57,
        "mean_pred_length": 11.4,
        "std_pred_length": 3.9293765408777004,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.8245614035087719,
        "vocab_size-1": 47,
        "unique-1": 41,
        "entropy-1": 5.405442154926137,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679557,
        "cond_entropy-2": 0.07437446363334002,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.10329767497409284,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 9.8,
        "std_pred_length-nopunct": 2.993325909419153,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8775510204081632,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.354406017540444,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.41397707318275,
        "cond_entropy-2-nopunct": 0.08915103593489508,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.12274734849299755,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.253565480308377,
        "rouge1": {
            "precision": 0.87905,
            "recall": 0.83154,
            "fmeasure": 0.85225
        },
        "rouge2": {
            "precision": 0.71909,
            "recall": 0.66698,
            "fmeasure": 0.68954
        },
        "rougeL": {
            "precision": 0.85048,
            "recall": 0.80932,
            "fmeasure": 0.82725
        },
        "rougeLsum": {
            "precision": 0.85048,
            "recall": 0.80932,
            "fmeasure": 0.82725
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.75,
            "3": 0.8947368421052632
        },
        "bleu": 64.3385,
        "nubia": {
            "semantic_relation": 4.70371,
            "contradiction": 0.60202,
            "irrelevancy": 3.50213,
            "logical_agreement": 95.89585,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.0644,
            "nubia_score": 0.90581
        },
        "meteor": 0.4779228142229397,
        "bleurt": 0.48734,
        "bertscore": {
            "precision": 0.96145,
            "recall": 0.9482,
            "f1": 0.95464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429872,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.857694370844596,
        "rouge1": {
            "precision": 0.6369,
            "recall": 0.90278,
            "fmeasure": 0.72162
        },
        "rouge2": {
            "precision": 0.52448,
            "recall": 0.73636,
            "fmeasure": 0.58874
        },
        "rougeL": {
            "precision": 0.6369,
            "recall": 0.90278,
            "fmeasure": 0.72162
        },
        "rougeLsum": {
            "precision": 0.6369,
            "recall": 0.90278,
            "fmeasure": 0.72162
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "bleu": 50.54062,
        "nubia": {
            "semantic_relation": 4.09592,
            "contradiction": 0.60654,
            "irrelevancy": 44.25874,
            "logical_agreement": 55.13471,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.38087,
            "nubia_score": 0.73581
        },
        "meteor": 0.5142409684009683,
        "bleurt": 0.4163,
        "bertscore": {
            "precision": 0.90231,
            "recall": 0.95882,
            "f1": 0.92891
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 80,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.29285308902091,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.7125,
        "vocab_size-1": 57,
        "unique-1": 49,
        "entropy-1": 5.489063213848725,
        "distinct-2": 0.9733333333333334,
        "vocab_size-2": 73,
        "unique-2": 71,
        "entropy-2": 6.175485357162557,
        "cond_entropy-2": 0.5871512623905705,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.042392816408057254,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 5.74108003776293,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7605633802816901,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.441794126455518,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.983788058752401,
        "cond_entropy-2-nopunct": 0.5956267348005954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.04808301130376398,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.569925494617039,
        "rouge1": {
            "precision": 0.82303,
            "recall": 0.81747,
            "fmeasure": 0.8123
        },
        "rouge2": {
            "precision": 0.6854,
            "recall": 0.66752,
            "fmeasure": 0.66985
        },
        "rougeL": {
            "precision": 0.79903,
            "recall": 0.79259,
            "fmeasure": 0.78828
        },
        "rougeLsum": {
            "precision": 0.79903,
            "recall": 0.79259,
            "fmeasure": 0.78828
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.3333333333333333,
            "3": 0.82
        },
        "bleu": 58.45122,
        "nubia": {
            "semantic_relation": 4.52708,
            "contradiction": 15.44746,
            "irrelevancy": 5.79901,
            "logical_agreement": 78.75353,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.6799,
            "nubia_score": 0.81763
        },
        "meteor": 0.4499385418099888,
        "bleurt": 0.44615,
        "bertscore": {
            "precision": 0.96115,
            "recall": 0.94586,
            "f1": 0.95313
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 13,
        "total_length": 194,
        "mean_pred_length": 14.923076923076923,
        "std_pred_length": 3.7305709701483507,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.5979381443298969,
        "vocab_size-1": 116,
        "unique-1": 83,
        "entropy-1": 6.367060761581457,
        "distinct-2": 0.8397790055248618,
        "vocab_size-2": 152,
        "unique-2": 125,
        "entropy-2": 7.171062599766456,
        "cond_entropy-2": 0.6267717868703175,
        "distinct-3": 0.8988095238095238,
        "vocab_size-3": 151,
        "unique-3": 134,
        "entropy-3": 7.189936470397836,
        "cond_entropy-3": 0.02050591072131065,
        "total_length-nopunct": 175,
        "mean_pred_length-nopunct": 13.461538461538462,
        "std_pred_length-nopunct": 3.2726226747973306,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.64,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.405110612965665,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.997197070759135,
        "cond_entropy-2-nopunct": 0.6328229175790698,
        "distinct-3-nopunct": 0.8926174496644296,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 7.004403419791029,
        "cond_entropy-3-nopunct": 0.0035451954589257257,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.478744299022182,
        "rouge1": {
            "precision": 0.73921,
            "recall": 0.7037,
            "fmeasure": 0.71038
        },
        "rouge2": {
            "precision": 0.52052,
            "recall": 0.50812,
            "fmeasure": 0.50855
        },
        "rougeL": {
            "precision": 0.6396,
            "recall": 0.61754,
            "fmeasure": 0.62006
        },
        "rougeLsum": {
            "precision": 0.6396,
            "recall": 0.61754,
            "fmeasure": 0.62006
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.6078431372549019,
            "3": 0.6991869918699187
        },
        "bleu": 45.02135,
        "nubia": {
            "semantic_relation": 4.20196,
            "contradiction": 0.56763,
            "irrelevancy": 43.68457,
            "logical_agreement": 55.7478,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.53546,
            "nubia_score": 0.7686
        },
        "meteor": 0.3887020764344506,
        "bleurt": 0.07204,
        "bertscore": {
            "precision": 0.9073,
            "recall": 0.90018,
            "f1": 0.90217
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 92,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 5.587684871413404,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7717391304347826,
        "vocab_size-1": 71,
        "unique-1": 62,
        "entropy-1": 5.909112771133319,
        "distinct-2": 1.0,
        "vocab_size-2": 86,
        "unique-2": 86,
        "entropy-2": 6.426264754702099,
        "cond_entropy-2": 0.3796743103736183,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": -0.10433665981473575,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.41602560309064,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.903989446485261,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.285402218862257,
        "cond_entropy-2-nopunct": 0.4189764628611015,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.11547721741993579,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.9189005458967205,
        "rouge1": {
            "precision": 0.80233,
            "recall": 0.70646,
            "fmeasure": 0.74407
        },
        "rouge2": {
            "precision": 0.66006,
            "recall": 0.56836,
            "fmeasure": 0.60322
        },
        "rougeL": {
            "precision": 0.75559,
            "recall": 0.65674,
            "fmeasure": 0.69595
        },
        "rougeLsum": {
            "precision": 0.75559,
            "recall": 0.65674,
            "fmeasure": 0.69595
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4090909090909091,
            "3": 0.8115942028985508
        },
        "bleu": 54.57497,
        "nubia": {
            "semantic_relation": 4.1699,
            "contradiction": 15.53388,
            "irrelevancy": 26.07122,
            "logical_agreement": 58.39489,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.70902,
            "nubia_score": 0.73406
        },
        "meteor": 0.4191921162958974,
        "bleurt": 0.36073,
        "bertscore": {
            "precision": 0.94593,
            "recall": 0.92594,
            "f1": 0.93493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.260329933156776,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.5469,
            "irrelevancy": 1.17376,
            "logical_agreement": 98.27934,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.24873,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.88151,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.02999212699343526,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8766906662773697,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.71282,
            "fmeasure": 0.76741
        },
        "rouge2": {
            "precision": 0.59091,
            "recall": 0.49405,
            "fmeasure": 0.53739
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.39231,
            "fmeasure": 0.42222
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.39231,
            "fmeasure": 0.42222
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "bleu": 55.02152,
        "nubia": {
            "semantic_relation": 3.97184,
            "contradiction": 0.29166,
            "irrelevancy": 0.54937,
            "logical_agreement": 99.15897,
            "grammar_ref": 4.56931,
            "grammar_hyp": 3.81632,
            "nubia_score": 0.77436
        },
        "meteor": 0.4269921288108823,
        "bleurt": 0.07735,
        "bertscore": {
            "precision": 0.93111,
            "recall": 0.87489,
            "f1": 0.89958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 130,
        "mean_pred_length": 16.25,
        "std_pred_length": 4.575751304430781,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5692307692307692,
        "vocab_size-1": 74,
        "unique-1": 50,
        "entropy-1": 5.791061965059119,
        "distinct-2": 0.8360655737704918,
        "vocab_size-2": 102,
        "unique-2": 84,
        "entropy-2": 6.590493280150383,
        "cond_entropy-2": 0.6834513706957996,
        "distinct-3": 0.868421052631579,
        "vocab_size-3": 99,
        "unique-3": 84,
        "entropy-3": 6.569732119427912,
        "cond_entropy-3": -0.014428244412820358,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.763139720814412,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6052631578947368,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.741134577659687,
        "distinct-2-nopunct": 0.8207547169811321,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.355186728107273,
        "cond_entropy-2-nopunct": 0.6681469003725153,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.328995558400931,
        "cond_entropy-3-nopunct": -0.016172089995675015,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.59,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.842761824948667,
        "rouge1": {
            "precision": 0.66291,
            "recall": 0.70977,
            "fmeasure": 0.67562
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.5396,
            "fmeasure": 0.4932
        },
        "rougeL": {
            "precision": 0.58176,
            "recall": 0.64553,
            "fmeasure": 0.60357
        },
        "rougeLsum": {
            "precision": 0.58176,
            "recall": 0.64553,
            "fmeasure": 0.60357
        },
        "local_recall": {
            "1": 0.5121951219512195,
            "2": 0.5714285714285714,
            "3": 0.7708333333333334
        },
        "bleu": 48.63267,
        "nubia": {
            "semantic_relation": 3.76132,
            "contradiction": 34.22246,
            "irrelevancy": 26.86013,
            "logical_agreement": 38.91741,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.6934,
            "nubia_score": 0.60231
        },
        "meteor": 0.4297762502228963,
        "bleurt": 0.06557,
        "bertscore": {
            "precision": 0.90828,
            "recall": 0.92127,
            "f1": 0.91123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.265986323710904,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.803921568627451,
        "vocab_size-1": 41,
        "unique-1": 35,
        "entropy-1": 5.2114493614945,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3032639817113996,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8837209302325582,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.176151091861087,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.16453552773935093,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.77064955771167,
        "rouge1": {
            "precision": 0.88342,
            "recall": 0.84265,
            "fmeasure": 0.85978
        },
        "rouge2": {
            "precision": 0.68036,
            "recall": 0.65353,
            "fmeasure": 0.66395
        },
        "rougeL": {
            "precision": 0.73832,
            "recall": 0.71532,
            "fmeasure": 0.7242
        },
        "rougeLsum": {
            "precision": 0.73832,
            "recall": 0.71532,
            "fmeasure": 0.7242
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.9230769230769231,
            "3": 0.8888888888888888
        },
        "bleu": 57.5678,
        "nubia": {
            "semantic_relation": 4.74578,
            "contradiction": 30.82976,
            "irrelevancy": 23.36883,
            "logical_agreement": 45.80142,
            "grammar_ref": 4.97796,
            "grammar_hyp": 4.81731,
            "nubia_score": 0.87986
        },
        "meteor": 0.47468836684581417,
        "bleurt": 0.53789,
        "bertscore": {
            "precision": 0.94176,
            "recall": 0.94351,
            "f1": 0.94243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 126,
        "mean_pred_length": 21.0,
        "std_pred_length": 6.2182527020592095,
        "median_pred_length": 22.5,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 90,
        "unique-1": 82,
        "entropy-1": 6.0533145233022125,
        "distinct-2": 0.9833333333333333,
        "vocab_size-2": 118,
        "unique-2": 116,
        "entropy-2": 6.8735572622752015,
        "cond_entropy-2": 0.7371928839468068,
        "distinct-3": 1.0,
        "vocab_size-3": 114,
        "unique-3": 114,
        "entropy-3": 6.832890014164754,
        "cond_entropy-3": -0.038912862145531045,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.852349955359813,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7927927927927928,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.142338925741074,
        "distinct-2-nopunct": 0.9904761904761905,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.695197898618494,
        "cond_entropy-2-nopunct": 0.5901205123408153,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 99,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.62935662007962,
        "cond_entropy-3-nopunct": -0.06468687738449275,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.7825475229754675,
        "rouge1": {
            "precision": 0.58612,
            "recall": 0.60412,
            "fmeasure": 0.58435
        },
        "rouge2": {
            "precision": 0.32088,
            "recall": 0.31164,
            "fmeasure": 0.31005
        },
        "rougeL": {
            "precision": 0.43876,
            "recall": 0.44953,
            "fmeasure": 0.4375
        },
        "rougeLsum": {
            "precision": 0.43876,
            "recall": 0.44953,
            "fmeasure": 0.4375
        },
        "local_recall": {
            "1": 0.33962264150943394,
            "2": 0.5405405405405406,
            "3": 0.7380952380952381
        },
        "bleu": 28.34512,
        "nubia": {
            "semantic_relation": 3.86644,
            "contradiction": 10.36143,
            "irrelevancy": 48.78506,
            "logical_agreement": 40.85351,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.62584,
            "nubia_score": 0.63801
        },
        "meteor": 0.36610144181657056,
        "bleurt": -0.01972,
        "bertscore": {
            "precision": 0.89556,
            "recall": 0.91441,
            "f1": 0.90412
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 22,
        "total_length": 327,
        "mean_pred_length": 14.863636363636363,
        "std_pred_length": 5.610829257665722,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.599388379204893,
        "vocab_size-1": 196,
        "unique-1": 158,
        "entropy-1": 6.958290751963256,
        "distinct-2": 0.8852459016393442,
        "vocab_size-2": 270,
        "unique-2": 247,
        "entropy-2": 7.9808823078941975,
        "cond_entropy-2": 0.8015402051366777,
        "distinct-3": 0.9540636042402827,
        "vocab_size-3": 270,
        "unique-3": 259,
        "entropy-3": 8.047450557304206,
        "cond_entropy-3": 0.07356199054154275,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 13.136363636363637,
        "std_pred_length-nopunct": 4.8175385505411805,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6608996539792388,
        "vocab_size-1-nopunct": 191,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 7.091912220814843,
        "distinct-2-nopunct": 0.8913857677902621,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 220,
        "entropy-2-nopunct": 7.798003177052997,
        "cond_entropy-2-nopunct": 0.7604144321265687,
        "distinct-3-nopunct": 0.963265306122449,
        "vocab_size-3-nopunct": 236,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.860087377769283,
        "cond_entropy-3-nopunct": 0.07750967256095126,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.619641528945341,
        "rouge1": {
            "precision": 0.85213,
            "recall": 0.83425,
            "fmeasure": 0.83587
        },
        "rouge2": {
            "precision": 0.69675,
            "recall": 0.68023,
            "fmeasure": 0.68251
        },
        "rougeL": {
            "precision": 0.77392,
            "recall": 0.7627,
            "fmeasure": 0.76184
        },
        "rougeLsum": {
            "precision": 0.77392,
            "recall": 0.7627,
            "fmeasure": 0.76184
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.83399209486166
        },
        "bleu": 60.07706,
        "nubia": {
            "semantic_relation": 4.48795,
            "contradiction": 0.41891,
            "irrelevancy": 25.28836,
            "logical_agreement": 74.29273,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.4291,
            "nubia_score": 0.83272
        },
        "meteor": 0.47532929074958924,
        "bleurt": 0.48714,
        "bertscore": {
            "precision": 0.95471,
            "recall": 0.94931,
            "f1": 0.95143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.237802837211829,
        "rouge1": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 54.10823,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11134,
            "irrelevancy": 94.39482,
            "logical_agreement": 5.49385,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.81767,
            "nubia_score": 0.99066
        },
        "meteor": 0.4856660049203748,
        "bleurt": 0.31071,
        "bertscore": {
            "precision": 0.89191,
            "recall": 0.94076,
            "f1": 0.91569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 167,
        "mean_pred_length": 16.7,
        "std_pred_length": 6.197580172938467,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5988023952095808,
        "vocab_size-1": 100,
        "unique-1": 81,
        "entropy-1": 6.105788159292592,
        "distinct-2": 0.8853503184713376,
        "vocab_size-2": 139,
        "unique-2": 126,
        "entropy-2": 7.032713643931344,
        "cond_entropy-2": 0.7967336399440988,
        "distinct-3": 0.9727891156462585,
        "vocab_size-3": 143,
        "unique-3": 139,
        "entropy-3": 7.1452505761288725,
        "cond_entropy-3": 0.13035374205877664,
        "total_length-nopunct": 148,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 5.96322060635023,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6554054054054054,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.154097194734164,
        "distinct-2-nopunct": 0.8840579710144928,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.839543185192922,
        "cond_entropy-2-nopunct": 0.7546746984946112,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.9375,
        "cond_entropy-3-nopunct": 0.11897097664967299,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.5440881551953165,
        "rouge1": {
            "precision": 0.88369,
            "recall": 0.85771,
            "fmeasure": 0.86482
        },
        "rouge2": {
            "precision": 0.68204,
            "recall": 0.69395,
            "fmeasure": 0.68411
        },
        "rougeL": {
            "precision": 0.7632,
            "recall": 0.76603,
            "fmeasure": 0.7601
        },
        "rougeLsum": {
            "precision": 0.7632,
            "recall": 0.76603,
            "fmeasure": 0.7601
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5769230769230769,
            "3": 0.9174311926605505
        },
        "bleu": 66.86936,
        "nubia": {
            "semantic_relation": 4.51571,
            "contradiction": 5.88583,
            "irrelevancy": 20.28132,
            "logical_agreement": 73.83285,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.913,
            "nubia_score": 0.83465
        },
        "meteor": 0.482010677297989,
        "bleurt": 0.55366,
        "bertscore": {
            "precision": 0.96203,
            "recall": 0.95649,
            "f1": 0.95815
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.286790198827111,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.20056288677677891,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.2626923908396215,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.15446975243603325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6301467288002347,
        "rouge1": {
            "precision": 0.62937,
            "recall": 0.65665,
            "fmeasure": 0.63655
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.51567,
            "fmeasure": 0.49063
        },
        "rougeL": {
            "precision": 0.62937,
            "recall": 0.65665,
            "fmeasure": 0.63655
        },
        "rougeLsum": {
            "precision": 0.62937,
            "recall": 0.65665,
            "fmeasure": 0.63655
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "bleu": 44.85574,
        "nubia": {
            "semantic_relation": 4.07584,
            "contradiction": 4.40243,
            "irrelevancy": 52.62432,
            "logical_agreement": 42.97325,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.68563,
            "nubia_score": 0.70733
        },
        "meteor": 0.40074328100317613,
        "bleurt": 0.34095,
        "bertscore": {
            "precision": 0.9159,
            "recall": 0.90159,
            "f1": 0.90811
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.609660370521621,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.70833,
            "fmeasure": 0.68627
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.26786,
            "fmeasure": 0.25833
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.59028,
            "fmeasure": 0.5719
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.59028,
            "fmeasure": 0.5719
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.8333333333333334
        },
        "bleu": 21.36435,
        "nubia": {
            "semantic_relation": 4.44556,
            "contradiction": 0.22811,
            "irrelevancy": 2.18053,
            "logical_agreement": 97.59135,
            "grammar_ref": 6.12307,
            "grammar_hyp": 5.96372,
            "nubia_score": 0.78878
        },
        "meteor": 0.36034183204783765,
        "bleurt": 0.54238,
        "bertscore": {
            "precision": 0.89054,
            "recall": 0.90023,
            "f1": 0.89399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 110,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 6.944222218666553,
        "median_pred_length": 20.5,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6727272727272727,
        "vocab_size-1": 74,
        "unique-1": 60,
        "entropy-1": 5.853966363812438,
        "distinct-2": 0.9326923076923077,
        "vocab_size-2": 97,
        "unique-2": 90,
        "entropy-2": 6.565824333525714,
        "cond_entropy-2": 0.6162289802319897,
        "distinct-3": 0.9795918367346939,
        "vocab_size-3": 96,
        "unique-3": 94,
        "entropy-3": 6.573893517584606,
        "cond_entropy-3": -0.004097220964659261,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.7871355387816905,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8045977011494253,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.960481789514965,
        "distinct-2-nopunct": 0.9876543209876543,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.315158644859923,
        "cond_entropy-2-nopunct": 0.3904147595178362,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.08436464572207733,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.1286452653057495,
        "rouge1": {
            "precision": 0.77935,
            "recall": 0.6068,
            "fmeasure": 0.67558
        },
        "rouge2": {
            "precision": 0.46403,
            "recall": 0.37832,
            "fmeasure": 0.41337
        },
        "rougeL": {
            "precision": 0.70128,
            "recall": 0.53153,
            "fmeasure": 0.59824
        },
        "rougeLsum": {
            "precision": 0.70128,
            "recall": 0.53153,
            "fmeasure": 0.59824
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.23404255319148937,
            "3": 0.7903225806451613
        },
        "bleu": 40.96635,
        "nubia": {
            "semantic_relation": 3.90394,
            "contradiction": 5.85786,
            "irrelevancy": 22.61772,
            "logical_agreement": 71.52443,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.50165,
            "nubia_score": 0.66095
        },
        "meteor": 0.3373444686235321,
        "bleurt": 0.11715,
        "bertscore": {
            "precision": 0.93647,
            "recall": 0.89237,
            "f1": 0.91221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9319229794768673,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.79259,
            "fmeasure": 0.77895
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "bleu": 70.71068,
        "nubia": {
            "semantic_relation": 3.77294,
            "contradiction": 97.25474,
            "irrelevancy": 1.13362,
            "logical_agreement": 1.61164,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.0947,
            "nubia_score": 0.66169
        },
        "meteor": 0.5023397349274512,
        "bleurt": 0.63675,
        "bertscore": {
            "precision": 0.99319,
            "recall": 0.99319,
            "f1": 0.99319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 170,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.04979338490167,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6588235294117647,
        "vocab_size-1": 112,
        "unique-1": 87,
        "entropy-1": 6.427798198471348,
        "distinct-2": 0.91875,
        "vocab_size-2": 147,
        "unique-2": 134,
        "entropy-2": 7.1594280948873665,
        "cond_entropy-2": 0.5853589365896811,
        "distinct-3": 0.9466666666666667,
        "vocab_size-3": 142,
        "unique-3": 134,
        "entropy-3": 7.122152023829195,
        "cond_entropy-3": -0.026442737724814803,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.440588203494177,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.4978087941331815,
        "distinct-2-nopunct": 0.9071428571428571,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.943568731230693,
        "cond_entropy-2-nopunct": 0.4836892154091085,
        "distinct-3-nopunct": 0.9384615384615385,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 114,
        "entropy-3-nopunct": 6.899290889951533,
        "cond_entropy-3-nopunct": -0.03768443468574297,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.6890492307973215,
        "rouge1": {
            "precision": 0.75015,
            "recall": 0.79143,
            "fmeasure": 0.75225
        },
        "rouge2": {
            "precision": 0.5134,
            "recall": 0.51459,
            "fmeasure": 0.50607
        },
        "rougeL": {
            "precision": 0.62087,
            "recall": 0.63073,
            "fmeasure": 0.61483
        },
        "rougeLsum": {
            "precision": 0.62087,
            "recall": 0.63073,
            "fmeasure": 0.61483
        },
        "local_recall": {
            "1": 0.32608695652173914,
            "2": 0.7037037037037037,
            "3": 0.8105263157894737
        },
        "bleu": 47.49209,
        "nubia": {
            "semantic_relation": 4.30637,
            "contradiction": 3.44499,
            "irrelevancy": 45.58877,
            "logical_agreement": 50.96624,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.0556,
            "nubia_score": 0.73731
        },
        "meteor": 0.4127453442814466,
        "bleurt": 0.28938,
        "bertscore": {
            "precision": 0.92352,
            "recall": 0.92935,
            "f1": 0.92549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.8064516129032258,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.51839711669891,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.23170796075197078,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.396291529045929,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.375661995283382,
        "rouge1": {
            "precision": 0.66912,
            "recall": 0.67481,
            "fmeasure": 0.64034
        },
        "rouge2": {
            "precision": 0.26799,
            "recall": 0.31125,
            "fmeasure": 0.28299
        },
        "rougeL": {
            "precision": 0.57026,
            "recall": 0.64388,
            "fmeasure": 0.58773
        },
        "rougeLsum": {
            "precision": 0.57026,
            "recall": 0.64388,
            "fmeasure": 0.58773
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.36363636363636365,
            "3": 0.7777777777777778
        },
        "bleu": 12.6216,
        "nubia": {
            "semantic_relation": 3.87956,
            "contradiction": 0.27551,
            "irrelevancy": 45.51502,
            "logical_agreement": 54.20947,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.31087,
            "nubia_score": 0.64631
        },
        "meteor": 0.347799657858226,
        "bleurt": 0.1163,
        "bertscore": {
            "precision": 0.9039,
            "recall": 0.91295,
            "f1": 0.90323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 67,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 6.79869268479038,
        "median_pred_length": 25.0,
        "min_pred_length": 13,
        "max_pred_length": 29,
        "distinct-1": 0.7910447761194029,
        "vocab_size-1": 53,
        "unique-1": 46,
        "entropy-1": 5.511443526894631,
        "distinct-2": 0.984375,
        "vocab_size-2": 63,
        "unique-2": 62,
        "entropy-2": 5.96875,
        "cond_entropy-2": 0.40901037136358204,
        "distinct-3": 1.0,
        "vocab_size-3": 61,
        "unique-3": 61,
        "entropy-3": 5.930737337562883,
        "cond_entropy-3": -0.03647577719121215,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.354126134736337,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.609120057986431,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.717850465126429,
        "cond_entropy-2-nopunct": 0.12116207137212434,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.043246473917463175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.685167896128361,
        "rouge1": {
            "precision": 0.84778,
            "recall": 0.67515,
            "fmeasure": 0.74894
        },
        "rouge2": {
            "precision": 0.60642,
            "recall": 0.4841,
            "fmeasure": 0.53616
        },
        "rougeL": {
            "precision": 0.81778,
            "recall": 0.65029,
            "fmeasure": 0.72181
        },
        "rougeLsum": {
            "precision": 0.81778,
            "recall": 0.65029,
            "fmeasure": 0.72181
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "bleu": 51.02236,
        "nubia": {
            "semantic_relation": 4.01094,
            "contradiction": 6.21345,
            "irrelevancy": 37.17674,
            "logical_agreement": 56.60981,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.7044,
            "nubia_score": 0.69867
        },
        "meteor": 0.39911411531647606,
        "bleurt": 0.42835,
        "bertscore": {
            "precision": 0.95337,
            "recall": 0.90674,
            "f1": 0.92915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 134,
        "mean_pred_length": 19.142857142857142,
        "std_pred_length": 5.742786069211937,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.6119402985074627,
        "vocab_size-1": 82,
        "unique-1": 65,
        "entropy-1": 5.930917781060155,
        "distinct-2": 0.9291338582677166,
        "vocab_size-2": 118,
        "unique-2": 110,
        "entropy-2": 6.841008407227553,
        "cond_entropy-2": 0.8179230309814363,
        "distinct-3": 0.975,
        "vocab_size-3": 117,
        "unique-3": 114,
        "entropy-3": 6.856890595608535,
        "cond_entropy-3": 0.02449663802104825,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 17.142857142857142,
        "std_pred_length-nopunct": 5.166611805721463,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.966807262687906,
        "distinct-2-nopunct": 0.9292035398230089,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.671905621688095,
        "cond_entropy-2-nopunct": 0.7367849371457076,
        "distinct-3-nopunct": 0.9716981132075472,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.671316680978278,
        "cond_entropy-3-nopunct": -0.00023126726554059522,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2244894551853776,
        "rouge1": {
            "precision": 0.71936,
            "recall": 0.69214,
            "fmeasure": 0.6857
        },
        "rouge2": {
            "precision": 0.50607,
            "recall": 0.46184,
            "fmeasure": 0.46368
        },
        "rougeL": {
            "precision": 0.62928,
            "recall": 0.60657,
            "fmeasure": 0.59717
        },
        "rougeLsum": {
            "precision": 0.62928,
            "recall": 0.60657,
            "fmeasure": 0.59717
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.8,
            "3": 0.7101449275362319
        },
        "bleu": 47.21644,
        "nubia": {
            "semantic_relation": 4.00004,
            "contradiction": 15.33424,
            "irrelevancy": 36.02179,
            "logical_agreement": 48.64396,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.43942,
            "nubia_score": 0.70349
        },
        "meteor": 0.3659339694045614,
        "bleurt": 0.01743,
        "bertscore": {
            "precision": 0.90717,
            "recall": 0.90208,
            "f1": 0.903
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 4.0,
        "median_pred_length": 21.0,
        "min_pred_length": 17,
        "max_pred_length": 25,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 30,
        "unique-1": 20,
        "entropy-1": 4.773269803731142,
        "distinct-2": 0.925,
        "vocab_size-2": 37,
        "unique-2": 34,
        "entropy-2": 5.171928094887363,
        "cond_entropy-2": 0.379610672108602,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 37,
        "unique-3": 36,
        "entropy-3": 5.19529593449622,
        "cond_entropy-3": 0.031262576450960075,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7297297297297297,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.614858771034358,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.957854445516392,
        "cond_entropy-2-nopunct": 0.34840107988744523,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": 0.03632322362560795,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.121200677404275,
        "rouge1": {
            "precision": 0.82292,
            "recall": 0.84482,
            "fmeasure": 0.83329
        },
        "rouge2": {
            "precision": 0.65072,
            "recall": 0.66892,
            "fmeasure": 0.65925
        },
        "rougeL": {
            "precision": 0.78125,
            "recall": 0.80195,
            "fmeasure": 0.79103
        },
        "rougeLsum": {
            "precision": 0.78125,
            "recall": 0.80195,
            "fmeasure": 0.79103
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bleu": 49.45859,
        "nubia": {
            "semantic_relation": 4.70719,
            "contradiction": 0.90298,
            "irrelevancy": 2.27572,
            "logical_agreement": 96.82129,
            "grammar_ref": 3.82725,
            "grammar_hyp": 3.73087,
            "nubia_score": 0.88911
        },
        "meteor": 0.4586721940350715,
        "bleurt": 0.59926,
        "bertscore": {
            "precision": 0.95367,
            "recall": 0.96376,
            "f1": 0.95612
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0944791993871068,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.69444,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "bleu": 10.81606,
        "nubia": {
            "semantic_relation": 3.64471,
            "contradiction": 0.19032,
            "irrelevancy": 35.93123,
            "logical_agreement": 63.87844,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.28193,
            "nubia_score": 0.64427
        },
        "meteor": 0.3150777603805283,
        "bleurt": 0.17343,
        "bertscore": {
            "precision": 0.89969,
            "recall": 0.89329,
            "f1": 0.89648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.606739354015323,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.031031312388743962,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.807008112479406,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.86556,
            "fmeasure": 0.89699
        },
        "rouge2": {
            "precision": 0.82857,
            "recall": 0.75441,
            "fmeasure": 0.7882
        },
        "rougeL": {
            "precision": 0.87778,
            "recall": 0.81695,
            "fmeasure": 0.84519
        },
        "rougeLsum": {
            "precision": 0.87778,
            "recall": 0.81695,
            "fmeasure": 0.84519
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.95
        },
        "bleu": 75.82045,
        "nubia": {
            "semantic_relation": 4.61282,
            "contradiction": 0.50104,
            "irrelevancy": 17.07245,
            "logical_agreement": 82.4265,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.62705,
            "nubia_score": 0.86977
        },
        "meteor": 0.5125740251619455,
        "bleurt": 0.60837,
        "bertscore": {
            "precision": 0.98238,
            "recall": 0.97499,
            "f1": 0.97865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 5.312459150169742,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.140450958934099,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 47,
        "unique-2": 45,
        "entropy-2": 5.533077191053984,
        "cond_entropy-2": 0.3298727377414692,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.004191366319064997,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.993898304391787,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.333241498888144,
        "cond_entropy-2-nopunct": 0.35304065856602124,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.004336659814735825,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6452151449552304,
        "rouge1": {
            "precision": 0.78831,
            "recall": 0.75568,
            "fmeasure": 0.77063
        },
        "rouge2": {
            "precision": 0.55189,
            "recall": 0.5265,
            "fmeasure": 0.53809
        },
        "rougeL": {
            "precision": 0.60952,
            "recall": 0.59615,
            "fmeasure": 0.60243
        },
        "rougeLsum": {
            "precision": 0.60952,
            "recall": 0.59615,
            "fmeasure": 0.60243
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.6666666666666666,
            "3": 0.7058823529411765
        },
        "bleu": 36.00411,
        "nubia": {
            "semantic_relation": 4.57585,
            "contradiction": 0.50665,
            "irrelevancy": 33.71253,
            "logical_agreement": 65.78082,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.79747,
            "nubia_score": 0.81436
        },
        "meteor": 0.32760228772354494,
        "bleurt": 0.09043,
        "bertscore": {
            "precision": 0.88478,
            "recall": 0.91729,
            "f1": 0.90041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9472807507835431,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 47.87975,
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        },
        "meteor": 0.4180407844493463,
        "bleurt": 0.78138,
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 11,
        "total_length": 145,
        "mean_pred_length": 13.181818181818182,
        "std_pred_length": 4.782889613805784,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 100,
        "unique-1": 78,
        "entropy-1": 6.3398928571400175,
        "distinct-2": 0.9477611940298507,
        "vocab_size-2": 127,
        "unique-2": 121,
        "entropy-2": 6.955978089695365,
        "cond_entropy-2": 0.40105859641068076,
        "distinct-3": 0.991869918699187,
        "vocab_size-3": 122,
        "unique-3": 121,
        "entropy-3": 6.926254342737602,
        "cond_entropy-3": -0.019876412743219996,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 11.727272727272727,
        "std_pred_length-nopunct": 4.4126040361860355,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7596899224806202,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.452010468699075,
        "distinct-2-nopunct": 0.9491525423728814,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.774550782394346,
        "cond_entropy-2-nopunct": 0.3661961158475202,
        "distinct-3-nopunct": 0.9906542056074766,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.722775397616091,
        "cond_entropy-3-nopunct": -0.050008890043278575,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.203097203750048,
        "rouge1": {
            "precision": 0.81515,
            "recall": 0.72174,
            "fmeasure": 0.75851
        },
        "rouge2": {
            "precision": 0.60812,
            "recall": 0.56578,
            "fmeasure": 0.58226
        },
        "rougeL": {
            "precision": 0.75584,
            "recall": 0.66936,
            "fmeasure": 0.70353
        },
        "rougeLsum": {
            "precision": 0.75584,
            "recall": 0.66936,
            "fmeasure": 0.70353
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.3684210526315789,
            "3": 0.7741935483870968
        },
        "bleu": 52.39996,
        "nubia": {
            "semantic_relation": 4.52802,
            "contradiction": 1.19694,
            "irrelevancy": 16.13232,
            "logical_agreement": 82.67074,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.62092,
            "nubia_score": 0.83533
        },
        "meteor": 0.42357562957129735,
        "bleurt": 0.45545,
        "bertscore": {
            "precision": 0.95391,
            "recall": 0.92985,
            "f1": 0.94079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.832427429188973,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.049274940679377,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.4844903834760599,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.07528329880449636,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.912782031835941,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.413977073182751,
        "cond_entropy-2-nopunct": 0.5623023567000139,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.821878492129439,
        "rouge1": {
            "precision": 0.75643,
            "recall": 0.83896,
            "fmeasure": 0.7887
        },
        "rouge2": {
            "precision": 0.52287,
            "recall": 0.59286,
            "fmeasure": 0.54991
        },
        "rougeL": {
            "precision": 0.70435,
            "recall": 0.78804,
            "fmeasure": 0.73723
        },
        "rougeLsum": {
            "precision": 0.70435,
            "recall": 0.78804,
            "fmeasure": 0.73723
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "bleu": 59.02314,
        "nubia": {
            "semantic_relation": 4.5381,
            "contradiction": 3.2895,
            "irrelevancy": 20.17913,
            "logical_agreement": 76.53138,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.2784,
            "nubia_score": 0.79426
        },
        "meteor": 0.46742296738925065,
        "bleurt": 0.5165,
        "bertscore": {
            "precision": 0.94723,
            "recall": 0.95846,
            "f1": 0.95104
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.048968687611256,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.05923165719793806,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4928857366752846,
        "rouge1": {
            "precision": 0.69017,
            "recall": 0.68772,
            "fmeasure": 0.67992
        },
        "rouge2": {
            "precision": 0.38258,
            "recall": 0.33333,
            "fmeasure": 0.35292
        },
        "rougeL": {
            "precision": 0.49893,
            "recall": 0.46784,
            "fmeasure": 0.47687
        },
        "rougeLsum": {
            "precision": 0.49893,
            "recall": 0.46784,
            "fmeasure": 0.47687
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "bleu": 41.81908,
        "nubia": {
            "semantic_relation": 4.25009,
            "contradiction": 0.4201,
            "irrelevancy": 1.0599,
            "logical_agreement": 98.52001,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.8868,
            "nubia_score": 0.80008
        },
        "meteor": 0.38727209589621453,
        "bleurt": 0.31757,
        "bertscore": {
            "precision": 0.92895,
            "recall": 0.91847,
            "f1": 0.92055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 7.399324293474371,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.7,
        "vocab_size-1": 35,
        "unique-1": 24,
        "entropy-1": 4.973660689688187,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 40,
        "unique-2": 34,
        "entropy-2": 5.26269239083962,
        "cond_entropy-2": 0.17339652724591725,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 38,
        "unique-3": 34,
        "entropy-3": 5.201841232302571,
        "cond_entropy-3": -0.08362548565920483,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 7.119515432949071,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7209302325581395,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.833014173206122,
        "distinct-2-nopunct": 0.8717948717948718,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.028991962451991,
        "cond_entropy-2-nopunct": 0.20554195145058457,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516393,
        "cond_entropy-3-nopunct": -0.09897634477442475,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6744508247029595,
        "rouge1": {
            "precision": 0.77627,
            "recall": 0.67504,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.53517,
            "recall": 0.4621,
            "fmeasure": 0.4892
        },
        "rougeL": {
            "precision": 0.71467,
            "recall": 0.61227,
            "fmeasure": 0.65209
        },
        "rougeLsum": {
            "precision": 0.71467,
            "recall": 0.61227,
            "fmeasure": 0.65209
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.725
        },
        "bleu": 51.73737,
        "nubia": {
            "semantic_relation": 4.68992,
            "contradiction": 0.54922,
            "irrelevancy": 1.43207,
            "logical_agreement": 98.01871,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.88723,
            "nubia_score": 0.90445
        },
        "meteor": 0.45058568918614617,
        "bleurt": 0.38773,
        "bertscore": {
            "precision": 0.93817,
            "recall": 0.92671,
            "f1": 0.93218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9631490819047652,
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.32479,
            "fmeasure": 0.41751
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.11111,
            "fmeasure": 0.11667
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.22507,
            "fmeasure": 0.28844
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.22507,
            "fmeasure": 0.28844
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 1.0,
            "3": 0.2857142857142857
        },
        "bleu": 11.47874,
        "nubia": {
            "semantic_relation": 2.12657,
            "contradiction": 17.41438,
            "irrelevancy": 46.10893,
            "logical_agreement": 36.47669,
            "grammar_ref": 4.13721,
            "grammar_hyp": 4.34121,
            "nubia_score": 0.17836
        },
        "meteor": 0.15983317722509083,
        "bleurt": -0.32549,
        "bertscore": {
            "precision": 0.87115,
            "recall": 0.82962,
            "f1": 0.84417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 81,
        "mean_pred_length": 27.0,
        "std_pred_length": 9.201449161228174,
        "median_pred_length": 21.0,
        "min_pred_length": 20,
        "max_pred_length": 40,
        "distinct-1": 0.5432098765432098,
        "vocab_size-1": 44,
        "unique-1": 21,
        "entropy-1": 5.211651509239509,
        "distinct-2": 0.7051282051282052,
        "vocab_size-2": 55,
        "unique-2": 32,
        "entropy-2": 5.69565862911866,
        "cond_entropy-2": 0.46643927345314506,
        "distinct-3": 0.7466666666666667,
        "vocab_size-3": 56,
        "unique-3": 37,
        "entropy-3": 5.72215202382922,
        "cond_entropy-3": 0.023416471633632502,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 9.201449161228174,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5694444444444444,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 5.105630689177162,
        "distinct-2-nopunct": 0.7101449275362319,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.528814311850629,
        "cond_entropy-2-nopunct": 0.44047178117775043,
        "distinct-3-nopunct": 0.7424242424242424,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.529242604206946,
        "cond_entropy-3-nopunct": 0.026778753489375338,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.242726717818016,
        "rouge1": {
            "precision": 0.62916,
            "recall": 0.66902,
            "fmeasure": 0.64488
        },
        "rouge2": {
            "precision": 0.39778,
            "recall": 0.41781,
            "fmeasure": 0.40489
        },
        "rougeL": {
            "precision": 0.46613,
            "recall": 0.48477,
            "fmeasure": 0.47243
        },
        "rougeLsum": {
            "precision": 0.46613,
            "recall": 0.48477,
            "fmeasure": 0.47243
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.5161290322580645,
            "3": 0.6
        },
        "bleu": 25.46752,
        "nubia": {
            "semantic_relation": 3.84153,
            "contradiction": 5.51211,
            "irrelevancy": 70.24273,
            "logical_agreement": 24.24516,
            "grammar_ref": 3.62435,
            "grammar_hyp": 2.89404,
            "nubia_score": 0.77985
        },
        "meteor": 0.2926429719911667,
        "bleurt": -0.09629,
        "bertscore": {
            "precision": 0.87717,
            "recall": 0.87299,
            "f1": 0.87493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 42,
        "unique-1": 36,
        "entropy-1": 5.201659669183334,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.3708597119406494,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.04579617458367275,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 3.8586123009300755,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.142885038426153,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.3679698397410164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.050785573447938395,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.683188030707617,
        "rouge1": {
            "precision": 0.69196,
            "recall": 0.73687,
            "fmeasure": 0.7127
        },
        "rouge2": {
            "precision": 0.4403,
            "recall": 0.46741,
            "fmeasure": 0.4527
        },
        "rougeL": {
            "precision": 0.61298,
            "recall": 0.65609,
            "fmeasure": 0.63285
        },
        "rougeLsum": {
            "precision": 0.61298,
            "recall": 0.65609,
            "fmeasure": 0.63285
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7692307692307693,
            "3": 0.6666666666666666
        },
        "bleu": 45.66706,
        "nubia": {
            "semantic_relation": 4.25128,
            "contradiction": 0.53909,
            "irrelevancy": 66.79996,
            "logical_agreement": 32.66095,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.28066,
            "nubia_score": 0.75705
        },
        "meteor": 0.4246193957581606,
        "bleurt": 0.29735,
        "bertscore": {
            "precision": 0.91387,
            "recall": 0.94216,
            "f1": 0.92715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0756477005806677,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.7875,
            "fmeasure": 0.73889
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.50794,
            "fmeasure": 0.47222
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.675,
            "fmeasure": 0.63333
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.675,
            "fmeasure": 0.63333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.875
        },
        "bleu": 24.71244,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23178,
            "irrelevancy": 0.42974,
            "logical_agreement": 99.33848,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.23077,
            "nubia_score": 1.0
        },
        "meteor": 0.410497365800436,
        "bleurt": 0.60936,
        "bertscore": {
            "precision": 0.91191,
            "recall": 0.96118,
            "f1": 0.9335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22626,
            "irrelevancy": 0.50857,
            "logical_agreement": 99.26518,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.34196,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.92451,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.8043478260869565,
        "vocab_size-1": 37,
        "unique-1": 32,
        "entropy-1": 5.055958151615121,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 41,
        "unique-2": 39,
        "entropy-2": 5.333241498888144,
        "cond_entropy-2": 0.19932808939307267,
        "distinct-3": 0.975,
        "vocab_size-3": 39,
        "unique-3": 38,
        "entropy-3": 5.271928094887364,
        "cond_entropy-3": -0.054336659814735816,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.993391529870108,
        "distinct-2-nopunct": 0.9487179487179487,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.182838116298145,
        "cond_entropy-2-nopunct": 0.2201331935748593,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": -0.05992166186438031,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0221834647871795,
        "rouge1": {
            "precision": 0.73569,
            "recall": 0.59129,
            "fmeasure": 0.64093
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.29697,
            "fmeasure": 0.32163
        },
        "rougeL": {
            "precision": 0.51633,
            "recall": 0.42656,
            "fmeasure": 0.45811
        },
        "rougeLsum": {
            "precision": 0.51633,
            "recall": 0.42656,
            "fmeasure": 0.45811
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5714285714285714,
            "3": 0.6818181818181818
        },
        "bleu": 32.6086,
        "nubia": {
            "semantic_relation": 3.65259,
            "contradiction": 22.27609,
            "irrelevancy": 44.51999,
            "logical_agreement": 33.20392,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.90574,
            "nubia_score": 0.5687
        },
        "meteor": 0.31353467104464555,
        "bleurt": 0.07329,
        "bertscore": {
            "precision": 0.90986,
            "recall": 0.87014,
            "f1": 0.889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3464372969835736,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.45455,
            "fmeasure": 0.47368
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.12857,
            "fmeasure": 0.13445
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.45455,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.45455,
            "fmeasure": 0.47368
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 7.80985,
        "nubia": {
            "semantic_relation": 3.26669,
            "contradiction": 1.03904,
            "irrelevancy": 97.20069,
            "logical_agreement": 1.76027,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.27052,
            "nubia_score": 0.51455
        },
        "meteor": 0.147239263803681,
        "bleurt": -0.10263,
        "bertscore": {
            "precision": 0.80266,
            "recall": 0.81488,
            "f1": 0.80872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 98,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 5.280993172584953,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6836734693877551,
        "vocab_size-1": 67,
        "unique-1": 53,
        "entropy-1": 5.75114667592041,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 88,
        "unique-2": 84,
        "entropy-2": 6.436605434317895,
        "cond_entropy-2": 0.5731935845370626,
        "distinct-3": 0.9651162790697675,
        "vocab_size-3": 83,
        "unique-3": 80,
        "entropy-3": 6.3564973128416336,
        "cond_entropy-3": -0.09729720135491499,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.358898943540674,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7380952380952381,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.673692089723994,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.208479141939177,
        "cond_entropy-2-nopunct": 0.5516043855270814,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.11436944588676,
        "cond_entropy-3-nopunct": -0.11547721741993579,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.468105749542146,
        "rouge1": {
            "precision": 0.8032,
            "recall": 0.63063,
            "fmeasure": 0.70195
        },
        "rouge2": {
            "precision": 0.6101,
            "recall": 0.47824,
            "fmeasure": 0.53256
        },
        "rougeL": {
            "precision": 0.71614,
            "recall": 0.56464,
            "fmeasure": 0.62758
        },
        "rougeLsum": {
            "precision": 0.71614,
            "recall": 0.56464,
            "fmeasure": 0.62758
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.6410256410256411
        },
        "bleu": 41.95814,
        "nubia": {
            "semantic_relation": 3.88399,
            "contradiction": 0.32396,
            "irrelevancy": 17.53255,
            "logical_agreement": 82.14349,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.21794,
            "nubia_score": 0.6657
        },
        "meteor": 0.3700651398490027,
        "bleurt": 0.12353,
        "bertscore": {
            "precision": 0.92843,
            "recall": 0.88135,
            "f1": 0.90326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 100,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7,
        "vocab_size-1": 70,
        "unique-1": 58,
        "entropy-1": 5.810015409922192,
        "distinct-2": 0.9347826086956522,
        "vocab_size-2": 86,
        "unique-2": 82,
        "entropy-2": 6.376716575575211,
        "cond_entropy-2": 0.37833949433584485,
        "distinct-3": 0.9761904761904762,
        "vocab_size-3": 82,
        "unique-3": 81,
        "entropy-3": 6.335711619181575,
        "cond_entropy-3": -0.027019682062020715,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.598076211353316,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.807339823350323,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.15305590733327,
        "cond_entropy-2-nopunct": 0.3859252635116549,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.103884897245603,
        "cond_entropy-3-nopunct": -0.05818521147055712,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.813080316095297,
        "rouge1": {
            "precision": 0.80272,
            "recall": 0.69082,
            "fmeasure": 0.73623
        },
        "rouge2": {
            "precision": 0.5254,
            "recall": 0.47047,
            "fmeasure": 0.49203
        },
        "rougeL": {
            "precision": 0.69757,
            "recall": 0.60547,
            "fmeasure": 0.64265
        },
        "rougeLsum": {
            "precision": 0.69757,
            "recall": 0.60547,
            "fmeasure": 0.64265
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.34285714285714286,
            "3": 0.8405797101449275
        },
        "bleu": 45.56972,
        "nubia": {
            "semantic_relation": 4.21914,
            "contradiction": 24.33524,
            "irrelevancy": 16.92181,
            "logical_agreement": 58.74296,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.44284,
            "nubia_score": 0.74516
        },
        "meteor": 0.40640384717108013,
        "bleurt": 0.28868,
        "bertscore": {
            "precision": 0.93182,
            "recall": 0.92401,
            "f1": 0.92707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 104,
        "mean_pred_length": 20.8,
        "std_pred_length": 11.617228585166085,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 60,
        "unique-1": 42,
        "entropy-1": 5.441050470649644,
        "distinct-2": 0.8787878787878788,
        "vocab_size-2": 87,
        "unique-2": 77,
        "entropy-2": 6.371682125086418,
        "cond_entropy-2": 0.8769680762854591,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 88,
        "unique-3": 82,
        "entropy-3": 6.426929277209539,
        "cond_entropy-3": 0.06895324228235683,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 18.8,
        "std_pred_length-nopunct": 10.533755265810955,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6170212765957447,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.408235651781488,
        "distinct-2-nopunct": 0.8764044943820225,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.211578655636892,
        "cond_entropy-2-nopunct": 0.8452729589057322,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.2494602799216175,
        "cond_entropy-3-nopunct": 0.04170036091149276,
        "msttr-100": 0.59,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.743425233923866,
        "rouge1": {
            "precision": 0.82535,
            "recall": 0.80059,
            "fmeasure": 0.80228
        },
        "rouge2": {
            "precision": 0.63163,
            "recall": 0.63473,
            "fmeasure": 0.62621
        },
        "rougeL": {
            "precision": 0.74861,
            "recall": 0.71845,
            "fmeasure": 0.72315
        },
        "rougeLsum": {
            "precision": 0.74861,
            "recall": 0.71845,
            "fmeasure": 0.72315
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5714285714285714,
            "3": 0.8412698412698413
        },
        "bleu": 58.70758,
        "nubia": {
            "semantic_relation": 4.26453,
            "contradiction": 3.1771,
            "irrelevancy": 39.1159,
            "logical_agreement": 57.707,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.28849,
            "nubia_score": 0.75573
        },
        "meteor": 0.45787013983570274,
        "bleurt": 0.17607,
        "bertscore": {
            "precision": 0.95235,
            "recall": 0.94523,
            "f1": 0.94718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 17,
        "total_length": 291,
        "mean_pred_length": 17.11764705882353,
        "std_pred_length": 5.645220288945919,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5979381443298969,
        "vocab_size-1": 174,
        "unique-1": 141,
        "entropy-1": 6.733968410490479,
        "distinct-2": 0.9014598540145985,
        "vocab_size-2": 247,
        "unique-2": 230,
        "entropy-2": 7.855673061221193,
        "cond_entropy-2": 0.9435756005045431,
        "distinct-3": 0.9727626459143969,
        "vocab_size-3": 250,
        "unique-3": 243,
        "entropy-3": 7.9511498410226995,
        "cond_entropy-3": 0.11150831042232635,
        "total_length-nopunct": 254,
        "mean_pred_length-nopunct": 14.941176470588236,
        "std_pred_length-nopunct": 5.011405676176204,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6692913385826772,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 141,
        "entropy-1-nopunct": 6.871875084016233,
        "distinct-2-nopunct": 0.8987341772151899,
        "vocab_size-2-nopunct": 213,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.633864042330504,
        "cond_entropy-2-nopunct": 0.8252200268663202,
        "distinct-3-nopunct": 0.9727272727272728,
        "vocab_size-3-nopunct": 214,
        "unique-3-nopunct": 208,
        "entropy-3-nopunct": 7.726814258979191,
        "cond_entropy-3-nopunct": 0.10355451897443095,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.604205774235954,
        "rouge1": {
            "precision": 0.7617,
            "recall": 0.69365,
            "fmeasure": 0.71424
        },
        "rouge2": {
            "precision": 0.55033,
            "recall": 0.49523,
            "fmeasure": 0.51164
        },
        "rougeL": {
            "precision": 0.68352,
            "recall": 0.61936,
            "fmeasure": 0.63794
        },
        "rougeLsum": {
            "precision": 0.68352,
            "recall": 0.61936,
            "fmeasure": 0.63794
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3764705882352941,
            "3": 0.7049180327868853
        },
        "bleu": 42.33077,
        "nubia": {
            "semantic_relation": 4.06159,
            "contradiction": 4.11574,
            "irrelevancy": 31.15714,
            "logical_agreement": 64.72712,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.29547,
            "nubia_score": 0.70042
        },
        "meteor": 0.3669228461301484,
        "bleurt": 0.19167,
        "bertscore": {
            "precision": 0.92685,
            "recall": 0.91833,
            "f1": 0.92143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 15,
        "total_length": 224,
        "mean_pred_length": 14.933333333333334,
        "std_pred_length": 5.0789325212642416,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6607142857142857,
        "vocab_size-1": 148,
        "unique-1": 122,
        "entropy-1": 6.720815710571058,
        "distinct-2": 0.9569377990430622,
        "vocab_size-2": 200,
        "unique-2": 193,
        "entropy-2": 7.61401092631857,
        "cond_entropy-2": 0.6907776522937389,
        "distinct-3": 1.0,
        "vocab_size-3": 194,
        "unique-3": 194,
        "entropy-3": 7.599912842187102,
        "cond_entropy-3": -0.017189717706502797,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 13.266666666666667,
        "std_pred_length-nopunct": 4.567518168789504,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7185929648241206,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.7865151533857855,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 176,
        "unique-2-nopunct": 170,
        "entropy-2-nopunct": 7.428400135381336,
        "cond_entropy-2-nopunct": 0.6830899657234017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 169,
        "unique-3-nopunct": 169,
        "entropy-3-nopunct": 7.400879436282176,
        "cond_entropy-3-nopunct": -0.01907438365455095,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.636535854329644,
        "rouge1": {
            "precision": 0.82785,
            "recall": 0.80753,
            "fmeasure": 0.8105
        },
        "rouge2": {
            "precision": 0.64169,
            "recall": 0.60453,
            "fmeasure": 0.61596
        },
        "rougeL": {
            "precision": 0.72012,
            "recall": 0.69217,
            "fmeasure": 0.69997
        },
        "rougeLsum": {
            "precision": 0.72012,
            "recall": 0.69217,
            "fmeasure": 0.69997
        },
        "local_recall": {
            "1": 0.3191489361702128,
            "2": 0.37037037037037035,
            "3": 0.8580645161290322
        },
        "bleu": 56.45609,
        "nubia": {
            "semantic_relation": 4.44685,
            "contradiction": 9.35763,
            "irrelevancy": 22.39268,
            "logical_agreement": 68.24969,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.62123,
            "nubia_score": 0.81222
        },
        "meteor": 0.46562422661734537,
        "bleurt": 0.27956,
        "bertscore": {
            "precision": 0.95338,
            "recall": 0.95224,
            "f1": 0.95134
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 25,
        "mean_pred_length": 8.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 13,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.453660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.1844245711374276,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.21150410519371154,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.22239242133644796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.2630344058337938,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.884382501609796,
        "rouge1": {
            "precision": 0.80606,
            "recall": 0.66081,
            "fmeasure": 0.71303
        },
        "rouge2": {
            "precision": 0.62778,
            "recall": 0.51058,
            "fmeasure": 0.54975
        },
        "rougeL": {
            "precision": 0.80606,
            "recall": 0.66081,
            "fmeasure": 0.71303
        },
        "rougeLsum": {
            "precision": 0.80606,
            "recall": 0.66081,
            "fmeasure": 0.71303
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.7272727272727273
        },
        "bleu": 44.29288,
        "nubia": {
            "semantic_relation": 3.5678,
            "contradiction": 16.88677,
            "irrelevancy": 46.81404,
            "logical_agreement": 36.29919,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.50219,
            "nubia_score": 0.48759
        },
        "meteor": 0.35149931728215383,
        "bleurt": 0.02927,
        "bertscore": {
            "precision": 0.93919,
            "recall": 0.90822,
            "f1": 0.92264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.019249213048515,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.42857,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.24603,
            "fmeasure": 0.29132
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.28139,
            "fmeasure": 0.33033
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.28139,
            "fmeasure": 0.33033
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4666666666666667
        },
        "bleu": 15.28933,
        "nubia": {
            "semantic_relation": 2.87172,
            "contradiction": 95.5915,
            "irrelevancy": 4.01718,
            "logical_agreement": 0.39131,
            "grammar_ref": 3.42286,
            "grammar_hyp": 5.27822,
            "nubia_score": 0.21705
        },
        "meteor": 0.2589617573644575,
        "bleurt": -0.13523,
        "bertscore": {
            "precision": 0.88196,
            "recall": 0.81766,
            "f1": 0.84859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 29,
        "total_length": 497,
        "mean_pred_length": 17.137931034482758,
        "std_pred_length": 6.072686946802415,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 40,
        "distinct-1": 0.5492957746478874,
        "vocab_size-1": 273,
        "unique-1": 213,
        "entropy-1": 7.279293101713813,
        "distinct-2": 0.9017094017094017,
        "vocab_size-2": 422,
        "unique-2": 395,
        "entropy-2": 8.620288731464472,
        "cond_entropy-2": 1.1439336861543619,
        "distinct-3": 0.9703872437357631,
        "vocab_size-3": 426,
        "unique-3": 415,
        "entropy-3": 8.715412493990128,
        "cond_entropy-3": 0.111643588620132,
        "total_length-nopunct": 429,
        "mean_pred_length-nopunct": 14.793103448275861,
        "std_pred_length-nopunct": 4.908678523937723,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.62004662004662,
        "vocab_size-1-nopunct": 266,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.463578019094955,
        "distinct-2-nopunct": 0.9025,
        "vocab_size-2-nopunct": 361,
        "unique-2-nopunct": 339,
        "entropy-2-nopunct": 8.390041721186416,
        "cond_entropy-2-nopunct": 1.0068547489258068,
        "distinct-3-nopunct": 0.9784366576819407,
        "vocab_size-3-nopunct": 363,
        "unique-3-nopunct": 355,
        "entropy-3-nopunct": 8.492148691984617,
        "cond_entropy-3-nopunct": 0.11925149799252102,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.7775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.834508810328007,
        "rouge1": {
            "precision": 0.82605,
            "recall": 0.81387,
            "fmeasure": 0.80775
        },
        "rouge2": {
            "precision": 0.63762,
            "recall": 0.63494,
            "fmeasure": 0.62835
        },
        "rougeL": {
            "precision": 0.74572,
            "recall": 0.72815,
            "fmeasure": 0.72592
        },
        "rougeLsum": {
            "precision": 0.74572,
            "recall": 0.72815,
            "fmeasure": 0.72592
        },
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.47761194029850745,
            "3": 0.8200589970501475
        },
        "bleu": 52.78601,
        "nubia": {
            "semantic_relation": 4.2988,
            "contradiction": 13.3085,
            "irrelevancy": 21.69819,
            "logical_agreement": 64.99332,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.68794,
            "nubia_score": 0.75887
        },
        "meteor": 0.4336433467400402,
        "bleurt": 0.46986,
        "bertscore": {
            "precision": 0.9494,
            "recall": 0.94537,
            "f1": 0.94634
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 113,
        "mean_pred_length": 14.125,
        "std_pred_length": 5.622221536012255,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.7079646017699115,
        "vocab_size-1": 80,
        "unique-1": 63,
        "entropy-1": 6.04575617476629,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 99,
        "unique-2": 93,
        "entropy-2": 6.599959803380399,
        "cond_entropy-2": 0.3846358410064294,
        "distinct-3": 0.9690721649484536,
        "vocab_size-3": 94,
        "unique-3": 91,
        "entropy-3": 6.5380571720840495,
        "cond_entropy-3": -0.052477005375902025,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 4.575751304430781,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.12491392574787,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.35851976299633,
        "cond_entropy-2-nopunct": 0.27714325221446634,
        "distinct-3-nopunct": 0.9634146341463414,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.28438127291077,
        "cond_entropy-3-nopunct": -0.0611303600042741,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.925429971656866,
        "rouge1": {
            "precision": 0.96264,
            "recall": 0.85547,
            "fmeasure": 0.89805
        },
        "rouge2": {
            "precision": 0.88393,
            "recall": 0.79895,
            "fmeasure": 0.83229
        },
        "rougeL": {
            "precision": 0.91508,
            "recall": 0.82589,
            "fmeasure": 0.86169
        },
        "rougeLsum": {
            "precision": 0.91508,
            "recall": 0.82589,
            "fmeasure": 0.86169
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8679245283018868
        },
        "bleu": 70.71262,
        "nubia": {
            "semantic_relation": 4.43782,
            "contradiction": 3.94895,
            "irrelevancy": 1.15936,
            "logical_agreement": 94.89169,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.26201,
            "nubia_score": 0.80411
        },
        "meteor": 0.5147714831256434,
        "bleurt": 0.6626,
        "bertscore": {
            "precision": 0.98242,
            "recall": 0.9528,
            "f1": 0.9667
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7910011142063147,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "bleu": 33.40891,
        "nubia": {
            "semantic_relation": 4.98459,
            "contradiction": 0.13212,
            "irrelevancy": 0.41925,
            "logical_agreement": 99.44863,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.453,
            "nubia_score": 0.98464
        },
        "meteor": 0.424582730950162,
        "bleurt": 0.50996,
        "bertscore": {
            "precision": 0.96668,
            "recall": 0.9373,
            "f1": 0.95176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.41829583405449,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.03462179117476817,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4393043493516706,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.70244,
            "fmeasure": 0.78144
        },
        "rouge2": {
            "precision": 0.80357,
            "recall": 0.60027,
            "fmeasure": 0.67024
        },
        "rougeL": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "rougeLsum": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bleu": 56.08087,
        "nubia": {
            "semantic_relation": 4.36892,
            "contradiction": 0.38357,
            "irrelevancy": 0.5779,
            "logical_agreement": 99.03854,
            "grammar_ref": 5.26806,
            "grammar_hyp": 5.12533,
            "nubia_score": 0.76865
        },
        "meteor": 0.4071117545172738,
        "bleurt": 0.47935,
        "bertscore": {
            "precision": 0.9814,
            "recall": 0.93225,
            "f1": 0.95555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 108,
        "mean_pred_length": 21.6,
        "std_pred_length": 14.60958589419974,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 48,
        "distinct-1": 0.6481481481481481,
        "vocab_size-1": 70,
        "unique-1": 55,
        "entropy-1": 5.764204923832991,
        "distinct-2": 0.9029126213592233,
        "vocab_size-2": 93,
        "unique-2": 84,
        "entropy-2": 6.484996765026302,
        "cond_entropy-2": 0.6561682724283985,
        "distinct-3": 0.9387755102040817,
        "vocab_size-3": 92,
        "unique-3": 86,
        "entropy-3": 6.492260864523377,
        "cond_entropy-3": -0.002863259576546152,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 16.8,
        "std_pred_length-nopunct": 10.146920715172657,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.764283047753005,
        "distinct-2-nopunct": 0.9493670886075949,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.202514925392294,
        "cond_entropy-2-nopunct": 0.47798088871686806,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.155399311574901,
        "cond_entropy-3-nopunct": -0.04027332849409911,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.839504320762937,
        "rouge1": {
            "precision": 0.8956,
            "recall": 0.79577,
            "fmeasure": 0.83954
        },
        "rouge2": {
            "precision": 0.70756,
            "recall": 0.63928,
            "fmeasure": 0.66935
        },
        "rougeL": {
            "precision": 0.68291,
            "recall": 0.62493,
            "fmeasure": 0.64954
        },
        "rougeLsum": {
            "precision": 0.68291,
            "recall": 0.62493,
            "fmeasure": 0.64954
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25,
            "3": 0.8441558441558441
        },
        "bleu": 62.67769,
        "nubia": {
            "semantic_relation": 4.48985,
            "contradiction": 21.8101,
            "irrelevancy": 4.44468,
            "logical_agreement": 73.74521,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.55872,
            "nubia_score": 0.85798
        },
        "meteor": 0.4730832276258785,
        "bleurt": 0.51153,
        "bertscore": {
            "precision": 0.96742,
            "recall": 0.95362,
            "f1": 0.95975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.04505465518404473,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.04896868761125602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.594973079092027,
        "rouge1": {
            "precision": 0.75801,
            "recall": 0.73568,
            "fmeasure": 0.73508
        },
        "rouge2": {
            "precision": 0.60556,
            "recall": 0.51349,
            "fmeasure": 0.55305
        },
        "rougeL": {
            "precision": 0.69551,
            "recall": 0.6592,
            "fmeasure": 0.66768
        },
        "rougeLsum": {
            "precision": 0.69551,
            "recall": 0.6592,
            "fmeasure": 0.66768
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "bleu": 59.99867,
        "nubia": {
            "semantic_relation": 3.62994,
            "contradiction": 46.96511,
            "irrelevancy": 10.69926,
            "logical_agreement": 42.33564,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.09383,
            "nubia_score": 0.55521
        },
        "meteor": 0.40864234246403003,
        "bleurt": 0.1709,
        "bertscore": {
            "precision": 0.94246,
            "recall": 0.94321,
            "f1": 0.93765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7913310434313825,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.55,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 59.11603,
        "nubia": {
            "semantic_relation": 4.0584,
            "contradiction": 0.41127,
            "irrelevancy": 35.16538,
            "logical_agreement": 64.42336,
            "grammar_ref": 4.09688,
            "grammar_hyp": 4.65525,
            "nubia_score": 0.68652
        },
        "meteor": 0.5566661162140665,
        "bleurt": 0.29208,
        "bertscore": {
            "precision": 0.96286,
            "recall": 0.94809,
            "f1": 0.95542
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.7648576597402945,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.24101678429722817,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.593069207771891,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.12385402685271857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4683107042797463,
        "rouge1": {
            "precision": 0.56275,
            "recall": 0.69933,
            "fmeasure": 0.62256
        },
        "rouge2": {
            "precision": 0.27679,
            "recall": 0.37238,
            "fmeasure": 0.31432
        },
        "rougeL": {
            "precision": 0.45425,
            "recall": 0.57692,
            "fmeasure": 0.50728
        },
        "rougeLsum": {
            "precision": 0.45425,
            "recall": 0.57692,
            "fmeasure": 0.50728
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "bleu": 11.45374,
        "nubia": {
            "semantic_relation": 4.08717,
            "contradiction": 31.19902,
            "irrelevancy": 43.83007,
            "logical_agreement": 24.97091,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.04477,
            "nubia_score": 0.72464
        },
        "meteor": 0.36782773853421347,
        "bleurt": -0.11855,
        "bertscore": {
            "precision": 0.84892,
            "recall": 0.92341,
            "f1": 0.88207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.0,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.947702779220088,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.0249628412503394,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": -0.02810710212234293,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2598504287078605,
        "rouge1": {
            "precision": 0.89167,
            "recall": 0.84552,
            "fmeasure": 0.86711
        },
        "rouge2": {
            "precision": 0.78947,
            "recall": 0.75794,
            "fmeasure": 0.77276
        },
        "rougeL": {
            "precision": 0.71667,
            "recall": 0.67805,
            "fmeasure": 0.69509
        },
        "rougeLsum": {
            "precision": 0.71667,
            "recall": 0.67805,
            "fmeasure": 0.69509
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8461538461538461
        },
        "bleu": 57.78802,
        "nubia": {
            "semantic_relation": 4.28956,
            "contradiction": 37.47916,
            "irrelevancy": 2.65042,
            "logical_agreement": 59.87043,
            "grammar_ref": 4.36539,
            "grammar_hyp": 5.00288,
            "nubia_score": 0.70328
        },
        "meteor": 0.4355803344686153,
        "bleurt": 0.10981,
        "bertscore": {
            "precision": 0.92841,
            "recall": 0.92677,
            "f1": 0.92759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9778957842950224,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.31746,
            "fmeasure": 0.30556
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bleu": 22.82484,
        "nubia": {
            "semantic_relation": 4.17196,
            "contradiction": 0.3361,
            "irrelevancy": 10.00749,
            "logical_agreement": 89.65641,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.16124,
            "nubia_score": 0.75011
        },
        "meteor": 0.34272262745996446,
        "bleurt": 0.41278,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.92079,
            "f1": 0.91622
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 7.632168761236874,
        "median_pred_length": 19.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 52,
        "unique-1": 39,
        "entropy-1": 5.464030940510979,
        "distinct-2": 0.9571428571428572,
        "vocab_size-2": 67,
        "unique-2": 64,
        "entropy-2": 6.043568731230686,
        "cond_entropy-2": 0.5078476435835907,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 64,
        "unique-3": 62,
        "entropy-3": 5.983788058752401,
        "cond_entropy-3": -0.054585867283482976,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 7.8859051477937525,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.746268656716418,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.433158265732894,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.8820418282618245,
        "cond_entropy-2-nopunct": 0.4731966371146316,
        "distinct-3-nopunct": 0.9661016949152542,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.814846439192345,
        "cond_entropy-3-nopunct": -0.06073856905332946,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.439627947811586,
        "rouge1": {
            "precision": 0.79127,
            "recall": 0.71186,
            "fmeasure": 0.73762
        },
        "rouge2": {
            "precision": 0.49255,
            "recall": 0.43824,
            "fmeasure": 0.4568
        },
        "rougeL": {
            "precision": 0.67692,
            "recall": 0.58703,
            "fmeasure": 0.61828
        },
        "rougeLsum": {
            "precision": 0.67692,
            "recall": 0.58703,
            "fmeasure": 0.61828
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.7090909090909091
        },
        "bleu": 25.71778,
        "nubia": {
            "semantic_relation": 4.15726,
            "contradiction": 0.93112,
            "irrelevancy": 49.07031,
            "logical_agreement": 49.99857,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.495,
            "nubia_score": 0.7216
        },
        "meteor": 0.3501317021379741,
        "bleurt": 0.0286,
        "bertscore": {
            "precision": 0.9213,
            "recall": 0.89829,
            "f1": 0.90915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 7.648529270389178,
        "median_pred_length": 7.5,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.050340709546386,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.062496476250065006,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 5.958187643906492,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.003258334775643,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": -0.04492500144231238,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.1926450779423958,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8654156850753525,
        "rouge1": {
            "precision": 0.62659,
            "recall": 0.41982,
            "fmeasure": 0.48124
        },
        "rouge2": {
            "precision": 0.34444,
            "recall": 0.24281,
            "fmeasure": 0.25712
        },
        "rougeL": {
            "precision": 0.55714,
            "recall": 0.40475,
            "fmeasure": 0.43773
        },
        "rougeLsum": {
            "precision": 0.55714,
            "recall": 0.40475,
            "fmeasure": 0.43773
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.15789473684210525,
            "3": 0.75
        },
        "bleu": 36.49195,
        "nubia": {
            "semantic_relation": 3.6476,
            "contradiction": 23.15616,
            "irrelevancy": 26.63546,
            "logical_agreement": 50.20838,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.65335,
            "nubia_score": 0.51946
        },
        "meteor": 0.27645018838526825,
        "bleurt": -0.11379,
        "bertscore": {
            "precision": 0.85914,
            "recall": 0.82954,
            "f1": 0.83405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.01117167855772,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "meteor": 1.0,
        "bleurt": 0.77386,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.0615528128088303,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 44,
        "unique-1": 34,
        "entropy-1": 5.306256857196536,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 50,
        "unique-2": 46,
        "entropy-2": 5.606739354015319,
        "cond_entropy-2": 0.19320280333219297,
        "distinct-3": 0.96,
        "vocab_size-3": 48,
        "unique-3": 46,
        "entropy-3": 5.563856189774728,
        "cond_entropy-3": -0.031031312388743997,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7924528301886793,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.275090265883954,
        "distinct-2-nopunct": 0.9183673469387755,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.45144453799276,
        "cond_entropy-2-nopunct": 0.2133200017969072,
        "distinct-3-nopunct": 0.9555555555555556,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.402964207440784,
        "cond_entropy-3-nopunct": -0.03396785889664477,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.28629452687131,
        "rouge1": {
            "precision": 0.78251,
            "recall": 0.75699,
            "fmeasure": 0.76805
        },
        "rouge2": {
            "precision": 0.62714,
            "recall": 0.59915,
            "fmeasure": 0.61111
        },
        "rougeL": {
            "precision": 0.73489,
            "recall": 0.70804,
            "fmeasure": 0.71966
        },
        "rougeLsum": {
            "precision": 0.73489,
            "recall": 0.70804,
            "fmeasure": 0.71966
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4444444444444444,
            "3": 0.782608695652174
        },
        "bleu": 64.14556,
        "nubia": {
            "semantic_relation": 4.36706,
            "contradiction": 25.1223,
            "irrelevancy": 0.6652,
            "logical_agreement": 74.2125,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.21981,
            "nubia_score": 0.83995
        },
        "meteor": 0.45461918897196046,
        "bleurt": 0.42796,
        "bertscore": {
            "precision": 0.95298,
            "recall": 0.94778,
            "f1": 0.94795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5384477168423927,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.67879,
            "fmeasure": 0.62714
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.42963,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bleu": 16.54462,
        "nubia": {
            "semantic_relation": 3.96046,
            "contradiction": 0.1618,
            "irrelevancy": 1.06129,
            "logical_agreement": 98.77691,
            "grammar_ref": 5.84412,
            "grammar_hyp": 5.77311,
            "nubia_score": 0.62235
        },
        "meteor": 0.3568330242611599,
        "bleurt": 0.00366,
        "bertscore": {
            "precision": 0.9176,
            "recall": 0.9421,
            "f1": 0.92969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.598076211353316,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.158562939644919,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.23328538598860132,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8837209302325582,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.15859556855496,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.15425990016853336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.15611920191728196,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.562759700991858,
        "rouge1": {
            "precision": 0.75048,
            "recall": 0.78845,
            "fmeasure": 0.75915
        },
        "rouge2": {
            "precision": 0.50645,
            "recall": 0.56724,
            "fmeasure": 0.52828
        },
        "rougeL": {
            "precision": 0.67917,
            "recall": 0.73352,
            "fmeasure": 0.69772
        },
        "rougeLsum": {
            "precision": 0.67917,
            "recall": 0.73352,
            "fmeasure": 0.69772
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.6875,
            "3": 0.8095238095238095
        },
        "bleu": 46.44192,
        "nubia": {
            "semantic_relation": 3.8777,
            "contradiction": 8.68423,
            "irrelevancy": 50.36048,
            "logical_agreement": 40.95529,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.4244,
            "nubia_score": 0.53105
        },
        "meteor": 0.3995576221190216,
        "bleurt": 0.17923,
        "bertscore": {
            "precision": 0.9203,
            "recall": 0.93015,
            "f1": 0.92436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.673642355475211,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 78.56293,
        "nubia": {
            "semantic_relation": 4.7361,
            "contradiction": 0.20205,
            "irrelevancy": 0.47436,
            "logical_agreement": 99.32359,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.27871,
            "nubia_score": 0.91305
        },
        "meteor": 0.5124329313818176,
        "bleurt": 0.6799,
        "bertscore": {
            "precision": 0.97641,
            "recall": 0.96546,
            "f1": 0.96962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 74,
        "mean_pred_length": 14.8,
        "std_pred_length": 4.261455150532504,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6891891891891891,
        "vocab_size-1": 51,
        "unique-1": 40,
        "entropy-1": 5.388224988153723,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 66,
        "unique-2": 63,
        "entropy-2": 6.021567935039033,
        "cond_entropy-2": 0.4894207335097838,
        "distinct-3": 0.984375,
        "vocab_size-3": 63,
        "unique-3": 62,
        "entropy-3": 5.96875,
        "cond_entropy-3": -0.04602445677816912,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 3.867815921162743,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.388759133144316,
        "distinct-2-nopunct": 0.9661016949152542,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.814846439192345,
        "cond_entropy-2-nopunct": 0.46093822696800657,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.71785046512643,
        "cond_entropy-3-nopunct": -0.09071851016133552,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.663598320731221,
        "rouge1": {
            "precision": 0.80106,
            "recall": 0.76546,
            "fmeasure": 0.77372
        },
        "rouge2": {
            "precision": 0.60826,
            "recall": 0.57987,
            "fmeasure": 0.5857
        },
        "rougeL": {
            "precision": 0.7273,
            "recall": 0.66638,
            "fmeasure": 0.68453
        },
        "rougeLsum": {
            "precision": 0.7273,
            "recall": 0.66638,
            "fmeasure": 0.68453
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.125,
            "3": 0.75
        },
        "bleu": 41.76419,
        "nubia": {
            "semantic_relation": 4.34896,
            "contradiction": 4.7703,
            "irrelevancy": 23.65296,
            "logical_agreement": 71.57674,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.44696,
            "nubia_score": 0.78316
        },
        "meteor": 0.3865358859741636,
        "bleurt": 0.2896,
        "bertscore": {
            "precision": 0.95226,
            "recall": 0.93236,
            "f1": 0.94136
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 119,
        "mean_pred_length": 14.875,
        "std_pred_length": 3.4072532926097527,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7394957983193278,
        "vocab_size-1": 88,
        "unique-1": 75,
        "entropy-1": 6.173184965148891,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 108,
        "unique-2": 105,
        "entropy-2": 6.740361812296067,
        "cond_entropy-2": 0.40297020196943517,
        "distinct-3": 0.9902912621359223,
        "vocab_size-3": 102,
        "unique-3": 101,
        "entropy-3": 6.667083051455081,
        "cond_entropy-3": -0.06908038771057683,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 3.018174116912409,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.2011569178477615,
        "distinct-2-nopunct": 0.9690721649484536,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.538057172084049,
        "cond_entropy-2-nopunct": 0.3689075614377807,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.453261520854051,
        "cond_entropy-3-nopunct": -0.09047154605219067,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.143355261995462,
        "rouge1": {
            "precision": 0.69369,
            "recall": 0.70973,
            "fmeasure": 0.69304
        },
        "rouge2": {
            "precision": 0.44961,
            "recall": 0.46033,
            "fmeasure": 0.44748
        },
        "rougeL": {
            "precision": 0.61882,
            "recall": 0.61909,
            "fmeasure": 0.6103
        },
        "rougeLsum": {
            "precision": 0.61882,
            "recall": 0.61909,
            "fmeasure": 0.6103
        },
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.32,
            "3": 0.855072463768116
        },
        "bleu": 39.88315,
        "nubia": {
            "semantic_relation": 3.51324,
            "contradiction": 9.93834,
            "irrelevancy": 38.74175,
            "logical_agreement": 51.31992,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.87342,
            "nubia_score": 0.52769
        },
        "meteor": 0.35531396406028787,
        "bleurt": 0.00709,
        "bertscore": {
            "precision": 0.90512,
            "recall": 0.90832,
            "f1": 0.90309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.927798970294787,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.2714152448569105,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.892147223664533,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.17749942094644394,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.930825233457635,
        "rouge1": {
            "precision": 0.75728,
            "recall": 0.67801,
            "fmeasure": 0.70366
        },
        "rouge2": {
            "precision": 0.52879,
            "recall": 0.44685,
            "fmeasure": 0.47665
        },
        "rougeL": {
            "precision": 0.69029,
            "recall": 0.60292,
            "fmeasure": 0.63358
        },
        "rougeLsum": {
            "precision": 0.69029,
            "recall": 0.60292,
            "fmeasure": 0.63358
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.6818181818181818
        },
        "bleu": 42.24835,
        "nubia": {
            "semantic_relation": 3.93177,
            "contradiction": 20.96414,
            "irrelevancy": 35.53163,
            "logical_agreement": 43.50423,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.75406,
            "nubia_score": 0.6946
        },
        "meteor": 0.36179578591897155,
        "bleurt": 0.34533,
        "bertscore": {
            "precision": 0.91219,
            "recall": 0.91152,
            "f1": 0.91119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 100,
        "mean_pred_length": 20.0,
        "std_pred_length": 4.6475800154489,
        "median_pred_length": 23.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.59,
        "vocab_size-1": 59,
        "unique-1": 40,
        "entropy-1": 5.523305065291619,
        "distinct-2": 0.8,
        "vocab_size-2": 76,
        "unique-2": 62,
        "entropy-2": 6.1249644240521,
        "cond_entropy-2": 0.5384289918971078,
        "distinct-3": 0.8555555555555555,
        "vocab_size-3": 77,
        "unique-3": 67,
        "entropy-3": 6.177801290701996,
        "cond_entropy-3": 0.07755304355428236,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 17.8,
        "std_pred_length-nopunct": 4.166533331199932,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6292134831460674,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.459492172832982,
        "distinct-2-nopunct": 0.7976190476190477,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.936785726272923,
        "cond_entropy-2-nopunct": 0.5189155033202539,
        "distinct-3-nopunct": 0.8607594936708861,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.996633121512671,
        "cond_entropy-3-nopunct": 0.06861569880693541,
        "msttr-100": 0.59,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.413927468928165,
        "rouge1": {
            "precision": 0.80455,
            "recall": 0.91223,
            "fmeasure": 0.84214
        },
        "rouge2": {
            "precision": 0.66101,
            "recall": 0.72907,
            "fmeasure": 0.68746
        },
        "rougeL": {
            "precision": 0.69598,
            "recall": 0.7897,
            "fmeasure": 0.72878
        },
        "rougeLsum": {
            "precision": 0.69598,
            "recall": 0.7897,
            "fmeasure": 0.72878
        },
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.14285714285714285,
            "3": 0.890625
        },
        "bleu": 62.92527,
        "nubia": {
            "semantic_relation": 4.64193,
            "contradiction": 0.91618,
            "irrelevancy": 31.31996,
            "logical_agreement": 67.76385,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.53393,
            "nubia_score": 0.9066
        },
        "meteor": 0.4985630887495873,
        "bleurt": 0.59026,
        "bertscore": {
            "precision": 0.94849,
            "recall": 0.97125,
            "f1": 0.95903
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8055555555555556,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.7181288207064656,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.16264411804726028,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.07083685708326808,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.523231428797621,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.680813428089397,
        "cond_entropy-2-nopunct": 0.200210795604096,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.08659166810897904,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.62576563019898,
        "rouge1": {
            "precision": 0.57564,
            "recall": 0.48387,
            "fmeasure": 0.50573
        },
        "rouge2": {
            "precision": 0.34259,
            "recall": 0.26616,
            "fmeasure": 0.29044
        },
        "rougeL": {
            "precision": 0.57564,
            "recall": 0.48387,
            "fmeasure": 0.50573
        },
        "rougeLsum": {
            "precision": 0.57564,
            "recall": 0.48387,
            "fmeasure": 0.50573
        },
        "local_recall": {
            "1": 0.06060606060606061,
            "2": 0.65
        },
        "bleu": 28.36061,
        "nubia": {
            "semantic_relation": 3.21538,
            "contradiction": 14.02026,
            "irrelevancy": 49.29343,
            "logical_agreement": 36.68631,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.96842,
            "nubia_score": 0.46396
        },
        "meteor": 0.25956673594011265,
        "bleurt": -0.08871,
        "bertscore": {
            "precision": 0.89702,
            "recall": 0.88332,
            "f1": 0.88911
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.921928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.34705205013517054,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864637,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.3108863768876157,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2946687031774156,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.58333,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.43478,
            "fmeasure": 0.47619
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.5
        },
        "bleu": 32.1655,
        "nubia": {
            "semantic_relation": 3.37304,
            "contradiction": 72.25389,
            "irrelevancy": 23.61675,
            "logical_agreement": 4.12935,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.45799,
            "nubia_score": 0.48696
        },
        "meteor": 0.30081754383110176,
        "bleurt": -0.32485,
        "bertscore": {
            "precision": 0.88714,
            "recall": 0.86303,
            "f1": 0.87492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.978953565626596,
        "rouge1": {
            "precision": 0.84444,
            "recall": 0.85205,
            "fmeasure": 0.83974
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.65,
            "fmeasure": 0.63889
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.82175,
            "fmeasure": 0.74199
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.82175,
            "fmeasure": 0.74199
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bleu": 60.06007,
        "nubia": {
            "semantic_relation": 4.63138,
            "contradiction": 9.71338,
            "irrelevancy": 52.29425,
            "logical_agreement": 37.99237,
            "grammar_ref": 5.72031,
            "grammar_hyp": 4.93733,
            "nubia_score": 0.88443
        },
        "meteor": 0.5603000267655747,
        "bleurt": 0.39336,
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.96252,
            "f1": 0.93969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.8431372549019608,
        "vocab_size-1": 43,
        "unique-1": 38,
        "entropy-1": 5.304682449772216,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.2042038254163274,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9318181818181818,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.32306798227366,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.044461849395420534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6532318108022097,
        "rouge1": {
            "precision": 0.84052,
            "recall": 0.74159,
            "fmeasure": 0.77439
        },
        "rouge2": {
            "precision": 0.6994,
            "recall": 0.63828,
            "fmeasure": 0.65794
        },
        "rougeL": {
            "precision": 0.79869,
            "recall": 0.70737,
            "fmeasure": 0.7378
        },
        "rougeLsum": {
            "precision": 0.79869,
            "recall": 0.70737,
            "fmeasure": 0.7378
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.660377358490566
        },
        "bleu": 46.79665,
        "nubia": {
            "semantic_relation": 4.04033,
            "contradiction": 32.78225,
            "irrelevancy": 33.68001,
            "logical_agreement": 33.53774,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.58478,
            "nubia_score": 0.63111
        },
        "meteor": 0.3535988211702498,
        "bleurt": 0.38287,
        "bertscore": {
            "precision": 0.95747,
            "recall": 0.93466,
            "f1": 0.94557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.0562872997343227,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8613244846796526,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.27381,
            "fmeasure": 0.25824
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.08333,
            "recall": 0.09127,
            "fmeasure": 0.08608
        },
        "rougeLsum": {
            "precision": 0.08333,
            "recall": 0.09127,
            "fmeasure": 0.08608
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bleu": 4.06543,
        "nubia": {
            "semantic_relation": 2.73374,
            "contradiction": 0.23086,
            "irrelevancy": 44.36186,
            "logical_agreement": 55.40728,
            "grammar_ref": 5.77141,
            "grammar_hyp": 5.47538,
            "nubia_score": 0.33027
        },
        "meteor": 0.11200000000000004,
        "bleurt": -0.6032,
        "bertscore": {
            "precision": 0.81299,
            "recall": 0.82557,
            "f1": 0.81689
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "total_length": 13022,
        "mean_pred_length": 26.044,
        "std_pred_length": 12.524458631014756,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.11495929964675165,
        "vocab_size-1": 1497,
        "unique-1": 652,
        "entropy-1": 7.808407023393447,
        "distinct-2": 0.3262258425171698,
        "vocab_size-2": 4085,
        "unique-2": 2354,
        "entropy-2": 10.917803800648194,
        "cond_entropy-2": 2.961286219576414,
        "distinct-3": 0.5157211778406255,
        "vocab_size-3": 6200,
        "unique-3": 4282,
        "entropy-3": 12.01036732679214,
        "cond_entropy-3": 1.1456443257207711,
        "total_length-nopunct": 11474,
        "mean_pred_length-nopunct": 22.948,
        "std_pred_length-nopunct": 11.223248014723724,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.12968450409621754,
        "vocab_size-1-nopunct": 1488,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.091904375530413,
        "distinct-2-nopunct": 0.3429925277929652,
        "vocab_size-2-nopunct": 3764,
        "unique-2-nopunct": 2226,
        "entropy-2-nopunct": 10.830874011524735,
        "cond_entropy-2-nopunct": 2.8719290087414837,
        "distinct-3-nopunct": 0.5312201642161543,
        "vocab_size-3-nopunct": 5564,
        "unique-3-nopunct": 3932,
        "entropy-3-nopunct": 11.865771238760281,
        "cond_entropy-3-nopunct": 1.0913384615807427,
        "msttr-100": 0.61138,
        "msttr-100_nopunct": 0.65193,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "nist": 6.936518338760467,
        "rouge1": {
            "precision": 0.62014,
            "recall": 0.62405,
            "fmeasure": 0.61424
        },
        "rouge2": {
            "precision": 0.36741,
            "recall": 0.37022,
            "fmeasure": 0.36371
        },
        "rougeL": {
            "precision": 0.49388,
            "recall": 0.5016,
            "fmeasure": 0.491
        },
        "rougeLsum": {
            "precision": 0.49388,
            "recall": 0.5016,
            "fmeasure": 0.491
        },
        "local_recall": {
            "1": 0.21994564081120635,
            "2": 0.5290677674578603,
            "3": 0.6934934576088905,
            "4": 0.7777777777777778,
            "5": 0.5454545454545454
        },
        "bleu": 36.61284,
        "nubia": {
            "semantic_relation": 3.36988,
            "contradiction": 46.5168,
            "irrelevancy": 9.63568,
            "logical_agreement": 43.84751,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.6512,
            "nubia_score": 0.50766
        },
        "meteor": 0.3081888234915757,
        "bleurt": -0.24396,
        "bertscore": {
            "precision": 0.87465,
            "recall": 0.87667,
            "f1": 0.87433
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 77,
        "mean_pred_length": 19.25,
        "std_pred_length": 4.205650960315181,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7922077922077922,
        "vocab_size-1": 61,
        "unique-1": 53,
        "entropy-1": 5.747306021214384,
        "distinct-2": 1.0,
        "vocab_size-2": 73,
        "unique-2": 73,
        "entropy-2": 6.189824558880028,
        "cond_entropy-2": 0.3613941825686785,
        "distinct-3": 1.0,
        "vocab_size-3": 69,
        "unique-3": 69,
        "entropy-3": 6.108524456778164,
        "cond_entropy-3": -0.08130010210184817,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8507462686567164,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.707880235233888,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 5.97727992349992,
        "cond_entropy-2-nopunct": 0.29214311399452536,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.882643049361836,
        "cond_entropy-3-nopunct": -0.0946368741380753,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.465316569180122,
        "rouge1": {
            "precision": 0.80604,
            "recall": 0.739,
            "fmeasure": 0.77005
        },
        "rouge2": {
            "precision": 0.56697,
            "recall": 0.53026,
            "fmeasure": 0.54755
        },
        "rougeL": {
            "precision": 0.67702,
            "recall": 0.63415,
            "fmeasure": 0.6544
        },
        "rougeLsum": {
            "precision": 0.67702,
            "recall": 0.63415,
            "fmeasure": 0.6544
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.8333333333333334,
            "3": 0.8
        },
        "bleu": 48.21389,
        "nubia": {
            "semantic_relation": 4.1663,
            "contradiction": 14.0981,
            "irrelevancy": 46.33186,
            "logical_agreement": 39.57004,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.5557,
            "nubia_score": 0.67418
        },
        "meteor": 0.4281670797665193,
        "bleurt": 0.37793,
        "bertscore": {
            "precision": 0.94616,
            "recall": 0.94287,
            "f1": 0.94318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.971928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.24178889224043365,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.8365916681089764,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.2704790162786154,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.073769372415743,
        "rouge1": {
            "precision": 0.81042,
            "recall": 0.86343,
            "fmeasure": 0.83473
        },
        "rouge2": {
            "precision": 0.67018,
            "recall": 0.72157,
            "fmeasure": 0.69314
        },
        "rougeL": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rougeLsum": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.9047619047619048
        },
        "bleu": 59.56191,
        "nubia": {
            "semantic_relation": 3.43217,
            "contradiction": 49.99192,
            "irrelevancy": 45.39948,
            "logical_agreement": 4.60859,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.35323,
            "nubia_score": 0.61142
        },
        "meteor": 0.5055762173065844,
        "bleurt": 0.41064,
        "bertscore": {
            "precision": 0.93365,
            "recall": 0.95372,
            "f1": 0.94017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8547840675833696,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.7381,
            "fmeasure": 0.79487
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.59524,
            "fmeasure": 0.64103
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.59524,
            "fmeasure": 0.64103
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "bleu": 50.3321,
        "nubia": {
            "semantic_relation": 4.43142,
            "contradiction": 0.27472,
            "irrelevancy": 0.4827,
            "logical_agreement": 99.24258,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.20337,
            "nubia_score": 0.85981
        },
        "meteor": 0.41527730364601223,
        "bleurt": 0.39842,
        "bertscore": {
            "precision": 0.94599,
            "recall": 0.92959,
            "f1": 0.93772
        }
    },
    "e2e_nlg_validation": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_validation",
        "N": 4299
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 31,
        "total_length": 462,
        "mean_pred_length": 14.903225806451612,
        "std_pred_length": 4.595613888647258,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 264,
        "unique-1": 212,
        "entropy-1": 7.250690008303735,
        "distinct-2": 0.9373549883990719,
        "vocab_size-2": 404,
        "unique-2": 382,
        "entropy-2": 8.614376041736962,
        "cond_entropy-2": 1.119214641383343,
        "distinct-3": 0.9825,
        "vocab_size-3": 393,
        "unique-3": 386,
        "entropy-3": 8.60885618977475,
        "cond_entropy-3": -0.004889330617464192,
        "total_length-nopunct": 411,
        "mean_pred_length-nopunct": 13.258064516129032,
        "std_pred_length-nopunct": 4.111100174040881,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6374695863746959,
        "vocab_size-1-nopunct": 262,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 7.468934606692663,
        "distinct-2-nopunct": 0.9447368421052632,
        "vocab_size-2-nopunct": 359,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.445857146544732,
        "cond_entropy-2-nopunct": 1.057543222185351,
        "distinct-3-nopunct": 0.9914040114613181,
        "vocab_size-3-nopunct": 346,
        "unique-3-nopunct": 343,
        "entropy-3-nopunct": 8.429891249132325,
        "cond_entropy-3-nopunct": -0.016413025448620132,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.7575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.586304943291419,
        "rouge1": {
            "precision": 0.79302,
            "recall": 0.75918,
            "fmeasure": 0.76657
        },
        "rouge2": {
            "precision": 0.58079,
            "recall": 0.56803,
            "fmeasure": 0.56847
        },
        "rougeL": {
            "precision": 0.69115,
            "recall": 0.66509,
            "fmeasure": 0.66905
        },
        "rougeLsum": {
            "precision": 0.69115,
            "recall": 0.66509,
            "fmeasure": 0.66905
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5443037974683544,
            "3": 0.7875
        },
        "bleu": 50.6266,
        "nubia": {
            "semantic_relation": 4.36492,
            "contradiction": 3.31925,
            "irrelevancy": 26.61292,
            "logical_agreement": 70.06783,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.57479,
            "nubia_score": 0.7897
        },
        "meteor": 0.4086383671611187,
        "bleurt": 0.35248,
        "bertscore": {
            "precision": 0.93714,
            "recall": 0.9267,
            "f1": 0.93027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9845405119274035,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.73077,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.29604,
            "fmeasure": 0.28846
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.54762,
            "fmeasure": 0.5348
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.54762,
            "fmeasure": 0.5348
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bleu": 21.92534,
        "nubia": {
            "semantic_relation": 4.71796,
            "contradiction": 1.61662,
            "irrelevancy": 1.53658,
            "logical_agreement": 96.8468,
            "grammar_ref": 5.03839,
            "grammar_hyp": 5.10181,
            "nubia_score": 0.78161
        },
        "meteor": 0.36127889831679777,
        "bleurt": 0.0719,
        "bertscore": {
            "precision": 0.92745,
            "recall": 0.92602,
            "f1": 0.92427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 2.3570226039551585,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 24,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 48,
        "unique-1": 41,
        "entropy-1": 5.401540463507996,
        "distinct-2": 1.0,
        "vocab_size-2": 59,
        "unique-2": 59,
        "entropy-2": 5.882643049361836,
        "cond_entropy-2": 0.42861241701440544,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.07528812730423731,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.2803946541231985,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.4773537401344049,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.08406426478847459,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.213806565035741,
        "rouge1": {
            "precision": 0.79861,
            "recall": 0.83164,
            "fmeasure": 0.80781
        },
        "rouge2": {
            "precision": 0.57583,
            "recall": 0.59219,
            "fmeasure": 0.57953
        },
        "rougeL": {
            "precision": 0.69306,
            "recall": 0.72264,
            "fmeasure": 0.70183
        },
        "rougeLsum": {
            "precision": 0.69306,
            "recall": 0.72264,
            "fmeasure": 0.70183
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.8809523809523809
        },
        "bleu": 59.77845,
        "nubia": {
            "semantic_relation": 4.70251,
            "contradiction": 0.475,
            "irrelevancy": 66.03089,
            "logical_agreement": 33.49412,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.85939,
            "nubia_score": 0.91012
        },
        "meteor": 0.46545251147003724,
        "bleurt": 0.52706,
        "bertscore": {
            "precision": 0.94942,
            "recall": 0.95535,
            "f1": 0.95214
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.743289445392766,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.35552614796204746,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.043068721891885896,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.635006998015215,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.37778634952676327,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.04580368961312477,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8201969647903344,
        "rouge1": {
            "precision": 0.68687,
            "recall": 0.64762,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.29902,
            "fmeasure": 0.31481
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.41905,
            "fmeasure": 0.43137
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.41905,
            "fmeasure": 0.43137
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.8260869565217391
        },
        "bleu": 14.04734,
        "nubia": {
            "semantic_relation": 3.801,
            "contradiction": 20.31752,
            "irrelevancy": 60.1269,
            "logical_agreement": 19.55559,
            "grammar_ref": 5.19058,
            "grammar_hyp": 4.71378,
            "nubia_score": 0.65042
        },
        "meteor": 0.3682866154687549,
        "bleurt": 0.06754,
        "bertscore": {
            "precision": 0.90806,
            "recall": 0.91243,
            "f1": 0.90975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.22503715874966057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3075756701757837,
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.58442,
            "fmeasure": 0.65497
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.29524,
            "fmeasure": 0.33033
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.58201,
            "fmeasure": 0.61203
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.58201,
            "fmeasure": 0.61203
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.6428571428571429
        },
        "bleu": 20.61012,
        "nubia": {
            "semantic_relation": 4.15889,
            "contradiction": 0.29636,
            "irrelevancy": 0.82041,
            "logical_agreement": 98.88323,
            "grammar_ref": 4.70322,
            "grammar_hyp": 4.49725,
            "nubia_score": 0.73442
        },
        "meteor": 0.31140636114804904,
        "bleurt": -0.0515,
        "bertscore": {
            "precision": 0.8941,
            "recall": 0.86625,
            "f1": 0.874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.7924528301886793,
        "vocab_size-1": 42,
        "unique-1": 35,
        "entropy-1": 5.230476530476399,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.3481285447002616,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8478260869565217,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.140743684873601,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.3122293213064061,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.1043366598147359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.687585450939697,
        "rouge1": {
            "precision": 0.80258,
            "recall": 0.70307,
            "fmeasure": 0.74262
        },
        "rouge2": {
            "precision": 0.57407,
            "recall": 0.50339,
            "fmeasure": 0.53054
        },
        "rougeL": {
            "precision": 0.75397,
            "recall": 0.65352,
            "fmeasure": 0.69198
        },
        "rougeLsum": {
            "precision": 0.75397,
            "recall": 0.65352,
            "fmeasure": 0.69198
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bleu": 47.2267,
        "nubia": {
            "semantic_relation": 3.91574,
            "contradiction": 33.1524,
            "irrelevancy": 3.84262,
            "logical_agreement": 63.00498,
            "grammar_ref": 4.44265,
            "grammar_hyp": 3.96299,
            "nubia_score": 0.68819
        },
        "meteor": 0.3899742084340368,
        "bleurt": 0.34972,
        "bertscore": {
            "precision": 0.93967,
            "recall": 0.91849,
            "f1": 0.92469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 8.65383665716478,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.7258064516129032,
        "vocab_size-1": 45,
        "unique-1": 35,
        "entropy-1": 5.258046964278322,
        "distinct-2": 0.9322033898305084,
        "vocab_size-2": 55,
        "unique-2": 51,
        "entropy-2": 5.7470498290228536,
        "cond_entropy-2": 0.4438089755269437,
        "distinct-3": 0.9642857142857143,
        "vocab_size-3": 54,
        "unique-3": 52,
        "entropy-3": 5.735926350629038,
        "cond_entropy-3": -0.00385955587566578,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 7.930251502246879,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.0830620415870795,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.546593564294941,
        "cond_entropy-2-nopunct": 0.4845871576273309,
        "distinct-3-nopunct": 0.9591836734693877,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.533077191053984,
        "cond_entropy-3-nopunct": -0.004097220964659238,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.697881402796203,
        "rouge1": {
            "precision": 0.72755,
            "recall": 0.60192,
            "fmeasure": 0.64613
        },
        "rouge2": {
            "precision": 0.41826,
            "recall": 0.30401,
            "fmeasure": 0.34611
        },
        "rougeL": {
            "precision": 0.62153,
            "recall": 0.50652,
            "fmeasure": 0.54654
        },
        "rougeLsum": {
            "precision": 0.62153,
            "recall": 0.50652,
            "fmeasure": 0.54654
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.8666666666666667,
            "3": 0.5757575757575758
        },
        "bleu": 21.41829,
        "nubia": {
            "semantic_relation": 3.65905,
            "contradiction": 41.56715,
            "irrelevancy": 15.65049,
            "logical_agreement": 42.78237,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.54765,
            "nubia_score": 0.49949
        },
        "meteor": 0.28820071280423715,
        "bleurt": 0.00736,
        "bertscore": {
            "precision": 0.91499,
            "recall": 0.90428,
            "f1": 0.90885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 4.5,
        "median_pred_length": 21.5,
        "min_pred_length": 17,
        "max_pred_length": 26,
        "distinct-1": 0.7674418604651163,
        "vocab_size-1": 33,
        "unique-1": 25,
        "entropy-1": 4.9260374290200755,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.40713542075322817,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.07214978575583503,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.739097917988785,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.3737076928764665,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2864914829571985,
        "rouge1": {
            "precision": 0.84375,
            "recall": 0.81101,
            "fmeasure": 0.82519
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.53558,
            "fmeasure": 0.55698
        },
        "rougeL": {
            "precision": 0.71875,
            "recall": 0.6723,
            "fmeasure": 0.69292
        },
        "rougeLsum": {
            "precision": 0.71875,
            "recall": 0.6723,
            "fmeasure": 0.69292
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8709677419354839
        },
        "bleu": 67.30819,
        "nubia": {
            "semantic_relation": 3.80564,
            "contradiction": 0.22715,
            "irrelevancy": 43.64208,
            "logical_agreement": 56.13076,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.00892,
            "nubia_score": 0.66042
        },
        "meteor": 0.4358119570299818,
        "bleurt": 0.13271,
        "bertscore": {
            "precision": 0.93491,
            "recall": 0.9267,
            "f1": 0.92772
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1850,
        "total_length": 24434,
        "mean_pred_length": 13.207567567567567,
        "std_pred_length": 4.315922378259872,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 49,
        "distinct-1": 0.2527216174183515,
        "vocab_size-1": 6175,
        "unique-1": 4558,
        "entropy-1": 9.094721848588078,
        "distinct-2": 0.5912150194828197,
        "vocab_size-2": 13352,
        "unique-2": 11620,
        "entropy-2": 12.338829319809031,
        "cond_entropy-2": 2.803626077865277,
        "distinct-3": 0.7531108324491174,
        "vocab_size-3": 15615,
        "unique-3": 14414,
        "entropy-3": 13.12788791999339,
        "cond_entropy-3": 0.8513507349324205,
        "total_length-nopunct": 21249,
        "mean_pred_length-nopunct": 11.485945945945947,
        "std_pred_length-nopunct": 3.7602569344785968,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.28975481199115255,
        "vocab_size-1-nopunct": 6157,
        "unique-1-nopunct": 4555,
        "entropy-1-nopunct": 9.545829913767658,
        "distinct-2-nopunct": 0.6111139749471622,
        "vocab_size-2-nopunct": 11855,
        "unique-2-nopunct": 10488,
        "entropy-2-nopunct": 12.158204485028271,
        "cond_entropy-2-nopunct": 2.874679686529384,
        "distinct-3-nopunct": 0.7594734742720383,
        "vocab_size-3-nopunct": 13328,
        "unique-3-nopunct": 12354,
        "entropy-3-nopunct": 12.906619667678607,
        "cond_entropy-3-nopunct": 0.9103872696322214,
        "msttr-100": 0.68619,
        "msttr-100_nopunct": 0.73189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 9.349879405966702,
        "rouge1": {
            "precision": 0.75586,
            "recall": 0.72361,
            "fmeasure": 0.72574
        },
        "rouge2": {
            "precision": 0.55212,
            "recall": 0.52963,
            "fmeasure": 0.5307
        },
        "rougeL": {
            "precision": 0.68521,
            "recall": 0.65719,
            "fmeasure": 0.65854
        },
        "rougeLsum": {
            "precision": 0.68521,
            "recall": 0.65719,
            "fmeasure": 0.65854
        },
        "local_recall": {
            "1": 0.22156133828996283,
            "2": 0.46964490263459335,
            "3": 0.7676754240106418
        },
        "bleu": 49.8389,
        "nubia": {
            "semantic_relation": 4.15349,
            "contradiction": 8.7375,
            "irrelevancy": 28.61418,
            "logical_agreement": 62.64832,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.74131,
            "nubia_score": 0.72022
        },
        "meteor": 0.3978495432524594,
        "bleurt": 0.29583,
        "bertscore": {
            "precision": 0.92711,
            "recall": 0.92172,
            "f1": 0.92266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 84,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.779644730092272,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.411098561021973,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 66,
        "unique-2": 55,
        "entropy-2": 5.981072254980619,
        "cond_entropy-2": 0.4039613248403877,
        "distinct-3": 0.8714285714285714,
        "vocab_size-3": 61,
        "unique-3": 52,
        "entropy-3": 5.872140159802115,
        "cond_entropy-3": -0.10893209517850605,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 10.285714285714286,
        "std_pred_length-nopunct": 3.4934340744678525,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.459351953404397,
        "distinct-2-nopunct": 0.8615384615384616,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.745444736105379,
        "cond_entropy-2-nopunct": 0.33184680325891414,
        "distinct-3-nopunct": 0.8793103448275862,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.616601684782742,
        "cond_entropy-3-nopunct": -0.1299040592801927,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5115912196470065,
        "rouge1": {
            "precision": 0.87258,
            "recall": 0.80923,
            "fmeasure": 0.83264
        },
        "rouge2": {
            "precision": 0.67509,
            "recall": 0.61723,
            "fmeasure": 0.63965
        },
        "rougeL": {
            "precision": 0.78037,
            "recall": 0.73564,
            "fmeasure": 0.75223
        },
        "rougeLsum": {
            "precision": 0.78037,
            "recall": 0.73564,
            "fmeasure": 0.75223
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.46153846153846156,
            "3": 0.8035714285714286
        },
        "bleu": 45.00002,
        "nubia": {
            "semantic_relation": 4.33935,
            "contradiction": 26.01412,
            "irrelevancy": 14.08168,
            "logical_agreement": 59.9042,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.71172,
            "nubia_score": 0.64474
        },
        "meteor": 0.42975495662243784,
        "bleurt": 0.2006,
        "bertscore": {
            "precision": 0.92311,
            "recall": 0.94735,
            "f1": 0.93169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 1.00634,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.039583410898779,
        "distinct-2": 0.9387755102040817,
        "vocab_size-2": 46,
        "unique-2": 44,
        "entropy-2": 5.476854997132281,
        "cond_entropy-2": 0.38069365602051125,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": 0.05569749242361918,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.967149692647067,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.351365993588126,
        "cond_entropy-2-nopunct": 0.42426897087496285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": 0.014093251887212442,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.203873581972215,
        "rouge1": {
            "precision": 0.70791,
            "recall": 0.64937,
            "fmeasure": 0.66304
        },
        "rouge2": {
            "precision": 0.43194,
            "recall": 0.36344,
            "fmeasure": 0.38656
        },
        "rougeL": {
            "precision": 0.60741,
            "recall": 0.53713,
            "fmeasure": 0.55714
        },
        "rougeLsum": {
            "precision": 0.60741,
            "recall": 0.53713,
            "fmeasure": 0.55714
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.1875,
            "3": 0.6944444444444444
        },
        "bleu": 35.92287,
        "nubia": {
            "semantic_relation": 3.72721,
            "contradiction": 65.64299,
            "irrelevancy": 1.35509,
            "logical_agreement": 33.00192,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.09008,
            "nubia_score": 0.60078
        },
        "meteor": 0.33557596212611934,
        "bleurt": 0.07777,
        "bertscore": {
            "precision": 0.90936,
            "recall": 0.90451,
            "f1": 0.90484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 14,
        "total_length": 237,
        "mean_pred_length": 16.928571428571427,
        "std_pred_length": 7.722548484926515,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.6118143459915611,
        "vocab_size-1": 145,
        "unique-1": 119,
        "entropy-1": 6.5566232161200615,
        "distinct-2": 0.9237668161434978,
        "vocab_size-2": 206,
        "unique-2": 191,
        "entropy-2": 7.641663240708086,
        "cond_entropy-2": 0.9296441122566004,
        "distinct-3": 0.9617224880382775,
        "vocab_size-3": 201,
        "unique-3": 193,
        "entropy-3": 7.630804108157456,
        "cond_entropy-3": -0.009761940067522637,
        "total_length-nopunct": 209,
        "mean_pred_length-nopunct": 14.928571428571429,
        "std_pred_length-nopunct": 6.605887911707314,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6746411483253588,
        "vocab_size-1-nopunct": 141,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.657646553846549,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 167,
        "entropy-2-nopunct": 7.445741723983867,
        "cond_entropy-2-nopunct": 0.8378181244720698,
        "distinct-3-nopunct": 0.9613259668508287,
        "vocab_size-3-nopunct": 174,
        "unique-3-nopunct": 167,
        "entropy-3-nopunct": 7.422497820784832,
        "cond_entropy-3-nopunct": -0.0273199238800687,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.302660326762343,
        "rouge1": {
            "precision": 0.69154,
            "recall": 0.63262,
            "fmeasure": 0.64789
        },
        "rouge2": {
            "precision": 0.47353,
            "recall": 0.40976,
            "fmeasure": 0.4293
        },
        "rougeL": {
            "precision": 0.59928,
            "recall": 0.55112,
            "fmeasure": 0.56214
        },
        "rougeLsum": {
            "precision": 0.59928,
            "recall": 0.55112,
            "fmeasure": 0.56214
        },
        "local_recall": {
            "1": 0.3013698630136986,
            "2": 0.5384615384615384,
            "3": 0.7130434782608696
        },
        "bleu": 36.42954,
        "nubia": {
            "semantic_relation": 3.75785,
            "contradiction": 7.5564,
            "irrelevancy": 52.85785,
            "logical_agreement": 39.58575,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.08102,
            "nubia_score": 0.64807
        },
        "meteor": 0.3497126830497357,
        "bleurt": 0.03165,
        "bertscore": {
            "precision": 0.91347,
            "recall": 0.90564,
            "f1": 0.90805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1949875002403856,
        "rouge1": {
            "precision": 0.35,
            "recall": 0.58333,
            "fmeasure": 0.4375
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.27273,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bleu": 9.24652,
        "nubia": {
            "semantic_relation": 3.86236,
            "contradiction": 0.20028,
            "irrelevancy": 99.13162,
            "logical_agreement": 0.6681,
            "grammar_ref": 5.68739,
            "grammar_hyp": 3.44237,
            "nubia_score": 0.71299
        },
        "meteor": 0.30718306239377846,
        "bleurt": 0.03916,
        "bertscore": {
            "precision": 0.78783,
            "recall": 0.82385,
            "f1": 0.80544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 159,
        "mean_pred_length": 19.875,
        "std_pred_length": 6.333196270446701,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5974842767295597,
        "vocab_size-1": 95,
        "unique-1": 72,
        "entropy-1": 6.095256396626196,
        "distinct-2": 0.9072847682119205,
        "vocab_size-2": 137,
        "unique-2": 126,
        "entropy-2": 7.037976510805257,
        "cond_entropy-2": 0.8239489851735456,
        "distinct-3": 0.958041958041958,
        "vocab_size-3": 137,
        "unique-3": 133,
        "entropy-3": 7.065397385699187,
        "cond_entropy-3": 0.03863364292298497,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 16.625,
        "std_pred_length-nopunct": 4.442338910979215,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6616541353383458,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.066193149624243,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.79370608462748,
        "cond_entropy-2-nopunct": 0.7701349492935908,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.8126306383683115,
        "cond_entropy-3-nopunct": 0.03069058451245828,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.787289438897212,
        "rouge1": {
            "precision": 0.6317,
            "recall": 0.64178,
            "fmeasure": 0.63085
        },
        "rouge2": {
            "precision": 0.41912,
            "recall": 0.43491,
            "fmeasure": 0.42384
        },
        "rougeL": {
            "precision": 0.54636,
            "recall": 0.56258,
            "fmeasure": 0.54922
        },
        "rougeLsum": {
            "precision": 0.54636,
            "recall": 0.56258,
            "fmeasure": 0.54922
        },
        "local_recall": {
            "1": 0.12,
            "2": 0.18181818181818182,
            "3": 0.723404255319149
        },
        "bleu": 43.21038,
        "nubia": {
            "semantic_relation": 3.64721,
            "contradiction": 39.47856,
            "irrelevancy": 18.43106,
            "logical_agreement": 42.09038,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.46138,
            "nubia_score": 0.59701
        },
        "meteor": 0.3512719805572256,
        "bleurt": 0.12139,
        "bertscore": {
            "precision": 0.90406,
            "recall": 0.89842,
            "f1": 0.89943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 83,
        "mean_pred_length": 16.6,
        "std_pred_length": 3.7202150475476548,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6024096385542169,
        "vocab_size-1": 50,
        "unique-1": 34,
        "entropy-1": 5.344608257427284,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 65,
        "unique-2": 55,
        "entropy-2": 5.923034750830325,
        "cond_entropy-2": 0.4956382292384416,
        "distinct-3": 0.8767123287671232,
        "vocab_size-3": 64,
        "unique-3": 56,
        "entropy-3": 5.9329082917271005,
        "cond_entropy-3": 0.03469323048800084,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.9496835316262997,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.64,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.306668564379483,
        "distinct-2-nopunct": 0.8142857142857143,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.725502123995107,
        "cond_entropy-2-nopunct": 0.4704157114810822,
        "distinct-3-nopunct": 0.8615384615384616,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.733831082225943,
        "cond_entropy-3-nopunct": 0.024004411534671505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.453176729923307,
        "rouge1": {
            "precision": 0.6617,
            "recall": 0.74227,
            "fmeasure": 0.65965
        },
        "rouge2": {
            "precision": 0.45128,
            "recall": 0.53002,
            "fmeasure": 0.46374
        },
        "rougeL": {
            "precision": 0.57771,
            "recall": 0.66933,
            "fmeasure": 0.58906
        },
        "rougeLsum": {
            "precision": 0.57771,
            "recall": 0.66933,
            "fmeasure": 0.58906
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.7142857142857143
        },
        "bleu": 44.96622,
        "nubia": {
            "semantic_relation": 3.77031,
            "contradiction": 23.8075,
            "irrelevancy": 53.59024,
            "logical_agreement": 22.60227,
            "grammar_ref": 4.71659,
            "grammar_hyp": 3.76445,
            "nubia_score": 0.70982
        },
        "meteor": 0.38661475959031305,
        "bleurt": 0.1109,
        "bertscore": {
            "precision": 0.90722,
            "recall": 0.90976,
            "f1": 0.90615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.504706483564824,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2053555814454493,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.2225599568699096,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9071365348345295,
        "rouge1": {
            "precision": 0.62667,
            "recall": 0.77109,
            "fmeasure": 0.69104
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.48333,
            "fmeasure": 0.42208
        },
        "rougeL": {
            "precision": 0.30667,
            "recall": 0.36523,
            "fmeasure": 0.33301
        },
        "rougeLsum": {
            "precision": 0.30667,
            "recall": 0.36523,
            "fmeasure": 0.33301
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bleu": 30.5565,
        "nubia": {
            "semantic_relation": 4.61204,
            "contradiction": 0.28048,
            "irrelevancy": 3.39958,
            "logical_agreement": 96.31994,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.11443,
            "nubia_score": 0.9419
        },
        "meteor": 0.38238254170527,
        "bleurt": 0.2264,
        "bertscore": {
            "precision": 0.91346,
            "recall": 0.92951,
            "f1": 0.92141
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1055161915432032,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "bleu": 41.11336,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543,
        "bleurt": 0.18287,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 6.20966987850401,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7654320987654321,
        "vocab_size-1": 62,
        "unique-1": 50,
        "entropy-1": 5.758128824134447,
        "distinct-2": 0.9210526315789473,
        "vocab_size-2": 70,
        "unique-2": 64,
        "entropy-2": 6.090032776601484,
        "cond_entropy-2": 0.21741665535273638,
        "distinct-3": 0.9295774647887324,
        "vocab_size-3": 66,
        "unique-3": 61,
        "entropy-3": 6.00890204908214,
        "cond_entropy-3": -0.07001137985439647,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 6.0332412515993425,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.755355023771528,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.957854445516401,
        "cond_entropy-2-nopunct": 0.20774682651089887,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.868521659182303,
        "cond_entropy-3-nopunct": -0.09153058853189681,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6386746430552352,
        "rouge1": {
            "precision": 0.66204,
            "recall": 0.7727,
            "fmeasure": 0.70729
        },
        "rouge2": {
            "precision": 0.49158,
            "recall": 0.57737,
            "fmeasure": 0.52596
        },
        "rougeL": {
            "precision": 0.57593,
            "recall": 0.67538,
            "fmeasure": 0.61645
        },
        "rougeLsum": {
            "precision": 0.57593,
            "recall": 0.67538,
            "fmeasure": 0.61645
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.7555555555555555
        },
        "bleu": 38.97803,
        "nubia": {
            "semantic_relation": 4.02908,
            "contradiction": 37.4094,
            "irrelevancy": 35.03135,
            "logical_agreement": 27.55925,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.32228,
            "nubia_score": 0.62365
        },
        "meteor": 0.40104752470636895,
        "bleurt": 0.18751,
        "bertscore": {
            "precision": 0.89595,
            "recall": 0.92912,
            "f1": 0.91011
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6658,
        "mean_pred_length": 13.316,
        "std_pred_length": 7.4037925416640356,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 48,
        "distinct-1": 0.1491438870531691,
        "vocab_size-1": 993,
        "unique-1": 574,
        "entropy-1": 7.759398178185448,
        "distinct-2": 0.42822344917180905,
        "vocab_size-2": 2637,
        "unique-2": 1794,
        "entropy-2": 10.42288496029025,
        "cond_entropy-2": 2.4438294789908785,
        "distinct-3": 0.6202509277257466,
        "vocab_size-3": 3510,
        "unique-3": 2749,
        "entropy-3": 11.218759310865776,
        "cond_entropy-3": 0.8257466966402996,
        "total_length-nopunct": 5869,
        "mean_pred_length-nopunct": 11.738,
        "std_pred_length-nopunct": 6.7756443236049515,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.16731981598227977,
        "vocab_size-1-nopunct": 982,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 7.919667523299633,
        "distinct-2-nopunct": 0.4421680014900354,
        "vocab_size-2-nopunct": 2374,
        "unique-2-nopunct": 1652,
        "entropy-2-nopunct": 10.260163409861807,
        "cond_entropy-2-nopunct": 2.4704613819335917,
        "distinct-3-nopunct": 0.6344969199178645,
        "vocab_size-3-nopunct": 3090,
        "unique-3-nopunct": 2476,
        "entropy-3-nopunct": 11.034118059061536,
        "cond_entropy-3-nopunct": 0.8186245844500533,
        "msttr-100": 0.67803,
        "msttr-100_nopunct": 0.70276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.233921240862125,
        "rouge1": {
            "precision": 0.59345,
            "recall": 0.55101,
            "fmeasure": 0.5595
        },
        "rouge2": {
            "precision": 0.36329,
            "recall": 0.33468,
            "fmeasure": 0.34078
        },
        "rougeL": {
            "precision": 0.52937,
            "recall": 0.49071,
            "fmeasure": 0.49867
        },
        "rougeLsum": {
            "precision": 0.52937,
            "recall": 0.49071,
            "fmeasure": 0.49867
        },
        "local_recall": {
            "1": 0.5640983336083154
        },
        "bleu": 31.55474,
        "nubia": {
            "semantic_relation": 3.59217,
            "contradiction": 10.32754,
            "irrelevancy": 18.32377,
            "logical_agreement": 71.34869,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.53888,
            "nubia_score": 0.63673
        },
        "meteor": 0.31309512625263536,
        "bleurt": -0.07074,
        "bertscore": {
            "precision": 0.87722,
            "recall": 0.8643,
            "f1": 0.87026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9767769323620341,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.53704,
            "fmeasure": 0.61275
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 24.839,
        "nubia": {
            "semantic_relation": 4.74089,
            "contradiction": 0.54392,
            "irrelevancy": 0.53393,
            "logical_agreement": 98.92214,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75139,
            "nubia_score": 0.91626
        },
        "meteor": 0.41910267807653556,
        "bleurt": 0.604,
        "bertscore": {
            "precision": 0.97642,
            "recall": 0.95148,
            "f1": 0.96379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 85,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6941176470588235,
        "vocab_size-1": 59,
        "unique-1": 46,
        "entropy-1": 5.558347448753736,
        "distinct-2": 0.9375,
        "vocab_size-2": 75,
        "unique-2": 70,
        "entropy-2": 6.196928094887356,
        "cond_entropy-2": 0.5466503581646674,
        "distinct-3": 0.9866666666666667,
        "vocab_size-3": 74,
        "unique-3": 73,
        "entropy-3": 6.202152023829224,
        "cond_entropy-3": 0.013557262275185201,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 3.7202150475476548,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.532465604077629,
        "distinct-2-nopunct": 0.9315068493150684,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.052838257510164,
        "cond_entropy-2-nopunct": 0.5445463941712008,
        "distinct-3-nopunct": 0.9852941176470589,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.058051076544463,
        "cond_entropy-3-nopunct": 0.00057945884091052,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.961931926680849,
        "rouge1": {
            "precision": 0.80402,
            "recall": 0.71786,
            "fmeasure": 0.75437
        },
        "rouge2": {
            "precision": 0.60731,
            "recall": 0.52161,
            "fmeasure": 0.55512
        },
        "rougeL": {
            "precision": 0.63915,
            "recall": 0.56181,
            "fmeasure": 0.59355
        },
        "rougeLsum": {
            "precision": 0.63915,
            "recall": 0.56181,
            "fmeasure": 0.59355
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "bleu": 40.93731,
        "nubia": {
            "semantic_relation": 4.47961,
            "contradiction": 23.54138,
            "irrelevancy": 1.81832,
            "logical_agreement": 74.64031,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.4023,
            "nubia_score": 0.81689
        },
        "meteor": 0.39397789508451686,
        "bleurt": 0.36897,
        "bertscore": {
            "precision": 0.93427,
            "recall": 0.91581,
            "f1": 0.92201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7358490566037735,
        "vocab_size-1": 39,
        "unique-1": 29,
        "entropy-1": 5.1333963978777835,
        "distinct-2": 0.8367346938775511,
        "vocab_size-2": 41,
        "unique-2": 34,
        "entropy-2": 5.272773364479221,
        "cond_entropy-2": 0.02464423653493714,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 40,
        "unique-3": 35,
        "entropy-3": 5.269630874107453,
        "cond_entropy-3": 0.02725186337365453,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 2.48746859276655,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.054380872862171,
        "distinct-2-nopunct": 0.813953488372093,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.036616208140156,
        "cond_entropy-2-nopunct": 0.02876631005151801,
        "distinct-3-nopunct": 0.8717948717948718,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 5.0289919624519905,
        "cond_entropy-3-nopunct": 0.03233970780536746,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.5198305902376905,
        "rouge1": {
            "precision": 0.98684,
            "recall": 0.92643,
            "fmeasure": 0.95272
        },
        "rouge2": {
            "precision": 0.91204,
            "recall": 0.86437,
            "fmeasure": 0.88499
        },
        "rougeL": {
            "precision": 0.95175,
            "recall": 0.88839,
            "fmeasure": 0.91506
        },
        "rougeLsum": {
            "precision": 0.95175,
            "recall": 0.88839,
            "fmeasure": 0.91506
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "bleu": 75.38847,
        "nubia": {
            "semantic_relation": 4.8068,
            "contradiction": 0.33025,
            "irrelevancy": 8.80977,
            "logical_agreement": 90.85998,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.11057,
            "nubia_score": 0.92746
        },
        "meteor": 0.557855423473949,
        "bleurt": 0.68229,
        "bertscore": {
            "precision": 0.98602,
            "recall": 0.97833,
            "f1": 0.98075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0286497677077553,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 70.16879,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "meteor": 0.5613051214200641,
        "bleurt": 0.76221,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.294710659132164,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.875,
            "fmeasure": 0.84848
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "bleu": 75.90995,
        "nubia": {
            "semantic_relation": 3.77559,
            "contradiction": 97.22461,
            "irrelevancy": 2.18277,
            "logical_agreement": 0.59262,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.15402,
            "nubia_score": 0.54204
        },
        "meteor": 0.5246933677048612,
        "bleurt": 0.71585,
        "bertscore": {
            "precision": 0.9789,
            "recall": 0.98281,
            "f1": 0.98085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.645467781761527,
        "rouge1": {
            "precision": 0.87374,
            "recall": 0.79419,
            "fmeasure": 0.82929
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.67727,
            "fmeasure": 0.70166
        },
        "rougeL": {
            "precision": 0.87374,
            "recall": 0.79419,
            "fmeasure": 0.82929
        },
        "rougeLsum": {
            "precision": 0.87374,
            "recall": 0.79419,
            "fmeasure": 0.82929
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "bleu": 72.48561,
        "nubia": {
            "semantic_relation": 4.69254,
            "contradiction": 1.79771,
            "irrelevancy": 1.10646,
            "logical_agreement": 97.09583,
            "grammar_ref": 5.62679,
            "grammar_hyp": 6.03513,
            "nubia_score": 0.78481
        },
        "meteor": 0.49479106134755046,
        "bleurt": 0.53769,
        "bertscore": {
            "precision": 0.91357,
            "recall": 0.90508,
            "f1": 0.90928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9487445430153727,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54762,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bleu": 51.31108,
        "nubia": {
            "semantic_relation": 4.91614,
            "contradiction": 0.68707,
            "irrelevancy": 0.60509,
            "logical_agreement": 98.70784,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.87586,
            "nubia_score": 0.87589
        },
        "meteor": 0.4561301812414779,
        "bleurt": 0.59368,
        "bertscore": {
            "precision": 0.98804,
            "recall": 0.97187,
            "f1": 0.97989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3694706308487,
        "rouge1": {
            "precision": 0.96104,
            "recall": 0.72433,
            "fmeasure": 0.82315
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.49792,
            "fmeasure": 0.57676
        },
        "rougeL": {
            "precision": 0.92208,
            "recall": 0.69391,
            "fmeasure": 0.78898
        },
        "rougeLsum": {
            "precision": 0.92208,
            "recall": 0.69391,
            "fmeasure": 0.78898
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.8823529411764706
        },
        "bleu": 56.03752,
        "nubia": {
            "semantic_relation": 4.24848,
            "contradiction": 22.71069,
            "irrelevancy": 28.30225,
            "logical_agreement": 48.98706,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.67719,
            "nubia_score": 0.64599
        },
        "meteor": 0.409459819980906,
        "bleurt": 0.25485,
        "bertscore": {
            "precision": 0.94808,
            "recall": 0.92882,
            "f1": 0.93834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 3.0,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 24,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.844232898763193,
        "distinct-2": 0.95,
        "vocab_size-2": 38,
        "unique-2": 36,
        "entropy-2": 5.221928094887364,
        "cond_entropy-2": 0.32585129728889106,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 37,
        "unique-3": 36,
        "entropy-3": 5.19529593449622,
        "cond_entropy-3": -0.021369002496408333,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.767278500114892,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.31823811317901607,
        "distinct-3-nopunct": 0.9705882352941176,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.028639311838574,
        "cond_entropy-3-nopunct": -0.023638630780208267,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1360626297307848,
        "rouge1": {
            "precision": 0.67367,
            "recall": 0.8505,
            "fmeasure": 0.74469
        },
        "rouge2": {
            "precision": 0.30625,
            "recall": 0.41026,
            "fmeasure": 0.3469
        },
        "rougeL": {
            "precision": 0.5084,
            "recall": 0.65041,
            "fmeasure": 0.56522
        },
        "rougeLsum": {
            "precision": 0.5084,
            "recall": 0.65041,
            "fmeasure": 0.56522
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.7391304347826086
        },
        "bleu": 15.11633,
        "nubia": {
            "semantic_relation": 4.36573,
            "contradiction": 3.53035,
            "irrelevancy": 46.96936,
            "logical_agreement": 49.50028,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.0453,
            "nubia_score": 0.7399
        },
        "meteor": 0.3813600456555059,
        "bleurt": 0.25118,
        "bertscore": {
            "precision": 0.91519,
            "recall": 0.93617,
            "f1": 0.92542
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.1619781796795525,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.30118944924673074,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.034621791174768206,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.084962500721157,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728204,
        "cond_entropy-2-nopunct": 0.3290145724615955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.635257496647926,
        "rouge1": {
            "precision": 0.7125,
            "recall": 0.78462,
            "fmeasure": 0.74483
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.5,
            "fmeasure": 0.46049
        },
        "rougeL": {
            "precision": 0.67083,
            "recall": 0.73333,
            "fmeasure": 0.69885
        },
        "rougeLsum": {
            "precision": 0.67083,
            "recall": 0.73333,
            "fmeasure": 0.69885
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8
        },
        "bleu": 31.31422,
        "nubia": {
            "semantic_relation": 4.29089,
            "contradiction": 0.16024,
            "irrelevancy": 54.38355,
            "logical_agreement": 45.45622,
            "grammar_ref": 3.96214,
            "grammar_hyp": 3.8259,
            "nubia_score": 0.8748
        },
        "meteor": 0.37324885218488696,
        "bleurt": 0.21556,
        "bertscore": {
            "precision": 0.93151,
            "recall": 0.91929,
            "f1": 0.9253
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 55,
        "mean_pred_length": 27.5,
        "std_pred_length": 3.5,
        "median_pred_length": 27.5,
        "min_pred_length": 24,
        "max_pred_length": 31,
        "distinct-1": 0.8545454545454545,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.440361758939866,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 52,
        "unique-2": 51,
        "entropy-2": 5.690184605506591,
        "cond_entropy-2": 0.22495484485294487,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.016279426317193903,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8958333333333334,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.33496250072116,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.15599075968368273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.0186757919651701,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.816950468041128,
        "rouge1": {
            "precision": 0.67424,
            "recall": 0.79023,
            "fmeasure": 0.72734
        },
        "rouge2": {
            "precision": 0.44505,
            "recall": 0.52496,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.49299,
            "recall": 0.58184,
            "fmeasure": 0.53353
        },
        "rougeLsum": {
            "precision": 0.49299,
            "recall": 0.58184,
            "fmeasure": 0.53353
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8571428571428571
        },
        "bleu": 39.22089,
        "nubia": {
            "semantic_relation": 4.33393,
            "contradiction": 0.52954,
            "irrelevancy": 24.38277,
            "logical_agreement": 75.08769,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.21521,
            "nubia_score": 0.70085
        },
        "meteor": 0.41771623826604115,
        "bleurt": 0.22139,
        "bertscore": {
            "precision": 0.91564,
            "recall": 0.94113,
            "f1": 0.92821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 65,
        "mean_pred_length": 10.833333333333334,
        "std_pred_length": 3.7155828016013257,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.47692307692307695,
        "vocab_size-1": 31,
        "unique-1": 20,
        "entropy-1": 4.533229543498129,
        "distinct-2": 0.711864406779661,
        "vocab_size-2": 42,
        "unique-2": 32,
        "entropy-2": 5.208500040703918,
        "cond_entropy-2": 0.5638307448813009,
        "distinct-3": 0.7735849056603774,
        "vocab_size-3": 41,
        "unique-3": 34,
        "entropy-3": 5.203874463793058,
        "cond_entropy-3": -0.018022358990405624,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 3.5433819375782165,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.456529055211291,
        "distinct-2-nopunct": 0.7115384615384616,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.02698683335929,
        "cond_entropy-2-nopunct": 0.6407236269428841,
        "distinct-3-nopunct": 0.782608695652174,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.023136955868884,
        "cond_entropy-3-nopunct": -0.019375316478937157,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.455919543598001,
        "rouge1": {
            "precision": 0.9122,
            "recall": 0.85512,
            "fmeasure": 0.88077
        },
        "rouge2": {
            "precision": 0.78335,
            "recall": 0.73842,
            "fmeasure": 0.75857
        },
        "rougeL": {
            "precision": 0.89484,
            "recall": 0.8406,
            "fmeasure": 0.86505
        },
        "rougeLsum": {
            "precision": 0.89484,
            "recall": 0.8406,
            "fmeasure": 0.86505
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.23076923076923078,
            "3": 0.8809523809523809
        },
        "bleu": 75.33396,
        "nubia": {
            "semantic_relation": 4.34451,
            "contradiction": 22.34178,
            "irrelevancy": 11.57194,
            "logical_agreement": 66.08629,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.11354,
            "nubia_score": 0.81926
        },
        "meteor": 0.5103838831821695,
        "bleurt": 0.63194,
        "bertscore": {
            "precision": 0.97901,
            "recall": 0.96618,
            "f1": 0.97245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.681880802803401,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.4083801270078083,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.4548223999466066,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1681907449941207,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "bleu": 41.12176,
        "nubia": {
            "semantic_relation": 4.43122,
            "contradiction": 0.24231,
            "irrelevancy": 97.69814,
            "logical_agreement": 2.05955,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.99247,
            "nubia_score": 0.81442
        },
        "meteor": 0.40391483707176334,
        "bleurt": 0.58168,
        "bertscore": {
            "precision": 0.91274,
            "recall": 0.95219,
            "f1": 0.93205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.69041575982343,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6571428571428571,
        "vocab_size-1": 46,
        "unique-1": 35,
        "entropy-1": 5.256148510105488,
        "distinct-2": 0.7846153846153846,
        "vocab_size-2": 51,
        "unique-2": 41,
        "entropy-2": 5.537602043731118,
        "cond_entropy-2": 0.17000787300656478,
        "distinct-3": 0.8666666666666667,
        "vocab_size-3": 52,
        "unique-3": 45,
        "entropy-3": 5.627642470572459,
        "cond_entropy-3": 0.13043757428278852,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 4.445222154178573,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.226409765557392,
        "distinct-2-nopunct": 0.7627118644067796,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.348579066237653,
        "cond_entropy-2-nopunct": 0.15382949003980725,
        "distinct-3-nopunct": 0.8518518518518519,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.4446118076789585,
        "cond_entropy-3-nopunct": 0.1269645917305804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.546805396537273,
        "rouge1": {
            "precision": 0.91582,
            "recall": 0.90625,
            "fmeasure": 0.91007
        },
        "rouge2": {
            "precision": 0.82516,
            "recall": 0.82337,
            "fmeasure": 0.82359
        },
        "rougeL": {
            "precision": 0.90841,
            "recall": 0.90519,
            "fmeasure": 0.90609
        },
        "rougeLsum": {
            "precision": 0.90841,
            "recall": 0.90519,
            "fmeasure": 0.90609
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.8983050847457628
        },
        "bleu": 70.26775,
        "nubia": {
            "semantic_relation": 4.75172,
            "contradiction": 0.71415,
            "irrelevancy": 0.90359,
            "logical_agreement": 98.38226,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.56763,
            "nubia_score": 0.93031
        },
        "meteor": 0.5175034631584169,
        "bleurt": 0.78988,
        "bertscore": {
            "precision": 0.98868,
            "recall": 0.97939,
            "f1": 0.98309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.0,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 28,
        "unique-1": 20,
        "entropy-1": 4.668980145022533,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.47755304355428235,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.498939573903908,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.45818928780261536,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.997333840451075,
        "rouge1": {
            "precision": 0.92121,
            "recall": 0.92121,
            "fmeasure": 0.92121
        },
        "rouge2": {
            "precision": 0.65351,
            "recall": 0.67203,
            "fmeasure": 0.66228
        },
        "rougeL": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "rougeLsum": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "bleu": 54.47186,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.57754,
            "irrelevancy": 20.30422,
            "logical_agreement": 78.11823,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.10045,
            "nubia_score": 0.96457
        },
        "meteor": 0.4715439325255402,
        "bleurt": 0.60623,
        "bertscore": {
            "precision": 0.96493,
            "recall": 0.96896,
            "f1": 0.96693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7209302325581395,
        "vocab_size-1": 31,
        "unique-1": 20,
        "entropy-1": 4.850569696512249,
        "distinct-2": 0.875,
        "vocab_size-2": 35,
        "unique-2": 30,
        "entropy-2": 5.0719280948873635,
        "cond_entropy-2": 0.1456633401852642,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 34,
        "unique-3": 31,
        "entropy-3": 5.047291203466791,
        "cond_entropy-3": -0.00436662115030452,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.772581706041735,
        "distinct-2-nopunct": 0.8611111111111112,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.892147223664533,
        "cond_entropy-2-nopunct": 0.16230056035784188,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.8625759375402735,
        "cond_entropy-3-nopunct": -0.004318760871737893,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4775487611970926,
        "rouge1": {
            "precision": 0.45123,
            "recall": 0.50909,
            "fmeasure": 0.47514
        },
        "rouge2": {
            "precision": 0.15046,
            "recall": 0.16097,
            "fmeasure": 0.15159
        },
        "rougeL": {
            "precision": 0.37821,
            "recall": 0.37585,
            "fmeasure": 0.37056
        },
        "rougeLsum": {
            "precision": 0.37821,
            "recall": 0.37585,
            "fmeasure": 0.37056
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.25,
            "3": 0.5172413793103449
        },
        "bleu": 17.86693,
        "nubia": {
            "semantic_relation": 3.60719,
            "contradiction": 4.18657,
            "irrelevancy": 59.32682,
            "logical_agreement": 36.48661,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.64493,
            "nubia_score": 0.56835
        },
        "meteor": 0.22726006357249467,
        "bleurt": -0.18552,
        "bertscore": {
            "precision": 0.83607,
            "recall": 0.84562,
            "f1": 0.83714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971672,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.417538083023762,
        "rouge1": {
            "precision": 0.77946,
            "recall": 0.62715,
            "fmeasure": 0.68354
        },
        "rouge2": {
            "precision": 0.4875,
            "recall": 0.40476,
            "fmeasure": 0.43439
        },
        "rougeL": {
            "precision": 0.63131,
            "recall": 0.53965,
            "fmeasure": 0.57354
        },
        "rougeLsum": {
            "precision": 0.63131,
            "recall": 0.53965,
            "fmeasure": 0.57354
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.7
        },
        "bleu": 26.55855,
        "nubia": {
            "semantic_relation": 4.27251,
            "contradiction": 0.5136,
            "irrelevancy": 0.58506,
            "logical_agreement": 98.90135,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.61986,
            "nubia_score": 0.78152
        },
        "meteor": 0.4255686679116239,
        "bleurt": 0.35038,
        "bertscore": {
            "precision": 0.94791,
            "recall": 0.92076,
            "f1": 0.93367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6530612244897959,
        "vocab_size-1": 32,
        "unique-1": 25,
        "entropy-1": 4.645122599128944,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 40,
        "unique-2": 36,
        "entropy-2": 5.229871195093382,
        "cond_entropy-2": 0.5446154271121636,
        "distinct-3": 0.9302325581395349,
        "vocab_size-3": 40,
        "unique-3": 38,
        "entropy-3": 5.26917434767504,
        "cond_entropy-3": 0.013281577765165545,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.08248290463863,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.5417444851704865,
        "distinct-2-nopunct": 0.8809523809523809,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.1182751607709775,
        "cond_entropy-2-nopunct": 0.568921171601329,
        "distinct-3-nopunct": 0.9487179487179487,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.163482026499081,
        "cond_entropy-3-nopunct": -0.014993088513405336,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9088669166200978,
        "rouge1": {
            "precision": 0.69815,
            "recall": 0.69493,
            "fmeasure": 0.68728
        },
        "rouge2": {
            "precision": 0.48663,
            "recall": 0.50366,
            "fmeasure": 0.48589
        },
        "rougeL": {
            "precision": 0.58704,
            "recall": 0.58581,
            "fmeasure": 0.57728
        },
        "rougeLsum": {
            "precision": 0.58704,
            "recall": 0.58581,
            "fmeasure": 0.57728
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.6153846153846154,
            "3": 0.64
        },
        "bleu": 40.73267,
        "nubia": {
            "semantic_relation": 4.43864,
            "contradiction": 0.49156,
            "irrelevancy": 33.80849,
            "logical_agreement": 65.69994,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.50338,
            "nubia_score": 0.94454
        },
        "meteor": 0.37760299276124554,
        "bleurt": 0.35571,
        "bertscore": {
            "precision": 0.93448,
            "recall": 0.90907,
            "f1": 0.92122
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 2.3570226039551585,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 21,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 29,
        "entropy-1": 5.041797285193381,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.5081285447002617,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.04671414660772557,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.9680949908370575,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.49821593948489207,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.05191662593186679,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0601475567767307,
        "rouge1": {
            "precision": 0.43398,
            "recall": 0.67166,
            "fmeasure": 0.5242
        },
        "rouge2": {
            "precision": 0.17017,
            "recall": 0.29718,
            "fmeasure": 0.21382
        },
        "rougeL": {
            "precision": 0.33938,
            "recall": 0.57076,
            "fmeasure": 0.42182
        },
        "rougeLsum": {
            "precision": 0.33938,
            "recall": 0.57076,
            "fmeasure": 0.42182
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.7333333333333333,
            "3": 0.5384615384615384
        },
        "bleu": 12.73185,
        "nubia": {
            "semantic_relation": 2.89649,
            "contradiction": 0.36511,
            "irrelevancy": 97.85903,
            "logical_agreement": 1.77586,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.89561,
            "nubia_score": 0.4283
        },
        "meteor": 0.35092967992275986,
        "bleurt": -0.127,
        "bertscore": {
            "precision": 0.78234,
            "recall": 0.86001,
            "f1": 0.81455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 44,
        "unique-1": 34,
        "entropy-1": 5.275652212593064,
        "distinct-2": 0.9298245614035088,
        "vocab_size-2": 53,
        "unique-2": 49,
        "entropy-2": 5.692539136971754,
        "cond_entropy-2": 0.36669091818365757,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 51,
        "unique-3": 48,
        "entropy-3": 5.643776391052356,
        "cond_entropy-3": -0.04096547496423611,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.215552159365316,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.546593564294941,
        "cond_entropy-2-nopunct": 0.3636841484388125,
        "distinct-3-nopunct": 0.9387755102040817,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.492260864523372,
        "cond_entropy-3-nopunct": -0.044913547495271496,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9117623108844284,
        "rouge1": {
            "precision": 0.78463,
            "recall": 0.72585,
            "fmeasure": 0.75089
        },
        "rouge2": {
            "precision": 0.50475,
            "recall": 0.46141,
            "fmeasure": 0.4798
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.53846,
            "fmeasure": 0.55744
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.53846,
            "fmeasure": 0.55744
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.17647058823529413,
            "3": 0.75
        },
        "bleu": 31.40565,
        "nubia": {
            "semantic_relation": 4.19351,
            "contradiction": 16.89362,
            "irrelevancy": 7.23221,
            "logical_agreement": 75.87418,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.52985,
            "nubia_score": 0.62938
        },
        "meteor": 0.32735188573328494,
        "bleurt": -0.12035,
        "bertscore": {
            "precision": 0.88789,
            "recall": 0.87025,
            "f1": 0.87888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.9370039370059056,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 38,
        "unique-1": 29,
        "entropy-1": 5.079965439170125,
        "distinct-2": 0.875,
        "vocab_size-2": 42,
        "unique-2": 37,
        "entropy-2": 5.319235677759421,
        "cond_entropy-2": 0.12430976183687528,
        "distinct-3": 0.9318181818181818,
        "vocab_size-3": 41,
        "unique-3": 38,
        "entropy-3": 5.323067982273659,
        "cond_entropy-3": 0.027989288419856113,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.038319436645929,
        "distinct-2-nopunct": 0.8604651162790697,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.12963946395411,
        "cond_entropy-2-nopunct": 0.10248549613157173,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.131556065016094,
        "cond_entropy-3-nopunct": 0.03233970780536746,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.098867791372461,
        "rouge1": {
            "precision": 0.925,
            "recall": 0.88462,
            "fmeasure": 0.90217
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.8125,
            "fmeasure": 0.82143
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.86538,
            "fmeasure": 0.88043
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.86538,
            "fmeasure": 0.88043
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8775510204081632
        },
        "bleu": 74.1589,
        "nubia": {
            "semantic_relation": 4.71946,
            "contradiction": 2.8939,
            "irrelevancy": 1.15332,
            "logical_agreement": 95.95278,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.13379,
            "nubia_score": 0.88302
        },
        "meteor": 0.519238961017518,
        "bleurt": 0.75843,
        "bertscore": {
            "precision": 0.97624,
            "recall": 0.95912,
            "f1": 0.9674
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.944797625754069,
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        },
        "meteor": 1.0,
        "bleurt": 0.56963,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 93,
        "mean_pred_length": 23.25,
        "std_pred_length": 10.328964130056798,
        "median_pred_length": 20.5,
        "min_pred_length": 12,
        "max_pred_length": 40,
        "distinct-1": 0.6344086021505376,
        "vocab_size-1": 59,
        "unique-1": 37,
        "entropy-1": 5.641204241169029,
        "distinct-2": 0.8539325842696629,
        "vocab_size-2": 76,
        "unique-2": 63,
        "entropy-2": 6.18359859950573,
        "cond_entropy-2": 0.49286422664855645,
        "distinct-3": 0.8941176470588236,
        "vocab_size-3": 76,
        "unique-3": 67,
        "entropy-3": 6.197626230255354,
        "cond_entropy-3": 0.027775152230127442,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 7.660776723022281,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.649776475703644,
        "distinct-2-nopunct": 0.8767123287671232,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.943249216414268,
        "cond_entropy-2-nopunct": 0.29988425112110184,
        "distinct-3-nopunct": 0.927536231884058,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.963596920546279,
        "cond_entropy-3-nopunct": 0.020149173260470575,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.131008943291217,
        "rouge1": {
            "precision": 0.74444,
            "recall": 0.67181,
            "fmeasure": 0.70387
        },
        "rouge2": {
            "precision": 0.57146,
            "recall": 0.51169,
            "fmeasure": 0.5376
        },
        "rougeL": {
            "precision": 0.59861,
            "recall": 0.54226,
            "fmeasure": 0.56695
        },
        "rougeLsum": {
            "precision": 0.59861,
            "recall": 0.54226,
            "fmeasure": 0.56695
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.6388888888888888
        },
        "bleu": 33.51439,
        "nubia": {
            "semantic_relation": 3.79076,
            "contradiction": 21.38537,
            "irrelevancy": 18.29492,
            "logical_agreement": 60.31971,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.10167,
            "nubia_score": 0.66145
        },
        "meteor": 0.2994696883133916,
        "bleurt": 0.1912,
        "bertscore": {
            "precision": 0.92285,
            "recall": 0.88068,
            "f1": 0.90096
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 42,
        "mean_pred_length": 10.5,
        "std_pred_length": 2.0615528128088303,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 12,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 32,
        "unique-1": 25,
        "entropy-1": 4.850534387012965,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.13863344598491653,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.04281761336971669,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 1.920286436967152,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.810672622327237,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.16084643561324513,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.04848208974812274,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.927331479020932,
        "rouge1": {
            "precision": 0.73929,
            "recall": 0.69127,
            "fmeasure": 0.7008
        },
        "rouge2": {
            "precision": 0.56944,
            "recall": 0.56049,
            "fmeasure": 0.55541
        },
        "rougeL": {
            "precision": 0.72738,
            "recall": 0.68532,
            "fmeasure": 0.69287
        },
        "rougeLsum": {
            "precision": 0.72738,
            "recall": 0.68532,
            "fmeasure": 0.69287
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2777777777777778,
            "3": 1.0
        },
        "bleu": 60.38035,
        "nubia": {
            "semantic_relation": 4.15247,
            "contradiction": 20.77629,
            "irrelevancy": 13.85919,
            "logical_agreement": 65.36452,
            "grammar_ref": 4.6519,
            "grammar_hyp": 5.01263,
            "nubia_score": 0.66662
        },
        "meteor": 0.41255963432897214,
        "bleurt": 0.27283,
        "bertscore": {
            "precision": 0.91788,
            "recall": 0.9028,
            "f1": 0.90954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.6875,
        "vocab_size-1": 22,
        "unique-1": 15,
        "entropy-1": 4.2621987351738495,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 28,
        "unique-2": 26,
        "entropy-2": 4.773557262275186,
        "cond_entropy-2": 0.4938786114230791,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": 0.043321469306228495,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.186569246460625,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.664497779200463,
        "cond_entropy-2-nopunct": 0.5293800576789717,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.717064442054546,
        "rouge1": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "rouge2": {
            "precision": 0.65625,
            "recall": 0.65696,
            "fmeasure": 0.6529
        },
        "rougeL": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "rougeLsum": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "bleu": 66.49127,
        "nubia": {
            "semantic_relation": 3.47406,
            "contradiction": 50.8117,
            "irrelevancy": 0.83739,
            "logical_agreement": 48.35091,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.07251,
            "nubia_score": 0.53739
        },
        "meteor": 0.45150508987937693,
        "bleurt": 0.55241,
        "bertscore": {
            "precision": 0.96387,
            "recall": 0.95405,
            "f1": 0.95067
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 69,
        "mean_pred_length": 23.0,
        "std_pred_length": 16.51262143533445,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 46,
        "distinct-1": 0.6231884057971014,
        "vocab_size-1": 43,
        "unique-1": 32,
        "entropy-1": 5.1552717392300895,
        "distinct-2": 0.7575757575757576,
        "vocab_size-2": 50,
        "unique-2": 42,
        "entropy-2": 5.453188816197036,
        "cond_entropy-2": 0.26920299591361796,
        "distinct-3": 0.8253968253968254,
        "vocab_size-3": 52,
        "unique-3": 46,
        "entropy-3": 5.56816186777266,
        "cond_entropy-3": 0.14312568505950335,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 12.036980056845193,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.7090909090909091,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.049274940679377,
        "distinct-2-nopunct": 0.8269230769230769,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.296217602590058,
        "cond_entropy-2-nopunct": 0.28917832188251996,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.323594282758262,
        "cond_entropy-3-nopunct": 0.05212497295704413,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0579266806679666,
        "rouge1": {
            "precision": 0.59008,
            "recall": 0.68445,
            "fmeasure": 0.61827
        },
        "rouge2": {
            "precision": 0.39776,
            "recall": 0.46078,
            "fmeasure": 0.41646
        },
        "rougeL": {
            "precision": 0.55278,
            "recall": 0.63913,
            "fmeasure": 0.57814
        },
        "rougeLsum": {
            "precision": 0.55278,
            "recall": 0.63913,
            "fmeasure": 0.57814
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.6086956521739131,
            "3": 0.47058823529411764
        },
        "bleu": 28.76458,
        "nubia": {
            "semantic_relation": 3.90199,
            "contradiction": 0.48519,
            "irrelevancy": 60.72559,
            "logical_agreement": 38.78922,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.6622,
            "nubia_score": 0.49028
        },
        "meteor": 0.34902349689165685,
        "bleurt": 0.24464,
        "bertscore": {
            "precision": 0.91232,
            "recall": 0.91334,
            "f1": 0.91269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.0,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.084962500721157,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.3290145724615955,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.362496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6602869913864873,
        "rouge1": {
            "precision": 0.86458,
            "recall": 0.65822,
            "fmeasure": 0.70866
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.40334,
            "fmeasure": 0.4281
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.53185,
            "fmeasure": 0.58835
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.53185,
            "fmeasure": 0.58835
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.65
        },
        "bleu": 20.60368,
        "nubia": {
            "semantic_relation": 4.69111,
            "contradiction": 0.42352,
            "irrelevancy": 14.64655,
            "logical_agreement": 84.92992,
            "grammar_ref": 4.12394,
            "grammar_hyp": 4.37485,
            "nubia_score": 0.86549
        },
        "meteor": 0.32644195303146195,
        "bleurt": 0.10636,
        "bertscore": {
            "precision": 0.94547,
            "recall": 0.88345,
            "f1": 0.91059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.546060565661952,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 16,
        "distinct-1": 0.9393939393939394,
        "vocab_size-1": 31,
        "unique-1": 30,
        "entropy-1": 4.900306619292896,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.13750352374993471,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.15200309344505,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.857980995127571,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.15754127698647996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.17687776208407924,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2538826350453296,
        "rouge1": {
            "precision": 0.80286,
            "recall": 0.59137,
            "fmeasure": 0.67554
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.39438,
            "fmeasure": 0.45609
        },
        "rougeL": {
            "precision": 0.77323,
            "recall": 0.54848,
            "fmeasure": 0.63599
        },
        "rougeLsum": {
            "precision": 0.77323,
            "recall": 0.54848,
            "fmeasure": 0.63599
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "bleu": 42.22102,
        "nubia": {
            "semantic_relation": 3.75552,
            "contradiction": 0.62003,
            "irrelevancy": 33.57056,
            "logical_agreement": 65.80941,
            "grammar_ref": 4.66623,
            "grammar_hyp": 5.34161,
            "nubia_score": 0.60108
        },
        "meteor": 0.35297930619238665,
        "bleurt": 0.10637,
        "bertscore": {
            "precision": 0.9293,
            "recall": 0.884,
            "f1": 0.89994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.812814895472356,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.30940744572636597,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.740436146246769,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.29601824788118386,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2019505088723355,
        "rouge1": {
            "precision": 0.81229,
            "recall": 0.76852,
            "fmeasure": 0.77563
        },
        "rouge2": {
            "precision": 0.59192,
            "recall": 0.57763,
            "fmeasure": 0.57275
        },
        "rougeL": {
            "precision": 0.76599,
            "recall": 0.73241,
            "fmeasure": 0.73507
        },
        "rougeLsum": {
            "precision": 0.76599,
            "recall": 0.73241,
            "fmeasure": 0.73507
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "bleu": 45.04028,
        "nubia": {
            "semantic_relation": 3.97838,
            "contradiction": 1.04822,
            "irrelevancy": 72.05894,
            "logical_agreement": 26.89284,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.17701,
            "nubia_score": 0.68065
        },
        "meteor": 0.42660941915345724,
        "bleurt": 0.13701,
        "bertscore": {
            "precision": 0.93287,
            "recall": 0.93443,
            "f1": 0.92909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4107918909526207,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.67949,
            "fmeasure": 0.57586
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "bleu": 39.67088,
        "nubia": {
            "semantic_relation": 2.93054,
            "contradiction": 95.03615,
            "irrelevancy": 4.63757,
            "logical_agreement": 0.32627,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.02961,
            "nubia_score": 0.49817
        },
        "meteor": 0.40718621833397906,
        "bleurt": 0.36657,
        "bertscore": {
            "precision": 0.91098,
            "recall": 0.96814,
            "f1": 0.93869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.012496476250064989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.160091652250454,
        "rouge1": {
            "precision": 0.72778,
            "recall": 0.70213,
            "fmeasure": 0.70905
        },
        "rouge2": {
            "precision": 0.59428,
            "recall": 0.58162,
            "fmeasure": 0.58136
        },
        "rougeL": {
            "precision": 0.71389,
            "recall": 0.68931,
            "fmeasure": 0.69572
        },
        "rougeLsum": {
            "precision": 0.71389,
            "recall": 0.68931,
            "fmeasure": 0.69572
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.8125
        },
        "bleu": 48.8556,
        "nubia": {
            "semantic_relation": 3.6506,
            "contradiction": 67.8381,
            "irrelevancy": 28.94807,
            "logical_agreement": 3.21383,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.71944,
            "nubia_score": 0.4102
        },
        "meteor": 0.3895284087997485,
        "bleurt": -0.00412,
        "bertscore": {
            "precision": 0.92923,
            "recall": 0.93086,
            "f1": 0.92254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.149966532662911,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6627906976744186,
        "vocab_size-1": 57,
        "unique-1": 45,
        "entropy-1": 5.488229470247946,
        "distinct-2": 0.9375,
        "vocab_size-2": 75,
        "unique-2": 70,
        "entropy-2": 6.196928094887357,
        "cond_entropy-2": 0.5851790834193917,
        "distinct-3": 0.9864864864864865,
        "vocab_size-3": 73,
        "unique-3": 72,
        "entropy-3": 6.182426338601928,
        "cond_entropy-3": -0.0043666211503045164,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 3.496029493900505,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7236842105263158,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.495805678460298,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.014997302659257,
        "cond_entropy-2-nopunct": 0.5693734957689559,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.019908016944966432,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.990299885754002,
        "rouge1": {
            "precision": 0.80256,
            "recall": 0.73693,
            "fmeasure": 0.75897
        },
        "rouge2": {
            "precision": 0.62847,
            "recall": 0.57047,
            "fmeasure": 0.59042
        },
        "rougeL": {
            "precision": 0.73114,
            "recall": 0.67483,
            "fmeasure": 0.69344
        },
        "rougeLsum": {
            "precision": 0.73114,
            "recall": 0.67483,
            "fmeasure": 0.69344
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7777777777777778,
            "3": 0.7101449275362319
        },
        "bleu": 47.77634,
        "nubia": {
            "semantic_relation": 4.13249,
            "contradiction": 20.61908,
            "irrelevancy": 24.40901,
            "logical_agreement": 54.97191,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.077,
            "nubia_score": 0.70149
        },
        "meteor": 0.3917906098360233,
        "bleurt": 0.27167,
        "bertscore": {
            "precision": 0.93768,
            "recall": 0.91265,
            "f1": 0.92398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.152391277629865,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2545471137682952,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9841837197791885,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0604999937113702,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.56142,
            "fmeasure": 0.67116
        },
        "rouge2": {
            "precision": 0.68421,
            "recall": 0.44444,
            "fmeasure": 0.53461
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.56142,
            "fmeasure": 0.67116
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.56142,
            "fmeasure": 0.67116
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 39.6701,
        "nubia": {
            "semantic_relation": 2.77873,
            "contradiction": 97.82447,
            "irrelevancy": 1.84418,
            "logical_agreement": 0.33134,
            "grammar_ref": 3.4256,
            "grammar_hyp": 4.03125,
            "nubia_score": 0.20029
        },
        "meteor": 0.33425357515877374,
        "bleurt": -0.0147,
        "bertscore": {
            "precision": 0.9624,
            "recall": 0.87236,
            "f1": 0.91387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.582038907903782,
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.74411,
            "fmeasure": 0.75355
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.66667,
            "fmeasure": 0.63158
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.66667,
            "fmeasure": 0.63158
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "bleu": 9.67915,
        "nubia": {
            "semantic_relation": 4.92887,
            "contradiction": 0.20503,
            "irrelevancy": 0.61016,
            "logical_agreement": 99.18482,
            "grammar_ref": 6.26263,
            "grammar_hyp": 6.45941,
            "nubia_score": 0.8932
        },
        "meteor": 0.32114629127633987,
        "bleurt": 0.62634,
        "bertscore": {
            "precision": 0.95592,
            "recall": 0.92029,
            "f1": 0.93777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.389917098318631,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53257
        },
        "rouge2": {
            "precision": 0.10714,
            "recall": 0.12238,
            "fmeasure": 0.11407
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.38095,
            "fmeasure": 0.35504
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.38095,
            "fmeasure": 0.35504
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.7142857142857143
        },
        "bleu": 8.03228,
        "nubia": {
            "semantic_relation": 3.72771,
            "contradiction": 3.54209,
            "irrelevancy": 94.76796,
            "logical_agreement": 1.68994,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.46166,
            "nubia_score": 0.63432
        },
        "meteor": 0.28084909398746477,
        "bleurt": 0.11884,
        "bertscore": {
            "precision": 0.85018,
            "recall": 0.88823,
            "f1": 0.86879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3764992953429935,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0,
        "bleurt": 0.91462,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.251192788981044,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0,
        "bleurt": 0.64779,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0482519504853314,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.65,
            "fmeasure": 0.74286
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.36842,
            "fmeasure": 0.42424
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.4,
            "fmeasure": 0.45714
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.4,
            "fmeasure": 0.45714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bleu": 22.89416,
        "nubia": {
            "semantic_relation": 4.61459,
            "contradiction": 0.25598,
            "irrelevancy": 1.17774,
            "logical_agreement": 98.56628,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.25741,
            "nubia_score": 0.90275
        },
        "meteor": 0.3591749598502967,
        "bleurt": 0.38196,
        "bertscore": {
            "precision": 0.9094,
            "recall": 0.88162,
            "f1": 0.89529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.08740439341878142,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.30559,
            "fmeasure": 0.44388
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.13056,
            "fmeasure": 0.19394
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.24072,
            "fmeasure": 0.35352
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.24072,
            "fmeasure": 0.35352
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.08333333333333333,
            "3": 0.38461538461538464
        },
        "bleu": 5.35133,
        "nubia": {
            "semantic_relation": 3.25791,
            "contradiction": 3.824,
            "irrelevancy": 95.43497,
            "logical_agreement": 0.74103,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.92669,
            "nubia_score": 0.19734
        },
        "meteor": 0.15559633973890294,
        "bleurt": -0.73467,
        "bertscore": {
            "precision": 0.89182,
            "recall": 0.8035,
            "f1": 0.84536
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.018549068142959,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "bleu": 69.85342,
        "nubia": {
            "semantic_relation": 4.38462,
            "contradiction": 0.18156,
            "irrelevancy": 63.65703,
            "logical_agreement": 36.16141,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.57005,
            "nubia_score": 0.947
        },
        "meteor": 0.5255759325753065,
        "bleurt": 0.6035,
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0990195135927845,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 39,
        "unique-1": 30,
        "entropy-1": 5.157431959491295,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 46,
        "unique-2": 44,
        "entropy-2": 5.5016291673878275,
        "cond_entropy-2": 0.27732413800647193,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 44,
        "unique-3": 43,
        "entropy-3": 5.447408651885229,
        "cond_entropy-3": -0.04866495994703734,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.019060684834029,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.3084077152934377,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.524921146975272,
        "rouge1": {
            "precision": 0.72286,
            "recall": 0.61779,
            "fmeasure": 0.66073
        },
        "rouge2": {
            "precision": 0.45741,
            "recall": 0.37823,
            "fmeasure": 0.41051
        },
        "rougeL": {
            "precision": 0.71701,
            "recall": 0.6125,
            "fmeasure": 0.65517
        },
        "rougeLsum": {
            "precision": 0.71701,
            "recall": 0.6125,
            "fmeasure": 0.65517
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 42.12667,
        "nubia": {
            "semantic_relation": 4.05097,
            "contradiction": 0.17393,
            "irrelevancy": 5.87383,
            "logical_agreement": 93.95224,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.11674,
            "nubia_score": 0.78361
        },
        "meteor": 0.405812844746954,
        "bleurt": 0.33317,
        "bertscore": {
            "precision": 0.93896,
            "recall": 0.9082,
            "f1": 0.91931
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 389,
        "total_length": 6787,
        "mean_pred_length": 17.447300771208226,
        "std_pred_length": 5.218655892166845,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 36,
        "distinct-1": 0.019596287019301606,
        "vocab_size-1": 133,
        "unique-1": 8,
        "entropy-1": 5.749801298818734,
        "distinct-2": 0.052672710221944356,
        "vocab_size-2": 337,
        "unique-2": 53,
        "entropy-2": 7.205439733489851,
        "cond_entropy-2": 1.3247079918320759,
        "distinct-3": 0.08620402729239474,
        "vocab_size-3": 518,
        "unique-3": 109,
        "entropy-3": 7.993232309625446,
        "cond_entropy-3": 0.8086004619564199,
        "total_length-nopunct": 6202,
        "mean_pred_length-nopunct": 15.94344473007712,
        "std_pred_length-nopunct": 4.838458767987584,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.021122218639148663,
        "vocab_size-1-nopunct": 131,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 5.8241754347788675,
        "distinct-2-nopunct": 0.0553930844658524,
        "vocab_size-2-nopunct": 322,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 7.153285328102193,
        "cond_entropy-2-nopunct": 1.4030252800693839,
        "distinct-3-nopunct": 0.09273598820058997,
        "vocab_size-3-nopunct": 503,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 7.997303626417428,
        "cond_entropy-3-nopunct": 0.8466529572864404,
        "msttr-100": 0.26851,
        "msttr-100_nopunct": 0.26468,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.8210947386572185,
        "rouge1": {
            "precision": 0.7245,
            "recall": 0.68008,
            "fmeasure": 0.68403
        },
        "rouge2": {
            "precision": 0.45986,
            "recall": 0.43111,
            "fmeasure": 0.43308
        },
        "rougeL": {
            "precision": 0.56339,
            "recall": 0.52282,
            "fmeasure": 0.52878
        },
        "rougeLsum": {
            "precision": 0.56339,
            "recall": 0.52282,
            "fmeasure": 0.52878
        },
        "local_recall": {
            "1": 0.6614083590827777
        },
        "bleu": 30.79309,
        "nubia": {
            "semantic_relation": 4.12067,
            "contradiction": 4.34758,
            "irrelevancy": 28.63814,
            "logical_agreement": 67.01428,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.82576,
            "nubia_score": 0.73789
        },
        "meteor": 0.3468877177654031,
        "bleurt": 0.11298,
        "bertscore": {
            "precision": 0.91658,
            "recall": 0.90212,
            "f1": 0.90877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6017006625380596,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bleu": 45.46697,
        "nubia": {
            "semantic_relation": 4.27352,
            "contradiction": 6.06656,
            "irrelevancy": 34.69403,
            "logical_agreement": 59.23942,
            "grammar_ref": 4.85143,
            "grammar_hyp": 5.53057,
            "nubia_score": 0.55699
        },
        "meteor": 0.4486121983053691,
        "bleurt": -0.11575,
        "bertscore": {
            "precision": 0.89081,
            "recall": 0.92678,
            "f1": 0.90844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.224744871391589,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.803055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.20229933717060217,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.16992500144231223,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.224744871391589,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.815622570826658,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.2286652330002962,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.1926450779423958,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.278977857451522,
        "rouge1": {
            "precision": 0.72969,
            "recall": 0.73929,
            "fmeasure": 0.72297
        },
        "rouge2": {
            "precision": 0.5369,
            "recall": 0.54506,
            "fmeasure": 0.52893
        },
        "rougeL": {
            "precision": 0.70191,
            "recall": 0.71336,
            "fmeasure": 0.69616
        },
        "rougeLsum": {
            "precision": 0.70191,
            "recall": 0.71336,
            "fmeasure": 0.69616
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6,
            "3": 0.72
        },
        "bleu": 58.68796,
        "nubia": {
            "semantic_relation": 4.00026,
            "contradiction": 0.49273,
            "irrelevancy": 50.35148,
            "logical_agreement": 49.15579,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.76219,
            "nubia_score": 0.72615
        },
        "meteor": 0.4173775180257288,
        "bleurt": 0.43232,
        "bertscore": {
            "precision": 0.92507,
            "recall": 0.92678,
            "f1": 0.92379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 5.312459150169743,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 5.003055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.10374148695780358,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.852168723603279,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.12479798526556812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6981413518163175,
        "rouge1": {
            "precision": 0.6784,
            "recall": 0.73214,
            "fmeasure": 0.68275
        },
        "rouge2": {
            "precision": 0.50763,
            "recall": 0.51029,
            "fmeasure": 0.49417
        },
        "rougeL": {
            "precision": 0.56111,
            "recall": 0.64087,
            "fmeasure": 0.58055
        },
        "rougeLsum": {
            "precision": 0.56111,
            "recall": 0.64087,
            "fmeasure": 0.58055
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.8125
        },
        "bleu": 37.31383,
        "nubia": {
            "semantic_relation": 4.00038,
            "contradiction": 1.79445,
            "irrelevancy": 43.01655,
            "logical_agreement": 55.18899,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.23761,
            "nubia_score": 0.74252
        },
        "meteor": 0.32580217316436527,
        "bleurt": 0.33171,
        "bertscore": {
            "precision": 0.92563,
            "recall": 0.94162,
            "f1": 0.93051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 1.5,
        "median_pred_length": 16.5,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.346831997884095,
        "distinct-2": 0.8709677419354839,
        "vocab_size-2": 27,
        "unique-2": 25,
        "entropy-2": 4.647429374763426,
        "cond_entropy-2": 0.2810852556841296,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 27,
        "unique-3": 26,
        "entropy-3": 4.694019357121935,
        "cond_entropy-3": 0.06774632274633388,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.276146310107718,
        "distinct-2-nopunct": 0.8620689655172413,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.530057719116298,
        "cond_entropy-2-nopunct": 0.24601959865813777,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.578780557638898,
        "cond_entropy-3-nopunct": 0.014311136718945176,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.067257053315643,
        "rouge1": {
            "precision": 0.62185,
            "recall": 0.83791,
            "fmeasure": 0.71344
        },
        "rouge2": {
            "precision": 0.38381,
            "recall": 0.52259,
            "fmeasure": 0.44155
        },
        "rougeL": {
            "precision": 0.61204,
            "recall": 0.79524,
            "fmeasure": 0.69019
        },
        "rougeLsum": {
            "precision": 0.61204,
            "recall": 0.79524,
            "fmeasure": 0.69019
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bleu": 36.05478,
        "nubia": {
            "semantic_relation": 4.79162,
            "contradiction": 0.36826,
            "irrelevancy": 15.02192,
            "logical_agreement": 84.60982,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.00117,
            "nubia_score": 0.87123
        },
        "meteor": 0.38367099304762475,
        "bleurt": 0.55798,
        "bertscore": {
            "precision": 0.90811,
            "recall": 0.91814,
            "f1": 0.91308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 2.5,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.9161269465882835,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.17139956434903558,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.04281761336971672,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864636,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.19247650427734211,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.047238912308487487,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.076946965343473,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96429,
            "fmeasure": 0.98148
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.91026,
            "fmeasure": 0.92667
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.89286,
            "fmeasure": 0.90741
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.89286,
            "fmeasure": 0.90741
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 0.9375
        },
        "bleu": 86.22478,
        "nubia": {
            "semantic_relation": 4.79482,
            "contradiction": 0.54744,
            "irrelevancy": 16.07733,
            "logical_agreement": 83.37523,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.88981,
            "nubia_score": 0.91875
        },
        "meteor": 0.612405556746418,
        "bleurt": 0.73756,
        "bertscore": {
            "precision": 0.9988,
            "recall": 0.99413,
            "f1": 0.99645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.22239242133644807,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.055725754669781385,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.167082557082436,
        "rouge1": {
            "precision": 0.90476,
            "recall": 0.95556,
            "fmeasure": 0.92713
        },
        "rouge2": {
            "precision": 0.80556,
            "recall": 0.81065,
            "fmeasure": 0.80405
        },
        "rougeL": {
            "precision": 0.90476,
            "recall": 0.95556,
            "fmeasure": 0.92713
        },
        "rougeLsum": {
            "precision": 0.90476,
            "recall": 0.95556,
            "fmeasure": 0.92713
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 76.94134,
        "nubia": {
            "semantic_relation": 4.58074,
            "contradiction": 7.79843,
            "irrelevancy": 2.93456,
            "logical_agreement": 89.26702,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.59856,
            "nubia_score": 0.84259
        },
        "meteor": 0.5428146347176549,
        "bleurt": 0.56826,
        "bertscore": {
            "precision": 0.9808,
            "recall": 0.97858,
            "f1": 0.97968
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.433288378057127,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 78.39204,
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "meteor": 0.5347033086663171,
        "bleurt": 0.61374,
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.821928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.4523152080299073,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.614369445886757,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.5057731339256741,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1533677205824238,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.64706,
            "fmeasure": 0.62857
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.25,
            "fmeasure": 0.24242
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.41176,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.41176,
            "fmeasure": 0.4
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "bleu": 16.58611,
        "nubia": {
            "semantic_relation": 4.26443,
            "contradiction": 29.6186,
            "irrelevancy": 47.51544,
            "logical_agreement": 22.86595,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.59557,
            "nubia_score": 0.76486
        },
        "meteor": 0.2981415426175763,
        "bleurt": 0.02507,
        "bertscore": {
            "precision": 0.9054,
            "recall": 0.89776,
            "f1": 0.90156
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3648189689631285,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.84175,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "bleu": 10.88697,
        "nubia": {
            "semantic_relation": 4.05623,
            "contradiction": 3.3209,
            "irrelevancy": 92.48141,
            "logical_agreement": 4.19768,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.98883,
            "nubia_score": 0.50759
        },
        "meteor": 0.37885739133291024,
        "bleurt": -0.38963,
        "bertscore": {
            "precision": 0.87464,
            "recall": 0.91728,
            "f1": 0.89545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.48632742052165673,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.22527,
            "fmeasure": 0.31053
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.13889,
            "fmeasure": 0.19608
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.20513,
            "fmeasure": 0.2807
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.20513,
            "fmeasure": 0.2807
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.2
        },
        "bleu": 11.14789,
        "nubia": {
            "semantic_relation": 2.75979,
            "contradiction": 2.58058,
            "irrelevancy": 96.03589,
            "logical_agreement": 1.38353,
            "grammar_ref": 5.35534,
            "grammar_hyp": 6.53297,
            "nubia_score": 0.17861
        },
        "meteor": 0.1284489847454993,
        "bleurt": -0.64067,
        "bertscore": {
            "precision": 0.85753,
            "recall": 0.7895,
            "f1": 0.82078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6427632821965177,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54762,
            "fmeasure": 0.51648
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.10096,
            "fmeasure": 0.0943
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8571428571428571
        },
        "bleu": 6.69008,
        "nubia": {
            "semantic_relation": 2.88205,
            "contradiction": 48.35945,
            "irrelevancy": 51.19135,
            "logical_agreement": 0.44921,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.16709,
            "nubia_score": 0.38721
        },
        "meteor": 0.2930113120669336,
        "bleurt": 0.24402,
        "bertscore": {
            "precision": 0.84286,
            "recall": 0.92076,
            "f1": 0.88009
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.75,
        "vocab_size-1": 21,
        "unique-1": 14,
        "entropy-1": 4.3073549220576055,
        "distinct-2": 0.8518518518518519,
        "vocab_size-2": 23,
        "unique-2": 19,
        "entropy-2": 4.458591205867173,
        "cond_entropy-2": 0.16975480232808673,
        "distinct-3": 0.8846153846153846,
        "vocab_size-3": 23,
        "unique-3": 20,
        "entropy-3": 4.46967048737186,
        "cond_entropy-3": 0.022475292900700432,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.262692390839622,
        "cond_entropy-2-nopunct": 0.11251249881411757,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.277613436819114,
        "cond_entropy-3-nopunct": 0.026778753489375338,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.312886528821104,
        "rouge1": {
            "precision": 0.49275,
            "recall": 0.55988,
            "fmeasure": 0.52312
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.20875,
            "fmeasure": 0.19394
        },
        "rougeL": {
            "precision": 0.21739,
            "recall": 0.21437,
            "fmeasure": 0.21585
        },
        "rougeLsum": {
            "precision": 0.21739,
            "recall": 0.21437,
            "fmeasure": 0.21585
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "bleu": 6.14444,
        "nubia": {
            "semantic_relation": 3.36822,
            "contradiction": 4.43761,
            "irrelevancy": 84.02687,
            "logical_agreement": 11.53552,
            "grammar_ref": 4.86737,
            "grammar_hyp": 4.75814,
            "nubia_score": 0.49193
        },
        "meteor": 0.2520816688039351,
        "bleurt": -0.32165,
        "bertscore": {
            "precision": 0.81898,
            "recall": 0.83378,
            "f1": 0.82416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 26,
        "entropy-1": 4.970573095811683,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 37,
        "unique-2": 33,
        "entropy-2": 5.16243005339857,
        "cond_entropy-2": 0.11165422749696848,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 37,
        "unique-3": 36,
        "entropy-3": 5.19529593449622,
        "cond_entropy-3": 0.048270245667607334,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8048780487804879,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.948896211882388,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.0374011976541135,
        "cond_entropy-2-nopunct": 0.12076728519822492,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.072140159802107,
        "cond_entropy-3-nopunct": 0.05278407492995249,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.957404396518136,
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "bleu": 76.5665,
        "nubia": {
            "semantic_relation": 4.53811,
            "contradiction": 0.50213,
            "irrelevancy": 48.32052,
            "logical_agreement": 51.17736,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.8389,
            "nubia_score": 0.83775
        },
        "meteor": 0.5609348411263468,
        "bleurt": 0.64742,
        "bertscore": {
            "precision": 0.97017,
            "recall": 0.97746,
            "f1": 0.97378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.090634124990776,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.6333333333333333,
        "vocab_size-1": 19,
        "unique-1": 10,
        "entropy-1": 4.12323142879762,
        "distinct-2": 0.8214285714285714,
        "vocab_size-2": 23,
        "unique-2": 18,
        "entropy-2": 4.450212064914748,
        "cond_entropy-2": 0.3115277194607619,
        "distinct-3": 0.8461538461538461,
        "vocab_size-3": 22,
        "unique-3": 18,
        "entropy-3": 4.392747410448783,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6428571428571429,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.039148671903071,
        "distinct-2-nopunct": 0.8076923076923077,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.315824333525707,
        "cond_entropy-2-nopunct": 0.3357684500960624,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.251629167387823,
        "cond_entropy-3-nopunct": -0.03214388408660256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9404010223804486,
        "rouge1": {
            "precision": 0.80838,
            "recall": 0.95833,
            "fmeasure": 0.87137
        },
        "rouge2": {
            "precision": 0.68542,
            "recall": 0.79966,
            "fmeasure": 0.73294
        },
        "rougeL": {
            "precision": 0.80838,
            "recall": 0.95833,
            "fmeasure": 0.87137
        },
        "rougeLsum": {
            "precision": 0.80838,
            "recall": 0.95833,
            "fmeasure": 0.87137
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.9473684210526315
        },
        "bleu": 63.31602,
        "nubia": {
            "semantic_relation": 4.9359,
            "contradiction": 0.15174,
            "irrelevancy": 0.70343,
            "logical_agreement": 99.14483,
            "grammar_ref": 4.16906,
            "grammar_hyp": 3.94614,
            "nubia_score": 0.95107
        },
        "meteor": 0.5194886535739337,
        "bleurt": 0.78843,
        "bertscore": {
            "precision": 0.95866,
            "recall": 0.97064,
            "f1": 0.96458
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.5358485029514135,
        "distinct-2": 0.8064516129032258,
        "vocab_size-2": 25,
        "unique-2": 19,
        "entropy-2": 4.567099536193328,
        "cond_entropy-2": -0.06875040183120606,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": -0.07541281690069972,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.50258340716107,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.378783493486177,
        "cond_entropy-2-nopunct": -0.0754128169006997,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.243856189774722,
        "cond_entropy-3-nopunct": -0.08349873228287957,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.530478399818445,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.93333,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.85185,
            "recall": 0.85185,
            "fmeasure": 0.85185
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 1.0
        },
        "bleu": 80.01822,
        "nubia": {
            "semantic_relation": 4.76862,
            "contradiction": 0.57904,
            "irrelevancy": 16.70478,
            "logical_agreement": 82.71619,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.73041,
            "nubia_score": 0.9033
        },
        "meteor": 0.5598024108436183,
        "bleurt": 0.76905,
        "bertscore": {
            "precision": 0.98151,
            "recall": 0.9746,
            "f1": 0.97802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 91,
        "mean_pred_length": 22.75,
        "std_pred_length": 6.2599920127744575,
        "median_pred_length": 21.0,
        "min_pred_length": 17,
        "max_pred_length": 32,
        "distinct-1": 0.7252747252747253,
        "vocab_size-1": 66,
        "unique-1": 56,
        "entropy-1": 5.770218645926572,
        "distinct-2": 0.9540229885057471,
        "vocab_size-2": 83,
        "unique-2": 80,
        "entropy-2": 6.3423126050192575,
        "cond_entropy-2": 0.5140514760707245,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": 0.037576507813418716,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 5.123475382979799,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.77816450456532,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.234120167580205,
        "cond_entropy-2-nopunct": 0.4856678425047669,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.02189479917924466,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.470060256222849,
        "rouge1": {
            "precision": 0.80914,
            "recall": 0.74364,
            "fmeasure": 0.76151
        },
        "rouge2": {
            "precision": 0.5189,
            "recall": 0.46854,
            "fmeasure": 0.48345
        },
        "rougeL": {
            "precision": 0.64931,
            "recall": 0.606,
            "fmeasure": 0.61661
        },
        "rougeLsum": {
            "precision": 0.64931,
            "recall": 0.606,
            "fmeasure": 0.61661
        },
        "local_recall": {
            "1": 0.6428571428571429,
            "2": 0.6,
            "3": 0.7313432835820896
        },
        "bleu": 43.2192,
        "nubia": {
            "semantic_relation": 4.2863,
            "contradiction": 10.03384,
            "irrelevancy": 23.97377,
            "logical_agreement": 65.99239,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.09025,
            "nubia_score": 0.71772
        },
        "meteor": 0.41203641842704275,
        "bleurt": 0.15222,
        "bertscore": {
            "precision": 0.94172,
            "recall": 0.91353,
            "f1": 0.92698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 9.187391537607729,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.5585585585585585,
        "vocab_size-1": 62,
        "unique-1": 35,
        "entropy-1": 5.62774959710356,
        "distinct-2": 0.8269230769230769,
        "vocab_size-2": 86,
        "unique-2": 68,
        "entropy-2": 6.354285871987252,
        "cond_entropy-2": 0.6161053078675656,
        "distinct-3": 0.8969072164948454,
        "vocab_size-3": 87,
        "unique-3": 77,
        "entropy-3": 6.393727275176832,
        "cond_entropy-3": 0.02318446425222112,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 8.42493868444956,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6082474226804123,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.6077599457177785,
        "distinct-2-nopunct": 0.8444444444444444,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.180741985218555,
        "cond_entropy-2-nopunct": 0.5769832369959509,
        "distinct-3-nopunct": 0.9156626506024096,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.2063647325517515,
        "cond_entropy-3-nopunct": -0.008379930042990804,
        "msttr-100": 0.59,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.11586020731396,
        "rouge1": {
            "precision": 0.62321,
            "recall": 0.66585,
            "fmeasure": 0.63395
        },
        "rouge2": {
            "precision": 0.31741,
            "recall": 0.34562,
            "fmeasure": 0.32568
        },
        "rougeL": {
            "precision": 0.50913,
            "recall": 0.55045,
            "fmeasure": 0.52048
        },
        "rougeLsum": {
            "precision": 0.50913,
            "recall": 0.55045,
            "fmeasure": 0.52048
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.7916666666666666,
            "3": 0.6739130434782609
        },
        "bleu": 30.50453,
        "nubia": {
            "semantic_relation": 3.97281,
            "contradiction": 14.80958,
            "irrelevancy": 44.0211,
            "logical_agreement": 41.16931,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.62973,
            "nubia_score": 0.68853
        },
        "meteor": 0.33713160541007736,
        "bleurt": 0.13581,
        "bertscore": {
            "precision": 0.90186,
            "recall": 0.90401,
            "f1": 0.90254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 93,
        "mean_pred_length": 23.25,
        "std_pred_length": 9.03811374126261,
        "median_pred_length": 23.5,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.6451612903225806,
        "vocab_size-1": 60,
        "unique-1": 44,
        "entropy-1": 5.538370662574006,
        "distinct-2": 0.898876404494382,
        "vocab_size-2": 80,
        "unique-2": 72,
        "entropy-2": 6.26500435790839,
        "cond_entropy-2": 0.6817252975156776,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 80,
        "unique-3": 75,
        "entropy-3": 6.291743877314178,
        "cond_entropy-3": 0.03665618166734473,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 20.75,
        "std_pred_length-nopunct": 8.257572282456872,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6987951807228916,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.536924698704312,
        "distinct-2-nopunct": 0.8860759493670886,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.066377108909212,
        "cond_entropy-2-nopunct": 0.5592303713513648,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.095485357162555,
        "cond_entropy-3-nopunct": 0.028436442347624036,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8534422888067614,
        "rouge1": {
            "precision": 0.54831,
            "recall": 0.52759,
            "fmeasure": 0.51591
        },
        "rouge2": {
            "precision": 0.25894,
            "recall": 0.24031,
            "fmeasure": 0.24127
        },
        "rougeL": {
            "precision": 0.41149,
            "recall": 0.39745,
            "fmeasure": 0.39088
        },
        "rougeLsum": {
            "precision": 0.41149,
            "recall": 0.39745,
            "fmeasure": 0.39088
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.42105263157894735,
            "3": 0.5925925925925926
        },
        "bleu": 29.198,
        "nubia": {
            "semantic_relation": 3.26601,
            "contradiction": 39.35294,
            "irrelevancy": 53.73582,
            "logical_agreement": 6.91124,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.00745,
            "nubia_score": 0.48044
        },
        "meteor": 0.29444605727481815,
        "bleurt": -0.1649,
        "bertscore": {
            "precision": 0.85813,
            "recall": 0.84494,
            "f1": 0.85035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 5.11737237261468,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7014925373134329,
        "vocab_size-1": 47,
        "unique-1": 34,
        "entropy-1": 5.362814332565773,
        "distinct-2": 0.9206349206349206,
        "vocab_size-2": 58,
        "unique-2": 53,
        "entropy-2": 5.818549764769761,
        "cond_entropy-2": 0.37340367714950545,
        "distinct-3": 0.9661016949152542,
        "vocab_size-3": 57,
        "unique-3": 55,
        "entropy-3": 5.814846439192345,
        "cond_entropy-3": 0.007058041116162005,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.358898943540674,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.33414846266518,
        "distinct-2-nopunct": 0.9107142857142857,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.628783493486179,
        "cond_entropy-2-nopunct": 0.3355451831740905,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.623516641218019,
        "cond_entropy-3-nopunct": 0.008469411468103209,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.725012879698966,
        "rouge1": {
            "precision": 0.72251,
            "recall": 0.76905,
            "fmeasure": 0.73655
        },
        "rouge2": {
            "precision": 0.4275,
            "recall": 0.47051,
            "fmeasure": 0.44573
        },
        "rougeL": {
            "precision": 0.56126,
            "recall": 0.62107,
            "fmeasure": 0.58292
        },
        "rougeLsum": {
            "precision": 0.56126,
            "recall": 0.62107,
            "fmeasure": 0.58292
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "bleu": 46.8802,
        "nubia": {
            "semantic_relation": 4.43917,
            "contradiction": 6.32133,
            "irrelevancy": 44.37889,
            "logical_agreement": 49.29978,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.12003,
            "nubia_score": 0.78668
        },
        "meteor": 0.38823649906516416,
        "bleurt": 0.52015,
        "bertscore": {
            "precision": 0.92345,
            "recall": 0.92661,
            "f1": 0.92497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8928571428571429,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.593069207771892,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.0346217911747682,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.432445714446437,
        "rouge1": {
            "precision": 0.96429,
            "recall": 0.88235,
            "fmeasure": 0.91935
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 0.78125,
            "fmeasure": 0.81034
        },
        "rougeL": {
            "precision": 0.96429,
            "recall": 0.88235,
            "fmeasure": 0.91935
        },
        "rougeLsum": {
            "precision": 0.96429,
            "recall": 0.88235,
            "fmeasure": 0.91935
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8148148148148148
        },
        "bleu": 66.86654,
        "nubia": {
            "semantic_relation": 4.8334,
            "contradiction": 0.42249,
            "irrelevancy": 0.57141,
            "logical_agreement": 99.0061,
            "grammar_ref": 5.04945,
            "grammar_hyp": 5.00144,
            "nubia_score": 0.93026
        },
        "meteor": 0.48434597349042036,
        "bleurt": 0.67055,
        "bertscore": {
            "precision": 0.97588,
            "recall": 0.95523,
            "f1": 0.96533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.22125202633764687,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.32479,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.07937,
            "fmeasure": 0.10741
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.25
        },
        "bleu": 4.42014,
        "nubia": {
            "semantic_relation": 2.77856,
            "contradiction": 5.43097,
            "irrelevancy": 30.9441,
            "logical_agreement": 63.62493,
            "grammar_ref": 4.61776,
            "grammar_hyp": 5.17462,
            "nubia_score": 0.22176
        },
        "meteor": 0.14078298802960232,
        "bleurt": -0.86803,
        "bertscore": {
            "precision": 0.84326,
            "recall": 0.76332,
            "f1": 0.8013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.50789957099271,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0,
        "bleurt": 0.89367,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8199590916958066,
        "rouge1": {
            "precision": 0.45,
            "recall": 0.5625,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.28571,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.5625,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.5625,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "bleu": 16.59039,
        "nubia": {
            "semantic_relation": 3.76257,
            "contradiction": 0.4451,
            "irrelevancy": 99.18662,
            "logical_agreement": 0.36829,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.89577,
            "nubia_score": 0.4506
        },
        "meteor": 0.29455071633689894,
        "bleurt": -0.98496,
        "bertscore": {
            "precision": 0.82861,
            "recall": 0.91851,
            "f1": 0.87007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3868853579532634,
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.64386,
            "fmeasure": 0.69069
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.37061,
            "fmeasure": 0.39167
        },
        "rougeL": {
            "precision": 0.62745,
            "recall": 0.56275,
            "fmeasure": 0.59247
        },
        "rougeLsum": {
            "precision": 0.62745,
            "recall": 0.56275,
            "fmeasure": 0.59247
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7222222222222222
        },
        "bleu": 33.11841,
        "nubia": {
            "semantic_relation": 4.24101,
            "contradiction": 0.23107,
            "irrelevancy": 39.1587,
            "logical_agreement": 60.61023,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.90583,
            "nubia_score": 0.77912
        },
        "meteor": 0.3674621577328844,
        "bleurt": 0.26858,
        "bertscore": {
            "precision": 0.92394,
            "recall": 0.9002,
            "f1": 0.91192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.14438990933517493,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0146323231216545,
        "rouge1": {
            "precision": 0.85833,
            "recall": 0.8096,
            "fmeasure": 0.83183
        },
        "rouge2": {
            "precision": 0.66162,
            "recall": 0.61851,
            "fmeasure": 0.63794
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.7846,
            "fmeasure": 0.80683
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.7846,
            "fmeasure": 0.80683
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.6923076923076923,
            "3": 0.8888888888888888
        },
        "bleu": 69.05122,
        "nubia": {
            "semantic_relation": 4.3786,
            "contradiction": 28.79191,
            "irrelevancy": 38.43976,
            "logical_agreement": 32.76833,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.69094,
            "nubia_score": 0.69874
        },
        "meteor": 0.49275687876847063,
        "bleurt": 0.4516,
        "bertscore": {
            "precision": 0.94051,
            "recall": 0.96227,
            "f1": 0.95113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6330370023236713,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "bleu": 42.95749,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "meteor": 0.42350497485471644,
        "bleurt": 0.45492,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 7.5,
        "median_pred_length": 21.5,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.7209302325581395,
        "vocab_size-1": 31,
        "unique-1": 24,
        "entropy-1": 4.722435394086041,
        "distinct-2": 0.8780487804878049,
        "vocab_size-2": 36,
        "unique-2": 31,
        "entropy-2": 5.1136495655936915,
        "cond_entropy-2": 0.3767668232450201,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 36,
        "unique-3": 33,
        "entropy-3": 5.131556065016094,
        "cond_entropy-3": 0.03041431680826748,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.725,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.615311532225102,
        "distinct-2-nopunct": 0.868421052631579,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.984769618706746,
        "cond_entropy-2-nopunct": 0.3803326424112339,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.003258334775643,
        "cond_entropy-3-nopunct": 0.0053308213320601774,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.631713151157583,
        "rouge1": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.76914,
            "fmeasure": 0.69726
        },
        "rougeL": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "rougeLsum": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "bleu": 68.81482,
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 1.81656,
            "irrelevancy": 1.78451,
            "logical_agreement": 96.39893,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.43929,
            "nubia_score": 0.9916
        },
        "meteor": 0.5331911546685959,
        "bleurt": 0.72192,
        "bertscore": {
            "precision": 0.96205,
            "recall": 0.96897,
            "f1": 0.96534
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.413909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.5591926814244064,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.04730571477835684,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.356558335416675,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.359201735291603,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.05658352836636749,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2133772004861587,
        "rouge1": {
            "precision": 0.50617,
            "recall": 0.56174,
            "fmeasure": 0.53231
        },
        "rouge2": {
            "precision": 0.25641,
            "recall": 0.29545,
            "fmeasure": 0.27444
        },
        "rougeL": {
            "precision": 0.37037,
            "recall": 0.42319,
            "fmeasure": 0.39487
        },
        "rougeLsum": {
            "precision": 0.37037,
            "recall": 0.42319,
            "fmeasure": 0.39487
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3,
            "3": 0.6666666666666666
        },
        "bleu": 14.29117,
        "nubia": {
            "semantic_relation": 3.8721,
            "contradiction": 0.06755,
            "irrelevancy": 99.11369,
            "logical_agreement": 0.81875,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.34542,
            "nubia_score": 0.67966
        },
        "meteor": 0.2794563633152097,
        "bleurt": -0.03891,
        "bertscore": {
            "precision": 0.84692,
            "recall": 0.86887,
            "f1": 0.85152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 2.770102775666474,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.7706422018348624,
        "vocab_size-1": 84,
        "unique-1": 72,
        "entropy-1": 6.141903017377922,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 100,
        "unique-2": 98,
        "entropy-2": 6.63320965569699,
        "cond_entropy-2": 0.3284043751013378,
        "distinct-3": 0.9894736842105263,
        "vocab_size-3": 94,
        "unique-3": 93,
        "entropy-3": 6.548802976752,
        "cond_entropy-3": -0.08151710206160051,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 2.5872528966106905,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8350515463917526,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.1925955741012935,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.447408651885218,
        "cond_entropy-2-nopunct": 0.28649330974617976,
        "distinct-3-nopunct": 0.9879518072289156,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.3509430458047635,
        "cond_entropy-3-nopunct": -0.09271727944058125,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.756079166078601,
        "rouge1": {
            "precision": 0.75767,
            "recall": 0.72172,
            "fmeasure": 0.71338
        },
        "rouge2": {
            "precision": 0.54859,
            "recall": 0.51547,
            "fmeasure": 0.51093
        },
        "rougeL": {
            "precision": 0.67549,
            "recall": 0.63121,
            "fmeasure": 0.63016
        },
        "rougeLsum": {
            "precision": 0.67549,
            "recall": 0.63121,
            "fmeasure": 0.63016
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.4642857142857143,
            "3": 0.7536231884057971
        },
        "bleu": 44.42407,
        "nubia": {
            "semantic_relation": 3.98904,
            "contradiction": 6.61884,
            "irrelevancy": 52.44887,
            "logical_agreement": 40.93229,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.62225,
            "nubia_score": 0.61697
        },
        "meteor": 0.37987602675789056,
        "bleurt": 0.20298,
        "bertscore": {
            "precision": 0.91851,
            "recall": 0.91411,
            "f1": 0.9103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 2.8613807855648994,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.5254237288135594,
        "vocab_size-1": 31,
        "unique-1": 17,
        "entropy-1": 4.636714659457992,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 40,
        "unique-2": 26,
        "entropy-2": 5.22217994075805,
        "cond_entropy-2": 0.5306237096566992,
        "distinct-3": 0.7450980392156863,
        "vocab_size-3": 38,
        "unique-3": 25,
        "entropy-3": 5.162621420402867,
        "cond_entropy-3": -0.054916969549958713,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.8613807855648994,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5454545454545454,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.590272895264168,
        "distinct-2-nopunct": 0.7254901960784313,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 5.108604018399662,
        "cond_entropy-2-nopunct": 0.5725340108421983,
        "distinct-3-nopunct": 0.7446808510638298,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 5.0439505538052956,
        "cond_entropy-3-nopunct": -0.05922186258825236,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.092033562511772,
        "rouge1": {
            "precision": 0.87847,
            "recall": 0.79693,
            "fmeasure": 0.82915
        },
        "rouge2": {
            "precision": 0.79567,
            "recall": 0.73214,
            "fmeasure": 0.75582
        },
        "rougeL": {
            "precision": 0.87847,
            "recall": 0.79693,
            "fmeasure": 0.82915
        },
        "rougeLsum": {
            "precision": 0.87847,
            "recall": 0.79693,
            "fmeasure": 0.82915
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7843137254901961
        },
        "bleu": 59.29134,
        "nubia": {
            "semantic_relation": 3.85795,
            "contradiction": 50.22257,
            "irrelevancy": 19.02366,
            "logical_agreement": 30.75378,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.15726,
            "nubia_score": 0.62709
        },
        "meteor": 0.44116636553856675,
        "bleurt": 0.5349,
        "bertscore": {
            "precision": 0.95291,
            "recall": 0.94836,
            "f1": 0.95054
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 39,
        "unique-1": 37,
        "entropy-1": 5.231486767965346,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": -0.05563315263446055,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9736842105263158,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.19529593449622,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": -0.06150163935576179,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.755109566494604,
        "rouge1": {
            "precision": 0.90556,
            "recall": 0.83303,
            "fmeasure": 0.86595
        },
        "rouge2": {
            "precision": 0.73593,
            "recall": 0.68129,
            "fmeasure": 0.70593
        },
        "rougeL": {
            "precision": 0.74444,
            "recall": 0.69189,
            "fmeasure": 0.71571
        },
        "rougeLsum": {
            "precision": 0.74444,
            "recall": 0.69189,
            "fmeasure": 0.71571
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "bleu": 60.00319,
        "nubia": {
            "semantic_relation": 4.69855,
            "contradiction": 3.94166,
            "irrelevancy": 29.38828,
            "logical_agreement": 66.67006,
            "grammar_ref": 4.8308,
            "grammar_hyp": 4.9613,
            "nubia_score": 0.84044
        },
        "meteor": 0.48661542435890665,
        "bleurt": 0.65766,
        "bertscore": {
            "precision": 0.97155,
            "recall": 0.96073,
            "f1": 0.96564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.12385402685271857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.770752061688852,
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.88622,
            "fmeasure": 0.88148
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.67778,
            "fmeasure": 0.67048
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.82372,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.82372,
            "fmeasure": 0.81481
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "bleu": 71.381,
        "nubia": {
            "semantic_relation": 4.69422,
            "contradiction": 0.16423,
            "irrelevancy": 18.08598,
            "logical_agreement": 81.74979,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.79863,
            "nubia_score": 0.83555
        },
        "meteor": 0.5059638511647186,
        "bleurt": 0.55439,
        "bertscore": {
            "precision": 0.96954,
            "recall": 0.97714,
            "f1": 0.97332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.19432195860366142,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.34119,
            "fmeasure": 0.46358
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.2674,
            "fmeasure": 0.36918
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 17.92681,
        "nubia": {
            "semantic_relation": 3.33397,
            "contradiction": 5.86135,
            "irrelevancy": 1.66517,
            "logical_agreement": 92.47349,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.6356,
            "nubia_score": 0.31744
        },
        "meteor": 0.2526845694782849,
        "bleurt": -0.29666,
        "bertscore": {
            "precision": 0.87739,
            "recall": 0.81951,
            "f1": 0.84746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 13,
        "unique-1": 6,
        "entropy-1": 3.5503407095463877,
        "distinct-2": 0.7,
        "vocab_size-2": 14,
        "unique-2": 8,
        "entropy-2": 3.721928094887362,
        "cond_entropy-2": 0.16249647625006503,
        "distinct-3": 0.7222222222222222,
        "vocab_size-3": 13,
        "unique-3": 8,
        "entropy-3": 3.6143694458867563,
        "cond_entropy-3": -0.04089198233393864,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.4219280948873623,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.503258334775645,
        "cond_entropy-2-nopunct": 0.125774684332728,
        "distinct-3-nopunct": 0.6875,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.375,
        "cond_entropy-3-nopunct": -0.10742500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4845704627410363,
        "rouge1": {
            "precision": 0.69192,
            "recall": 0.74038,
            "fmeasure": 0.70266
        },
        "rouge2": {
            "precision": 0.39167,
            "recall": 0.42727,
            "fmeasure": 0.39916
        },
        "rougeL": {
            "precision": 0.57071,
            "recall": 0.63568,
            "fmeasure": 0.59034
        },
        "rougeLsum": {
            "precision": 0.57071,
            "recall": 0.63568,
            "fmeasure": 0.59034
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bleu": 30.44009,
        "nubia": {
            "semantic_relation": 4.16955,
            "contradiction": 0.32436,
            "irrelevancy": 66.17723,
            "logical_agreement": 33.49841,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.90865,
            "nubia_score": 0.7554
        },
        "meteor": 0.4115994198377596,
        "bleurt": 0.08872,
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.93917,
            "f1": 0.9283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4182958340544896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.03462179117476819,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.328101041410247,
        "rouge1": {
            "precision": 0.5641,
            "recall": 0.44706,
            "fmeasure": 0.49841
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.25758,
            "fmeasure": 0.27743
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.37582,
            "fmeasure": 0.37778
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.37582,
            "fmeasure": 0.37778
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.3
        },
        "bleu": 24.71244,
        "nubia": {
            "semantic_relation": 2.77976,
            "contradiction": 66.49575,
            "irrelevancy": 17.9966,
            "logical_agreement": 15.50765,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.46508,
            "nubia_score": 0.30329
        },
        "meteor": 0.26494784234096713,
        "bleurt": -0.0075,
        "bertscore": {
            "precision": 0.87512,
            "recall": 0.86025,
            "f1": 0.86511
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.636893804262699,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.5669775143563275,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4216817952963827,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.58182,
            "fmeasure": 0.51449
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.32222,
            "fmeasure": 0.28139
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.58182,
            "fmeasure": 0.51449
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.58182,
            "fmeasure": 0.51449
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.625
        },
        "bleu": 14.57685,
        "nubia": {
            "semantic_relation": 3.3089,
            "contradiction": 24.23263,
            "irrelevancy": 75.10029,
            "logical_agreement": 0.66707,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.32913,
            "nubia_score": 0.39596
        },
        "meteor": 0.25665832586274206,
        "bleurt": -0.49001,
        "bertscore": {
            "precision": 0.81843,
            "recall": 0.89869,
            "f1": 0.85645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.282100621995838,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 63.40466,
        "nubia": {
            "semantic_relation": 4.44341,
            "contradiction": 53.77061,
            "irrelevancy": 38.83098,
            "logical_agreement": 7.39841,
            "grammar_ref": 5.3705,
            "grammar_hyp": 4.99775,
            "nubia_score": 0.66513
        },
        "meteor": 0.49956437727591835,
        "bleurt": 0.59174,
        "bertscore": {
            "precision": 0.97368,
            "recall": 0.98391,
            "f1": 0.97877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8690357018548505,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.61111,
            "fmeasure": 0.51242
        },
        "rouge2": {
            "precision": 0.05882,
            "recall": 0.08283,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.27778,
            "recall": 0.38194,
            "fmeasure": 0.32026
        },
        "rougeLsum": {
            "precision": 0.27778,
            "recall": 0.38194,
            "fmeasure": 0.32026
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "bleu": 9.3796,
        "nubia": {
            "semantic_relation": 4.00064,
            "contradiction": 0.41264,
            "irrelevancy": 25.30558,
            "logical_agreement": 74.28178,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.79577,
            "nubia_score": 0.71746
        },
        "meteor": 0.2449667850162747,
        "bleurt": -0.36772,
        "bertscore": {
            "precision": 0.83549,
            "recall": 0.85227,
            "f1": 0.84204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 10,
        "total_length": 168,
        "mean_pred_length": 16.8,
        "std_pred_length": 3.7894590642992827,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6130952380952381,
        "vocab_size-1": 103,
        "unique-1": 79,
        "entropy-1": 6.216298102273686,
        "distinct-2": 0.8481012658227848,
        "vocab_size-2": 134,
        "unique-2": 113,
        "entropy-2": 6.982547282973548,
        "cond_entropy-2": 0.6304321696630192,
        "distinct-3": 0.8851351351351351,
        "vocab_size-3": 131,
        "unique-3": 114,
        "entropy-3": 6.979723635899218,
        "cond_entropy-3": 0.005367803277275705,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.66,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.213138924522657,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.823890963358095,
        "cond_entropy-2-nopunct": 0.6690148792620763,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.822367813028456,
        "cond_entropy-3-nopunct": 0.006583930715514483,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.957859507453548,
        "rouge1": {
            "precision": 0.82301,
            "recall": 0.71254,
            "fmeasure": 0.7562
        },
        "rouge2": {
            "precision": 0.64506,
            "recall": 0.55957,
            "fmeasure": 0.59197
        },
        "rougeL": {
            "precision": 0.7125,
            "recall": 0.60723,
            "fmeasure": 0.64771
        },
        "rougeLsum": {
            "precision": 0.7125,
            "recall": 0.60723,
            "fmeasure": 0.64771
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4166666666666667,
            "3": 0.7606837606837606
        },
        "bleu": 46.89119,
        "nubia": {
            "semantic_relation": 4.14024,
            "contradiction": 24.01327,
            "irrelevancy": 13.74919,
            "logical_agreement": 62.23754,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.5503,
            "nubia_score": 0.67097
        },
        "meteor": 0.3920738197703211,
        "bleurt": 0.28341,
        "bertscore": {
            "precision": 0.93752,
            "recall": 0.91781,
            "f1": 0.92729
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 1.0,
        "vocab_size-1": 22,
        "unique-1": 22,
        "entropy-1": 4.459431618637295,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.06711419585853673,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.156723187874199,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.73333,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 1.0
        },
        "bleu": 50.13106,
        "nubia": {
            "semantic_relation": 4.17897,
            "contradiction": 0.29263,
            "irrelevancy": 37.75376,
            "logical_agreement": 61.95361,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.06699,
            "nubia_score": 0.7845
        },
        "meteor": 0.4853073065079512,
        "bleurt": 0.67055,
        "bertscore": {
            "precision": 0.92426,
            "recall": 0.97728,
            "f1": 0.94442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.59375,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.125,
        "distinct-2": 0.7096774193548387,
        "vocab_size-2": 22,
        "unique-2": 13,
        "entropy-2": 4.373551149096553,
        "cond_entropy-2": 0.27677695554816567,
        "distinct-3": 0.7666666666666667,
        "vocab_size-3": 23,
        "unique-3": 16,
        "entropy-3": 4.440223928941852,
        "cond_entropy-3": 0.08602761855497648,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 31.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 31,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5806451612903226,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 4.050970503935262,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.306890595608518,
        "cond_entropy-2-nopunct": 0.2526942852216431,
        "distinct-3-nopunct": 0.7586206896551724,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.375222374437916,
        "cond_entropy-3-nopunct": 0.05453867538112245,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8463534141726847,
        "rouge1": {
            "precision": 0.48387,
            "recall": 0.75,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.32749,
            "fmeasure": 0.2483
        },
        "rougeL": {
            "precision": 0.29032,
            "recall": 0.45,
            "fmeasure": 0.35294
        },
        "rougeLsum": {
            "precision": 0.29032,
            "recall": 0.45,
            "fmeasure": 0.35294
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "bleu": 16.48727,
        "nubia": {
            "semantic_relation": 4.01469,
            "contradiction": 91.47718,
            "irrelevancy": 1.22776,
            "logical_agreement": 7.29507,
            "grammar_ref": 5.26752,
            "grammar_hyp": 3.3174,
            "nubia_score": 0.8296
        },
        "meteor": 0.35595494842138653,
        "bleurt": 0.12372,
        "bertscore": {
            "precision": 0.85121,
            "recall": 0.89873,
            "f1": 0.87432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 4.0,
        "median_pred_length": 23.0,
        "min_pred_length": 19,
        "max_pred_length": 27,
        "distinct-1": 0.6521739130434783,
        "vocab_size-1": 30,
        "unique-1": 15,
        "entropy-1": 4.81149918427085,
        "distinct-2": 0.8409090909090909,
        "vocab_size-2": 37,
        "unique-2": 30,
        "entropy-2": 5.141249800455477,
        "cond_entropy-2": 0.3166625603567269,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 38,
        "unique-3": 34,
        "entropy-3": 5.201841232302572,
        "cond_entropy-3": 0.07574294699860605,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.599379462396518,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.29580486304138953,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516392,
        "cond_entropy-3-nopunct": 0.09125822274458811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5404130911461733,
        "rouge1": {
            "precision": 0.80455,
            "recall": 0.66544,
            "fmeasure": 0.72305
        },
        "rouge2": {
            "precision": 0.54365,
            "recall": 0.46199,
            "fmeasure": 0.49732
        },
        "rougeL": {
            "precision": 0.67576,
            "recall": 0.57609,
            "fmeasure": 0.61922
        },
        "rougeLsum": {
            "precision": 0.67576,
            "recall": 0.57609,
            "fmeasure": 0.61922
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.06666666666666667,
            "3": 0.7878787878787878
        },
        "bleu": 40.78321,
        "nubia": {
            "semantic_relation": 4.12947,
            "contradiction": 47.94519,
            "irrelevancy": 0.85653,
            "logical_agreement": 51.19827,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.62568,
            "nubia_score": 0.68459
        },
        "meteor": 0.40222927985195756,
        "bleurt": 0.22125,
        "bertscore": {
            "precision": 0.93285,
            "recall": 0.90787,
            "f1": 0.92007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.8205128205128205,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.855789718806774,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.21785611591339749,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.786425874087821,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.21446698305503362,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2990919747888943,
        "rouge1": {
            "precision": 0.62169,
            "recall": 0.75966,
            "fmeasure": 0.66546
        },
        "rouge2": {
            "precision": 0.46749,
            "recall": 0.55605,
            "fmeasure": 0.49698
        },
        "rougeL": {
            "precision": 0.62169,
            "recall": 0.75966,
            "fmeasure": 0.66546
        },
        "rougeLsum": {
            "precision": 0.62169,
            "recall": 0.75966,
            "fmeasure": 0.66546
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.6923076923076923,
            "3": 0.9166666666666666
        },
        "bleu": 33.51874,
        "nubia": {
            "semantic_relation": 4.35491,
            "contradiction": 0.94288,
            "irrelevancy": 33.81567,
            "logical_agreement": 65.24145,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.76932,
            "nubia_score": 0.85467
        },
        "meteor": 0.4258750311562594,
        "bleurt": 0.34332,
        "bertscore": {
            "precision": 0.89595,
            "recall": 0.93228,
            "f1": 0.91109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.042817613369716734,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.047238912308487487,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.51505647131016,
        "rouge1": {
            "precision": 0.92361,
            "recall": 0.87205,
            "fmeasure": 0.88854
        },
        "rouge2": {
            "precision": 0.73214,
            "recall": 0.72024,
            "fmeasure": 0.72026
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.74705,
            "fmeasure": 0.7709
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.74705,
            "fmeasure": 0.7709
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "bleu": 63.49441,
        "nubia": {
            "semantic_relation": 4.58405,
            "contradiction": 1.47985,
            "irrelevancy": 27.00374,
            "logical_agreement": 71.51642,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.30837,
            "nubia_score": 0.7384
        },
        "meteor": 0.48716672772047065,
        "bleurt": 0.46611,
        "bertscore": {
            "precision": 0.96669,
            "recall": 0.95017,
            "f1": 0.95809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 5.734883511361751,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 31,
        "entropy-1": 5.044325652580696,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.22762709340339438,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.017535737070865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.10292371784890873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.434541751755032,
        "rouge1": {
            "precision": 0.6145,
            "recall": 0.53748,
            "fmeasure": 0.54183
        },
        "rouge2": {
            "precision": 0.35634,
            "recall": 0.27947,
            "fmeasure": 0.2927
        },
        "rougeL": {
            "precision": 0.44697,
            "recall": 0.40283,
            "fmeasure": 0.40114
        },
        "rougeLsum": {
            "precision": 0.44697,
            "recall": 0.40283,
            "fmeasure": 0.40114
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.4166666666666667,
            "3": 0.625
        },
        "bleu": 18.14579,
        "nubia": {
            "semantic_relation": 3.4986,
            "contradiction": 43.77417,
            "irrelevancy": 23.15221,
            "logical_agreement": 33.07363,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.21451,
            "nubia_score": 0.57908
        },
        "meteor": 0.2804569538426848,
        "bleurt": -0.05708,
        "bertscore": {
            "precision": 0.857,
            "recall": 0.85624,
            "f1": 0.856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.869860669156856,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.71673,
            "fmeasure": 0.81368
        },
        "rouge2": {
            "precision": 0.8125,
            "recall": 0.59885,
            "fmeasure": 0.68943
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.53755,
            "fmeasure": 0.61026
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.53755,
            "fmeasure": 0.61026
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7058823529411765
        },
        "bleu": 41.65802,
        "nubia": {
            "semantic_relation": 4.11707,
            "contradiction": 0.22646,
            "irrelevancy": 1.47841,
            "logical_agreement": 98.29512,
            "grammar_ref": 3.0511,
            "grammar_hyp": 3.07225,
            "nubia_score": 0.847
        },
        "meteor": 0.3871741045878519,
        "bleurt": 0.10993,
        "bertscore": {
            "precision": 0.93007,
            "recall": 0.8913,
            "f1": 0.91027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.180832987205441,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.44743007442701976,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.4885497999310017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6492617522437143,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.61905,
            "fmeasure": 0.71605
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.5873,
            "fmeasure": 0.68833
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.61111,
            "fmeasure": 0.70951
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.61111,
            "fmeasure": 0.70951
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 66.87708,
        "nubia": {
            "semantic_relation": 4.09888,
            "contradiction": 0.45492,
            "irrelevancy": 0.57278,
            "logical_agreement": 98.9723,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.89133,
            "nubia_score": 0.86475
        },
        "meteor": 0.4015835737060602,
        "bleurt": 0.21535,
        "bertscore": {
            "precision": 0.98235,
            "recall": 0.88869,
            "f1": 0.92733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.1294709175589395,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.64286,
            "fmeasure": 0.61111
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.81481,
            "fmeasure": 0.78974
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 1.0
        },
        "bleu": 48.68357,
        "nubia": {
            "semantic_relation": 4.4182,
            "contradiction": 0.25512,
            "irrelevancy": 1.02065,
            "logical_agreement": 98.72424,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.55868,
            "nubia_score": 0.90114
        },
        "meteor": 0.5220503747508378,
        "bleurt": 0.64203,
        "bertscore": {
            "precision": 0.95241,
            "recall": 0.97474,
            "f1": 0.96345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.483856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.968100686794592,
        "rouge1": {
            "precision": 0.85641,
            "recall": 0.69815,
            "fmeasure": 0.75464
        },
        "rouge2": {
            "precision": 0.49537,
            "recall": 0.42956,
            "fmeasure": 0.45157
        },
        "rougeL": {
            "precision": 0.64487,
            "recall": 0.55017,
            "fmeasure": 0.58133
        },
        "rougeLsum": {
            "precision": 0.64487,
            "recall": 0.55017,
            "fmeasure": 0.58133
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8,
            "3": 0.6
        },
        "bleu": 30.02449,
        "nubia": {
            "semantic_relation": 4.26094,
            "contradiction": 0.28142,
            "irrelevancy": 0.46993,
            "logical_agreement": 99.24865,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.1143,
            "nubia_score": 0.77125
        },
        "meteor": 0.32583984151498385,
        "bleurt": 0.27538,
        "bertscore": {
            "precision": 0.92312,
            "recall": 0.88318,
            "f1": 0.89831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.03753715874966059,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": -0.028107102122342943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.029992126993435245,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9389541241592614,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.7208,
            "fmeasure": 0.62302
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.22222,
            "fmeasure": 0.17249
        },
        "rougeL": {
            "precision": 0.42222,
            "recall": 0.54416,
            "fmeasure": 0.47222
        },
        "rougeLsum": {
            "precision": 0.42222,
            "recall": 0.54416,
            "fmeasure": 0.47222
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.2857142857142857,
            "3": 0.8333333333333334
        },
        "bleu": 14.00905,
        "nubia": {
            "semantic_relation": 4.34302,
            "contradiction": 0.5095,
            "irrelevancy": 2.90793,
            "logical_agreement": 96.58256,
            "grammar_ref": 5.94843,
            "grammar_hyp": 4.62585,
            "nubia_score": 0.85864
        },
        "meteor": 0.32012392694386516,
        "bleurt": 0.24578,
        "bertscore": {
            "precision": 0.88569,
            "recall": 0.88165,
            "f1": 0.88367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.625,
        "distinct-2": 0.8666666666666667,
        "vocab_size-2": 13,
        "unique-2": 11,
        "entropy-2": 3.640223928941851,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.506890595608518,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.52164063634332,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.5465935642949384,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0456046332701447,
        "rouge1": {
            "precision": 0.62745,
            "recall": 0.44444,
            "fmeasure": 0.52033
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.25328,
            "fmeasure": 0.29522
        },
        "rougeL": {
            "precision": 0.62745,
            "recall": 0.44444,
            "fmeasure": 0.52033
        },
        "rougeLsum": {
            "precision": 0.62745,
            "recall": 0.44444,
            "fmeasure": 0.52033
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.4117647058823529
        },
        "bleu": 12.33641,
        "nubia": {
            "semantic_relation": 3.68281,
            "contradiction": 1.45095,
            "irrelevancy": 92.81253,
            "logical_agreement": 5.73652,
            "grammar_ref": 3.8277,
            "grammar_hyp": 3.90946,
            "nubia_score": 0.57004
        },
        "meteor": 0.19817469610141275,
        "bleurt": -0.07722,
        "bertscore": {
            "precision": 0.85485,
            "recall": 0.787,
            "f1": 0.81952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99428,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.6,
        "vocab_size-1": 12,
        "unique-1": 4,
        "entropy-1": 3.5219280948873624,
        "distinct-2": 0.6666666666666666,
        "vocab_size-2": 12,
        "unique-2": 6,
        "entropy-2": 3.503258334775645,
        "cond_entropy-2": -0.040891982333938634,
        "distinct-3": 0.6875,
        "vocab_size-3": 11,
        "unique-3": 6,
        "entropy-3": 3.375,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6111111111111112,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.392147223664534,
        "distinct-2-nopunct": 0.625,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.25,
        "cond_entropy-2-nopunct": -0.04492500144231236,
        "distinct-3-nopunct": 0.6428571428571429,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.09306920777189,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.27669746579841,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.65302,
            "fmeasure": 0.74196
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.38681,
            "fmeasure": 0.44167
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bleu": 33.92072,
        "nubia": {
            "semantic_relation": 4.84412,
            "contradiction": 0.57963,
            "irrelevancy": 0.83691,
            "logical_agreement": 98.58346,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.92275,
            "nubia_score": 0.93636
        },
        "meteor": 0.41664419714148093,
        "bleurt": 0.36837,
        "bertscore": {
            "precision": 0.96929,
            "recall": 0.94456,
            "f1": 0.95676
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.456435556800404,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 50.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432,
        "bleurt": 0.93658,
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7109047337507373,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "bleu": 53.10725,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 17,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.452819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.29780470209872617,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.15754127698647996,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551767,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.3466967678036592,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.818054664721242,
        "rouge1": {
            "precision": 0.72083,
            "recall": 0.65211,
            "fmeasure": 0.65476
        },
        "rouge2": {
            "precision": 0.51508,
            "recall": 0.5,
            "fmeasure": 0.48909
        },
        "rougeL": {
            "precision": 0.65417,
            "recall": 0.62537,
            "fmeasure": 0.61688
        },
        "rougeLsum": {
            "precision": 0.65417,
            "recall": 0.62537,
            "fmeasure": 0.61688
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 48.5631,
        "nubia": {
            "semantic_relation": 4.30417,
            "contradiction": 33.92373,
            "irrelevancy": 1.71757,
            "logical_agreement": 64.35871,
            "grammar_ref": 4.11451,
            "grammar_hyp": 5.22676,
            "nubia_score": 0.69875
        },
        "meteor": 0.3740013257509161,
        "bleurt": 0.12714,
        "bertscore": {
            "precision": 0.91994,
            "recall": 0.89729,
            "f1": 0.90507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1812916586249655,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.40316,
            "fmeasure": 0.46964
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.14069,
            "fmeasure": 0.16517
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.26877,
            "fmeasure": 0.31309
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.26877,
            "fmeasure": 0.31309
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.3684210526315789
        },
        "bleu": 4.89646,
        "nubia": {
            "semantic_relation": 4.2267,
            "contradiction": 2.04442,
            "irrelevancy": 1.53706,
            "logical_agreement": 96.41851,
            "grammar_ref": 4.34096,
            "grammar_hyp": 6.78121,
            "nubia_score": 0.47086
        },
        "meteor": 0.1986883652947772,
        "bleurt": -0.30296,
        "bertscore": {
            "precision": 0.86684,
            "recall": 0.83074,
            "f1": 0.84841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 63,
        "mean_pred_length": 21.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 24,
        "distinct-1": 0.5396825396825397,
        "vocab_size-1": 34,
        "unique-1": 20,
        "entropy-1": 4.8244356301175255,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 50,
        "unique-2": 42,
        "entropy-2": 5.540223928941851,
        "cond_entropy-2": 0.6941823884573889,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 51,
        "unique-3": 45,
        "entropy-3": 5.622363698375263,
        "cond_entropy-3": 0.10143801504745141,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5818181818181818,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.758365849770286,
        "distinct-2-nopunct": 0.8076923076923077,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.277362795064171,
        "cond_entropy-2-nopunct": 0.5587850528181715,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.3698118849315355,
        "cond_entropy-3-nopunct": 0.11835175862717742,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.606109219415778,
        "rouge1": {
            "precision": 0.52976,
            "recall": 0.63319,
            "fmeasure": 0.56103
        },
        "rouge2": {
            "precision": 0.30906,
            "recall": 0.3796,
            "fmeasure": 0.32863
        },
        "rougeL": {
            "precision": 0.48056,
            "recall": 0.57616,
            "fmeasure": 0.50889
        },
        "rougeLsum": {
            "precision": 0.48056,
            "recall": 0.57616,
            "fmeasure": 0.50889
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.55,
            "3": 0.631578947368421
        },
        "bleu": 9.97523,
        "nubia": {
            "semantic_relation": 3.28376,
            "contradiction": 9.93369,
            "irrelevancy": 70.66481,
            "logical_agreement": 19.4015,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.12943,
            "nubia_score": 0.45373
        },
        "meteor": 0.2988643628309826,
        "bleurt": -0.19629,
        "bertscore": {
            "precision": 0.84628,
            "recall": 0.86323,
            "f1": 0.85387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 8.0,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.5789473684210527,
        "vocab_size-1": 22,
        "unique-1": 12,
        "entropy-1": 4.273728829005326,
        "distinct-2": 0.6944444444444444,
        "vocab_size-2": 25,
        "unique-2": 18,
        "entropy-2": 4.474937501201926,
        "cond_entropy-2": 0.19977526577650462,
        "distinct-3": 0.7352941176470589,
        "vocab_size-3": 25,
        "unique-3": 19,
        "entropy-3": 4.491443355765327,
        "cond_entropy-3": 0.05738747222459954,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5882352941176471,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.1162996057016965,
        "distinct-2-nopunct": 0.65625,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.218139062229566,
        "cond_entropy-2-nopunct": 0.11300708060212446,
        "distinct-3-nopunct": 0.7,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.231401845392172,
        "cond_entropy-3-nopunct": 0.012554762323262277,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0643514855408838,
        "rouge1": {
            "precision": 0.62778,
            "recall": 0.67491,
            "fmeasure": 0.64563
        },
        "rouge2": {
            "precision": 0.48068,
            "recall": 0.5564,
            "fmeasure": 0.50419
        },
        "rougeL": {
            "precision": 0.54444,
            "recall": 0.60473,
            "fmeasure": 0.56245
        },
        "rougeLsum": {
            "precision": 0.54444,
            "recall": 0.60473,
            "fmeasure": 0.56245
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.8333333333333334
        },
        "bleu": 39.41005,
        "nubia": {
            "semantic_relation": 3.94923,
            "contradiction": 26.16688,
            "irrelevancy": 34.94137,
            "logical_agreement": 38.89175,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.41692,
            "nubia_score": 0.75476
        },
        "meteor": 0.40143077531185345,
        "bleurt": 0.31017,
        "bertscore": {
            "precision": 0.95205,
            "recall": 0.92816,
            "f1": 0.93873
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 7.119515432949071,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.8679245283018868,
        "vocab_size-1": 46,
        "unique-1": 41,
        "entropy-1": 5.426033662110366,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.05005469567445818,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.12285674778553377,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 6.819090848492928,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.418295834054493,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.03356002700705002,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.795574610753818,
        "rouge1": {
            "precision": 0.80345,
            "recall": 0.67838,
            "fmeasure": 0.72715
        },
        "rouge2": {
            "precision": 0.48125,
            "recall": 0.43182,
            "fmeasure": 0.45392
        },
        "rougeL": {
            "precision": 0.75584,
            "recall": 0.6349,
            "fmeasure": 0.68169
        },
        "rougeLsum": {
            "precision": 0.75584,
            "recall": 0.6349,
            "fmeasure": 0.68169
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.7111111111111111
        },
        "bleu": 42.71829,
        "nubia": {
            "semantic_relation": 4.20139,
            "contradiction": 2.85058,
            "irrelevancy": 2.96001,
            "logical_agreement": 94.18941,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.51632,
            "nubia_score": 0.68669
        },
        "meteor": 0.38037326417512046,
        "bleurt": 0.22022,
        "bertscore": {
            "precision": 0.92141,
            "recall": 0.87061,
            "f1": 0.89488
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 3.5,
        "median_pred_length": 17.5,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 26,
        "unique-1": 19,
        "entropy-1": 4.557854445516393,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.39995958726197156,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.02568167993932012,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7419354838709677,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.373551149096553,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.45550882267173165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.167765919870141,
        "rouge1": {
            "precision": 0.66944,
            "recall": 0.72222,
            "fmeasure": 0.68664
        },
        "rouge2": {
            "precision": 0.43182,
            "recall": 0.47164,
            "fmeasure": 0.44494
        },
        "rougeL": {
            "precision": 0.425,
            "recall": 0.44722,
            "fmeasure": 0.42934
        },
        "rougeLsum": {
            "precision": 0.425,
            "recall": 0.44722,
            "fmeasure": 0.42934
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.14285714285714285,
            "3": 0.7619047619047619
        },
        "bleu": 45.38743,
        "nubia": {
            "semantic_relation": 4.13233,
            "contradiction": 43.06298,
            "irrelevancy": 6.72436,
            "logical_agreement": 50.21266,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.29812,
            "nubia_score": 0.67233
        },
        "meteor": 0.4303325050854699,
        "bleurt": -0.07854,
        "bertscore": {
            "precision": 0.90518,
            "recall": 0.92771,
            "f1": 0.91602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966063,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.187561469069796,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.7619,
            "fmeasure": 0.72666
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.59487,
            "fmeasure": 0.56194
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.57143,
            "fmeasure": 0.54499
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.57143,
            "fmeasure": 0.54499
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "bleu": 45.30778,
        "nubia": {
            "semantic_relation": 3.93137,
            "contradiction": 0.25297,
            "irrelevancy": 0.5222,
            "logical_agreement": 99.22482,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.55901,
            "nubia_score": 0.73033
        },
        "meteor": 0.48368623828192886,
        "bleurt": 0.10819,
        "bertscore": {
            "precision": 0.89642,
            "recall": 0.90682,
            "f1": 0.90159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861537,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.3068905956085185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.857506457306185,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.45635,
            "fmeasure": 0.50061
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.28333,
            "fmeasure": 0.30631
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.31944,
            "fmeasure": 0.35043
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.31944,
            "fmeasure": 0.35043
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4666666666666667
        },
        "bleu": 28.55878,
        "nubia": {
            "semantic_relation": 3.24169,
            "contradiction": 0.3811,
            "irrelevancy": 98.81181,
            "logical_agreement": 0.80709,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.17922,
            "nubia_score": 0.35795
        },
        "meteor": 0.2710623670793544,
        "bleurt": -0.47475,
        "bertscore": {
            "precision": 0.86138,
            "recall": 0.82916,
            "f1": 0.84496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 18,
        "distinct-1": 0.78,
        "vocab_size-1": 39,
        "unique-1": 34,
        "entropy-1": 5.076565630242721,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 46,
        "unique-2": 45,
        "entropy-2": 5.512035660188278,
        "cond_entropy-2": 0.37051224646539815,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.04970268758579487,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.923714976226823,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.3859043520461843,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.05842067520435856,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.617257076402635,
        "rouge1": {
            "precision": 0.75926,
            "recall": 0.6841,
            "fmeasure": 0.71767
        },
        "rouge2": {
            "precision": 0.52137,
            "recall": 0.47439,
            "fmeasure": 0.49495
        },
        "rougeL": {
            "precision": 0.65767,
            "recall": 0.59003,
            "fmeasure": 0.61971
        },
        "rougeLsum": {
            "precision": 0.65767,
            "recall": 0.59003,
            "fmeasure": 0.61971
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855,
            "3": 0.7027027027027027
        },
        "bleu": 42.03983,
        "nubia": {
            "semantic_relation": 4.01915,
            "contradiction": 0.35643,
            "irrelevancy": 13.98772,
            "logical_agreement": 85.65585,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.57345,
            "nubia_score": 0.69371
        },
        "meteor": 0.33442347932088706,
        "bleurt": -0.09484,
        "bertscore": {
            "precision": 0.91007,
            "recall": 0.89102,
            "f1": 0.90014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3697446296378888,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77778,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.33333,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.33333,
            "fmeasure": 0.375
        },
        "local_recall": {
            "1": 0,
            "2": 0.6363636363636364
        },
        "bleu": 15.56087,
        "nubia": {
            "semantic_relation": 4.74794,
            "contradiction": 1.13527,
            "irrelevancy": 0.56403,
            "logical_agreement": 98.30071,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.98987,
            "nubia_score": 0.74508
        },
        "meteor": 0.3308105615250485,
        "bleurt": -0.042,
        "bertscore": {
            "precision": 0.8705,
            "recall": 0.81523,
            "f1": 0.84196
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5848040654130635,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "bleu": 37.42032,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.06983,
            "irrelevancy": 2.29714,
            "logical_agreement": 97.63303,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.7095,
            "nubia_score": 0.99841
        },
        "meteor": 0.4854043997759893,
        "bleurt": 0.62156,
        "bertscore": {
            "precision": 0.9266,
            "recall": 0.9505,
            "f1": 0.9384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.4444444444444444,
        "vocab_size-1": 24,
        "unique-1": 13,
        "entropy-1": 4.261030270674608,
        "distinct-2": 0.5490196078431373,
        "vocab_size-2": 28,
        "unique-2": 16,
        "entropy-2": 4.607645684642121,
        "cond_entropy-2": 0.34125628048325857,
        "distinct-3": 0.5625,
        "vocab_size-3": 27,
        "unique-3": 16,
        "entropy-3": 4.552694271103769,
        "cond_entropy-3": -0.030069351621933808,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.44,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.125588129810025,
        "distinct-2-nopunct": 0.5319148936170213,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.441742840532997,
        "cond_entropy-2-nopunct": 0.3030670336687531,
        "distinct-3-nopunct": 0.5454545454545454,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.3787753681455985,
        "cond_entropy-3-nopunct": -0.05913535802395023,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.88668248509268,
        "rouge1": {
            "precision": 0.77211,
            "recall": 0.72523,
            "fmeasure": 0.7411
        },
        "rouge2": {
            "precision": 0.55185,
            "recall": 0.51947,
            "fmeasure": 0.5299
        },
        "rougeL": {
            "precision": 0.71953,
            "recall": 0.68824,
            "fmeasure": 0.6962
        },
        "rougeLsum": {
            "precision": 0.71953,
            "recall": 0.68824,
            "fmeasure": 0.6962
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7631578947368421
        },
        "bleu": 60.68053,
        "nubia": {
            "semantic_relation": 4.0808,
            "contradiction": 0.23722,
            "irrelevancy": 45.69746,
            "logical_agreement": 54.06532,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.30538,
            "nubia_score": 0.71803
        },
        "meteor": 0.4385069256194241,
        "bleurt": -0.10503,
        "bertscore": {
            "precision": 0.92695,
            "recall": 0.90867,
            "f1": 0.91642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.09251370597287,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.68506,
            "fmeasure": 0.69398
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0
        },
        "bleu": 67.29865,
        "nubia": {
            "semantic_relation": 4.67622,
            "contradiction": 0.49994,
            "irrelevancy": 0.68259,
            "logical_agreement": 98.81746,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.20882,
            "nubia_score": 0.8468
        },
        "meteor": 0.5934341018717497,
        "bleurt": 0.67946,
        "bertscore": {
            "precision": 0.9565,
            "recall": 0.9669,
            "f1": 0.96167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094907,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0961769012815985,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67917,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "bleu": 60.54783,
        "nubia": {
            "semantic_relation": 2.77562,
            "contradiction": 0.31427,
            "irrelevancy": 99.10434,
            "logical_agreement": 0.58139,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.92987,
            "nubia_score": 0.3485
        },
        "meteor": 0.5023421543386601,
        "bleurt": -0.25249,
        "bertscore": {
            "precision": 0.90764,
            "recall": 0.95641,
            "f1": 0.93139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.664497779200462,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": -0.029992126993435272,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660257,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7831074788292094,
        "rouge1": {
            "precision": 0.8733,
            "recall": 0.80598,
            "fmeasure": 0.8366
        },
        "rouge2": {
            "precision": 0.72917,
            "recall": 0.67544,
            "fmeasure": 0.69974
        },
        "rougeL": {
            "precision": 0.8733,
            "recall": 0.80598,
            "fmeasure": 0.8366
        },
        "rougeLsum": {
            "precision": 0.8733,
            "recall": 0.80598,
            "fmeasure": 0.8366
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.84
        },
        "bleu": 52.54388,
        "nubia": {
            "semantic_relation": 4.43868,
            "contradiction": 0.67653,
            "irrelevancy": 2.94602,
            "logical_agreement": 96.37745,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.78749,
            "nubia_score": 0.79538
        },
        "meteor": 0.42894566696951775,
        "bleurt": 0.44388,
        "bertscore": {
            "precision": 0.96583,
            "recall": 0.94617,
            "f1": 0.95579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.03214388408660256,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2337113652220184,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.78022,
            "fmeasure": 0.85833
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.44231,
            "fmeasure": 0.49012
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.63187,
            "fmeasure": 0.695
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.63187,
            "fmeasure": 0.695
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7
        },
        "bleu": 41.42893,
        "nubia": {
            "semantic_relation": 4.01885,
            "contradiction": 99.6766,
            "irrelevancy": 0.16476,
            "logical_agreement": 0.15863,
            "grammar_ref": 4.1674,
            "grammar_hyp": 6.22203,
            "nubia_score": 0.41933
        },
        "meteor": 0.35287938918502076,
        "bleurt": -0.42764,
        "bertscore": {
            "precision": 0.89033,
            "recall": 0.88918,
            "f1": 0.88975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.024439644279765072,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.07038932789139804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8900072445637965,
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.87982,
            "fmeasure": 0.84309
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.70955,
            "fmeasure": 0.67836
        },
        "rougeL": {
            "precision": 0.7619,
            "recall": 0.82807,
            "fmeasure": 0.7935
        },
        "rougeLsum": {
            "precision": 0.7619,
            "recall": 0.82807,
            "fmeasure": 0.7935
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "bleu": 58.68136,
        "nubia": {
            "semantic_relation": 3.89118,
            "contradiction": 88.48835,
            "irrelevancy": 10.34067,
            "logical_agreement": 1.17098,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.04901,
            "nubia_score": 0.60183
        },
        "meteor": 0.4520497658419734,
        "bleurt": 0.12449,
        "bertscore": {
            "precision": 0.95274,
            "recall": 0.96644,
            "f1": 0.95954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.7380952380952381,
        "vocab_size-1": 31,
        "unique-1": 22,
        "entropy-1": 4.82088885135019,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 38,
        "unique-2": 37,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.30334120633989836,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.05992166186438025,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.12479798526556812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.11112710261498539,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5482868304100266,
        "rouge1": {
            "precision": 0.58319,
            "recall": 0.56197,
            "fmeasure": 0.56495
        },
        "rouge2": {
            "precision": 0.26852,
            "recall": 0.25985,
            "fmeasure": 0.25999
        },
        "rougeL": {
            "precision": 0.49088,
            "recall": 0.46561,
            "fmeasure": 0.47137
        },
        "rougeLsum": {
            "precision": 0.49088,
            "recall": 0.46561,
            "fmeasure": 0.47137
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.3333333333333333,
            "3": 0.5517241379310345
        },
        "bleu": 23.7579,
        "nubia": {
            "semantic_relation": 3.59509,
            "contradiction": 14.23876,
            "irrelevancy": 63.20779,
            "logical_agreement": 22.55346,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.29958,
            "nubia_score": 0.54017
        },
        "meteor": 0.2826475399667375,
        "bleurt": -0.12778,
        "bertscore": {
            "precision": 0.92397,
            "recall": 0.89193,
            "f1": 0.90745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.490498678107601,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "meteor": 1.0,
        "bleurt": 0.92254,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.12896868761125602,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.2626923908396215,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.05923165719793804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6381015578317575,
        "rouge1": {
            "precision": 0.56548,
            "recall": 0.65077,
            "fmeasure": 0.58939
        },
        "rouge2": {
            "precision": 0.3042,
            "recall": 0.4212,
            "fmeasure": 0.34762
        },
        "rougeL": {
            "precision": 0.52976,
            "recall": 0.62281,
            "fmeasure": 0.55808
        },
        "rougeLsum": {
            "precision": 0.52976,
            "recall": 0.62281,
            "fmeasure": 0.55808
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "bleu": 18.94522,
        "nubia": {
            "semantic_relation": 3.7923,
            "contradiction": 1.52908,
            "irrelevancy": 69.67318,
            "logical_agreement": 28.79774,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.24109,
            "nubia_score": 0.55722
        },
        "meteor": 0.30466524155990554,
        "bleurt": -0.01884,
        "bertscore": {
            "precision": 0.87471,
            "recall": 0.89805,
            "f1": 0.88569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 4.656984002549289,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.279089820981553,
        "distinct-2": 0.9818181818181818,
        "vocab_size-2": 54,
        "unique-2": 53,
        "entropy-2": 5.744996077161019,
        "cond_entropy-2": 0.36434649097075994,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.0697186852786542,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.9370039370059056,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1694850936326935,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.543295834054494,
        "cond_entropy-2-nopunct": 0.4180569591308314,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.08007633662931367,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.350508914741975,
        "rouge1": {
            "precision": 0.74653,
            "recall": 0.70485,
            "fmeasure": 0.71411
        },
        "rouge2": {
            "precision": 0.62344,
            "recall": 0.57327,
            "fmeasure": 0.58328
        },
        "rougeL": {
            "precision": 0.72569,
            "recall": 0.6854,
            "fmeasure": 0.6941
        },
        "rougeLsum": {
            "precision": 0.72569,
            "recall": 0.6854,
            "fmeasure": 0.6941
        },
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.5,
            "3": 0.7407407407407407
        },
        "bleu": 53.47947,
        "nubia": {
            "semantic_relation": 3.49141,
            "contradiction": 34.29498,
            "irrelevancy": 36.02114,
            "logical_agreement": 29.68389,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.43413,
            "nubia_score": 0.53532
        },
        "meteor": 0.45603929538648064,
        "bleurt": 0.24895,
        "bertscore": {
            "precision": 0.92926,
            "recall": 0.935,
            "f1": 0.92959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4182958340544896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8940012323125859,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.58333,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.36364,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7
        },
        "bleu": 10.71174,
        "nubia": {
            "semantic_relation": 3.84232,
            "contradiction": 0.09282,
            "irrelevancy": 99.75897,
            "logical_agreement": 0.1482,
            "grammar_ref": 5.64121,
            "grammar_hyp": 5.47176,
            "nubia_score": 0.68611
        },
        "meteor": 0.36502762288604423,
        "bleurt": -0.06959,
        "bertscore": {
            "precision": 0.88912,
            "recall": 0.89776,
            "f1": 0.89342
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 7.788880963698615,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 33,
        "unique-1": 25,
        "entropy-1": 4.945772482251059,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.2520591550578472,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 6.377042156569663,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.8365916681089764,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.23810548155250458,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.620325741895747,
        "rouge1": {
            "precision": 0.78875,
            "recall": 0.77306,
            "fmeasure": 0.78027
        },
        "rouge2": {
            "precision": 0.49405,
            "recall": 0.48633,
            "fmeasure": 0.48996
        },
        "rougeL": {
            "precision": 0.64496,
            "recall": 0.63945,
            "fmeasure": 0.64205
        },
        "rougeLsum": {
            "precision": 0.64496,
            "recall": 0.63945,
            "fmeasure": 0.64205
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.8709677419354839
        },
        "bleu": 51.99477,
        "nubia": {
            "semantic_relation": 4.2199,
            "contradiction": 1.54167,
            "irrelevancy": 60.66185,
            "logical_agreement": 37.79649,
            "grammar_ref": 5.15251,
            "grammar_hyp": 5.02766,
            "nubia_score": 0.72381
        },
        "meteor": 0.45035006144252027,
        "bleurt": 0.02795,
        "bertscore": {
            "precision": 0.93469,
            "recall": 0.93029,
            "f1": 0.93247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7896429248905212,
        "rouge1": {
            "precision": 0.53125,
            "recall": 0.45072,
            "fmeasure": 0.48222
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.25649,
            "fmeasure": 0.27307
        },
        "rougeL": {
            "precision": 0.53125,
            "recall": 0.45072,
            "fmeasure": 0.48222
        },
        "rougeLsum": {
            "precision": 0.53125,
            "recall": 0.45072,
            "fmeasure": 0.48222
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.4166666666666667
        },
        "bleu": 34.91986,
        "nubia": {
            "semantic_relation": 3.31836,
            "contradiction": 15.75049,
            "irrelevancy": 81.48814,
            "logical_agreement": 2.76137,
            "grammar_ref": 5.51157,
            "grammar_hyp": 6.1609,
            "nubia_score": 0.31195
        },
        "meteor": 0.26688094837341303,
        "bleurt": -0.47857,
        "bertscore": {
            "precision": 0.87244,
            "recall": 0.88158,
            "f1": 0.86298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4156844010247407,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.6374,
            "contradiction": 0.2158,
            "irrelevancy": 0.51722,
            "logical_agreement": 99.26698,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.20485,
            "nubia_score": 0.86208
        },
        "meteor": 1.0,
        "bleurt": 0.6432,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.11768784439846626,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910024,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.12336199461765374,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.029610672108601986,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7346314959119167,
        "rouge1": {
            "precision": 0.3913,
            "recall": 0.75,
            "fmeasure": 0.51429
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.63636,
            "fmeasure": 0.42424
        },
        "rougeL": {
            "precision": 0.3913,
            "recall": 0.75,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.3913,
            "recall": 0.75,
            "fmeasure": 0.51429
        },
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 1.0
        },
        "bleu": 26.5123,
        "nubia": {
            "semantic_relation": 3.61264,
            "contradiction": 0.05956,
            "irrelevancy": 99.66674,
            "logical_agreement": 0.2737,
            "grammar_ref": 5.08958,
            "grammar_hyp": 3.42627,
            "nubia_score": 0.55421
        },
        "meteor": 0.40846015972697175,
        "bleurt": 0.07026,
        "bertscore": {
            "precision": 0.78306,
            "recall": 0.91276,
            "f1": 0.84286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 45,
        "mean_pred_length": 45.0,
        "std_pred_length": 0.0,
        "median_pred_length": 45.0,
        "min_pred_length": 45,
        "max_pred_length": 45,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.546756984930101,
        "distinct-2": 0.8636363636363636,
        "vocab_size-2": 38,
        "unique-2": 32,
        "entropy-2": 5.186704345910023,
        "cond_entropy-2": 0.6386995453299136,
        "distinct-3": 0.8837209302325582,
        "vocab_size-3": 38,
        "unique-3": 33,
        "entropy-3": 5.193706615167214,
        "cond_entropy-3": 0.01334476397177737,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 34.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 34,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.862575937540274,
        "cond_entropy-2-nopunct": 0.13874945992629595,
        "distinct-3-nopunct": 0.9375,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.875,
        "cond_entropy-3-nopunct": 0.01810588064154659,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0796907814246604,
        "rouge1": {
            "precision": 0.43137,
            "recall": 0.54986,
            "fmeasure": 0.48342
        },
        "rouge2": {
            "precision": 0.21212,
            "recall": 0.27641,
            "fmeasure": 0.24002
        },
        "rougeL": {
            "precision": 0.32353,
            "recall": 0.41785,
            "fmeasure": 0.36466
        },
        "rougeLsum": {
            "precision": 0.32353,
            "recall": 0.41785,
            "fmeasure": 0.36466
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8
        },
        "bleu": 21.6938,
        "nubia": {
            "semantic_relation": 3.32772,
            "contradiction": 6.09991,
            "irrelevancy": 51.39388,
            "logical_agreement": 42.50622,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.24414,
            "nubia_score": 0.39834
        },
        "meteor": 0.28606808809381734,
        "bleurt": -0.36158,
        "bertscore": {
            "precision": 0.82398,
            "recall": 0.88054,
            "f1": 0.84742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.5483870967741935,
        "vocab_size-1": 17,
        "unique-1": 5,
        "entropy-1": 3.986454374903004,
        "distinct-2": 0.6206896551724138,
        "vocab_size-2": 18,
        "unique-2": 7,
        "entropy-2": 4.0993603054724,
        "cond_entropy-2": 0.11068123646483499,
        "distinct-3": 0.6296296296296297,
        "vocab_size-3": 17,
        "unique-3": 7,
        "entropy-3": 4.014146761422729,
        "cond_entropy-3": -0.02901941889002934,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5517241379310345,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.8924637537482623,
        "distinct-2-nopunct": 0.5925925925925926,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 3.9400726873486547,
        "cond_entropy-2-nopunct": 0.1191287292581188,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 3.8438561897747237,
        "cond_entropy-3-nopunct": -0.03103131238874397,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.960947223027678,
        "rouge1": {
            "precision": 0.58456,
            "recall": 0.63119,
            "fmeasure": 0.59506
        },
        "rouge2": {
            "precision": 0.41597,
            "recall": 0.46309,
            "fmeasure": 0.42932
        },
        "rougeL": {
            "precision": 0.5239,
            "recall": 0.56526,
            "fmeasure": 0.53308
        },
        "rougeLsum": {
            "precision": 0.5239,
            "recall": 0.56526,
            "fmeasure": 0.53308
        },
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.625
        },
        "bleu": 49.81721,
        "nubia": {
            "semantic_relation": 3.96461,
            "contradiction": 31.72089,
            "irrelevancy": 46.54305,
            "logical_agreement": 21.73606,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.33397,
            "nubia_score": 0.76142
        },
        "meteor": 0.3737475541867939,
        "bleurt": -0.09563,
        "bertscore": {
            "precision": 0.87441,
            "recall": 0.90791,
            "f1": 0.88924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.4565647621309536,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.3829562908893333,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.48854979993100167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5335016092716056,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.44363,
            "fmeasure": 0.55364
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.12772,
            "fmeasure": 0.16231
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.30147,
            "fmeasure": 0.37356
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.30147,
            "fmeasure": 0.37356
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855
        },
        "bleu": 8.1135,
        "nubia": {
            "semantic_relation": 3.37289,
            "contradiction": 7.71669,
            "irrelevancy": 1.59429,
            "logical_agreement": 90.68902,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.7638,
            "nubia_score": 0.45427
        },
        "meteor": 0.23620042041949743,
        "bleurt": 0.03192,
        "bertscore": {
            "precision": 0.92776,
            "recall": 0.83073,
            "f1": 0.87205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 5.058302540677964,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.20415212411964456,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.05563315263446055,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.912272579176128,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.16006657499176574,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.06678301694496641,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1875601881738893,
        "rouge1": {
            "precision": 0.6794,
            "recall": 0.64938,
            "fmeasure": 0.65789
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.44361,
            "fmeasure": 0.44547
        },
        "rougeL": {
            "precision": 0.58136,
            "recall": 0.55988,
            "fmeasure": 0.56437
        },
        "rougeLsum": {
            "precision": 0.58136,
            "recall": 0.55988,
            "fmeasure": 0.56437
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3,
            "3": 0.5833333333333334
        },
        "bleu": 28.66003,
        "nubia": {
            "semantic_relation": 3.74322,
            "contradiction": 35.66663,
            "irrelevancy": 11.058,
            "logical_agreement": 53.27537,
            "grammar_ref": 4.46773,
            "grammar_hyp": 3.94777,
            "nubia_score": 0.62603
        },
        "meteor": 0.2634520317845493,
        "bleurt": 0.18027,
        "bertscore": {
            "precision": 0.92684,
            "recall": 0.88603,
            "f1": 0.89756
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.918255449150654,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.53636,
            "fmeasure": 0.54499
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.329,
            "fmeasure": 0.33799
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.53636,
            "fmeasure": 0.54499
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.53636,
            "fmeasure": 0.54499
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "bleu": 26.47073,
        "nubia": {
            "semantic_relation": 2.98096,
            "contradiction": 11.08695,
            "irrelevancy": 88.68426,
            "logical_agreement": 0.22879,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.78186,
            "nubia_score": 0.25346
        },
        "meteor": 0.3601861140299824,
        "bleurt": -0.05792,
        "bertscore": {
            "precision": 0.84706,
            "recall": 0.88617,
            "f1": 0.86617
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7153661346858999,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.53289,
            "fmeasure": 0.66844
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.37778,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.41447,
            "fmeasure": 0.51989
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.41447,
            "fmeasure": 0.51989
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5625
        },
        "bleu": 21.93765,
        "nubia": {
            "semantic_relation": 4.01198,
            "contradiction": 0.50685,
            "irrelevancy": 0.55307,
            "logical_agreement": 98.94008,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.62615,
            "nubia_score": 0.66526
        },
        "meteor": 0.27448184812745874,
        "bleurt": -0.08912,
        "bertscore": {
            "precision": 0.91249,
            "recall": 0.77537,
            "f1": 0.83478
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3636363636363635,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.33333,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.71429,
            "fmeasure": 0.58824
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "bleu": 9.42516,
        "nubia": {
            "semantic_relation": 4.4396,
            "contradiction": 0.16522,
            "irrelevancy": 27.58363,
            "logical_agreement": 72.25115,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.34368,
            "nubia_score": 0.93948
        },
        "meteor": 0.3637926081556674,
        "bleurt": 0.43573,
        "bertscore": {
            "precision": 0.85238,
            "recall": 0.88967,
            "f1": 0.87063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9447487389043867,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.78571,
            "fmeasure": 0.84615
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.5,
            "fmeasure": 0.53846
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.5,
            "fmeasure": 0.53846
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "bleu": 37.32083,
        "nubia": {
            "semantic_relation": 4.43952,
            "contradiction": 1.60784,
            "irrelevancy": 0.5779,
            "logical_agreement": 97.81426,
            "grammar_ref": 5.0526,
            "grammar_hyp": 6.08728,
            "nubia_score": 0.61803
        },
        "meteor": 0.46864534130158897,
        "bleurt": 0.08646,
        "bertscore": {
            "precision": 0.91876,
            "recall": 0.90229,
            "f1": 0.91045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 7.22841614740048,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.7571428571428571,
        "vocab_size-1": 53,
        "unique-1": 46,
        "entropy-1": 5.450571945454583,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 63,
        "unique-2": 60,
        "entropy-2": 5.9534850284493706,
        "cond_entropy-2": 0.42283496611541,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 61,
        "unique-3": 60,
        "entropy-3": 5.921938245870745,
        "cond_entropy-3": -0.025681679939320076,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.548351349665063,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8771929824561403,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.560788698299351,
        "distinct-2-nopunct": 0.9811320754716981,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.690184605506591,
        "cond_entropy-2-nopunct": 0.1499318555744374,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.07239428391737851,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9106292353194916,
        "rouge1": {
            "precision": 0.63493,
            "recall": 0.77503,
            "fmeasure": 0.67433
        },
        "rouge2": {
            "precision": 0.30475,
            "recall": 0.4001,
            "fmeasure": 0.33417
        },
        "rougeL": {
            "precision": 0.53531,
            "recall": 0.67534,
            "fmeasure": 0.57601
        },
        "rougeLsum": {
            "precision": 0.53531,
            "recall": 0.67534,
            "fmeasure": 0.57601
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.5555555555555556,
            "3": 0.9130434782608695
        },
        "bleu": 30.3586,
        "nubia": {
            "semantic_relation": 4.24213,
            "contradiction": 11.71573,
            "irrelevancy": 26.96829,
            "logical_agreement": 61.31598,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.01659,
            "nubia_score": 0.70291
        },
        "meteor": 0.37432375558819375,
        "bleurt": 0.29966,
        "bertscore": {
            "precision": 0.9007,
            "recall": 0.93943,
            "f1": 0.91723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.028123899379558497,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5353440765644715,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.57393,
            "fmeasure": 0.57828
        },
        "rouge2": {
            "precision": 0.19298,
            "recall": 0.18889,
            "fmeasure": 0.19081
        },
        "rougeL": {
            "precision": 0.31667,
            "recall": 0.30994,
            "fmeasure": 0.31311
        },
        "rougeLsum": {
            "precision": 0.31667,
            "recall": 0.30994,
            "fmeasure": 0.31311
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5
        },
        "bleu": 10.51704,
        "nubia": {
            "semantic_relation": 3.72808,
            "contradiction": 0.07808,
            "irrelevancy": 99.71926,
            "logical_agreement": 0.20266,
            "grammar_ref": 4.46991,
            "grammar_hyp": 3.91004,
            "nubia_score": 0.67686
        },
        "meteor": 0.26323916530885594,
        "bleurt": -0.37991,
        "bertscore": {
            "precision": 0.81899,
            "recall": 0.81435,
            "f1": 0.81667
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6578823768686535,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.19221791690466283,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.487122805397797,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.680813428089397,
        "cond_entropy-2-nopunct": 0.2211615997086176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743962,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.862562091788894,
        "rouge1": {
            "precision": 0.71296,
            "recall": 0.83011,
            "fmeasure": 0.75869
        },
        "rouge2": {
            "precision": 0.54813,
            "recall": 0.63558,
            "fmeasure": 0.58283
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.70408,
            "fmeasure": 0.64891
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.70408,
            "fmeasure": 0.64891
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "bleu": 51.9505,
        "nubia": {
            "semantic_relation": 4.15202,
            "contradiction": 0.51009,
            "irrelevancy": 48.68082,
            "logical_agreement": 50.8091,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.69646,
            "nubia_score": 0.7593
        },
        "meteor": 0.47020029803469765,
        "bleurt": 0.08114,
        "bertscore": {
            "precision": 0.90196,
            "recall": 0.91216,
            "f1": 0.90585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.648529168376138,
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.48889,
            "fmeasure": 0.53216
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "bleu": 53.90595,
        "nubia": {
            "semantic_relation": 4.42268,
            "contradiction": 0.48172,
            "irrelevancy": 0.47937,
            "logical_agreement": 99.03891,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.44059,
            "nubia_score": 0.83222
        },
        "meteor": 0.4508446043207896,
        "bleurt": 0.4735,
        "bertscore": {
            "precision": 0.95217,
            "recall": 0.93968,
            "f1": 0.94588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8261047680705476,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.60769,
            "fmeasure": 0.59273
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.27778,
            "fmeasure": 0.27391
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34231,
            "fmeasure": 0.33636
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34231,
            "fmeasure": 0.33636
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.625
        },
        "bleu": 21.4016,
        "nubia": {
            "semantic_relation": 3.27597,
            "contradiction": 48.49099,
            "irrelevancy": 50.9202,
            "logical_agreement": 0.58882,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.50558,
            "nubia_score": 0.3142
        },
        "meteor": 0.3184464413482169,
        "bleurt": -0.70237,
        "bertscore": {
            "precision": 0.89564,
            "recall": 0.87143,
            "f1": 0.88337
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622848,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964168,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.136433152627309,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.89474,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.89474,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.89474,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bleu": 52.78891,
        "nubia": {
            "semantic_relation": 4.82887,
            "contradiction": 0.19847,
            "irrelevancy": 0.41829,
            "logical_agreement": 99.38323,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.57794,
            "nubia_score": 0.90824
        },
        "meteor": 0.4793714549862686,
        "bleurt": 0.69108,
        "bertscore": {
            "precision": 0.97508,
            "recall": 0.96487,
            "f1": 0.96995
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": -0.036006438040157185,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.03912675144043808,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": -0.04089198233393866,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.04492500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1857229292339186,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.65833,
            "fmeasure": 0.71905
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.57115,
            "fmeasure": 0.59921
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.6131,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.6131,
            "fmeasure": 0.65497
        },
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "bleu": 29.35804,
        "nubia": {
            "semantic_relation": 3.86545,
            "contradiction": 49.90804,
            "irrelevancy": 1.02027,
            "logical_agreement": 49.07169,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.09979,
            "nubia_score": 0.4575
        },
        "meteor": 0.2672429011987672,
        "bleurt": -0.07815,
        "bertscore": {
            "precision": 0.9084,
            "recall": 0.88879,
            "f1": 0.89751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 6.5,
        "median_pred_length": 20.5,
        "min_pred_length": 14,
        "max_pred_length": 27,
        "distinct-1": 0.8536585365853658,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 5.0648690777888135,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.18426047065442136,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.07594885323329875,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.14840107988744514,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.292940843693608,
        "rouge1": {
            "precision": 0.59936,
            "recall": 0.55702,
            "fmeasure": 0.57501
        },
        "rouge2": {
            "precision": 0.32456,
            "recall": 0.32222,
            "fmeasure": 0.32266
        },
        "rougeL": {
            "precision": 0.53269,
            "recall": 0.48684,
            "fmeasure": 0.50663
        },
        "rougeLsum": {
            "precision": 0.53269,
            "recall": 0.48684,
            "fmeasure": 0.50663
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "bleu": 33.80431,
        "nubia": {
            "semantic_relation": 3.15611,
            "contradiction": 6.50518,
            "irrelevancy": 76.10629,
            "logical_agreement": 17.38852,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.11742,
            "nubia_score": 0.46765
        },
        "meteor": 0.30165351277666363,
        "bleurt": -0.17907,
        "bertscore": {
            "precision": 0.86925,
            "recall": 0.8449,
            "f1": 0.85419
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6410,
        "mean_pred_length": 12.82,
        "std_pred_length": 6.952956205816344,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 37,
        "distinct-1": 0.1435257410296412,
        "vocab_size-1": 920,
        "unique-1": 509,
        "entropy-1": 7.694141589218011,
        "distinct-2": 0.42656514382402705,
        "vocab_size-2": 2521,
        "unique-2": 1686,
        "entropy-2": 10.413527946767838,
        "cond_entropy-2": 2.4836542579754353,
        "distinct-3": 0.6201478743068392,
        "vocab_size-3": 3355,
        "unique-3": 2601,
        "entropy-3": 11.194800958100437,
        "cond_entropy-3": 0.8157052596078396,
        "total_length-nopunct": 5635,
        "mean_pred_length-nopunct": 11.27,
        "std_pred_length-nopunct": 6.363104588170777,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.16149068322981366,
        "vocab_size-1-nopunct": 910,
        "unique-1-nopunct": 507,
        "entropy-1-nopunct": 7.857950548059743,
        "distinct-2-nopunct": 0.43933787731256085,
        "vocab_size-2-nopunct": 2256,
        "unique-2-nopunct": 1547,
        "entropy-2-nopunct": 10.241293953624623,
        "cond_entropy-2-nopunct": 2.5274217088049906,
        "distinct-3-nopunct": 0.6345987920621226,
        "vocab_size-3-nopunct": 2942,
        "unique-3-nopunct": 2336,
        "entropy-3-nopunct": 11.0058157767092,
        "cond_entropy-3-nopunct": 0.8140773427946482,
        "msttr-100": 0.66719,
        "msttr-100_nopunct": 0.69607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.036668090014798,
        "rouge1": {
            "precision": 0.57515,
            "recall": 0.53317,
            "fmeasure": 0.54328
        },
        "rouge2": {
            "precision": 0.36173,
            "recall": 0.33233,
            "fmeasure": 0.3391
        },
        "rougeL": {
            "precision": 0.51633,
            "recall": 0.47869,
            "fmeasure": 0.48766
        },
        "rougeLsum": {
            "precision": 0.51633,
            "recall": 0.47869,
            "fmeasure": 0.48766
        },
        "local_recall": {
            "1": 0.5505076578902083
        },
        "bleu": 31.19395,
        "nubia": {
            "semantic_relation": 3.49426,
            "contradiction": 10.2232,
            "irrelevancy": 21.63285,
            "logical_agreement": 68.14396,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.53549,
            "nubia_score": 0.61129
        },
        "meteor": 0.3049933373093315,
        "bleurt": -0.12077,
        "bertscore": {
            "precision": 0.87046,
            "recall": 0.85907,
            "f1": 0.86429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.031192427318204,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.86713,
            "fmeasure": 0.87652
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.75556,
            "fmeasure": 0.73982
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.83683,
            "fmeasure": 0.81971
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.83683,
            "fmeasure": 0.81971
        },
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 81.47064,
        "nubia": {
            "semantic_relation": 4.86365,
            "contradiction": 0.73994,
            "irrelevancy": 41.40122,
            "logical_agreement": 57.85884,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.4846,
            "nubia_score": 0.92055
        },
        "meteor": 0.5292398399849825,
        "bleurt": 0.38827,
        "bertscore": {
            "precision": 0.95034,
            "recall": 0.96658,
            "f1": 0.94107
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.354997429774719,
        "rouge1": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.8963,
            "fmeasure": 0.8807
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 71.70327,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23544,
            "irrelevancy": 0.46592,
            "logical_agreement": 99.29864,
            "grammar_ref": 5.07856,
            "grammar_hyp": 4.58636,
            "nubia_score": 1.0
        },
        "meteor": 0.5423794259791352,
        "bleurt": 0.72235,
        "bertscore": {
            "precision": 0.97182,
            "recall": 0.98396,
            "f1": 0.97747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673073,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.733880981892677,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8888888888888888
        },
        "bleu": 57.60844,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.39232,
            "irrelevancy": 0.99354,
            "logical_agreement": 97.61415,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.79546,
            "nubia_score": 0.75076
        },
        "meteor": 0.45231505213245843,
        "bleurt": -0.0324,
        "bertscore": {
            "precision": 0.90565,
            "recall": 0.94307,
            "f1": 0.92398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8998572512287097,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bleu": 70.97039,
        "nubia": {
            "semantic_relation": 4.54342,
            "contradiction": 0.48545,
            "irrelevancy": 0.54019,
            "logical_agreement": 98.97436,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.36395,
            "nubia_score": 0.7985
        },
        "meteor": 0.5047034859011716,
        "bleurt": 0.49536,
        "bertscore": {
            "precision": 0.98271,
            "recall": 0.9644,
            "f1": 0.97347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7164498480432577,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.63636,
            "fmeasure": 0.6087
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.9090909090909091
        },
        "bleu": 56.81097,
        "nubia": {
            "semantic_relation": 4.38823,
            "contradiction": 0.39825,
            "irrelevancy": 33.42089,
            "logical_agreement": 66.18086,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.83667,
            "nubia_score": 0.82559
        },
        "meteor": 0.45314685627681994,
        "bleurt": 0.50079,
        "bertscore": {
            "precision": 0.95302,
            "recall": 0.96403,
            "f1": 0.94279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.8647266763812915,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.16996929423497284,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.024282836980452648,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7711426205984715,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.18612739319226904,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.026442737724814768,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.615500220477335,
        "rouge1": {
            "precision": 0.85507,
            "recall": 0.88,
            "fmeasure": 0.86612
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.7622
        },
        "rougeL": {
            "precision": 0.76087,
            "recall": 0.75391,
            "fmeasure": 0.75725
        },
        "rougeLsum": {
            "precision": 0.76087,
            "recall": 0.75391,
            "fmeasure": 0.75725
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.96
        },
        "bleu": 63.68464,
        "nubia": {
            "semantic_relation": 4.55545,
            "contradiction": 1.39729,
            "irrelevancy": 29.64981,
            "logical_agreement": 68.9529,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.51186,
            "nubia_score": 0.83913
        },
        "meteor": 0.485182775206548,
        "bleurt": 0.43603,
        "bertscore": {
            "precision": 0.94929,
            "recall": 0.96612,
            "f1": 0.95755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.1002408513582384,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.084183719779189,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.11215732334180958,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3065743271964314,
        "rouge1": {
            "precision": 0.75694,
            "recall": 0.63056,
            "fmeasure": 0.64686
        },
        "rouge2": {
            "precision": 0.65584,
            "recall": 0.59149,
            "fmeasure": 0.585
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.60591,
            "fmeasure": 0.61032
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.60591,
            "fmeasure": 0.61032
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.36
        },
        "bleu": 26.45668,
        "nubia": {
            "semantic_relation": 3.96546,
            "contradiction": 0.10574,
            "irrelevancy": 82.81982,
            "logical_agreement": 17.07443,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.57221,
            "nubia_score": 0.68851
        },
        "meteor": 0.25643643459788873,
        "bleurt": -0.17646,
        "bertscore": {
            "precision": 0.90908,
            "recall": 0.86835,
            "f1": 0.88765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.426571953117379,
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.8,
            "fmeasure": 0.80331
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.5291,
            "fmeasure": 0.53724
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.64444,
            "fmeasure": 0.6501
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.64444,
            "fmeasure": 0.6501
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bleu": 47.85544,
        "nubia": {
            "semantic_relation": 4.51965,
            "contradiction": 1.13534,
            "irrelevancy": 41.43127,
            "logical_agreement": 57.43339,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.60529,
            "nubia_score": 0.67226
        },
        "meteor": 0.453807465334152,
        "bleurt": 0.28061,
        "bertscore": {
            "precision": 0.96564,
            "recall": 0.93089,
            "f1": 0.94794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1749829548732527,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.8,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.4,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.4,
            "fmeasure": 0.28571
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "bleu": 9.42516,
        "nubia": {
            "semantic_relation": 4.22332,
            "contradiction": 0.11069,
            "irrelevancy": 99.77341,
            "logical_agreement": 0.11591,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.68662,
            "nubia_score": 0.97045
        },
        "meteor": 0.3609414007581571,
        "bleurt": 0.38368,
        "bertscore": {
            "precision": 0.89096,
            "recall": 0.94658,
            "f1": 0.91793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.06903423794455238,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.937839673628595,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.76923,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.6,
            "fmeasure": 0.65217
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.69231,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.69231,
            "fmeasure": 0.75
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "bleu": 45.39749,
        "nubia": {
            "semantic_relation": 4.04395,
            "contradiction": 15.76136,
            "irrelevancy": 1.84721,
            "logical_agreement": 82.39143,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.7347,
            "nubia_score": 0.61004
        },
        "meteor": 0.4137967428796576,
        "bleurt": 0.37523,
        "bertscore": {
            "precision": 0.96719,
            "recall": 0.92378,
            "f1": 0.94498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0945894140476606,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bleu": 62.62845,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37071,
            "irrelevancy": 0.70467,
            "logical_agreement": 98.92462,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.34125,
            "nubia_score": 0.98178
        },
        "meteor": 0.512675617900284,
        "bleurt": 0.79405,
        "bertscore": {
            "precision": 0.96634,
            "recall": 0.98092,
            "f1": 0.97358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 6,
        "total_length": 96,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.033222956847166,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.65625,
        "vocab_size-1": 63,
        "unique-1": 47,
        "entropy-1": 5.66943838184688,
        "distinct-2": 0.8777777777777778,
        "vocab_size-2": 79,
        "unique-2": 68,
        "entropy-2": 6.2474086518852205,
        "cond_entropy-2": 0.4666743779152275,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 78,
        "unique-3": 72,
        "entropy-3": 6.2494602799216175,
        "cond_entropy-3": -0.004297578312819151,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.017323597731316,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7108433734939759,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.642859914079858,
        "distinct-2-nopunct": 0.8701298701298701,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 6.007046280954645,
        "cond_entropy-2-nopunct": 0.3952652902981972,
        "distinct-3-nopunct": 0.9014084507042254,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.952564020913127,
        "cond_entropy-3-nopunct": -0.032532378936698005,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.605462503252389,
        "rouge1": {
            "precision": 0.86547,
            "recall": 0.83908,
            "fmeasure": 0.83446
        },
        "rouge2": {
            "precision": 0.65718,
            "recall": 0.63762,
            "fmeasure": 0.63643
        },
        "rougeL": {
            "precision": 0.78534,
            "recall": 0.77909,
            "fmeasure": 0.76805
        },
        "rougeLsum": {
            "precision": 0.78534,
            "recall": 0.77909,
            "fmeasure": 0.76805
        },
        "local_recall": {
            "1": 0.35,
            "2": 0.55,
            "3": 0.8064516129032258
        },
        "bleu": 56.255,
        "nubia": {
            "semantic_relation": 4.50244,
            "contradiction": 3.57633,
            "irrelevancy": 25.31573,
            "logical_agreement": 71.10793,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.41473,
            "nubia_score": 0.82404
        },
        "meteor": 0.45938373948037226,
        "bleurt": 0.33412,
        "bertscore": {
            "precision": 0.94691,
            "recall": 0.9429,
            "f1": 0.94436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 3.418698582794336,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7164179104477612,
        "vocab_size-1": 48,
        "unique-1": 37,
        "entropy-1": 5.343606026926923,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 60,
        "unique-2": 57,
        "entropy-2": 5.8820418282618245,
        "cond_entropy-2": 0.4573236212416159,
        "distinct-3": 1.0,
        "vocab_size-3": 59,
        "unique-3": 59,
        "entropy-3": 5.882643049361836,
        "cond_entropy-3": 0.007058041116162032,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.266784396332406,
        "distinct-2-nopunct": 0.9464285714285714,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.700212064914751,
        "cond_entropy-2-nopunct": 0.4612923971020622,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": 0.008469411468103191,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1003901289789813,
        "rouge1": {
            "precision": 0.58548,
            "recall": 0.53566,
            "fmeasure": 0.55903
        },
        "rouge2": {
            "precision": 0.35448,
            "recall": 0.32795,
            "fmeasure": 0.34041
        },
        "rougeL": {
            "precision": 0.48915,
            "recall": 0.45378,
            "fmeasure": 0.47049
        },
        "rougeLsum": {
            "precision": 0.48915,
            "recall": 0.45378,
            "fmeasure": 0.47049
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.40540540540540543
        },
        "bleu": 21.62776,
        "nubia": {
            "semantic_relation": 3.07186,
            "contradiction": 47.30451,
            "irrelevancy": 27.86786,
            "logical_agreement": 24.82763,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.82605,
            "nubia_score": 0.43224
        },
        "meteor": 0.25042473929623366,
        "bleurt": 0.08686,
        "bertscore": {
            "precision": 0.87752,
            "recall": 0.86947,
            "f1": 0.87315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8936441277848375,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "meteor": 0.9652173913043478,
        "bleurt": 0.55466,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.452819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.4238830957527497,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.41269152701913925,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2671131093267114,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44048,
            "fmeasure": 0.36594
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.14444,
            "fmeasure": 0.12063
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.5
        },
        "bleu": 5.65304,
        "nubia": {
            "semantic_relation": 3.33196,
            "contradiction": 0.33125,
            "irrelevancy": 82.65665,
            "logical_agreement": 17.0121,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.6716,
            "nubia_score": 0.40817
        },
        "meteor": 0.24704253628256037,
        "bleurt": -0.16926,
        "bertscore": {
            "precision": 0.71649,
            "recall": 0.77892,
            "f1": 0.71421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 5.5,
        "median_pred_length": 22.5,
        "min_pred_length": 17,
        "max_pred_length": 28,
        "distinct-1": 0.8,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 5.058302540677964,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.17487328634648452,
        "distinct-3": 0.9512195121951219,
        "vocab_size-3": 39,
        "unique-3": 37,
        "entropy-3": 5.259991029008325,
        "cond_entropy-3": -0.01993226227913626,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8717948717948718,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.028991962451991,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.047291203466791,
        "cond_entropy-2-nopunct": 0.0321592548748094,
        "distinct-3-nopunct": 0.9428571428571428,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.01499730265925,
        "cond_entropy-3-nopunct": -0.02302749154112622,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5836626610975544,
        "rouge1": {
            "precision": 0.48438,
            "recall": 0.52607,
            "fmeasure": 0.50103
        },
        "rouge2": {
            "precision": 0.275,
            "recall": 0.30142,
            "fmeasure": 0.28518
        },
        "rougeL": {
            "precision": 0.3498,
            "recall": 0.38577,
            "fmeasure": 0.36419
        },
        "rougeLsum": {
            "precision": 0.3498,
            "recall": 0.38577,
            "fmeasure": 0.36419
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.47619047619047616
        },
        "bleu": 23.26097,
        "nubia": {
            "semantic_relation": 3.54866,
            "contradiction": 2.90124,
            "irrelevancy": 79.59118,
            "logical_agreement": 17.50758,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.66072,
            "nubia_score": 0.53954
        },
        "meteor": 0.2684356371411201,
        "bleurt": -0.1631,
        "bertscore": {
            "precision": 0.894,
            "recall": 0.88054,
            "f1": 0.88721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.389840024653597,
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.53289,
            "fmeasure": 0.5303
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.24074,
            "fmeasure": 0.2451
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.34056,
            "fmeasure": 0.34641
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.34056,
            "fmeasure": 0.34641
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bleu": 25.28117,
        "nubia": {
            "semantic_relation": 2.64832,
            "contradiction": 2.75565,
            "irrelevancy": 92.93255,
            "logical_agreement": 4.3118,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.08286,
            "nubia_score": 0.40226
        },
        "meteor": 0.2825988457704087,
        "bleurt": -0.07531,
        "bertscore": {
            "precision": 0.86754,
            "recall": 0.87356,
            "f1": 0.87054
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 8.5,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.8,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.686146588249909,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.26389216315066666,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.025681679939320096,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.456564762130954,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.3115277194607619,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343526,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3034284044418065,
        "rouge1": {
            "precision": 0.6712,
            "recall": 0.70238,
            "fmeasure": 0.65274
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.4783,
            "fmeasure": 0.44903
        },
        "rougeL": {
            "precision": 0.57699,
            "recall": 0.53816,
            "fmeasure": 0.53164
        },
        "rougeLsum": {
            "precision": 0.57699,
            "recall": 0.53816,
            "fmeasure": 0.53164
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.7272727272727273,
            "3": 0.8181818181818182
        },
        "bleu": 36.12311,
        "nubia": {
            "semantic_relation": 3.97146,
            "contradiction": 0.95652,
            "irrelevancy": 57.12159,
            "logical_agreement": 41.92189,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.42504,
            "nubia_score": 0.64138
        },
        "meteor": 0.4257843995367026,
        "bleurt": 0.11091,
        "bertscore": {
            "precision": 0.93537,
            "recall": 0.93758,
            "f1": 0.9327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.5,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.43063240949075,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779475,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.328211816128447,
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.78301,
            "fmeasure": 0.76891
        },
        "rouge2": {
            "precision": 0.54464,
            "recall": 0.55006,
            "fmeasure": 0.54215
        },
        "rougeL": {
            "precision": 0.57778,
            "recall": 0.59497,
            "fmeasure": 0.5821
        },
        "rougeLsum": {
            "precision": 0.57778,
            "recall": 0.59497,
            "fmeasure": 0.5821
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.8947368421052632
        },
        "bleu": 53.42748,
        "nubia": {
            "semantic_relation": 3.78956,
            "contradiction": 0.83833,
            "irrelevancy": 0.92737,
            "logical_agreement": 98.2343,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.16158,
            "nubia_score": 0.63074
        },
        "meteor": 0.4653854190614951,
        "bleurt": 0.32746,
        "bertscore": {
            "precision": 0.94233,
            "recall": 0.94462,
            "f1": 0.94348
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.504706483564823,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.07916418769779479,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.386842188131012,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.0906003680144804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.186185062975116,
        "rouge1": {
            "precision": 0.8869,
            "recall": 0.87454,
            "fmeasure": 0.8788
        },
        "rouge2": {
            "precision": 0.7028,
            "recall": 0.70085,
            "fmeasure": 0.70012
        },
        "rougeL": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "rougeLsum": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "bleu": 57.37425,
        "nubia": {
            "semantic_relation": 4.56147,
            "contradiction": 0.17796,
            "irrelevancy": 49.33775,
            "logical_agreement": 50.48429,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.72623,
            "nubia_score": 0.84833
        },
        "meteor": 0.5268872887718299,
        "bleurt": 0.53956,
        "bertscore": {
            "precision": 0.96016,
            "recall": 0.96948,
            "f1": 0.9648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 132,
        "mean_pred_length": 26.4,
        "std_pred_length": 17.23484841824842,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 60,
        "distinct-1": 0.5075757575757576,
        "vocab_size-1": 67,
        "unique-1": 40,
        "entropy-1": 5.6430906873569615,
        "distinct-2": 0.7322834645669292,
        "vocab_size-2": 93,
        "unique-2": 70,
        "entropy-2": 6.3772772813253535,
        "cond_entropy-2": 0.6979415285004464,
        "distinct-3": 0.7786885245901639,
        "vocab_size-3": 95,
        "unique-3": 75,
        "entropy-3": 6.444801169405973,
        "cond_entropy-3": 0.05979468338580449,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 19.6,
        "std_pred_length-nopunct": 9.562426470305537,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6224489795918368,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.693242879586657,
        "distinct-2-nopunct": 0.7956989247311828,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 6.089971310991718,
        "cond_entropy-2-nopunct": 0.4140116015410032,
        "distinct-3-nopunct": 0.8409090909090909,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.115514999245366,
        "cond_entropy-3-nopunct": 0.0169747962147994,
        "msttr-100": 0.55,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.758991660960727,
        "rouge1": {
            "precision": 0.6868,
            "recall": 0.768,
            "fmeasure": 0.70839
        },
        "rouge2": {
            "precision": 0.50418,
            "recall": 0.54807,
            "fmeasure": 0.51504
        },
        "rougeL": {
            "precision": 0.57156,
            "recall": 0.61706,
            "fmeasure": 0.58237
        },
        "rougeLsum": {
            "precision": 0.57156,
            "recall": 0.61706,
            "fmeasure": 0.58237
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5490196078431373,
            "3": 0.8285714285714286
        },
        "bleu": 49.19813,
        "nubia": {
            "semantic_relation": 3.8035,
            "contradiction": 30.34888,
            "irrelevancy": 29.64987,
            "logical_agreement": 40.00125,
            "grammar_ref": 4.74118,
            "grammar_hyp": 3.96215,
            "nubia_score": 0.71052
        },
        "meteor": 0.39962319202199575,
        "bleurt": 0.0011,
        "bertscore": {
            "precision": 0.91589,
            "recall": 0.92288,
            "f1": 0.91842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4182958340544896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7609861280393986,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.30556,
            "fmeasure": 0.28696
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.5714285714285714
        },
        "bleu": 9.66927,
        "nubia": {
            "semantic_relation": 3.64356,
            "contradiction": 7.6418,
            "irrelevancy": 91.53191,
            "logical_agreement": 0.82629,
            "grammar_ref": 5.35395,
            "grammar_hyp": 3.93524,
            "nubia_score": 0.61842
        },
        "meteor": 0.2667430971613824,
        "bleurt": -0.18714,
        "bertscore": {
            "precision": 0.90444,
            "recall": 0.86691,
            "f1": 0.88528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 6.5,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.607264455478377,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.20567735722909256,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.49468036840891,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.22981123847439044,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5586754918863766,
        "rouge1": {
            "precision": 0.57083,
            "recall": 0.58459,
            "fmeasure": 0.56787
        },
        "rouge2": {
            "precision": 0.37218,
            "recall": 0.38301,
            "fmeasure": 0.36964
        },
        "rougeL": {
            "precision": 0.54583,
            "recall": 0.56653,
            "fmeasure": 0.54593
        },
        "rougeLsum": {
            "precision": 0.54583,
            "recall": 0.56653,
            "fmeasure": 0.54593
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.6470588235294118
        },
        "bleu": 28.77102,
        "nubia": {
            "semantic_relation": 4.19971,
            "contradiction": 0.78602,
            "irrelevancy": 42.60009,
            "logical_agreement": 56.61389,
            "grammar_ref": 4.56502,
            "grammar_hyp": 4.91209,
            "nubia_score": 0.71554
        },
        "meteor": 0.34506306367250683,
        "bleurt": 0.53313,
        "bertscore": {
            "precision": 0.92823,
            "recall": 0.9021,
            "f1": 0.91327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1227137604546689,
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "bleu": 14.99111,
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "meteor": 0.2731132551770082,
        "bleurt": 0.34221,
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 7.5,
        "median_pred_length": 21.5,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.627906976744186,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 4.5012778358458805,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 37,
        "unique-2": 34,
        "entropy-2": 5.144018163101899,
        "cond_entropy-2": 0.6390811525660803,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": 0.10105245788938208,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6410256410256411,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.368108949354111,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.026888838543454,
        "cond_entropy-2-nopunct": 0.6384994577919103,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": 0.11282643709211573,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2855547220568173,
        "rouge1": {
            "precision": 0.41987,
            "recall": 0.62211,
            "fmeasure": 0.50108
        },
        "rouge2": {
            "precision": 0.28444,
            "recall": 0.43382,
            "fmeasure": 0.34345
        },
        "rougeL": {
            "precision": 0.40064,
            "recall": 0.59259,
            "fmeasure": 0.47781
        },
        "rougeLsum": {
            "precision": 0.40064,
            "recall": 0.59259,
            "fmeasure": 0.47781
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.5333333333333333,
            "3": 1.0
        },
        "bleu": 20.82854,
        "nubia": {
            "semantic_relation": 3.39824,
            "contradiction": 37.20811,
            "irrelevancy": 39.81631,
            "logical_agreement": 22.97558,
            "grammar_ref": 4.46901,
            "grammar_hyp": 3.33528,
            "nubia_score": 0.60807
        },
        "meteor": 0.3121811820071207,
        "bleurt": 0.11077,
        "bertscore": {
            "precision": 0.90138,
            "recall": 0.90888,
            "f1": 0.90486
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 8,
        "total_length": 113,
        "mean_pred_length": 14.125,
        "std_pred_length": 2.9764702249476644,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.504424778761062,
        "vocab_size-1": 57,
        "unique-1": 32,
        "entropy-1": 5.414922435694211,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 77,
        "unique-2": 56,
        "entropy-2": 6.1212487318900175,
        "cond_entropy-2": 0.584822031565038,
        "distinct-3": 0.7938144329896907,
        "vocab_size-3": 77,
        "unique-3": 61,
        "entropy-3": 6.151358460699231,
        "cond_entropy-3": 0.05839812351238117,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 12.625,
        "std_pred_length-nopunct": 2.4462982238476156,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5247524752475248,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.343419527113458,
        "distinct-2-nopunct": 0.7096774193548387,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.891151687382333,
        "cond_entropy-2-nopunct": 0.5963164145173206,
        "distinct-3-nopunct": 0.7764705882352941,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.921040641969152,
        "cond_entropy-3-nopunct": 0.03205433093747602,
        "msttr-100": 0.54,
        "msttr-100_nopunct": 0.53,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.143856663589571,
        "rouge1": {
            "precision": 0.82397,
            "recall": 0.66236,
            "fmeasure": 0.72521
        },
        "rouge2": {
            "precision": 0.6319,
            "recall": 0.50153,
            "fmeasure": 0.55144
        },
        "rougeL": {
            "precision": 0.72577,
            "recall": 0.59438,
            "fmeasure": 0.64582
        },
        "rougeLsum": {
            "precision": 0.72577,
            "recall": 0.59438,
            "fmeasure": 0.64582
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.6486486486486487,
            "3": 0.6438356164383562
        },
        "bleu": 44.06712,
        "nubia": {
            "semantic_relation": 3.75507,
            "contradiction": 33.59649,
            "irrelevancy": 14.91391,
            "logical_agreement": 51.4896,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.24333,
            "nubia_score": 0.61482
        },
        "meteor": 0.3526549462542613,
        "bleurt": 0.14634,
        "bertscore": {
            "precision": 0.93403,
            "recall": 0.8976,
            "f1": 0.91347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 1.0897247358851685,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 24,
        "entropy-1": 4.897300040726041,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 37,
        "unique-2": 33,
        "entropy-2": 5.16243005339857,
        "cond_entropy-2": 0.12801323760946903,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 34,
        "unique-3": 31,
        "entropy-3": 5.047291203466791,
        "cond_entropy-3": -0.09404458493507994,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 1.0897247358851685,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.9001157240775095,
        "distinct-2-nopunct": 0.8918918918918919,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.993237149412737,
        "cond_entropy-2-nopunct": 0.11554696917744622,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.8625759375402735,
        "cond_entropy-3-nopunct": -0.10445318566443552,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2184408215379925,
        "rouge1": {
            "precision": 0.76528,
            "recall": 0.76612,
            "fmeasure": 0.75307
        },
        "rouge2": {
            "precision": 0.68398,
            "recall": 0.68056,
            "fmeasure": 0.66413
        },
        "rougeL": {
            "precision": 0.76528,
            "recall": 0.76612,
            "fmeasure": 0.75307
        },
        "rougeLsum": {
            "precision": 0.76528,
            "recall": 0.76612,
            "fmeasure": 0.75307
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.7222222222222222
        },
        "bleu": 59.86822,
        "nubia": {
            "semantic_relation": 4.50737,
            "contradiction": 6.07398,
            "irrelevancy": 53.6528,
            "logical_agreement": 40.27322,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.89117,
            "nubia_score": 0.74463
        },
        "meteor": 0.41887035365113695,
        "bleurt": 0.31987,
        "bertscore": {
            "precision": 0.94676,
            "recall": 0.95335,
            "f1": 0.94805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 56,
        "mean_pred_length": 28.0,
        "std_pred_length": 10.0,
        "median_pred_length": 28.0,
        "min_pred_length": 18,
        "max_pred_length": 38,
        "distinct-1": 0.8392857142857143,
        "vocab_size-1": 47,
        "unique-1": 41,
        "entropy-1": 5.436731930947546,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.2948453116274104,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.054447784022376544,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.86,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.308758439731457,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.29016646724150397,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.06140054466414332,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.304412510550277,
        "rouge1": {
            "precision": 0.68627,
            "recall": 0.65648,
            "fmeasure": 0.66648
        },
        "rouge2": {
            "precision": 0.44271,
            "recall": 0.41774,
            "fmeasure": 0.42672
        },
        "rougeL": {
            "precision": 0.57516,
            "recall": 0.56423,
            "fmeasure": 0.56292
        },
        "rougeLsum": {
            "precision": 0.57516,
            "recall": 0.56423,
            "fmeasure": 0.56292
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0,
            "3": 0.717948717948718
        },
        "bleu": 38.03832,
        "nubia": {
            "semantic_relation": 3.69101,
            "contradiction": 49.97374,
            "irrelevancy": 2.67386,
            "logical_agreement": 47.3524,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.93302,
            "nubia_score": 0.54305
        },
        "meteor": 0.36224259386308244,
        "bleurt": 0.216,
        "bertscore": {
            "precision": 0.89445,
            "recall": 0.8941,
            "f1": 0.89397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4160855200757196,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 0.84615,
            "fmeasure": 0.84615
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "local_recall": {
            "1": 0,
            "2": 0.8,
            "3": 1.0
        },
        "bleu": 74.4782,
        "nubia": {
            "semantic_relation": 4.56461,
            "contradiction": 0.29772,
            "irrelevancy": 34.06963,
            "logical_agreement": 65.63266,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.2037,
            "nubia_score": 0.84079
        },
        "meteor": 0.5370438479273406,
        "bleurt": 0.6574,
        "bertscore": {
            "precision": 0.96662,
            "recall": 0.99259,
            "f1": 0.97906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.14719639064341358,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910023,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.16249647625006503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.955214327295357,
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96394
        },
        "rouge2": {
            "precision": 0.8287,
            "recall": 0.89286,
            "fmeasure": 0.85784
        },
        "rougeL": {
            "precision": 0.85641,
            "recall": 0.92308,
            "fmeasure": 0.88701
        },
        "rougeLsum": {
            "precision": 0.85641,
            "recall": 0.92308,
            "fmeasure": 0.88701
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 1.0
        },
        "bleu": 81.06348,
        "nubia": {
            "semantic_relation": 4.61445,
            "contradiction": 0.29114,
            "irrelevancy": 33.51625,
            "logical_agreement": 66.19261,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.06484,
            "nubia_score": 0.8671
        },
        "meteor": 0.5488266166274285,
        "bleurt": 0.60893,
        "bertscore": {
            "precision": 0.96032,
            "recall": 0.97163,
            "f1": 0.96592
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.8464393446710154,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.4265138924681673,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.22388309575274973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2115769177105458,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.93333,
            "fmeasure": 0.84848
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.64286,
            "fmeasure": 0.58065
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.46667,
            "fmeasure": 0.42424
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.46667,
            "fmeasure": 0.42424
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bleu": 41.52094,
        "nubia": {
            "semantic_relation": 4.27979,
            "contradiction": 0.381,
            "irrelevancy": 1.84151,
            "logical_agreement": 97.7775,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.89061,
            "nubia_score": 0.83191
        },
        "meteor": 0.4548022656206538,
        "bleurt": 0.21047,
        "bertscore": {
            "precision": 0.91146,
            "recall": 0.9352,
            "f1": 0.92318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5982245915424167,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.34091,
            "fmeasure": 0.40336
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.5625
        },
        "bleu": 34.01102,
        "nubia": {
            "semantic_relation": 3.8252,
            "contradiction": 35.4933,
            "irrelevancy": 2.38998,
            "logical_agreement": 62.11671,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.52825,
            "nubia_score": 0.53725
        },
        "meteor": 0.3496300493456508,
        "bleurt": 0.40241,
        "bertscore": {
            "precision": 0.97321,
            "recall": 0.91953,
            "f1": 0.93834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9522881867081354,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.53301,
            "fmeasure": 0.60633
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.32977,
            "fmeasure": 0.37725
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.49123,
            "fmeasure": 0.52437
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.49123,
            "fmeasure": 0.52437
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "bleu": 28.09343,
        "nubia": {
            "semantic_relation": 3.67523,
            "contradiction": 20.76941,
            "irrelevancy": 49.60655,
            "logical_agreement": 29.62404,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.29546,
            "nubia_score": 0.56027
        },
        "meteor": 0.30912926411134717,
        "bleurt": 0.1682,
        "bertscore": {
            "precision": 0.92682,
            "recall": 0.8761,
            "f1": 0.90075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.423065265165703,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0,
        "bleurt": 0.94038,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966063,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.113129958794178,
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.69758,
            "fmeasure": 0.69001
        },
        "rouge2": {
            "precision": 0.40351,
            "recall": 0.45185,
            "fmeasure": 0.42554
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.64187,
            "fmeasure": 0.62647
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.64187,
            "fmeasure": 0.62647
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bleu": 18.54541,
        "nubia": {
            "semantic_relation": 4.32793,
            "contradiction": 1.03592,
            "irrelevancy": 40.67919,
            "logical_agreement": 58.28489,
            "grammar_ref": 4.42639,
            "grammar_hyp": 3.74913,
            "nubia_score": 0.85973
        },
        "meteor": 0.3594595227826925,
        "bleurt": 0.42774,
        "bertscore": {
            "precision": 0.92232,
            "recall": 0.92776,
            "f1": 0.91894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6595744680851063,
        "vocab_size-1": 31,
        "unique-1": 23,
        "entropy-1": 4.724385660004151,
        "distinct-2": 0.8636363636363636,
        "vocab_size-2": 38,
        "unique-2": 32,
        "entropy-2": 5.186704345910023,
        "cond_entropy-2": 0.4108578239253507,
        "distinct-3": 0.9024390243902439,
        "vocab_size-3": 37,
        "unique-3": 33,
        "entropy-3": 5.16243005339857,
        "cond_entropy-3": -0.05309912621433559,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6585365853658537,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.521828528850024,
        "distinct-2-nopunct": 0.868421052631579,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.9847696187067445,
        "cond_entropy-2-nopunct": 0.47628768004893346,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516393,
        "cond_entropy-3-nopunct": -0.06150163935576179,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.933466654200098,
        "rouge1": {
            "precision": 0.79094,
            "recall": 0.8771,
            "fmeasure": 0.82235
        },
        "rouge2": {
            "precision": 0.62581,
            "recall": 0.63737,
            "fmeasure": 0.62878
        },
        "rougeL": {
            "precision": 0.72076,
            "recall": 0.76263,
            "fmeasure": 0.73537
        },
        "rougeLsum": {
            "precision": 0.72076,
            "recall": 0.76263,
            "fmeasure": 0.73537
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9032258064516129
        },
        "bleu": 53.47601,
        "nubia": {
            "semantic_relation": 4.52211,
            "contradiction": 0.6899,
            "irrelevancy": 27.95814,
            "logical_agreement": 71.35196,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.69954,
            "nubia_score": 0.786
        },
        "meteor": 0.48143103761427075,
        "bleurt": 0.51498,
        "bertscore": {
            "precision": 0.93426,
            "recall": 0.95458,
            "f1": 0.94405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5708514565692293,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57071,
            "fmeasure": 0.61472
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.21515,
            "fmeasure": 0.23509
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "bleu": 23.02104,
        "nubia": {
            "semantic_relation": 4.75868,
            "contradiction": 0.67843,
            "irrelevancy": 47.31477,
            "logical_agreement": 52.0068,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.55186,
            "nubia_score": 0.89352
        },
        "meteor": 0.2904516730189926,
        "bleurt": 0.30229,
        "bertscore": {
            "precision": 0.92577,
            "recall": 0.9082,
            "f1": 0.91649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4595216280661427,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "bleu": 38.14156,
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "meteor": 0.3918734238227112,
        "bleurt": 0.44858,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.771611544534406,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.75566,
            "fmeasure": 0.82483
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.59375,
            "fmeasure": 0.65056
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.51357,
            "fmeasure": 0.56138
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.51357,
            "fmeasure": 0.56138
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "bleu": 61.68673,
        "nubia": {
            "semantic_relation": 4.29686,
            "contradiction": 0.2819,
            "irrelevancy": 0.49154,
            "logical_agreement": 99.22655,
            "grammar_ref": 4.29821,
            "grammar_hyp": 5.14999,
            "nubia_score": 0.70671
        },
        "meteor": 0.5291073080791932,
        "bleurt": 0.44261,
        "bertscore": {
            "precision": 0.96802,
            "recall": 0.95686,
            "f1": 0.96241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6530437207411035,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.9828,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4089039873913056,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "bleu": 10.1471,
        "nubia": {
            "semantic_relation": 4.42997,
            "contradiction": 0.29922,
            "irrelevancy": 81.94674,
            "logical_agreement": 17.75405,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.87374,
            "nubia_score": 0.90732
        },
        "meteor": 0.2335237577237677,
        "bleurt": 0.15132,
        "bertscore": {
            "precision": 0.8491,
            "recall": 0.83445,
            "f1": 0.84171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.503310677983855,
        "rouge1": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.97619,
            "fmeasure": 0.95556
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "bleu": 81.53551,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16036,
            "irrelevancy": 2.58913,
            "logical_agreement": 97.25051,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.06363,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.83419,
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99927,
            "f1": 0.99595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 5,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.9496835316262997,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7,
        "vocab_size-1": 49,
        "unique-1": 38,
        "entropy-1": 5.369007574818199,
        "distinct-2": 0.8615384615384616,
        "vocab_size-2": 56,
        "unique-2": 49,
        "entropy-2": 5.714675505336151,
        "cond_entropy-2": 0.2255408033825157,
        "distinct-3": 0.9,
        "vocab_size-3": 54,
        "unique-3": 48,
        "entropy-3": 5.706890595608517,
        "cond_entropy-3": 0.017856115913397443,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.3466401061363023,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.34672992103457,
        "distinct-2-nopunct": 0.8545454545454545,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.454086986251929,
        "cond_entropy-2-nopunct": 0.14009894472408332,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.443856189774724,
        "cond_entropy-3-nopunct": 0.022496476250064984,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.308646717100051,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.76074,
            "fmeasure": 0.77522
        },
        "rouge2": {
            "precision": 0.62607,
            "recall": 0.6054,
            "fmeasure": 0.61251
        },
        "rougeL": {
            "precision": 0.77,
            "recall": 0.73834,
            "fmeasure": 0.74959
        },
        "rougeLsum": {
            "precision": 0.77,
            "recall": 0.73834,
            "fmeasure": 0.74959
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.717391304347826
        },
        "bleu": 49.43392,
        "nubia": {
            "semantic_relation": 4.16623,
            "contradiction": 21.65379,
            "irrelevancy": 24.25621,
            "logical_agreement": 54.09,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.84231,
            "nubia_score": 0.70613
        },
        "meteor": 0.3978849710951134,
        "bleurt": 0.31855,
        "bertscore": {
            "precision": 0.93026,
            "recall": 0.93429,
            "f1": 0.93189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.708358585831593,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "bleu": 34.78701,
        "nubia": {
            "semantic_relation": 3.45396,
            "contradiction": 73.65503,
            "irrelevancy": 18.43624,
            "logical_agreement": 7.90873,
            "grammar_ref": 5.49813,
            "grammar_hyp": 4.91604,
            "nubia_score": 0.39438
        },
        "meteor": 0.26027818000876035,
        "bleurt": 0.44213,
        "bertscore": {
            "precision": 0.92911,
            "recall": 0.90253,
            "f1": 0.91563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 5.436502143433363,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 27,
        "distinct-1": 0.7758620689655172,
        "vocab_size-1": 45,
        "unique-1": 36,
        "entropy-1": 5.349191770915037,
        "distinct-2": 0.9636363636363636,
        "vocab_size-2": 53,
        "unique-2": 51,
        "entropy-2": 5.708632440797383,
        "cond_entropy-2": 0.3007403093455141,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 51,
        "unique-3": 50,
        "entropy-3": 5.661978179679557,
        "cond_entropy-3": -0.04245845692202903,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7962962962962963,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.2964636595308106,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.59399396942248,
        "cond_entropy-2-nopunct": 0.3048885751445654,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.543295834054494,
        "cond_entropy-3-nopunct": -0.06662950791700607,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.296819646999042,
        "rouge1": {
            "precision": 0.7363,
            "recall": 0.74474,
            "fmeasure": 0.72858
        },
        "rouge2": {
            "precision": 0.48942,
            "recall": 0.5135,
            "fmeasure": 0.49229
        },
        "rougeL": {
            "precision": 0.63852,
            "recall": 0.66339,
            "fmeasure": 0.64048
        },
        "rougeLsum": {
            "precision": 0.63852,
            "recall": 0.66339,
            "fmeasure": 0.64048
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.07692307692307693,
            "3": 0.8780487804878049
        },
        "bleu": 44.73187,
        "nubia": {
            "semantic_relation": 4.08769,
            "contradiction": 3.97186,
            "irrelevancy": 26.56418,
            "logical_agreement": 69.46396,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.19027,
            "nubia_score": 0.70675
        },
        "meteor": 0.39711251745609905,
        "bleurt": -0.00154,
        "bertscore": {
            "precision": 0.92148,
            "recall": 0.91407,
            "f1": 0.91773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.72,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.0536606896881855,
        "distinct-2": 0.875,
        "vocab_size-2": 21,
        "unique-2": 18,
        "entropy-2": 4.334962500721156,
        "cond_entropy-2": 0.3058932902032429,
        "distinct-3": 0.9130434782608695,
        "vocab_size-3": 21,
        "unique-3": 19,
        "entropy-3": 4.349648912578752,
        "cond_entropy-3": 0.025555977074987156,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.8796640049025934,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.20184123230257,
        "cond_entropy-2-nopunct": 0.3021661613873427,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.221928094887362,
        "cond_entropy-3-nopunct": -0.020389327891398,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5287855477614216,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9333333333333333
        },
        "bleu": 64.44281,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.3456,
            "irrelevancy": 0.69108,
            "logical_agreement": 98.96331,
            "grammar_ref": 3.47563,
            "grammar_hyp": 2.87876,
            "nubia_score": 1.0
        },
        "meteor": 0.601757720024524,
        "bleurt": 0.8218,
        "bertscore": {
            "precision": 0.98199,
            "recall": 0.99063,
            "f1": 0.98629
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0877627602658655,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2,
            "fmeasure": 0.21053
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.26869,
            "fmeasure": 0.30857
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.26869,
            "fmeasure": 0.30857
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "bleu": 18.36028,
        "nubia": {
            "semantic_relation": 3.43374,
            "contradiction": 1.16957,
            "irrelevancy": 84.26305,
            "logical_agreement": 14.56737,
            "grammar_ref": 4.59968,
            "grammar_hyp": 5.40135,
            "nubia_score": 0.38447
        },
        "meteor": 0.2532969659486065,
        "bleurt": -0.273,
        "bertscore": {
            "precision": 0.83563,
            "recall": 0.79964,
            "f1": 0.80872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.088779347361362,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819113,
        "cond_entropy-2": 0.20859693530755724,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.9219280948873623,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.03740119765411,
        "cond_entropy-2-nopunct": 0.13652573434569693,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.646567429301563,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.92063,
            "fmeasure": 0.7886
        },
        "rouge2": {
            "precision": 0.5873,
            "recall": 0.80238,
            "fmeasure": 0.6741
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.84444,
            "fmeasure": 0.72156
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.84444,
            "fmeasure": 0.72156
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 1.0
        },
        "bleu": 55.92599,
        "nubia": {
            "semantic_relation": 3.80198,
            "contradiction": 0.37605,
            "irrelevancy": 95.10599,
            "logical_agreement": 4.51796,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.03118,
            "nubia_score": 0.7678
        },
        "meteor": 0.49440428136592957,
        "bleurt": 0.18353,
        "bertscore": {
            "precision": 0.87819,
            "recall": 0.98568,
            "f1": 0.92177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9450672866492799,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.41159,
            "fmeasure": 0.51877
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.20899,
            "fmeasure": 0.25594
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.2638,
            "fmeasure": 0.34536
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.2638,
            "fmeasure": 0.34536
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.5
        },
        "bleu": 22.34848,
        "nubia": {
            "semantic_relation": 3.782,
            "contradiction": 19.00878,
            "irrelevancy": 2.71582,
            "logical_agreement": 78.2754,
            "grammar_ref": 3.59602,
            "grammar_hyp": 4.3121,
            "nubia_score": 0.51414
        },
        "meteor": 0.24471746231685645,
        "bleurt": -0.06119,
        "bertscore": {
            "precision": 0.91568,
            "recall": 0.86375,
            "f1": 0.88356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.03600643804015718,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4457324615573395,
        "rouge1": {
            "precision": 0.71759,
            "recall": 0.69192,
            "fmeasure": 0.69988
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.34881,
            "fmeasure": 0.34578
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.51498,
            "fmeasure": 0.52214
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.51498,
            "fmeasure": 0.52214
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6842105263157895
        },
        "bleu": 11.80207,
        "nubia": {
            "semantic_relation": 4.05261,
            "contradiction": 0.23036,
            "irrelevancy": 0.89021,
            "logical_agreement": 98.87942,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.03309,
            "nubia_score": 0.66065
        },
        "meteor": 0.36130959206901175,
        "bleurt": 0.29262,
        "bertscore": {
            "precision": 0.91747,
            "recall": 0.88844,
            "f1": 0.90202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.55,
        "vocab_size-1": 11,
        "unique-1": 2,
        "entropy-1": 3.4219280948873623,
        "distinct-2": 0.5555555555555556,
        "vocab_size-2": 10,
        "unique-2": 2,
        "entropy-2": 3.281036112553423,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 0.5625,
        "vocab_size-3": 9,
        "unique-3": 2,
        "entropy-3": 3.125,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.5555555555555556,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.281036112553423,
        "distinct-2-nopunct": 0.5625,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 3.125,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 0.5714285714285714,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 2.950212064914747,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6125095646742262,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.64489,
            "fmeasure": 0.76
        },
        "rouge2": {
            "precision": 0.77083,
            "recall": 0.51667,
            "fmeasure": 0.61272
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.56723,
            "fmeasure": 0.66333
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.56723,
            "fmeasure": 0.66333
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714,
            "3": 0.631578947368421
        },
        "bleu": 48.68228,
        "nubia": {
            "semantic_relation": 4.62189,
            "contradiction": 0.27006,
            "irrelevancy": 17.10684,
            "logical_agreement": 82.62309,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.9564,
            "nubia_score": 0.7143
        },
        "meteor": 0.37060075338492704,
        "bleurt": 0.19316,
        "bertscore": {
            "precision": 0.9295,
            "recall": 0.8746,
            "f1": 0.90113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9615384615384616,
        "vocab_size-1": 25,
        "unique-1": 24,
        "entropy-1": 4.623516641218013,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.016583528366367506,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.172340008278376,
        "rouge1": {
            "precision": 0.4058,
            "recall": 0.76768,
            "fmeasure": 0.52838
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.58182,
            "fmeasure": 0.37121
        },
        "rougeL": {
            "precision": 0.4058,
            "recall": 0.76768,
            "fmeasure": 0.52838
        },
        "rougeLsum": {
            "precision": 0.4058,
            "recall": 0.76768,
            "fmeasure": 0.52838
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.9
        },
        "bleu": 25.13074,
        "nubia": {
            "semantic_relation": 4.16709,
            "contradiction": 0.13656,
            "irrelevancy": 97.29994,
            "logical_agreement": 2.5635,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.40741,
            "nubia_score": 0.66468
        },
        "meteor": 0.346162991238991,
        "bleurt": -0.07859,
        "bertscore": {
            "precision": 0.81449,
            "recall": 0.90418,
            "f1": 0.85568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.378783493486176,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2777001806988724,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.315824333525706,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.30118944924673074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4218120230934956,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.72677,
            "fmeasure": 0.67626
        },
        "rouge2": {
            "precision": 0.43182,
            "recall": 0.48521,
            "fmeasure": 0.44901
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.71843,
            "fmeasure": 0.66674
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.71843,
            "fmeasure": 0.66674
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.7058823529411765
        },
        "bleu": 39.39429,
        "nubia": {
            "semantic_relation": 3.89708,
            "contradiction": 46.91855,
            "irrelevancy": 49.10038,
            "logical_agreement": 3.98106,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.89087,
            "nubia_score": 0.69929
        },
        "meteor": 0.36107708269991606,
        "bleurt": 0.4152,
        "bertscore": {
            "precision": 0.91245,
            "recall": 0.94155,
            "f1": 0.92642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5915180358814969,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "bleu": 9.15027,
        "nubia": {
            "semantic_relation": 4.48529,
            "contradiction": 0.47979,
            "irrelevancy": 1.23299,
            "logical_agreement": 98.28722,
            "grammar_ref": 3.76485,
            "grammar_hyp": 5.05136,
            "nubia_score": 0.74206
        },
        "meteor": 0.31467549293696634,
        "bleurt": 0.2364,
        "bertscore": {
            "precision": 0.90869,
            "recall": 0.90764,
            "f1": 0.90817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6961650890339652,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.74566,
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8646054890616752,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bleu": 42.50281,
        "nubia": {
            "semantic_relation": 4.6542,
            "contradiction": 0.23542,
            "irrelevancy": 4.26769,
            "logical_agreement": 95.49688,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.03878,
            "nubia_score": 0.87015
        },
        "meteor": 0.48351570164972274,
        "bleurt": 0.68139,
        "bertscore": {
            "precision": 0.96145,
            "recall": 0.96696,
            "f1": 0.9642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7990385038524417,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "bleu": 20.16495,
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "meteor": 0.861811391223156,
        "bleurt": 0.49066,
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2775418301849517,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "bleu": 11.33958,
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        },
        "meteor": 0.31127891035349853,
        "bleurt": -0.04695,
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6897436213475805,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 10.2292,
        "nubia": {
            "semantic_relation": 4.72327,
            "contradiction": 0.84395,
            "irrelevancy": 0.72514,
            "logical_agreement": 98.4309,
            "grammar_ref": 3.90557,
            "grammar_hyp": 5.44201,
            "nubia_score": 0.76386
        },
        "meteor": 0.21681459836474348,
        "bleurt": -0.37669,
        "bertscore": {
            "precision": 0.84997,
            "recall": 0.83542,
            "f1": 0.84204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8094988549899862,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 24.59813,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "meteor": 0.3010544205973617,
        "bleurt": 0.30353,
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2231086688195565,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.86111,
            "fmeasure": 0.71212
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.59394,
            "fmeasure": 0.44762
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.72222,
            "fmeasure": 0.59848
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bleu": 21.83418,
        "nubia": {
            "semantic_relation": 4.37388,
            "contradiction": 9.95059,
            "irrelevancy": 70.10601,
            "logical_agreement": 19.94339,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.17175,
            "nubia_score": 0.73579
        },
        "meteor": 0.42919650333815856,
        "bleurt": 0.10378,
        "bertscore": {
            "precision": 0.86422,
            "recall": 0.94535,
            "f1": 0.90005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8441645853579183,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "bleu": 44.5345,
        "nubia": {
            "semantic_relation": 4.19399,
            "contradiction": 0.18495,
            "irrelevancy": 94.22535,
            "logical_agreement": 5.5897,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31806,
            "nubia_score": 0.76494
        },
        "meteor": 0.4505163353501177,
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5776685007264514,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.54971,
            "fmeasure": 0.5873
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2037,
            "fmeasure": 0.21795
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.45809,
            "fmeasure": 0.48942
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.45809,
            "fmeasure": 0.48942
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 12.4195,
        "nubia": {
            "semantic_relation": 4.24931,
            "contradiction": 0.35328,
            "irrelevancy": 10.34535,
            "logical_agreement": 89.30138,
            "grammar_ref": 3.44041,
            "grammar_hyp": 4.36176,
            "nubia_score": 0.7433
        },
        "meteor": 0.37801464691166176,
        "bleurt": 0.30653,
        "bertscore": {
            "precision": 0.92623,
            "recall": 0.92851,
            "f1": 0.92737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.6571428571428571,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.250571945454579,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 28,
        "unique-2": 25,
        "entropy-2": 4.66791394400062,
        "cond_entropy-2": 0.44318644182516864,
        "distinct-3": 0.8787878787878788,
        "vocab_size-3": 29,
        "unique-3": 27,
        "entropy-3": 4.756219119227336,
        "cond_entropy-3": 0.10101877817367375,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.132944044980957,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.453660689688184,
        "cond_entropy-2-nopunct": 0.3434164716336324,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.13922662353657628,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5927475049462854,
        "rouge1": {
            "precision": 0.84,
            "recall": 0.77778,
            "fmeasure": 0.80769
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.55556,
            "fmeasure": 0.57692
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.55556,
            "fmeasure": 0.57692
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 11.75574,
        "nubia": {
            "semantic_relation": 2.78624,
            "contradiction": 83.96186,
            "irrelevancy": 5.15758,
            "logical_agreement": 10.88056,
            "grammar_ref": 4.95946,
            "grammar_hyp": 4.99523,
            "nubia_score": 0.42853
        },
        "meteor": 0.2892460913210024,
        "bleurt": -0.37297,
        "bertscore": {
            "precision": 0.89139,
            "recall": 0.89244,
            "f1": 0.89191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.315824333525707,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.21785611591339746,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.1757358691004915,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.2497078476741285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.009399886704119,
        "rouge1": {
            "precision": 0.7549,
            "recall": 0.59615,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.39744,
            "fmeasure": 0.43957
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.55769,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.55769,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3333333333333333,
            "3": 0.6190476190476191
        },
        "bleu": 32.37936,
        "nubia": {
            "semantic_relation": 3.12847,
            "contradiction": 50.10101,
            "irrelevancy": 0.31126,
            "logical_agreement": 49.58772,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.71177,
            "nubia_score": 0.53956
        },
        "meteor": 0.3339236534170983,
        "bleurt": -0.2282,
        "bertscore": {
            "precision": 0.89126,
            "recall": 0.85719,
            "f1": 0.87291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.4893514498647592,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.37778,
            "fmeasure": 0.48148
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1369,
            "fmeasure": 0.17677
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.30065,
            "fmeasure": 0.38034
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.30065,
            "fmeasure": 0.38034
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.38461538461538464
        },
        "bleu": 6.77869,
        "nubia": {
            "semantic_relation": 3.25574,
            "contradiction": 2.0338,
            "irrelevancy": 59.70891,
            "logical_agreement": 38.25728,
            "grammar_ref": 4.4151,
            "grammar_hyp": 6.54173,
            "nubia_score": 0.23307
        },
        "meteor": 0.1726966706820555,
        "bleurt": -0.6707,
        "bertscore": {
            "precision": 0.84589,
            "recall": 0.80768,
            "f1": 0.82544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 18,
        "unique-1": 10,
        "entropy-1": 4.060262039120378,
        "distinct-2": 0.7307692307692307,
        "vocab_size-2": 19,
        "unique-2": 12,
        "entropy-2": 4.161978179679553,
        "cond_entropy-2": 0.06747240834078934,
        "distinct-3": 0.76,
        "vocab_size-3": 19,
        "unique-3": 13,
        "entropy-3": 4.163856189774723,
        "cond_entropy-3": 0.023416471633632495,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.7216117239699007,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": -0.0224469564457176,
        "distinct-3-nopunct": 0.8235294117647058,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.734521664779752,
        "cond_entropy-3-nopunct": -0.023638630780208267,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0603645129234236,
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.40191,
            "fmeasure": 0.41078
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.11547,
            "fmeasure": 0.11323
        },
        "rougeL": {
            "precision": 0.21053,
            "recall": 0.21832,
            "fmeasure": 0.21432
        },
        "rougeLsum": {
            "precision": 0.21053,
            "recall": 0.21832,
            "fmeasure": 0.21432
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4375
        },
        "bleu": 5.83273,
        "nubia": {
            "semantic_relation": 3.18825,
            "contradiction": 95.22357,
            "irrelevancy": 3.38036,
            "logical_agreement": 1.39607,
            "grammar_ref": 4.78465,
            "grammar_hyp": 4.52785,
            "nubia_score": 0.41521
        },
        "meteor": 0.17497581339707385,
        "bleurt": -0.18465,
        "bertscore": {
            "precision": 0.85862,
            "recall": 0.85053,
            "f1": 0.85335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.262496476250065,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.3300749985576876,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.017269886490594,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.60513,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.32143,
            "fmeasure": 0.40303
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.57949,
            "fmeasure": 0.71212
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.57949,
            "fmeasure": 0.71212
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 21.00291,
        "nubia": {
            "semantic_relation": 4.78801,
            "contradiction": 0.3674,
            "irrelevancy": 0.49787,
            "logical_agreement": 99.13473,
            "grammar_ref": 4.20051,
            "grammar_hyp": 5.4498,
            "nubia_score": 0.81941
        },
        "meteor": 0.3303062632324884,
        "bleurt": 0.35395,
        "bertscore": {
            "precision": 0.95654,
            "recall": 0.91125,
            "f1": 0.93245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6865810299389701,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.76282,
            "fmeasure": 0.80556
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.49206,
            "fmeasure": 0.5213
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.73718,
            "fmeasure": 0.77381
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.73718,
            "fmeasure": 0.77381
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "bleu": 37.15012,
        "nubia": {
            "semantic_relation": 3.58078,
            "contradiction": 0.25408,
            "irrelevancy": 0.48782,
            "logical_agreement": 99.25811,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.761,
            "nubia_score": 0.55451
        },
        "meteor": 0.45385927170199863,
        "bleurt": 0.20762,
        "bertscore": {
            "precision": 0.9663,
            "recall": 0.96118,
            "f1": 0.96373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.23825690928867382,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.35294,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.25,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.35294,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.35294,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 21.74757,
        "nubia": {
            "semantic_relation": 3.39225,
            "contradiction": 2.39751,
            "irrelevancy": 1.854,
            "logical_agreement": 95.74849,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.5538,
            "nubia_score": 0.39976
        },
        "meteor": 0.23142070240716414,
        "bleurt": -0.28451,
        "bertscore": {
            "precision": 0.90688,
            "recall": 0.79121,
            "f1": 0.84178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.199430449946261,
        "rouge1": {
            "precision": 0.90741,
            "recall": 0.76944,
            "fmeasure": 0.83124
        },
        "rouge2": {
            "precision": 0.58824,
            "recall": 0.4958,
            "fmeasure": 0.53704
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.56667,
            "fmeasure": 0.55005
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.56667,
            "fmeasure": 0.55005
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "bleu": 51.01365,
        "nubia": {
            "semantic_relation": 3.98754,
            "contradiction": 78.9885,
            "irrelevancy": 17.67447,
            "logical_agreement": 3.33703,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.29336,
            "nubia_score": 0.65714
        },
        "meteor": 0.4142154030452011,
        "bleurt": -0.17819,
        "bertscore": {
            "precision": 0.91115,
            "recall": 0.89552,
            "f1": 0.90233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0909514646162273,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.3125,
            "fmeasure": 0.40724
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "bleu": 31.85036,
        "nubia": {
            "semantic_relation": 3.4502,
            "contradiction": 1.65058,
            "irrelevancy": 0.74865,
            "logical_agreement": 97.60076,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.46862,
            "nubia_score": 0.42783
        },
        "meteor": 0.3769465296142278,
        "bleurt": 0.09535,
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.89087,
            "f1": 0.91786
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4426432198282866,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80556,
            "fmeasure": 0.86141
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71667,
            "fmeasure": 0.76741
        },
        "rougeL": {
            "precision": 0.84444,
            "recall": 0.74206,
            "fmeasure": 0.78734
        },
        "rougeLsum": {
            "precision": 0.84444,
            "recall": 0.74206,
            "fmeasure": 0.78734
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "bleu": 44.80304,
        "nubia": {
            "semantic_relation": 4.17861,
            "contradiction": 0.23785,
            "irrelevancy": 33.61478,
            "logical_agreement": 66.14737,
            "grammar_ref": 3.89472,
            "grammar_hyp": 5.36987,
            "nubia_score": 0.58929
        },
        "meteor": 0.4622283698410643,
        "bleurt": -0.04473,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.94405,
            "f1": 0.93772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.7256507561120933,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548847,
        "cond_entropy-2": 0.3819258801385093,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.0428176133697167,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.6163485660751635,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.3689470925126362,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.04723891230848748,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1786464124224905,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.60417,
            "fmeasure": 0.68444
        },
        "rouge2": {
            "precision": 0.58144,
            "recall": 0.40963,
            "fmeasure": 0.46785
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.60417,
            "fmeasure": 0.68444
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.60417,
            "fmeasure": 0.68444
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "bleu": 22.8812,
        "nubia": {
            "semantic_relation": 4.81142,
            "contradiction": 0.75542,
            "irrelevancy": 2.29182,
            "logical_agreement": 96.95276,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.44616,
            "nubia_score": 0.93012
        },
        "meteor": 0.36167763258719443,
        "bleurt": 0.46943,
        "bertscore": {
            "precision": 0.94652,
            "recall": 0.89891,
            "f1": 0.92162
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7015593220636813,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.72222,
            "fmeasure": 0.73529
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.27381,
            "fmeasure": 0.27937
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.39167,
            "fmeasure": 0.4213
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.39167,
            "fmeasure": 0.4213
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bleu": 13.46238,
        "nubia": {
            "semantic_relation": 4.22494,
            "contradiction": 0.40657,
            "irrelevancy": 0.57096,
            "logical_agreement": 99.02248,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.36921,
            "nubia_score": 0.73728
        },
        "meteor": 0.3368655301618297,
        "bleurt": 0.14096,
        "bertscore": {
            "precision": 0.89943,
            "recall": 0.89057,
            "f1": 0.89498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.02810710212234294,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.012481468287395,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.65741,
            "fmeasure": 0.58124
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.42029,
            "fmeasure": 0.36508
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.4537,
            "fmeasure": 0.39512
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.4537,
            "fmeasure": 0.39512
        },
        "local_recall": {
            "1": 0.8,
            "2": 0.0,
            "3": 0.75
        },
        "bleu": 37.91621,
        "nubia": {
            "semantic_relation": 3.72427,
            "contradiction": 0.48071,
            "irrelevancy": 65.24092,
            "logical_agreement": 34.27837,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.4011,
            "nubia_score": 0.5859
        },
        "meteor": 0.3512276926634747,
        "bleurt": -0.34479,
        "bertscore": {
            "precision": 0.8968,
            "recall": 0.8407,
            "f1": 0.83492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.53125,
        "vocab_size-1": 17,
        "unique-1": 9,
        "entropy-1": 3.8514097655573916,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 22,
        "unique-2": 18,
        "entropy-2": 4.240223928941852,
        "cond_entropy-2": 0.39872017901396756,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 20,
        "entropy-3": 4.378783493486177,
        "cond_entropy-3": 0.18617861216337134,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.56610893983748,
        "distinct-2-nopunct": 0.6923076923076923,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.9312089489103217,
        "cond_entropy-2-nopunct": 0.34519585385900586,
        "distinct-3-nopunct": 0.7916666666666666,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.084962500721157,
        "cond_entropy-3-nopunct": 0.13452278258006412,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7590715480028294,
        "rouge1": {
            "precision": 0.5963,
            "recall": 0.76008,
            "fmeasure": 0.66005
        },
        "rouge2": {
            "precision": 0.45425,
            "recall": 0.60277,
            "fmeasure": 0.50641
        },
        "rougeL": {
            "precision": 0.54074,
            "recall": 0.70343,
            "fmeasure": 0.60397
        },
        "rougeLsum": {
            "precision": 0.54074,
            "recall": 0.70343,
            "fmeasure": 0.60397
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.6842105263157895
        },
        "bleu": 20.42362,
        "nubia": {
            "semantic_relation": 4.10768,
            "contradiction": 1.00867,
            "irrelevancy": 22.53451,
            "logical_agreement": 76.45682,
            "grammar_ref": 6.00658,
            "grammar_hyp": 5.28251,
            "nubia_score": 0.73306
        },
        "meteor": 0.3513651346539527,
        "bleurt": -0.01314,
        "bertscore": {
            "precision": 0.91076,
            "recall": 0.89193,
            "f1": 0.89949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 49,
        "mean_pred_length": 24.5,
        "std_pred_length": 4.5,
        "median_pred_length": 24.5,
        "min_pred_length": 20,
        "max_pred_length": 29,
        "distinct-1": 0.6530612244897959,
        "vocab_size-1": 32,
        "unique-1": 20,
        "entropy-1": 4.843802956139344,
        "distinct-2": 0.8936170212765957,
        "vocab_size-2": 42,
        "unique-2": 37,
        "entropy-2": 5.34182289423083,
        "cond_entropy-2": 0.4882712950266277,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 44,
        "unique-3": 43,
        "entropy-3": 5.447408651885229,
        "cond_entropy-3": 0.07059757798537059,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.665311532225103,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.142664355548852,
        "cond_entropy-2-nopunct": 0.4855958003059707,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": 0.03310859910983796,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.770198622421077,
        "rouge1": {
            "precision": 0.52165,
            "recall": 0.61324,
            "fmeasure": 0.54752
        },
        "rouge2": {
            "precision": 0.20879,
            "recall": 0.26913,
            "fmeasure": 0.22619
        },
        "rougeL": {
            "precision": 0.35008,
            "recall": 0.52393,
            "fmeasure": 0.40397
        },
        "rougeLsum": {
            "precision": 0.35008,
            "recall": 0.52393,
            "fmeasure": 0.40397
        },
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.6,
            "3": 0.5217391304347826
        },
        "bleu": 19.56371,
        "nubia": {
            "semantic_relation": 4.39503,
            "contradiction": 33.42576,
            "irrelevancy": 66.25399,
            "logical_agreement": 0.32025,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.4607,
            "nubia_score": 0.83115
        },
        "meteor": 0.31439748608841545,
        "bleurt": 0.29894,
        "bertscore": {
            "precision": 0.8734,
            "recall": 0.90913,
            "f1": 0.88537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.8,
        "vocab_size-1": 28,
        "unique-1": 24,
        "entropy-1": 4.626150431961055,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.4761104264946906,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.043068721891885896,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 29.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.651084443403434,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.16365964121574644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.05246741989413545,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.0172343994556154,
        "rouge1": {
            "precision": 0.98851,
            "recall": 0.88693,
            "fmeasure": 0.93477
        },
        "rouge2": {
            "precision": 0.94048,
            "recall": 0.83132,
            "fmeasure": 0.88249
        },
        "rougeL": {
            "precision": 0.98851,
            "recall": 0.87753,
            "fmeasure": 0.92967
        },
        "rougeLsum": {
            "precision": 0.98851,
            "recall": 0.87753,
            "fmeasure": 0.92967
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bleu": 69.48985,
        "nubia": {
            "semantic_relation": 3.80657,
            "contradiction": 0.13084,
            "irrelevancy": 0.64339,
            "logical_agreement": 99.22578,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.39342,
            "nubia_score": 0.70564
        },
        "meteor": 0.4936694726824888,
        "bleurt": 0.5876,
        "bertscore": {
            "precision": 0.99308,
            "recall": 0.96668,
            "f1": 0.9797
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.451815875634701,
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "bleu": 69.05636,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "meteor": 0.9489775258149422,
        "bleurt": 0.78257,
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8015020510845376,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.64394,
            "fmeasure": 0.73781
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.36797,
            "fmeasure": 0.41475
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.42803,
            "fmeasure": 0.48617
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.42803,
            "fmeasure": 0.48617
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.875
        },
        "bleu": 50.48006,
        "nubia": {
            "semantic_relation": 3.74564,
            "contradiction": 0.67737,
            "irrelevancy": 51.58465,
            "logical_agreement": 47.73799,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.05482,
            "nubia_score": 0.51396
        },
        "meteor": 0.4535606800758789,
        "bleurt": 0.04878,
        "bertscore": {
            "precision": 0.94882,
            "recall": 0.95324,
            "f1": 0.95102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9835135346342163,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.61111,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.21481,
            "fmeasure": 0.19577
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.44444,
            "fmeasure": 0.35526
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.44444,
            "fmeasure": 0.35526
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6
        },
        "bleu": 11.73118,
        "nubia": {
            "semantic_relation": 2.63542,
            "contradiction": 5.12658,
            "irrelevancy": 94.58687,
            "logical_agreement": 0.28654,
            "grammar_ref": 7.45181,
            "grammar_hyp": 6.419,
            "nubia_score": 0.26139
        },
        "meteor": 0.3116464419000416,
        "bleurt": -0.98811,
        "bertscore": {
            "precision": 0.8015,
            "recall": 0.81944,
            "f1": 0.81004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5138039015607525,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.89167,
            "fmeasure": 0.85926
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.51323,
            "fmeasure": 0.49537
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.625
        },
        "bleu": 24.38418,
        "nubia": {
            "semantic_relation": 4.84068,
            "contradiction": 1.00439,
            "irrelevancy": 54.96337,
            "logical_agreement": 44.03224,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.79844,
            "nubia_score": 1.0
        },
        "meteor": 0.4293370916987086,
        "bleurt": 0.47101,
        "bertscore": {
            "precision": 0.97051,
            "recall": 0.92756,
            "f1": 0.94855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2933477144856607,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.56667,
            "fmeasure": 0.61153
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.31313,
            "fmeasure": 0.34056
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.56667,
            "fmeasure": 0.61153
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.56667,
            "fmeasure": 0.61153
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.36363636363636365,
            "3": 1.0
        },
        "bleu": 19.14916,
        "nubia": {
            "semantic_relation": 3.59716,
            "contradiction": 13.13104,
            "irrelevancy": 33.16974,
            "logical_agreement": 53.69922,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.54921,
            "nubia_score": 0.39613
        },
        "meteor": 0.31574599835095557,
        "bleurt": 0.22654,
        "bertscore": {
            "precision": 0.92509,
            "recall": 0.87933,
            "f1": 0.90163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774723,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 21,
        "unique-2": 19,
        "entropy-2": 4.349648912578752,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.036006438040157185,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.1757358691004915,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.201841232302569,
        "cond_entropy-2-nopunct": 0.05923165719793805,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548846,
        "cond_entropy-3-nopunct": -0.0391267514404381,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.338296450579125,
        "rouge1": {
            "precision": 0.98718,
            "recall": 0.79412,
            "fmeasure": 0.8637
        },
        "rouge2": {
            "precision": 0.81944,
            "recall": 0.6875,
            "fmeasure": 0.73275
        },
        "rougeL": {
            "precision": 0.98718,
            "recall": 0.79412,
            "fmeasure": 0.8637
        },
        "rougeLsum": {
            "precision": 0.98718,
            "recall": 0.79412,
            "fmeasure": 0.8637
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.7391304347826086
        },
        "bleu": 62.01485,
        "nubia": {
            "semantic_relation": 4.31261,
            "contradiction": 0.24714,
            "irrelevancy": 32.84145,
            "logical_agreement": 66.91141,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.98597,
            "nubia_score": 0.83592
        },
        "meteor": 0.47418775167350796,
        "bleurt": 0.35211,
        "bertscore": {
            "precision": 0.98838,
            "recall": 0.94709,
            "f1": 0.96683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.386842188131012,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.1453336945603553,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.243300368538955,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.15930901853019974,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.91686310792718,
        "rouge1": {
            "precision": 0.50725,
            "recall": 0.74444,
            "fmeasure": 0.60324
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.37778,
            "fmeasure": 0.31622
        },
        "rougeL": {
            "precision": 0.44928,
            "recall": 0.63743,
            "fmeasure": 0.52548
        },
        "rougeLsum": {
            "precision": 0.44928,
            "recall": 0.63743,
            "fmeasure": 0.52548
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "bleu": 21.91286,
        "nubia": {
            "semantic_relation": 3.86841,
            "contradiction": 0.52981,
            "irrelevancy": 39.411,
            "logical_agreement": 60.05919,
            "grammar_ref": 5.46955,
            "grammar_hyp": 3.65828,
            "nubia_score": 0.79335
        },
        "meteor": 0.3352388821623225,
        "bleurt": 0.19157,
        "bertscore": {
            "precision": 0.88321,
            "recall": 0.88054,
            "f1": 0.87457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.5,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.6190476190476191,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.5225715891363594,
        "distinct-2": 0.7894736842105263,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.787143960698138,
        "cond_entropy-2": 0.2508614066820324,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 15,
        "unique-3": 13,
        "entropy-3": 3.8521687236032816,
        "cond_entropy-3": 0.11923459263989908,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6111111111111112,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.266332639970623,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.452819531114783,
        "cond_entropy-2-nopunct": 0.20037578003304896,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": 0.07556117221213765,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2231407849274794,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.71717,
            "fmeasure": 0.71542
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "bleu": 60.53095,
        "nubia": {
            "semantic_relation": 4.78034,
            "contradiction": 2.32657,
            "irrelevancy": 4.78386,
            "logical_agreement": 92.88957,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.28568,
            "nubia_score": 0.83025
        },
        "meteor": 0.49581907213344034,
        "bleurt": 0.72636,
        "bertscore": {
            "precision": 0.96991,
            "recall": 0.97293,
            "f1": 0.97141
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.5746987351738495,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.32870084182032044,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": 0.01936095188830983,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.02341647163363251,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3108907790670914,
        "rouge1": {
            "precision": 0.65432,
            "recall": 0.5954,
            "fmeasure": 0.62343
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.42365,
            "fmeasure": 0.44175
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.54559,
            "fmeasure": 0.56809
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.54559,
            "fmeasure": 0.56809
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.4,
            "3": 0.75
        },
        "bleu": 38.61527,
        "nubia": {
            "semantic_relation": 2.69357,
            "contradiction": 2.02874,
            "irrelevancy": 35.29988,
            "logical_agreement": 62.67138,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.08178,
            "nubia_score": 0.49445
        },
        "meteor": 0.3416461791466232,
        "bleurt": -0.39653,
        "bertscore": {
            "precision": 0.88182,
            "recall": 0.84868,
            "f1": 0.86493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8535769082186824,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bleu": 76.74162,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "meteor": 0.5426177315437225,
        "bleurt": 0.39021,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5622829933062867,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.55686,
            "fmeasure": 0.65201
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.34226,
            "fmeasure": 0.40598
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.55686,
            "fmeasure": 0.65201
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.55686,
            "fmeasure": 0.65201
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "bleu": 20.90152,
        "nubia": {
            "semantic_relation": 3.67875,
            "contradiction": 0.45191,
            "irrelevancy": 4.90836,
            "logical_agreement": 94.63973,
            "grammar_ref": 4.68072,
            "grammar_hyp": 4.869,
            "nubia_score": 0.55786
        },
        "meteor": 0.2848351822332963,
        "bleurt": -0.14348,
        "bertscore": {
            "precision": 0.91964,
            "recall": 0.8235,
            "f1": 0.86809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.017574998557687627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2334623442314507,
        "rouge1": {
            "precision": 0.6625,
            "recall": 0.63333,
            "fmeasure": 0.63657
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.31481,
            "fmeasure": 0.35417
        },
        "rougeL": {
            "precision": 0.62917,
            "recall": 0.63333,
            "fmeasure": 0.61343
        },
        "rougeLsum": {
            "precision": 0.62917,
            "recall": 0.63333,
            "fmeasure": 0.61343
        },
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.6666666666666666
        },
        "bleu": 34.9524,
        "nubia": {
            "semantic_relation": 3.66537,
            "contradiction": 0.51179,
            "irrelevancy": 50.12658,
            "logical_agreement": 49.36163,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.89176,
            "nubia_score": 0.53163
        },
        "meteor": 0.33209941739675014,
        "bleurt": 0.10551,
        "bertscore": {
            "precision": 0.90964,
            "recall": 0.90429,
            "f1": 0.90689
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0881978509745025,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bleu": 68.94026,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268,
        "bleurt": 0.64449,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.04281761336971669,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.04723891230848747,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4812433175017645,
        "rouge1": {
            "precision": 0.6375,
            "recall": 0.48504,
            "fmeasure": 0.53881
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.26549,
            "fmeasure": 0.3176
        },
        "rougeL": {
            "precision": 0.5875,
            "recall": 0.42949,
            "fmeasure": 0.48618
        },
        "rougeLsum": {
            "precision": 0.5875,
            "recall": 0.42949,
            "fmeasure": 0.48618
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "bleu": 26.44193,
        "nubia": {
            "semantic_relation": 3.66444,
            "contradiction": 0.65571,
            "irrelevancy": 35.35306,
            "logical_agreement": 63.99123,
            "grammar_ref": 5.01983,
            "grammar_hyp": 5.39419,
            "nubia_score": 0.49807
        },
        "meteor": 0.2778512859355548,
        "bleurt": 0.20901,
        "bertscore": {
            "precision": 0.92439,
            "recall": 0.90376,
            "f1": 0.91342
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.290684382655964,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.51282,
            "fmeasure": 0.56762
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bleu": 50.69803,
        "nubia": {
            "semantic_relation": 3.73265,
            "contradiction": 11.45659,
            "irrelevancy": 67.96269,
            "logical_agreement": 20.58072,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.22389,
            "nubia_score": 0.5958
        },
        "meteor": 0.3830169194522598,
        "bleurt": 0.03235,
        "bertscore": {
            "precision": 0.94285,
            "recall": 0.89457,
            "f1": 0.90548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.867976246918685,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0,
        "bleurt": 0.73788,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3471155155881471,
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.47222,
            "fmeasure": 0.42319
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.10438,
            "fmeasure": 0.09248
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.37778,
            "fmeasure": 0.33855
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.37778,
            "fmeasure": 0.33855
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bleu": 4.61922,
        "nubia": {
            "semantic_relation": 3.21031,
            "contradiction": 0.14519,
            "irrelevancy": 99.7586,
            "logical_agreement": 0.09621,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.68132,
            "nubia_score": 0.391
        },
        "meteor": 0.22827190578125076,
        "bleurt": -0.14508,
        "bertscore": {
            "precision": 0.81967,
            "recall": 0.8252,
            "f1": 0.82242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518523,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.20077710377579552,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0848474523384635,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47857,
            "fmeasure": 0.48892
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.21703,
            "fmeasure": 0.22365
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.34048,
            "fmeasure": 0.34852
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.34048,
            "fmeasure": 0.34852
        },
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "bleu": 33.15796,
        "nubia": {
            "semantic_relation": 4.12277,
            "contradiction": 85.02813,
            "irrelevancy": 12.39056,
            "logical_agreement": 2.58131,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.65134,
            "nubia_score": 0.65997
        },
        "meteor": 0.34675109852855823,
        "bleurt": 0.22186,
        "bertscore": {
            "precision": 0.89794,
            "recall": 0.89785,
            "f1": 0.89789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.16916029185586146,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.41806,
            "fmeasure": 0.57234
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.26182,
            "fmeasure": 0.36429
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.38095238095238093
        },
        "bleu": 13.53478,
        "nubia": {
            "semantic_relation": 3.59355,
            "contradiction": 0.11709,
            "irrelevancy": 0.85004,
            "logical_agreement": 99.03287,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.27801,
            "nubia_score": 0.65524
        },
        "meteor": 0.2726771323971795,
        "bleurt": 0.12432,
        "bertscore": {
            "precision": 0.94312,
            "recall": 0.76732,
            "f1": 0.8459
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8076083232145888,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.375,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "bleu": 26.68078,
        "nubia": {
            "semantic_relation": 3.20989,
            "contradiction": 0.14667,
            "irrelevancy": 97.50456,
            "logical_agreement": 2.34876,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.81037,
            "nubia_score": 0.48508
        },
        "meteor": 0.22905788893451226,
        "bleurt": -0.51516,
        "bertscore": {
            "precision": 0.87049,
            "recall": 0.795,
            "f1": 0.83103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.68,
        "vocab_size-1": 17,
        "unique-1": 9,
        "entropy-1": 4.003856189774724,
        "distinct-2": 0.7916666666666666,
        "vocab_size-2": 19,
        "unique-2": 14,
        "entropy-2": 4.16829583405449,
        "cond_entropy-2": 0.19110631094643168,
        "distinct-3": 0.8695652173913043,
        "vocab_size-3": 20,
        "unique-3": 17,
        "entropy-3": 4.2626923908396215,
        "cond_entropy-3": 0.1125124988141176,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.82790978214397,
        "distinct-2-nopunct": 0.7727272727272727,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.004886164091841,
        "cond_entropy-2-nopunct": 0.16314238985301172,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.106603137064473,
        "cond_entropy-3-nopunct": 0.12336199461765371,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.057615545849043,
        "rouge1": {
            "precision": 0.60215,
            "recall": 0.82345,
            "fmeasure": 0.69555
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.51748,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.35484,
            "recall": 0.45464,
            "fmeasure": 0.39804
        },
        "rougeLsum": {
            "precision": 0.35484,
            "recall": 0.45464,
            "fmeasure": 0.39804
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bleu": 36.02421,
        "nubia": {
            "semantic_relation": 3.41501,
            "contradiction": 5.00889,
            "irrelevancy": 67.8808,
            "logical_agreement": 27.11032,
            "grammar_ref": 3.13705,
            "grammar_hyp": 2.4387,
            "nubia_score": 0.67319
        },
        "meteor": 0.37653715977757884,
        "bleurt": -0.04602,
        "bertscore": {
            "precision": 0.89065,
            "recall": 0.92137,
            "f1": 0.90376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.601606249704982,
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.66667,
            "fmeasure": 0.63492
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.12037,
            "fmeasure": 0.10916
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.58519,
            "fmeasure": 0.54762
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.58519,
            "fmeasure": 0.54762
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.5714285714285714
        },
        "bleu": 9.57846,
        "nubia": {
            "semantic_relation": 4.6245,
            "contradiction": 0.21348,
            "irrelevancy": 18.97202,
            "logical_agreement": 80.81449,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.52076,
            "nubia_score": 0.93765
        },
        "meteor": 0.2765864332603939,
        "bleurt": 0.56023,
        "bertscore": {
            "precision": 0.88544,
            "recall": 0.89107,
            "f1": 0.88825
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 5407,
        "mean_pred_length": 15.061281337047355,
        "std_pred_length": 7.083790553712874,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 59,
        "distinct-1": 0.47179582023303124,
        "vocab_size-1": 2551,
        "unique-1": 2139,
        "entropy-1": 9.352033311981701,
        "distinct-2": 0.8965927099841522,
        "vocab_size-2": 4526,
        "unique-2": 4320,
        "entropy-2": 11.956751249288907,
        "cond_entropy-2": 2.213692752688185,
        "distinct-3": 0.980806142034549,
        "vocab_size-3": 4599,
        "unique-3": 4551,
        "entropy-3": 12.140551800688407,
        "cond_entropy-3": 0.2019932999858134,
        "total_length-nopunct": 4818,
        "mean_pred_length-nopunct": 13.420612813370473,
        "std_pred_length-nopunct": 6.279800811467042,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5273972602739726,
        "vocab_size-1-nopunct": 2541,
        "unique-1-nopunct": 2137,
        "entropy-1-nopunct": 9.75249379491385,
        "distinct-2-nopunct": 0.9060327427674366,
        "vocab_size-2-nopunct": 4040,
        "unique-2-nopunct": 3877,
        "entropy-2-nopunct": 11.80498900188289,
        "cond_entropy-2-nopunct": 2.2159210825578985,
        "distinct-3-nopunct": 0.988780487804878,
        "vocab_size-3-nopunct": 4054,
        "unique-3-nopunct": 4022,
        "entropy-3-nopunct": 11.975824327810438,
        "cond_entropy-3-nopunct": 0.19528244073036438,
        "msttr-100": 0.75259,
        "msttr-100_nopunct": 0.80521,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "nist": 7.041111514198446,
        "rouge1": {
            "precision": 0.66122,
            "recall": 0.56611,
            "fmeasure": 0.59352
        },
        "rouge2": {
            "precision": 0.42897,
            "recall": 0.36213,
            "fmeasure": 0.37697
        },
        "rougeL": {
            "precision": 0.62876,
            "recall": 0.54257,
            "fmeasure": 0.5657
        },
        "rougeLsum": {
            "precision": 0.62876,
            "recall": 0.54257,
            "fmeasure": 0.5657
        },
        "local_recall": {
            "1": 0.03207729468599034,
            "2": 0.10989010989010989,
            "3": 0.1981242672919109,
            "4": 0.2762039660056657,
            "5": 0.32669322709163345,
            "6": 0.3916256157635468,
            "7": 0.4920091324200913,
            "8": 0.558531746031746,
            "9": 0.6654676258992805
        },
        "bleu": 37.11316,
        "sari": 42.20432,
        "nubia": {
            "semantic_relation": 3.41342,
            "contradiction": 8.21703,
            "irrelevancy": 24.55144,
            "logical_agreement": 67.23153,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.74593,
            "nubia_score": 0.34036
        },
        "meteor": 0.2812571017773859,
        "bleurt": -0.86718,
        "bertscore": {
            "precision": 0.85554,
            "recall": 0.87455,
            "f1": 0.86033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.425622163887878,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "bleu": 51.15078,
        "nubia": {
            "semantic_relation": 4.03933,
            "contradiction": 14.76512,
            "irrelevancy": 1.30136,
            "logical_agreement": 83.93352,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.12865,
            "nubia_score": 0.54196
        },
        "meteor": 0.42750933026297866,
        "bleurt": 0.50807,
        "bertscore": {
            "precision": 0.99151,
            "recall": 0.95959,
            "f1": 0.97529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 17,
        "mean_pred_length": 8.5,
        "std_pred_length": 0.5,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 9,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.0472389123084875,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.2064508774674265,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 7.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.05260472362127269,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.24100809950379498,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6726192839443913,
        "rouge1": {
            "precision": 0.72917,
            "recall": 0.50606,
            "fmeasure": 0.59419
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.38632,
            "fmeasure": 0.45098
        },
        "rougeL": {
            "precision": 0.72917,
            "recall": 0.50606,
            "fmeasure": 0.59419
        },
        "rougeLsum": {
            "precision": 0.72917,
            "recall": 0.50606,
            "fmeasure": 0.59419
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "bleu": 12.95447,
        "nubia": {
            "semantic_relation": 3.9568,
            "contradiction": 10.55164,
            "irrelevancy": 10.35372,
            "logical_agreement": 79.09464,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.79714,
            "nubia_score": 0.58505
        },
        "meteor": 0.26978441677006393,
        "bleurt": 0.00991,
        "bertscore": {
            "precision": 0.91876,
            "recall": 0.84443,
            "f1": 0.87907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 14,
        "entropy-1": 4.133660689688185,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.3473095707241781,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8801799226757367,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.42165680130500777,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.025875816557868653,
        "rouge1": {
            "precision": 0.51389,
            "recall": 0.22984,
            "fmeasure": 0.30952
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.0575,
            "fmeasure": 0.08727
        },
        "rougeL": {
            "precision": 0.27778,
            "recall": 0.12328,
            "fmeasure": 0.1653
        },
        "rougeLsum": {
            "precision": 0.27778,
            "recall": 0.12328,
            "fmeasure": 0.1653
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.125,
            "3": 0.20588235294117646
        },
        "bleu": 1.26537,
        "nubia": {
            "semantic_relation": 1.97165,
            "contradiction": 50.17642,
            "irrelevancy": 1.69562,
            "logical_agreement": 48.12796,
            "grammar_ref": 3.44707,
            "grammar_hyp": 4.43291,
            "nubia_score": 0.14938
        },
        "meteor": 0.12115175553151988,
        "bleurt": -0.75948,
        "bertscore": {
            "precision": 0.86478,
            "recall": 0.79709,
            "f1": 0.82312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.52164063634332,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.032143884086602556,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.334962500721156,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.05628729973432274,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.154554319133346,
        "rouge1": {
            "precision": 0.81352,
            "recall": 0.53175,
            "fmeasure": 0.63861
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.26478,
            "fmeasure": 0.33028
        },
        "rougeL": {
            "precision": 0.59441,
            "recall": 0.39524,
            "fmeasure": 0.47185
        },
        "rougeLsum": {
            "precision": 0.59441,
            "recall": 0.39524,
            "fmeasure": 0.47185
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 0.5333333333333333
        },
        "bleu": 16.10412,
        "nubia": {
            "semantic_relation": 3.94144,
            "contradiction": 10.71393,
            "irrelevancy": 46.13081,
            "logical_agreement": 43.15526,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.43305,
            "nubia_score": 0.59435
        },
        "meteor": 0.2564971443433345,
        "bleurt": -0.15221,
        "bertscore": {
            "precision": 0.91825,
            "recall": 0.85121,
            "f1": 0.88328
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.289797400827294,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.03846,
            "fmeasure": 0.04167
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.2727272727272727
        },
        "bleu": 6.58199,
        "nubia": {
            "semantic_relation": 3.68723,
            "contradiction": 0.20292,
            "irrelevancy": 51.69562,
            "logical_agreement": 48.10146,
            "grammar_ref": 5.03823,
            "grammar_hyp": 3.43689,
            "nubia_score": 0.79292
        },
        "meteor": 0.19460615860168817,
        "bleurt": 0.01855,
        "bertscore": {
            "precision": 0.84134,
            "recall": 0.78849,
            "f1": 0.81406
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8101521400462466,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.59074,
            "fmeasure": 0.67402
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.30857,
            "fmeasure": 0.36111
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.42963,
            "fmeasure": 0.4902
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.42963,
            "fmeasure": 0.4902
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5384615384615384
        },
        "bleu": 15.77755,
        "nubia": {
            "semantic_relation": 3.66751,
            "contradiction": 31.58767,
            "irrelevancy": 51.72853,
            "logical_agreement": 16.68379,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.86482,
            "nubia_score": 0.44529
        },
        "meteor": 0.28143464487440667,
        "bleurt": -0.1319,
        "bertscore": {
            "precision": 0.9045,
            "recall": 0.8539,
            "f1": 0.87364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.3684210526315789,
        "vocab_size-1": 14,
        "unique-1": 3,
        "entropy-1": 3.5954541576680272,
        "distinct-2": 0.5142857142857142,
        "vocab_size-2": 18,
        "unique-2": 10,
        "entropy-2": 3.8925912307979864,
        "cond_entropy-2": 0.3029237178489085,
        "distinct-3": 0.65625,
        "vocab_size-3": 21,
        "unique-3": 15,
        "entropy-3": 4.194548827786958,
        "cond_entropy-3": 0.2693072174976419,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.3548387096774194,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 3.210999535635012,
        "distinct-2-nopunct": 0.5357142857142857,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.574164743022575,
        "cond_entropy-2-nopunct": 0.3801188796051384,
        "distinct-3-nopunct": 0.68,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.8830741894285685,
        "cond_entropy-3-nopunct": 0.2666967678036592,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3596845607224277,
        "rouge1": {
            "precision": 0.93939,
            "recall": 0.73737,
            "fmeasure": 0.81374
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.63525,
            "fmeasure": 0.69793
        },
        "rougeL": {
            "precision": 0.93939,
            "recall": 0.73737,
            "fmeasure": 0.81374
        },
        "rougeLsum": {
            "precision": 0.93939,
            "recall": 0.73737,
            "fmeasure": 0.81374
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7222222222222222
        },
        "bleu": 55.63038,
        "nubia": {
            "semantic_relation": 4.12099,
            "contradiction": 32.62734,
            "irrelevancy": 1.11331,
            "logical_agreement": 66.25934,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.44259,
            "nubia_score": 0.70802
        },
        "meteor": 0.4193942401971592,
        "bleurt": 0.64363,
        "bertscore": {
            "precision": 0.98066,
            "recall": 0.93218,
            "f1": 0.9553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3596620301993743,
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.43266,
            "fmeasure": 0.51551
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.29464,
            "fmeasure": 0.36147
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.34641,
            "fmeasure": 0.3957
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.34641,
            "fmeasure": 0.3957
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.5555555555555556
        },
        "bleu": 29.11164,
        "nubia": {
            "semantic_relation": 3.09851,
            "contradiction": 35.81617,
            "irrelevancy": 5.51525,
            "logical_agreement": 58.66857,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.39805,
            "nubia_score": 0.36884
        },
        "meteor": 0.22882379019033555,
        "bleurt": -0.60306,
        "bertscore": {
            "precision": 0.91667,
            "recall": 0.89197,
            "f1": 0.90059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9754338947042096,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.5,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7
        },
        "bleu": 34.66668,
        "nubia": {
            "semantic_relation": 4.83681,
            "contradiction": 0.16909,
            "irrelevancy": 0.46041,
            "logical_agreement": 99.3705,
            "grammar_ref": 5.42176,
            "grammar_hyp": 5.92683,
            "nubia_score": 0.87647
        },
        "meteor": 0.4407781147481815,
        "bleurt": 0.6686,
        "bertscore": {
            "precision": 0.9374,
            "recall": 0.93529,
            "f1": 0.93635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9288709332057588,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.60447,
            "fmeasure": 0.64955
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.42328,
            "fmeasure": 0.44511
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.4689,
            "fmeasure": 0.50811
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.4689,
            "fmeasure": 0.50811
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "bleu": 32.68043,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 5.52809,
            "irrelevancy": 3.87682,
            "logical_agreement": 90.59508,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.78935,
            "nubia_score": 0.96788
        },
        "meteor": 0.4143104795614488,
        "bleurt": 0.5813,
        "bertscore": {
            "precision": 0.95444,
            "recall": 0.93955,
            "f1": 0.94694
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.10341647163363243,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.02443964427976503,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.10777297761309833,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.02555597707498716,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.233101956544771,
        "rouge1": {
            "precision": 0.86957,
            "recall": 0.74074,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "bleu": 45.8736,
        "nubia": {
            "semantic_relation": 4.16847,
            "contradiction": 0.12934,
            "irrelevancy": 3.90988,
            "logical_agreement": 95.96078,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.08326,
            "nubia_score": 0.73512
        },
        "meteor": 0.41030282160569487,
        "bleurt": 0.14383,
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.91449,
            "f1": 0.9194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.66578250153649,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.35294,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.25,
            "fmeasure": 0.25806
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.29412,
            "fmeasure": 0.30303
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bleu": 20.70317,
        "nubia": {
            "semantic_relation": 2.17157,
            "contradiction": 99.8497,
            "irrelevancy": 0.12154,
            "logical_agreement": 0.02876,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.00634,
            "nubia_score": 0.20962
        },
        "meteor": 0.21512735963051483,
        "bleurt": -0.16681,
        "bertscore": {
            "precision": 0.84619,
            "recall": 0.80411,
            "f1": 0.82461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.0559581516151235,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.4247281854058968,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.970573095811684,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.4450233042444857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.417966546760986,
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.85671,
            "fmeasure": 0.7072
        },
        "rouge2": {
            "precision": 0.25397,
            "recall": 0.36111,
            "fmeasure": 0.29702
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.727,
            "fmeasure": 0.60073
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.727,
            "fmeasure": 0.60073
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8
        },
        "bleu": 10.51704,
        "nubia": {
            "semantic_relation": 3.85957,
            "contradiction": 8.53205,
            "irrelevancy": 90.62568,
            "logical_agreement": 0.84227,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.57359,
            "nubia_score": 0.53645
        },
        "meteor": 0.3569890917816816,
        "bleurt": -0.22308,
        "bertscore": {
            "precision": 0.88647,
            "recall": 0.90073,
            "f1": 0.88704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.0826430951702087,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.03462179117476821,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.09060036801448043,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4378122710938497,
        "rouge1": {
            "precision": 0.67708,
            "recall": 0.5947,
            "fmeasure": 0.63012
        },
        "rouge2": {
            "precision": 0.52101,
            "recall": 0.44363,
            "fmeasure": 0.4761
        },
        "rougeL": {
            "precision": 0.64931,
            "recall": 0.56692,
            "fmeasure": 0.60234
        },
        "rougeLsum": {
            "precision": 0.64931,
            "recall": 0.56692,
            "fmeasure": 0.60234
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.47368421052631576,
            "3": 0.8333333333333334
        },
        "bleu": 39.94018,
        "nubia": {
            "semantic_relation": 4.02286,
            "contradiction": 51.22313,
            "irrelevancy": 23.01239,
            "logical_agreement": 25.76448,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.05381,
            "nubia_score": 0.56041
        },
        "meteor": 0.30804872982480547,
        "bleurt": 0.26738,
        "bertscore": {
            "precision": 0.92234,
            "recall": 0.90509,
            "f1": 0.91356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5154721347627746,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.63492,
            "fmeasure": 0.55728
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.52083,
            "fmeasure": 0.44314
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6666666666666666
        },
        "bleu": 40.35279,
        "nubia": {
            "semantic_relation": 3.58823,
            "contradiction": 0.11698,
            "irrelevancy": 86.19248,
            "logical_agreement": 13.69054,
            "grammar_ref": 4.8549,
            "grammar_hyp": 4.91734,
            "nubia_score": 0.55131
        },
        "meteor": 0.37146259355923894,
        "bleurt": 0.43262,
        "bertscore": {
            "precision": 0.90707,
            "recall": 0.9337,
            "f1": 0.91994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.18135626121219853,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.32043,
            "fmeasure": 0.34797
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.08519,
            "fmeasure": 0.09117
        },
        "rougeL": {
            "precision": 0.23333,
            "recall": 0.16559,
            "fmeasure": 0.18211
        },
        "rougeLsum": {
            "precision": 0.23333,
            "recall": 0.16559,
            "fmeasure": 0.18211
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.14285714285714285,
            "3": 0.2222222222222222
        },
        "bleu": 11.0168,
        "nubia": {
            "semantic_relation": 2.22193,
            "contradiction": 74.93439,
            "irrelevancy": 12.27789,
            "logical_agreement": 12.78772,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.45914,
            "nubia_score": 0.13811
        },
        "meteor": 0.12508677152544423,
        "bleurt": -0.5825,
        "bertscore": {
            "precision": 0.84377,
            "recall": 0.8008,
            "f1": 0.7925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6356900651746193,
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.53333,
            "fmeasure": 0.5614
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2963,
            "fmeasure": 0.31373
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.53333,
            "fmeasure": 0.5614
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.53333,
            "fmeasure": 0.5614
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 13.66927,
        "nubia": {
            "semantic_relation": 4.92907,
            "contradiction": 0.49635,
            "irrelevancy": 5.33773,
            "logical_agreement": 94.16593,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.15194,
            "nubia_score": 0.98226
        },
        "meteor": 0.3795786645356242,
        "bleurt": 0.09909,
        "bertscore": {
            "precision": 0.97096,
            "recall": 0.95794,
            "f1": 0.9644
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4929182263680483,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "bleu": 19.43406,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "meteor": 0.38388402914845343,
        "bleurt": 0.5593,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.625,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.3068905956085186,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.13452278258006406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.089998731966934,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.50783,
            "fmeasure": 0.65497
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.13258,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.29623,
            "fmeasure": 0.38207
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.29623,
            "fmeasure": 0.38207
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.4444444444444444
        },
        "bleu": 12.39211,
        "nubia": {
            "semantic_relation": 2.94924,
            "contradiction": 78.51209,
            "irrelevancy": 10.89131,
            "logical_agreement": 10.5966,
            "grammar_ref": 3.96534,
            "grammar_hyp": 4.40267,
            "nubia_score": 0.2946
        },
        "meteor": 0.2329642843282422,
        "bleurt": -0.90308,
        "bertscore": {
            "precision": 0.90693,
            "recall": 0.82682,
            "f1": 0.86503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 8,
        "entropy-1": 3.721928094887362,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 14,
        "unique-2": 10,
        "entropy-2": 3.7254805569978675,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.506890595608518,
        "cond_entropy-2-nopunct": -0.04723891230848751,
        "distinct-3-nopunct": 0.8461538461538461,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.3927474104487847,
        "cond_entropy-3-nopunct": -0.05260472362127269,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0604169987684,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.85354,
            "fmeasure": 0.92059
        },
        "rouge2": {
            "precision": 0.74107,
            "recall": 0.64352,
            "fmeasure": 0.68867
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.80808,
            "fmeasure": 0.87059
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.80808,
            "fmeasure": 0.87059
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8823529411764706
        },
        "bleu": 62.87167,
        "nubia": {
            "semantic_relation": 4.95116,
            "contradiction": 0.41024,
            "irrelevancy": 10.79107,
            "logical_agreement": 88.79868,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.88861,
            "nubia_score": 0.98316
        },
        "meteor": 0.48963727981203664,
        "bleurt": 0.8134,
        "bertscore": {
            "precision": 0.99372,
            "recall": 0.97278,
            "f1": 0.9818
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.10738098714625,
        "rouge1": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.85833,
            "fmeasure": 0.70055
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 1.0,
            "fmeasure": 0.82619
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "bleu": 50.1413,
        "nubia": {
            "semantic_relation": 4.14019,
            "contradiction": 0.47018,
            "irrelevancy": 81.86249,
            "logical_agreement": 17.66733,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.68485,
            "nubia_score": 0.77508
        },
        "meteor": 0.5103416375985329,
        "bleurt": 0.3654,
        "bertscore": {
            "precision": 0.91137,
            "recall": 0.97758,
            "f1": 0.94331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4126055779636177,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.54684,
            "fmeasure": 0.67406
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.30637,
            "fmeasure": 0.37987
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.51961,
            "fmeasure": 0.63547
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.51961,
            "fmeasure": 0.63547
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5294117647058824
        },
        "bleu": 26.53128,
        "nubia": {
            "semantic_relation": 4.04081,
            "contradiction": 0.11229,
            "irrelevancy": 25.5609,
            "logical_agreement": 74.32681,
            "grammar_ref": 4.84215,
            "grammar_hyp": 5.76145,
            "nubia_score": 0.53588
        },
        "meteor": 0.37874476599098156,
        "bleurt": 0.19479,
        "bertscore": {
            "precision": 0.94642,
            "recall": 0.90312,
            "f1": 0.92426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4558307284093153,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.55873,
            "fmeasure": 0.60779
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.16239,
            "fmeasure": 0.1715
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.34921,
            "fmeasure": 0.37987
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.34921,
            "fmeasure": 0.37987
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7
        },
        "bleu": 9.90853,
        "nubia": {
            "semantic_relation": 3.63745,
            "contradiction": 4.46042,
            "irrelevancy": 5.94399,
            "logical_agreement": 89.59559,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.54521,
            "nubia_score": 0.68444
        },
        "meteor": 0.3376739056758712,
        "bleurt": 0.16428,
        "bertscore": {
            "precision": 0.89307,
            "recall": 0.8611,
            "f1": 0.8768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97683,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.452819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.4905497624194164,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.3232314287976203,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.5258134337464763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2441816278287212,
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.28356,
            "fmeasure": 0.27381
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07639,
            "fmeasure": 0.0735
        },
        "rougeL": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "rougeLsum": {
            "precision": 0.24444,
            "recall": 0.23379,
            "fmeasure": 0.2381
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bleu": 6.15034,
        "nubia": {
            "semantic_relation": 1.25766,
            "contradiction": 24.30802,
            "irrelevancy": 73.51439,
            "logical_agreement": 2.17759,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.80434,
            "nubia_score": 0.10996
        },
        "meteor": 0.12124354408519472,
        "bleurt": -0.60118,
        "bertscore": {
            "precision": 0.65955,
            "recall": 0.65714,
            "f1": 0.65834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7054392373313632,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.26667,
            "fmeasure": 0.2963
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.07143,
            "fmeasure": 0.08
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bleu": 5.3708,
        "nubia": {
            "semantic_relation": 2.38982,
            "contradiction": 0.31357,
            "irrelevancy": 98.7788,
            "logical_agreement": 0.90763,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.75265,
            "nubia_score": 0.17093
        },
        "meteor": 0.11753763311968543,
        "bleurt": -0.27735,
        "bertscore": {
            "precision": 0.77791,
            "recall": 0.79147,
            "f1": 0.78463
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 17,
        "mean_pred_length": 8.5,
        "std_pred_length": 1.5,
        "median_pred_length": 8.5,
        "min_pred_length": 7,
        "max_pred_length": 10,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.18057224564182078,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.2064508774674265,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 7.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.2064508774674265,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.24100809950379498,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.037335212413274844,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.3201,
            "fmeasure": 0.46562
        },
        "rouge2": {
            "precision": 0.74444,
            "recall": 0.22506,
            "fmeasure": 0.33739
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.3201,
            "fmeasure": 0.46562
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.3201,
            "fmeasure": 0.46562
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.23529411764705882,
            "3": 0.39285714285714285
        },
        "bleu": 18.20651,
        "nubia": {
            "semantic_relation": 3.68836,
            "contradiction": 0.27003,
            "irrelevancy": 2.36534,
            "logical_agreement": 97.36463,
            "grammar_ref": 3.63495,
            "grammar_hyp": 5.22602,
            "nubia_score": 0.42518
        },
        "meteor": 0.19040591968938367,
        "bleurt": -0.15674,
        "bertscore": {
            "precision": 0.9199,
            "recall": 0.81508,
            "f1": 0.85465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8755164008479155,
        "rouge1": {
            "precision": 0.64706,
            "recall": 0.76825,
            "fmeasure": 0.70228
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.52564,
            "fmeasure": 0.47739
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.62857,
            "fmeasure": 0.5746
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.62857,
            "fmeasure": 0.5746
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "bleu": 24.26438,
        "nubia": {
            "semantic_relation": 3.47839,
            "contradiction": 0.11509,
            "irrelevancy": 99.59765,
            "logical_agreement": 0.28725,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.47339,
            "nubia_score": 0.66075
        },
        "meteor": 0.3729970546597674,
        "bleurt": -0.15472,
        "bertscore": {
            "precision": 0.83366,
            "recall": 0.91464,
            "f1": 0.87227
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1474994498662379,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.36607,
            "fmeasure": 0.42222
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.17692,
            "fmeasure": 0.20696
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.36607,
            "fmeasure": 0.42222
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.36607,
            "fmeasure": 0.42222
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.375
        },
        "bleu": 8.15486,
        "nubia": {
            "semantic_relation": 1.99834,
            "contradiction": 75.85076,
            "irrelevancy": 9.07281,
            "logical_agreement": 15.07644,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.45409,
            "nubia_score": 0.18541
        },
        "meteor": 0.26278054217196267,
        "bleurt": 0.18846,
        "bertscore": {
            "precision": 0.90357,
            "recall": 0.87227,
            "f1": 0.88445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.190572262757721,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.44405,
            "irrelevancy": 0.50174,
            "logical_agreement": 99.05421,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.68353,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.83087,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 0.9375,
        "vocab_size-3": 15,
        "unique-3": 14,
        "entropy-3": 3.875,
        "cond_entropy-3": 0.0375371587496606,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660255,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.367298074464469,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.7208,
            "fmeasure": 0.70222
        },
        "rouge2": {
            "precision": 0.48485,
            "recall": 0.58333,
            "fmeasure": 0.52479
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.7208,
            "fmeasure": 0.70222
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.7208,
            "fmeasure": 0.70222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "bleu": 47.63101,
        "nubia": {
            "semantic_relation": 3.92785,
            "contradiction": 30.14129,
            "irrelevancy": 66.58874,
            "logical_agreement": 3.26997,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.36211,
            "nubia_score": 0.52422
        },
        "meteor": 0.4181568082778626,
        "bleurt": -0.13078,
        "bertscore": {
            "precision": 0.93644,
            "recall": 0.95492,
            "f1": 0.93664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 31,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.5806451612903226,
        "vocab_size-1": 18,
        "unique-1": 9,
        "entropy-1": 4.018081793978685,
        "distinct-2": 0.75,
        "vocab_size-2": 21,
        "unique-2": 15,
        "entropy-2": 4.280394654123195,
        "cond_entropy-2": 0.19279343325383375,
        "distinct-3": 0.84,
        "vocab_size-3": 21,
        "unique-3": 17,
        "entropy-3": 4.323856189774722,
        "cond_entropy-3": -0.08349873228287957,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 8.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.8441065448145375,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.1757358691004915,
        "cond_entropy-2-nopunct": 0.23659071636491807,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": -0.10163386116965065,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1167736057372477,
        "rouge1": {
            "precision": 0.86263,
            "recall": 0.76194,
            "fmeasure": 0.79786
        },
        "rouge2": {
            "precision": 0.6963,
            "recall": 0.62716,
            "fmeasure": 0.64979
        },
        "rougeL": {
            "precision": 0.86263,
            "recall": 0.76194,
            "fmeasure": 0.79786
        },
        "rougeLsum": {
            "precision": 0.86263,
            "recall": 0.76194,
            "fmeasure": 0.79786
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6296296296296297
        },
        "bleu": 50.78755,
        "nubia": {
            "semantic_relation": 3.89603,
            "contradiction": 41.67632,
            "irrelevancy": 12.7267,
            "logical_agreement": 45.59699,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.43633,
            "nubia_score": 0.54628
        },
        "meteor": 0.399737647952039,
        "bleurt": 0.19725,
        "bertscore": {
            "precision": 0.9447,
            "recall": 0.91857,
            "f1": 0.92983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.854285871987245,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94692,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2340686174361553,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "bleu": 67.03421,
        "nubia": {
            "semantic_relation": 4.74676,
            "contradiction": 0.20597,
            "irrelevancy": 33.54833,
            "logical_agreement": 66.24571,
            "grammar_ref": 4.85772,
            "grammar_hyp": 4.97714,
            "nubia_score": 0.86781
        },
        "meteor": 1.0,
        "bleurt": 0.75312,
        "bertscore": {
            "precision": 0.99407,
            "recall": 0.98329,
            "f1": 0.98865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 173,
        "mean_pred_length": 57.666666666666664,
        "std_pred_length": 29.48822740612863,
        "median_pred_length": 70.0,
        "min_pred_length": 17,
        "max_pred_length": 86,
        "distinct-1": 0.15606936416184972,
        "vocab_size-1": 27,
        "unique-1": 13,
        "entropy-1": 3.08213855301969,
        "distinct-2": 0.2647058823529412,
        "vocab_size-2": 45,
        "unique-2": 30,
        "entropy-2": 4.200961422294853,
        "cond_entropy-2": 1.1838668047095822,
        "distinct-3": 0.2994011976047904,
        "vocab_size-3": 50,
        "unique-3": 35,
        "entropy-3": 4.401780951331027,
        "cond_entropy-3": 0.2584559873686787,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 13.140268896284683,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.25252525252525254,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.5309110281109177,
        "distinct-2-nopunct": 0.375,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.097940410357359,
        "cond_entropy-2-nopunct": 0.60283517162955,
        "distinct-3-nopunct": 0.44086021505376344,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.343892471605423,
        "cond_entropy-3-nopunct": 0.315425892120015,
        "msttr-100": 0.2,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7553601024083272,
        "rouge1": {
            "precision": 0.29458,
            "recall": 0.4277,
            "fmeasure": 0.32873
        },
        "rouge2": {
            "precision": 0.07884,
            "recall": 0.08843,
            "fmeasure": 0.08002
        },
        "rougeL": {
            "precision": 0.19484,
            "recall": 0.246,
            "fmeasure": 0.20675
        },
        "rougeLsum": {
            "precision": 0.19484,
            "recall": 0.246,
            "fmeasure": 0.20675
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "bleu": 1.73209,
        "nubia": {
            "semantic_relation": 3.59037,
            "contradiction": 2.40437,
            "irrelevancy": 18.27283,
            "logical_agreement": 79.32281,
            "grammar_ref": 4.73012,
            "grammar_hyp": 2.26479,
            "nubia_score": 0.4806
        },
        "meteor": 0.15394448110772488,
        "bleurt": -0.35295,
        "bertscore": {
            "precision": 0.80953,
            "recall": 0.81725,
            "f1": 0.81021
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 3,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 26,
        "distinct-1": 0.5862068965517241,
        "vocab_size-1": 34,
        "unique-1": 19,
        "entropy-1": 4.881615641970835,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 45,
        "unique-2": 35,
        "entropy-2": 5.417723349888292,
        "cond_entropy-2": 0.5029114998684914,
        "distinct-3": 0.8846153846153846,
        "vocab_size-3": 46,
        "unique-3": 40,
        "entropy-3": 5.469670487371864,
        "cond_entropy-3": 0.0729261584625864,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5849056603773585,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.749160020960798,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.243856189774728,
        "cond_entropy-2-nopunct": 0.5134217948300698,
        "distinct-3-nopunct": 0.8723404255319149,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.29926970274147,
        "cond_entropy-3-nopunct": 0.038392236370997826,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.062118423544521,
        "rouge1": {
            "precision": 0.70136,
            "recall": 0.77288,
            "fmeasure": 0.72293
        },
        "rouge2": {
            "precision": 0.47454,
            "recall": 0.49521,
            "fmeasure": 0.4767
        },
        "rougeL": {
            "precision": 0.59924,
            "recall": 0.63185,
            "fmeasure": 0.60633
        },
        "rougeLsum": {
            "precision": 0.59924,
            "recall": 0.63185,
            "fmeasure": 0.60633
        },
        "local_recall": {
            "1": 0.45,
            "2": 0.6666666666666666,
            "3": 0.8333333333333334
        },
        "bleu": 39.94495,
        "nubia": {
            "semantic_relation": 4.02058,
            "contradiction": 3.73194,
            "irrelevancy": 67.2688,
            "logical_agreement": 28.99927,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.18793,
            "nubia_score": 0.67928
        },
        "meteor": 0.4167853746081628,
        "bleurt": -0.10273,
        "bertscore": {
            "precision": 0.91718,
            "recall": 0.9189,
            "f1": 0.91464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.183692100800589,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.48148,
            "fmeasure": 0.61617
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.29264,
            "fmeasure": 0.37892
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.44192,
            "fmeasure": 0.54581
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.44192,
            "fmeasure": 0.54581
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.3888888888888889
        },
        "bleu": 11.41744,
        "nubia": {
            "semantic_relation": 3.69888,
            "contradiction": 1.57373,
            "irrelevancy": 54.9028,
            "logical_agreement": 43.52347,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.39765,
            "nubia_score": 0.49765
        },
        "meteor": 0.23718787065544186,
        "bleurt": -0.64996,
        "bertscore": {
            "precision": 0.88311,
            "recall": 0.84529,
            "f1": 0.86375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.573335161354208,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "bleu": 28.99784,
        "nubia": {
            "semantic_relation": 2.49111,
            "contradiction": 23.11552,
            "irrelevancy": 74.93293,
            "logical_agreement": 1.95155,
            "grammar_ref": 3.66596,
            "grammar_hyp": 4.48074,
            "nubia_score": 0.23506
        },
        "meteor": 0.35544347173293367,
        "bleurt": -0.40575,
        "bertscore": {
            "precision": 0.83406,
            "recall": 0.89226,
            "f1": 0.86218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6596087951881056,
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.47727,
            "fmeasure": 0.37749
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "bleu": 17.02602,
        "nubia": {
            "semantic_relation": 4.29483,
            "contradiction": 0.11788,
            "irrelevancy": 99.76088,
            "logical_agreement": 0.12123,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.10057,
            "nubia_score": 0.83986
        },
        "meteor": 0.33963139034838774,
        "bleurt": 0.08312,
        "bertscore": {
            "precision": 0.87255,
            "recall": 0.93079,
            "f1": 0.90073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9444110717651109,
        "rouge1": {
            "precision": 0.20833,
            "recall": 0.375,
            "fmeasure": 0.26667
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.07143,
            "fmeasure": 0.05556
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.375,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.375,
            "fmeasure": 0.26667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4
        },
        "bleu": 6.25038,
        "nubia": {
            "semantic_relation": 2.13153,
            "contradiction": 21.38797,
            "irrelevancy": 78.10656,
            "logical_agreement": 0.50548,
            "grammar_ref": 7.18676,
            "grammar_hyp": 6.18674,
            "nubia_score": 0.14912
        },
        "meteor": 0.22351883771210704,
        "bleurt": -0.86513,
        "bertscore": {
            "precision": 0.67865,
            "recall": 0.75861,
            "f1": 0.70747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.47872969366552,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0,
        "bleurt": 0.9148,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.887772522769625,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.69841,
            "fmeasure": 0.59444
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.46667,
            "fmeasure": 0.38828
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.69841,
            "fmeasure": 0.59444
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.69841,
            "fmeasure": 0.59444
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "bleu": 14.25877,
        "nubia": {
            "semantic_relation": 2.84777,
            "contradiction": 1.17349,
            "irrelevancy": 98.58929,
            "logical_agreement": 0.23722,
            "grammar_ref": 6.44614,
            "grammar_hyp": 6.12343,
            "nubia_score": 0.36194
        },
        "meteor": 0.2913866485807477,
        "bleurt": -0.99573,
        "bertscore": {
            "precision": 0.86601,
            "recall": 0.90489,
            "f1": 0.88503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.5909090909090909,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.6412498004554794,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.521928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2544789837508556,
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 82.65168,
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        },
        "meteor": 0.5690637876265101,
        "bleurt": 0.56358,
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7924812503605787,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.40909,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.40909,
            "fmeasure": 0.40909
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "bleu": 14.99111,
        "nubia": {
            "semantic_relation": 3.57175,
            "contradiction": 0.10846,
            "irrelevancy": 99.73916,
            "logical_agreement": 0.15237,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.24754,
            "nubia_score": 0.60445
        },
        "meteor": 0.2217786470992739,
        "bleurt": -0.56204,
        "bertscore": {
            "precision": 0.82093,
            "recall": 0.81183,
            "f1": 0.81636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.599928732545885,
        "rouge1": {
            "precision": 0.67857,
            "recall": 0.50535,
            "fmeasure": 0.57706
        },
        "rouge2": {
            "precision": 0.57692,
            "recall": 0.42411,
            "fmeasure": 0.48682
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.41444,
            "fmeasure": 0.46595
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.41444,
            "fmeasure": 0.46595
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.5
        },
        "bleu": 23.38912,
        "nubia": {
            "semantic_relation": 2.98445,
            "contradiction": 0.20128,
            "irrelevancy": 99.66454,
            "logical_agreement": 0.13418,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.96214,
            "nubia_score": 0.39759
        },
        "meteor": 0.4442956524987175,
        "bleurt": -0.41764,
        "bertscore": {
            "precision": 0.89116,
            "recall": 0.86043,
            "f1": 0.87553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.4565647621309536,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.3829562908893333,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.41269152701913925,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.541848263840016,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.53333,
            "fmeasure": 0.55172
        },
        "rouge2": {
            "precision": 0.11538,
            "recall": 0.10714,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.46667,
            "fmeasure": 0.48276
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.46667,
            "fmeasure": 0.48276
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5555555555555556
        },
        "bleu": 13.68466,
        "nubia": {
            "semantic_relation": 2.83618,
            "contradiction": 46.26992,
            "irrelevancy": 43.97508,
            "logical_agreement": 9.755,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.94684,
            "nubia_score": 0.34045
        },
        "meteor": 0.30413552356291607,
        "bleurt": -0.75748,
        "bertscore": {
            "precision": 0.88235,
            "recall": 0.86513,
            "f1": 0.87366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.557533649399047,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rougeLsum": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "bleu": 61.28081,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31478,
            "irrelevancy": 0.53733,
            "logical_agreement": 99.14789,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.43696,
            "nubia_score": 0.88323
        },
        "meteor": 0.4907863019777329,
        "bleurt": 0.67301,
        "bertscore": {
            "precision": 0.98135,
            "recall": 0.98613,
            "f1": 0.98373
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7136563235793887,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.61538,
            "fmeasure": 0.72727
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "bleu": 42.88819,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 4.36088,
            "irrelevancy": 1.21054,
            "logical_agreement": 94.42858,
            "grammar_ref": 3.94537,
            "grammar_hyp": 4.87325,
            "nubia_score": 0.90707
        },
        "meteor": 0.35984860195205803,
        "bleurt": 0.62333,
        "bertscore": {
            "precision": 0.96184,
            "recall": 0.88586,
            "f1": 0.92229
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.3067316181128199,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.3379852264664119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9105250180801645,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72751,
            "fmeasure": 0.83954
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.51584,
            "fmeasure": 0.60333
        },
        "rougeL": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "rougeLsum": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bleu": 62.207,
        "nubia": {
            "semantic_relation": 3.27646,
            "contradiction": 93.29798,
            "irrelevancy": 1.81369,
            "logical_agreement": 4.88833,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.87496,
            "nubia_score": 0.56072
        },
        "meteor": 0.3977613383709655,
        "bleurt": -0.14434,
        "bertscore": {
            "precision": 0.96167,
            "recall": 0.90351,
            "f1": 0.93168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.763324482612094,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79365,
            "fmeasure": 0.76863
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "bleu": 59.69492,
        "nubia": {
            "semantic_relation": 4.92238,
            "contradiction": 0.17593,
            "irrelevancy": 35.19794,
            "logical_agreement": 64.62613,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.71883,
            "nubia_score": 1.0
        },
        "meteor": 0.902035682675735,
        "bleurt": 0.64829,
        "bertscore": {
            "precision": 0.96429,
            "recall": 0.97126,
            "f1": 0.96429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9095734506091306,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.7,
            "fmeasure": 0.66844
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.42208,
            "fmeasure": 0.40123
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.52222,
            "fmeasure": 0.49691
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.52222,
            "fmeasure": 0.49691
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bleu": 12.87433,
        "nubia": {
            "semantic_relation": 4.89203,
            "contradiction": 0.23678,
            "irrelevancy": 5.74834,
            "logical_agreement": 94.01489,
            "grammar_ref": 4.47457,
            "grammar_hyp": 3.82592,
            "nubia_score": 0.99903
        },
        "meteor": 0.39260414895946116,
        "bleurt": 0.20277,
        "bertscore": {
            "precision": 0.869,
            "recall": 0.88273,
            "f1": 0.87453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1679090245203874,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.28571,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.2,
            "2": 1.0
        },
        "bleu": 25.96536,
        "nubia": {
            "semantic_relation": 3.65133,
            "contradiction": 2.9075,
            "irrelevancy": 72.29606,
            "logical_agreement": 24.79643,
            "grammar_ref": 5.57872,
            "grammar_hyp": 6.0593,
            "nubia_score": 0.42814
        },
        "meteor": 0.34119261573023246,
        "bleurt": -0.00216,
        "bertscore": {
            "precision": 0.85185,
            "recall": 0.86421,
            "f1": 0.85799
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8450301966065585,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.85,
            "fmeasure": 0.70222
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.66667,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.85,
            "fmeasure": 0.70222
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.85,
            "fmeasure": 0.70222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.875
        },
        "bleu": 34.79159,
        "nubia": {
            "semantic_relation": 4.39349,
            "contradiction": 0.35223,
            "irrelevancy": 45.13642,
            "logical_agreement": 54.51136,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.03436,
            "nubia_score": 0.80766
        },
        "meteor": 0.40451532910394367,
        "bleurt": 0.18204,
        "bertscore": {
            "precision": 0.86219,
            "recall": 0.92317,
            "f1": 0.89164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3749768291684963,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.82353,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.5,
            "fmeasure": 0.48485
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.82353,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.82353,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "bleu": 29.18618,
        "nubia": {
            "semantic_relation": 4.06602,
            "contradiction": 0.72618,
            "irrelevancy": 6.02864,
            "logical_agreement": 93.24518,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.22875,
            "nubia_score": 0.61316
        },
        "meteor": 0.439771595151467,
        "bleurt": 0.4194,
        "bertscore": {
            "precision": 0.95728,
            "recall": 0.94722,
            "f1": 0.95222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9313738634396848,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "bleu": 8.29519,
        "nubia": {
            "semantic_relation": 2.78899,
            "contradiction": 0.29727,
            "irrelevancy": 97.22608,
            "logical_agreement": 2.47665,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.90146,
            "nubia_score": 0.40056
        },
        "meteor": 0.2331715255855191,
        "bleurt": -0.53575,
        "bertscore": {
            "precision": 0.79602,
            "recall": 0.78154,
            "f1": 0.78871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.100819138141714,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.63333,
            "fmeasure": 0.65134
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.28105,
            "fmeasure": 0.2846
        },
        "rougeL": {
            "precision": 0.48485,
            "recall": 0.44444,
            "fmeasure": 0.45539
        },
        "rougeLsum": {
            "precision": 0.48485,
            "recall": 0.44444,
            "fmeasure": 0.45539
        },
        "local_recall": {
            "1": 0,
            "2": 0.2857142857142857,
            "3": 0.7
        },
        "bleu": 26.65838,
        "nubia": {
            "semantic_relation": 4.48567,
            "contradiction": 0.13824,
            "irrelevancy": 1.07816,
            "logical_agreement": 98.7836,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.69391,
            "nubia_score": 0.90183
        },
        "meteor": 0.35516970206552856,
        "bleurt": 0.36691,
        "bertscore": {
            "precision": 0.92002,
            "recall": 0.90828,
            "f1": 0.91411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.73609896478902,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.66667,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.8125
        },
        "bleu": 65.25942,
        "nubia": {
            "semantic_relation": 3.62949,
            "contradiction": 0.23057,
            "irrelevancy": 33.2221,
            "logical_agreement": 66.54734,
            "grammar_ref": 3.23206,
            "grammar_hyp": 2.92393,
            "nubia_score": 0.7323
        },
        "meteor": 0.4368767317307086,
        "bleurt": -0.22932,
        "bertscore": {
            "precision": 0.97026,
            "recall": 0.92549,
            "f1": 0.94735
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.826874881864636,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.3664419324431711,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.6168746059562227,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.4125371587496607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9791848689144755,
        "rouge1": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.92593,
            "fmeasure": 0.62957
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "bleu": 17.12473,
        "nubia": {
            "semantic_relation": 4.26231,
            "contradiction": 0.11478,
            "irrelevancy": 86.07327,
            "logical_agreement": 13.81196,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.35373,
            "nubia_score": 0.68242
        },
        "meteor": 0.49254427229214076,
        "bleurt": 0.37,
        "bertscore": {
            "precision": 0.88056,
            "recall": 0.9534,
            "f1": 0.88762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.4838561897747224,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043809,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0759718251120627,
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.5,
            "fmeasure": 0.60185
        },
        "rouge2": {
            "precision": 0.47024,
            "recall": 0.25407,
            "fmeasure": 0.32658
        },
        "rougeL": {
            "precision": 0.53365,
            "recall": 0.35363,
            "fmeasure": 0.41459
        },
        "rougeLsum": {
            "precision": 0.53365,
            "recall": 0.35363,
            "fmeasure": 0.41459
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5769230769230769
        },
        "bleu": 28.48834,
        "nubia": {
            "semantic_relation": 3.57472,
            "contradiction": 12.15695,
            "irrelevancy": 8.1355,
            "logical_agreement": 79.70756,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.97585,
            "nubia_score": 0.47143
        },
        "meteor": 0.2702851175589981,
        "bleurt": -0.32584,
        "bertscore": {
            "precision": 0.89098,
            "recall": 0.8475,
            "f1": 0.86849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6670162561116353,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.38406,
            "fmeasure": 0.49754
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.11991,
            "fmeasure": 0.15714
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.30725,
            "fmeasure": 0.39803
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.30725,
            "fmeasure": 0.39803
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42105263157894735
        },
        "bleu": 8.22164,
        "nubia": {
            "semantic_relation": 3.35342,
            "contradiction": 1.22686,
            "irrelevancy": 2.1341,
            "logical_agreement": 96.63904,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.88965,
            "nubia_score": 0.37429
        },
        "meteor": 0.23232000964397576,
        "bleurt": -0.31583,
        "bertscore": {
            "precision": 0.8808,
            "recall": 0.83679,
            "f1": 0.85823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.616961879953846,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 74.19447,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24117,
            "irrelevancy": 0.43431,
            "logical_agreement": 99.32451,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.55935,
            "nubia_score": 0.9976
        },
        "meteor": 0.549453875996166,
        "bleurt": 0.65172,
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.96353,
            "f1": 0.96239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7523186607677644,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.35417,
            "fmeasure": 0.44505
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.52778,
            "fmeasure": 0.64583
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "bleu": 11.09148,
        "nubia": {
            "semantic_relation": 4.48995,
            "contradiction": 0.4933,
            "irrelevancy": 0.56798,
            "logical_agreement": 98.93872,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.65309,
            "nubia_score": 0.88518
        },
        "meteor": 0.3632707060776975,
        "bleurt": 0.46665,
        "bertscore": {
            "precision": 0.95553,
            "recall": 0.90658,
            "f1": 0.93041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.505982505323458,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21928,
            "irrelevancy": 8.36789,
            "logical_agreement": 91.41284,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.40881,
            "nubia_score": 1.0
        },
        "meteor": 0.544209755399708,
        "bleurt": 0.8097,
        "bertscore": {
            "precision": 0.97901,
            "recall": 0.99673,
            "f1": 0.98779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.20859693530755724,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5558941141594504,
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.41071,
            "fmeasure": 0.40361
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.17094,
            "fmeasure": 0.16344
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.375,
            "fmeasure": 0.36106
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.375,
            "fmeasure": 0.36106
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5555555555555556
        },
        "bleu": 6.28779,
        "nubia": {
            "semantic_relation": 2.52766,
            "contradiction": 0.18153,
            "irrelevancy": 99.25534,
            "logical_agreement": 0.56313,
            "grammar_ref": 3.10421,
            "grammar_hyp": 3.93184,
            "nubia_score": 0.25614
        },
        "meteor": 0.19921239576062594,
        "bleurt": -0.23982,
        "bertscore": {
            "precision": 0.80272,
            "recall": 0.85751,
            "f1": 0.8162
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.091445086292439,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.62105,
            "fmeasure": 0.66066
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.47368,
            "fmeasure": 0.50532
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.62105,
            "fmeasure": 0.66066
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.62105,
            "fmeasure": 0.66066
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 44.20105,
        "nubia": {
            "semantic_relation": 3.7489,
            "contradiction": 4.27704,
            "irrelevancy": 9.92945,
            "logical_agreement": 85.79351,
            "grammar_ref": 4.62058,
            "grammar_hyp": 3.51269,
            "nubia_score": 0.69567
        },
        "meteor": 0.3828712799979558,
        "bleurt": 0.3841,
        "bertscore": {
            "precision": 0.94576,
            "recall": 0.91551,
            "f1": 0.93039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 4,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 6.06217782649107,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 36,
        "unique-1": 25,
        "entropy-1": 4.956379808112289,
        "distinct-2": 0.92,
        "vocab_size-2": 46,
        "unique-2": 42,
        "entropy-2": 5.483856189774729,
        "cond_entropy-2": 0.43135699718653103,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 44,
        "unique-3": 42,
        "entropy-3": 5.43660543431788,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.873670062235365,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7083333333333334,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.8949746782469115,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.277613436819114,
        "cond_entropy-2-nopunct": 0.42263765152440813,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.221928094887364,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5927425182923187,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.42425,
            "fmeasure": 0.51062
        },
        "rouge2": {
            "precision": 0.40718,
            "recall": 0.26916,
            "fmeasure": 0.311
        },
        "rougeL": {
            "precision": 0.56528,
            "recall": 0.39712,
            "fmeasure": 0.46248
        },
        "rougeLsum": {
            "precision": 0.56528,
            "recall": 0.39712,
            "fmeasure": 0.46248
        },
        "local_recall": {
            "1": 0.175,
            "2": 0.4444444444444444,
            "3": 0.4482758620689655
        },
        "bleu": 37.10871,
        "nubia": {
            "semantic_relation": 3.86462,
            "contradiction": 1.00759,
            "irrelevancy": 45.50696,
            "logical_agreement": 53.48545,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.03354,
            "nubia_score": 0.5775
        },
        "meteor": 0.2428110649901947,
        "bleurt": -0.1739,
        "bertscore": {
            "precision": 0.89995,
            "recall": 0.84184,
            "f1": 0.8627
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.803136096693226,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.67402,
            "fmeasure": 0.75019
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.45694,
            "fmeasure": 0.51235
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.61275,
            "fmeasure": 0.68199
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.61275,
            "fmeasure": 0.68199
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.625
        },
        "bleu": 44.6401,
        "nubia": {
            "semantic_relation": 3.59877,
            "contradiction": 7.00675,
            "irrelevancy": 3.13876,
            "logical_agreement": 89.85448,
            "grammar_ref": 4.86284,
            "grammar_hyp": 4.98381,
            "nubia_score": 0.50355
        },
        "meteor": 0.37363815877832,
        "bleurt": 0.17617,
        "bertscore": {
            "precision": 0.94325,
            "recall": 0.90199,
            "f1": 0.92216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.243250542201963,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.53333,
            "fmeasure": 0.48485
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.28571,
            "fmeasure": 0.25806
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.46667,
            "fmeasure": 0.42424
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.46667,
            "fmeasure": 0.42424
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7142857142857143
        },
        "bleu": 21.95152,
        "nubia": {
            "semantic_relation": 3.81643,
            "contradiction": 0.08474,
            "irrelevancy": 99.78075,
            "logical_agreement": 0.13452,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.831,
            "nubia_score": 0.54495
        },
        "meteor": 0.2897076397532571,
        "bleurt": -0.26594,
        "bertscore": {
            "precision": 0.85116,
            "recall": 0.92226,
            "f1": 0.86506
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622232,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819114,
        "cond_entropy-2": 0.2540514807621027,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.9161269465882844,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.1219280948873624,
        "cond_entropy-2-nopunct": 0.17961067210860202,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548847,
        "cond_entropy-3-nopunct": -0.021369002496408343,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.066996497013684,
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.56316,
            "fmeasure": 0.57085
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.29678,
            "fmeasure": 0.30105
        },
        "rougeL": {
            "precision": 0.34211,
            "recall": 0.33289,
            "fmeasure": 0.33738
        },
        "rougeLsum": {
            "precision": 0.34211,
            "recall": 0.33289,
            "fmeasure": 0.33738
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.35714285714285715
        },
        "bleu": 9.77445,
        "nubia": {
            "semantic_relation": 3.57589,
            "contradiction": 0.67274,
            "irrelevancy": 37.56882,
            "logical_agreement": 61.75844,
            "grammar_ref": 4.38153,
            "grammar_hyp": 5.90308,
            "nubia_score": 0.45696
        },
        "meteor": 0.20883965084455605,
        "bleurt": -0.75089,
        "bertscore": {
            "precision": 0.79373,
            "recall": 0.782,
            "f1": 0.78782
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0088906840841796,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "bleu": 58.33511,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "meteor": 0.4630505936482093,
        "bleurt": 0.7528,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 9,
        "entropy-1": 3.7216117239699,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.07482944545381269,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 14,
        "unique-3": 13,
        "entropy-3": 3.7735572622751845,
        "cond_entropy-3": -0.04723891230848747,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6168746059562227,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.640223928941851,
        "cond_entropy-2-nopunct": 0.019427754358179165,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.5465935642949384,
        "cond_entropy-3-nopunct": -0.12952780054434962,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8209415231106132,
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.63157,
            "fmeasure": 0.68977
        },
        "rouge2": {
            "precision": 0.53571,
            "recall": 0.43468,
            "fmeasure": 0.47603
        },
        "rougeL": {
            "precision": 0.77083,
            "recall": 0.63157,
            "fmeasure": 0.68977
        },
        "rougeLsum": {
            "precision": 0.77083,
            "recall": 0.63157,
            "fmeasure": 0.68977
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.631578947368421
        },
        "bleu": 16.79464,
        "nubia": {
            "semantic_relation": 3.86997,
            "contradiction": 1.65577,
            "irrelevancy": 17.17399,
            "logical_agreement": 81.17024,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.64973,
            "nubia_score": 0.66701
        },
        "meteor": 0.30045863150781554,
        "bleurt": 0.04349,
        "bertscore": {
            "precision": 0.93505,
            "recall": 0.86964,
            "f1": 0.89632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.349348814341928,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.52381,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.2549,
            "recall": 0.20238,
            "fmeasure": 0.22462
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.4127,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.4127,
            "fmeasure": 0.44444
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "bleu": 16.65262,
        "nubia": {
            "semantic_relation": 3.3317,
            "contradiction": 61.92938,
            "irrelevancy": 11.09929,
            "logical_agreement": 26.97133,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.36154,
            "nubia_score": 0.40296
        },
        "meteor": 0.31261885607038564,
        "bleurt": 0.16422,
        "bertscore": {
            "precision": 0.90738,
            "recall": 0.86444,
            "f1": 0.88539
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.14774469748364955,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.04730571477835684,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 29.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.720049960644813,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.09223106978717507,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.05246741989413545,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.384007422686711,
        "rouge1": {
            "precision": 0.47778,
            "recall": 0.59697,
            "fmeasure": 0.5303
        },
        "rouge2": {
            "precision": 0.16092,
            "recall": 0.20238,
            "fmeasure": 0.17912
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.43636,
            "fmeasure": 0.37762
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.43636,
            "fmeasure": 0.37762
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5789473684210527
        },
        "bleu": 7.80333,
        "nubia": {
            "semantic_relation": 3.55063,
            "contradiction": 0.42941,
            "irrelevancy": 98.98226,
            "logical_agreement": 0.58834,
            "grammar_ref": 4.82125,
            "grammar_hyp": 3.83014,
            "nubia_score": 0.64767
        },
        "meteor": 0.24652736616449578,
        "bleurt": -0.02558,
        "bertscore": {
            "precision": 0.83786,
            "recall": 0.83752,
            "f1": 0.83769
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.462425934400558,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "meteor": 1.0,
        "bleurt": 0.45919,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6042028126043453,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bleu": 15.6197,
        "nubia": {
            "semantic_relation": 4.74574,
            "contradiction": 0.29988,
            "irrelevancy": 0.49995,
            "logical_agreement": 99.20017,
            "grammar_ref": 5.72796,
            "grammar_hyp": 5.20023,
            "nubia_score": 0.96448
        },
        "meteor": 0.29493026749867945,
        "bleurt": 0.62629,
        "bertscore": {
            "precision": 0.89356,
            "recall": 0.89135,
            "f1": 0.89245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.335603496353879,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.83333,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.5,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.5,
            "fmeasure": 0.44444
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.75
        },
        "bleu": 28.78788,
        "nubia": {
            "semantic_relation": 4.44597,
            "contradiction": 1.56644,
            "irrelevancy": 68.84922,
            "logical_agreement": 29.58435,
            "grammar_ref": 4.44512,
            "grammar_hyp": 3.76002,
            "nubia_score": 0.85703
        },
        "meteor": 0.4326424155243092,
        "bleurt": -0.17277,
        "bertscore": {
            "precision": 0.89018,
            "recall": 0.92089,
            "f1": 0.90527
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.315824333525707,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.13452278258006406,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.0346217911747682,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.10174184518886818,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8809750481361862,
        "rouge1": {
            "precision": 0.34286,
            "recall": 0.42222,
            "fmeasure": 0.37391
        },
        "rouge2": {
            "precision": 0.14957,
            "recall": 0.17361,
            "fmeasure": 0.15873
        },
        "rougeL": {
            "precision": 0.33095,
            "recall": 0.4037,
            "fmeasure": 0.35942
        },
        "rougeLsum": {
            "precision": 0.33095,
            "recall": 0.4037,
            "fmeasure": 0.35942
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.4666666666666667
        },
        "bleu": 5.51967,
        "nubia": {
            "semantic_relation": 3.80933,
            "contradiction": 40.0104,
            "irrelevancy": 46.90381,
            "logical_agreement": 13.08579,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.33655,
            "nubia_score": 0.58843
        },
        "meteor": 0.2169606337077368,
        "bleurt": 0.04207,
        "bertscore": {
            "precision": 0.84581,
            "recall": 0.82938,
            "f1": 0.83426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0323250490537745,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.90909,
            "fmeasure": 0.92063
        },
        "rougeL": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.94097,
            "contradiction": 0.61596,
            "irrelevancy": 0.67712,
            "logical_agreement": 98.70691,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.43131,
            "nubia_score": 0.9388
        },
        "meteor": 1.0,
        "bleurt": 0.66206,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1566687205209765,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bleu": 47.0852,
        "nubia": {
            "semantic_relation": 4.8718,
            "contradiction": 0.95834,
            "irrelevancy": 0.67672,
            "logical_agreement": 98.36494,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.45667,
            "nubia_score": 0.93365
        },
        "meteor": 0.506392260197945,
        "bleurt": 0.6985,
        "bertscore": {
            "precision": 0.96017,
            "recall": 0.94001,
            "f1": 0.94998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.625,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "bleu": 59.46036,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.78492,
            "irrelevancy": 0.54406,
            "logical_agreement": 98.67101,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.3113,
            "nubia_score": 1.0
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.90115,
        "bertscore": {
            "precision": 0.97522,
            "recall": 0.97522,
            "f1": 0.97522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6561321200171344,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.7619,
            "fmeasure": 0.68571
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.45,
            "fmeasure": 0.39744
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.7619,
            "fmeasure": 0.68571
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.7619,
            "fmeasure": 0.68571
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.8
        },
        "bleu": 26.08474,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.38778,
            "irrelevancy": 1.16307,
            "logical_agreement": 98.44915,
            "grammar_ref": 7.77345,
            "grammar_hyp": 6.69486,
            "nubia_score": 1.0
        },
        "meteor": 0.5167439403199088,
        "bleurt": 0.78116,
        "bertscore": {
            "precision": 0.95836,
            "recall": 0.97508,
            "f1": 0.96665
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622231,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.24970784767412849,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.821928094887362,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.23688579544383914,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.04492500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.399706486893812,
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.72514,
            "fmeasure": 0.70846
        },
        "rouge2": {
            "precision": 0.50481,
            "recall": 0.5058,
            "fmeasure": 0.47565
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.67565,
            "fmeasure": 0.65199
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.67565,
            "fmeasure": 0.65199
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.8
        },
        "bleu": 29.68826,
        "nubia": {
            "semantic_relation": 4.0533,
            "contradiction": 3.81941,
            "irrelevancy": 44.02322,
            "logical_agreement": 52.15737,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.81657,
            "nubia_score": 0.64872
        },
        "meteor": 0.44870687969456746,
        "bleurt": 0.31909,
        "bertscore": {
            "precision": 0.88758,
            "recall": 0.95193,
            "f1": 0.91554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4052088690524895,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "bleu": 17.31747,
        "nubia": {
            "semantic_relation": 4.40134,
            "contradiction": 0.28662,
            "irrelevancy": 33.62168,
            "logical_agreement": 66.09171,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.63693,
            "nubia_score": 0.63015
        },
        "meteor": 0.37239613830825974,
        "bleurt": -0.22161,
        "bertscore": {
            "precision": 0.89853,
            "recall": 0.89961,
            "f1": 0.89907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 9,
        "unique-1": 6,
        "entropy-1": 3.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 9,
        "unique-2": 7,
        "entropy-2": 3.0957952550009344,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 0.9,
        "vocab_size-3": 9,
        "unique-3": 8,
        "entropy-3": 3.121928094887362,
        "cond_entropy-3": 0.06249647625006499,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.9139770731827523,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.9219280948873623,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.94770277922009,
        "cond_entropy-3-nopunct": 0.07021912877717243,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.247301164185721,
        "rouge1": {
            "precision": 0.81818,
            "recall": 1.0,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 1.0,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 1.0,
            "fmeasure": 0.9
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 1.0,
            "fmeasure": 0.9
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bleu": 80.70557,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.09214,
            "irrelevancy": 2.40864,
            "logical_agreement": 96.49922,
            "grammar_ref": 7.00423,
            "grammar_hyp": 5.98893,
            "nubia_score": 0.9862
        },
        "meteor": 0.5970027534000633,
        "bleurt": 0.74722,
        "bertscore": {
            "precision": 0.97649,
            "recall": 0.99024,
            "f1": 0.98332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 1.0,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.971928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.24178889224043365,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.793345194191514,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.22503715874966068,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.455562553240238,
        "rouge1": {
            "precision": 0.67302,
            "recall": 0.63555,
            "fmeasure": 0.6517
        },
        "rouge2": {
            "precision": 0.37381,
            "recall": 0.36416,
            "fmeasure": 0.36783
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.37573,
            "fmeasure": 0.37652
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.37573,
            "fmeasure": 0.37652
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bleu": 24.7985,
        "nubia": {
            "semantic_relation": 4.53601,
            "contradiction": 0.56734,
            "irrelevancy": 0.74443,
            "logical_agreement": 98.68823,
            "grammar_ref": 4.13564,
            "grammar_hyp": 3.96608,
            "nubia_score": 0.84113
        },
        "meteor": 0.35377869320120503,
        "bleurt": 0.35164,
        "bertscore": {
            "precision": 0.90472,
            "recall": 0.90643,
            "f1": 0.90442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.991511658684707,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.5303,
            "fmeasure": 0.44121
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.28571,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.2857142857142857
        },
        "bleu": 3.7165,
        "nubia": {
            "semantic_relation": 2.61744,
            "contradiction": 0.66647,
            "irrelevancy": 96.66171,
            "logical_agreement": 2.67182,
            "grammar_ref": 5.51883,
            "grammar_hyp": 5.27095,
            "nubia_score": 0.26677
        },
        "meteor": 0.15827338129496404,
        "bleurt": -0.97619,
        "bertscore": {
            "precision": 0.75368,
            "recall": 0.7584,
            "f1": 0.75603
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9432084465906385,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.58824,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.47059,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.47059,
            "fmeasure": 0.53333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "bleu": 12.17136,
        "nubia": {
            "semantic_relation": 3.42094,
            "contradiction": 70.00471,
            "irrelevancy": 15.61719,
            "logical_agreement": 14.3781,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.85331,
            "nubia_score": 0.40189
        },
        "meteor": 0.2712238641079883,
        "bleurt": 0.16103,
        "bertscore": {
            "precision": 0.92944,
            "recall": 0.89227,
            "f1": 0.9103
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2221,
        "total_length": 32761,
        "mean_pred_length": 14.750562809545249,
        "std_pred_length": 4.37039134228117,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.25460150789047953,
        "vocab_size-1": 8341,
        "unique-1": 5991,
        "entropy-1": 9.670952824720942,
        "distinct-2": 0.6522593320235757,
        "vocab_size-2": 19920,
        "unique-2": 17203,
        "entropy-2": 13.460204961634233,
        "cond_entropy-2": 3.367448856578895,
        "distinct-3": 0.8492178396129807,
        "vocab_size-3": 24049,
        "unique-3": 22350,
        "entropy-3": 14.312598786027783,
        "cond_entropy-3": 0.8409577826701636,
        "total_length-nopunct": 28496,
        "mean_pred_length-nopunct": 12.830256641152634,
        "std_pred_length-nopunct": 3.953068143914835,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.2921462661426165,
        "vocab_size-1-nopunct": 8325,
        "unique-1-nopunct": 5990,
        "entropy-1-nopunct": 10.20527600788229,
        "distinct-2-nopunct": 0.6923311132254996,
        "vocab_size-2-nopunct": 18191,
        "unique-2-nopunct": 16047,
        "entropy-2-nopunct": 13.387254043627909,
        "cond_entropy-2-nopunct": 3.3598417650843904,
        "distinct-3-nopunct": 0.8755300573709155,
        "vocab_size-3-nopunct": 21060,
        "unique-3-nopunct": 19750,
        "entropy-3-nopunct": 14.183382570136581,
        "cond_entropy-3-nopunct": 0.8596165394359666,
        "msttr-100": 0.72703,
        "msttr-100_nopunct": 0.78345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.036022681384111,
        "rouge1": {
            "precision": 0.78802,
            "recall": 0.74019,
            "fmeasure": 0.752
        },
        "rouge2": {
            "precision": 0.55358,
            "recall": 0.5202,
            "fmeasure": 0.52787
        },
        "rougeL": {
            "precision": 0.68191,
            "recall": 0.64373,
            "fmeasure": 0.65226
        },
        "rougeLsum": {
            "precision": 0.68191,
            "recall": 0.64373,
            "fmeasure": 0.65226
        },
        "local_recall": {
            "1": 0.2062780269058296,
            "2": 0.42772346368715086,
            "3": 0.774289312702411
        },
        "bleu": 47.02885,
        "nubia": {
            "semantic_relation": 4.27313,
            "contradiction": 8.63992,
            "irrelevancy": 25.968,
            "logical_agreement": 65.39208,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.83568,
            "nubia_score": 0.73851
        },
        "meteor": 0.3976127550557035,
        "bleurt": 0.28687,
        "bertscore": {
            "precision": 0.93284,
            "recall": 0.92577,
            "f1": 0.9277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 14,
        "mean_pred_length": 7.0,
        "std_pred_length": 2.0,
        "median_pred_length": 7.0,
        "min_pred_length": 5,
        "max_pred_length": 9,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 10,
        "unique-2": 8,
        "entropy-2": 3.2516291673878226,
        "cond_entropy-2": -0.05572575466978136,
        "distinct-3": 0.9,
        "vocab_size-3": 9,
        "unique-3": 8,
        "entropy-3": 3.121928094887362,
        "cond_entropy-3": -0.06303440583379406,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.0849625007211556,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.9219280948873623,
        "cond_entropy-2-nopunct": -0.16303440583379405,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.75,
        "cond_entropy-3-nopunct": -0.19692809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.314881869149367,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.63889,
            "fmeasure": 0.73718
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.5006,
            "fmeasure": 0.56346
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.63005,
            "fmeasure": 0.72402
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.63005,
            "fmeasure": 0.72402
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.35714285714285715,
            "3": 1.0
        },
        "bleu": 46.04104,
        "nubia": {
            "semantic_relation": 3.98444,
            "contradiction": 12.63145,
            "irrelevancy": 21.34056,
            "logical_agreement": 66.028,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.92491,
            "nubia_score": 0.61189
        },
        "meteor": 0.40633621987494106,
        "bleurt": 0.13236,
        "bertscore": {
            "precision": 0.96773,
            "recall": 0.89832,
            "f1": 0.93081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 1.0,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 19,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.926733681937769,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.11621100163636434,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9666666666666667,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.840223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.028107102122342922,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.135883073047861,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.8303,
            "fmeasure": 0.80276
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51429,
            "fmeasure": 0.52496
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.64848,
            "fmeasure": 0.64276
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.64848,
            "fmeasure": 0.64276
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "bleu": 57.89305,
        "nubia": {
            "semantic_relation": 4.68696,
            "contradiction": 0.16182,
            "irrelevancy": 48.16425,
            "logical_agreement": 51.67393,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.83693,
            "nubia_score": 0.89017
        },
        "meteor": 0.4584315474282535,
        "bleurt": 0.64725,
        "bertscore": {
            "precision": 0.93496,
            "recall": 0.94656,
            "f1": 0.94056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.02443964427976506,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601983,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4518519732456374,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.57937,
            "fmeasure": 0.56183
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.25263,
            "fmeasure": 0.24512
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.38571,
            "fmeasure": 0.37431
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.38571,
            "fmeasure": 0.37431
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.0,
            "3": 0.8
        },
        "bleu": 24.46706,
        "nubia": {
            "semantic_relation": 3.44405,
            "contradiction": 6.4649,
            "irrelevancy": 80.26208,
            "logical_agreement": 13.27302,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.15656,
            "nubia_score": 0.59263
        },
        "meteor": 0.35194089022029423,
        "bleurt": -0.05762,
        "bertscore": {
            "precision": 0.86211,
            "recall": 0.89798,
            "f1": 0.87968
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8270775813000784,
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "bleu": 51.56627,
        "nubia": {
            "semantic_relation": 4.60306,
            "contradiction": 3.38079,
            "irrelevancy": 59.36379,
            "logical_agreement": 37.25543,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.57301,
            "nubia_score": 0.82616
        },
        "meteor": 0.44463865444394446,
        "bleurt": 0.11695,
        "bertscore": {
            "precision": 0.9178,
            "recall": 0.96872,
            "f1": 0.94258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 18,
        "unique-1": 9,
        "entropy-1": 4.0661089398374815,
        "distinct-2": 0.8076923076923077,
        "vocab_size-2": 21,
        "unique-2": 16,
        "entropy-2": 4.315824333525707,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 0.875,
        "vocab_size-3": 21,
        "unique-3": 18,
        "entropy-3": 4.334962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.697845823084412,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": 0.2002408513582384,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3425373921640102,
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.86364,
            "fmeasure": 0.89931
        },
        "rouge2": {
            "precision": 0.76623,
            "recall": 0.7,
            "fmeasure": 0.72269
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.86364,
            "fmeasure": 0.89931
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.86364,
            "fmeasure": 0.89931
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.782608695652174
        },
        "bleu": 48.60299,
        "nubia": {
            "semantic_relation": 4.18077,
            "contradiction": 38.92699,
            "irrelevancy": 13.55482,
            "logical_agreement": 47.51819,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.61135,
            "nubia_score": 0.62189
        },
        "meteor": 0.3295456566218854,
        "bleurt": 0.35554,
        "bertscore": {
            "precision": 0.97175,
            "recall": 0.91021,
            "f1": 0.93736
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.353995254377449,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.40892,
            "irrelevancy": 0.54064,
            "logical_agreement": 99.05044,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.8105,
            "nubia_score": 0.99007
        },
        "meteor": 1.0,
        "bleurt": 0.89781,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393867,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6618019919399132,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.37607,
            "fmeasure": 0.38444
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.14583,
            "fmeasure": 0.15406
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.37607,
            "fmeasure": 0.38444
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.37607,
            "fmeasure": 0.38444
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "bleu": 12.40421,
        "nubia": {
            "semantic_relation": 2.14857,
            "contradiction": 0.36039,
            "irrelevancy": 84.168,
            "logical_agreement": 15.4716,
            "grammar_ref": 4.60771,
            "grammar_hyp": 6.06996,
            "nubia_score": 0.13187
        },
        "meteor": 0.2383029048841891,
        "bleurt": -0.45448,
        "bertscore": {
            "precision": 0.79135,
            "recall": 0.81602,
            "f1": 0.80329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bleu": 61.0195,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51812,
            "irrelevancy": 0.46692,
            "logical_agreement": 99.01496,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.57356,
            "nubia_score": 0.90444
        },
        "meteor": 0.5230551846972475,
        "bleurt": 0.84839,
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.97723,
            "f1": 0.98438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0824229688160574,
        "rouge1": {
            "precision": 0.85294,
            "recall": 0.725,
            "fmeasure": 0.78378
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.57895,
            "fmeasure": 0.62857
        },
        "rougeL": {
            "precision": 0.79412,
            "recall": 0.675,
            "fmeasure": 0.72973
        },
        "rougeLsum": {
            "precision": 0.79412,
            "recall": 0.675,
            "fmeasure": 0.72973
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75
        },
        "bleu": 51.22072,
        "nubia": {
            "semantic_relation": 4.08852,
            "contradiction": 0.33001,
            "irrelevancy": 0.56936,
            "logical_agreement": 99.10063,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.78611,
            "nubia_score": 0.66805
        },
        "meteor": 0.40638042909497374,
        "bleurt": 0.21615,
        "bertscore": {
            "precision": 0.93446,
            "recall": 0.91157,
            "f1": 0.92288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.724828456273269,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16111,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "bleu": 11.35509,
        "nubia": {
            "semantic_relation": 3.19379,
            "contradiction": 77.42395,
            "irrelevancy": 15.57207,
            "logical_agreement": 7.00397,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.40419,
            "nubia_score": 0.28775
        },
        "meteor": 0.23647970285015268,
        "bleurt": 0.31472,
        "bertscore": {
            "precision": 0.89773,
            "recall": 0.87974,
            "f1": 0.88864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5059972434314313,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.60185,
            "fmeasure": 0.65278
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.60185,
            "fmeasure": 0.65278
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.60185,
            "fmeasure": 0.65278
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5555555555555556
        },
        "bleu": 27.48391,
        "nubia": {
            "semantic_relation": 3.71256,
            "contradiction": 95.47996,
            "irrelevancy": 1.54623,
            "logical_agreement": 2.9738,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50575,
            "nubia_score": 0.35469
        },
        "meteor": 0.3044906212094506,
        "bleurt": 0.3466,
        "bertscore": {
            "precision": 0.95496,
            "recall": 0.93311,
            "f1": 0.94391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.0559581516151235,
        "distinct-2": 0.8636363636363636,
        "vocab_size-2": 19,
        "unique-2": 16,
        "entropy-2": 4.186704345910024,
        "cond_entropy-2": 0.15200091267862392,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 19,
        "unique-3": 17,
        "entropy-3": 4.20184123230257,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8801799226757376,
        "distinct-2-nopunct": 0.85,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.021928094887362,
        "cond_entropy-2-nopunct": 0.1673550472167754,
        "distinct-3-nopunct": 0.8947368421052632,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.037401197654111,
        "cond_entropy-3-nopunct": 0.03126257645096007,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3495543725135084,
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.61275,
            "fmeasure": 0.5358
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.19583,
            "fmeasure": 0.16984
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.42892,
            "fmeasure": 0.37506
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.42892,
            "fmeasure": 0.37506
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6153846153846154
        },
        "bleu": 12.25915,
        "nubia": {
            "semantic_relation": 3.50258,
            "contradiction": 5.22699,
            "irrelevancy": 11.02275,
            "logical_agreement": 83.75027,
            "grammar_ref": 5.85115,
            "grammar_hyp": 3.69391,
            "nubia_score": 0.7426
        },
        "meteor": 0.24292357052068428,
        "bleurt": -0.03038,
        "bertscore": {
            "precision": 0.85354,
            "recall": 0.85536,
            "f1": 0.85445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 1.0,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.675,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 4.562814895472355,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.5671712074141254,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": 0.033108599109837954,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.478232197413861,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.720049960644813,
        "cond_entropy-2-nopunct": 0.2746428744704718,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": 0.04505465518404472,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1826177190985487,
        "rouge1": {
            "precision": 0.63987,
            "recall": 0.81371,
            "fmeasure": 0.71473
        },
        "rouge2": {
            "precision": 0.48363,
            "recall": 0.64141,
            "fmeasure": 0.55077
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.76865,
            "fmeasure": 0.66561
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.76865,
            "fmeasure": 0.66561
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "bleu": 44.52945,
        "nubia": {
            "semantic_relation": 3.79929,
            "contradiction": 2.22813,
            "irrelevancy": 27.50169,
            "logical_agreement": 70.27019,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.14061,
            "nubia_score": 0.63185
        },
        "meteor": 0.4247913342687309,
        "bleurt": -0.36011,
        "bertscore": {
            "precision": 0.85466,
            "recall": 0.94255,
            "f1": 0.894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 2,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 4.0,
        "median_pred_length": 22.0,
        "min_pred_length": 18,
        "max_pred_length": 26,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 30,
        "unique-1": 18,
        "entropy-1": 4.7887549139935,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.106603137064476,
        "cond_entropy-2": 0.3021661613873428,
        "distinct-3": 0.9,
        "vocab_size-3": 36,
        "unique-3": 32,
        "entropy-3": 5.121928094887363,
        "cond_entropy-3": 0.029610672108601993,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.631305423879506,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.28918020093769947,
        "distinct-3-nopunct": 0.8857142857142857,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.900711588373535,
        "cond_entropy-3-nopunct": 0.03411536560173093,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.347844211293734,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.85249,
            "fmeasure": 0.90271
        },
        "rouge2": {
            "precision": 0.84127,
            "recall": 0.74242,
            "fmeasure": 0.78307
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.72955,
            "fmeasure": 0.76634
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.72955,
            "fmeasure": 0.76634
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9714285714285714
        },
        "bleu": 61.93087,
        "nubia": {
            "semantic_relation": 4.5819,
            "contradiction": 9.04773,
            "irrelevancy": 1.88079,
            "logical_agreement": 89.07147,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.74406,
            "nubia_score": 0.77657
        },
        "meteor": 0.49720416284611607,
        "bleurt": 0.44746,
        "bertscore": {
            "precision": 0.96325,
            "recall": 0.94179,
            "f1": 0.94962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.32207203349778,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.70707,
            "fmeasure": 0.60985
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.275,
            "fmeasure": 0.23636
        },
        "rougeL": {
            "precision": 0.42308,
            "recall": 0.56061,
            "fmeasure": 0.48106
        },
        "rougeLsum": {
            "precision": 0.42308,
            "recall": 0.56061,
            "fmeasure": 0.48106
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.8571428571428571
        },
        "bleu": 14.94975,
        "nubia": {
            "semantic_relation": 4.76652,
            "contradiction": 5.09555,
            "irrelevancy": 3.73773,
            "logical_agreement": 91.16672,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.48159,
            "nubia_score": 0.75344
        },
        "meteor": 0.315209769613972,
        "bleurt": 0.43844,
        "bertscore": {
            "precision": 0.86309,
            "recall": 0.89415,
            "f1": 0.87702
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0182899183808685,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.80855,
            "fmeasure": 0.85827
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "bleu": 81.96501,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.48733,
            "irrelevancy": 0.52385,
            "logical_agreement": 98.98882,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.64499,
            "nubia_score": 0.95124
        },
        "meteor": 0.5534770148308852,
        "bleurt": 0.72022,
        "bertscore": {
            "precision": 0.99739,
            "recall": 0.98801,
            "f1": 0.99268
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2182,
        "mean_pred_length": 20.58490566037736,
        "std_pred_length": 4.12737735844744,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.38130155820348305,
        "vocab_size-1": 832,
        "unique-1": 605,
        "entropy-1": 7.962904308716023,
        "distinct-2": 0.8020231213872833,
        "vocab_size-2": 1665,
        "unique-2": 1476,
        "entropy-2": 10.446853352559462,
        "cond_entropy-2": 2.300165193190029,
        "distinct-3": 0.9421319796954315,
        "vocab_size-3": 1856,
        "unique-3": 1771,
        "entropy-3": 10.810957014623916,
        "cond_entropy-3": 0.38260391553017764,
        "total_length-nopunct": 2029,
        "mean_pred_length-nopunct": 19.141509433962263,
        "std_pred_length-nopunct": 3.861856722387642,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4066042385411533,
        "vocab_size-1-nopunct": 825,
        "unique-1-nopunct": 604,
        "entropy-1-nopunct": 8.075821756141304,
        "distinct-2-nopunct": 0.8044721788871555,
        "vocab_size-2-nopunct": 1547,
        "unique-2-nopunct": 1379,
        "entropy-2-nopunct": 10.33453894326311,
        "cond_entropy-2-nopunct": 2.370969224557477,
        "distinct-3-nopunct": 0.9471656576774904,
        "vocab_size-3-nopunct": 1721,
        "unique-3-nopunct": 1649,
        "entropy-3-nopunct": 10.706379330573315,
        "cond_entropy-3-nopunct": 0.388354389844632,
        "msttr-100": 0.67714,
        "msttr-100_nopunct": 0.7035,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.469169104803264,
        "rouge1": {
            "precision": 0.33465,
            "recall": 0.30266,
            "fmeasure": 0.31186
        },
        "rouge2": {
            "precision": 0.08837,
            "recall": 0.08173,
            "fmeasure": 0.0829
        },
        "rougeL": {
            "precision": 0.25477,
            "recall": 0.23257,
            "fmeasure": 0.23822
        },
        "rougeLsum": {
            "precision": 0.25477,
            "recall": 0.23257,
            "fmeasure": 0.23822
        },
        "local_recall": {
            "1": 0.2757816145590294
        },
        "bleu": 4.76724,
        "nubia": {
            "semantic_relation": 2.26541,
            "contradiction": 32.25178,
            "irrelevancy": 62.18664,
            "logical_agreement": 5.56158,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.52486,
            "nubia_score": 0.2915
        },
        "meteor": 0.1262439221259009,
        "bleurt": -0.51037,
        "bertscore": {
            "precision": 0.80715,
            "recall": 0.7917,
            "f1": 0.7991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7456398254417365,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.8963,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.49537,
            "fmeasure": 0.51716
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "bleu": 55.62833,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18796,
            "irrelevancy": 0.48475,
            "logical_agreement": 99.32729,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.58474,
            "nubia_score": 0.95724
        },
        "meteor": 0.46736318340128513,
        "bleurt": 0.70029,
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95351,
            "f1": 0.963
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2239,
        "mean_pred_length": 21.12264150943396,
        "std_pred_length": 4.693839459492039,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 38,
        "distinct-1": 0.36221527467619474,
        "vocab_size-1": 811,
        "unique-1": 568,
        "entropy-1": 7.849114809693312,
        "distinct-2": 0.759493670886076,
        "vocab_size-2": 1620,
        "unique-2": 1391,
        "entropy-2": 10.32572732727656,
        "cond_entropy-2": 2.309070916542447,
        "distinct-3": 0.9210656142081894,
        "vocab_size-3": 1867,
        "unique-3": 1753,
        "entropy-3": 10.800587511643124,
        "cond_entropy-3": 0.49426186659050847,
        "total_length-nopunct": 2086,
        "mean_pred_length-nopunct": 19.67924528301887,
        "std_pred_length-nopunct": 4.50062295438888,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.38494726749760305,
        "vocab_size-1-nopunct": 803,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 7.934772024600684,
        "distinct-2-nopunct": 0.76010101010101,
        "vocab_size-2-nopunct": 1505,
        "unique-2-nopunct": 1298,
        "entropy-2-nopunct": 10.210376401371471,
        "cond_entropy-2-nopunct": 2.3868572956213066,
        "distinct-3-nopunct": 0.9252934898612594,
        "vocab_size-3-nopunct": 1734,
        "unique-3-nopunct": 1631,
        "entropy-3-nopunct": 10.700902708074366,
        "cond_entropy-3-nopunct": 0.5099808624886932,
        "msttr-100": 0.67136,
        "msttr-100_nopunct": 0.6765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.6006613547054216,
        "rouge1": {
            "precision": 0.34687,
            "recall": 0.31499,
            "fmeasure": 0.32357
        },
        "rouge2": {
            "precision": 0.10634,
            "recall": 0.09538,
            "fmeasure": 0.09792
        },
        "rougeL": {
            "precision": 0.25879,
            "recall": 0.23788,
            "fmeasure": 0.24281
        },
        "rougeLsum": {
            "precision": 0.25879,
            "recall": 0.23788,
            "fmeasure": 0.24281
        },
        "local_recall": {
            "1": 0.2824884792626728
        },
        "bleu": 5.04074,
        "nubia": {
            "semantic_relation": 2.40389,
            "contradiction": 32.00746,
            "irrelevancy": 59.23489,
            "logical_agreement": 8.75766,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.43149,
            "nubia_score": 0.31778
        },
        "meteor": 0.1295535143818633,
        "bleurt": -0.45622,
        "bertscore": {
            "precision": 0.81371,
            "recall": 0.79922,
            "f1": 0.80612
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10393,
        "mean_pred_length": 20.786,
        "std_pred_length": 4.631220573455771,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.24526123352256327,
        "vocab_size-1": 2549,
        "unique-1": 1581,
        "entropy-1": 8.591945479624314,
        "distinct-2": 0.6508642474476903,
        "vocab_size-2": 6439,
        "unique-2": 5336,
        "entropy-2": 11.986515318929143,
        "cond_entropy-2": 3.1815704848096598,
        "distinct-3": 0.8596827424677952,
        "vocab_size-3": 8075,
        "unique-3": 7379,
        "entropy-3": 12.815743521724292,
        "cond_entropy-3": 0.8502736052827399,
        "total_length-nopunct": 9661,
        "mean_pred_length-nopunct": 19.322,
        "std_pred_length-nopunct": 4.417048335710172,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.26291274195217884,
        "vocab_size-1-nopunct": 2540,
        "unique-1-nopunct": 1581,
        "entropy-1-nopunct": 8.73855011604115,
        "distinct-2-nopunct": 0.6564785503765964,
        "vocab_size-2-nopunct": 6014,
        "unique-2-nopunct": 5002,
        "entropy-2-nopunct": 11.888804029585819,
        "cond_entropy-2-nopunct": 3.291037365303906,
        "distinct-3-nopunct": 0.8680290959473502,
        "vocab_size-3-nopunct": 7518,
        "unique-3-nopunct": 6892,
        "entropy-3-nopunct": 12.730124626910621,
        "cond_entropy-3-nopunct": 0.8651637109172093,
        "msttr-100": 0.67777,
        "msttr-100_nopunct": 0.69562,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.1561101869985344,
        "rouge1": {
            "precision": 0.37344,
            "recall": 0.33911,
            "fmeasure": 0.34781
        },
        "rouge2": {
            "precision": 0.1234,
            "recall": 0.11225,
            "fmeasure": 0.11481
        },
        "rougeL": {
            "precision": 0.28182,
            "recall": 0.25719,
            "fmeasure": 0.26303
        },
        "rougeLsum": {
            "precision": 0.28182,
            "recall": 0.25719,
            "fmeasure": 0.26303
        },
        "local_recall": {
            "1": 0.31517234408167394
        },
        "bleu": 7.53008,
        "nubia": {
            "semantic_relation": 2.4496,
            "contradiction": 29.04461,
            "irrelevancy": 61.84892,
            "logical_agreement": 9.10647,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.53073,
            "nubia_score": 0.3258
        },
        "meteor": 0.1455179601889616,
        "bleurt": -0.4468,
        "bertscore": {
            "precision": 0.81726,
            "recall": 0.80285,
            "f1": 0.80966
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2202,
        "mean_pred_length": 20.77358490566038,
        "std_pred_length": 5.023122044404228,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.3773841961852861,
        "vocab_size-1": 831,
        "unique-1": 618,
        "entropy-1": 7.916389438575487,
        "distinct-2": 0.7786259541984732,
        "vocab_size-2": 1632,
        "unique-2": 1427,
        "entropy-2": 10.381816088774793,
        "cond_entropy-2": 2.2864145410416685,
        "distinct-3": 0.9266331658291457,
        "vocab_size-3": 1844,
        "unique-3": 1750,
        "entropy-3": 10.778969039599874,
        "cond_entropy-3": 0.41200750245686607,
        "total_length-nopunct": 2054,
        "mean_pred_length-nopunct": 19.37735849056604,
        "std_pred_length-nopunct": 4.737352238326287,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.4011684518013632,
        "vocab_size-1-nopunct": 824,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 8.007216264857203,
        "distinct-2-nopunct": 0.7797741273100616,
        "vocab_size-2-nopunct": 1519,
        "unique-2-nopunct": 1335,
        "entropy-2-nopunct": 10.27030951283086,
        "cond_entropy-2-nopunct": 2.3780032950886505,
        "distinct-3-nopunct": 0.9277958740499457,
        "vocab_size-3-nopunct": 1709,
        "unique-3-nopunct": 1622,
        "entropy-3-nopunct": 10.671236640390807,
        "cond_entropy-3-nopunct": 0.4215225499909825,
        "msttr-100": 0.68455,
        "msttr-100_nopunct": 0.696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.5596135934912354,
        "rouge1": {
            "precision": 0.33775,
            "recall": 0.30225,
            "fmeasure": 0.3114
        },
        "rouge2": {
            "precision": 0.1001,
            "recall": 0.08737,
            "fmeasure": 0.09136
        },
        "rougeL": {
            "precision": 0.25434,
            "recall": 0.23052,
            "fmeasure": 0.23545
        },
        "rougeLsum": {
            "precision": 0.25434,
            "recall": 0.23052,
            "fmeasure": 0.23545
        },
        "local_recall": {
            "1": 0.28169014084507044
        },
        "bleu": 5.42984,
        "nubia": {
            "semantic_relation": 2.20868,
            "contradiction": 36.92469,
            "irrelevancy": 51.75483,
            "logical_agreement": 11.32048,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.53945,
            "nubia_score": 0.27428
        },
        "meteor": 0.12563147038062447,
        "bleurt": -0.50419,
        "bertscore": {
            "precision": 0.80861,
            "recall": 0.78992,
            "f1": 0.79877
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 737,
        "total_length": 14940,
        "mean_pred_length": 20.27137042062415,
        "std_pred_length": 4.088857997416002,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 41,
        "distinct-1": 0.009437751004016065,
        "vocab_size-1": 141,
        "unique-1": 15,
        "entropy-1": 5.638571686179253,
        "distinct-2": 0.029641625008800958,
        "vocab_size-2": 421,
        "unique-2": 73,
        "entropy-2": 7.16454791494639,
        "cond_entropy-2": 1.4192333592946351,
        "distinct-3": 0.054210604485370566,
        "vocab_size-3": 730,
        "unique-3": 157,
        "entropy-3": 8.037979073753903,
        "cond_entropy-3": 0.9012019885489267,
        "total_length-nopunct": 13660,
        "mean_pred_length-nopunct": 18.53459972862958,
        "std_pred_length-nopunct": 3.714610068438229,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.010175695461200585,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 5.689724665312861,
        "distinct-2-nopunct": 0.031184709432794243,
        "vocab_size-2-nopunct": 403,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 7.114301239671729,
        "cond_entropy-2-nopunct": 1.4832598120762743,
        "distinct-3-nopunct": 0.059002133595929755,
        "vocab_size-3-nopunct": 719,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 8.060250558608015,
        "cond_entropy-3-nopunct": 0.9395748411240519,
        "msttr-100": 0.25597,
        "msttr-100_nopunct": 0.25559,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.14854468664997,
        "rouge1": {
            "precision": 0.75071,
            "recall": 0.71312,
            "fmeasure": 0.71913
        },
        "rouge2": {
            "precision": 0.47853,
            "recall": 0.45268,
            "fmeasure": 0.45707
        },
        "rougeL": {
            "precision": 0.57613,
            "recall": 0.54708,
            "fmeasure": 0.55186
        },
        "rougeLsum": {
            "precision": 0.57613,
            "recall": 0.54708,
            "fmeasure": 0.55186
        },
        "local_recall": {
            "1": 0.7004926108374384
        },
        "bleu": 33.20788,
        "nubia": {
            "semantic_relation": 4.29263,
            "contradiction": 2.39327,
            "irrelevancy": 17.16397,
            "logical_agreement": 80.44275,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.50964,
            "nubia_score": 0.79366
        },
        "meteor": 0.36637862273846206,
        "bleurt": 0.24023,
        "bertscore": {
            "precision": 0.9243,
            "recall": 0.9085,
            "f1": 0.9159
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 1369,
        "total_length": 24551,
        "mean_pred_length": 17.933528122717313,
        "std_pred_length": 5.550942842621477,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 68,
        "distinct-1": 0.2502545721151888,
        "vocab_size-1": 6144,
        "unique-1": 4365,
        "entropy-1": 9.464704791929645,
        "distinct-2": 0.6419635924424122,
        "vocab_size-2": 14882,
        "unique-2": 12703,
        "entropy-2": 13.07698834386085,
        "cond_entropy-2": 3.2986653404625357,
        "distinct-3": 0.8370696373722092,
        "vocab_size-3": 18259,
        "unique-3": 16814,
        "entropy-3": 13.89398615986842,
        "cond_entropy-3": 0.8121208973892208,
        "total_length-nopunct": 21398,
        "mean_pred_length-nopunct": 15.630387143900657,
        "std_pred_length-nopunct": 4.697494467203102,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.28647537153004954,
        "vocab_size-1-nopunct": 6130,
        "unique-1-nopunct": 4364,
        "entropy-1-nopunct": 9.941012307819983,
        "distinct-2-nopunct": 0.6822107943481951,
        "vocab_size-2-nopunct": 13664,
        "unique-2-nopunct": 11949,
        "entropy-2-nopunct": 12.99527475869136,
        "cond_entropy-2-nopunct": 3.18573284668357,
        "distinct-3-nopunct": 0.8606645230439443,
        "vocab_size-3-nopunct": 16060,
        "unique-3-nopunct": 14966,
        "entropy-3-nopunct": 13.749575345072666,
        "cond_entropy-3-nopunct": 0.8042639281000465,
        "msttr-100": 0.71522,
        "msttr-100_nopunct": 0.77033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 9.585468694068298,
        "rouge1": {
            "precision": 0.76613,
            "recall": 0.71757,
            "fmeasure": 0.73021
        },
        "rouge2": {
            "precision": 0.52243,
            "recall": 0.49179,
            "fmeasure": 0.49901
        },
        "rougeL": {
            "precision": 0.64761,
            "recall": 0.61136,
            "fmeasure": 0.61941
        },
        "rougeLsum": {
            "precision": 0.64761,
            "recall": 0.61136,
            "fmeasure": 0.61941
        },
        "local_recall": {
            "1": 0.21732620320855614,
            "2": 0.4175421451258246,
            "3": 0.7593431141701382
        },
        "bleu": 45.60684,
        "nubia": {
            "semantic_relation": 4.14341,
            "contradiction": 13.04338,
            "irrelevancy": 27.69457,
            "logical_agreement": 59.26205,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.47498,
            "nubia_score": 0.71136
        },
        "meteor": 0.38803694626387314,
        "bleurt": 0.23566,
        "bertscore": {
            "precision": 0.92761,
            "recall": 0.91957,
            "f1": 0.92201
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 483,
        "total_length": 10200,
        "mean_pred_length": 21.11801242236025,
        "std_pred_length": 5.507433954370261,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 42,
        "distinct-1": 0.30833333333333335,
        "vocab_size-1": 3145,
        "unique-1": 2303,
        "entropy-1": 9.120949070608916,
        "distinct-2": 0.7114335700319029,
        "vocab_size-2": 6913,
        "unique-2": 5986,
        "entropy-2": 12.214596420138996,
        "cond_entropy-2": 2.859170360073471,
        "distinct-3": 0.8909465020576132,
        "vocab_size-3": 8227,
        "unique-3": 7699,
        "entropy-3": 12.880395838942404,
        "cond_entropy-3": 0.6643868755007554,
        "total_length-nopunct": 8950,
        "mean_pred_length-nopunct": 18.530020703933747,
        "std_pred_length-nopunct": 4.893972017837106,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.3500558659217877,
        "vocab_size-1-nopunct": 3133,
        "unique-1-nopunct": 2301,
        "entropy-1-nopunct": 9.505296321227714,
        "distinct-2-nopunct": 0.7421755049013818,
        "vocab_size-2-nopunct": 6284,
        "unique-2-nopunct": 5550,
        "entropy-2-nopunct": 12.106237509354463,
        "cond_entropy-2-nopunct": 2.698916578720003,
        "distinct-3-nopunct": 0.904559118236473,
        "vocab_size-3-nopunct": 7222,
        "unique-3-nopunct": 6831,
        "entropy-3-nopunct": 12.70285970627544,
        "cond_entropy-3-nopunct": 0.6256102780397443,
        "msttr-100": 0.71206,
        "msttr-100_nopunct": 0.76169,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.723405995560437,
        "rouge1": {
            "precision": 0.75366,
            "recall": 0.72055,
            "fmeasure": 0.72637
        },
        "rouge2": {
            "precision": 0.50329,
            "recall": 0.48146,
            "fmeasure": 0.4849
        },
        "rougeL": {
            "precision": 0.61387,
            "recall": 0.58738,
            "fmeasure": 0.59151
        },
        "rougeLsum": {
            "precision": 0.61387,
            "recall": 0.58738,
            "fmeasure": 0.59151
        },
        "local_recall": {
            "1": 0.2286212914485166,
            "2": 0.4167741935483871,
            "3": 0.7526269702276708
        },
        "bleu": 41.32702,
        "nubia": {
            "semantic_relation": 4.06473,
            "contradiction": 13.03895,
            "irrelevancy": 33.88117,
            "logical_agreement": 53.07988,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.26425,
            "nubia_score": 0.69746
        },
        "meteor": 0.377921188913656,
        "bleurt": 0.16787,
        "bertscore": {
            "precision": 0.92059,
            "recall": 0.916,
            "f1": 0.91661
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 5383,
        "mean_pred_length": 14.994428969359332,
        "std_pred_length": 7.0101376766048356,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 60,
        "distinct-1": 0.3852870146758313,
        "vocab_size-1": 2074,
        "unique-1": 1574,
        "entropy-1": 8.904740822477796,
        "distinct-2": 0.8485270700636943,
        "vocab_size-2": 4263,
        "unique-2": 3954,
        "entropy-2": 11.80090700037757,
        "cond_entropy-2": 2.534226796506092,
        "distinct-3": 0.9682743837084673,
        "vocab_size-3": 4517,
        "unique-3": 4438,
        "entropy-3": 12.098853225551231,
        "cond_entropy-3": 0.3197084836565822,
        "total_length-nopunct": 4802,
        "mean_pred_length-nopunct": 13.376044568245126,
        "std_pred_length-nopunct": 6.21800646592378,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.43002915451895046,
        "vocab_size-1-nopunct": 2065,
        "unique-1-nopunct": 1572,
        "entropy-1-nopunct": 9.252728333795297,
        "distinct-2-nopunct": 0.8586540625703354,
        "vocab_size-2-nopunct": 3815,
        "unique-2-nopunct": 3563,
        "entropy-2-nopunct": 11.651595217813568,
        "cond_entropy-2-nopunct": 2.5846295771637227,
        "distinct-3-nopunct": 0.9774730656219393,
        "vocab_size-3-nopunct": 3992,
        "unique-3-nopunct": 3932,
        "entropy-3-nopunct": 11.94164090825444,
        "cond_entropy-3-nopunct": 0.32280653447918695,
        "msttr-100": 0.71623,
        "msttr-100_nopunct": 0.76417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "nist": 9.518763184086424,
        "rouge1": {
            "precision": 0.81805,
            "recall": 0.70356,
            "fmeasure": 0.73856
        },
        "rouge2": {
            "precision": 0.65043,
            "recall": 0.54915,
            "fmeasure": 0.5763
        },
        "rougeL": {
            "precision": 0.77801,
            "recall": 0.6741,
            "fmeasure": 0.70358
        },
        "rougeLsum": {
            "precision": 0.77801,
            "recall": 0.6741,
            "fmeasure": 0.70358
        },
        "local_recall": {
            "1": 0.03884057971014493,
            "2": 0.12225274725274725,
            "3": 0.22743259085580306,
            "4": 0.34560906515580736,
            "5": 0.4448871181938911,
            "6": 0.49507389162561577,
            "7": 0.6187214611872146,
            "8": 0.6964285714285714,
            "9": 0.8266187050359712
        },
        "bleu": 63.04384,
        "sari": 45.40031,
        "nubia": {
            "semantic_relation": 3.82596,
            "contradiction": 4.42807,
            "irrelevancy": 22.75018,
            "logical_agreement": 72.82175,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.11987,
            "nubia_score": 0.55277
        },
        "meteor": 0.39171757578496225,
        "bleurt": 0.04429,
        "bertscore": {
            "precision": 0.94904,
            "recall": 0.92549,
            "f1": 0.93284
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "total_length": 9942,
        "mean_pred_length": 21.19829424307036,
        "std_pred_length": 5.504128831214484,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.11144638905652786,
        "vocab_size-1": 1108,
        "unique-1": 551,
        "entropy-1": 7.671468764933079,
        "distinct-2": 0.29050987015728913,
        "vocab_size-2": 2752,
        "unique-2": 1645,
        "entropy-2": 10.080112844469273,
        "cond_entropy-2": 2.2801456300803826,
        "distinct-3": 0.4512438916037317,
        "vocab_size-3": 4063,
        "unique-3": 2807,
        "entropy-3": 11.134887644918038,
        "cond_entropy-3": 1.1025307450166284,
        "total_length-nopunct": 8877,
        "mean_pred_length-nopunct": 18.927505330490405,
        "std_pred_length-nopunct": 4.930548605872945,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.12380308662836544,
        "vocab_size-1-nopunct": 1099,
        "unique-1-nopunct": 550,
        "entropy-1-nopunct": 7.819768901699995,
        "distinct-2-nopunct": 0.30566127497621315,
        "vocab_size-2-nopunct": 2570,
        "unique-2-nopunct": 1563,
        "entropy-2-nopunct": 10.021156449622977,
        "cond_entropy-2-nopunct": 2.313264646231936,
        "distinct-3-nopunct": 0.47676029726665825,
        "vocab_size-3-nopunct": 3785,
        "unique-3-nopunct": 2660,
        "entropy-3-nopunct": 11.107246042095666,
        "cond_entropy-3-nopunct": 1.1339976711107445,
        "msttr-100": 0.6801,
        "msttr-100_nopunct": 0.69477,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.535442384318594,
        "rouge1": {
            "precision": 0.66463,
            "recall": 0.64308,
            "fmeasure": 0.64268
        },
        "rouge2": {
            "precision": 0.43303,
            "recall": 0.42043,
            "fmeasure": 0.41952
        },
        "rougeL": {
            "precision": 0.57039,
            "recall": 0.55478,
            "fmeasure": 0.55339
        },
        "rougeLsum": {
            "precision": 0.57039,
            "recall": 0.55478,
            "fmeasure": 0.55339
        },
        "local_recall": {
            "1": 0.6265199768384482
        },
        "bleu": 33.68767,
        "nubia": {
            "semantic_relation": 4.23306,
            "contradiction": 9.15112,
            "irrelevancy": 16.41621,
            "logical_agreement": 74.43267,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.73589,
            "nubia_score": 0.72652
        },
        "meteor": 0.3385207565528901,
        "bleurt": -0.05927,
        "bertscore": {
            "precision": 0.89031,
            "recall": 0.88275,
            "f1": 0.88618
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2076,
        "mean_pred_length": 19.58490566037736,
        "std_pred_length": 5.452830188679244,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.39065510597302505,
        "vocab_size-1": 811,
        "unique-1": 611,
        "entropy-1": 7.862578892448635,
        "distinct-2": 0.798984771573604,
        "vocab_size-2": 1574,
        "unique-2": 1409,
        "entropy-2": 10.308284088940011,
        "cond_entropy-2": 2.2577089910351087,
        "distinct-3": 0.9345493562231759,
        "vocab_size-3": 1742,
        "unique-3": 1660,
        "entropy-3": 10.709027146849815,
        "cond_entropy-3": 0.41932077786220995,
        "total_length-nopunct": 1930,
        "mean_pred_length-nopunct": 18.20754716981132,
        "std_pred_length-nopunct": 4.982454084144198,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.4155440414507772,
        "vocab_size-1-nopunct": 802,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 7.964253487531556,
        "distinct-2-nopunct": 0.7987938596491229,
        "vocab_size-2-nopunct": 1457,
        "unique-2-nopunct": 1313,
        "entropy-2-nopunct": 10.182694702723426,
        "cond_entropy-2-nopunct": 2.347148910231547,
        "distinct-3-nopunct": 0.9371362048894063,
        "vocab_size-3-nopunct": 1610,
        "unique-3-nopunct": 1539,
        "entropy-3-nopunct": 10.5960710822528,
        "cond_entropy-3-nopunct": 0.43158801763096294,
        "msttr-100": 0.679,
        "msttr-100_nopunct": 0.69316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.1717610967114753,
        "rouge1": {
            "precision": 0.3063,
            "recall": 0.26717,
            "fmeasure": 0.27801
        },
        "rouge2": {
            "precision": 0.08696,
            "recall": 0.07484,
            "fmeasure": 0.07884
        },
        "rougeL": {
            "precision": 0.2321,
            "recall": 0.20421,
            "fmeasure": 0.21168
        },
        "rougeLsum": {
            "precision": 0.2321,
            "recall": 0.20421,
            "fmeasure": 0.21168
        },
        "local_recall": {
            "1": 0.24075875486381323
        },
        "bleu": 4.68519,
        "nubia": {
            "semantic_relation": 2.07291,
            "contradiction": 35.98766,
            "irrelevancy": 57.22442,
            "logical_agreement": 6.78792,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.58915,
            "nubia_score": 0.26155
        },
        "meteor": 0.11174582552490722,
        "bleurt": -0.58964,
        "bertscore": {
            "precision": 0.79802,
            "recall": 0.78052,
            "f1": 0.78885
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "total_length": 8104,
        "mean_pred_length": 24.1910447761194,
        "std_pred_length": 4.689707095308421,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 39,
        "distinct-1": 0.10513326752221125,
        "vocab_size-1": 852,
        "unique-1": 432,
        "entropy-1": 7.353323484961926,
        "distinct-2": 0.26631484103488223,
        "vocab_size-2": 2069,
        "unique-2": 1227,
        "entropy-2": 9.595912783460687,
        "cond_entropy-2": 2.147227137893489,
        "distinct-3": 0.4167339252085015,
        "vocab_size-3": 3098,
        "unique-3": 2080,
        "entropy-3": 10.665053915576264,
        "cond_entropy-3": 1.048295309258388,
        "total_length-nopunct": 7394,
        "mean_pred_length-nopunct": 22.071641791044776,
        "std_pred_length-nopunct": 4.168209679393281,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.11360562618339194,
        "vocab_size-1-nopunct": 840,
        "unique-1-nopunct": 430,
        "entropy-1-nopunct": 7.39799288378973,
        "distinct-2-nopunct": 0.2776597251735373,
        "vocab_size-2-nopunct": 1960,
        "unique-2-nopunct": 1172,
        "entropy-2-nopunct": 9.567180716702072,
        "cond_entropy-2-nopunct": 2.1748314655496093,
        "distinct-3-nopunct": 0.432034503271862,
        "vocab_size-3-nopunct": 2905,
        "unique-3-nopunct": 1980,
        "entropy-3-nopunct": 10.593857762054004,
        "cond_entropy-3-nopunct": 1.0587192251676623,
        "msttr-100": 0.64272,
        "msttr-100_nopunct": 0.6374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.7224764537425115,
        "rouge1": {
            "precision": 0.7666,
            "recall": 0.66605,
            "fmeasure": 0.70538
        },
        "rouge2": {
            "precision": 0.52528,
            "recall": 0.45483,
            "fmeasure": 0.48213
        },
        "rougeL": {
            "precision": 0.64452,
            "recall": 0.56136,
            "fmeasure": 0.59377
        },
        "rougeLsum": {
            "precision": 0.64452,
            "recall": 0.56136,
            "fmeasure": 0.59377
        },
        "local_recall": {
            "1": 0.6536305732484077
        },
        "bleu": 37.88946,
        "nubia": {
            "semantic_relation": 4.42239,
            "contradiction": 2.13416,
            "irrelevancy": 5.9421,
            "logical_agreement": 91.92374,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.45768,
            "nubia_score": 0.78915
        },
        "meteor": 0.3659780538564404,
        "bleurt": 0.01803,
        "bertscore": {
            "precision": 0.91144,
            "recall": 0.8901,
            "f1": 0.90039
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10401,
        "mean_pred_length": 20.802,
        "std_pred_length": 4.315877199365153,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 42,
        "distinct-1": 0.23565041822901645,
        "vocab_size-1": 2451,
        "unique-1": 1518,
        "entropy-1": 8.522963384344852,
        "distinct-2": 0.6354913645086355,
        "vocab_size-2": 6292,
        "unique-2": 5204,
        "entropy-2": 11.890836856592927,
        "cond_entropy-2": 3.1604857999552656,
        "distinct-3": 0.8455483459206468,
        "vocab_size-3": 7949,
        "unique-3": 7264,
        "entropy-3": 12.752911629636344,
        "cond_entropy-3": 0.8812655070260819,
        "total_length-nopunct": 9683,
        "mean_pred_length-nopunct": 19.366,
        "std_pred_length-nopunct": 4.1211702221577795,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.2520912940204482,
        "vocab_size-1-nopunct": 2441,
        "unique-1-nopunct": 1517,
        "entropy-1-nopunct": 8.661899155439128,
        "distinct-2-nopunct": 0.6409670042469782,
        "vocab_size-2-nopunct": 5886,
        "unique-2-nopunct": 4889,
        "entropy-2-nopunct": 11.79493957636926,
        "cond_entropy-2-nopunct": 3.2667064025820944,
        "distinct-3-nopunct": 0.8539675227455948,
        "vocab_size-3-nopunct": 7415,
        "unique-3-nopunct": 6797,
        "entropy-3-nopunct": 12.671002753199335,
        "cond_entropy-3-nopunct": 0.9009106837559434,
        "msttr-100": 0.67558,
        "msttr-100_nopunct": 0.69135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.064533191790737,
        "rouge1": {
            "precision": 0.37013,
            "recall": 0.33561,
            "fmeasure": 0.34517
        },
        "rouge2": {
            "precision": 0.11779,
            "recall": 0.10714,
            "fmeasure": 0.1097
        },
        "rougeL": {
            "precision": 0.27443,
            "recall": 0.24984,
            "fmeasure": 0.25645
        },
        "rougeLsum": {
            "precision": 0.27443,
            "recall": 0.24984,
            "fmeasure": 0.25645
        },
        "local_recall": {
            "1": 0.30893423137876386
        },
        "bleu": 6.8522,
        "nubia": {
            "semantic_relation": 2.43756,
            "contradiction": 28.2286,
            "irrelevancy": 62.24332,
            "logical_agreement": 9.52808,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.4827,
            "nubia_score": 0.32775
        },
        "meteor": 0.14299005572164683,
        "bleurt": -0.44939,
        "bertscore": {
            "precision": 0.81721,
            "recall": 0.80161,
            "f1": 0.80902
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10303,
        "mean_pred_length": 20.606,
        "std_pred_length": 4.558811687271147,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.23915364456954286,
        "vocab_size-1": 2464,
        "unique-1": 1556,
        "entropy-1": 8.51587566331266,
        "distinct-2": 0.6386820361113945,
        "vocab_size-2": 6261,
        "unique-2": 5193,
        "entropy-2": 11.892798875581235,
        "cond_entropy-2": 3.165208273486726,
        "distinct-3": 0.8482210039772117,
        "vocab_size-3": 7891,
        "unique-3": 7227,
        "entropy-3": 12.74821777233792,
        "cond_entropy-3": 0.8809521625556712,
        "total_length-nopunct": 9615,
        "mean_pred_length-nopunct": 19.23,
        "std_pred_length-nopunct": 4.3230891732648775,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.25533021320852833,
        "vocab_size-1-nopunct": 2455,
        "unique-1-nopunct": 1556,
        "entropy-1-nopunct": 8.655681578711892,
        "distinct-2-nopunct": 0.6416895227646736,
        "vocab_size-2-nopunct": 5849,
        "unique-2-nopunct": 4873,
        "entropy-2-nopunct": 11.788694631053474,
        "cond_entropy-2-nopunct": 3.2727174127860756,
        "distinct-3-nopunct": 0.8550203134068485,
        "vocab_size-3-nopunct": 7366,
        "unique-3-nopunct": 6768,
        "entropy-3-nopunct": 12.663543197432944,
        "cond_entropy-3-nopunct": 0.903529979093291,
        "msttr-100": 0.67515,
        "msttr-100_nopunct": 0.69083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.0861422848699536,
        "rouge1": {
            "precision": 0.36566,
            "recall": 0.33085,
            "fmeasure": 0.3407
        },
        "rouge2": {
            "precision": 0.11949,
            "recall": 0.10843,
            "fmeasure": 0.11127
        },
        "rougeL": {
            "precision": 0.27656,
            "recall": 0.25044,
            "fmeasure": 0.25765
        },
        "rougeLsum": {
            "precision": 0.27656,
            "recall": 0.25044,
            "fmeasure": 0.25765
        },
        "local_recall": {
            "1": 0.30665073675826365
        },
        "bleu": 6.92745,
        "nubia": {
            "semantic_relation": 2.35655,
            "contradiction": 30.71651,
            "irrelevancy": 59.79892,
            "logical_agreement": 9.48457,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.5396,
            "nubia_score": 0.31276
        },
        "meteor": 0.1428463278758879,
        "bleurt": -0.45919,
        "bertscore": {
            "precision": 0.81784,
            "recall": 0.80147,
            "f1": 0.80925
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "total_length": 7223,
        "mean_pred_length": 28.21484375,
        "std_pred_length": 7.444897474988218,
        "median_pred_length": 29.0,
        "min_pred_length": 13,
        "max_pred_length": 50,
        "distinct-1": 0.07254603350408417,
        "vocab_size-1": 524,
        "unique-1": 222,
        "entropy-1": 6.8611842117382755,
        "distinct-2": 0.1934835653796469,
        "vocab_size-2": 1348,
        "unique-2": 673,
        "entropy-2": 8.92615428325637,
        "cond_entropy-2": 1.9984399253909055,
        "distinct-3": 0.33124720607957087,
        "vocab_size-3": 2223,
        "unique-3": 1373,
        "entropy-3": 9.943917726215467,
        "cond_entropy-3": 1.0530681957660248,
        "total_length-nopunct": 6580,
        "mean_pred_length-nopunct": 25.703125,
        "std_pred_length-nopunct": 6.787349647275805,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.07857142857142857,
        "vocab_size-1-nopunct": 517,
        "unique-1-nopunct": 222,
        "entropy-1-nopunct": 6.89982317253173,
        "distinct-2-nopunct": 0.19908285895003164,
        "vocab_size-2-nopunct": 1259,
        "unique-2-nopunct": 626,
        "entropy-2-nopunct": 8.869152652197652,
        "cond_entropy-2-nopunct": 2.0329827247152017,
        "distinct-3-nopunct": 0.34162821357943307,
        "vocab_size-3-nopunct": 2073,
        "unique-3-nopunct": 1292,
        "entropy-3-nopunct": 9.883557609269285,
        "cond_entropy-3-nopunct": 1.0684902210395066,
        "msttr-100": 0.60361,
        "msttr-100_nopunct": 0.60908,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.202602724134648,
        "rouge1": {
            "precision": 0.73287,
            "recall": 0.63208,
            "fmeasure": 0.66722
        },
        "rouge2": {
            "precision": 0.48705,
            "recall": 0.41516,
            "fmeasure": 0.43979
        },
        "rougeL": {
            "precision": 0.60576,
            "recall": 0.51955,
            "fmeasure": 0.54997
        },
        "rougeLsum": {
            "precision": 0.60576,
            "recall": 0.51955,
            "fmeasure": 0.54997
        },
        "local_recall": {
            "1": 0.6235538415900326
        },
        "bleu": 34.06418,
        "nubia": {
            "semantic_relation": 3.97865,
            "contradiction": 6.99256,
            "irrelevancy": 6.06593,
            "logical_agreement": 86.94152,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.08637,
            "nubia_score": 0.67486
        },
        "meteor": 0.3405508295819242,
        "bleurt": -0.01767,
        "bertscore": {
            "precision": 0.90411,
            "recall": 0.88296,
            "f1": 0.89304
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "total_length": 1264,
        "mean_pred_length": 27.47826086956522,
        "std_pred_length": 6.797503155522501,
        "median_pred_length": 27.0,
        "min_pred_length": 15,
        "max_pred_length": 50,
        "distinct-1": 0.14161392405063292,
        "vocab_size-1": 179,
        "unique-1": 73,
        "entropy-1": 6.275845208160986,
        "distinct-2": 0.37192118226600984,
        "vocab_size-2": 453,
        "unique-2": 249,
        "entropy-2": 8.073760867773062,
        "cond_entropy-2": 1.7599280050866637,
        "distinct-3": 0.5494880546075085,
        "vocab_size-3": 644,
        "unique-3": 442,
        "entropy-3": 8.886171901962076,
        "cond_entropy-3": 0.8047138848750399,
        "total_length-nopunct": 1174,
        "mean_pred_length-nopunct": 25.52173913043478,
        "std_pred_length-nopunct": 6.292642807053684,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.14906303236797275,
        "vocab_size-1-nopunct": 175,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.248385358361172,
        "distinct-2-nopunct": 0.37943262411347517,
        "vocab_size-2-nopunct": 428,
        "unique-2-nopunct": 233,
        "entropy-2-nopunct": 8.035795130073513,
        "cond_entropy-2-nopunct": 1.7928234654827946,
        "distinct-3-nopunct": 0.5536044362292052,
        "vocab_size-3-nopunct": 599,
        "unique-3-nopunct": 408,
        "entropy-3-nopunct": 8.813847252884063,
        "cond_entropy-3-nopunct": 0.8202124989031486,
        "msttr-100": 0.54583,
        "msttr-100_nopunct": 0.54273,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 5.145749611530774,
        "rouge1": {
            "precision": 0.67747,
            "recall": 0.6199,
            "fmeasure": 0.63332
        },
        "rouge2": {
            "precision": 0.43439,
            "recall": 0.40702,
            "fmeasure": 0.41009
        },
        "rougeL": {
            "precision": 0.54958,
            "recall": 0.51025,
            "fmeasure": 0.51729
        },
        "rougeLsum": {
            "precision": 0.54958,
            "recall": 0.51025,
            "fmeasure": 0.51729
        },
        "local_recall": {
            "1": 0.5962014863748968
        },
        "bleu": 33.48675,
        "nubia": {
            "semantic_relation": 3.85867,
            "contradiction": 32.70377,
            "irrelevancy": 19.86047,
            "logical_agreement": 47.43576,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.45165,
            "nubia_score": 0.58087
        },
        "meteor": 0.3105994152094388,
        "bleurt": -0.1189,
        "bertscore": {
            "precision": 0.89293,
            "recall": 0.88216,
            "f1": 0.8871
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10394,
        "mean_pred_length": 20.788,
        "std_pred_length": 4.726421056148086,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.24340965941889553,
        "vocab_size-1": 2530,
        "unique-1": 1591,
        "entropy-1": 8.553790341181097,
        "distinct-2": 0.6438245401253285,
        "vocab_size-2": 6370,
        "unique-2": 5283,
        "entropy-2": 11.93622175830075,
        "cond_entropy-2": 3.1713888012820313,
        "distinct-3": 0.8529912710240579,
        "vocab_size-3": 8013,
        "unique-3": 7350,
        "entropy-3": 12.78195923277772,
        "cond_entropy-3": 0.8668578114942515,
        "total_length-nopunct": 9675,
        "mean_pred_length-nopunct": 19.35,
        "std_pred_length-nopunct": 4.463574800538241,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.26046511627906976,
        "vocab_size-1-nopunct": 2520,
        "unique-1-nopunct": 1590,
        "entropy-1-nopunct": 8.698624422155053,
        "distinct-2-nopunct": 0.6491553133514987,
        "vocab_size-2-nopunct": 5956,
        "unique-2-nopunct": 4970,
        "entropy-2-nopunct": 11.834972768420622,
        "cond_entropy-2-nopunct": 3.2736691070294306,
        "distinct-3-nopunct": 0.8597118155619596,
        "vocab_size-3-nopunct": 7458,
        "unique-3-nopunct": 6863,
        "entropy-3-nopunct": 12.693262618414781,
        "cond_entropy-3-nopunct": 0.8848482362023343,
        "msttr-100": 0.67272,
        "msttr-100_nopunct": 0.69156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.171536695431385,
        "rouge1": {
            "precision": 0.37185,
            "recall": 0.33825,
            "fmeasure": 0.3466
        },
        "rouge2": {
            "precision": 0.12302,
            "recall": 0.11309,
            "fmeasure": 0.11523
        },
        "rougeL": {
            "precision": 0.28124,
            "recall": 0.25617,
            "fmeasure": 0.26225
        },
        "rougeLsum": {
            "precision": 0.28124,
            "recall": 0.25617,
            "fmeasure": 0.26225
        },
        "local_recall": {
            "1": 0.31588991562876656
        },
        "bleu": 7.40261,
        "nubia": {
            "semantic_relation": 2.41681,
            "contradiction": 29.94894,
            "irrelevancy": 60.67358,
            "logical_agreement": 9.37748,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.53162,
            "nubia_score": 0.31972
        },
        "meteor": 0.14714867522689956,
        "bleurt": -0.44903,
        "bertscore": {
            "precision": 0.81876,
            "recall": 0.80279,
            "f1": 0.81036
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 214,
        "total_length": 13100,
        "mean_pred_length": 61.21495327102804,
        "std_pred_length": 12.15324889248452,
        "median_pred_length": 62.0,
        "min_pred_length": 34,
        "max_pred_length": 93,
        "distinct-1": 0.09366412213740458,
        "vocab_size-1": 1227,
        "unique-1": 536,
        "entropy-1": 5.749109590351758,
        "distinct-2": 0.22776656836877232,
        "vocab_size-2": 2935,
        "unique-2": 1427,
        "entropy-2": 9.810003800525429,
        "cond_entropy-2": 4.067358004743119,
        "distinct-3": 0.38407512626262624,
        "vocab_size-3": 4867,
        "unique-3": 2723,
        "entropy-3": 11.312949279099978,
        "cond_entropy-3": 1.5287503432139422,
        "total_length-nopunct": 12044,
        "mean_pred_length-nopunct": 56.2803738317757,
        "std_pred_length-nopunct": 11.864731678557886,
        "median_pred_length-nopunct": 57.0,
        "min_pred_length-nopunct": 30,
        "max_pred_length-nopunct": 88,
        "distinct-1-nopunct": 0.10129525074726005,
        "vocab_size-1-nopunct": 1220,
        "unique-1-nopunct": 535,
        "entropy-1-nopunct": 5.651812700551443,
        "distinct-2-nopunct": 0.23245984784446322,
        "vocab_size-2-nopunct": 2750,
        "unique-2-nopunct": 1347,
        "entropy-2-nopunct": 9.726959396563966,
        "cond_entropy-2-nopunct": 4.13416854397802,
        "distinct-3-nopunct": 0.38705234159779617,
        "vocab_size-3-nopunct": 4496,
        "unique-3-nopunct": 2557,
        "entropy-3-nopunct": 11.184923899492455,
        "cond_entropy-3-nopunct": 1.4791408319731187,
        "msttr-100": 0.43809,
        "msttr-100_nopunct": 0.43108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0908313872861026,
        "rouge1": {
            "precision": 0.42888,
            "recall": 0.39711,
            "fmeasure": 0.39981
        },
        "rouge2": {
            "precision": 0.19694,
            "recall": 0.19168,
            "fmeasure": 0.18993
        },
        "rougeL": {
            "precision": 0.41035,
            "recall": 0.37831,
            "fmeasure": 0.38115
        },
        "rougeLsum": {
            "precision": 0.41035,
            "recall": 0.37831,
            "fmeasure": 0.38115
        },
        "local_recall": {
            "1": 0.0860517435320585,
            "2": 0.18694690265486727,
            "3": 0.2652014652014652
        },
        "bleu": 1.97912,
        "nubia": {
            "semantic_relation": 3.4074,
            "contradiction": 31.58268,
            "irrelevancy": 17.50221,
            "logical_agreement": 50.91511,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.35595,
            "nubia_score": 0.13559
        },
        "meteor": 0.1278820345521488,
        "bleurt": -0.51917,
        "bertscore": {
            "precision": 0.85799,
            "recall": 0.86981,
            "f1": 0.86346
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 6535,
        "mean_pred_length": 18.2033426183844,
        "std_pred_length": 8.756081211719877,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37551644988523336,
        "vocab_size-1": 2454,
        "unique-1": 1833,
        "entropy-1": 9.044024449013124,
        "distinct-2": 0.8455310880829016,
        "vocab_size-2": 5222,
        "unique-2": 4850,
        "entropy-2": 12.054670081583298,
        "cond_entropy-2": 2.7255399110759475,
        "distinct-3": 0.9692281244627815,
        "vocab_size-3": 5638,
        "unique-3": 5534,
        "entropy-3": 12.419648140097925,
        "cond_entropy-3": 0.3788863029069956,
        "total_length-nopunct": 5850,
        "mean_pred_length-nopunct": 16.295264623955433,
        "std_pred_length-nopunct": 7.9806000761981375,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.4176068376068376,
        "vocab_size-1-nopunct": 2443,
        "unique-1-nopunct": 1830,
        "entropy-1-nopunct": 9.36465943906204,
        "distinct-2-nopunct": 0.8584957202695319,
        "vocab_size-2-nopunct": 4714,
        "unique-2-nopunct": 4410,
        "entropy-2-nopunct": 11.923729586000785,
        "cond_entropy-2-nopunct": 2.70775265858682,
        "distinct-3-nopunct": 0.9785658612626656,
        "vocab_size-3-nopunct": 5022,
        "unique-3-nopunct": 4943,
        "entropy-3-nopunct": 12.275681859901173,
        "cond_entropy-3-nopunct": 0.37615686540364046,
        "msttr-100": 0.72169,
        "msttr-100_nopunct": 0.76293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "nist": 7.832605082061171,
        "rouge1": {
            "precision": 0.70463,
            "recall": 0.62056,
            "fmeasure": 0.64464
        },
        "rouge2": {
            "precision": 0.46551,
            "recall": 0.41184,
            "fmeasure": 0.42505
        },
        "rougeL": {
            "precision": 0.65094,
            "recall": 0.57469,
            "fmeasure": 0.596
        },
        "rougeLsum": {
            "precision": 0.65094,
            "recall": 0.57469,
            "fmeasure": 0.596
        },
        "local_recall": {
            "1": 0.0583616298811545,
            "2": 0.16475095785440613,
            "3": 0.28227571115973743,
            "4": 0.2884310618066561,
            "5": 0.4122533748701973,
            "6": 0.5489130434782609,
            "7": 0.699885452462772
        },
        "bleu": 40.76127,
        "sari": 44.71088,
        "nubia": {
            "semantic_relation": 3.60699,
            "contradiction": 13.30392,
            "irrelevancy": 24.05066,
            "logical_agreement": 62.64542,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.15778,
            "nubia_score": 0.51877
        },
        "meteor": 0.3334139036819337,
        "bleurt": -0.09388,
        "bertscore": {
            "precision": 0.91185,
            "recall": 0.8957,
            "f1": 0.90091
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "total_length": 27212,
        "mean_pred_length": 19.478883321403007,
        "std_pred_length": 6.349328929193714,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.05953255916507423,
        "vocab_size-1": 1620,
        "unique-1": 759,
        "entropy-1": 7.213567915842361,
        "distinct-2": 0.17447220608173541,
        "vocab_size-2": 4504,
        "unique-2": 2618,
        "entropy-2": 9.707558789455401,
        "cond_entropy-2": 2.3796229792401324,
        "distinct-3": 0.3077238103038742,
        "vocab_size-3": 7514,
        "unique-3": 5057,
        "entropy-3": 11.081086591233616,
        "cond_entropy-3": 1.4085621817863845,
        "total_length-nopunct": 24541,
        "mean_pred_length-nopunct": 17.566929133858267,
        "std_pred_length-nopunct": 6.040248690404705,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.06548225418687095,
        "vocab_size-1-nopunct": 1607,
        "unique-1-nopunct": 756,
        "entropy-1-nopunct": 7.286261827108161,
        "distinct-2-nopunct": 0.1850155547874179,
        "vocab_size-2-nopunct": 4282,
        "unique-2-nopunct": 2534,
        "entropy-2-nopunct": 9.68079885129626,
        "cond_entropy-2-nopunct": 2.487714231783812,
        "distinct-3-nopunct": 0.32464247942244906,
        "vocab_size-3-nopunct": 7060,
        "unique-3-nopunct": 4809,
        "entropy-3-nopunct": 11.086172825921416,
        "cond_entropy-3-nopunct": 1.4719610885156664,
        "msttr-100": 0.59474,
        "msttr-100_nopunct": 0.6022,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.572652481189757,
        "rouge1": {
            "precision": 0.66453,
            "recall": 0.62877,
            "fmeasure": 0.63363
        },
        "rouge2": {
            "precision": 0.4396,
            "recall": 0.41629,
            "fmeasure": 0.41898
        },
        "rougeL": {
            "precision": 0.57451,
            "recall": 0.54573,
            "fmeasure": 0.54896
        },
        "rougeLsum": {
            "precision": 0.57451,
            "recall": 0.54573,
            "fmeasure": 0.54896
        },
        "local_recall": {
            "1": 0.6195201301342009
        },
        "bleu": 34.47726,
        "nubia": {
            "semantic_relation": 4.03705,
            "contradiction": 8.48931,
            "irrelevancy": 18.01582,
            "logical_agreement": 73.49487,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.87675,
            "nubia_score": 0.67471
        },
        "meteor": 0.3329308487932086,
        "bleurt": -0.06427,
        "bertscore": {
            "precision": 0.88375,
            "recall": 0.87456,
            "f1": 0.87871
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 1187,
        "total_length": 28267,
        "mean_pred_length": 23.813816343723673,
        "std_pred_length": 4.81728961152604,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 34,
        "distinct-1": 0.004811264018112994,
        "vocab_size-1": 136,
        "unique-1": 14,
        "entropy-1": 5.529850137322348,
        "distinct-2": 0.016617429837518464,
        "vocab_size-2": 450,
        "unique-2": 76,
        "entropy-2": 7.003923470406511,
        "cond_entropy-2": 1.3859004052896895,
        "distinct-3": 0.033213609855945625,
        "vocab_size-3": 860,
        "unique-3": 188,
        "entropy-3": 7.861332298605407,
        "cond_entropy-3": 0.8928263251872754,
        "total_length-nopunct": 25785,
        "mean_pred_length-nopunct": 21.722830665543388,
        "std_pred_length-nopunct": 4.352401199295913,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.005196819856505721,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 5.5866087456825735,
        "distinct-2-nopunct": 0.017603057159118626,
        "vocab_size-2-nopunct": 433,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.975434750937201,
        "cond_entropy-2-nopunct": 1.443738260705423,
        "distinct-3-nopunct": 0.035923283926359406,
        "vocab_size-3-nopunct": 841,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.892056481539437,
        "cond_entropy-3-nopunct": 0.9395770000997641,
        "msttr-100": 0.26872,
        "msttr-100_nopunct": 0.26412,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.0307811667671425,
        "rouge1": {
            "precision": 0.74542,
            "recall": 0.73373,
            "fmeasure": 0.72636
        },
        "rouge2": {
            "precision": 0.43918,
            "recall": 0.43306,
            "fmeasure": 0.42825
        },
        "rougeL": {
            "precision": 0.53242,
            "recall": 0.52359,
            "fmeasure": 0.51869
        },
        "rougeLsum": {
            "precision": 0.53242,
            "recall": 0.52359,
            "fmeasure": 0.51869
        },
        "local_recall": {
            "1": 0.7243441276792858
        },
        "bleu": 32.25718,
        "nubia": {
            "semantic_relation": 4.19367,
            "contradiction": 1.94842,
            "irrelevancy": 22.86561,
            "logical_agreement": 75.18597,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.39562,
            "nubia_score": 0.77762
        },
        "meteor": 0.36706014469139026,
        "bleurt": 0.20437,
        "bertscore": {
            "precision": 0.91731,
            "recall": 0.90764,
            "f1": 0.91204
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 6848,
        "mean_pred_length": 19.075208913649025,
        "std_pred_length": 9.351830792015178,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.4185163551401869,
        "vocab_size-1": 2866,
        "unique-1": 2259,
        "entropy-1": 9.376268004367812,
        "distinct-2": 0.8733240869163199,
        "vocab_size-2": 5667,
        "unique-2": 5351,
        "entropy-2": 12.226375819209014,
        "cond_entropy-2": 2.5624731671528815,
        "distinct-3": 0.9774877650897227,
        "vocab_size-3": 5992,
        "unique-3": 5924,
        "entropy-3": 12.508290840609517,
        "cond_entropy-3": 0.29764399729491087,
        "total_length-nopunct": 6109,
        "mean_pred_length-nopunct": 17.016713091922007,
        "std_pred_length-nopunct": 8.335563257691483,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4670158782124734,
        "vocab_size-1-nopunct": 2853,
        "unique-1-nopunct": 2254,
        "entropy-1-nopunct": 9.741134951647686,
        "distinct-2-nopunct": 0.8899130434782608,
        "vocab_size-2-nopunct": 5117,
        "unique-2-nopunct": 4861,
        "entropy-2-nopunct": 12.11439328738939,
        "cond_entropy-2-nopunct": 2.51030753920876,
        "distinct-3-nopunct": 0.9872008903728436,
        "vocab_size-3-nopunct": 5322,
        "unique-3-nopunct": 5268,
        "entropy-3-nopunct": 12.367532851341538,
        "cond_entropy-3-nopunct": 0.2737476765917342,
        "msttr-100": 0.75029,
        "msttr-100_nopunct": 0.7977,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "nist": 9.31371439573802,
        "rouge1": {
            "precision": 0.76945,
            "recall": 0.69402,
            "fmeasure": 0.71548
        },
        "rouge2": {
            "precision": 0.5813,
            "recall": 0.51969,
            "fmeasure": 0.53612
        },
        "rougeL": {
            "precision": 0.74341,
            "recall": 0.67269,
            "fmeasure": 0.69204
        },
        "rougeLsum": {
            "precision": 0.74341,
            "recall": 0.67269,
            "fmeasure": 0.69204
        },
        "local_recall": {
            "1": 0.03904923599320883,
            "2": 0.14814814814814814,
            "3": 0.33260393873085337,
            "4": 0.45166402535657685,
            "5": 0.5617860851505712,
            "6": 0.658816425120773,
            "7": 0.7609774723176785
        },
        "bleu": 51.04599,
        "sari": 46.29961,
        "nubia": {
            "semantic_relation": 3.99504,
            "contradiction": 6.35376,
            "irrelevancy": 16.71353,
            "logical_agreement": 76.93271,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.02114,
            "nubia_score": 0.51642
        },
        "meteor": 0.3738831218555855,
        "bleurt": -0.45323,
        "bertscore": {
            "precision": 0.90009,
            "recall": 0.91027,
            "f1": 0.90248
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "total_length": 5223,
        "mean_pred_length": 5.313326551373347,
        "std_pred_length": 1.5254688995040273,
        "median_pred_length": 5.0,
        "min_pred_length": 4,
        "max_pred_length": 12,
        "distinct-1": 0.008998659774076202,
        "vocab_size-1": 47,
        "unique-1": 7,
        "entropy-1": 3.419163768782611,
        "distinct-2": 0.017452830188679245,
        "vocab_size-2": 74,
        "unique-2": 17,
        "entropy-2": 3.878722010276887,
        "cond_entropy-2": 0.47092317709299336,
        "distinct-3": 0.02579060485108996,
        "vocab_size-3": 84,
        "unique-3": 22,
        "entropy-3": 4.321680497577161,
        "cond_entropy-3": 0.4483216111284312,
        "total_length-nopunct": 4262,
        "mean_pred_length-nopunct": 4.335707019328586,
        "std_pred_length-nopunct": 1.2175458044703216,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.010323791647114031,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0817912601206943,
        "distinct-2-nopunct": 0.018298261665141813,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.4600954862544033,
        "cond_entropy-2-nopunct": 0.29159168049341677,
        "distinct-3-nopunct": 0.025261324041811847,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.6269814784781764,
        "cond_entropy-3-nopunct": 0.29970355957822087,
        "msttr-100": 0.1625,
        "msttr-100_nopunct": 0.14667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 2.71290429273694,
        "rouge1": {
            "precision": 0.54639,
            "recall": 0.5111,
            "fmeasure": 0.51929
        },
        "rouge2": {
            "precision": 0.36653,
            "recall": 0.3378,
            "fmeasure": 0.34484
        },
        "rougeL": {
            "precision": 0.54563,
            "recall": 0.51049,
            "fmeasure": 0.51861
        },
        "rougeLsum": {
            "precision": 0.54563,
            "recall": 0.51049,
            "fmeasure": 0.51861
        },
        "local_recall": {
            "1": 0.4945407835581246
        },
        "bleu": 29.11264,
        "nubia": {
            "semantic_relation": 3.11544,
            "contradiction": 2.19719,
            "irrelevancy": 22.69864,
            "logical_agreement": 75.10417,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.4928,
            "nubia_score": 0.59848
        },
        "meteor": 0.2693643285526757,
        "bleurt": 0.12106,
        "bertscore": {
            "precision": 0.85773,
            "recall": 0.85107,
            "f1": 0.85392
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "total_length": 10671,
        "mean_pred_length": 10.3904576436222,
        "std_pred_length": 4.30104111905443,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 27,
        "distinct-1": 0.10392652984724955,
        "vocab_size-1": 1109,
        "unique-1": 595,
        "entropy-1": 7.196105110216129,
        "distinct-2": 0.2764413106594774,
        "vocab_size-2": 2666,
        "unique-2": 1620,
        "entropy-2": 9.87237269173906,
        "cond_entropy-2": 2.3039912592372636,
        "distinct-3": 0.44302622418194476,
        "vocab_size-3": 3818,
        "unique-3": 2637,
        "entropy-3": 10.931376022261906,
        "cond_entropy-3": 1.1337447627182364,
        "total_length-nopunct": 9169,
        "mean_pred_length-nopunct": 8.92794547224927,
        "std_pred_length-nopunct": 4.032809449917533,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.12007852546624495,
        "vocab_size-1-nopunct": 1101,
        "unique-1-nopunct": 595,
        "entropy-1-nopunct": 7.475130680984768,
        "distinct-2-nopunct": 0.28506509457135837,
        "vocab_size-2-nopunct": 2321,
        "unique-2-nopunct": 1404,
        "entropy-2-nopunct": 9.701381776095836,
        "cond_entropy-2-nopunct": 2.497439906889554,
        "distinct-3-nopunct": 0.45722713864306785,
        "vocab_size-3-nopunct": 3255,
        "unique-3-nopunct": 2277,
        "entropy-3-nopunct": 10.717452752038716,
        "cond_entropy-3-nopunct": 1.1918793431112247,
        "msttr-100": 0.60519,
        "msttr-100_nopunct": 0.64077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.432545889065168,
        "rouge1": {
            "precision": 0.68382,
            "recall": 0.66517,
            "fmeasure": 0.66411
        },
        "rouge2": {
            "precision": 0.48921,
            "recall": 0.47642,
            "fmeasure": 0.4732
        },
        "rougeL": {
            "precision": 0.63147,
            "recall": 0.61425,
            "fmeasure": 0.61309
        },
        "rougeLsum": {
            "precision": 0.63147,
            "recall": 0.61425,
            "fmeasure": 0.61309
        },
        "local_recall": {
            "1": 0.6359523284043258
        },
        "bleu": 46.31388,
        "nubia": {
            "semantic_relation": 4.00105,
            "contradiction": 10.69718,
            "irrelevancy": 14.25332,
            "logical_agreement": 75.0495,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.62429,
            "nubia_score": 0.73779
        },
        "meteor": 0.37961220696931475,
        "bleurt": 0.22192,
        "bertscore": {
            "precision": 0.90877,
            "recall": 0.9019,
            "f1": 0.90497
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 6965,
        "mean_pred_length": 19.401114206128135,
        "std_pred_length": 9.376114909277238,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.4637473079684135,
        "vocab_size-1": 3230,
        "unique-1": 2694,
        "entropy-1": 9.627630067681443,
        "distinct-2": 0.8941871026339692,
        "vocab_size-2": 5907,
        "unique-2": 5643,
        "entropy-2": 12.329145995841296,
        "cond_entropy-2": 2.4055183668220232,
        "distinct-3": 0.9836721626380662,
        "vocab_size-3": 6145,
        "unique-3": 6098,
        "entropy-3": 12.554721004186806,
        "cond_entropy-3": 0.23728053344037733,
        "total_length-nopunct": 6208,
        "mean_pred_length-nopunct": 17.292479108635096,
        "std_pred_length-nopunct": 8.351986685678622,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5183634020618557,
        "vocab_size-1-nopunct": 3218,
        "unique-1-nopunct": 2691,
        "entropy-1-nopunct": 10.026011624712044,
        "distinct-2-nopunct": 0.9095571892631219,
        "vocab_size-2-nopunct": 5320,
        "unique-2-nopunct": 5108,
        "entropy-2-nopunct": 12.209157049711465,
        "cond_entropy-2-nopunct": 2.309083242687009,
        "distinct-3-nopunct": 0.9918032786885246,
        "vocab_size-3-nopunct": 5445,
        "unique-3-nopunct": 5408,
        "entropy-3-nopunct": 12.40430147725169,
        "cond_entropy-3-nopunct": 0.21231372779913876,
        "msttr-100": 0.76812,
        "msttr-100_nopunct": 0.82081,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "nist": 8.119998956641206,
        "rouge1": {
            "precision": 0.68717,
            "recall": 0.62849,
            "fmeasure": 0.64481
        },
        "rouge2": {
            "precision": 0.45934,
            "recall": 0.42085,
            "fmeasure": 0.42993
        },
        "rougeL": {
            "precision": 0.6619,
            "recall": 0.60629,
            "fmeasure": 0.62155
        },
        "rougeLsum": {
            "precision": 0.6619,
            "recall": 0.60629,
            "fmeasure": 0.62155
        },
        "local_recall": {
            "1": 0.03395585738539898,
            "2": 0.1251596424010217,
            "3": 0.2800875273522976,
            "4": 0.39461172741679873,
            "5": 0.4963655244029076,
            "6": 0.6044685990338164,
            "7": 0.6995036273386789
        },
        "bleu": 39.09718,
        "sari": 44.81487,
        "nubia": {
            "semantic_relation": 3.79911,
            "contradiction": 7.93174,
            "irrelevancy": 17.43075,
            "logical_agreement": 74.63751,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.71535,
            "nubia_score": 0.43363
        },
        "meteor": 0.31952780144575493,
        "bleurt": -0.87217,
        "bertscore": {
            "precision": 0.85692,
            "recall": 0.88672,
            "f1": 0.86857
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "total_length": 37698,
        "mean_pred_length": 7.466428995840761,
        "std_pred_length": 2.7558813650799143,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 34,
        "distinct-1": 0.02761419703963075,
        "vocab_size-1": 1041,
        "unique-1": 455,
        "entropy-1": 6.650546082854444,
        "distinct-2": 0.09240711813531809,
        "vocab_size-2": 3017,
        "unique-2": 1475,
        "entropy-2": 8.852389329634773,
        "cond_entropy-2": 1.8459413710142365,
        "distinct-3": 0.15474077026194702,
        "vocab_size-3": 4271,
        "unique-3": 2388,
        "entropy-3": 9.511295727056895,
        "cond_entropy-3": 0.7159213754459038,
        "total_length-nopunct": 32215,
        "mean_pred_length-nopunct": 6.380471380471381,
        "std_pred_length-nopunct": 2.552833077145695,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.032034766413161574,
        "vocab_size-1-nopunct": 1032,
        "unique-1-nopunct": 455,
        "entropy-1-nopunct": 6.790064259240599,
        "distinct-2-nopunct": 0.09338879481705073,
        "vocab_size-2-nopunct": 2537,
        "unique-2-nopunct": 1255,
        "entropy-2-nopunct": 8.517250561196924,
        "cond_entropy-2-nopunct": 1.9461190662209185,
        "distinct-3-nopunct": 0.15599150205668308,
        "vocab_size-3-nopunct": 3451,
        "unique-3-nopunct": 1976,
        "entropy-3-nopunct": 9.094594603275134,
        "cond_entropy-3-nopunct": 0.7149164051647043,
        "msttr-100": 0.54431,
        "msttr-100_nopunct": 0.56429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.722925763923394,
        "rouge1": {
            "precision": 0.51047,
            "recall": 0.48561,
            "fmeasure": 0.48537
        },
        "rouge2": {
            "precision": 0.30136,
            "recall": 0.28637,
            "fmeasure": 0.28557
        },
        "rougeL": {
            "precision": 0.48582,
            "recall": 0.46025,
            "fmeasure": 0.46122
        },
        "rougeLsum": {
            "precision": 0.48582,
            "recall": 0.46025,
            "fmeasure": 0.46122
        },
        "local_recall": {
            "1": 0.46843707911225624
        },
        "bleu": 26.66413,
        "nubia": {
            "semantic_relation": 3.13522,
            "contradiction": 9.09267,
            "irrelevancy": 23.24251,
            "logical_agreement": 67.66482,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.42087,
            "nubia_score": 0.58215
        },
        "meteor": 0.2627381523049121,
        "bleurt": -0.09263,
        "bertscore": {
            "precision": 0.85903,
            "recall": 0.85183,
            "f1": 0.85483
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "total_length": 19495,
        "mean_pred_length": 20.349686847599166,
        "std_pred_length": 5.985704517082235,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.08166196460630931,
        "vocab_size-1": 1592,
        "unique-1": 771,
        "entropy-1": 7.54576192713846,
        "distinct-2": 0.22484760209311108,
        "vocab_size-2": 4168,
        "unique-2": 2405,
        "entropy-2": 10.159147289366294,
        "cond_entropy-2": 2.467865527976535,
        "distinct-3": 0.3648102849991467,
        "vocab_size-3": 6413,
        "unique-3": 4177,
        "entropy-3": 11.402493041644282,
        "cond_entropy-3": 1.3144834831211092,
        "total_length-nopunct": 17089,
        "mean_pred_length-nopunct": 17.838204592901878,
        "std_pred_length-nopunct": 5.493583437926194,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.09245713616946574,
        "vocab_size-1-nopunct": 1580,
        "unique-1-nopunct": 770,
        "entropy-1-nopunct": 7.765700746470084,
        "distinct-2-nopunct": 0.24201847374620297,
        "vocab_size-2-nopunct": 3904,
        "unique-2-nopunct": 2313,
        "entropy-2-nopunct": 10.133937491607975,
        "cond_entropy-2-nopunct": 2.513464011762446,
        "distinct-3-nopunct": 0.39286891188295,
        "vocab_size-3-nopunct": 5961,
        "unique-3-nopunct": 3975,
        "entropy-3-nopunct": 11.425861940980436,
        "cond_entropy-3-nopunct": 1.3903243564339507,
        "msttr-100": 0.63897,
        "msttr-100_nopunct": 0.66588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.650073321072059,
        "rouge1": {
            "precision": 0.66566,
            "recall": 0.60726,
            "fmeasure": 0.62462
        },
        "rouge2": {
            "precision": 0.4226,
            "recall": 0.38501,
            "fmeasure": 0.39596
        },
        "rougeL": {
            "precision": 0.58115,
            "recall": 0.53195,
            "fmeasure": 0.54645
        },
        "rougeLsum": {
            "precision": 0.58115,
            "recall": 0.53195,
            "fmeasure": 0.54645
        },
        "local_recall": {
            "1": 0.5967129498441485
        },
        "bleu": 31.83206,
        "nubia": {
            "semantic_relation": 4.28923,
            "contradiction": 6.79789,
            "irrelevancy": 14.19272,
            "logical_agreement": 79.00938,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.85502,
            "nubia_score": 0.73138
        },
        "meteor": 0.33454681555615645,
        "bleurt": -0.08269,
        "bertscore": {
            "precision": 0.89004,
            "recall": 0.87617,
            "f1": 0.8827
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "total_length": 2212,
        "mean_pred_length": 30.72222222222222,
        "std_pred_length": 8.060917755549204,
        "median_pred_length": 29.5,
        "min_pred_length": 13,
        "max_pred_length": 50,
        "distinct-1": 0.16636528028933092,
        "vocab_size-1": 368,
        "unique-1": 202,
        "entropy-1": 6.833246352543522,
        "distinct-2": 0.3598130841121495,
        "vocab_size-2": 770,
        "unique-2": 505,
        "entropy-2": 8.492594874859082,
        "cond_entropy-2": 1.6041506529576546,
        "distinct-3": 0.5004835589941973,
        "vocab_size-3": 1035,
        "unique-3": 775,
        "entropy-3": 9.2005338054376,
        "cond_entropy-3": 0.6976431902072686,
        "total_length-nopunct": 1957,
        "mean_pred_length-nopunct": 27.180555555555557,
        "std_pred_length-nopunct": 7.683543722515183,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.18446601941747573,
        "vocab_size-1-nopunct": 361,
        "unique-1-nopunct": 201,
        "entropy-1-nopunct": 6.891646529749328,
        "distinct-2-nopunct": 0.38726790450928383,
        "vocab_size-2-nopunct": 730,
        "unique-2-nopunct": 485,
        "entropy-2-nopunct": 8.496721593226818,
        "cond_entropy-2-nopunct": 1.614122641921196,
        "distinct-3-nopunct": 0.5267512410369554,
        "vocab_size-3-nopunct": 955,
        "unique-3-nopunct": 733,
        "entropy-3-nopunct": 9.151516718179543,
        "cond_entropy-3-nopunct": 0.7020379204267055,
        "msttr-100": 0.60227,
        "msttr-100_nopunct": 0.62316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 5.793522027609819,
        "rouge1": {
            "precision": 0.68218,
            "recall": 0.59883,
            "fmeasure": 0.63147
        },
        "rouge2": {
            "precision": 0.44817,
            "recall": 0.39477,
            "fmeasure": 0.41531
        },
        "rougeL": {
            "precision": 0.55564,
            "recall": 0.48792,
            "fmeasure": 0.51446
        },
        "rougeLsum": {
            "precision": 0.55564,
            "recall": 0.48792,
            "fmeasure": 0.51446
        },
        "local_recall": {
            "1": 0.6122448979591837
        },
        "bleu": 34.91734,
        "nubia": {
            "semantic_relation": 4.18707,
            "contradiction": 3.27519,
            "irrelevancy": 7.50713,
            "logical_agreement": 89.21768,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.118,
            "nubia_score": 0.73113
        },
        "meteor": 0.3397991097107876,
        "bleurt": -0.07313,
        "bertscore": {
            "precision": 0.90065,
            "recall": 0.88061,
            "f1": 0.89025
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 1406,
        "total_length": 37260,
        "mean_pred_length": 26.500711237553343,
        "std_pred_length": 4.403016818544185,
        "median_pred_length": 26.0,
        "min_pred_length": 16,
        "max_pred_length": 42,
        "distinct-1": 0.0033548040794417608,
        "vocab_size-1": 125,
        "unique-1": 12,
        "entropy-1": 5.602564523813039,
        "distinct-2": 0.013192391364980198,
        "vocab_size-2": 473,
        "unique-2": 79,
        "entropy-2": 7.193398877579462,
        "cond_entropy-2": 1.5141345941069382,
        "distinct-3": 0.028303529958197862,
        "vocab_size-3": 975,
        "unique-3": 200,
        "entropy-3": 8.159192966699067,
        "cond_entropy-3": 0.9877005306977302,
        "total_length-nopunct": 34208,
        "mean_pred_length-nopunct": 24.330014224751068,
        "std_pred_length-nopunct": 4.0805259855111915,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.003595650140318054,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 5.641907027736268,
        "distinct-2-nopunct": 0.01399304920431681,
        "vocab_size-2-nopunct": 459,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 7.178161078523227,
        "cond_entropy-2-nopunct": 1.5786530933746863,
        "distinct-3-nopunct": 0.030577143585170087,
        "vocab_size-3-nopunct": 960,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 8.194748998995045,
        "cond_entropy-3-nopunct": 1.0257781675792828,
        "msttr-100": 0.28699,
        "msttr-100_nopunct": 0.28044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.239013982629048,
        "rouge1": {
            "precision": 0.79141,
            "recall": 0.72459,
            "fmeasure": 0.74761
        },
        "rouge2": {
            "precision": 0.48214,
            "recall": 0.44225,
            "fmeasure": 0.45575
        },
        "rougeL": {
            "precision": 0.54527,
            "recall": 0.50053,
            "fmeasure": 0.5158
        },
        "rougeLsum": {
            "precision": 0.54527,
            "recall": 0.50053,
            "fmeasure": 0.5158
        },
        "local_recall": {
            "1": 0.7125672104255901
        },
        "bleu": 31.81252,
        "nubia": {
            "semantic_relation": 4.48388,
            "contradiction": 1.90908,
            "irrelevancy": 11.08214,
            "logical_agreement": 87.00878,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.34124,
            "nubia_score": 0.84007
        },
        "meteor": 0.36795605880105997,
        "bleurt": 0.27623,
        "bertscore": {
            "precision": 0.92576,
            "recall": 0.90802,
            "f1": 0.91657
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 6651,
        "mean_pred_length": 18.526462395543174,
        "std_pred_length": 8.941390500756915,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.37227484588783644,
        "vocab_size-1": 2476,
        "unique-1": 1844,
        "entropy-1": 9.122696483386921,
        "distinct-2": 0.8475842339478703,
        "vocab_size-2": 5333,
        "unique-2": 4944,
        "entropy-2": 12.098250764629745,
        "cond_entropy-2": 2.688791529649974,
        "distinct-3": 0.9698297657171752,
        "vocab_size-3": 5754,
        "unique-3": 5661,
        "entropy-3": 12.4385007929367,
        "cond_entropy-3": 0.3589813487186626,
        "total_length-nopunct": 5945,
        "mean_pred_length-nopunct": 16.559888579387188,
        "std_pred_length-nopunct": 8.006693299486516,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4148023549201009,
        "vocab_size-1-nopunct": 2466,
        "unique-1-nopunct": 1842,
        "entropy-1-nopunct": 9.455214206896406,
        "distinct-2-nopunct": 0.8644826351593269,
        "vocab_size-2-nopunct": 4829,
        "unique-2-nopunct": 4510,
        "entropy-2-nopunct": 11.991005925495536,
        "cond_entropy-2-nopunct": 2.6856811449090086,
        "distinct-3-nopunct": 0.981251195714559,
        "vocab_size-3-nopunct": 5129,
        "unique-3-nopunct": 5054,
        "entropy-3-nopunct": 12.308980235141894,
        "cond_entropy-3-nopunct": 0.34179959604153043,
        "msttr-100": 0.73288,
        "msttr-100_nopunct": 0.77186,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "nist": 10.450917940113579,
        "rouge1": {
            "precision": 0.85357,
            "recall": 0.75976,
            "fmeasure": 0.78861
        },
        "rouge2": {
            "precision": 0.7122,
            "recall": 0.63066,
            "fmeasure": 0.6545
        },
        "rougeL": {
            "precision": 0.82722,
            "recall": 0.73609,
            "fmeasure": 0.76374
        },
        "rougeLsum": {
            "precision": 0.82722,
            "recall": 0.73609,
            "fmeasure": 0.76374
        },
        "local_recall": {
            "1": 0.039261460101867575,
            "2": 0.16347381864623245,
            "3": 0.36323851203501095,
            "4": 0.5007923930269413,
            "5": 0.6199376947040498,
            "6": 0.7246376811594203,
            "7": 0.8319969453990073
        },
        "bleu": 65.63275,
        "sari": 48.40238,
        "nubia": {
            "semantic_relation": 4.15418,
            "contradiction": 4.97674,
            "irrelevancy": 15.80532,
            "logical_agreement": 79.21793,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.03636,
            "nubia_score": 0.6506
        },
        "meteor": 0.4404047773874821,
        "bleurt": 0.15023,
        "bertscore": {
            "precision": 0.95381,
            "recall": 0.93419,
            "f1": 0.94142
        }
    },
    "cs_restaurants_validation": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_validation",
        "N": 781
    },
    "cs_restaurants_test": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_test",
        "N": 842,
        "total_length": 13404,
        "mean_pred_length": 15.919239904988123,
        "std_pred_length": 6.601168498873635,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.05364070426738287,
        "vocab_size-1": 719,
        "unique-1": 275,
        "entropy-1": 6.411811003606481,
        "distinct-2": 0.16470307275911478,
        "vocab_size-2": 2069,
        "unique-2": 1022,
        "entropy-2": 9.156695101653652,
        "cond_entropy-2": 2.669913077529431,
        "distinct-3": 0.27755972696245734,
        "vocab_size-3": 3253,
        "unique-3": 1956,
        "entropy-3": 10.004351247082708,
        "cond_entropy-3": 0.9225386570304897,
        "total_length-nopunct": 12242,
        "mean_pred_length-nopunct": 14.539192399049881,
        "std_pred_length-nopunct": 6.232548714675027,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.058405489299134125,
        "vocab_size-1-nopunct": 715,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 6.4099495823830575,
        "distinct-2-nopunct": 0.16017543859649122,
        "vocab_size-2-nopunct": 1826,
        "unique-2-nopunct": 900,
        "entropy-2-nopunct": 8.976512440735524,
        "cond_entropy-2-nopunct": 2.7541696533666356,
        "distinct-3-nopunct": 0.278461829892025,
        "vocab_size-3-nopunct": 2940,
        "unique-3-nopunct": 1794,
        "entropy-3-nopunct": 9.835360262208686,
        "cond_entropy-3-nopunct": 0.9425171021966422,
        "msttr-100": 0.54418,
        "msttr-100_nopunct": 0.54664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.5713486196153696,
        "rouge1": {
            "precision": 0.41873,
            "recall": 0.44235,
            "fmeasure": 0.41496
        },
        "rouge2": {
            "precision": 0.22273,
            "recall": 0.23929,
            "fmeasure": 0.22142
        },
        "rougeL": {
            "precision": 0.3694,
            "recall": 0.39108,
            "fmeasure": 0.36665
        },
        "rougeLsum": {
            "precision": 0.3694,
            "recall": 0.39108,
            "fmeasure": 0.36665
        },
        "local_recall": {
            "1": 0.2769465225824328
        },
        "bleu": 3.61466,
        "nubia": {
            "semantic_relation": 2.73135,
            "contradiction": 34.51004,
            "irrelevancy": 26.50134,
            "logical_agreement": 38.98863,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.12463,
            "nubia_score": 0.32126
        },
        "meteor": 0.12885591271202704,
        "bleurt": -0.66531,
        "bertscore": {
            "precision": 0.82457,
            "recall": 0.8552,
            "f1": 0.83935
        }
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "total_length": 9587,
        "mean_pred_length": 9.3623046875,
        "std_pred_length": 5.83183820728212,
        "median_pred_length": 6.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.07228538646083238,
        "vocab_size-1": 693,
        "unique-1": 396,
        "entropy-1": 6.097656433981224,
        "distinct-2": 0.19327338549573747,
        "vocab_size-2": 1655,
        "unique-2": 1031,
        "entropy-2": 8.42049413118236,
        "cond_entropy-2": 1.9873206598365907,
        "distinct-3": 0.3163549542379626,
        "vocab_size-3": 2385,
        "unique-3": 1669,
        "entropy-3": 9.358215447574906,
        "cond_entropy-3": 0.8844989196889137,
        "total_length-nopunct": 8116,
        "mean_pred_length-nopunct": 7.92578125,
        "std_pred_length-nopunct": 5.123700232951616,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.08440118284869394,
        "vocab_size-1-nopunct": 685,
        "unique-1-nopunct": 395,
        "entropy-1-nopunct": 6.322120592389621,
        "distinct-2-nopunct": 0.20995487873660462,
        "vocab_size-2-nopunct": 1489,
        "unique-2-nopunct": 941,
        "entropy-2-nopunct": 8.351931067906321,
        "cond_entropy-2-nopunct": 2.1729464722408083,
        "distinct-3-nopunct": 0.3528345418589321,
        "vocab_size-3-nopunct": 2141,
        "unique-3-nopunct": 1532,
        "entropy-3-nopunct": 9.340263089080224,
        "cond_entropy-3-nopunct": 0.9409600377947431,
        "msttr-100": 0.46189,
        "msttr-100_nopunct": 0.48506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.294848148797951,
        "rouge1": {
            "precision": 0.42181,
            "recall": 0.37665,
            "fmeasure": 0.38889
        },
        "rouge2": {
            "precision": 0.19856,
            "recall": 0.18302,
            "fmeasure": 0.18663
        },
        "rougeL": {
            "precision": 0.38031,
            "recall": 0.33835,
            "fmeasure": 0.34976
        },
        "rougeLsum": {
            "precision": 0.38031,
            "recall": 0.33835,
            "fmeasure": 0.34976
        },
        "local_recall": {
            "1": 0.40521872601688413
        },
        "bleu": 23.5077,
        "nubia": {
            "semantic_relation": 2.44272,
            "contradiction": 11.10596,
            "irrelevancy": 30.0735,
            "logical_agreement": 58.82054,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.05582,
            "nubia_score": 0.40055
        },
        "meteor": 0.23865978368643145,
        "bleurt": -0.48967,
        "bertscore": {
            "precision": 0.8555,
            "recall": 0.83938,
            "f1": 0.84704
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 774,
        "total_length": 24700,
        "mean_pred_length": 31.912144702842376,
        "std_pred_length": 4.146856136121244,
        "median_pred_length": 32.0,
        "min_pred_length": 21,
        "max_pred_length": 43,
        "distinct-1": 0.004412955465587044,
        "vocab_size-1": 109,
        "unique-1": 3,
        "entropy-1": 5.716584138496964,
        "distinct-2": 0.016467441277271587,
        "vocab_size-2": 394,
        "unique-2": 44,
        "entropy-2": 7.224727784754074,
        "cond_entropy-2": 1.4452124770206045,
        "distinct-3": 0.03330165860400829,
        "vocab_size-3": 771,
        "unique-3": 125,
        "entropy-3": 8.143135315057956,
        "cond_entropy-3": 0.9257070264045979,
        "total_length-nopunct": 22761,
        "mean_pred_length-nopunct": 29.406976744186046,
        "std_pred_length-nopunct": 3.7469716153556423,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.004701023680857608,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 5.742663668386649,
        "distinct-2-nopunct": 0.017191977077363897,
        "vocab_size-2-nopunct": 378,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 7.210437803686032,
        "cond_entropy-2-nopunct": 1.4901034764042058,
        "distinct-3-nopunct": 0.03568566445104417,
        "vocab_size-3-nopunct": 757,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 8.187868361275271,
        "cond_entropy-3-nopunct": 0.9615991893055865,
        "msttr-100": 0.31032,
        "msttr-100_nopunct": 0.30467,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.5209864341333805,
        "rouge1": {
            "precision": 0.80249,
            "recall": 0.74244,
            "fmeasure": 0.76547
        },
        "rouge2": {
            "precision": 0.49129,
            "recall": 0.45509,
            "fmeasure": 0.46889
        },
        "rougeL": {
            "precision": 0.53128,
            "recall": 0.49341,
            "fmeasure": 0.50781
        },
        "rougeLsum": {
            "precision": 0.53128,
            "recall": 0.49341,
            "fmeasure": 0.50781
        },
        "local_recall": {
            "1": 0.729749871908333
        },
        "bleu": 34.18338,
        "nubia": {
            "semantic_relation": 4.43608,
            "contradiction": 3.07665,
            "irrelevancy": 12.75181,
            "logical_agreement": 84.17154,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.16536,
            "nubia_score": 0.82873
        },
        "meteor": 0.3732510353716834,
        "bleurt": 0.29676,
        "bertscore": {
            "precision": 0.92564,
            "recall": 0.91006,
            "f1": 0.9176
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 73,
        "total_length": 2437,
        "mean_pred_length": 33.38356164383562,
        "std_pred_length": 5.303475564959062,
        "median_pred_length": 32.0,
        "min_pred_length": 25,
        "max_pred_length": 44,
        "distinct-1": 0.03652031185884284,
        "vocab_size-1": 89,
        "unique-1": 3,
        "entropy-1": 5.615852396599978,
        "distinct-2": 0.11209813874788493,
        "vocab_size-2": 265,
        "unique-2": 55,
        "entropy-2": 7.128026897361736,
        "cond_entropy-2": 1.4543440335119966,
        "distinct-3": 0.19947621126145787,
        "vocab_size-3": 457,
        "unique-3": 142,
        "entropy-3": 8.025215038518958,
        "cond_entropy-3": 0.8893093273012083,
        "total_length-nopunct": 2249,
        "mean_pred_length-nopunct": 30.80821917808219,
        "std_pred_length-nopunct": 4.671855500224153,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.03868385949310805,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 5.643445204326874,
        "distinct-2-nopunct": 0.12040441176470588,
        "vocab_size-2-nopunct": 262,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 7.144972912527993,
        "cond_entropy-2-nopunct": 1.505296544838287,
        "distinct-3-nopunct": 0.2201616737993343,
        "vocab_size-3-nopunct": 463,
        "unique-3-nopunct": 157,
        "entropy-3-nopunct": 8.101198881471078,
        "cond_entropy-3-nopunct": 0.921510873947643,
        "msttr-100": 0.37417,
        "msttr-100_nopunct": 0.37636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.625919940589558,
        "rouge1": {
            "precision": 0.80553,
            "recall": 0.80584,
            "fmeasure": 0.80061
        },
        "rouge2": {
            "precision": 0.5511,
            "recall": 0.55165,
            "fmeasure": 0.54777
        },
        "rougeL": {
            "precision": 0.57197,
            "recall": 0.57914,
            "fmeasure": 0.57221
        },
        "rougeLsum": {
            "precision": 0.57197,
            "recall": 0.57914,
            "fmeasure": 0.57221
        },
        "local_recall": {
            "1": 0.7876016260162602
        },
        "bleu": 41.78902,
        "nubia": {
            "semantic_relation": 4.51879,
            "contradiction": 4.71181,
            "irrelevancy": 15.53867,
            "logical_agreement": 79.74953,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.20368,
            "nubia_score": 0.8559
        },
        "meteor": 0.4085787249127964,
        "bleurt": 0.3425,
        "bertscore": {
            "precision": 0.93124,
            "recall": 0.92274,
            "f1": 0.92682
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "total_length": 7646,
        "mean_pred_length": 15.292,
        "std_pred_length": 6.545436272701767,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 43,
        "distinct-1": 0.07729531781323568,
        "vocab_size-1": 591,
        "unique-1": 255,
        "entropy-1": 6.4183740523143396,
        "distinct-2": 0.22040302267002518,
        "vocab_size-2": 1575,
        "unique-2": 867,
        "entropy-2": 9.069494783635255,
        "cond_entropy-2": 2.5628699736815457,
        "distinct-3": 0.35164008426120974,
        "vocab_size-3": 2337,
        "unique-3": 1519,
        "entropy-3": 9.843374953390152,
        "cond_entropy-3": 0.8289729011777648,
        "total_length-nopunct": 6967,
        "mean_pred_length-nopunct": 13.934,
        "std_pred_length-nopunct": 6.206580701159053,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.08425434189751686,
        "vocab_size-1-nopunct": 587,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 6.420199845479375,
        "distinct-2-nopunct": 0.2166383176124942,
        "vocab_size-2-nopunct": 1401,
        "unique-2-nopunct": 764,
        "entropy-2-nopunct": 8.907722066710951,
        "cond_entropy-2-nopunct": 2.6584327885879087,
        "distinct-3-nopunct": 0.351265292441763,
        "vocab_size-3-nopunct": 2096,
        "unique-3-nopunct": 1360,
        "entropy-3-nopunct": 9.678314757460221,
        "cond_entropy-3-nopunct": 0.839711823140012,
        "msttr-100": 0.55211,
        "msttr-100_nopunct": 0.56319,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "nist": 1.554564490703202,
        "rouge1": {
            "precision": 0.42022,
            "recall": 0.42597,
            "fmeasure": 0.40968
        },
        "rouge2": {
            "precision": 0.22025,
            "recall": 0.22635,
            "fmeasure": 0.21515
        },
        "rougeL": {
            "precision": 0.36774,
            "recall": 0.37441,
            "fmeasure": 0.35919
        },
        "rougeLsum": {
            "precision": 0.36774,
            "recall": 0.37441,
            "fmeasure": 0.35919
        },
        "local_recall": {
            "1": 0.2676450034940601
        },
        "bleu": 3.55975,
        "nubia": {
            "semantic_relation": 2.67356,
            "contradiction": 36.10408,
            "irrelevancy": 25.50304,
            "logical_agreement": 38.39288,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.26929,
            "nubia_score": 0.32425
        },
        "meteor": 0.12456857394316762,
        "bleurt": -0.65408,
        "bertscore": {
            "precision": 0.82663,
            "recall": 0.85268,
            "f1": 0.83919
        }
    },
    "totto_validation": {
        "predictions_file": "T5-small (Baseline)/totto_validation",
        "N": 7700
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "total_length": 18453,
        "mean_pred_length": 14.809791332263242,
        "std_pred_length": 5.06046272014838,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.09787026499756137,
        "vocab_size-1": 1806,
        "unique-1": 878,
        "entropy-1": 7.782620420251036,
        "distinct-2": 0.2580926367176149,
        "vocab_size-2": 4441,
        "unique-2": 2593,
        "entropy-2": 10.283238566894521,
        "cond_entropy-2": 2.3018576320401825,
        "distinct-3": 0.3934590564500971,
        "vocab_size-3": 6280,
        "unique-3": 4187,
        "entropy-3": 11.367130864113228,
        "cond_entropy-3": 1.1623460630437634,
        "total_length-nopunct": 16528,
        "mean_pred_length-nopunct": 13.264847512038523,
        "std_pred_length-nopunct": 4.598188658747531,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.10836156824782188,
        "vocab_size-1-nopunct": 1791,
        "unique-1-nopunct": 876,
        "entropy-1-nopunct": 7.917132073827324,
        "distinct-2-nopunct": 0.25958644156524013,
        "vocab_size-2-nopunct": 3967,
        "unique-2-nopunct": 2356,
        "entropy-2-nopunct": 10.085160592474153,
        "cond_entropy-2-nopunct": 2.3416575852585177,
        "distinct-3-nopunct": 0.3974779139355942,
        "vocab_size-3-nopunct": 5579,
        "unique-3-nopunct": 3777,
        "entropy-3-nopunct": 11.16695580402483,
        "cond_entropy-3-nopunct": 1.20377090534586,
        "msttr-100": 0.65179,
        "msttr-100_nopunct": 0.66624,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.286734407347278,
        "rouge1": {
            "precision": 0.70365,
            "recall": 0.66215,
            "fmeasure": 0.67116
        },
        "rouge2": {
            "precision": 0.4956,
            "recall": 0.46582,
            "fmeasure": 0.4717
        },
        "rougeL": {
            "precision": 0.61407,
            "recall": 0.57917,
            "fmeasure": 0.5865
        },
        "rougeLsum": {
            "precision": 0.61407,
            "recall": 0.57917,
            "fmeasure": 0.5865
        },
        "local_recall": {
            "1": 0.6389452332657201
        },
        "bleu": 38.67612,
        "nubia": {
            "semantic_relation": 4.28412,
            "contradiction": 9.07414,
            "irrelevancy": 16.10298,
            "logical_agreement": 74.82289,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.79504,
            "nubia_score": 0.76428
        },
        "meteor": 0.3656303980833738,
        "bleurt": -0.00929,
        "bertscore": {
            "precision": 0.90189,
            "recall": 0.88944,
            "f1": 0.8952
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "total_length": 36603,
        "mean_pred_length": 14.542312276519667,
        "std_pred_length": 4.282103444527554,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 42,
        "distinct-1": 0.06472147091768435,
        "vocab_size-1": 2369,
        "unique-1": 1127,
        "entropy-1": 7.979837603269472,
        "distinct-2": 0.2180073930646013,
        "vocab_size-2": 7431,
        "unique-2": 4241,
        "entropy-2": 11.062641502226713,
        "cond_entropy-2": 2.8536775060946202,
        "distinct-3": 0.36779752288637585,
        "vocab_size-3": 11611,
        "unique-3": 7707,
        "entropy-3": 12.253443788853428,
        "cond_entropy-3": 1.2571913379498412,
        "total_length-nopunct": 32261,
        "mean_pred_length-nopunct": 12.817242749304729,
        "std_pred_length-nopunct": 3.854625446397402,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.0729983571494994,
        "vocab_size-1-nopunct": 2355,
        "unique-1-nopunct": 1125,
        "entropy-1-nopunct": 8.17134869916868,
        "distinct-2-nopunct": 0.22885287789133943,
        "vocab_size-2-nopunct": 6807,
        "unique-2-nopunct": 3991,
        "entropy-2-nopunct": 10.915709808453704,
        "cond_entropy-2-nopunct": 2.926239360697119,
        "distinct-3-nopunct": 0.381055569838763,
        "vocab_size-3-nopunct": 10375,
        "unique-3-nopunct": 7006,
        "entropy-3-nopunct": 12.096919530714548,
        "cond_entropy-3-nopunct": 1.2856004501426133,
        "msttr-100": 0.67689,
        "msttr-100_nopunct": 0.70298,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.883943669295052,
        "rouge1": {
            "precision": 0.63773,
            "recall": 0.6101,
            "fmeasure": 0.61321
        },
        "rouge2": {
            "precision": 0.40815,
            "recall": 0.39126,
            "fmeasure": 0.3925
        },
        "rougeL": {
            "precision": 0.55919,
            "recall": 0.53577,
            "fmeasure": 0.53808
        },
        "rougeLsum": {
            "precision": 0.55919,
            "recall": 0.53577,
            "fmeasure": 0.53808
        },
        "local_recall": {
            "1": 0.5857995562361323
        },
        "bleu": 33.37279,
        "nubia": {
            "semantic_relation": 3.96966,
            "contradiction": 9.28838,
            "irrelevancy": 20.241,
            "logical_agreement": 70.47062,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.60798,
            "nubia_score": 0.69371
        },
        "meteor": 0.3256688307824537,
        "bleurt": -0.04504,
        "bertscore": {
            "precision": 0.8861,
            "recall": 0.87743,
            "f1": 0.88135
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 4168,
        "mean_pred_length": 8.336,
        "std_pred_length": 1.466664242422239,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.014395393474088292,
        "vocab_size-1": 60,
        "unique-1": 9,
        "entropy-1": 4.5712128632288715,
        "distinct-2": 0.04171210468920392,
        "vocab_size-2": 153,
        "unique-2": 30,
        "entropy-2": 5.774352689776508,
        "cond_entropy-2": 1.0022028353654453,
        "distinct-3": 0.07354797979797979,
        "vocab_size-3": 233,
        "unique-3": 64,
        "entropy-3": 6.269346865956814,
        "cond_entropy-3": 0.6182354440721258,
        "total_length-nopunct": 3671,
        "mean_pred_length-nopunct": 7.342,
        "std_pred_length-nopunct": 1.4618604584569623,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.01607191500953419,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 4.59153877556851,
        "distinct-2-nopunct": 0.0413118889940082,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 5.4434499951086,
        "cond_entropy-2-nopunct": 1.053183562225706,
        "distinct-3-nopunct": 0.07150879820292025,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.879865094326086,
        "cond_entropy-3-nopunct": 0.6867453792340857,
        "msttr-100": 0.29439,
        "msttr-100_nopunct": 0.29722,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.655342754041573,
        "rouge1": {
            "precision": 0.57586,
            "recall": 0.54785,
            "fmeasure": 0.55248
        },
        "rouge2": {
            "precision": 0.34688,
            "recall": 0.32615,
            "fmeasure": 0.32968
        },
        "rougeL": {
            "precision": 0.55297,
            "recall": 0.52734,
            "fmeasure": 0.53121
        },
        "rougeLsum": {
            "precision": 0.55297,
            "recall": 0.52734,
            "fmeasure": 0.53121
        },
        "local_recall": {
            "1": 0.5333156357844439
        },
        "bleu": 28.69549,
        "nubia": {
            "semantic_relation": 3.67124,
            "contradiction": 6.93055,
            "irrelevancy": 19.12669,
            "logical_agreement": 73.94276,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.78869,
            "nubia_score": 0.73248
        },
        "meteor": 0.28967786955326413,
        "bleurt": 0.10416,
        "bertscore": {
            "precision": 0.89191,
            "recall": 0.88727,
            "f1": 0.88925
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "total_length": 24660,
        "mean_pred_length": 18.569277108433734,
        "std_pred_length": 4.882167769344904,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 41,
        "distinct-1": 0.07793998377939984,
        "vocab_size-1": 1922,
        "unique-1": 950,
        "entropy-1": 7.8921664208204625,
        "distinct-2": 0.23474198525630036,
        "vocab_size-2": 5477,
        "unique-2": 3155,
        "entropy-2": 10.751309092581112,
        "cond_entropy-2": 2.67902285183965,
        "distinct-3": 0.38524813670241775,
        "vocab_size-3": 8477,
        "unique-3": 5613,
        "entropy-3": 11.939280863724148,
        "cond_entropy-3": 1.2488517556245597,
        "total_length-nopunct": 21697,
        "mean_pred_length-nopunct": 16.338102409638555,
        "std_pred_length-nopunct": 4.353643400300735,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.08798451398810896,
        "vocab_size-1-nopunct": 1909,
        "unique-1-nopunct": 948,
        "entropy-1-nopunct": 8.101464876874541,
        "distinct-2-nopunct": 0.2512641759536551,
        "vocab_size-2-nopunct": 5118,
        "unique-2-nopunct": 3017,
        "entropy-2-nopunct": 10.680334924730197,
        "cond_entropy-2-nopunct": 2.7174942918639826,
        "distinct-3-nopunct": 0.4094322777165065,
        "vocab_size-3-nopunct": 7796,
        "unique-3-nopunct": 5293,
        "entropy-3-nopunct": 11.873397034919678,
        "cond_entropy-3-nopunct": 1.2828457354364384,
        "msttr-100": 0.67045,
        "msttr-100_nopunct": 0.69856,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.737946830216495,
        "rouge1": {
            "precision": 0.6512,
            "recall": 0.6085,
            "fmeasure": 0.61714
        },
        "rouge2": {
            "precision": 0.41925,
            "recall": 0.39313,
            "fmeasure": 0.39788
        },
        "rougeL": {
            "precision": 0.55352,
            "recall": 0.51844,
            "fmeasure": 0.52544
        },
        "rougeLsum": {
            "precision": 0.55352,
            "recall": 0.51844,
            "fmeasure": 0.52544
        },
        "local_recall": {
            "1": 0.5864332603938731
        },
        "bleu": 31.69258,
        "nubia": {
            "semantic_relation": 4.15159,
            "contradiction": 7.32681,
            "irrelevancy": 16.35025,
            "logical_agreement": 76.32294,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.66543,
            "nubia_score": 0.71705
        },
        "meteor": 0.3256586653445627,
        "bleurt": -0.05369,
        "bertscore": {
            "precision": 0.89152,
            "recall": 0.87746,
            "f1": 0.88404
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "total_length": 21420,
        "mean_pred_length": 10.30798845043311,
        "std_pred_length": 5.33366410249916,
        "median_pred_length": 8.0,
        "min_pred_length": 2,
        "max_pred_length": 41,
        "distinct-1": 0.01750700280112045,
        "vocab_size-1": 375,
        "unique-1": 103,
        "entropy-1": 6.041949248437205,
        "distinct-2": 0.07481129149002172,
        "vocab_size-2": 1447,
        "unique-2": 498,
        "entropy-2": 8.4671492618797,
        "cond_entropy-2": 2.137000180212556,
        "distinct-3": 0.15413577386468952,
        "vocab_size-3": 2661,
        "unique-3": 1267,
        "entropy-3": 9.548009297533447,
        "cond_entropy-3": 1.1599438330299257,
        "total_length-nopunct": 18615,
        "mean_pred_length-nopunct": 8.95813282001925,
        "std_pred_length-nopunct": 4.788066531932947,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.0198764437281762,
        "vocab_size-1-nopunct": 370,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.195445952969343,
        "distinct-2-nopunct": 0.08187700308399347,
        "vocab_size-2-nopunct": 1354,
        "unique-2-nopunct": 514,
        "entropy-2-nopunct": 8.215058491220404,
        "cond_entropy-2-nopunct": 2.2261858116510655,
        "distinct-3-nopunct": 0.1665859899038794,
        "vocab_size-3-nopunct": 2409,
        "unique-3-nopunct": 1228,
        "entropy-3-nopunct": 9.288111271545326,
        "cond_entropy-3-nopunct": 1.183131133182611,
        "msttr-100": 0.48042,
        "msttr-100_nopunct": 0.50048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.669017929960011,
        "rouge1": {
            "precision": 0.47775,
            "recall": 0.43385,
            "fmeasure": 0.44014
        },
        "rouge2": {
            "precision": 0.24525,
            "recall": 0.22459,
            "fmeasure": 0.22585
        },
        "rougeL": {
            "precision": 0.44067,
            "recall": 0.40088,
            "fmeasure": 0.40667
        },
        "rougeLsum": {
            "precision": 0.44067,
            "recall": 0.40088,
            "fmeasure": 0.40667
        },
        "local_recall": {
            "1": 0.42448388265121334
        },
        "bleu": 18.06175,
        "nubia": {
            "semantic_relation": 3.1036,
            "contradiction": 13.79265,
            "irrelevancy": 23.32721,
            "logical_agreement": 62.88013,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.27062,
            "nubia_score": 0.536
        },
        "meteor": 0.23303034173740234,
        "bleurt": -0.27889,
        "bertscore": {
            "precision": 0.84719,
            "recall": 0.83412,
            "f1": 0.83985
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "total_length": 7053,
        "mean_pred_length": 9.864335664335664,
        "std_pred_length": 2.8967888079421606,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 24,
        "distinct-1": 0.009924854671770877,
        "vocab_size-1": 70,
        "unique-1": 19,
        "entropy-1": 4.07229973034576,
        "distinct-2": 0.023824550331334807,
        "vocab_size-2": 151,
        "unique-2": 55,
        "entropy-2": 4.570199013766456,
        "cond_entropy-2": 0.4136490616420539,
        "distinct-3": 0.03539036101725058,
        "vocab_size-3": 199,
        "unique-3": 83,
        "entropy-3": 4.656318676476073,
        "cond_entropy-3": 0.09194656477030502,
        "total_length-nopunct": 6250,
        "mean_pred_length-nopunct": 8.741258741258742,
        "std_pred_length-nopunct": 2.5185001828102376,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.01072,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 3.9333734489822088,
        "distinct-2-nopunct": 0.025112917795844625,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 4.311678234167313,
        "cond_entropy-2-nopunct": 0.3530828965588966,
        "distinct-3-nopunct": 0.036721991701244815,
        "vocab_size-3-nopunct": 177,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 4.382942230554968,
        "cond_entropy-3-nopunct": 0.04561165921378949,
        "msttr-100": 0.206,
        "msttr-100_nopunct": 0.19081,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 2.975989639476034,
        "rouge1": {
            "precision": 0.54646,
            "recall": 0.60928,
            "fmeasure": 0.56564
        },
        "rouge2": {
            "precision": 0.29585,
            "recall": 0.32107,
            "fmeasure": 0.3012
        },
        "rougeL": {
            "precision": 0.45915,
            "recall": 0.50484,
            "fmeasure": 0.47189
        },
        "rougeLsum": {
            "precision": 0.45915,
            "recall": 0.50484,
            "fmeasure": 0.47189
        },
        "local_recall": {
            "1": 0.6082899694957833
        },
        "bleu": 27.41708,
        "nubia": {
            "semantic_relation": 3.70823,
            "contradiction": 1.06311,
            "irrelevancy": 23.79638,
            "logical_agreement": 75.14051,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.12426,
            "nubia_score": 0.78011
        },
        "meteor": 0.3014408934737308,
        "bleurt": 0.25691,
        "bertscore": {
            "precision": 0.8561,
            "recall": 0.86906,
            "f1": 0.86204
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_test",
        "N": 4693,
        "total_length": 116485,
        "mean_pred_length": 24.82101001491583,
        "std_pred_length": 6.442977905433643,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 44,
        "distinct-1": 0.001837146413701335,
        "vocab_size-1": 214,
        "unique-1": 17,
        "entropy-1": 5.791460687464363,
        "distinct-2": 0.007540790038643195,
        "vocab_size-2": 843,
        "unique-2": 131,
        "entropy-2": 7.495903820430885,
        "cond_entropy-2": 1.6144252586987087,
        "distinct-3": 0.016592125043184344,
        "vocab_size-3": 1777,
        "unique-3": 337,
        "entropy-3": 8.559961037761186,
        "cond_entropy-3": 1.09407910464822,
        "total_length-nopunct": 106780,
        "mean_pred_length-nopunct": 22.753036437246962,
        "std_pred_length-nopunct": 5.957208892277344,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.0019853905225697696,
        "vocab_size-1-nopunct": 212,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 5.850147389187399,
        "distinct-2-nopunct": 0.007914817753484772,
        "vocab_size-2-nopunct": 808,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 7.483835667199672,
        "cond_entropy-2-nopunct": 1.6865185357156596,
        "distinct-3-nopunct": 0.017803971497217488,
        "vocab_size-3-nopunct": 1734,
        "unique-3-nopunct": 326,
        "entropy-3-nopunct": 8.619128393912376,
        "cond_entropy-3-nopunct": 1.1434642154224726,
        "msttr-100": 0.28493,
        "msttr-100_nopunct": 0.27903,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.444061752957559,
        "rouge1": {
            "precision": 0.76509,
            "recall": 0.72332,
            "fmeasure": 0.73201
        },
        "rouge2": {
            "precision": 0.46871,
            "recall": 0.4431,
            "fmeasure": 0.44818
        },
        "rougeL": {
            "precision": 0.54524,
            "recall": 0.51609,
            "fmeasure": 0.52182
        },
        "rougeLsum": {
            "precision": 0.54524,
            "recall": 0.51609,
            "fmeasure": 0.52182
        },
        "local_recall": {
            "1": 0.7141994973979461
        },
        "bleu": 32.73934,
        "nubia": {
            "semantic_relation": 4.32337,
            "contradiction": 2.5932,
            "irrelevancy": 17.83251,
            "logical_agreement": 79.57429,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.40563,
            "nubia_score": 0.8003
        },
        "meteor": 0.3672321687773484,
        "bleurt": 0.22974,
        "bertscore": {
            "precision": 0.92169,
            "recall": 0.9074,
            "f1": 0.91414
        }
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2306,
        "mean_pred_length": 21.754716981132077,
        "std_pred_length": 4.3822354094744,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 38,
        "distinct-1": 0.3612315698178664,
        "vocab_size-1": 833,
        "unique-1": 609,
        "entropy-1": 7.9097373353193134,
        "distinct-2": 0.7745454545454545,
        "vocab_size-2": 1704,
        "unique-2": 1498,
        "entropy-2": 10.428792479459702,
        "cond_entropy-2": 2.3520337872419708,
        "distinct-3": 0.940305635148042,
        "vocab_size-3": 1969,
        "unique-3": 1884,
        "entropy-3": 10.887542003982286,
        "cond_entropy-3": 0.4732562529805406,
        "total_length-nopunct": 2132,
        "mean_pred_length-nopunct": 20.11320754716981,
        "std_pred_length-nopunct": 4.093991812024564,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.3869606003752345,
        "vocab_size-1-nopunct": 825,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 8.007506447938429,
        "distinct-2-nopunct": 0.78035538005923,
        "vocab_size-2-nopunct": 1581,
        "unique-2-nopunct": 1393,
        "entropy-2-nopunct": 10.327304837720273,
        "cond_entropy-2-nopunct": 2.418647535586946,
        "distinct-3-nopunct": 0.9489583333333333,
        "vocab_size-3-nopunct": 1822,
        "unique-3-nopunct": 1750,
        "entropy-3-nopunct": 10.788402464398272,
        "cond_entropy-3-nopunct": 0.46927753933462296,
        "msttr-100": 0.67783,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.2725318961640713,
        "rouge1": {
            "precision": 0.38959,
            "recall": 0.39227,
            "fmeasure": 0.38373
        },
        "rouge2": {
            "precision": 0.16216,
            "recall": 0.16467,
            "fmeasure": 0.16026
        },
        "rougeL": {
            "precision": 0.31393,
            "recall": 0.31571,
            "fmeasure": 0.3093
        },
        "rougeLsum": {
            "precision": 0.31393,
            "recall": 0.31571,
            "fmeasure": 0.3093
        },
        "local_recall": {
            "1": 0.3699949315762798
        },
        "bleu": 11.84405,
        "nubia": {
            "semantic_relation": 2.69461,
            "contradiction": 24.07597,
            "irrelevancy": 67.65629,
            "logical_agreement": 8.26774,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.43672,
            "nubia_score": 0.39833
        },
        "meteor": 0.18207857485375958,
        "bleurt": -0.33211,
        "bertscore": {
            "precision": 0.82473,
            "recall": 0.82312,
            "f1": 0.82354
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2205,
        "mean_pred_length": 20.80188679245283,
        "std_pred_length": 4.0338656288617685,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 42,
        "distinct-1": 0.3795918367346939,
        "vocab_size-1": 837,
        "unique-1": 619,
        "entropy-1": 7.9647749209712275,
        "distinct-2": 0.7984754645069081,
        "vocab_size-2": 1676,
        "unique-2": 1494,
        "entropy-2": 10.426450862435338,
        "cond_entropy-2": 2.280575399244358,
        "distinct-3": 0.9458103361766181,
        "vocab_size-3": 1885,
        "unique-3": 1816,
        "entropy-3": 10.827828981414582,
        "cond_entropy-3": 0.4215954345394137,
        "total_length-nopunct": 2057,
        "mean_pred_length-nopunct": 19.40566037735849,
        "std_pred_length-nopunct": 3.887032874044384,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.4035002430724356,
        "vocab_size-1-nopunct": 830,
        "unique-1-nopunct": 616,
        "entropy-1-nopunct": 8.07440672550491,
        "distinct-2-nopunct": 0.7990773962070733,
        "vocab_size-2-nopunct": 1559,
        "unique-2-nopunct": 1389,
        "entropy-2-nopunct": 10.321901801079592,
        "cond_entropy-2-nopunct": 2.358495919167912,
        "distinct-3-nopunct": 0.9495934959349593,
        "vocab_size-3-nopunct": 1752,
        "unique-3-nopunct": 1688,
        "entropy-3-nopunct": 10.732302058970122,
        "cond_entropy-3-nopunct": 0.43031828302527314,
        "msttr-100": 0.69409,
        "msttr-100_nopunct": 0.7135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.3228516188207475,
        "rouge1": {
            "precision": 0.41185,
            "recall": 0.37768,
            "fmeasure": 0.38643
        },
        "rouge2": {
            "precision": 0.15602,
            "recall": 0.14445,
            "fmeasure": 0.14648
        },
        "rougeL": {
            "precision": 0.31094,
            "recall": 0.28685,
            "fmeasure": 0.29247
        },
        "rougeLsum": {
            "precision": 0.31094,
            "recall": 0.28685,
            "fmeasure": 0.29247
        },
        "local_recall": {
            "1": 0.35243960208432024
        },
        "bleu": 9.53857,
        "nubia": {
            "semantic_relation": 2.72283,
            "contradiction": 26.72553,
            "irrelevancy": 63.9176,
            "logical_agreement": 9.35687,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.54636,
            "nubia_score": 0.37468
        },
        "meteor": 0.17221169764267447,
        "bleurt": -0.37059,
        "bertscore": {
            "precision": 0.83032,
            "recall": 0.81697,
            "f1": 0.82326
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2222,
        "mean_pred_length": 20.962264150943398,
        "std_pred_length": 4.1229329373270165,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.369036903690369,
        "vocab_size-1": 820,
        "unique-1": 601,
        "entropy-1": 7.877567257540691,
        "distinct-2": 0.781663516068053,
        "vocab_size-2": 1654,
        "unique-2": 1471,
        "entropy-2": 10.373590095856287,
        "cond_entropy-2": 2.321300943827656,
        "distinct-3": 0.9288557213930348,
        "vocab_size-3": 1867,
        "unique-3": 1784,
        "entropy-3": 10.797289810911822,
        "cond_entropy-3": 0.4325976302392995,
        "total_length-nopunct": 2079,
        "mean_pred_length-nopunct": 19.61320754716981,
        "std_pred_length-nopunct": 4.083031510460669,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.3924963924963925,
        "vocab_size-1-nopunct": 816,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 7.981975115804413,
        "distinct-2-nopunct": 0.7866193613786112,
        "vocab_size-2-nopunct": 1552,
        "unique-2-nopunct": 1384,
        "entropy-2-nopunct": 10.284022855894268,
        "cond_entropy-2-nopunct": 2.405254841493321,
        "distinct-3-nopunct": 0.9357257632565613,
        "vocab_size-3-nopunct": 1747,
        "unique-3-nopunct": 1671,
        "entropy-3-nopunct": 10.714327690505558,
        "cond_entropy-3-nopunct": 0.43174815094548824,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.6885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.9146288683400607,
        "rouge1": {
            "precision": 0.38113,
            "recall": 0.3479,
            "fmeasure": 0.35753
        },
        "rouge2": {
            "precision": 0.11711,
            "recall": 0.1084,
            "fmeasure": 0.11049
        },
        "rougeL": {
            "precision": 0.28027,
            "recall": 0.25661,
            "fmeasure": 0.26351
        },
        "rougeLsum": {
            "precision": 0.28027,
            "recall": 0.25661,
            "fmeasure": 0.26351
        },
        "local_recall": {
            "1": 0.32350230414746545
        },
        "bleu": 6.5453,
        "nubia": {
            "semantic_relation": 2.51245,
            "contradiction": 33.31338,
            "irrelevancy": 58.23612,
            "logical_agreement": 8.45049,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.51012,
            "nubia_score": 0.32682
        },
        "meteor": 0.14896237428935893,
        "bleurt": -0.40032,
        "bertscore": {
            "precision": 0.82629,
            "recall": 0.80725,
            "f1": 0.81638
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2200,
        "mean_pred_length": 20.754716981132077,
        "std_pred_length": 4.106624470601351,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 33,
        "distinct-1": 0.3640909090909091,
        "vocab_size-1": 801,
        "unique-1": 585,
        "entropy-1": 7.888774888139493,
        "distinct-2": 0.7908309455587392,
        "vocab_size-2": 1656,
        "unique-2": 1466,
        "entropy-2": 10.405636166921383,
        "cond_entropy-2": 2.3390097035031103,
        "distinct-3": 0.9416498993963782,
        "vocab_size-3": 1872,
        "unique-3": 1787,
        "entropy-3": 10.823969098654837,
        "cond_entropy-3": 0.4309989943145064,
        "total_length-nopunct": 2048,
        "mean_pred_length-nopunct": 19.32075471698113,
        "std_pred_length-nopunct": 3.9942108338342956,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.3876953125,
        "vocab_size-1-nopunct": 794,
        "unique-1-nopunct": 585,
        "entropy-1-nopunct": 7.98533242774853,
        "distinct-2-nopunct": 0.7945417095777549,
        "vocab_size-2-nopunct": 1543,
        "unique-2-nopunct": 1370,
        "entropy-2-nopunct": 10.303958360380774,
        "cond_entropy-2-nopunct": 2.4189015074885245,
        "distinct-3-nopunct": 0.94880174291939,
        "vocab_size-3-nopunct": 1742,
        "unique-3-nopunct": 1669,
        "entropy-3-nopunct": 10.727805810448768,
        "cond_entropy-3-nopunct": 0.42848567984338015,
        "msttr-100": 0.68318,
        "msttr-100_nopunct": 0.7,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.9809438000702193,
        "rouge1": {
            "precision": 0.38884,
            "recall": 0.3477,
            "fmeasure": 0.3612
        },
        "rouge2": {
            "precision": 0.13442,
            "recall": 0.12026,
            "fmeasure": 0.12451
        },
        "rougeL": {
            "precision": 0.29189,
            "recall": 0.25639,
            "fmeasure": 0.26865
        },
        "rougeLsum": {
            "precision": 0.29189,
            "recall": 0.25639,
            "fmeasure": 0.26865
        },
        "local_recall": {
            "1": 0.3259953161592506
        },
        "bleu": 7.47129,
        "nubia": {
            "semantic_relation": 2.47658,
            "contradiction": 24.18794,
            "irrelevancy": 65.73162,
            "logical_agreement": 10.08044,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.54842,
            "nubia_score": 0.32487
        },
        "meteor": 0.1527387909348023,
        "bleurt": -0.44733,
        "bertscore": {
            "precision": 0.82047,
            "recall": 0.80222,
            "f1": 0.81098
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2191,
        "mean_pred_length": 20.669811320754718,
        "std_pred_length": 4.124756592276958,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.3925148334094021,
        "vocab_size-1": 860,
        "unique-1": 637,
        "entropy-1": 7.995667420826185,
        "distinct-2": 0.8129496402877698,
        "vocab_size-2": 1695,
        "unique-2": 1522,
        "entropy-2": 10.462958180863275,
        "cond_entropy-2": 2.2829364697357106,
        "distinct-3": 0.9494694290045478,
        "vocab_size-3": 1879,
        "unique-3": 1808,
        "entropy-3": 10.831080036506401,
        "cond_entropy-3": 0.3843698670969516,
        "total_length-nopunct": 2038,
        "mean_pred_length-nopunct": 19.22641509433962,
        "std_pred_length-nopunct": 3.919672249650195,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4185475956820412,
        "vocab_size-1-nopunct": 853,
        "unique-1-nopunct": 636,
        "entropy-1-nopunct": 8.098372690154443,
        "distinct-2-nopunct": 0.8146997929606625,
        "vocab_size-2-nopunct": 1574,
        "unique-2-nopunct": 1417,
        "entropy-2-nopunct": 10.352182745109102,
        "cond_entropy-2-nopunct": 2.3674331357247858,
        "distinct-3-nopunct": 0.9529025191675794,
        "vocab_size-3-nopunct": 1740,
        "unique-3-nopunct": 1676,
        "entropy-3-nopunct": 10.726208267668557,
        "cond_entropy-3-nopunct": 0.38983450155835625,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.0198923729479645,
        "rouge1": {
            "precision": 0.39689,
            "recall": 0.34384,
            "fmeasure": 0.363
        },
        "rouge2": {
            "precision": 0.13177,
            "recall": 0.11534,
            "fmeasure": 0.12127
        },
        "rougeL": {
            "precision": 0.29222,
            "recall": 0.25556,
            "fmeasure": 0.26882
        },
        "rougeLsum": {
            "precision": 0.29222,
            "recall": 0.25556,
            "fmeasure": 0.26882
        },
        "local_recall": {
            "1": 0.32878581173260574
        },
        "bleu": 8.2419,
        "nubia": {
            "semantic_relation": 2.48515,
            "contradiction": 23.18243,
            "irrelevancy": 67.76541,
            "logical_agreement": 9.05217,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.53539,
            "nubia_score": 0.33479
        },
        "meteor": 0.1521070845075913,
        "bleurt": -0.43884,
        "bertscore": {
            "precision": 0.82226,
            "recall": 0.80295,
            "f1": 0.81222
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2264,
        "mean_pred_length": 21.358490566037737,
        "std_pred_length": 4.038000344008515,
        "median_pred_length": 21.0,
        "min_pred_length": 14,
        "max_pred_length": 33,
        "distinct-1": 0.3741166077738516,
        "vocab_size-1": 847,
        "unique-1": 624,
        "entropy-1": 7.9524234926269255,
        "distinct-2": 0.7812789620018535,
        "vocab_size-2": 1686,
        "unique-2": 1487,
        "entropy-2": 10.397073268777067,
        "cond_entropy-2": 2.2709784672248436,
        "distinct-3": 0.9269005847953217,
        "vocab_size-3": 1902,
        "unique-3": 1796,
        "entropy-3": 10.83129039794303,
        "cond_entropy-3": 0.4482481271561174,
        "total_length-nopunct": 2107,
        "mean_pred_length-nopunct": 19.87735849056604,
        "std_pred_length-nopunct": 3.781042159891997,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.39867109634551495,
        "vocab_size-1-nopunct": 840,
        "unique-1-nopunct": 623,
        "entropy-1-nopunct": 8.046280501602835,
        "distinct-2-nopunct": 0.784607696151924,
        "vocab_size-2-nopunct": 1570,
        "unique-2-nopunct": 1387,
        "entropy-2-nopunct": 10.292674798407218,
        "cond_entropy-2-nopunct": 2.349021003216651,
        "distinct-3-nopunct": 0.9319261213720317,
        "vocab_size-3-nopunct": 1766,
        "unique-3-nopunct": 1670,
        "entropy-3-nopunct": 10.732874262119344,
        "cond_entropy-3-nopunct": 0.4549671184338543,
        "msttr-100": 0.67364,
        "msttr-100_nopunct": 0.69238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.795413925412999,
        "rouge1": {
            "precision": 0.37486,
            "recall": 0.33969,
            "fmeasure": 0.34895
        },
        "rouge2": {
            "precision": 0.11383,
            "recall": 0.1028,
            "fmeasure": 0.10564
        },
        "rougeL": {
            "precision": 0.27203,
            "recall": 0.2478,
            "fmeasure": 0.25402
        },
        "rougeLsum": {
            "precision": 0.27203,
            "recall": 0.2478,
            "fmeasure": 0.25402
        },
        "local_recall": {
            "1": 0.31668194317140236
        },
        "bleu": 6.57939,
        "nubia": {
            "semantic_relation": 2.42286,
            "contradiction": 28.56062,
            "irrelevancy": 62.24618,
            "logical_agreement": 9.1932,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.47156,
            "nubia_score": 0.31749
        },
        "meteor": 0.14340030156469727,
        "bleurt": -0.43461,
        "bertscore": {
            "precision": 0.82104,
            "recall": 0.80716,
            "f1": 0.81378
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2222,
        "mean_pred_length": 20.962264150943398,
        "std_pred_length": 4.65999540104617,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.37398739873987397,
        "vocab_size-1": 831,
        "unique-1": 609,
        "entropy-1": 7.891450844869043,
        "distinct-2": 0.77882797731569,
        "vocab_size-2": 1648,
        "unique-2": 1468,
        "entropy-2": 10.330286369629414,
        "cond_entropy-2": 2.263418138657679,
        "distinct-3": 0.926865671641791,
        "vocab_size-3": 1863,
        "unique-3": 1770,
        "entropy-3": 10.791138304455805,
        "cond_entropy-3": 0.4736480129344645,
        "total_length-nopunct": 2083,
        "mean_pred_length-nopunct": 19.650943396226417,
        "std_pred_length-nopunct": 4.539226209575997,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.3955832933269323,
        "vocab_size-1-nopunct": 824,
        "unique-1-nopunct": 607,
        "entropy-1-nopunct": 7.983955899336188,
        "distinct-2-nopunct": 0.7804754678806272,
        "vocab_size-2-nopunct": 1543,
        "unique-2-nopunct": 1378,
        "entropy-2-nopunct": 10.228280867217789,
        "cond_entropy-2-nopunct": 2.3541284876008186,
        "distinct-3-nopunct": 0.9321218599679316,
        "vocab_size-3-nopunct": 1744,
        "unique-3-nopunct": 1659,
        "entropy-3-nopunct": 10.704980479781135,
        "cond_entropy-3-nopunct": 0.49129295174097043,
        "msttr-100": 0.67227,
        "msttr-100_nopunct": 0.6935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.8115844964830727,
        "rouge1": {
            "precision": 0.38518,
            "recall": 0.34187,
            "fmeasure": 0.35323
        },
        "rouge2": {
            "precision": 0.12648,
            "recall": 0.11367,
            "fmeasure": 0.11573
        },
        "rougeL": {
            "precision": 0.29117,
            "recall": 0.25784,
            "fmeasure": 0.26635
        },
        "rougeLsum": {
            "precision": 0.29117,
            "recall": 0.25784,
            "fmeasure": 0.26635
        },
        "local_recall": {
            "1": 0.3132530120481928
        },
        "bleu": 7.09786,
        "nubia": {
            "semantic_relation": 2.34464,
            "contradiction": 30.1791,
            "irrelevancy": 59.48667,
            "logical_agreement": 10.33422,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.46307,
            "nubia_score": 0.30503
        },
        "meteor": 0.14050960812900165,
        "bleurt": -0.47153,
        "bertscore": {
            "precision": 0.81756,
            "recall": 0.80267,
            "f1": 0.80964
        }
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "total_length": 12562,
        "mean_pred_length": 25.124,
        "std_pred_length": 6.555045690153502,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 44,
        "distinct-1": 0.014090113039324947,
        "vocab_size-1": 177,
        "unique-1": 37,
        "entropy-1": 5.812759921024471,
        "distinct-2": 0.049908804510031504,
        "vocab_size-2": 602,
        "unique-2": 185,
        "entropy-2": 7.567876699757402,
        "cond_entropy-2": 1.6677125507635517,
        "distinct-3": 0.09920428991523958,
        "vocab_size-3": 1147,
        "unique-3": 426,
        "entropy-3": 8.628880511026974,
        "cond_entropy-3": 1.0853638640994552,
        "total_length-nopunct": 11513,
        "mean_pred_length-nopunct": 23.026,
        "std_pred_length-nopunct": 6.081227178785545,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.015200208460001738,
        "vocab_size-1-nopunct": 175,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.859672979698672,
        "distinct-2-nopunct": 0.05248342867520203,
        "vocab_size-2-nopunct": 578,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.547457372978411,
        "cond_entropy-2-nopunct": 1.7383305218028908,
        "distinct-3-nopunct": 0.10691524778845239,
        "vocab_size-3-nopunct": 1124,
        "unique-3-nopunct": 417,
        "entropy-3-nopunct": 8.675415797450041,
        "cond_entropy-3-nopunct": 1.1283048275205099,
        "msttr-100": 0.48336,
        "msttr-100_nopunct": 0.48809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "nist": 5.320527947299425,
        "rouge1": {
            "precision": 0.75561,
            "recall": 0.72054,
            "fmeasure": 0.72587
        },
        "rouge2": {
            "precision": 0.45523,
            "recall": 0.43406,
            "fmeasure": 0.437
        },
        "rougeL": {
            "precision": 0.52821,
            "recall": 0.50348,
            "fmeasure": 0.50713
        },
        "rougeLsum": {
            "precision": 0.52821,
            "recall": 0.50348,
            "fmeasure": 0.50713
        },
        "local_recall": {
            "1": 0.7137543011252674
        },
        "bleu": 31.59186,
        "nubia": {
            "semantic_relation": 4.2836,
            "contradiction": 2.82975,
            "irrelevancy": 18.90913,
            "logical_agreement": 78.26113,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.39498,
            "nubia_score": 0.78636
        },
        "meteor": 0.3642783914542359,
        "bleurt": 0.20242,
        "bertscore": {
            "precision": 0.91846,
            "recall": 0.90593,
            "f1": 0.91181
        }
    },
    "common_gen_validation": {
        "predictions_file": "T5-small (Baseline)/common_gen_validation",
        "N": 993
    },
    "common_gen_test": {
        "predictions_file": "T5-small (Baseline)/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "T5-small (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000
    },
    "totto_test": {
        "predictions_file": "T5-small (Baseline)/totto_test",
        "N": 7700,
        "total_length": 124200,
        "mean_pred_length": 16.12987012987013,
        "std_pred_length": 6.990811500654213,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 109,
        "distinct-1": 0.16936392914653783,
        "vocab_size-1": 21035,
        "unique-1": 14353,
        "entropy-1": 9.992875235737328,
        "distinct-2": 0.5261459227467811,
        "vocab_size-2": 61296,
        "unique-2": 50736,
        "entropy-2": 14.461250994353826,
        "cond_entropy-2": 4.073138607811618,
        "distinct-3": 0.7500919117647059,
        "vocab_size-3": 81610,
        "unique-3": 73420,
        "entropy-3": 15.752256834679427,
        "cond_entropy-3": 1.2752075923596364,
        "total_length-nopunct": 107684,
        "mean_pred_length-nopunct": 13.984935064935065,
        "std_pred_length-nopunct": 5.8630280336235945,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.195172913339029,
        "vocab_size-1-nopunct": 21017,
        "unique-1-nopunct": 14351,
        "entropy-1-nopunct": 10.572324549668526,
        "distinct-2-nopunct": 0.5720615298447752,
        "vocab_size-2-nopunct": 57197,
        "unique-2-nopunct": 48436,
        "entropy-2-nopunct": 14.466066802681373,
        "cond_entropy-2-nopunct": 4.073588843366503,
        "distinct-3-nopunct": 0.7801243985956395,
        "vocab_size-3-nopunct": 71993,
        "unique-3-nopunct": 65714,
        "entropy-3-nopunct": 15.637413954465353,
        "cond_entropy-3-nopunct": 1.2573064622326031,
        "msttr-100": 0.71004,
        "msttr-100_nopunct": 0.76511,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.4995981872761,
        "rouge1": {
            "precision": 0.76114,
            "recall": 0.71885,
            "fmeasure": 0.72699
        },
        "rouge2": {
            "precision": 0.53239,
            "recall": 0.50461,
            "fmeasure": 0.50916
        },
        "rougeL": {
            "precision": 0.6631,
            "recall": 0.62947,
            "fmeasure": 0.6348
        },
        "rougeLsum": {
            "precision": 0.6631,
            "recall": 0.62947,
            "fmeasure": 0.6348
        },
        "local_recall": {
            "1": 0.21638493656005514,
            "2": 0.44219904389395914,
            "3": 0.7547157963479265
        },
        "bleu": 45.21338,
        "nubia": {
            "semantic_relation": 4.12852,
            "contradiction": 11.03062,
            "irrelevancy": 28.44912,
            "logical_agreement": 60.52025,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.66135,
            "nubia_score": 0.70787
        },
        "meteor": 0.38421275188592846,
        "bleurt": 0.24921,
        "bertscore": {
            "precision": 0.92662,
            "recall": 0.9195,
            "f1": 0.9214
        }
    },
    "totto_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "total_length": 125494,
        "mean_pred_length": 12.5494,
        "std_pred_length": 7.043973285014644,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 50,
        "distinct-1": 0.03238401835944348,
        "vocab_size-1": 4064,
        "unique-1": 1771,
        "entropy-1": 7.937112604549057,
        "distinct-2": 0.12303669454690287,
        "vocab_size-2": 14210,
        "unique-2": 7461,
        "entropy-2": 11.186316399727511,
        "cond_entropy-2": 2.986995238004503,
        "distinct-3": 0.24072230911417603,
        "vocab_size-3": 25395,
        "unique-3": 15616,
        "entropy-3": 12.602824565370405,
        "cond_entropy-3": 1.451721190536153,
        "total_length-nopunct": 110198,
        "mean_pred_length-nopunct": 11.0198,
        "std_pred_length-nopunct": 6.448163146199079,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.03673387901776802,
        "vocab_size-1-nopunct": 4048,
        "unique-1-nopunct": 1769,
        "entropy-1-nopunct": 8.140205583069424,
        "distinct-2-nopunct": 0.13353559951296434,
        "vocab_size-2-nopunct": 13380,
        "unique-2-nopunct": 7257,
        "entropy-2-nopunct": 11.06979501083756,
        "cond_entropy-2-nopunct": 3.0867031317345375,
        "distinct-3-nopunct": 0.26002172852645117,
        "vocab_size-3-nopunct": 23455,
        "unique-3-nopunct": 14850,
        "entropy-3-nopunct": 12.502739399009153,
        "cond_entropy-3-nopunct": 1.4935872983990093,
        "msttr-100": 0.67529,
        "msttr-100_nopunct": 0.70012,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.87577615509305,
        "rouge1": {
            "precision": 0.58347,
            "recall": 0.55106,
            "fmeasure": 0.55513
        },
        "rouge2": {
            "precision": 0.36294,
            "recall": 0.34273,
            "fmeasure": 0.34479
        },
        "rougeL": {
            "precision": 0.52593,
            "recall": 0.49655,
            "fmeasure": 0.50039
        },
        "rougeLsum": {
            "precision": 0.52593,
            "recall": 0.49655,
            "fmeasure": 0.50039
        },
        "local_recall": {
            "1": 0.5605321389533179
        },
        "bleu": 31.72126,
        "nubia": {
            "semantic_relation": 3.59975,
            "contradiction": 8.7319,
            "irrelevancy": 20.21674,
            "logical_agreement": 71.05135,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.50803,
            "nubia_score": 0.64422
        },
        "meteor": 0.312170339299955,
        "bleurt": -0.06841,
        "bertscore": {
            "precision": 0.87469,
            "recall": 0.86535,
            "f1": 0.86951
        }
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "total_length": 6200,
        "mean_pred_length": 12.4,
        "std_pred_length": 7.0159817559625965,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 49,
        "distinct-1": 0.1456451612903226,
        "vocab_size-1": 903,
        "unique-1": 513,
        "entropy-1": 7.634484737208965,
        "distinct-2": 0.4205263157894737,
        "vocab_size-2": 2397,
        "unique-2": 1598,
        "entropy-2": 10.260010720676133,
        "cond_entropy-2": 2.364873710744506,
        "distinct-3": 0.6036538461538462,
        "vocab_size-3": 3139,
        "unique-3": 2422,
        "entropy-3": 11.001751317183125,
        "cond_entropy-3": 0.7748080472793446,
        "total_length-nopunct": 5422,
        "mean_pred_length-nopunct": 10.844,
        "std_pred_length-nopunct": 6.446678524635767,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.16433050534857985,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 510,
        "entropy-1-nopunct": 7.8069562532789085,
        "distinct-2-nopunct": 0.4333604225924421,
        "vocab_size-2-nopunct": 2133,
        "unique-2-nopunct": 1461,
        "entropy-2-nopunct": 10.075253667573131,
        "cond_entropy-2-nopunct": 2.416329076286592,
        "distinct-3-nopunct": 0.6189507010402533,
        "vocab_size-3-nopunct": 2737,
        "unique-3-nopunct": 2169,
        "entropy-3-nopunct": 10.801661017331998,
        "cond_entropy-3-nopunct": 0.7772528166249371,
        "msttr-100": 0.66435,
        "msttr-100_nopunct": 0.69296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "nist": 6.0100080928856645,
        "rouge1": {
            "precision": 0.57044,
            "recall": 0.55108,
            "fmeasure": 0.54713
        },
        "rouge2": {
            "precision": 0.3451,
            "recall": 0.33467,
            "fmeasure": 0.33145
        },
        "rougeL": {
            "precision": 0.51675,
            "recall": 0.49845,
            "fmeasure": 0.49562
        },
        "rougeLsum": {
            "precision": 0.51675,
            "recall": 0.49845,
            "fmeasure": 0.49562
        },
        "local_recall": {
            "1": 0.5632418397626113
        },
        "bleu": 32.48241,
        "nubia": {
            "semantic_relation": 3.60896,
            "contradiction": 8.58391,
            "irrelevancy": 20.64748,
            "logical_agreement": 70.76861,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.42976,
            "nubia_score": 0.65282
        },
        "meteor": 0.3170064953110792,
        "bleurt": -0.03418,
        "bertscore": {
            "precision": 0.87355,
            "recall": 0.86709,
            "f1": 0.86977
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "total_length": 6178,
        "mean_pred_length": 12.356,
        "std_pred_length": 7.079354772858894,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 37,
        "distinct-1": 0.14891550663645192,
        "vocab_size-1": 920,
        "unique-1": 508,
        "entropy-1": 7.717064430585541,
        "distinct-2": 0.42620641070799575,
        "vocab_size-2": 2420,
        "unique-2": 1612,
        "entropy-2": 10.335880328603112,
        "cond_entropy-2": 2.376669130289526,
        "distinct-3": 0.6131711085361143,
        "vocab_size-3": 3175,
        "unique-3": 2454,
        "entropy-3": 11.100848320061443,
        "cond_entropy-3": 0.7946222671459416,
        "total_length-nopunct": 5416,
        "mean_pred_length-nopunct": 10.832,
        "std_pred_length-nopunct": 6.492439911158208,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.1672821270310192,
        "vocab_size-1-nopunct": 906,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.891852727616648,
        "distinct-2-nopunct": 0.43999186330349876,
        "vocab_size-2-nopunct": 2163,
        "unique-2-nopunct": 1473,
        "entropy-2-nopunct": 10.169340494634406,
        "cond_entropy-2-nopunct": 2.4132173870300555,
        "distinct-3-nopunct": 0.6309712474530225,
        "vocab_size-3-nopunct": 2787,
        "unique-3-nopunct": 2191,
        "entropy-3-nopunct": 10.935422321151458,
        "cond_entropy-3-nopunct": 0.8139650258106054,
        "msttr-100": 0.67328,
        "msttr-100_nopunct": 0.70074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "nist": 6.107996255260852,
        "rouge1": {
            "precision": 0.59757,
            "recall": 0.54374,
            "fmeasure": 0.55691
        },
        "rouge2": {
            "precision": 0.37432,
            "recall": 0.3385,
            "fmeasure": 0.34674
        },
        "rougeL": {
            "precision": 0.53777,
            "recall": 0.48837,
            "fmeasure": 0.50077
        },
        "rougeLsum": {
            "precision": 0.53777,
            "recall": 0.48837,
            "fmeasure": 0.50077
        },
        "local_recall": {
            "1": 0.5504619138922782
        },
        "bleu": 31.53634,
        "nubia": {
            "semantic_relation": 3.60572,
            "contradiction": 7.98898,
            "irrelevancy": 18.59903,
            "logical_agreement": 73.41199,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.64737,
            "nubia_score": 0.63791
        },
        "meteor": 0.3098562162087375,
        "bleurt": -0.0906,
        "bertscore": {
            "precision": 0.87643,
            "recall": 0.85998,
            "f1": 0.8676
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "total_length": 5857,
        "mean_pred_length": 11.714,
        "std_pred_length": 7.0145708350547,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 66,
        "distinct-1": 0.1529793409595356,
        "vocab_size-1": 896,
        "unique-1": 513,
        "entropy-1": 7.655486184754217,
        "distinct-2": 0.42299794661190965,
        "vocab_size-2": 2266,
        "unique-2": 1542,
        "entropy-2": 10.163675126149572,
        "cond_entropy-2": 2.245247121631095,
        "distinct-3": 0.6007823759522339,
        "vocab_size-3": 2918,
        "unique-3": 2262,
        "entropy-3": 10.885955095271962,
        "cond_entropy-3": 0.7527122909806269,
        "total_length-nopunct": 5134,
        "mean_pred_length-nopunct": 10.268,
        "std_pred_length-nopunct": 6.52688103154945,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.17218543046357615,
        "vocab_size-1-nopunct": 884,
        "unique-1-nopunct": 509,
        "entropy-1-nopunct": 7.8363801659308105,
        "distinct-2-nopunct": 0.4341821320673284,
        "vocab_size-2-nopunct": 2012,
        "unique-2-nopunct": 1401,
        "entropy-2-nopunct": 9.971289293459733,
        "cond_entropy-2-nopunct": 2.2730498708634883,
        "distinct-3-nopunct": 0.6170778906627963,
        "vocab_size-3-nopunct": 2551,
        "unique-3-nopunct": 2021,
        "entropy-3-nopunct": 10.693844612801628,
        "cond_entropy-3-nopunct": 0.7646998419790981,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.69745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "nist": 6.002108313470567,
        "rouge1": {
            "precision": 0.59512,
            "recall": 0.53675,
            "fmeasure": 0.55314
        },
        "rouge2": {
            "precision": 0.37137,
            "recall": 0.33163,
            "fmeasure": 0.3426
        },
        "rougeL": {
            "precision": 0.54248,
            "recall": 0.48985,
            "fmeasure": 0.50482
        },
        "rougeLsum": {
            "precision": 0.54248,
            "recall": 0.48985,
            "fmeasure": 0.50482
        },
        "local_recall": {
            "1": 0.5491022352510077
        },
        "bleu": 31.62693,
        "nubia": {
            "semantic_relation": 3.5621,
            "contradiction": 7.73861,
            "irrelevancy": 18.37763,
            "logical_agreement": 73.88375,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.63181,
            "nubia_score": 0.6269
        },
        "meteor": 0.3093694622360799,
        "bleurt": -0.06164,
        "bertscore": {
            "precision": 0.87672,
            "recall": 0.86214,
            "f1": 0.86894
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "total_length": 5863,
        "mean_pred_length": 11.726,
        "std_pred_length": 6.70782557912771,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 39,
        "distinct-1": 0.1661265563704588,
        "vocab_size-1": 974,
        "unique-1": 573,
        "entropy-1": 7.8979975250416885,
        "distinct-2": 0.4484430356143949,
        "vocab_size-2": 2405,
        "unique-2": 1688,
        "entropy-2": 10.305572762647829,
        "cond_entropy-2": 2.402959211808533,
        "distinct-3": 0.635485197368421,
        "vocab_size-3": 3091,
        "unique-3": 2467,
        "entropy-3": 11.057905737489593,
        "cond_entropy-3": 0.8123995049857614,
        "total_length-nopunct": 5356,
        "mean_pred_length-nopunct": 10.712,
        "std_pred_length-nopunct": 6.144026041611477,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.179798356982823,
        "vocab_size-1-nopunct": 963,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 7.953149238303897,
        "distinct-2-nopunct": 0.4619028006589786,
        "vocab_size-2-nopunct": 2243,
        "unique-2-nopunct": 1599,
        "entropy-2-nopunct": 10.208073057351578,
        "cond_entropy-2-nopunct": 2.3941505518012987,
        "distinct-3-nopunct": 0.6543493229286206,
        "vocab_size-3-nopunct": 2851,
        "unique-3-nopunct": 2310,
        "entropy-3-nopunct": 10.97086062343002,
        "cond_entropy-3-nopunct": 0.8102107372759193,
        "msttr-100": 0.7031,
        "msttr-100_nopunct": 0.70925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "nist": 5.613778363734328,
        "rouge1": {
            "precision": 0.60094,
            "recall": 0.51946,
            "fmeasure": 0.54555
        },
        "rouge2": {
            "precision": 0.37077,
            "recall": 0.31905,
            "fmeasure": 0.33501
        },
        "rougeL": {
            "precision": 0.53699,
            "recall": 0.46406,
            "fmeasure": 0.48754
        },
        "rougeLsum": {
            "precision": 0.53699,
            "recall": 0.46406,
            "fmeasure": 0.48754
        },
        "local_recall": {
            "1": 0.532090414123082
        },
        "bleu": 28.06466,
        "nubia": {
            "semantic_relation": 3.56081,
            "contradiction": 9.91851,
            "irrelevancy": 17.30336,
            "logical_agreement": 72.77814,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.89891,
            "nubia_score": 0.6006
        },
        "meteor": 0.29824763303140267,
        "bleurt": -0.13687,
        "bertscore": {
            "precision": 0.87379,
            "recall": 0.84828,
            "f1": 0.86038
        }
    },
    "mlsum_de_test": {
        "predictions_file": "T5-small (Baseline)/mlsum_de_test",
        "N": 10695,
        "total_length": 247157,
        "mean_pred_length": 23.10958391771856,
        "std_pred_length": 9.470327507506422,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 109,
        "distinct-1": 0.12487204489454072,
        "vocab_size-1": 30863,
        "unique-1": 18472,
        "entropy-1": 10.116873124258033,
        "distinct-2": 0.5090754539841497,
        "vocab_size-2": 120377,
        "unique-2": 96157,
        "entropy-2": 15.367830482522777,
        "cond_entropy-2": 4.969918321216619,
        "distinct-3": 0.7946378345816705,
        "vocab_size-3": 179403,
        "unique-3": 161810,
        "entropy-3": 17.019213197707213,
        "cond_entropy-3": 1.6465642750395038,
        "total_length-nopunct": 220365,
        "mean_pred_length-nopunct": 20.604488078541376,
        "std_pred_length-nopunct": 8.402625341491463,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 99,
        "distinct-1-nopunct": 0.13998139450457195,
        "vocab_size-1-nopunct": 30847,
        "unique-1-nopunct": 18469,
        "entropy-1-nopunct": 10.62578010265472,
        "distinct-2-nopunct": 0.5592645585920732,
        "vocab_size-2-nopunct": 117261,
        "unique-2-nopunct": 95799,
        "entropy-2-nopunct": 15.567965330475323,
        "cond_entropy-2-nopunct": 5.092588129119176,
        "distinct-3-nopunct": 0.8244905138836537,
        "vocab_size-3-nopunct": 164053,
        "unique-3-nopunct": 149964,
        "entropy-3-nopunct": 16.979664183036842,
        "cond_entropy-3-nopunct": 1.4742598448198603,
        "msttr-100": 0.6956,
        "msttr-100_nopunct": 0.73844,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "nist": 4.495007580807072,
        "rouge1": {
            "precision": 0.31933,
            "recall": 0.28143,
            "fmeasure": 0.2879
        },
        "rouge2": {
            "precision": 0.19609,
            "recall": 0.17552,
            "fmeasure": 0.17889
        },
        "rougeL": {
            "precision": 0.28349,
            "recall": 0.25013,
            "fmeasure": 0.25608
        },
        "rougeLsum": {
            "precision": 0.28349,
            "recall": 0.25013,
            "fmeasure": 0.25608
        },
        "local_recall": {
            "1": 0.2806478802844642
        },
        "bleu": 20.12842,
        "nubia": {
            "semantic_relation": 2.12712,
            "contradiction": 34.48475,
            "irrelevancy": 40.81497,
            "logical_agreement": 24.70028,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.70172,
            "nubia_score": 0.26569
        },
        "meteor": 0.24662117980555281,
        "bleurt": -0.56032,
        "bertscore": {
            "precision": 0.86152,
            "recall": 0.85319,
            "f1": 0.85706
        }
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "T5-small (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "total_length": 6423,
        "mean_pred_length": 12.846,
        "std_pred_length": 7.016144525307329,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.14385801027557216,
        "vocab_size-1": 924,
        "unique-1": 505,
        "entropy-1": 7.6849943387251045,
        "distinct-2": 0.4234340705723451,
        "vocab_size-2": 2508,
        "unique-2": 1660,
        "entropy-2": 10.398518426617843,
        "cond_entropy-2": 2.4782075501177285,
        "distinct-3": 0.6168172598192883,
        "vocab_size-3": 3345,
        "unique-3": 2565,
        "entropy-3": 11.186803614476219,
        "cond_entropy-3": 0.8269504529338096,
        "total_length-nopunct": 5642,
        "mean_pred_length-nopunct": 11.284,
        "std_pred_length-nopunct": 6.410877007087252,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.1619992910315491,
        "vocab_size-1-nopunct": 914,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.852197871153078,
        "distinct-2-nopunct": 0.43582263710618435,
        "vocab_size-2-nopunct": 2241,
        "unique-2-nopunct": 1521,
        "entropy-2-nopunct": 10.222973950585162,
        "cond_entropy-2-nopunct": 2.5195684506057856,
        "distinct-3-nopunct": 0.6301959939694163,
        "vocab_size-3-nopunct": 2926,
        "unique-3-nopunct": 2292,
        "entropy-3-nopunct": 10.995357715776482,
        "cond_entropy-3-nopunct": 0.8236266710868486,
        "msttr-100": 0.67078,
        "msttr-100_nopunct": 0.69643,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "nist": 6.024313517694747,
        "rouge1": {
            "precision": 0.57267,
            "recall": 0.53178,
            "fmeasure": 0.54122
        },
        "rouge2": {
            "precision": 0.35709,
            "recall": 0.32871,
            "fmeasure": 0.33496
        },
        "rougeL": {
            "precision": 0.51062,
            "recall": 0.47245,
            "fmeasure": 0.48161
        },
        "rougeLsum": {
            "precision": 0.51062,
            "recall": 0.47245,
            "fmeasure": 0.48161
        },
        "local_recall": {
            "1": 0.5489588711065221
        },
        "bleu": 30.69627,
        "nubia": {
            "semantic_relation": 3.48093,
            "contradiction": 10.11966,
            "irrelevancy": 22.18025,
            "logical_agreement": 67.70009,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.52879,
            "nubia_score": 0.6073
        },
        "meteor": 0.3032315766553868,
        "bleurt": -0.13469,
        "bertscore": {
            "precision": 0.86941,
            "recall": 0.85812,
            "f1": 0.86329
        }
    },
    "xsum_validation": {
        "predictions_file": "T5-small (Baseline)/xsum_validation",
        "N": 1117
    },
    "xsum_test": {
        "predictions_file": "T5-small (Baseline)/xsum_test",
        "N": 1166,
        "total_length": 24309,
        "mean_pred_length": 20.848198970840482,
        "std_pred_length": 4.48536128773462,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.17553169607964128,
        "vocab_size-1": 4267,
        "unique-1": 2408,
        "entropy-1": 8.779865982651282,
        "distinct-2": 0.5538607786371689,
        "vocab_size-2": 12818,
        "unique-2": 10209,
        "entropy-2": 12.62094206057136,
        "cond_entropy-2": 3.620412031629314,
        "distinct-3": 0.7910997861400555,
        "vocab_size-3": 17386,
        "unique-3": 15618,
        "entropy-3": 13.755630416799226,
        "cond_entropy-3": 1.153187500072646,
        "total_length-nopunct": 22643,
        "mean_pred_length-nopunct": 19.419382504288166,
        "std_pred_length-nopunct": 4.2601832351136775,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.18796095923685024,
        "vocab_size-1-nopunct": 4256,
        "unique-1-nopunct": 2408,
        "entropy-1-nopunct": 8.939015904866553,
        "distinct-2-nopunct": 0.5612981328863436,
        "vocab_size-2-nopunct": 12055,
        "unique-2-nopunct": 9670,
        "entropy-2-nopunct": 12.535551858349896,
        "cond_entropy-2-nopunct": 3.738867536511893,
        "distinct-3-nopunct": 0.8002067845010093,
        "vocab_size-3-nopunct": 16253,
        "unique-3-nopunct": 14650,
        "entropy-3-nopunct": 13.683603664448368,
        "cond_entropy-3-nopunct": 1.1767546304347851,
        "msttr-100": 0.67745,
        "msttr-100_nopunct": 0.69531,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.2143426564530264,
        "rouge1": {
            "precision": 0.36854,
            "recall": 0.33436,
            "fmeasure": 0.34354
        },
        "rouge2": {
            "precision": 0.12032,
            "recall": 0.1099,
            "fmeasure": 0.11231
        },
        "rougeL": {
            "precision": 0.2775,
            "recall": 0.2529,
            "fmeasure": 0.25921
        },
        "rougeLsum": {
            "precision": 0.2775,
            "recall": 0.2529,
            "fmeasure": 0.25921
        },
        "local_recall": {
            "1": 0.30994152046783624
        },
        "bleu": 7.0847,
        "nubia": {
            "semantic_relation": 2.41909,
            "contradiction": 29.76332,
            "irrelevancy": 61.4037,
            "logical_agreement": 8.83298,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.50878,
            "nubia_score": 0.32065
        },
        "meteor": 0.14379811488857994,
        "bleurt": -0.45052,
        "bertscore": {
            "precision": 0.81729,
            "recall": 0.80215,
            "f1": 0.80933
        }
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "total_length": 10700,
        "mean_pred_length": 21.4,
        "std_pred_length": 4.682734244007447,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 37,
        "distinct-1": 0.23121495327102803,
        "vocab_size-1": 2474,
        "unique-1": 1524,
        "entropy-1": 8.438073351832738,
        "distinct-2": 0.6292156862745099,
        "vocab_size-2": 6418,
        "unique-2": 5342,
        "entropy-2": 11.867922137292323,
        "cond_entropy-2": 3.2328618021118016,
        "distinct-3": 0.8445360824742268,
        "vocab_size-3": 8192,
        "unique-3": 7503,
        "entropy-3": 12.793940234131028,
        "cond_entropy-3": 0.954662945918944,
        "total_length-nopunct": 9948,
        "mean_pred_length-nopunct": 19.896,
        "std_pred_length-nopunct": 4.498131167496119,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.24778850020104543,
        "vocab_size-1-nopunct": 2465,
        "unique-1-nopunct": 1524,
        "entropy-1-nopunct": 8.569639280874643,
        "distinct-2-nopunct": 0.6298687552921253,
        "vocab_size-2-nopunct": 5951,
        "unique-2-nopunct": 4956,
        "entropy-2-nopunct": 11.753888433597988,
        "cond_entropy-2-nopunct": 3.335109872376808,
        "distinct-3-nopunct": 0.8491282968261064,
        "vocab_size-3-nopunct": 7598,
        "unique-3-nopunct": 6959,
        "entropy-3-nopunct": 12.702632438450756,
        "cond_entropy-3-nopunct": 0.9836961459044364,
        "msttr-100": 0.66757,
        "msttr-100_nopunct": 0.68182,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "nist": 2.6961570125376864,
        "rouge1": {
            "precision": 0.33209,
            "recall": 0.30862,
            "fmeasure": 0.31241
        },
        "rouge2": {
            "precision": 0.09218,
            "recall": 0.08462,
            "fmeasure": 0.08601
        },
        "rougeL": {
            "precision": 0.24889,
            "recall": 0.23284,
            "fmeasure": 0.23469
        },
        "rougeLsum": {
            "precision": 0.24889,
            "recall": 0.23284,
            "fmeasure": 0.23469
        },
        "local_recall": {
            "1": 0.28414030122308703
        },
        "bleu": 5.24707,
        "nubia": {
            "semantic_relation": 2.06904,
            "contradiction": 32.59707,
            "irrelevancy": 61.28705,
            "logical_agreement": 6.11588,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.49341,
            "nubia_score": 0.26311
        },
        "meteor": 0.12821522230601012,
        "bleurt": -0.51307,
        "bertscore": {
            "precision": 0.80141,
            "recall": 0.79084,
            "f1": 0.79578
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "total_length": 10678,
        "mean_pred_length": 21.356,
        "std_pred_length": 4.490129619509887,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 38,
        "distinct-1": 0.2510769807079978,
        "vocab_size-1": 2681,
        "unique-1": 1800,
        "entropy-1": 8.555909156438206,
        "distinct-2": 0.6382393397524071,
        "vocab_size-2": 6496,
        "unique-2": 5444,
        "entropy-2": 11.904406680042062,
        "cond_entropy-2": 3.146998346598539,
        "distinct-3": 0.8473858235172557,
        "vocab_size-3": 8201,
        "unique-3": 7536,
        "entropy-3": 12.794903907747283,
        "cond_entropy-3": 0.9059985590064886,
        "total_length-nopunct": 9920,
        "mean_pred_length-nopunct": 19.84,
        "std_pred_length-nopunct": 4.265489420922293,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.2690524193548387,
        "vocab_size-1-nopunct": 2669,
        "unique-1-nopunct": 1797,
        "entropy-1-nopunct": 8.700067749365049,
        "distinct-2-nopunct": 0.6454352441613588,
        "vocab_size-2-nopunct": 6080,
        "unique-2-nopunct": 5116,
        "entropy-2-nopunct": 11.815042242339809,
        "cond_entropy-2-nopunct": 3.245659557335065,
        "distinct-3-nopunct": 0.8559417040358744,
        "vocab_size-3-nopunct": 7635,
        "unique-3-nopunct": 7040,
        "entropy-3-nopunct": 12.710230496527688,
        "cond_entropy-3-nopunct": 0.9207736910885446,
        "msttr-100": 0.67264,
        "msttr-100_nopunct": 0.69071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "nist": 2.8671509733823335,
        "rouge1": {
            "precision": 0.34884,
            "recall": 0.3211,
            "fmeasure": 0.32826
        },
        "rouge2": {
            "precision": 0.10492,
            "recall": 0.09589,
            "fmeasure": 0.09834
        },
        "rougeL": {
            "precision": 0.25881,
            "recall": 0.23862,
            "fmeasure": 0.24371
        },
        "rougeLsum": {
            "precision": 0.25881,
            "recall": 0.23862,
            "fmeasure": 0.24371
        },
        "local_recall": {
            "1": 0.29635499207606975
        },
        "bleu": 6.1118,
        "nubia": {
            "semantic_relation": 2.25268,
            "contradiction": 28.99236,
            "irrelevancy": 61.79256,
            "logical_agreement": 9.21507,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.98432,
            "nubia_score": 0.2649
        },
        "meteor": 0.1336565097897799,
        "bleurt": -0.654,
        "bertscore": {
            "precision": 0.80404,
            "recall": 0.79767,
            "f1": 0.80051
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "total_length": 10832,
        "mean_pred_length": 21.664,
        "std_pred_length": 5.225619963219675,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 58,
        "distinct-1": 0.26153988183161003,
        "vocab_size-1": 2833,
        "unique-1": 1955,
        "entropy-1": 8.611360037977372,
        "distinct-2": 0.6453735965931088,
        "vocab_size-2": 6668,
        "unique-2": 5620,
        "entropy-2": 11.951777460992163,
        "cond_entropy-2": 3.1398507399560818,
        "distinct-3": 0.8504882017900732,
        "vocab_size-3": 8362,
        "unique-3": 7691,
        "entropy-3": 12.826018542189932,
        "cond_entropy-3": 0.8953696741635747,
        "total_length-nopunct": 10068,
        "mean_pred_length-nopunct": 20.136,
        "std_pred_length-nopunct": 4.964826683782627,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.28029400079459676,
        "vocab_size-1-nopunct": 2822,
        "unique-1-nopunct": 1955,
        "entropy-1-nopunct": 8.754771301917637,
        "distinct-2-nopunct": 0.6503971571906354,
        "vocab_size-2-nopunct": 6223,
        "unique-2-nopunct": 5266,
        "entropy-2-nopunct": 11.852786062194262,
        "cond_entropy-2-nopunct": 3.2388214734171705,
        "distinct-3-nopunct": 0.8597265108072343,
        "vocab_size-3-nopunct": 7796,
        "unique-3-nopunct": 7204,
        "entropy-3-nopunct": 12.741382453469166,
        "cond_entropy-3-nopunct": 0.918445602502115,
        "msttr-100": 0.66685,
        "msttr-100_nopunct": 0.6844,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "nist": 2.6751427087611463,
        "rouge1": {
            "precision": 0.32438,
            "recall": 0.3053,
            "fmeasure": 0.30827
        },
        "rouge2": {
            "precision": 0.0925,
            "recall": 0.08652,
            "fmeasure": 0.08744
        },
        "rougeL": {
            "precision": 0.24741,
            "recall": 0.23277,
            "fmeasure": 0.23496
        },
        "rougeLsum": {
            "precision": 0.24741,
            "recall": 0.23277,
            "fmeasure": 0.23496
        },
        "local_recall": {
            "1": 0.2802668259657507
        },
        "bleu": 5.65399,
        "nubia": {
            "semantic_relation": 2.01258,
            "contradiction": 33.80993,
            "irrelevancy": 59.26117,
            "logical_agreement": 6.9289,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.46546,
            "nubia_score": 0.2108
        },
        "meteor": 0.12331391543743933,
        "bleurt": -0.84545,
        "bertscore": {
            "precision": 0.79045,
            "recall": 0.79022,
            "f1": 0.79003
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "total_length": 10413,
        "mean_pred_length": 20.826,
        "std_pred_length": 4.514390767312905,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.24402189570728897,
        "vocab_size-1": 2541,
        "unique-1": 1597,
        "entropy-1": 8.557263106563044,
        "distinct-2": 0.643094925854938,
        "vocab_size-2": 6375,
        "unique-2": 5305,
        "entropy-2": 11.929897175603934,
        "cond_entropy-2": 3.161953687691546,
        "distinct-3": 0.8524381174970785,
        "vocab_size-3": 8024,
        "unique-3": 7361,
        "entropy-3": 12.782015805661832,
        "cond_entropy-3": 0.8726036104879038,
        "total_length-nopunct": 9695,
        "mean_pred_length-nopunct": 19.39,
        "std_pred_length-nopunct": 4.286478741344696,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.26106240330067043,
        "vocab_size-1-nopunct": 2531,
        "unique-1-nopunct": 1595,
        "entropy-1-nopunct": 8.700647070466944,
        "distinct-2-nopunct": 0.6485046220772159,
        "vocab_size-2-nopunct": 5963,
        "unique-2-nopunct": 4989,
        "entropy-2-nopunct": 11.830871067412591,
        "cond_entropy-2-nopunct": 3.266228471991586,
        "distinct-3-nopunct": 0.8596894767107534,
        "vocab_size-3-nopunct": 7475,
        "unique-3-nopunct": 6883,
        "entropy-3-nopunct": 12.694846646798142,
        "cond_entropy-3-nopunct": 0.8886144300600508,
        "msttr-100": 0.67317,
        "msttr-100_nopunct": 0.69167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "nist": 3.168244297684059,
        "rouge1": {
            "precision": 0.37038,
            "recall": 0.33783,
            "fmeasure": 0.34601
        },
        "rouge2": {
            "precision": 0.12205,
            "recall": 0.1119,
            "fmeasure": 0.1142
        },
        "rougeL": {
            "precision": 0.27918,
            "recall": 0.25521,
            "fmeasure": 0.26104
        },
        "rougeLsum": {
            "precision": 0.27918,
            "recall": 0.25521,
            "fmeasure": 0.26104
        },
        "local_recall": {
            "1": 0.31568903173965446
        },
        "bleu": 7.31991,
        "nubia": {
            "semantic_relation": 2.41255,
            "contradiction": 28.76061,
            "irrelevancy": 62.5507,
            "logical_agreement": 8.68868,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.52866,
            "nubia_score": 0.31931
        },
        "meteor": 0.14651940005198189,
        "bleurt": -0.4468,
        "bertscore": {
            "precision": 0.81817,
            "recall": 0.80233,
            "f1": 0.80983
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "T5-small (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "total_length": 9278,
        "mean_pred_length": 23.13715710723192,
        "std_pred_length": 4.552124372970068,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 41,
        "distinct-1": 0.17740892433714162,
        "vocab_size-1": 1646,
        "unique-1": 975,
        "entropy-1": 7.914245460003893,
        "distinct-2": 0.5081671735946829,
        "vocab_size-2": 4511,
        "unique-2": 3523,
        "entropy-2": 11.105445936848986,
        "cond_entropy-2": 3.038420888246666,
        "distinct-3": 0.7228645587541294,
        "vocab_size-3": 6127,
        "unique-3": 5322,
        "entropy-3": 12.10768863645732,
        "cond_entropy-3": 1.029210692691042,
        "total_length-nopunct": 8591,
        "mean_pred_length-nopunct": 21.423940149625935,
        "std_pred_length-nopunct": 4.2666514563278435,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.19054824816668606,
        "vocab_size-1-nopunct": 1637,
        "unique-1-nopunct": 972,
        "entropy-1-nopunct": 8.025320170120896,
        "distinct-2-nopunct": 0.5192918192918193,
        "vocab_size-2-nopunct": 4253,
        "unique-2-nopunct": 3344,
        "entropy-2-nopunct": 11.032356521494359,
        "cond_entropy-2-nopunct": 3.11810913945011,
        "distinct-3-nopunct": 0.7393760431377584,
        "vocab_size-3-nopunct": 5759,
        "unique-3-nopunct": 5045,
        "entropy-3-nopunct": 12.052933493095004,
        "cond_entropy-3-nopunct": 1.0397002206832937,
        "msttr-100": 0.65413,
        "msttr-100_nopunct": 0.67082,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "nist": 2.3050924614803483,
        "rouge1": {
            "precision": 0.29068,
            "recall": 0.27767,
            "fmeasure": 0.27617
        },
        "rouge2": {
            "precision": 0.07781,
            "recall": 0.07551,
            "fmeasure": 0.0747
        },
        "rougeL": {
            "precision": 0.21747,
            "recall": 0.21082,
            "fmeasure": 0.20787
        },
        "rougeLsum": {
            "precision": 0.21747,
            "recall": 0.21082,
            "fmeasure": 0.20787
        },
        "local_recall": {
            "1": 0.25708793849111006
        },
        "bleu": 4.80556,
        "nubia": {
            "semantic_relation": 1.80307,
            "contradiction": 24.83515,
            "irrelevancy": 71.31304,
            "logical_agreement": 3.85181,
            "grammar_ref": 4.04957,
            "grammar_hyp": 3.56051,
            "nubia_score": 0.22544
        },
        "meteor": 0.11524562699618138,
        "bleurt": -0.63145,
        "bertscore": {
            "precision": 0.78108,
            "recall": 0.77061,
            "f1": 0.77551
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_test",
        "N": 500,
        "total_length": 22679,
        "mean_pred_length": 45.358,
        "std_pred_length": 20.611594698130467,
        "median_pred_length": 46.0,
        "min_pred_length": 8,
        "max_pred_length": 89,
        "distinct-1": 0.0700648176727369,
        "vocab_size-1": 1589,
        "unique-1": 573,
        "entropy-1": 5.830309350665282,
        "distinct-2": 0.18053113305378962,
        "vocab_size-2": 4004,
        "unique-2": 1760,
        "entropy-2": 9.998832784846586,
        "cond_entropy-2": 4.170320050775912,
        "distinct-3": 0.31565109091747773,
        "vocab_size-3": 6843,
        "unique-3": 3500,
        "entropy-3": 11.59285091422801,
        "cond_entropy-3": 1.6365811738890912,
        "total_length-nopunct": 20895,
        "mean_pred_length-nopunct": 41.79,
        "std_pred_length-nopunct": 19.287972936521868,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.07561617611868868,
        "vocab_size-1-nopunct": 1580,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 5.734674139898122,
        "distinct-2-nopunct": 0.1812699190978181,
        "vocab_size-2-nopunct": 3697,
        "unique-2-nopunct": 1613,
        "entropy-2-nopunct": 9.884697571239622,
        "cond_entropy-2-nopunct": 4.241634895525668,
        "distinct-3-nopunct": 0.31751696406132196,
        "vocab_size-3-nopunct": 6317,
        "unique-3-nopunct": 3302,
        "entropy-3-nopunct": 11.45428010240025,
        "cond_entropy-3-nopunct": 1.6067649971850266,
        "msttr-100": 0.42274,
        "msttr-100_nopunct": 0.4201,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.146126549012215,
        "rouge1": {
            "precision": 0.40231,
            "recall": 0.39634,
            "fmeasure": 0.3899
        },
        "rouge2": {
            "precision": 0.1939,
            "recall": 0.20417,
            "fmeasure": 0.19362
        },
        "rougeL": {
            "precision": 0.3904,
            "recall": 0.38637,
            "fmeasure": 0.37905
        },
        "rougeLsum": {
            "precision": 0.3904,
            "recall": 0.38637,
            "fmeasure": 0.37905
        },
        "local_recall": {
            "1": 0.09110169491525423,
            "2": 0.19303030303030302,
            "3": 0.26711749788672867,
            "4": 0.26666666666666666,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "bleu": 2.08174,
        "nubia": {
            "semantic_relation": 3.34644,
            "contradiction": 33.06792,
            "irrelevancy": 16.89228,
            "logical_agreement": 50.0398,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.59921,
            "nubia_score": 0.16576
        },
        "meteor": 0.1295984822074646,
        "bleurt": -0.4698,
        "bertscore": {
            "precision": 0.86177,
            "recall": 0.87237,
            "f1": 0.86652
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "T5-small (Baseline)/web_nlg_en_test",
        "N": 500,
        "total_length": 12879,
        "mean_pred_length": 25.758,
        "std_pred_length": 12.733398446604898,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 76,
        "distinct-1": 0.11212050625048528,
        "vocab_size-1": 1444,
        "unique-1": 581,
        "entropy-1": 7.79187370054327,
        "distinct-2": 0.3211891105905162,
        "vocab_size-2": 3976,
        "unique-2": 2177,
        "entropy-2": 10.89438049449423,
        "cond_entropy-2": 2.9526341621471137,
        "distinct-3": 0.510649044532368,
        "vocab_size-3": 6066,
        "unique-3": 4097,
        "entropy-3": 11.983058038195253,
        "cond_entropy-3": 1.1424836890586332,
        "total_length-nopunct": 11362,
        "mean_pred_length-nopunct": 22.724,
        "std_pred_length-nopunct": 11.517631006417943,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.12621017426509418,
        "vocab_size-1-nopunct": 1434,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 8.059289481901228,
        "distinct-2-nopunct": 0.33621800773338245,
        "vocab_size-2-nopunct": 3652,
        "unique-2-nopunct": 2091,
        "entropy-2-nopunct": 10.790740815821987,
        "cond_entropy-2-nopunct": 2.867673198454759,
        "distinct-3-nopunct": 0.5239336035514379,
        "vocab_size-3-nopunct": 5429,
        "unique-3-nopunct": 3774,
        "entropy-3-nopunct": 11.824605828895109,
        "cond_entropy-3-nopunct": 1.0926459665396435,
        "msttr-100": 0.51039,
        "msttr-100_nopunct": 0.52912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.815307400479254,
        "rouge1": {
            "precision": 0.61514,
            "recall": 0.62802,
            "fmeasure": 0.61327
        },
        "rouge2": {
            "precision": 0.35932,
            "recall": 0.36472,
            "fmeasure": 0.35676
        },
        "rougeL": {
            "precision": 0.48938,
            "recall": 0.50231,
            "fmeasure": 0.4888
        },
        "rougeLsum": {
            "precision": 0.48938,
            "recall": 0.50231,
            "fmeasure": 0.4888
        },
        "local_recall": {
            "1": 0.2140739276536865,
            "2": 0.5154394299287411,
            "3": 0.6920344053851907,
            "4": 0.4,
            "5": 0.4444444444444444
        },
        "bleu": 34.51682,
        "nubia": {
            "semantic_relation": 3.52954,
            "contradiction": 38.24577,
            "irrelevancy": 11.11872,
            "logical_agreement": 50.63551,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.68987,
            "nubia_score": 0.54815
        },
        "meteor": 0.3011714549078543,
        "bleurt": -0.23768,
        "bertscore": {
            "precision": 0.87206,
            "recall": 0.87704,
            "f1": 0.87332
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "T5-small (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "total_length": 125947,
        "mean_pred_length": 24.90055357848952,
        "std_pred_length": 12.592802824136182,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 78,
        "distinct-1": 0.11068941697698238,
        "vocab_size-1": 13941,
        "unique-1": 8568,
        "entropy-1": 8.905008622727122,
        "distinct-2": 0.41713472689822895,
        "vocab_size-2": 50427,
        "unique-2": 40936,
        "entropy-2": 12.782243934236016,
        "cond_entropy-2": 3.6833802534663986,
        "distinct-3": 0.612858388514301,
        "vocab_size-3": 70988,
        "unique-3": 64771,
        "entropy-3": 13.824582291005104,
        "cond_entropy-3": 1.0754379364302236,
        "total_length-nopunct": 113117,
        "mean_pred_length-nopunct": 22.36397785686042,
        "std_pred_length-nopunct": 12.034835728392597,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.1231379898688968,
        "vocab_size-1-nopunct": 13929,
        "unique-1-nopunct": 8567,
        "entropy-1-nopunct": 9.228247762014972,
        "distinct-2-nopunct": 0.44851423759242637,
        "vocab_size-2-nopunct": 48466,
        "unique-2-nopunct": 40217,
        "entropy-2-nopunct": 12.75992883035348,
        "cond_entropy-2-nopunct": 3.6645629631594567,
        "distinct-3-nopunct": 0.6230036601586393,
        "vocab_size-3-nopunct": 64170,
        "unique-3-nopunct": 59234,
        "entropy-3-nopunct": 13.614592168779039,
        "cond_entropy-3-nopunct": 0.9362536789084895,
        "msttr-100": 0.60085,
        "msttr-100_nopunct": 0.62949,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "nist": 2.6595185195218916,
        "rouge1": {
            "precision": 0.22104,
            "recall": 0.24223,
            "fmeasure": 0.21837
        },
        "rouge2": {
            "precision": 0.12211,
            "recall": 0.13601,
            "fmeasure": 0.12224
        },
        "rougeL": {
            "precision": 0.19885,
            "recall": 0.21782,
            "fmeasure": 0.19666
        },
        "rougeLsum": {
            "precision": 0.19885,
            "recall": 0.21782,
            "fmeasure": 0.19666
        },
        "local_recall": {
            "1": 0.23432862074272773
        },
        "bleu": 12.47082,
        "nubia": {
            "semantic_relation": 1.90489,
            "contradiction": 31.23445,
            "irrelevancy": 47.55497,
            "logical_agreement": 21.21058,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.34916,
            "nubia_score": 0.2237
        },
        "meteor": 0.19677253664233846,
        "bleurt": -0.67678,
        "bertscore": {
            "precision": 0.83122,
            "recall": 0.83415,
            "f1": 0.83235
        }
    },
    "mlsum_es_validation": {
        "predictions_file": "T5-small (Baseline)/mlsum_es_validation",
        "N": 9977
    },
    "mlsum_es_test": {
        "predictions_file": "T5-small (Baseline)/mlsum_es_test",
        "N": 13366,
        "total_length": 300218,
        "mean_pred_length": 22.461319766571897,
        "std_pred_length": 8.003877849231367,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 93,
        "distinct-1": 0.09440473256100566,
        "vocab_size-1": 28342,
        "unique-1": 15054,
        "entropy-1": 9.679873609033711,
        "distinct-2": 0.42142289403594885,
        "vocab_size-2": 120886,
        "unique-2": 92663,
        "entropy-2": 14.945142022012373,
        "cond_entropy-2": 5.460371899197406,
        "distinct-3": 0.7295876205728995,
        "vocab_size-3": 199532,
        "unique-3": 176626,
        "entropy-3": 16.985740704555738,
        "cond_entropy-3": 2.0874649835526267,
        "total_length-nopunct": 291444,
        "mean_pred_length-nopunct": 21.804878048780488,
        "std_pred_length-nopunct": 7.4146402990279805,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.09719534456018995,
        "vocab_size-1-nopunct": 28327,
        "unique-1-nopunct": 15053,
        "entropy-1-nopunct": 9.735767746519713,
        "distinct-2-nopunct": 0.43011672983839067,
        "vocab_size-2-nopunct": 119606,
        "unique-2-nopunct": 92484,
        "entropy-2-nopunct": 14.952162602064243,
        "cond_entropy-2-nopunct": 5.4164888224131325,
        "distinct-3-nopunct": 0.7344170268064916,
        "vocab_size-3-nopunct": 194409,
        "unique-3-nopunct": 172683,
        "entropy-3-nopunct": 16.953229786917678,
        "cond_entropy-3-nopunct": 2.046617699561563,
        "msttr-100": 0.66358,
        "msttr-100_nopunct": 0.66769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "nist": 1.9305224023704395,
        "rouge1": {
            "precision": 0.25713,
            "recall": 0.23439,
            "fmeasure": 0.23501
        },
        "rouge2": {
            "precision": 0.07116,
            "recall": 0.06502,
            "fmeasure": 0.06508
        },
        "rougeL": {
            "precision": 0.20133,
            "recall": 0.18419,
            "fmeasure": 0.18432
        },
        "rougeLsum": {
            "precision": 0.20133,
            "recall": 0.18419,
            "fmeasure": 0.18432
        },
        "local_recall": {
            "1": 0.21243358852470168
        },
        "bleu": 4.47747,
        "nubia": {
            "semantic_relation": 1.34733,
            "contradiction": 38.35068,
            "irrelevancy": 50.88082,
            "logical_agreement": 10.7685,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.31316,
            "nubia_score": 0.14268
        },
        "meteor": 0.14902138124333,
        "bleurt": -0.60118,
        "bertscore": {
            "precision": 0.82138,
            "recall": 0.81949,
            "f1": 0.82022
        }
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "T5-small (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "T5-small (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "T5-small (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "total_length": 42047,
        "mean_pred_length": 21.69607843137255,
        "std_pred_length": 7.153340029593717,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 64,
        "distinct-1": 0.16852569743382406,
        "vocab_size-1": 7086,
        "unique-1": 4178,
        "entropy-1": 8.984081219873882,
        "distinct-2": 0.5359644967463661,
        "vocab_size-2": 21497,
        "unique-2": 17259,
        "entropy-2": 13.180890892591876,
        "cond_entropy-2": 4.35477159430261,
        "distinct-3": 0.7950800345812266,
        "vocab_size-3": 30349,
        "unique-3": 27357,
        "entropy-3": 14.52688973642849,
        "cond_entropy-3": 1.3661229783464188,
        "total_length-nopunct": 41153,
        "mean_pred_length-nopunct": 21.234778121775026,
        "std_pred_length-nopunct": 6.69735619150796,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 64,
        "distinct-1-nopunct": 0.17196802177241027,
        "vocab_size-1-nopunct": 7077,
        "unique-1-nopunct": 4178,
        "entropy-1-nopunct": 8.999932465042255,
        "distinct-2-nopunct": 0.5395639423689914,
        "vocab_size-2-nopunct": 21159,
        "unique-2-nopunct": 17058,
        "entropy-2-nopunct": 13.154979093069548,
        "cond_entropy-2-nopunct": 4.317421727697979,
        "distinct-3-nopunct": 0.7963623682163264,
        "vocab_size-3-nopunct": 29686,
        "unique-3-nopunct": 26789,
        "entropy-3-nopunct": 14.49512455914876,
        "cond_entropy-3-nopunct": 1.3603595924441518,
        "msttr-100": 0.65548,
        "msttr-100_nopunct": 0.65681,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "nist": 1.6845824260339484,
        "rouge1": {
            "precision": 0.27346,
            "recall": 0.22394,
            "fmeasure": 0.236
        },
        "rouge2": {
            "precision": 0.07259,
            "recall": 0.05991,
            "fmeasure": 0.06284
        },
        "rougeL": {
            "precision": 0.20971,
            "recall": 0.17333,
            "fmeasure": 0.18183
        },
        "rougeLsum": {
            "precision": 0.20971,
            "recall": 0.17333,
            "fmeasure": 0.18183
        },
        "local_recall": {
            "1": 0.20205182545034198
        },
        "bleu": 3.74174,
        "nubia": {
            "semantic_relation": 1.30643,
            "contradiction": 35.63062,
            "irrelevancy": 54.83766,
            "logical_agreement": 9.53172,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.26829,
            "nubia_score": 0.14001
        },
        "meteor": 0.1466584708565699,
        "bleurt": -0.62204,
        "bertscore": {
            "precision": 0.82474,
            "recall": 0.81799,
            "f1": 0.82115
        }
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "total_length": 494764,
        "mean_pred_length": 21.861258395192646,
        "std_pred_length": 20.2148131022604,
        "median_pred_length": 16.0,
        "min_pred_length": 3,
        "max_pred_length": 138,
        "distinct-1": 0.014805038361723973,
        "vocab_size-1": 7325,
        "unique-1": 1471,
        "entropy-1": 7.192068006633575,
        "distinct-2": 0.06454762651122992,
        "vocab_size-2": 30475,
        "unique-2": 10217,
        "entropy-2": 11.113636875070403,
        "cond_entropy-2": 3.703168852441385,
        "distinct-3": 0.1646384872080089,
        "vocab_size-3": 74005,
        "unique-3": 34004,
        "entropy-3": 13.216859027216415,
        "cond_entropy-3": 2.193668909955153,
        "total_length-nopunct": 405351,
        "mean_pred_length-nopunct": 17.910524920466596,
        "std_pred_length-nopunct": 17.23002608049998,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 127,
        "distinct-1-nopunct": 0.018026352469834785,
        "vocab_size-1-nopunct": 7307,
        "unique-1-nopunct": 1471,
        "entropy-1-nopunct": 7.908640655090098,
        "distinct-2-nopunct": 0.10571202370407531,
        "vocab_size-2-nopunct": 40458,
        "unique-2-nopunct": 17924,
        "entropy-2-nopunct": 11.587828480553837,
        "cond_entropy-2-nopunct": 3.922936975668461,
        "distinct-3-nopunct": 0.2328659462852033,
        "vocab_size-3-nopunct": 83852,
        "unique-3-nopunct": 45936,
        "entropy-3-nopunct": 13.839886983229562,
        "cond_entropy-3-nopunct": 2.3956180599802686,
        "msttr-100": 0.31051,
        "msttr-100_nopunct": 0.3498,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "nist": 0.6161189798753209,
        "rouge1": {
            "precision": 0.33493,
            "recall": 0.16032,
            "fmeasure": 0.19576
        },
        "rouge2": {
            "precision": 0.08271,
            "recall": 0.03834,
            "fmeasure": 0.04679
        },
        "rougeL": {
            "precision": 0.2856,
            "recall": 0.13889,
            "fmeasure": 0.16808
        },
        "rougeLsum": {
            "precision": 0.2856,
            "recall": 0.13889,
            "fmeasure": 0.16808
        },
        "local_recall": {
            "1": 0.11870937421167396
        },
        "bleu": 2.55323,
        "sari": 64.38371,
        "nubia": {
            "semantic_relation": 2.38566,
            "contradiction": 29.71693,
            "irrelevancy": 26.30151,
            "logical_agreement": 43.98157,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.4756,
            "nubia_score": 0.35069
        },
        "meteor": 0.07752833105413975,
        "bleurt": -0.82171,
        "bertscore": {
            "precision": 0.82689,
            "recall": 0.76526,
            "f1": 0.79412
        }
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "total_length": 38296,
        "mean_pred_length": 42.55111111111111,
        "std_pred_length": 20.850436949561857,
        "median_pred_length": 39.0,
        "min_pred_length": 4,
        "max_pred_length": 121,
        "distinct-1": 0.06752663463547107,
        "vocab_size-1": 2586,
        "unique-1": 960,
        "entropy-1": 7.752409775963633,
        "distinct-2": 0.24403679537918493,
        "vocab_size-2": 9126,
        "unique-2": 4916,
        "entropy-2": 11.409683047405553,
        "cond_entropy-2": 3.543362954189485,
        "distinct-3": 0.42018303375712407,
        "vocab_size-3": 15335,
        "unique-3": 10197,
        "entropy-3": 12.860095232955679,
        "cond_entropy-3": 1.4713204140273692,
        "total_length-nopunct": 32076,
        "mean_pred_length-nopunct": 35.64,
        "std_pred_length-nopunct": 18.16808434835354,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 108,
        "distinct-1-nopunct": 0.08030926549445068,
        "vocab_size-1-nopunct": 2576,
        "unique-1-nopunct": 959,
        "entropy-1-nopunct": 8.401123887144127,
        "distinct-2-nopunct": 0.3115537593020272,
        "vocab_size-2-nopunct": 9713,
        "unique-2-nopunct": 5802,
        "entropy-2-nopunct": 11.812916750314823,
        "cond_entropy-2-nopunct": 3.4897980613007196,
        "distinct-3-nopunct": 0.5036332408508389,
        "vocab_size-3-nopunct": 15248,
        "unique-3-nopunct": 10846,
        "entropy-3-nopunct": 13.1004186656696,
        "cond_entropy-3-nopunct": 1.3152049566042852,
        "msttr-100": 0.51964,
        "msttr-100_nopunct": 0.58272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "nist": 2.136086953109704,
        "rouge1": {
            "precision": 0.25425,
            "recall": 0.2449,
            "fmeasure": 0.22821
        },
        "rouge2": {
            "precision": 0.07606,
            "recall": 0.06853,
            "fmeasure": 0.06687
        },
        "rougeL": {
            "precision": 0.20095,
            "recall": 0.19482,
            "fmeasure": 0.1802
        },
        "rougeLsum": {
            "precision": 0.20095,
            "recall": 0.19482,
            "fmeasure": 0.1802
        },
        "local_recall": {
            "1": 0.2187937023503406
        },
        "bleu": 7.71891,
        "sari": 64.67358,
        "nubia": {
            "semantic_relation": 2.10774,
            "contradiction": 34.52001,
            "irrelevancy": 44.31539,
            "logical_agreement": 21.16459,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.58288,
            "nubia_score": 0.23421
        },
        "meteor": 0.11909345165990247,
        "bleurt": -0.81993,
        "bertscore": {
            "precision": 0.79936,
            "recall": 0.79448,
            "f1": 0.7964
        }
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "total_length": 151910,
        "mean_pred_length": 38.782231299463874,
        "std_pred_length": 31.390664496606874,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 128,
        "distinct-1": 0.012876045026660522,
        "vocab_size-1": 1956,
        "unique-1": 327,
        "entropy-1": 6.5605265663841354,
        "distinct-2": 0.0396505240112708,
        "vocab_size-2": 5868,
        "unique-2": 1385,
        "entropy-2": 9.315959691466277,
        "cond_entropy-2": 2.664612005497542,
        "distinct-3": 0.07305866348316166,
        "vocab_size-3": 10526,
        "unique-3": 3259,
        "entropy-3": 10.640195329740576,
        "cond_entropy-3": 1.359120256401794,
        "total_length-nopunct": 125480,
        "mean_pred_length-nopunct": 32.03472044932346,
        "std_pred_length-nopunct": 27.04679365904295,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 118,
        "distinct-1-nopunct": 0.015508447561364361,
        "vocab_size-1-nopunct": 1946,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 7.085140207296888,
        "distinct-2-nopunct": 0.05401314544721667,
        "vocab_size-2-nopunct": 6566,
        "unique-2-nopunct": 1861,
        "entropy-2-nopunct": 9.646404695777914,
        "cond_entropy-2-nopunct": 2.6486854648244624,
        "distinct-3-nopunct": 0.09553235979123813,
        "vocab_size-3-nopunct": 11239,
        "unique-3-nopunct": 4049,
        "entropy-3-nopunct": 11.05991086907643,
        "cond_entropy-3-nopunct": 1.4537459933250256,
        "msttr-100": 0.23284,
        "msttr-100_nopunct": 0.25235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "nist": 1.3073404129367985,
        "rouge1": {
            "precision": 0.1718,
            "recall": 0.1355,
            "fmeasure": 0.13331
        },
        "rouge2": {
            "precision": 0.02738,
            "recall": 0.02361,
            "fmeasure": 0.02179
        },
        "rougeL": {
            "precision": 0.15059,
            "recall": 0.12171,
            "fmeasure": 0.11822
        },
        "rougeLsum": {
            "precision": 0.15059,
            "recall": 0.12171,
            "fmeasure": 0.11822
        },
        "local_recall": {
            "1": 0.10249631665290854
        },
        "bleu": 2.77169,
        "sari": 63.31962,
        "nubia": {
            "semantic_relation": 2.34298,
            "contradiction": 25.96713,
            "irrelevancy": 33.52162,
            "logical_agreement": 40.51124,
            "grammar_ref": 3.92068,
            "grammar_hyp": 2.33351,
            "nubia_score": 0.32889
        },
        "meteor": 0.07459082257160177,
        "bleurt": -0.89786,
        "bertscore": {
            "precision": 0.77756,
            "recall": 0.74054,
            "f1": 0.75781
        }
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "T5-small (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "total_length": 1219611,
        "mean_pred_length": 115.27514177693762,
        "std_pred_length": 27.981475208565655,
        "median_pred_length": 130.0,
        "min_pred_length": 4,
        "max_pred_length": 180,
        "distinct-1": 0.0012102219478177878,
        "vocab_size-1": 1476,
        "unique-1": 520,
        "entropy-1": 3.756469215055402,
        "distinct-2": 0.003218279762884492,
        "vocab_size-2": 3891,
        "unique-2": 1547,
        "entropy-2": 5.710786799590936,
        "cond_entropy-2": 1.9643147894879296,
        "distinct-3": 0.008944045271771645,
        "vocab_size-3": 10719,
        "unique-3": 5183,
        "entropy-3": 7.313904451401579,
        "cond_entropy-3": 1.6141495856591792,
        "total_length-nopunct": 717822,
        "mean_pred_length-nopunct": 67.84706994328923,
        "std_pred_length-nopunct": 17.50923212911553,
        "median_pred_length-nopunct": 76.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 149,
        "distinct-1-nopunct": 0.002031144211238998,
        "vocab_size-1-nopunct": 1458,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 3.7650041362882605,
        "distinct-2-nopunct": 0.006884489326142961,
        "vocab_size-2-nopunct": 4869,
        "unique-2-nopunct": 2430,
        "entropy-2-nopunct": 6.702633977579363,
        "cond_entropy-2-nopunct": 2.9435826207721507,
        "distinct-3-nopunct": 0.019237256143161244,
        "vocab_size-3-nopunct": 13402,
        "unique-3-nopunct": 7628,
        "entropy-3-nopunct": 7.909923702315457,
        "cond_entropy-3-nopunct": 1.208178276336787,
        "msttr-100": 0.24184,
        "msttr-100_nopunct": 0.3103,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "nist": 0.039483914998780845,
        "rouge1": {
            "precision": 0.0031,
            "recall": 0.00372,
            "fmeasure": 0.00293
        },
        "rouge2": {
            "precision": 2e-05,
            "recall": 3e-05,
            "fmeasure": 2e-05
        },
        "rougeL": {
            "precision": 0.00278,
            "recall": 0.00338,
            "fmeasure": 0.00264
        },
        "rougeLsum": {
            "precision": 0.00278,
            "recall": 0.00338,
            "fmeasure": 0.00264
        },
        "local_recall": {
            "1": 0.00045037268339550977
        },
        "bleu": 0.00323,
        "sari": 59.55903,
        "nubia": {
            "semantic_relation": 2.72964,
            "contradiction": 37.23161,
            "irrelevancy": 34.04611,
            "logical_agreement": 28.72228,
            "grammar_ref": 3.95647,
            "grammar_hyp": 0.73614,
            "nubia_score": 0.13391
        },
        "meteor": 0.006819964896075355,
        "bleurt": -1.48987,
        "bertscore": {
            "precision": 0.50875,
            "recall": 0.55897,
            "f1": 0.53237
        }
    },
    "dart_validation": {
        "predictions_file": "T5-small (Baseline)/dart_validation",
        "N": 2768
    },
    "dart_test": {
        "predictions_file": "T5-small (Baseline)/dart_test",
        "N": 6959
    },
    "web_nlg_ru_validation": {
        "predictions_file": "T5-small (Baseline)/web_nlg_ru_validation",
        "N": 790
    }
}
