{
    "submission_name": "T5-xl (Baseline)",
    "param_count": 0,
    "mlsum_de_validation": {
        "predictions_file": "T5-xl (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.76245,
        "msttr-100_nopunct": 0.81394,
        "total_length": 323463,
        "mean_pred_length": 28.393872893258425,
        "std_pred_length": 7.118736727749694,
        "median_pred_length": 28.0,
        "min_pred_length": 7,
        "max_pred_length": 84,
        "distinct-1": 0.11241471203816202,
        "vocab_size-1": 36362,
        "unique-1": 21697,
        "entropy-1": 10.407896071625434,
        "distinct-2": 0.5051254361988138,
        "vocab_size-2": 157635,
        "unique-2": 126426,
        "entropy-2": 15.836892715435772,
        "cond_entropy-2": 5.197387409859995,
        "distinct-3": 0.822052753933597,
        "vocab_size-3": 247174,
        "unique-3": 225560,
        "entropy-3": 17.60297194143799,
        "cond_entropy-3": 1.7481813091422596,
        "total_length-nopunct": 286619,
        "mean_pred_length-nopunct": 25.15967345505618,
        "std_pred_length-nopunct": 6.314808330210901,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.1268129468039453,
        "vocab_size-1-nopunct": 36347,
        "unique-1-nopunct": 21696,
        "entropy-1-nopunct": 10.97686346421776,
        "distinct-2-nopunct": 0.5674624945953703,
        "vocab_size-2-nopunct": 156181,
        "unique-2-nopunct": 128206,
        "entropy-2-nopunct": 16.170698718704347,
        "cond_entropy-2-nopunct": 5.292421199425831,
        "distinct-3-nopunct": 0.8672200428297989,
        "vocab_size-3-nopunct": 228803,
        "unique-3-nopunct": 212830,
        "entropy-3-nopunct": 17.594182270692322,
        "cond_entropy-3-nopunct": 1.4629339360734575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "bleu": 36.24826,
        "local_recall": {
            "1": 0.49311687269224597
        },
        "rouge1": {
            "precision": 0.45967,
            "recall": 0.48426,
            "fmeasure": 0.46586
        },
        "rouge2": {
            "precision": 0.34411,
            "recall": 0.35526,
            "fmeasure": 0.34712
        },
        "rougeL": {
            "precision": 0.41788,
            "recall": 0.43769,
            "fmeasure": 0.42294
        },
        "rougeLsum": {
            "precision": 0.41788,
            "recall": 0.43769,
            "fmeasure": 0.42294
        },
        "nist": 7.263353994489048,
        "bleurt": -0.21815,
        "bertscore": {
            "precision": 0.8951,
            "recall": 0.89991,
            "f1": 0.89739
        },
        "nubia": {
            "semantic_relation": 2.86114,
            "contradiction": 21.67429,
            "irrelevancy": 42.29214,
            "logical_agreement": 36.03357,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.9272,
            "nubia_score": 0.44415
        },
        "meteor": 0.4468578131913133
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.4604,
        "msttr-100_nopunct": 0.45924,
        "total_length": 9990,
        "mean_pred_length": 46.6822429906542,
        "std_pred_length": 12.54010249838204,
        "median_pred_length": 44.0,
        "min_pred_length": 15,
        "max_pred_length": 81,
        "distinct-1": 0.12342342342342343,
        "vocab_size-1": 1233,
        "unique-1": 632,
        "entropy-1": 5.842719935927026,
        "distinct-2": 0.30902209492635024,
        "vocab_size-2": 3021,
        "unique-2": 1820,
        "entropy-2": 9.981567567260932,
        "cond_entropy-2": 4.129062051127295,
        "distinct-3": 0.5156870947500523,
        "vocab_size-3": 4931,
        "unique-3": 3408,
        "entropy-3": 11.488769637675047,
        "cond_entropy-3": 1.5334794624024246,
        "total_length-nopunct": 9239,
        "mean_pred_length-nopunct": 43.17289719626168,
        "std_pred_length-nopunct": 12.28489742286707,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.13269834397662084,
        "vocab_size-1-nopunct": 1226,
        "unique-1-nopunct": 631,
        "entropy-1-nopunct": 5.743752444010907,
        "distinct-2-nopunct": 0.3112465373961219,
        "vocab_size-2-nopunct": 2809,
        "unique-2-nopunct": 1701,
        "entropy-2-nopunct": 9.84481304595668,
        "cond_entropy-2-nopunct": 4.168231825986061,
        "distinct-3-nopunct": 0.5108387243218704,
        "vocab_size-3-nopunct": 4501,
        "unique-3-nopunct": 3131,
        "entropy-3-nopunct": 11.32154584454462,
        "cond_entropy-3-nopunct": 1.5111796010189718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.04468,
        "local_recall": {
            "1": 0.0949390469154045,
            "2": 0.21607278241091737,
            "3": 0.2826855123674912,
            "4": 0.18181818181818182
        },
        "rouge1": {
            "precision": 0.45736,
            "recall": 0.45866,
            "fmeasure": 0.45417
        },
        "rouge2": {
            "precision": 0.21277,
            "recall": 0.21321,
            "fmeasure": 0.21071
        },
        "rougeL": {
            "precision": 0.43684,
            "recall": 0.43859,
            "fmeasure": 0.43391
        },
        "rougeLsum": {
            "precision": 0.43684,
            "recall": 0.43859,
            "fmeasure": 0.43391
        },
        "nist": 1.0906274127676858,
        "bleurt": -0.51426,
        "bertscore": {
            "precision": 0.85983,
            "recall": 0.87364,
            "f1": 0.86616
        },
        "nubia": {
            "semantic_relation": 3.27503,
            "contradiction": 31.153,
            "irrelevancy": 17.27749,
            "logical_agreement": 51.5695,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.57313,
            "nubia_score": 0.14488
        },
        "meteor": 0.13199001555120446
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 9.0,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.8913043478260869,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.289760053836066,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.13484437853854514,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0671141958585368,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 8.5,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.9069767441860465,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.2226627197680635,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.12043084752972881,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.07214978575583503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.78653,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.5909090909090909
        },
        "rouge1": {
            "precision": 0.49399,
            "recall": 0.4754,
            "fmeasure": 0.42676
        },
        "rouge2": {
            "precision": 0.32392,
            "recall": 0.25478,
            "fmeasure": 0.25089
        },
        "rougeL": {
            "precision": 0.47837,
            "recall": 0.43651,
            "fmeasure": 0.40463
        },
        "rougeLsum": {
            "precision": 0.47837,
            "recall": 0.43651,
            "fmeasure": 0.40463
        },
        "nist": 2.0679300960666205,
        "bleurt": -0.10035,
        "bertscore": {
            "precision": 0.82877,
            "recall": 0.85036,
            "f1": 0.83424
        },
        "nubia": {
            "semantic_relation": 3.19305,
            "contradiction": 52.41345,
            "irrelevancy": 44.09072,
            "logical_agreement": 3.49583,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.6521,
            "nubia_score": 0.23615
        },
        "meteor": 0.2565831257728959
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.53906,
        "msttr-100_nopunct": 0.56043,
        "total_length": 5345,
        "mean_pred_length": 11.799116997792494,
        "std_pred_length": 4.124101252495737,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.1756782039289055,
        "vocab_size-1": 939,
        "unique-1": 484,
        "entropy-1": 7.498725902449956,
        "distinct-2": 0.4580948487326247,
        "vocab_size-2": 2241,
        "unique-2": 1467,
        "entropy-2": 10.423946800067421,
        "cond_entropy-2": 2.558951495279868,
        "distinct-3": 0.6499211534129309,
        "vocab_size-3": 2885,
        "unique-3": 2240,
        "entropy-3": 11.09138425674924,
        "cond_entropy-3": 0.7711341584043996,
        "total_length-nopunct": 4675,
        "mean_pred_length-nopunct": 10.32008830022075,
        "std_pred_length-nopunct": 3.6182597979848,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.19871657754010696,
        "vocab_size-1-nopunct": 929,
        "unique-1-nopunct": 482,
        "entropy-1-nopunct": 7.745650044444639,
        "distinct-2-nopunct": 0.43841781146376124,
        "vocab_size-2-nopunct": 1851,
        "unique-2-nopunct": 1178,
        "entropy-2-nopunct": 10.12263145352527,
        "cond_entropy-2-nopunct": 2.6717681800909845,
        "distinct-3-nopunct": 0.6362430352878747,
        "vocab_size-3-nopunct": 2398,
        "unique-3-nopunct": 1834,
        "entropy-3-nopunct": 10.808780888842172,
        "cond_entropy-3-nopunct": 0.8028001672207755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 54.85881,
        "local_recall": {
            "1": 0.24769230769230768,
            "2": 0.6738035264483627,
            "3": 0.885921231326392,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.79548,
            "recall": 0.78952,
            "fmeasure": 0.78566
        },
        "rouge2": {
            "precision": 0.56087,
            "recall": 0.55655,
            "fmeasure": 0.55299
        },
        "rougeL": {
            "precision": 0.68675,
            "recall": 0.68123,
            "fmeasure": 0.67774
        },
        "rougeLsum": {
            "precision": 0.68675,
            "recall": 0.68123,
            "fmeasure": 0.67774
        },
        "nist": 9.0333864814129,
        "bleurt": 0.33275,
        "bertscore": {
            "precision": 0.93977,
            "recall": 0.93996,
            "f1": 0.93878
        },
        "nubia": {
            "semantic_relation": 4.5576,
            "contradiction": 7.98013,
            "irrelevancy": 6.49147,
            "logical_agreement": 85.52841,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.14708,
            "nubia_score": 0.81544
        },
        "meteor": 0.4448011394229776
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 24,
        "entropy-1": 4.389898095464288,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.48591022725446525,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.523561956057013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.06413033741971555,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.29327,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.50974,
            "fmeasure": 0.6435
        },
        "rouge2": {
            "precision": 0.52174,
            "recall": 0.30065,
            "fmeasure": 0.38075
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.31364,
            "fmeasure": 0.39687
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.31364,
            "fmeasure": 0.39687
        },
        "nist": 2.221239893115792,
        "bleurt": -0.50329,
        "bertscore": {
            "precision": 0.95997,
            "recall": 0.87935,
            "f1": 0.91789
        },
        "nubia": {
            "semantic_relation": 2.76425,
            "contradiction": 37.58676,
            "irrelevancy": 50.58292,
            "logical_agreement": 11.83032,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.97574,
            "nubia_score": 0.23561
        },
        "meteor": 0.31373515158150944
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.52183,
        "msttr-100_nopunct": 0.54113,
        "total_length": 8214,
        "mean_pred_length": 19.840579710144926,
        "std_pred_length": 6.88263906048276,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 53,
        "distinct-1": 0.1447528609690772,
        "vocab_size-1": 1189,
        "unique-1": 459,
        "entropy-1": 7.9311671674956985,
        "distinct-2": 0.4094871794871795,
        "vocab_size-2": 3194,
        "unique-2": 1917,
        "entropy-2": 10.86269684046035,
        "cond_entropy-2": 2.726757031547903,
        "distinct-3": 0.6066883292715949,
        "vocab_size-3": 4481,
        "unique-3": 3242,
        "entropy-3": 11.720183858759405,
        "cond_entropy-3": 0.9190032779570191,
        "total_length-nopunct": 7192,
        "mean_pred_length-nopunct": 17.3719806763285,
        "std_pred_length-nopunct": 6.090444518621708,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.16407119021134595,
        "vocab_size-1-nopunct": 1180,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 8.230836351207312,
        "distinct-2-nopunct": 0.4170846857480083,
        "vocab_size-2-nopunct": 2827,
        "unique-2-nopunct": 1722,
        "entropy-2-nopunct": 10.702197611334679,
        "cond_entropy-2-nopunct": 2.628701490164395,
        "distinct-3-nopunct": 0.6104651162790697,
        "vocab_size-3-nopunct": 3885,
        "unique-3-nopunct": 2840,
        "entropy-3-nopunct": 11.508596219179289,
        "cond_entropy-3-nopunct": 0.8560548491193424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.5453,
        "local_recall": {
            "1": 0.21341290139244104,
            "2": 0.5861376192867905,
            "3": 0.8899363057324841,
            "4": 0.9090909090909091,
            "5": 1.0
        },
        "rouge1": {
            "precision": 0.78054,
            "recall": 0.76108,
            "fmeasure": 0.76355
        },
        "rouge2": {
            "precision": 0.52686,
            "recall": 0.51469,
            "fmeasure": 0.51511
        },
        "rougeL": {
            "precision": 0.63927,
            "recall": 0.62411,
            "fmeasure": 0.62543
        },
        "rougeLsum": {
            "precision": 0.63927,
            "recall": 0.62411,
            "fmeasure": 0.62543
        },
        "nist": 8.935216331584508,
        "bleurt": 0.22327,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.92657,
            "f1": 0.92549
        },
        "nubia": {
            "semantic_relation": 4.5077,
            "contradiction": 8.55985,
            "irrelevancy": 5.40722,
            "logical_agreement": 86.03293,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.63738,
            "nubia_score": 0.80298
        },
        "meteor": 0.4053549454559615
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.50898,
        "msttr-100_nopunct": 0.52161,
        "total_length": 9847,
        "mean_pred_length": 25.777486910994764,
        "std_pred_length": 7.725338466201202,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 55,
        "distinct-1": 0.11922412917639891,
        "vocab_size-1": 1174,
        "unique-1": 344,
        "entropy-1": 7.980882096810475,
        "distinct-2": 0.36555731642894873,
        "vocab_size-2": 3460,
        "unique-2": 1882,
        "entropy-2": 10.943215448939997,
        "cond_entropy-2": 2.805221652061358,
        "distinct-3": 0.5609380160739844,
        "vocab_size-3": 5095,
        "unique-3": 3500,
        "entropy-3": 11.852518811902074,
        "cond_entropy-3": 0.947984952832041,
        "total_length-nopunct": 8739,
        "mean_pred_length-nopunct": 22.876963350785342,
        "std_pred_length-nopunct": 7.0058347555229625,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.13331044741961323,
        "vocab_size-1-nopunct": 1165,
        "unique-1-nopunct": 343,
        "entropy-1-nopunct": 8.24160270152615,
        "distinct-2-nopunct": 0.38099796577719275,
        "vocab_size-2-nopunct": 3184,
        "unique-2-nopunct": 1814,
        "entropy-2-nopunct": 10.839575889088819,
        "cond_entropy-2-nopunct": 2.712218621487687,
        "distinct-3-nopunct": 0.5740438871473355,
        "vocab_size-3-nopunct": 4578,
        "unique-3-nopunct": 3236,
        "entropy-3-nopunct": 11.693778662190955,
        "cond_entropy-3-nopunct": 0.8811106143292942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.13061,
        "local_recall": {
            "1": 0.23128574981347924,
            "2": 0.5577256944444444,
            "3": 0.8750809061488674,
            "4": 0.5,
            "5": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.75339,
            "recall": 0.74465,
            "fmeasure": 0.74293
        },
        "rouge2": {
            "precision": 0.4822,
            "recall": 0.4746,
            "fmeasure": 0.47413
        },
        "rougeL": {
            "precision": 0.5804,
            "recall": 0.57068,
            "fmeasure": 0.57015
        },
        "rougeLsum": {
            "precision": 0.5804,
            "recall": 0.57068,
            "fmeasure": 0.57015
        },
        "nist": 8.620378665033456,
        "bleurt": 0.18023,
        "bertscore": {
            "precision": 0.91746,
            "recall": 0.91555,
            "f1": 0.91529
        },
        "nubia": {
            "semantic_relation": 4.43341,
            "contradiction": 9.35957,
            "irrelevancy": 8.13233,
            "logical_agreement": 82.5081,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.41288,
            "nubia_score": 0.78225
        },
        "meteor": 0.3883737002699914
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.7001,
        "msttr-100_nopunct": 0.73096,
        "total_length": 125254,
        "mean_pred_length": 12.5254,
        "std_pred_length": 7.445519111519358,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 56,
        "distinct-1": 0.0349130566688489,
        "vocab_size-1": 4373,
        "unique-1": 1848,
        "entropy-1": 8.170933369396046,
        "distinct-2": 0.15663664601662416,
        "vocab_size-2": 18053,
        "unique-2": 9697,
        "entropy-2": 11.859890043111408,
        "cond_entropy-2": 3.425638344908218,
        "distinct-3": 0.3307238473450697,
        "vocab_size-3": 34811,
        "unique-3": 22842,
        "entropy-3": 13.558957732899772,
        "cond_entropy-3": 1.7171246000905447,
        "total_length-nopunct": 109824,
        "mean_pred_length-nopunct": 10.9824,
        "std_pred_length-nopunct": 6.807855039584789,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.039654356060606064,
        "vocab_size-1-nopunct": 4355,
        "unique-1-nopunct": 1846,
        "entropy-1-nopunct": 8.412983650028757,
        "distinct-2-nopunct": 0.17352540471229363,
        "vocab_size-2-nopunct": 17322,
        "unique-2-nopunct": 9745,
        "entropy-2-nopunct": 11.775909535162727,
        "cond_entropy-2-nopunct": 3.5113871631627593,
        "distinct-3-nopunct": 0.35637966343157335,
        "vocab_size-3-nopunct": 32020,
        "unique-3-nopunct": 21766,
        "entropy-3-nopunct": 13.453410628484706,
        "cond_entropy-3-nopunct": 1.718221976810383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "bleu": 35.48672,
        "local_recall": {
            "1": 0.6124525634347794
        },
        "rouge1": {
            "precision": 0.61263,
            "recall": 0.60566,
            "fmeasure": 0.59555
        },
        "rouge2": {
            "precision": 0.39884,
            "recall": 0.39488,
            "fmeasure": 0.38741
        },
        "rougeL": {
            "precision": 0.55382,
            "recall": 0.54731,
            "fmeasure": 0.53826
        },
        "rougeLsum": {
            "precision": 0.55382,
            "recall": 0.54731,
            "fmeasure": 0.53826
        },
        "nist": 7.447190723702935,
        "bleurt": 0.00744,
        "bertscore": {
            "precision": 0.88031,
            "recall": 0.87767,
            "f1": 0.87841
        },
        "nubia": {
            "semantic_relation": 3.83076,
            "contradiction": 3.52828,
            "irrelevancy": 20.60089,
            "logical_agreement": 75.87083,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.72808,
            "nubia_score": 0.6962
        },
        "meteor": 0.3428295320737684
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.65575,
        "msttr-100_nopunct": 0.69736,
        "total_length": 12048,
        "mean_pred_length": 24.096,
        "std_pred_length": 12.135682263474106,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.11014276228419655,
        "vocab_size-1": 1327,
        "unique-1": 426,
        "entropy-1": 8.030269929776289,
        "distinct-2": 0.3410980256321441,
        "vocab_size-2": 3939,
        "unique-2": 2093,
        "entropy-2": 11.083454288020231,
        "cond_entropy-2": 2.8762432267760323,
        "distinct-3": 0.5388305575669804,
        "vocab_size-3": 5953,
        "unique-3": 3995,
        "entropy-3": 12.040692313959662,
        "cond_entropy-3": 1.0031509712505284,
        "total_length-nopunct": 10673,
        "mean_pred_length-nopunct": 21.346,
        "std_pred_length-nopunct": 10.894507056310534,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.12330178956244729,
        "vocab_size-1-nopunct": 1316,
        "unique-1-nopunct": 425,
        "entropy-1-nopunct": 8.292896825982634,
        "distinct-2-nopunct": 0.3542711098004522,
        "vocab_size-2-nopunct": 3604,
        "unique-2-nopunct": 1981,
        "entropy-2-nopunct": 10.967179284116527,
        "cond_entropy-2-nopunct": 2.796485638169498,
        "distinct-3-nopunct": 0.5507081567249044,
        "vocab_size-3-nopunct": 5327,
        "unique-3-nopunct": 3660,
        "entropy-3-nopunct": 11.882848508047582,
        "cond_entropy-3-nopunct": 0.9496728483442984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.70722,
        "local_recall": {
            "1": 0.2370896926615095,
            "2": 0.5896112831097351,
            "3": 0.8704068829539344,
            "4": 0.7777777777777778,
            "5": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.7788,
            "recall": 0.75251,
            "fmeasure": 0.75879
        },
        "rouge2": {
            "precision": 0.5167,
            "recall": 0.49917,
            "fmeasure": 0.50274
        },
        "rougeL": {
            "precision": 0.61425,
            "recall": 0.59403,
            "fmeasure": 0.59819
        },
        "rougeLsum": {
            "precision": 0.61425,
            "recall": 0.59403,
            "fmeasure": 0.59819
        },
        "nist": 8.97590752719345,
        "bleurt": 0.19555,
        "bertscore": {
            "precision": 0.92591,
            "recall": 0.92229,
            "f1": 0.92254
        },
        "nubia": {
            "semantic_relation": 4.44837,
            "contradiction": 7.51457,
            "irrelevancy": 6.92375,
            "logical_agreement": 85.56169,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.5687,
            "nubia_score": 0.78586
        },
        "meteor": 0.3891167203999433
    },
    "mlsum_de_test": {
        "predictions_file": "T5-xl (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.77608,
        "msttr-100_nopunct": 0.82766,
        "total_length": 305852,
        "mean_pred_length": 28.597662459093034,
        "std_pred_length": 10.051097789093316,
        "median_pred_length": 27.0,
        "min_pred_length": 6,
        "max_pred_length": 91,
        "distinct-1": 0.12214404352431896,
        "vocab_size-1": 37358,
        "unique-1": 22368,
        "entropy-1": 10.612939038288504,
        "distinct-2": 0.5411357345412781,
        "vocab_size-2": 159720,
        "unique-2": 129274,
        "entropy-2": 16.054211841541697,
        "cond_entropy-2": 5.2051615322495515,
        "distinct-3": 0.8567084531501571,
        "vocab_size-3": 243701,
        "unique-3": 225124,
        "entropy-3": 17.66974227078943,
        "cond_entropy-3": 1.5940618018417692,
        "total_length-nopunct": 271614,
        "mean_pred_length-nopunct": 25.396353436185134,
        "std_pred_length-nopunct": 8.890297371690318,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.1374892310411098,
        "vocab_size-1-nopunct": 37344,
        "unique-1-nopunct": 22367,
        "entropy-1-nopunct": 11.177451160768308,
        "distinct-2-nopunct": 0.6022098812275074,
        "vocab_size-2-nopunct": 157128,
        "unique-2-nopunct": 130359,
        "entropy-2-nopunct": 16.31877322989448,
        "cond_entropy-2-nopunct": 5.235010609228287,
        "distinct-3-nopunct": 0.891764978579193,
        "vocab_size-3-nopunct": 223141,
        "unique-3-nopunct": 209585,
        "entropy-3-nopunct": 17.609514646138877,
        "cond_entropy-3-nopunct": 1.324765953192947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "bleu": 37.93614,
        "local_recall": {
            "1": 0.5047629535818512
        },
        "rouge1": {
            "precision": 0.47515,
            "recall": 0.49549,
            "fmeasure": 0.47661
        },
        "rouge2": {
            "precision": 0.36257,
            "recall": 0.37434,
            "fmeasure": 0.36448
        },
        "rougeL": {
            "precision": 0.43417,
            "recall": 0.45076,
            "fmeasure": 0.43558
        },
        "rougeLsum": {
            "precision": 0.43417,
            "recall": 0.45076,
            "fmeasure": 0.43558
        },
        "nist": 7.488100003431117,
        "bleurt": -0.21639,
        "bertscore": {
            "precision": 0.89529,
            "recall": 0.90067,
            "f1": 0.89781
        },
        "nubia": {
            "semantic_relation": 2.88874,
            "contradiction": 21.81738,
            "irrelevancy": 41.05743,
            "logical_agreement": 37.12519,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.9781,
            "nubia_score": 0.43581
        },
        "meteor": 0.4591300775113517
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.46845,
        "msttr-100_nopunct": 0.46554,
        "total_length": 7107,
        "mean_pred_length": 35.535,
        "std_pred_length": 11.565412876330875,
        "median_pred_length": 34.0,
        "min_pred_length": 11,
        "max_pred_length": 85,
        "distinct-1": 0.14084705220205432,
        "vocab_size-1": 1001,
        "unique-1": 558,
        "entropy-1": 5.7544108199517146,
        "distinct-2": 0.3461705516143043,
        "vocab_size-2": 2391,
        "unique-2": 1540,
        "entropy-2": 9.781082140485115,
        "cond_entropy-2": 4.010730992305232,
        "distinct-3": 0.5537498136275533,
        "vocab_size-3": 3714,
        "unique-3": 2735,
        "entropy-3": 11.112508483053043,
        "cond_entropy-3": 1.3785119271833508,
        "total_length-nopunct": 6547,
        "mean_pred_length-nopunct": 32.735,
        "std_pred_length-nopunct": 11.117768436156602,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.1516725217656942,
        "vocab_size-1-nopunct": 993,
        "unique-1-nopunct": 555,
        "entropy-1-nopunct": 5.645886222078153,
        "distinct-2-nopunct": 0.3429966913502442,
        "vocab_size-2-nopunct": 2177,
        "unique-2-nopunct": 1401,
        "entropy-2-nopunct": 9.600927429788419,
        "cond_entropy-2-nopunct": 4.075268839553669,
        "distinct-3-nopunct": 0.5451439726695949,
        "vocab_size-3-nopunct": 3351,
        "unique-3-nopunct": 2473,
        "entropy-3-nopunct": 10.926896610353712,
        "cond_entropy-3-nopunct": 1.3705162040355836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.72379,
        "local_recall": {
            "1": 0.10948191593352884,
            "2": 0.17540322580645162,
            "3": 0.26397919375812745,
            "4": 0.15,
            "5": 0.23076923076923078,
            "6": 0.0,
            "7": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.38589,
            "recall": 0.38925,
            "fmeasure": 0.38524
        },
        "rouge2": {
            "precision": 0.18649,
            "recall": 0.18899,
            "fmeasure": 0.18675
        },
        "rougeL": {
            "precision": 0.36747,
            "recall": 0.37211,
            "fmeasure": 0.36733
        },
        "rougeLsum": {
            "precision": 0.36747,
            "recall": 0.37211,
            "fmeasure": 0.36733
        },
        "nist": 1.0924791396988698,
        "bleurt": -0.46388,
        "bertscore": {
            "precision": 0.86398,
            "recall": 0.87722,
            "f1": 0.87002
        },
        "nubia": {
            "semantic_relation": 3.2612,
            "contradiction": 32.075,
            "irrelevancy": 17.31085,
            "logical_agreement": 50.61415,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.72108,
            "nubia_score": 0.17031
        },
        "meteor": 0.13469205229273867
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.4,
        "vocab_size-1": 28,
        "unique-1": 0,
        "entropy-1": 4.686146588249909,
        "distinct-2": 0.4852941176470588,
        "vocab_size-2": 33,
        "unique-2": 0,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.32611438325616504,
        "distinct-3": 0.5,
        "vocab_size-3": 33,
        "unique-3": 0,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": 0.01753733871417469,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4090909090909091,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.635006998015215,
        "distinct-2-nopunct": 0.484375,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.31528634952676315,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.0187124394191333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 46.00127,
        "local_recall": {
            "1": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.70175,
            "fmeasure": 0.7677
        },
        "rouge2": {
            "precision": 0.64062,
            "recall": 0.52769,
            "fmeasure": 0.57832
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.34023,
            "fmeasure": 0.37127
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.34023,
            "fmeasure": 0.37127
        },
        "nist": 4.217019473016001,
        "bleurt": 0.1036,
        "bertscore": {
            "precision": 0.93923,
            "recall": 0.90484,
            "f1": 0.92171
        },
        "nubia": {
            "semantic_relation": 3.96176,
            "contradiction": 2.96411,
            "irrelevancy": 0.74484,
            "logical_agreement": 96.29105,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.53731,
            "nubia_score": 0.61065
        },
        "meteor": 0.42761758858022036
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.70135,
        "msttr-100_nopunct": 0.75052,
        "total_length": 8941,
        "mean_pred_length": 23.591029023746703,
        "std_pred_length": 6.486765397818423,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 64,
        "distinct-1": 0.33296051895761103,
        "vocab_size-1": 2977,
        "unique-1": 2172,
        "entropy-1": 9.174964728985941,
        "distinct-2": 0.7672272833450129,
        "vocab_size-2": 6569,
        "unique-2": 5751,
        "entropy-2": 12.287053304883129,
        "cond_entropy-2": 2.9058222283565325,
        "distinct-3": 0.9374312599291214,
        "vocab_size-3": 7671,
        "unique-3": 7296,
        "entropy-3": 12.855084064013585,
        "cond_entropy-3": 0.5599361364892039,
        "total_length-nopunct": 7779,
        "mean_pred_length-nopunct": 20.525065963060687,
        "std_pred_length-nopunct": 5.568122584116109,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.3808972875690963,
        "vocab_size-1-nopunct": 2963,
        "unique-1-nopunct": 2172,
        "entropy-1-nopunct": 9.57973273140483,
        "distinct-2-nopunct": 0.8036486486486486,
        "vocab_size-2-nopunct": 5947,
        "unique-2-nopunct": 5310,
        "entropy-2-nopunct": 12.206106725107594,
        "cond_entropy-2-nopunct": 2.7194250285622648,
        "distinct-3-nopunct": 0.9455917960404501,
        "vocab_size-3-nopunct": 6639,
        "unique-3-nopunct": 6350,
        "entropy-3-nopunct": 12.65363120066466,
        "cond_entropy-3-nopunct": 0.46835751066906145,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.39227,
        "local_recall": {
            "1": 0.22916666666666666,
            "2": 0.4670406732117812,
            "3": 0.7700795947901592
        },
        "rouge1": {
            "precision": 0.75068,
            "recall": 0.73189,
            "fmeasure": 0.73118
        },
        "rouge2": {
            "precision": 0.49747,
            "recall": 0.48704,
            "fmeasure": 0.48591
        },
        "rougeL": {
            "precision": 0.60191,
            "recall": 0.59295,
            "fmeasure": 0.58906
        },
        "rougeLsum": {
            "precision": 0.60191,
            "recall": 0.59295,
            "fmeasure": 0.58906
        },
        "nist": 8.759897822933082,
        "bleurt": 0.20254,
        "bertscore": {
            "precision": 0.92386,
            "recall": 0.91817,
            "f1": 0.91942
        },
        "nubia": {
            "semantic_relation": 4.14591,
            "contradiction": 8.85143,
            "irrelevancy": 29.79068,
            "logical_agreement": 61.35789,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.18922,
            "nubia_score": 0.72823
        },
        "meteor": 0.38060819493624254
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.70161,
        "msttr-100_nopunct": 0.7437,
        "total_length": 3186,
        "mean_pred_length": 25.693548387096776,
        "std_pred_length": 8.129176266005537,
        "median_pred_length": 25.0,
        "min_pred_length": 12,
        "max_pred_length": 78,
        "distinct-1": 0.4124293785310734,
        "vocab_size-1": 1314,
        "unique-1": 1017,
        "entropy-1": 8.569674394132527,
        "distinct-2": 0.8389941214892227,
        "vocab_size-2": 2569,
        "unique-2": 2349,
        "entropy-2": 11.068262888959934,
        "cond_entropy-2": 2.3412056800096788,
        "distinct-3": 0.9676650782845473,
        "vocab_size-3": 2843,
        "unique-3": 2768,
        "entropy-3": 11.448936121355441,
        "cond_entropy-3": 0.3878067038469853,
        "total_length-nopunct": 2797,
        "mean_pred_length-nopunct": 22.556451612903224,
        "std_pred_length-nopunct": 6.9761141084496545,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.4662138005005363,
        "vocab_size-1-nopunct": 1304,
        "unique-1-nopunct": 1015,
        "entropy-1-nopunct": 8.866852178009813,
        "distinct-2-nopunct": 0.8559670781893004,
        "vocab_size-2-nopunct": 2288,
        "unique-2-nopunct": 2116,
        "entropy-2-nopunct": 10.923913635172847,
        "cond_entropy-2-nopunct": 2.1330384190498464,
        "distinct-3-nopunct": 0.9697920753236563,
        "vocab_size-3-nopunct": 2472,
        "unique-3-nopunct": 2414,
        "entropy-3-nopunct": 11.247513040748201,
        "cond_entropy-3-nopunct": 0.3352440649341982,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.32106,
        "local_recall": {
            "1": 0.2318840579710145,
            "2": 0.4469525959367946,
            "3": 0.7560728744939271
        },
        "rouge1": {
            "precision": 0.73373,
            "recall": 0.71639,
            "fmeasure": 0.71475
        },
        "rouge2": {
            "precision": 0.4723,
            "recall": 0.47223,
            "fmeasure": 0.46471
        },
        "rougeL": {
            "precision": 0.59247,
            "recall": 0.58653,
            "fmeasure": 0.58151
        },
        "rougeLsum": {
            "precision": 0.59247,
            "recall": 0.58653,
            "fmeasure": 0.58151
        },
        "nist": 7.823745782909996,
        "bleurt": 0.15447,
        "bertscore": {
            "precision": 0.92016,
            "recall": 0.91543,
            "f1": 0.91578
        },
        "nubia": {
            "semantic_relation": 4.01508,
            "contradiction": 8.33179,
            "irrelevancy": 36.6367,
            "logical_agreement": 55.03151,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.20812,
            "nubia_score": 0.6829
        },
        "meteor": 0.3719063645527277
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.70828,
        "msttr-100_nopunct": 0.75769,
        "total_length": 2993,
        "mean_pred_length": 18.03012048192771,
        "std_pred_length": 8.030382591371184,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 50,
        "distinct-1": 0.4279986635482793,
        "vocab_size-1": 1281,
        "unique-1": 1001,
        "entropy-1": 8.487906890431983,
        "distinct-2": 0.8471878316236293,
        "vocab_size-2": 2395,
        "unique-2": 2245,
        "entropy-2": 10.933804206536898,
        "cond_entropy-2": 2.181049751459027,
        "distinct-3": 0.9511461856444946,
        "vocab_size-3": 2531,
        "unique-3": 2474,
        "entropy-3": 11.223324118751957,
        "cond_entropy-3": 0.31086116808958814,
        "total_length-nopunct": 2608,
        "mean_pred_length-nopunct": 15.710843373493976,
        "std_pred_length-nopunct": 6.724402818438584,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.48773006134969327,
        "vocab_size-1-nopunct": 1272,
        "unique-1-nopunct": 998,
        "entropy-1-nopunct": 8.836289038798174,
        "distinct-2-nopunct": 0.8660933660933661,
        "vocab_size-2-nopunct": 2115,
        "unique-2-nopunct": 1998,
        "entropy-2-nopunct": 10.790914052256687,
        "cond_entropy-2-nopunct": 2.0914037349624537,
        "distinct-3-nopunct": 0.9674868189806678,
        "vocab_size-3-nopunct": 2202,
        "unique-3-nopunct": 2160,
        "entropy-3-nopunct": 11.068432586012582,
        "cond_entropy-3-nopunct": 0.30338111883532615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.67821,
        "local_recall": {
            "1": 0.03351404632824051,
            "2": 0.15232974910394265,
            "3": 0.3665480427046263,
            "4": 0.5450643776824035,
            "5": 0.6682027649769585,
            "6": 0.8143939393939394,
            "7": 0.823943661971831,
            "8": 0.9003215434083601,
            "9": 0.9267676767676768,
            "10": 0.966996699669967
        },
        "rouge1": {
            "precision": 0.88423,
            "recall": 0.89161,
            "fmeasure": 0.88157
        },
        "rouge2": {
            "precision": 0.77352,
            "recall": 0.79701,
            "fmeasure": 0.77675
        },
        "rougeL": {
            "precision": 0.86181,
            "recall": 0.87678,
            "fmeasure": 0.86351
        },
        "rougeLsum": {
            "precision": 0.86181,
            "recall": 0.87678,
            "fmeasure": 0.86351
        },
        "nist": 11.495845626804227,
        "bleurt": 0.26352,
        "bertscore": {
            "precision": 0.96602,
            "recall": 0.97303,
            "f1": 0.96665
        },
        "nubia": {
            "semantic_relation": 4.30331,
            "contradiction": 3.62094,
            "irrelevancy": 31.90277,
            "logical_agreement": 64.47628,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.80725,
            "nubia_score": 0.67262
        },
        "meteor": 0.5267971415769163
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "T5-xl (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.71257,
        "msttr-100_nopunct": 0.75842,
        "total_length": 148910,
        "mean_pred_length": 29.440490312376433,
        "std_pred_length": 7.558426536063747,
        "median_pred_length": 30.0,
        "min_pred_length": 10,
        "max_pred_length": 86,
        "distinct-1": 0.10352561950171245,
        "vocab_size-1": 15416,
        "unique-1": 9550,
        "entropy-1": 9.252717233968506,
        "distinct-2": 0.41515585462836807,
        "vocab_size-2": 59721,
        "unique-2": 49024,
        "entropy-2": 13.20400794899734,
        "cond_entropy-2": 3.815208411865807,
        "distinct-3": 0.6282404138507428,
        "vocab_size-3": 87196,
        "unique-3": 81094,
        "entropy-3": 14.251144249483326,
        "cond_entropy-3": 1.048225066368493,
        "total_length-nopunct": 130645,
        "mean_pred_length-nopunct": 25.829379201265322,
        "std_pred_length-nopunct": 6.530818660669369,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.1178996517279651,
        "vocab_size-1-nopunct": 15403,
        "unique-1-nopunct": 9549,
        "entropy-1-nopunct": 9.725653404094134,
        "distinct-2-nopunct": 0.4679146726970148,
        "vocab_size-2-nopunct": 58764,
        "unique-2-nopunct": 49443,
        "entropy-2-nopunct": 13.400295827140686,
        "cond_entropy-2-nopunct": 3.7625175859857505,
        "distinct-3-nopunct": 0.6614922549759809,
        "vocab_size-3-nopunct": 79729,
        "unique-3-nopunct": 75511,
        "entropy-3-nopunct": 14.201172593112256,
        "cond_entropy-3-nopunct": 0.8261225456439013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "bleu": 20.66058,
        "local_recall": {
            "1": 0.4043006969943493
        },
        "rouge1": {
            "precision": 0.30244,
            "recall": 0.40287,
            "fmeasure": 0.3368
        },
        "rouge2": {
            "precision": 0.20751,
            "recall": 0.27256,
            "fmeasure": 0.23008
        },
        "rougeL": {
            "precision": 0.27509,
            "recall": 0.36548,
            "fmeasure": 0.30617
        },
        "rougeLsum": {
            "precision": 0.27509,
            "recall": 0.36548,
            "fmeasure": 0.30617
        },
        "nist": 4.135670980976838,
        "bleurt": -0.5097,
        "bertscore": {
            "precision": 0.8645,
            "recall": 0.88169,
            "f1": 0.87279
        },
        "nubia": {
            "semantic_relation": 2.06494,
            "contradiction": 22.31552,
            "irrelevancy": 61.01271,
            "logical_agreement": 16.67178,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.96248,
            "nubia_score": 0.2644
        },
        "meteor": 0.34591278470783615
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.4581,
        "msttr-100_nopunct": 0.4545,
        "total_length": 2178,
        "mean_pred_length": 68.0625,
        "std_pred_length": 4.892197231306195,
        "median_pred_length": 70.0,
        "min_pred_length": 46,
        "max_pred_length": 73,
        "distinct-1": 0.17401285583103765,
        "vocab_size-1": 379,
        "unique-1": 198,
        "entropy-1": 5.316618137533673,
        "distinct-2": 0.39748369058713884,
        "vocab_size-2": 853,
        "unique-2": 522,
        "entropy-2": 8.824714518032566,
        "cond_entropy-2": 3.518858595973127,
        "distinct-3": 0.5832544938505203,
        "vocab_size-3": 1233,
        "unique-3": 875,
        "entropy-3": 9.809503796714466,
        "cond_entropy-3": 0.9949715124713778,
        "total_length-nopunct": 2030,
        "mean_pred_length-nopunct": 63.4375,
        "std_pred_length-nopunct": 4.457700500257952,
        "median_pred_length-nopunct": 64.5,
        "min_pred_length-nopunct": 44,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.183743842364532,
        "vocab_size-1-nopunct": 373,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 5.195602394490577,
        "distinct-2-nopunct": 0.4059059059059059,
        "vocab_size-2-nopunct": 811,
        "unique-2-nopunct": 498,
        "entropy-2-nopunct": 8.761946621685272,
        "cond_entropy-2-nopunct": 3.59376749074481,
        "distinct-3-nopunct": 0.5839267548321465,
        "vocab_size-3-nopunct": 1148,
        "unique-3-nopunct": 810,
        "entropy-3-nopunct": 9.72048645354172,
        "cond_entropy-3-nopunct": 0.9684149237662134,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.51907,
        "local_recall": {
            "1": 0.08793103448275862,
            "2": 0.16331096196868009,
            "3": 0.24600638977635783
        },
        "rouge1": {
            "precision": 0.77634,
            "recall": 0.69461,
            "fmeasure": 0.70953
        },
        "rouge2": {
            "precision": 0.3934,
            "recall": 0.40176,
            "fmeasure": 0.38091
        },
        "rougeL": {
            "precision": 0.73281,
            "recall": 0.65413,
            "fmeasure": 0.66791
        },
        "rougeLsum": {
            "precision": 0.73281,
            "recall": 0.65413,
            "fmeasure": 0.66791
        },
        "nist": 1.1360494468106384,
        "bleurt": -0.50621,
        "bertscore": {
            "precision": 0.8623,
            "recall": 0.86598,
            "f1": 0.8639
        },
        "nubia": {
            "semantic_relation": 3.26717,
            "contradiction": 34.03473,
            "irrelevancy": 21.8236,
            "logical_agreement": 44.14167,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.41961,
            "nubia_score": 0.14312
        },
        "meteor": 0.11011849083690226
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.67289,
        "msttr-100_nopunct": 0.7197,
        "total_length": 3864,
        "mean_pred_length": 30.1875,
        "std_pred_length": 10.732361983738715,
        "median_pred_length": 28.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.37577639751552794,
        "vocab_size-1": 1452,
        "unique-1": 1126,
        "entropy-1": 8.438853955211059,
        "distinct-2": 0.7363490364025695,
        "vocab_size-2": 2751,
        "unique-2": 2478,
        "entropy-2": 10.86387799213842,
        "cond_entropy-2": 2.3028015548461216,
        "distinct-3": 0.8572616407982262,
        "vocab_size-3": 3093,
        "unique-3": 2956,
        "entropy-3": 11.296774071381384,
        "cond_entropy-3": 0.43935310333778904,
        "total_length-nopunct": 3302,
        "mean_pred_length-nopunct": 25.796875,
        "std_pred_length-nopunct": 9.144123262203708,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.4364021804966687,
        "vocab_size-1-nopunct": 1441,
        "unique-1-nopunct": 1122,
        "entropy-1-nopunct": 8.79948055031338,
        "distinct-2-nopunct": 0.7674858223062382,
        "vocab_size-2-nopunct": 2436,
        "unique-2-nopunct": 2227,
        "entropy-2-nopunct": 10.754807020668405,
        "cond_entropy-2-nopunct": 2.0110505138177692,
        "distinct-3-nopunct": 0.8752462245567958,
        "vocab_size-3-nopunct": 2666,
        "unique-3-nopunct": 2564,
        "entropy-3-nopunct": 11.115220329244805,
        "cond_entropy-3-nopunct": 0.3704460054816381,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.68582,
        "local_recall": {
            "1": 0.23129251700680273,
            "2": 0.437984496124031,
            "3": 0.7795918367346939
        },
        "rouge1": {
            "precision": 0.73853,
            "recall": 0.72625,
            "fmeasure": 0.72248
        },
        "rouge2": {
            "precision": 0.4995,
            "recall": 0.49202,
            "fmeasure": 0.48983
        },
        "rougeL": {
            "precision": 0.61409,
            "recall": 0.60761,
            "fmeasure": 0.60251
        },
        "rougeLsum": {
            "precision": 0.61409,
            "recall": 0.60761,
            "fmeasure": 0.60251
        },
        "nist": 7.9783380239464785,
        "bleurt": 0.15721,
        "bertscore": {
            "precision": 0.92004,
            "recall": 0.91694,
            "f1": 0.91699
        },
        "nubia": {
            "semantic_relation": 3.9494,
            "contradiction": 7.86201,
            "irrelevancy": 30.23981,
            "logical_agreement": 61.89818,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.01168,
            "nubia_score": 0.68105
        },
        "meteor": 0.39667290426960405
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": 0.48,
        "msttr-100_nopunct": 0.45,
        "total_length": 159,
        "mean_pred_length": 13.25,
        "std_pred_length": 5.101061980934297,
        "median_pred_length": 11.5,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.32075471698113206,
        "vocab_size-1": 51,
        "unique-1": 24,
        "entropy-1": 4.820017132496549,
        "distinct-2": 0.5578231292517006,
        "vocab_size-2": 82,
        "unique-2": 51,
        "entropy-2": 6.1035032968052265,
        "cond_entropy-2": 1.2380444887105866,
        "distinct-3": 0.5851851851851851,
        "vocab_size-3": 79,
        "unique-3": 49,
        "entropy-3": 6.101800226263793,
        "cond_entropy-3": 0.02529140036261451,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.73168985552613,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.34285714285714286,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.69498199541694,
        "distinct-2-nopunct": 0.5390625,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.8525610347337,
        "cond_entropy-2-nopunct": 1.2451570405486307,
        "distinct-3-nopunct": 0.5689655172413793,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.84623605935378,
        "cond_entropy-3-nopunct": 0.004532719265503177,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 2.04215,
        "local_recall": {
            "1": 0.18292682926829268
        },
        "rouge1": {
            "precision": 0.32668,
            "recall": 0.37399,
            "fmeasure": 0.33626
        },
        "rouge2": {
            "precision": 0.17735,
            "recall": 0.23851,
            "fmeasure": 0.1932
        },
        "rougeL": {
            "precision": 0.30287,
            "recall": 0.34657,
            "fmeasure": 0.31082
        },
        "rougeLsum": {
            "precision": 0.30287,
            "recall": 0.34657,
            "fmeasure": 0.31082
        },
        "nist": 0.770022363566071,
        "bleurt": -0.74718,
        "bertscore": {
            "precision": 0.80888,
            "recall": 0.84241,
            "f1": 0.82511
        },
        "nubia": {
            "semantic_relation": 2.20735,
            "contradiction": 41.51059,
            "irrelevancy": 29.92392,
            "logical_agreement": 28.56549,
            "grammar_ref": 6.83527,
            "grammar_hyp": 6.51793,
            "nubia_score": 0.17802
        },
        "meteor": 0.08733486750081512
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.75364,
        "total_length": 1277,
        "mean_pred_length": 22.017241379310345,
        "std_pred_length": 9.41841808832904,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 47,
        "distinct-1": 0.48707909162098667,
        "vocab_size-1": 622,
        "unique-1": 504,
        "entropy-1": 8.001126521542542,
        "distinct-2": 0.8917145200984413,
        "vocab_size-2": 1087,
        "unique-2": 1035,
        "entropy-2": 9.918108911886588,
        "cond_entropy-2": 1.7336800889735766,
        "distinct-3": 0.9664082687338501,
        "vocab_size-3": 1122,
        "unique-3": 1110,
        "entropy-3": 10.064562398709109,
        "cond_entropy-3": 0.16310780458864566,
        "total_length-nopunct": 1133,
        "mean_pred_length-nopunct": 19.53448275862069,
        "std_pred_length-nopunct": 8.455187180051233,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5419240953221536,
        "vocab_size-1-nopunct": 614,
        "unique-1-nopunct": 502,
        "entropy-1-nopunct": 8.213258552714558,
        "distinct-2-nopunct": 0.9172093023255814,
        "vocab_size-2-nopunct": 986,
        "unique-2-nopunct": 941,
        "entropy-2-nopunct": 9.843039112979781,
        "cond_entropy-2-nopunct": 1.7269992634275855,
        "distinct-3-nopunct": 0.9872173058013766,
        "vocab_size-3-nopunct": 1004,
        "unique-3-nopunct": 994,
        "entropy-3-nopunct": 9.961829738191561,
        "cond_entropy-3-nopunct": 0.13174121147223905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.94493,
        "local_recall": {
            "1": 0.035106382978723406,
            "2": 0.17054263565891473,
            "3": 0.36423841059602646,
            "4": 0.4636363636363636,
            "5": 0.6518518518518519,
            "6": 0.7692307692307693,
            "7": 0.9035087719298246,
            "8": 0.8979591836734694,
            "9": 0.9150326797385621,
            "10": 0.9483568075117371
        },
        "rouge1": {
            "precision": 0.88244,
            "recall": 0.87045,
            "fmeasure": 0.86764
        },
        "rouge2": {
            "precision": 0.76487,
            "recall": 0.75981,
            "fmeasure": 0.75208
        },
        "rougeL": {
            "precision": 0.86518,
            "recall": 0.85581,
            "fmeasure": 0.85183
        },
        "rougeLsum": {
            "precision": 0.86518,
            "recall": 0.85581,
            "fmeasure": 0.85183
        },
        "nist": 10.742556637425453,
        "bleurt": 0.1788,
        "bertscore": {
            "precision": 0.95919,
            "recall": 0.96484,
            "f1": 0.95958
        },
        "nubia": {
            "semantic_relation": 4.21742,
            "contradiction": 2.84599,
            "irrelevancy": 33.58655,
            "logical_agreement": 63.56745,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.76586,
            "nubia_score": 0.6419
        },
        "meteor": 0.5068365089676666
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72156,
        "msttr-100_nopunct": 0.76194,
        "total_length": 7723,
        "mean_pred_length": 21.512534818941504,
        "std_pred_length": 9.55349891325458,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.35374854331218436,
        "vocab_size-1": 2732,
        "unique-1": 1994,
        "entropy-1": 9.124634549184902,
        "distinct-2": 0.8155893536121673,
        "vocab_size-2": 6006,
        "unique-2": 5557,
        "entropy-2": 12.143242720581648,
        "cond_entropy-2": 2.776419083029817,
        "distinct-3": 0.9481798715203427,
        "vocab_size-3": 6642,
        "unique-3": 6504,
        "entropy-3": 12.56742354298717,
        "cond_entropy-3": 0.4432893017890854,
        "total_length-nopunct": 6792,
        "mean_pred_length-nopunct": 18.919220055710305,
        "std_pred_length-nopunct": 8.22365928851851,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4004711425206125,
        "vocab_size-1-nopunct": 2720,
        "unique-1-nopunct": 1991,
        "entropy-1-nopunct": 9.504696468726728,
        "distinct-2-nopunct": 0.8440851857609203,
        "vocab_size-2-nopunct": 5430,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.092331158621885,
        "cond_entropy-2-nopunct": 2.716657921518432,
        "distinct-3-nopunct": 0.9705301284162002,
        "vocab_size-3-nopunct": 5895,
        "unique-3-nopunct": 5792,
        "entropy-3-nopunct": 12.487194869687839,
        "cond_entropy-3-nopunct": 0.4221573916938865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.82119,
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.16711590296495957,
            "3": 0.3710843373493976,
            "4": 0.5626911314984709,
            "5": 0.6828528072837633,
            "6": 0.7971830985915493,
            "7": 0.8688524590163934,
            "8": 0.9071170084439083,
            "9": 0.926984126984127,
            "10": 0.9635658914728682
        },
        "rouge1": {
            "precision": 0.87923,
            "recall": 0.88301,
            "fmeasure": 0.87481
        },
        "rouge2": {
            "precision": 0.76929,
            "recall": 0.78066,
            "fmeasure": 0.76709
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "nist": 12.709964093712534,
        "sari": 47.58344,
        "bleurt": 0.2121,
        "bertscore": {
            "precision": 0.96314,
            "recall": 0.97071,
            "f1": 0.96417
        },
        "nubia": {
            "semantic_relation": 4.27732,
            "contradiction": 2.99509,
            "irrelevancy": 35.42939,
            "logical_agreement": 61.57552,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.73338,
            "nubia_score": 0.65371
        },
        "meteor": 0.5229674536458527
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.51333,
        "msttr-100_nopunct": 0.52313,
        "total_length": 12676,
        "mean_pred_length": 25.352,
        "std_pred_length": 6.834039508226448,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.02216787630167245,
        "vocab_size-1": 281,
        "unique-1": 76,
        "entropy-1": 6.1189089082823696,
        "distinct-2": 0.10134691195795006,
        "vocab_size-2": 1234,
        "unique-2": 537,
        "entropy-2": 8.379545328538233,
        "cond_entropy-2": 2.1725536881821785,
        "distinct-3": 0.21077423775265502,
        "vocab_size-3": 2461,
        "unique-3": 1275,
        "entropy-3": 9.736559040096871,
        "cond_entropy-3": 1.3618063982743343,
        "total_length-nopunct": 11542,
        "mean_pred_length-nopunct": 23.084,
        "std_pred_length-nopunct": 6.304359126826453,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.024172587073297523,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.169397381264933,
        "distinct-2-nopunct": 0.10822314798043832,
        "vocab_size-2-nopunct": 1195,
        "unique-2-nopunct": 536,
        "entropy-2-nopunct": 8.330887868531537,
        "cond_entropy-2-nopunct": 2.199762548531321,
        "distinct-3-nopunct": 0.22187440713337128,
        "vocab_size-3-nopunct": 2339,
        "unique-3-nopunct": 1213,
        "entropy-3-nopunct": 9.731262629711503,
        "cond_entropy-3-nopunct": 1.3850068729371023,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 29.62363,
        "local_recall": {
            "1": 0.6898539942341672
        },
        "rouge1": {
            "precision": 0.7309,
            "recall": 0.70105,
            "fmeasure": 0.70403
        },
        "rouge2": {
            "precision": 0.4287,
            "recall": 0.41083,
            "fmeasure": 0.41258
        },
        "rougeL": {
            "precision": 0.51672,
            "recall": 0.49499,
            "fmeasure": 0.49731
        },
        "rougeLsum": {
            "precision": 0.51672,
            "recall": 0.49499,
            "fmeasure": 0.49731
        },
        "nist": 5.177258613575599,
        "bleurt": 0.15933,
        "bertscore": {
            "precision": 0.91178,
            "recall": 0.90384,
            "f1": 0.90746
        },
        "nubia": {
            "semantic_relation": 4.30179,
            "contradiction": 3.0875,
            "irrelevancy": 21.91268,
            "logical_agreement": 74.99982,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.54757,
            "nubia_score": 0.77239
        },
        "meteor": 0.35649379181673874
    },
    "mlsum_es_validation": {
        "predictions_file": "T5-xl (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.68866,
        "msttr-100_nopunct": 0.69245,
        "total_length": 193264,
        "mean_pred_length": 19.370953192342387,
        "std_pred_length": 6.3821543054634144,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 71,
        "distinct-1": 0.11453762728702707,
        "vocab_size-1": 22136,
        "unique-1": 12527,
        "entropy-1": 9.693668683436238,
        "distinct-2": 0.4605454833130555,
        "vocab_size-2": 84412,
        "unique-2": 65996,
        "entropy-2": 14.703375206853359,
        "cond_entropy-2": 5.2171834451256185,
        "distinct-3": 0.7664416363741273,
        "vocab_size-3": 132832,
        "unique-3": 119632,
        "entropy-3": 16.511400053149018,
        "cond_entropy-3": 1.8491215075101755,
        "total_length-nopunct": 186561,
        "mean_pred_length-nopunct": 18.699107948281046,
        "std_pred_length-nopunct": 5.889452368364329,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.1185671174575608,
        "vocab_size-1-nopunct": 22120,
        "unique-1-nopunct": 12525,
        "entropy-1-nopunct": 9.757270270537218,
        "distinct-2-nopunct": 0.47064286685090384,
        "vocab_size-2-nopunct": 83108,
        "unique-2-nopunct": 65516,
        "entropy-2-nopunct": 14.70944566077922,
        "cond_entropy-2-nopunct": 5.171939836204031,
        "distinct-3-nopunct": 0.7734188839604579,
        "vocab_size-3-nopunct": 128857,
        "unique-3-nopunct": 116603,
        "entropy-3-nopunct": 16.478861545183666,
        "cond_entropy-3-nopunct": 1.8085591644510863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "bleu": 7.82872,
        "local_recall": {
            "1": 0.26132176241803506
        },
        "rouge1": {
            "precision": 0.35539,
            "recall": 0.28523,
            "fmeasure": 0.30564
        },
        "rouge2": {
            "precision": 0.14499,
            "recall": 0.11796,
            "fmeasure": 0.12552
        },
        "rougeL": {
            "precision": 0.28728,
            "recall": 0.232,
            "fmeasure": 0.24794
        },
        "rougeLsum": {
            "precision": 0.28728,
            "recall": 0.232,
            "fmeasure": 0.24794
        },
        "nist": 2.8724602579578815,
        "bleurt": -0.50554,
        "bertscore": {
            "precision": 0.84435,
            "recall": 0.83598,
            "f1": 0.83994
        },
        "nubia": {
            "semantic_relation": 1.76114,
            "contradiction": 27.43768,
            "irrelevancy": 58.11196,
            "logical_agreement": 14.45036,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.5699,
            "nubia_score": 0.1795
        },
        "meteor": 0.2067672811805794
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72097,
        "msttr-100_nopunct": 0.76469,
        "total_length": 7277,
        "mean_pred_length": 20.270194986072422,
        "std_pred_length": 9.085602048622638,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3493197746324035,
        "vocab_size-1": 2542,
        "unique-1": 1841,
        "entropy-1": 9.072573604144493,
        "distinct-2": 0.8193119398670136,
        "vocab_size-2": 5668,
        "unique-2": 5217,
        "entropy-2": 12.091081062961148,
        "cond_entropy-2": 2.760173013699903,
        "distinct-3": 0.950297301417899,
        "vocab_size-3": 6233,
        "unique-3": 6100,
        "entropy-3": 12.486601610005762,
        "cond_entropy-3": 0.4156529258104046,
        "total_length-nopunct": 6448,
        "mean_pred_length-nopunct": 17.96100278551532,
        "std_pred_length-nopunct": 7.974795609364186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3926799007444169,
        "vocab_size-1-nopunct": 2532,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.424989179738812,
        "distinct-2-nopunct": 0.8438167186730169,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4770,
        "entropy-2-nopunct": 12.024778184187973,
        "cond_entropy-2-nopunct": 2.7364381967507607,
        "distinct-3-nopunct": 0.9703315881326352,
        "vocab_size-3-nopunct": 5560,
        "unique-3-nopunct": 5454,
        "entropy-3-nopunct": 12.406012635755967,
        "cond_entropy-3-nopunct": 0.4077793067418675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.56468,
        "local_recall": {
            "1": 0.04987266553480475,
            "2": 0.17113665389527458,
            "3": 0.38293216630196936,
            "4": 0.5213946117274167,
            "5": 0.6240913811007269,
            "6": 0.7379227053140096,
            "7": 0.8652157311951126
        },
        "rouge1": {
            "precision": 0.83092,
            "recall": 0.7738,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.67417,
            "recall": 0.63178,
            "fmeasure": 0.64105
        },
        "rougeL": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "rougeLsum": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "nist": 10.87722683854598,
        "sari": 46.54224,
        "bleurt": 0.17013,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.93981,
            "f1": 0.94171
        },
        "nubia": {
            "semantic_relation": 4.25223,
            "contradiction": 4.92643,
            "irrelevancy": 18.75903,
            "logical_agreement": 76.31454,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.91024,
            "nubia_score": 0.68324
        },
        "meteor": 0.44445575759907224
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.67812,
        "msttr-100_nopunct": 0.75231,
        "total_length": 1615,
        "mean_pred_length": 26.475409836065573,
        "std_pred_length": 8.747096112756788,
        "median_pred_length": 26.0,
        "min_pred_length": 11,
        "max_pred_length": 52,
        "distinct-1": 0.47306501547987617,
        "vocab_size-1": 764,
        "unique-1": 610,
        "entropy-1": 8.12512671830987,
        "distinct-2": 0.8622908622908623,
        "vocab_size-2": 1340,
        "unique-2": 1255,
        "entropy-2": 10.171206289603974,
        "cond_entropy-2": 1.9099558232937008,
        "distinct-3": 0.9658405894172807,
        "vocab_size-3": 1442,
        "unique-3": 1404,
        "entropy-3": 10.466209457845775,
        "cond_entropy-3": 0.28037404439136726,
        "total_length-nopunct": 1349,
        "mean_pred_length-nopunct": 22.114754098360656,
        "std_pred_length-nopunct": 7.57281237286481,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5611564121571534,
        "vocab_size-1-nopunct": 757,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 8.550306954168175,
        "distinct-2-nopunct": 0.9037267080745341,
        "vocab_size-2-nopunct": 1164,
        "unique-2-nopunct": 1098,
        "entropy-2-nopunct": 10.060840146081604,
        "cond_entropy-2-nopunct": 1.5712351498118688,
        "distinct-3-nopunct": 0.9771801140994295,
        "vocab_size-3-nopunct": 1199,
        "unique-3-nopunct": 1175,
        "entropy-3-nopunct": 10.212419309535704,
        "cond_entropy-3-nopunct": 0.16174597735281385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.19836,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4343891402714932,
            "3": 0.7400835073068893
        },
        "rouge1": {
            "precision": 0.72604,
            "recall": 0.68643,
            "fmeasure": 0.69622
        },
        "rouge2": {
            "precision": 0.4491,
            "recall": 0.43156,
            "fmeasure": 0.43497
        },
        "rougeL": {
            "precision": 0.59371,
            "recall": 0.57052,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.59371,
            "recall": 0.57052,
            "fmeasure": 0.57455
        },
        "nist": 7.038921826567915,
        "bleurt": 0.15741,
        "bertscore": {
            "precision": 0.91932,
            "recall": 0.91274,
            "f1": 0.9147
        },
        "nubia": {
            "semantic_relation": 3.97994,
            "contradiction": 5.78086,
            "irrelevancy": 31.26347,
            "logical_agreement": 62.95568,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.2173,
            "nubia_score": 0.68767
        },
        "meteor": 0.3636156408407292
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_test": {
        "predictions_file": "T5-xl (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.6895,
        "msttr-100_nopunct": 0.69373,
        "total_length": 256987,
        "mean_pred_length": 19.226919048331588,
        "std_pred_length": 6.20715001002278,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 84,
        "distinct-1": 0.10074828687832459,
        "vocab_size-1": 25891,
        "unique-1": 14226,
        "entropy-1": 9.73106286842691,
        "distinct-2": 0.4293267000792214,
        "vocab_size-2": 104593,
        "unique-2": 80665,
        "entropy-2": 14.849614000634736,
        "cond_entropy-2": 5.330414884003363,
        "distinct-3": 0.7381555232242514,
        "vocab_size-3": 169964,
        "unique-3": 151689,
        "entropy-3": 16.77115330630587,
        "cond_entropy-3": 1.9657970339078192,
        "total_length-nopunct": 248245,
        "mean_pred_length-nopunct": 18.572871464910968,
        "std_pred_length-nopunct": 5.718929895493719,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.10423573485870813,
        "vocab_size-1-nopunct": 25876,
        "unique-1-nopunct": 14226,
        "entropy-1-nopunct": 9.796562927212909,
        "distinct-2-nopunct": 0.4398136913048846,
        "vocab_size-2-nopunct": 103303,
        "unique-2-nopunct": 80514,
        "entropy-2-nopunct": 14.8623428662123,
        "cond_entropy-2-nopunct": 5.290988307000352,
        "distinct-3-nopunct": 0.7466965821419059,
        "vocab_size-3-nopunct": 165403,
        "unique-3-nopunct": 148407,
        "entropy-3-nopunct": 16.747312343263822,
        "cond_entropy-3-nopunct": 1.9267835407377032,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "bleu": 7.53639,
        "local_recall": {
            "1": 0.2576160642084659
        },
        "rouge1": {
            "precision": 0.35796,
            "recall": 0.28303,
            "fmeasure": 0.30542
        },
        "rouge2": {
            "precision": 0.14522,
            "recall": 0.11614,
            "fmeasure": 0.12464
        },
        "rougeL": {
            "precision": 0.28998,
            "recall": 0.23072,
            "fmeasure": 0.24834
        },
        "rougeLsum": {
            "precision": 0.28998,
            "recall": 0.23072,
            "fmeasure": 0.24834
        },
        "nist": 2.796331190862076,
        "bleurt": -0.51091,
        "bertscore": {
            "precision": 0.84477,
            "recall": 0.83536,
            "f1": 0.83983
        },
        "nubia": {
            "semantic_relation": 1.74209,
            "contradiction": 27.70062,
            "irrelevancy": 58.00311,
            "logical_agreement": 14.29627,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.57483,
            "nubia_score": 0.17781
        },
        "meteor": 0.2041178473022862
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 719,
        "mean_pred_length": 22.46875,
        "std_pred_length": 10.049827035203144,
        "median_pred_length": 20.5,
        "min_pred_length": 9,
        "max_pred_length": 44,
        "distinct-1": 0.5243393602225312,
        "vocab_size-1": 377,
        "unique-1": 298,
        "entropy-1": 7.56554326224429,
        "distinct-2": 0.8864628820960698,
        "vocab_size-2": 609,
        "unique-2": 568,
        "entropy-2": 9.132133855861541,
        "cond_entropy-2": 1.4117784683070818,
        "distinct-3": 0.9618320610687023,
        "vocab_size-3": 630,
        "unique-3": 616,
        "entropy-3": 9.257985542973213,
        "cond_entropy-3": 0.13859220292036267,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 19.65625,
        "std_pred_length-nopunct": 8.454323505609423,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5882352941176471,
        "vocab_size-1-nopunct": 370,
        "unique-1-nopunct": 297,
        "entropy-1-nopunct": 7.753006585426342,
        "distinct-2-nopunct": 0.8994974874371859,
        "vocab_size-2-nopunct": 537,
        "unique-2-nopunct": 505,
        "entropy-2-nopunct": 8.965553881850385,
        "cond_entropy-2-nopunct": 1.2758976237033681,
        "distinct-3-nopunct": 0.9769911504424779,
        "vocab_size-3-nopunct": 552,
        "unique-3-nopunct": 542,
        "entropy-3-nopunct": 9.091213451103897,
        "cond_entropy-3-nopunct": 0.1366207438754064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 84.50803,
        "local_recall": {
            "1": 0.04106776180698152,
            "2": 0.18691588785046728,
            "3": 0.3380281690140845,
            "4": 0.640625,
            "5": 0.7818181818181819,
            "6": 0.7647058823529411,
            "7": 0.8636363636363636,
            "8": 0.9047619047619048,
            "9": 0.9404761904761905,
            "10": 0.9758064516129032
        },
        "rouge1": {
            "precision": 0.91178,
            "recall": 0.89584,
            "fmeasure": 0.89823
        },
        "rouge2": {
            "precision": 0.81707,
            "recall": 0.80279,
            "fmeasure": 0.80242
        },
        "rougeL": {
            "precision": 0.8986,
            "recall": 0.8787,
            "fmeasure": 0.88242
        },
        "rougeLsum": {
            "precision": 0.8986,
            "recall": 0.8787,
            "fmeasure": 0.88242
        },
        "nist": 10.14890404639357,
        "bleurt": 0.27303,
        "bertscore": {
            "precision": 0.97024,
            "recall": 0.97389,
            "f1": 0.9698
        },
        "nubia": {
            "semantic_relation": 4.42583,
            "contradiction": 2.15526,
            "irrelevancy": 34.52784,
            "logical_agreement": 63.3169,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.54766,
            "nubia_score": 0.69698
        },
        "meteor": 0.5196930823113207
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.71141,
        "msttr-100_nopunct": 0.76054,
        "total_length": 6410,
        "mean_pred_length": 17.855153203342617,
        "std_pred_length": 8.488312129264969,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.36474258970358814,
        "vocab_size-1": 2338,
        "unique-1": 1736,
        "entropy-1": 8.948901883590207,
        "distinct-2": 0.8203602710295819,
        "vocab_size-2": 4964,
        "unique-2": 4574,
        "entropy-2": 11.89362754762165,
        "cond_entropy-2": 2.647670907809555,
        "distinct-3": 0.9453619114546732,
        "vocab_size-3": 5381,
        "unique-3": 5267,
        "entropy-3": 12.250780415998205,
        "cond_entropy-3": 0.3834204628916874,
        "total_length-nopunct": 5649,
        "mean_pred_length-nopunct": 15.735376044568245,
        "std_pred_length-nopunct": 7.36623719990956,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.4121083377588954,
        "vocab_size-1-nopunct": 2328,
        "unique-1-nopunct": 1733,
        "entropy-1-nopunct": 9.322931964688818,
        "distinct-2-nopunct": 0.8461247637051039,
        "vocab_size-2-nopunct": 4476,
        "unique-2-nopunct": 4151,
        "entropy-2-nopunct": 11.837986951801051,
        "cond_entropy-2-nopunct": 2.6628050025032977,
        "distinct-3-nopunct": 0.9697830054755627,
        "vocab_size-3-nopunct": 4782,
        "unique-3-nopunct": 4688,
        "entropy-3-nopunct": 12.190220812420453,
        "cond_entropy-3-nopunct": 0.38292313229347447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "bleu": 40.81718,
        "local_recall": {
            "1": 0.05178743961352657,
            "2": 0.12774725274725274,
            "3": 0.2227432590855803,
            "4": 0.3101983002832861,
            "5": 0.3665338645418327,
            "6": 0.4630541871921182,
            "7": 0.5205479452054794,
            "8": 0.6438492063492064,
            "9": 0.7568345323741007
        },
        "rouge1": {
            "precision": 0.67683,
            "recall": 0.63354,
            "fmeasure": 0.6413
        },
        "rouge2": {
            "precision": 0.43857,
            "recall": 0.41585,
            "fmeasure": 0.41459
        },
        "rougeL": {
            "precision": 0.61711,
            "recall": 0.58392,
            "fmeasure": 0.58737
        },
        "rougeLsum": {
            "precision": 0.61711,
            "recall": 0.58392,
            "fmeasure": 0.58737
        },
        "nist": 8.631257903184927,
        "sari": 44.17671,
        "bleurt": -0.20063,
        "bertscore": {
            "precision": 0.90253,
            "recall": 0.90142,
            "f1": 0.898
        },
        "nubia": {
            "semantic_relation": 3.43556,
            "contradiction": 13.99486,
            "irrelevancy": 35.32654,
            "logical_agreement": 50.6786,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.20368,
            "nubia_score": 0.44916
        },
        "meteor": 0.3369115006842995
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.22258,
        "msttr-100_nopunct": 0.20556,
        "total_length": 3113,
        "mean_pred_length": 17.010928961748633,
        "std_pred_length": 2.5819657674844883,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.023128814648249278,
        "vocab_size-1": 72,
        "unique-1": 22,
        "entropy-1": 4.1809250487495495,
        "distinct-2": 0.042320819112627986,
        "vocab_size-2": 124,
        "unique-2": 51,
        "entropy-2": 4.947019297341797,
        "cond_entropy-2": 0.7652506755040952,
        "distinct-3": 0.046232253367309795,
        "vocab_size-3": 127,
        "unique-3": 49,
        "entropy-3": 4.929715627915063,
        "cond_entropy-3": -0.002579283402644664,
        "total_length-nopunct": 2743,
        "mean_pred_length-nopunct": 14.989071038251366,
        "std_pred_length-nopunct": 2.3422679939770568,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.025154939846882975,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.0071714629496435,
        "distinct-2-nopunct": 0.041015625,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 4.738936027293802,
        "cond_entropy-2-nopunct": 0.7739608052525618,
        "distinct-3-nopunct": 0.045435422801851075,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 4.718437813620005,
        "cond_entropy-3-nopunct": -0.01100943289448786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 0.28898,
        "local_recall": {
            "1": 0.07377866400797607
        },
        "rouge1": {
            "precision": 0.19878,
            "recall": 0.31735,
            "fmeasure": 0.2367
        },
        "rouge2": {
            "precision": 0.0835,
            "recall": 0.13872,
            "fmeasure": 0.09938
        },
        "rougeL": {
            "precision": 0.1701,
            "recall": 0.2736,
            "fmeasure": 0.20252
        },
        "rougeLsum": {
            "precision": 0.1701,
            "recall": 0.2736,
            "fmeasure": 0.20252
        },
        "nist": 0.3665514795029689,
        "bleurt": -0.77689,
        "bertscore": {
            "precision": 0.81276,
            "recall": 0.85406,
            "f1": 0.83285
        },
        "nubia": {
            "semantic_relation": 1.78041,
            "contradiction": 32.30894,
            "irrelevancy": 29.86842,
            "logical_agreement": 37.82264,
            "grammar_ref": 6.72681,
            "grammar_hyp": 5.38946,
            "nubia_score": 0.05523
        },
        "meteor": 0.04693262211036002
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.67909,
        "msttr-100_nopunct": 0.73222,
        "total_length": 1103,
        "mean_pred_length": 27.575,
        "std_pred_length": 8.555371119945645,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.4732547597461469,
        "vocab_size-1": 522,
        "unique-1": 406,
        "entropy-1": 7.775262162523972,
        "distinct-2": 0.8570084666039511,
        "vocab_size-2": 911,
        "unique-2": 835,
        "entropy-2": 9.65648099654932,
        "cond_entropy-2": 1.7673675794044534,
        "distinct-3": 0.9599217986314761,
        "vocab_size-3": 982,
        "unique-3": 953,
        "entropy-3": 9.906949563702423,
        "cond_entropy-3": 0.2567129663661536,
        "total_length-nopunct": 965,
        "mean_pred_length-nopunct": 24.125,
        "std_pred_length-nopunct": 6.867268379785371,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5326424870466321,
        "vocab_size-1-nopunct": 514,
        "unique-1-nopunct": 403,
        "entropy-1-nopunct": 7.973809163751752,
        "distinct-2-nopunct": 0.8810810810810811,
        "vocab_size-2-nopunct": 815,
        "unique-2-nopunct": 760,
        "entropy-2-nopunct": 9.524996122737424,
        "cond_entropy-2-nopunct": 1.6090671707394892,
        "distinct-3-nopunct": 0.9683615819209039,
        "vocab_size-3-nopunct": 857,
        "unique-3-nopunct": 837,
        "entropy-3-nopunct": 9.7163934687522,
        "cond_entropy-3-nopunct": 0.2010556226313374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.02324,
        "local_recall": {
            "1": 0.23972602739726026,
            "2": 0.48520710059171596,
            "3": 0.7872670807453416
        },
        "rouge1": {
            "precision": 0.74362,
            "recall": 0.73338,
            "fmeasure": 0.72748
        },
        "rouge2": {
            "precision": 0.49288,
            "recall": 0.48534,
            "fmeasure": 0.4826
        },
        "rougeL": {
            "precision": 0.56127,
            "recall": 0.56441,
            "fmeasure": 0.55465
        },
        "rougeLsum": {
            "precision": 0.56127,
            "recall": 0.56441,
            "fmeasure": 0.55465
        },
        "nist": 6.984299256596371,
        "bleurt": 0.18984,
        "bertscore": {
            "precision": 0.91979,
            "recall": 0.91863,
            "f1": 0.91766
        },
        "nubia": {
            "semantic_relation": 4.05234,
            "contradiction": 14.97047,
            "irrelevancy": 25.28984,
            "logical_agreement": 59.73969,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.106,
            "nubia_score": 0.69415
        },
        "meteor": 0.38128616550675004
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.5143,
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.35294117647058826
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.27027,
            "fmeasure": 0.39216
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.16667,
            "fmeasure": 0.2449
        },
        "rougeL": {
            "precision": 0.45238,
            "recall": 0.24488,
            "fmeasure": 0.31373
        },
        "rougeLsum": {
            "precision": 0.45238,
            "recall": 0.24488,
            "fmeasure": 0.31373
        },
        "nist": 0.532083694644509,
        "bleurt": -0.35748,
        "bertscore": {
            "precision": 0.89678,
            "recall": 0.79348,
            "f1": 0.84197
        },
        "nubia": {
            "semantic_relation": 3.04065,
            "contradiction": 0.2937,
            "irrelevancy": 32.09876,
            "logical_agreement": 67.60754,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.38308,
            "nubia_score": 0.32217
        },
        "meteor": 0.1793797387716111
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.74,
        "total_length": 613,
        "mean_pred_length": 30.65,
        "std_pred_length": 12.378509603340785,
        "median_pred_length": 34.5,
        "min_pred_length": 13,
        "max_pred_length": 57,
        "distinct-1": 0.5285481239804242,
        "vocab_size-1": 324,
        "unique-1": 268,
        "entropy-1": 7.301369514044989,
        "distinct-2": 0.8684654300168634,
        "vocab_size-2": 515,
        "unique-2": 471,
        "entropy-2": 8.87155378156472,
        "cond_entropy-2": 1.4880951048509221,
        "distinct-3": 0.9528795811518325,
        "vocab_size-3": 546,
        "unique-3": 522,
        "entropy-3": 9.064198200473326,
        "cond_entropy-3": 0.19622522651319277,
        "total_length-nopunct": 502,
        "mean_pred_length-nopunct": 25.1,
        "std_pred_length-nopunct": 9.486305919587455,
        "median_pred_length-nopunct": 28.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6354581673306773,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 268,
        "entropy-1-nopunct": 7.66175317365499,
        "distinct-2-nopunct": 0.9128630705394191,
        "vocab_size-2-nopunct": 440,
        "unique-2-nopunct": 412,
        "entropy-2-nopunct": 8.70907433424334,
        "cond_entropy-2-nopunct": 1.0847192572782525,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 448,
        "unique-3-nopunct": 434,
        "entropy-3-nopunct": 8.79114298081004,
        "cond_entropy-3-nopunct": 0.0908918068257653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.70814,
        "local_recall": {
            "1": 0.25287356321839083,
            "2": 0.31868131868131866,
            "3": 0.786144578313253
        },
        "rouge1": {
            "precision": 0.70046,
            "recall": 0.67429,
            "fmeasure": 0.67734
        },
        "rouge2": {
            "precision": 0.45088,
            "recall": 0.46065,
            "fmeasure": 0.44407
        },
        "rougeL": {
            "precision": 0.5372,
            "recall": 0.55229,
            "fmeasure": 0.52872
        },
        "rougeLsum": {
            "precision": 0.5372,
            "recall": 0.55229,
            "fmeasure": 0.52872
        },
        "nist": 6.429065169863847,
        "bleurt": 0.0603,
        "bertscore": {
            "precision": 0.90772,
            "recall": 0.90658,
            "f1": 0.90081
        },
        "nubia": {
            "semantic_relation": 3.87496,
            "contradiction": 7.43949,
            "irrelevancy": 35.16083,
            "logical_agreement": 57.39968,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.36231,
            "nubia_score": 0.62646
        },
        "meteor": 0.3738419382422625
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.47795,
        "msttr-100_nopunct": 0.48389,
        "total_length": 3993,
        "mean_pred_length": 14.955056179775282,
        "std_pred_length": 6.069960625950481,
        "median_pred_length": 15.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.10693713999499123,
        "vocab_size-1": 427,
        "unique-1": 206,
        "entropy-1": 5.949383482386951,
        "distinct-2": 0.262211486849168,
        "vocab_size-2": 977,
        "unique-2": 571,
        "entropy-2": 8.479197068374523,
        "cond_entropy-2": 2.4351502589328717,
        "distinct-3": 0.37091644984099453,
        "vocab_size-3": 1283,
        "unique-3": 857,
        "entropy-3": 9.112272383577912,
        "cond_entropy-3": 0.822219157677293,
        "total_length-nopunct": 3656,
        "mean_pred_length-nopunct": 13.692883895131086,
        "std_pred_length-nopunct": 5.82350155274593,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.11570021881838075,
        "vocab_size-1-nopunct": 423,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 5.963439734733111,
        "distinct-2-nopunct": 0.23989377397462378,
        "vocab_size-2-nopunct": 813,
        "unique-2-nopunct": 464,
        "entropy-2-nopunct": 8.172818171351128,
        "cond_entropy-2-nopunct": 2.5365319232358194,
        "distinct-3-nopunct": 0.3506243996157541,
        "vocab_size-3-nopunct": 1095,
        "unique-3-nopunct": 724,
        "entropy-3-nopunct": 8.830555392880962,
        "cond_entropy-3-nopunct": 0.8748995883928897,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 5.38495,
        "local_recall": {
            "1": 0.33615537848605576
        },
        "rouge1": {
            "precision": 0.45194,
            "recall": 0.55078,
            "fmeasure": 0.47461
        },
        "rouge2": {
            "precision": 0.23932,
            "recall": 0.30019,
            "fmeasure": 0.25276
        },
        "rougeL": {
            "precision": 0.41248,
            "recall": 0.49566,
            "fmeasure": 0.43039
        },
        "rougeLsum": {
            "precision": 0.41248,
            "recall": 0.49566,
            "fmeasure": 0.43039
        },
        "nist": 1.6714372341163701,
        "bleurt": -0.6382,
        "bertscore": {
            "precision": 0.83259,
            "recall": 0.86431,
            "f1": 0.8476
        },
        "nubia": {
            "semantic_relation": 3.16244,
            "contradiction": 31.19264,
            "irrelevancy": 27.42221,
            "logical_agreement": 41.38515,
            "grammar_ref": 7.44295,
            "grammar_hyp": 6.59329,
            "nubia_score": 0.32573
        },
        "meteor": 0.16003516261631853
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.71152,
        "msttr-100_nopunct": 0.75948,
        "total_length": 6650,
        "mean_pred_length": 18.52367688022284,
        "std_pred_length": 8.419957182768833,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.358796992481203,
        "vocab_size-1": 2386,
        "unique-1": 1784,
        "entropy-1": 8.953558440738265,
        "distinct-2": 0.8051184231441743,
        "vocab_size-2": 5065,
        "unique-2": 4636,
        "entropy-2": 11.862205573509087,
        "cond_entropy-2": 2.619061858370618,
        "distinct-3": 0.9318948078219824,
        "vocab_size-3": 5528,
        "unique-3": 5383,
        "entropy-3": 12.239300490470816,
        "cond_entropy-3": 0.4090435695657765,
        "total_length-nopunct": 5825,
        "mean_pred_length-nopunct": 16.225626740947074,
        "std_pred_length-nopunct": 7.224749368474962,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4078969957081545,
        "vocab_size-1-nopunct": 2376,
        "unique-1-nopunct": 1783,
        "entropy-1-nopunct": 9.34550947310491,
        "distinct-2-nopunct": 0.8353457738748628,
        "vocab_size-2-nopunct": 4566,
        "unique-2-nopunct": 4212,
        "entropy-2-nopunct": 11.838107865539808,
        "cond_entropy-2-nopunct": 2.6501193156727476,
        "distinct-3-nopunct": 0.9633835911494028,
        "vocab_size-3-nopunct": 4920,
        "unique-3-nopunct": 4805,
        "entropy-3-nopunct": 12.221599643811588,
        "cond_entropy-3-nopunct": 0.41627158703636835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "bleu": 54.34087,
        "local_recall": {
            "1": 0.04772946859903382,
            "2": 0.1559065934065934,
            "3": 0.2661195779601407,
            "4": 0.37110481586402266,
            "5": 0.4594953519256308,
            "6": 0.5517241379310345,
            "7": 0.6495433789954338,
            "8": 0.7410714285714286,
            "9": 0.837410071942446
        },
        "rouge1": {
            "precision": 0.74923,
            "recall": 0.72105,
            "fmeasure": 0.72502
        },
        "rouge2": {
            "precision": 0.55098,
            "recall": 0.52737,
            "fmeasure": 0.52841
        },
        "rougeL": {
            "precision": 0.70642,
            "recall": 0.68346,
            "fmeasure": 0.68465
        },
        "rougeLsum": {
            "precision": 0.70642,
            "recall": 0.68346,
            "fmeasure": 0.68465
        },
        "nist": 10.19965325004505,
        "sari": 48.21767,
        "bleurt": -0.18834,
        "bertscore": {
            "precision": 0.91628,
            "recall": 0.92736,
            "f1": 0.91752
        },
        "nubia": {
            "semantic_relation": 3.87617,
            "contradiction": 6.22157,
            "irrelevancy": 29.74672,
            "logical_agreement": 64.0317,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.3391,
            "nubia_score": 0.51987
        },
        "meteor": 0.38271670754026643
    },
    "web_nlg_ru_test": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.4626,
        "msttr-100_nopunct": 0.45846,
        "total_length": 49366,
        "mean_pred_length": 44.796733212341195,
        "std_pred_length": 19.58907405568092,
        "median_pred_length": 44.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.05157395778471013,
        "vocab_size-1": 2546,
        "unique-1": 900,
        "entropy-1": 5.999085745910672,
        "distinct-2": 0.15442151500082876,
        "vocab_size-2": 7453,
        "unique-2": 3610,
        "entropy-2": 10.432168621845742,
        "cond_entropy-2": 4.427192026476155,
        "distinct-3": 0.30064458674356476,
        "vocab_size-3": 14179,
        "unique-3": 8298,
        "entropy-3": 12.31206777882221,
        "cond_entropy-3": 1.9216835662489677,
        "total_length-nopunct": 45535,
        "mean_pred_length-nopunct": 41.32032667876588,
        "std_pred_length-nopunct": 18.488381712104562,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.0556934226419238,
        "vocab_size-1-nopunct": 2536,
        "unique-1-nopunct": 899,
        "entropy-1-nopunct": 5.910710888354268,
        "distinct-2-nopunct": 0.1547498480858821,
        "vocab_size-2-nopunct": 6876,
        "unique-2-nopunct": 3361,
        "entropy-2-nopunct": 10.297966025076649,
        "cond_entropy-2-nopunct": 4.4772882818019815,
        "distinct-3-nopunct": 0.3011239066718977,
        "vocab_size-3-nopunct": 13048,
        "unique-3-nopunct": 7768,
        "entropy-3-nopunct": 12.144517317677112,
        "cond_entropy-3-nopunct": 1.88577403103933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.03604,
        "local_recall": {
            "1": 0.09135679109271287,
            "2": 0.18246869409660108,
            "3": 0.26572121664489645,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.42994,
            "recall": 0.4127,
            "fmeasure": 0.41466
        },
        "rouge2": {
            "precision": 0.22295,
            "recall": 0.21399,
            "fmeasure": 0.21452
        },
        "rougeL": {
            "precision": 0.40967,
            "recall": 0.39423,
            "fmeasure": 0.39541
        },
        "rougeLsum": {
            "precision": 0.40967,
            "recall": 0.39423,
            "fmeasure": 0.39541
        },
        "nist": 1.1410213257395803,
        "bleurt": -0.47858,
        "bertscore": {
            "precision": 0.86167,
            "recall": 0.87319,
            "f1": 0.86692
        },
        "nubia": {
            "semantic_relation": 3.31214,
            "contradiction": 32.96149,
            "irrelevancy": 17.24722,
            "logical_agreement": 49.79129,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.63533,
            "nubia_score": 0.15928
        },
        "meteor": 0.1277643403208298
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71833,
        "total_length": 807,
        "mean_pred_length": 31.03846153846154,
        "std_pred_length": 9.885812558451045,
        "median_pred_length": 34.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.49318463444857497,
        "vocab_size-1": 398,
        "unique-1": 315,
        "entropy-1": 7.448023166022855,
        "distinct-2": 0.8617157490396927,
        "vocab_size-2": 673,
        "unique-2": 615,
        "entropy-2": 9.22509787923886,
        "cond_entropy-2": 1.694113140177644,
        "distinct-3": 0.9682119205298013,
        "vocab_size-3": 731,
        "unique-3": 709,
        "entropy-3": 9.49475697327947,
        "cond_entropy-3": 0.26964068653260526,
        "total_length-nopunct": 678,
        "mean_pred_length-nopunct": 26.076923076923077,
        "std_pred_length-nopunct": 8.347837476409348,
        "median_pred_length-nopunct": 27.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5766961651917404,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 313,
        "entropy-1-nopunct": 7.724641214960037,
        "distinct-2-nopunct": 0.906441717791411,
        "vocab_size-2-nopunct": 591,
        "unique-2-nopunct": 553,
        "entropy-2-nopunct": 9.113953157584225,
        "cond_entropy-2-nopunct": 1.4346275891390718,
        "distinct-3-nopunct": 0.9824281150159745,
        "vocab_size-3-nopunct": 615,
        "unique-3-nopunct": 605,
        "entropy-3-nopunct": 9.253669186385896,
        "cond_entropy-3-nopunct": 0.14307729064323718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.41889,
        "local_recall": {
            "1": 0.18333333333333332,
            "2": 0.37815126050420167,
            "3": 0.7841409691629956
        },
        "rouge1": {
            "precision": 0.76269,
            "recall": 0.68226,
            "fmeasure": 0.70435
        },
        "rouge2": {
            "precision": 0.49864,
            "recall": 0.45017,
            "fmeasure": 0.46361
        },
        "rougeL": {
            "precision": 0.619,
            "recall": 0.54463,
            "fmeasure": 0.56571
        },
        "rougeLsum": {
            "precision": 0.619,
            "recall": 0.54463,
            "fmeasure": 0.56571
        },
        "nist": 6.891201491192564,
        "bleurt": 0.10215,
        "bertscore": {
            "precision": 0.91983,
            "recall": 0.90838,
            "f1": 0.91121
        },
        "nubia": {
            "semantic_relation": 3.7292,
            "contradiction": 9.79327,
            "irrelevancy": 35.52601,
            "logical_agreement": 54.68072,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.08755,
            "nubia_score": 0.60019
        },
        "meteor": 0.36602153311748153
    },
    "schema_guided_dialog_test": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.69194,
        "msttr-100_nopunct": 0.71955,
        "total_length": 129292,
        "mean_pred_length": 12.9292,
        "std_pred_length": 7.470126328249075,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 53,
        "distinct-1": 0.034340871825016245,
        "vocab_size-1": 4440,
        "unique-1": 1933,
        "entropy-1": 8.122811278721331,
        "distinct-2": 0.15836770277973375,
        "vocab_size-2": 18892,
        "unique-2": 10391,
        "entropy-2": 11.870906336224015,
        "cond_entropy-2": 3.4833862734579855,
        "distinct-3": 0.33484912255018573,
        "vocab_size-3": 36597,
        "unique-3": 24387,
        "entropy-3": 13.598677306075277,
        "cond_entropy-3": 1.7484531423155054,
        "total_length-nopunct": 113503,
        "mean_pred_length-nopunct": 11.3503,
        "std_pred_length-nopunct": 6.8479624641202586,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.03895932266107504,
        "vocab_size-1-nopunct": 4422,
        "unique-1-nopunct": 1931,
        "entropy-1-nopunct": 8.356762351131485,
        "distinct-2-nopunct": 0.1749804353497,
        "vocab_size-2-nopunct": 18111,
        "unique-2-nopunct": 10423,
        "entropy-2-nopunct": 11.789866628428733,
        "cond_entropy-2-nopunct": 3.5857889915373273,
        "distinct-3-nopunct": 0.36112239878520863,
        "vocab_size-3-nopunct": 33770,
        "unique-3-nopunct": 23207,
        "entropy-3-nopunct": 13.505483263743447,
        "cond_entropy-3-nopunct": 1.7667809362097375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 31.62644,
        "local_recall": {
            "1": 0.5629226763354572
        },
        "rouge1": {
            "precision": 0.56905,
            "recall": 0.54796,
            "fmeasure": 0.54582
        },
        "rouge2": {
            "precision": 0.35113,
            "recall": 0.33774,
            "fmeasure": 0.33583
        },
        "rougeL": {
            "precision": 0.5105,
            "recall": 0.49083,
            "fmeasure": 0.48928
        },
        "rougeLsum": {
            "precision": 0.5105,
            "recall": 0.49083,
            "fmeasure": 0.48928
        },
        "nist": 6.850828538041282,
        "bleurt": -0.09157,
        "bertscore": {
            "precision": 0.87033,
            "recall": 0.86463,
            "f1": 0.86693
        },
        "nubia": {
            "semantic_relation": 3.61149,
            "contradiction": 6.544,
            "irrelevancy": 23.57002,
            "logical_agreement": 69.88598,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.64204,
            "nubia_score": 0.63736
        },
        "meteor": 0.3137968277462085
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 9.019977827023746,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.7373737373737373,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.919612554357492,
        "distinct-2": 0.9893617021276596,
        "vocab_size-2": 93,
        "unique-2": 92,
        "entropy-2": 6.533312255932943,
        "cond_entropy-2": 0.5139540401393541,
        "distinct-3": 1.0,
        "vocab_size-3": 89,
        "unique-3": 89,
        "entropy-3": 6.47573343096641,
        "cond_entropy-3": -0.056383510598879874,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 8.12403840463596,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.9056876796389615,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.5146541633628919,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.06246284125033935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 82.81111,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.23809523809523808,
            "3": 0.375,
            "4": 0.8,
            "5": 0.5714285714285714,
            "6": 1.0,
            "7": 0.8333333333333334,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.86577,
            "recall": 0.88733,
            "fmeasure": 0.87556
        },
        "rouge2": {
            "precision": 0.78857,
            "recall": 0.81685,
            "fmeasure": 0.80114
        },
        "rougeL": {
            "precision": 0.86577,
            "recall": 0.88733,
            "fmeasure": 0.87556
        },
        "rougeLsum": {
            "precision": 0.86577,
            "recall": 0.88733,
            "fmeasure": 0.87556
        },
        "nist": 7.632759383511048,
        "bleurt": 0.31086,
        "bertscore": {
            "precision": 0.97209,
            "recall": 0.98327,
            "f1": 0.97295
        },
        "nubia": {
            "semantic_relation": 4.45978,
            "contradiction": 0.35857,
            "irrelevancy": 49.89187,
            "logical_agreement": 49.74956,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.42981,
            "nubia_score": 0.63383
        },
        "meteor": 0.5869809402207832
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72156,
        "msttr-100_nopunct": 0.76194,
        "total_length": 7723,
        "mean_pred_length": 21.512534818941504,
        "std_pred_length": 9.55349891325458,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.35374854331218436,
        "vocab_size-1": 2732,
        "unique-1": 1994,
        "entropy-1": 9.124634549184902,
        "distinct-2": 0.8155893536121673,
        "vocab_size-2": 6006,
        "unique-2": 5557,
        "entropy-2": 12.143242720581648,
        "cond_entropy-2": 2.776419083029817,
        "distinct-3": 0.9481798715203427,
        "vocab_size-3": 6642,
        "unique-3": 6504,
        "entropy-3": 12.56742354298717,
        "cond_entropy-3": 0.4432893017890854,
        "total_length-nopunct": 6792,
        "mean_pred_length-nopunct": 18.919220055710305,
        "std_pred_length-nopunct": 8.22365928851851,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4004711425206125,
        "vocab_size-1-nopunct": 2720,
        "unique-1-nopunct": 1991,
        "entropy-1-nopunct": 9.504696468726728,
        "distinct-2-nopunct": 0.8440851857609203,
        "vocab_size-2-nopunct": 5430,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.092331158621885,
        "cond_entropy-2-nopunct": 2.716657921518432,
        "distinct-3-nopunct": 0.9705301284162002,
        "vocab_size-3-nopunct": 5895,
        "unique-3-nopunct": 5792,
        "entropy-3-nopunct": 12.487194869687839,
        "cond_entropy-3-nopunct": 0.4221573916938865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.82119,
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.16711590296495957,
            "3": 0.3710843373493976,
            "4": 0.5626911314984709,
            "5": 0.6828528072837633,
            "6": 0.7971830985915493,
            "7": 0.8688524590163934,
            "8": 0.9071170084439083,
            "9": 0.926984126984127,
            "10": 0.9635658914728682
        },
        "rouge1": {
            "precision": 0.87923,
            "recall": 0.88301,
            "fmeasure": 0.87481
        },
        "rouge2": {
            "precision": 0.76929,
            "recall": 0.78066,
            "fmeasure": 0.76709
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "nist": 12.709964093712534,
        "bleurt": 0.2121,
        "bertscore": {
            "precision": 0.96314,
            "recall": 0.97071,
            "f1": 0.96417
        },
        "nubia": {
            "semantic_relation": 4.27732,
            "contradiction": 2.99509,
            "irrelevancy": 35.42939,
            "logical_agreement": 61.57552,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.73338,
            "nubia_score": 0.65371
        },
        "meteor": 0.5229674536458527
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.68703,
        "msttr-100_nopunct": 0.71804,
        "total_length": 6420,
        "mean_pred_length": 12.84,
        "std_pred_length": 7.257988702113003,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 44,
        "distinct-1": 0.1590342679127726,
        "vocab_size-1": 1021,
        "unique-1": 585,
        "entropy-1": 7.797955826506721,
        "distinct-2": 0.4902027027027027,
        "vocab_size-2": 2902,
        "unique-2": 2059,
        "entropy-2": 10.693369906791752,
        "cond_entropy-2": 2.6398997030522433,
        "distinct-3": 0.7035055350553505,
        "vocab_size-3": 3813,
        "unique-3": 3159,
        "entropy-3": 11.499541234737674,
        "cond_entropy-3": 0.8235392656900072,
        "total_length-nopunct": 5620,
        "mean_pred_length-nopunct": 11.24,
        "std_pred_length-nopunct": 6.630716401717087,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.17935943060498222,
        "vocab_size-1-nopunct": 1008,
        "unique-1-nopunct": 581,
        "entropy-1-nopunct": 7.998060004571707,
        "distinct-2-nopunct": 0.509375,
        "vocab_size-2-nopunct": 2608,
        "unique-2-nopunct": 1906,
        "entropy-2-nopunct": 10.531888123780137,
        "cond_entropy-2-nopunct": 2.6593665263554764,
        "distinct-3-nopunct": 0.7183982683982684,
        "vocab_size-3-nopunct": 3319,
        "unique-3-nopunct": 2812,
        "entropy-3-nopunct": 11.291847262830018,
        "cond_entropy-3-nopunct": 0.8033947351701269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "bleu": 30.39648,
        "local_recall": {
            "1": 0.5508160237388724
        },
        "rouge1": {
            "precision": 0.54182,
            "recall": 0.5344,
            "fmeasure": 0.52472
        },
        "rouge2": {
            "precision": 0.32406,
            "recall": 0.31809,
            "fmeasure": 0.31195
        },
        "rougeL": {
            "precision": 0.48899,
            "recall": 0.48071,
            "fmeasure": 0.47284
        },
        "rougeLsum": {
            "precision": 0.48899,
            "recall": 0.48071,
            "fmeasure": 0.47284
        },
        "nist": 5.708628222096705,
        "bleurt": -0.10474,
        "bertscore": {
            "precision": 0.8648,
            "recall": 0.86117,
            "f1": 0.86244
        },
        "nubia": {
            "semantic_relation": 3.61078,
            "contradiction": 5.88193,
            "irrelevancy": 24.00739,
            "logical_agreement": 70.11068,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.56446,
            "nubia_score": 0.64731
        },
        "meteor": 0.309229796907654
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.44176,
        "msttr-100_nopunct": 0.43647,
        "total_length": 22217,
        "mean_pred_length": 44.434,
        "std_pred_length": 20.10615935478479,
        "median_pred_length": 43.5,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.08200927217896206,
        "vocab_size-1": 1822,
        "unique-1": 779,
        "entropy-1": 5.923923022806439,
        "distinct-2": 0.22213012847078326,
        "vocab_size-2": 4824,
        "unique-2": 2623,
        "entropy-2": 10.221388207868895,
        "cond_entropy-2": 4.2922383094223155,
        "distinct-3": 0.3972286374133949,
        "vocab_size-3": 8428,
        "unique-3": 5412,
        "entropy-3": 11.908175673340395,
        "cond_entropy-3": 1.7276956636393084,
        "total_length-nopunct": 20488,
        "mean_pred_length-nopunct": 40.976,
        "std_pred_length-nopunct": 18.845143247001335,
        "median_pred_length-nopunct": 40.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.08844201483795393,
        "vocab_size-1-nopunct": 1812,
        "unique-1-nopunct": 779,
        "entropy-1-nopunct": 5.8309465714268685,
        "distinct-2-nopunct": 0.22098258955373223,
        "vocab_size-2-nopunct": 4417,
        "unique-2-nopunct": 2385,
        "entropy-2-nopunct": 10.08331233324339,
        "cond_entropy-2-nopunct": 4.341694580639392,
        "distinct-3-nopunct": 0.3944478653530378,
        "vocab_size-3-nopunct": 7687,
        "unique-3-nopunct": 4966,
        "entropy-3-nopunct": 11.74238996390596,
        "cond_entropy-3-nopunct": 1.6942313902213582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "bleu": 2.03308,
        "local_recall": {
            "1": 0.0917535853976532,
            "2": 0.18333333333333332,
            "3": 0.2628909551986475,
            "4": 0.17777777777777778,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.42218,
            "recall": 0.40669,
            "fmeasure": 0.40671
        },
        "rouge2": {
            "precision": 0.21475,
            "recall": 0.20703,
            "fmeasure": 0.2064
        },
        "rougeL": {
            "precision": 0.40244,
            "recall": 0.38804,
            "fmeasure": 0.3875
        },
        "rougeLsum": {
            "precision": 0.40244,
            "recall": 0.38804,
            "fmeasure": 0.3875
        },
        "nist": 1.1332400380725607,
        "bleurt": -0.48138,
        "bertscore": {
            "precision": 0.86109,
            "recall": 0.8724,
            "f1": 0.86625
        },
        "nubia": {
            "semantic_relation": 3.31112,
            "contradiction": 33.39375,
            "irrelevancy": 17.15269,
            "logical_agreement": 49.45355,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.64672,
            "nubia_score": 0.15934
        },
        "meteor": 0.12843598156032263
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 91.0,
        "std_pred_length": 0.0,
        "median_pred_length": 91.0,
        "min_pred_length": 91,
        "max_pred_length": 91,
        "distinct-1": 0.6703296703296703,
        "vocab_size-1": 61,
        "unique-1": 53,
        "entropy-1": 5.335837192286765,
        "distinct-2": 0.9111111111111111,
        "vocab_size-2": 82,
        "unique-2": 77,
        "entropy-2": 6.273968202169255,
        "cond_entropy-2": 0.9511527593037468,
        "distinct-3": 0.9775280898876404,
        "vocab_size-3": 87,
        "unique-3": 85,
        "entropy-3": 6.430789610741691,
        "cond_entropy-3": 0.15926955345061958,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 67.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 67.0,
        "min_pred_length-nopunct": 67,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.8507462686567164,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.65338046725772,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.044394119358462,
        "cond_entropy-2-nopunct": 0.3972668145734568,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.022026306329998854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.13391,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.23881,
            "recall": 0.65812,
            "fmeasure": 0.34979
        },
        "rouge2": {
            "precision": 0.07071,
            "recall": 0.20741,
            "fmeasure": 0.10501
        },
        "rougeL": {
            "precision": 0.1194,
            "recall": 0.40769,
            "fmeasure": 0.18464
        },
        "rougeLsum": {
            "precision": 0.1194,
            "recall": 0.40769,
            "fmeasure": 0.18464
        },
        "nist": 1.113888576023422,
        "bleurt": -1.00927,
        "bertscore": {
            "precision": 0.76291,
            "recall": 0.86734,
            "f1": 0.81178
        },
        "nubia": {
            "semantic_relation": 2.53959,
            "contradiction": 0.35329,
            "irrelevancy": 60.767,
            "logical_agreement": 38.87972,
            "grammar_ref": 4.75948,
            "grammar_hyp": 4.23705,
            "nubia_score": 0.06486
        },
        "meteor": 0.20897957639577913
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.46365,
        "msttr-100_nopunct": 0.46617,
        "total_length": 5228,
        "mean_pred_length": 20.58267716535433,
        "std_pred_length": 6.939492078898904,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.16775057383320582,
        "vocab_size-1": 877,
        "unique-1": 534,
        "entropy-1": 5.6693139992825845,
        "distinct-2": 0.39123441897868916,
        "vocab_size-2": 1946,
        "unique-2": 1307,
        "entropy-2": 9.671503641718697,
        "cond_entropy-2": 3.936329826259188,
        "distinct-3": 0.586228813559322,
        "vocab_size-3": 2767,
        "unique-3": 2079,
        "entropy-3": 10.792589408137564,
        "cond_entropy-3": 1.1837175151059156,
        "total_length-nopunct": 4772,
        "mean_pred_length-nopunct": 18.787401574803148,
        "std_pred_length-nopunct": 6.79987253384451,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.18231349538977368,
        "vocab_size-1-nopunct": 870,
        "unique-1-nopunct": 533,
        "entropy-1-nopunct": 5.567695418257679,
        "distinct-2-nopunct": 0.37760070827799913,
        "vocab_size-2-nopunct": 1706,
        "unique-2-nopunct": 1118,
        "entropy-2-nopunct": 9.4497990976056,
        "cond_entropy-2-nopunct": 4.083207774523002,
        "distinct-3-nopunct": 0.5715290806754222,
        "vocab_size-3-nopunct": 2437,
        "unique-3-nopunct": 1815,
        "entropy-3-nopunct": 10.576675920828688,
        "cond_entropy-3-nopunct": 1.193367081508091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 3.2304,
        "local_recall": {
            "1": 0.109375,
            "2": 0.18862690707350901,
            "3": 0.24573378839590443,
            "4": 0.22857142857142856,
            "5": 0.36363636363636365,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.33228,
            "recall": 0.3333,
            "fmeasure": 0.3309
        },
        "rouge2": {
            "precision": 0.19417,
            "recall": 0.18734,
            "fmeasure": 0.18935
        },
        "rougeL": {
            "precision": 0.33064,
            "recall": 0.33182,
            "fmeasure": 0.32935
        },
        "rougeLsum": {
            "precision": 0.33064,
            "recall": 0.33182,
            "fmeasure": 0.32935
        },
        "nist": 1.055704855596246,
        "bleurt": -0.37519,
        "bertscore": {
            "precision": 0.86958,
            "recall": 0.88048,
            "f1": 0.87458
        },
        "nubia": {
            "semantic_relation": 3.35343,
            "contradiction": 36.15575,
            "irrelevancy": 15.48598,
            "logical_agreement": 48.35827,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.99775,
            "nubia_score": 0.21039
        },
        "meteor": 0.15040924148318555
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.45657,
        "msttr-100_nopunct": 0.45358,
        "total_length": 10287,
        "mean_pred_length": 64.69811320754717,
        "std_pred_length": 8.68219802110906,
        "median_pred_length": 66.0,
        "min_pred_length": 37,
        "max_pred_length": 87,
        "distinct-1": 0.11451346359482842,
        "vocab_size-1": 1178,
        "unique-1": 566,
        "entropy-1": 5.79372719557941,
        "distinct-2": 0.28791469194312796,
        "vocab_size-2": 2916,
        "unique-2": 1695,
        "entropy-2": 9.887607903974283,
        "cond_entropy-2": 4.1102888393078,
        "distinct-3": 0.4943324305346574,
        "vocab_size-3": 4928,
        "unique-3": 3360,
        "entropy-3": 11.445753587226438,
        "cond_entropy-3": 1.5752759914828578,
        "total_length-nopunct": 9522,
        "mean_pred_length-nopunct": 59.886792452830186,
        "std_pred_length-nopunct": 8.939335118069497,
        "median_pred_length-nopunct": 61.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.122978365889519,
        "vocab_size-1-nopunct": 1171,
        "unique-1-nopunct": 566,
        "entropy-1-nopunct": 5.692502696876267,
        "distinct-2-nopunct": 0.29178682046352666,
        "vocab_size-2-nopunct": 2732,
        "unique-2-nopunct": 1587,
        "entropy-2-nopunct": 9.788274522182585,
        "cond_entropy-2-nopunct": 4.1482724944562674,
        "distinct-3-nopunct": 0.49445893089960885,
        "vocab_size-3-nopunct": 4551,
        "unique-3-nopunct": 3138,
        "entropy-3-nopunct": 11.301591862887504,
        "cond_entropy-3-nopunct": 1.5283538131403325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.80348,
        "local_recall": {
            "1": 0.07472384665367121,
            "2": 0.16977491961414792,
            "3": 0.27486910994764396
        },
        "rouge1": {
            "precision": 0.4756,
            "recall": 0.4284,
            "fmeasure": 0.43953
        },
        "rouge2": {
            "precision": 0.24953,
            "recall": 0.21932,
            "fmeasure": 0.22783
        },
        "rougeL": {
            "precision": 0.44557,
            "recall": 0.40225,
            "fmeasure": 0.41198
        },
        "rougeLsum": {
            "precision": 0.44557,
            "recall": 0.40225,
            "fmeasure": 0.41198
        },
        "nist": 1.0454621522228313,
        "bleurt": -0.53508,
        "bertscore": {
            "precision": 0.85451,
            "recall": 0.8653,
            "f1": 0.85929
        },
        "nubia": {
            "semantic_relation": 3.33126,
            "contradiction": 32.61731,
            "irrelevancy": 18.06589,
            "logical_agreement": 49.3168,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.36975,
            "nubia_score": 0.12266
        },
        "meteor": 0.11733375950839724
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "T5-xl (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.67896,
        "msttr-100_nopunct": 0.68036,
        "total_length": 37402,
        "mean_pred_length": 19.299277605779153,
        "std_pred_length": 5.695961081886115,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 61,
        "distinct-1": 0.1790545960109085,
        "vocab_size-1": 6697,
        "unique-1": 4093,
        "entropy-1": 9.038131319757369,
        "distinct-2": 0.5515452289645838,
        "vocab_size-2": 19560,
        "unique-2": 15820,
        "entropy-2": 13.165294711845657,
        "cond_entropy-2": 4.292651179468404,
        "distinct-3": 0.8203483863270298,
        "vocab_size-3": 27503,
        "unique-3": 25073,
        "entropy-3": 14.455130962228724,
        "cond_entropy-3": 1.2954350590086943,
        "total_length-nopunct": 36388,
        "mean_pred_length-nopunct": 18.776057791537667,
        "std_pred_length-nopunct": 5.3502123778302675,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.18374189293173573,
        "vocab_size-1-nopunct": 6686,
        "unique-1-nopunct": 4092,
        "entropy-1-nopunct": 9.059345750905521,
        "distinct-2-nopunct": 0.5588679245283019,
        "vocab_size-2-nopunct": 19253,
        "unique-2-nopunct": 15657,
        "entropy-2-nopunct": 13.15260246385894,
        "cond_entropy-2-nopunct": 4.265216194361533,
        "distinct-3-nopunct": 0.8244955708661418,
        "vocab_size-3-nopunct": 26806,
        "unique-3-nopunct": 24526,
        "entropy-3-nopunct": 14.421543219286086,
        "cond_entropy-3-nopunct": 1.272829080846782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "bleu": 5.61732,
        "local_recall": {
            "1": 0.24316058183219344
        },
        "rouge1": {
            "precision": 0.36159,
            "recall": 0.26384,
            "fmeasure": 0.29468
        },
        "rouge2": {
            "precision": 0.12963,
            "recall": 0.09396,
            "fmeasure": 0.10523
        },
        "rougeL": {
            "precision": 0.28246,
            "recall": 0.20783,
            "fmeasure": 0.23112
        },
        "rougeLsum": {
            "precision": 0.28246,
            "recall": 0.20783,
            "fmeasure": 0.23112
        },
        "nist": 2.0794984004461563,
        "bleurt": -0.55159,
        "bertscore": {
            "precision": 0.84487,
            "recall": 0.83151,
            "f1": 0.83795
        },
        "nubia": {
            "semantic_relation": 1.65332,
            "contradiction": 26.18913,
            "irrelevancy": 61.15663,
            "logical_agreement": 12.65424,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.59958,
            "nubia_score": 0.16077
        },
        "meteor": 0.19097901563557698
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.44339,
        "msttr-100_nopunct": 0.43879,
        "total_length": 49224,
        "mean_pred_length": 44.789808917197455,
        "std_pred_length": 19.590169626762897,
        "median_pred_length": 44.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.05153989923614497,
        "vocab_size-1": 2537,
        "unique-1": 892,
        "entropy-1": 5.997780706271125,
        "distinct-2": 0.15424415584415585,
        "vocab_size-2": 7423,
        "unique-2": 3588,
        "entropy-2": 10.428899583868137,
        "cond_entropy-2": 4.42510644661386,
        "distinct-3": 0.3003232254497512,
        "vocab_size-3": 14123,
        "unique-3": 8256,
        "entropy-3": 12.307597745533602,
        "cond_entropy-3": 1.9204711485846457,
        "total_length-nopunct": 45407,
        "mean_pred_length-nopunct": 41.31665150136488,
        "std_pred_length-nopunct": 18.493188015652667,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.055652212213975816,
        "vocab_size-1-nopunct": 2527,
        "unique-1-nopunct": 891,
        "entropy-1-nopunct": 5.909154381246831,
        "distinct-2-nopunct": 0.15457705154825313,
        "vocab_size-2-nopunct": 6849,
        "unique-2-nopunct": 3342,
        "entropy-2-nopunct": 10.294828816718331,
        "cond_entropy-2-nopunct": 4.475661273945132,
        "distinct-3-nopunct": 0.3008401027563702,
        "vocab_size-3-nopunct": 12999,
        "unique-3-nopunct": 7730,
        "entropy-3-nopunct": 12.140420537468824,
        "cond_entropy-3-nopunct": 1.8848886067818813,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.03987,
        "local_recall": {
            "1": 0.09102619149849721,
            "2": 0.18263266712611992,
            "3": 0.266554117426374,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.43111,
            "recall": 0.41383,
            "fmeasure": 0.4158
        },
        "rouge2": {
            "precision": 0.22355,
            "recall": 0.21457,
            "fmeasure": 0.21511
        },
        "rougeL": {
            "precision": 0.41079,
            "recall": 0.39531,
            "fmeasure": 0.39649
        },
        "rougeLsum": {
            "precision": 0.41079,
            "recall": 0.39531,
            "fmeasure": 0.39649
        },
        "nist": 1.141086324499846,
        "bleurt": -0.47863,
        "bertscore": {
            "precision": 0.86166,
            "recall": 0.87316,
            "f1": 0.8669
        },
        "nubia": {
            "semantic_relation": 3.3124,
            "contradiction": 32.96001,
            "irrelevancy": 17.24622,
            "logical_agreement": 49.79377,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.63545,
            "nubia_score": 0.15941
        },
        "meteor": 0.12774908273937233
    },
    "web_nlg_en_validation": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.56316,
        "msttr-100_nopunct": 0.5881,
        "total_length": 37080,
        "mean_pred_length": 22.24355128974205,
        "std_pred_length": 11.353171011105989,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 72,
        "distinct-1": 0.09897518878101402,
        "vocab_size-1": 3670,
        "unique-1": 1229,
        "entropy-1": 8.741460428437069,
        "distinct-2": 0.3455510688165363,
        "vocab_size-2": 12237,
        "unique-2": 7034,
        "entropy-2": 12.365756412107993,
        "cond_entropy-2": 3.397463591616754,
        "distinct-3": 0.5714455046524033,
        "vocab_size-3": 19284,
        "unique-3": 13836,
        "entropy-3": 13.646266896217497,
        "cond_entropy-3": 1.3252527165645072,
        "total_length-nopunct": 32709,
        "mean_pred_length-nopunct": 19.621475704859026,
        "std_pred_length-nopunct": 10.205511266458808,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.11183466324253263,
        "vocab_size-1-nopunct": 3658,
        "unique-1-nopunct": 1228,
        "entropy-1-nopunct": 9.123633970325427,
        "distinct-2-nopunct": 0.3626377166419689,
        "vocab_size-2-nopunct": 11257,
        "unique-2-nopunct": 6724,
        "entropy-2-nopunct": 12.26500198851921,
        "cond_entropy-2-nopunct": 3.285828528054656,
        "distinct-3-nopunct": 0.584,
        "vocab_size-3-nopunct": 17155,
        "unique-3-nopunct": 12559,
        "entropy-3-nopunct": 13.482671190567894,
        "cond_entropy-3-nopunct": 1.264698372414073,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "bleu": 59.6543,
        "local_recall": {
            "1": 0.3267645736550277,
            "2": 0.7239463601532568,
            "3": 0.9334060341693929,
            "4": 0.950354609929078,
            "5": 0.9714285714285714,
            "6": 0.75,
            "7": 1.0,
            "8": 1.0
        },
        "rouge1": {
            "precision": 0.82006,
            "recall": 0.81697,
            "fmeasure": 0.81334
        },
        "rouge2": {
            "precision": 0.60448,
            "recall": 0.60298,
            "fmeasure": 0.59968
        },
        "rougeL": {
            "precision": 0.68576,
            "recall": 0.68561,
            "fmeasure": 0.68109
        },
        "rougeLsum": {
            "precision": 0.68576,
            "recall": 0.68561,
            "fmeasure": 0.68109
        },
        "nist": 11.116115022217445,
        "bleurt": 0.40918,
        "bertscore": {
            "precision": 0.94965,
            "recall": 0.95064,
            "f1": 0.94931
        },
        "nubia": {
            "semantic_relation": 4.74437,
            "contradiction": 2.68133,
            "irrelevancy": 3.95992,
            "logical_agreement": 93.35875,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.56801,
            "nubia_score": 0.88626
        },
        "meteor": 0.44973575509107616
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72156,
        "msttr-100_nopunct": 0.76194,
        "total_length": 7723,
        "mean_pred_length": 21.512534818941504,
        "std_pred_length": 9.55349891325458,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.35374854331218436,
        "vocab_size-1": 2732,
        "unique-1": 1994,
        "entropy-1": 9.124634549184902,
        "distinct-2": 0.8155893536121673,
        "vocab_size-2": 6006,
        "unique-2": 5557,
        "entropy-2": 12.143242720581648,
        "cond_entropy-2": 2.776419083029817,
        "distinct-3": 0.9481798715203427,
        "vocab_size-3": 6642,
        "unique-3": 6504,
        "entropy-3": 12.56742354298717,
        "cond_entropy-3": 0.4432893017890854,
        "total_length-nopunct": 6792,
        "mean_pred_length-nopunct": 18.919220055710305,
        "std_pred_length-nopunct": 8.22365928851851,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4004711425206125,
        "vocab_size-1-nopunct": 2720,
        "unique-1-nopunct": 1991,
        "entropy-1-nopunct": 9.504696468726728,
        "distinct-2-nopunct": 0.8440851857609203,
        "vocab_size-2-nopunct": 5430,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.092331158621885,
        "cond_entropy-2-nopunct": 2.716657921518432,
        "distinct-3-nopunct": 0.9705301284162002,
        "vocab_size-3-nopunct": 5895,
        "unique-3-nopunct": 5792,
        "entropy-3-nopunct": 12.487194869687839,
        "cond_entropy-3-nopunct": 0.4221573916938865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.82119,
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.16711590296495957,
            "3": 0.3710843373493976,
            "4": 0.5626911314984709,
            "5": 0.6828528072837633,
            "6": 0.7971830985915493,
            "7": 0.8688524590163934,
            "8": 0.9071170084439083,
            "9": 0.926984126984127,
            "10": 0.9635658914728682
        },
        "rouge1": {
            "precision": 0.87923,
            "recall": 0.88301,
            "fmeasure": 0.87481
        },
        "rouge2": {
            "precision": 0.76929,
            "recall": 0.78066,
            "fmeasure": 0.76709
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "nist": 12.709964093712534,
        "bleurt": 0.2121,
        "bertscore": {
            "precision": 0.96314,
            "recall": 0.97071,
            "f1": 0.96417
        },
        "nubia": {
            "semantic_relation": 4.27732,
            "contradiction": 2.99509,
            "irrelevancy": 35.42939,
            "logical_agreement": 61.57552,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.73338,
            "nubia_score": 0.65371
        },
        "meteor": 0.5229674536458527
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.69365,
        "msttr-100_nopunct": 0.72436,
        "total_length": 6372,
        "mean_pred_length": 12.744,
        "std_pred_length": 7.1687142501288195,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 39,
        "distinct-1": 0.15756434400502198,
        "vocab_size-1": 1004,
        "unique-1": 553,
        "entropy-1": 7.867941116394762,
        "distinct-2": 0.49165531335149865,
        "vocab_size-2": 2887,
        "unique-2": 2032,
        "entropy-2": 10.73260120246544,
        "cond_entropy-2": 2.6219731862124456,
        "distinct-3": 0.7115205657919226,
        "vocab_size-3": 3823,
        "unique-3": 3156,
        "entropy-3": 11.54490204885289,
        "cond_entropy-3": 0.834908385640412,
        "total_length-nopunct": 5596,
        "mean_pred_length-nopunct": 11.192,
        "std_pred_length-nopunct": 6.556457580126634,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.1769120800571837,
        "vocab_size-1-nopunct": 990,
        "unique-1-nopunct": 549,
        "entropy-1-nopunct": 8.05485528089015,
        "distinct-2-nopunct": 0.5086342229199372,
        "vocab_size-2-nopunct": 2592,
        "unique-2-nopunct": 1863,
        "entropy-2-nopunct": 10.571982380894745,
        "cond_entropy-2-nopunct": 2.6467102020594027,
        "distinct-3-nopunct": 0.7248205351316076,
        "vocab_size-3-nopunct": 3332,
        "unique-3-nopunct": 2793,
        "entropy-3-nopunct": 11.34563384078625,
        "cond_entropy-3-nopunct": 0.816806458441987,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "bleu": 31.8,
        "local_recall": {
            "1": 0.5527279065713788
        },
        "rouge1": {
            "precision": 0.5775,
            "recall": 0.54228,
            "fmeasure": 0.54821
        },
        "rouge2": {
            "precision": 0.36055,
            "recall": 0.3336,
            "fmeasure": 0.33917
        },
        "rougeL": {
            "precision": 0.52195,
            "recall": 0.48727,
            "fmeasure": 0.49396
        },
        "rougeLsum": {
            "precision": 0.52195,
            "recall": 0.48727,
            "fmeasure": 0.49396
        },
        "nist": 6.121909294826259,
        "bleurt": -0.1078,
        "bertscore": {
            "precision": 0.87163,
            "recall": 0.86261,
            "f1": 0.86659
        },
        "nubia": {
            "semantic_relation": 3.62412,
            "contradiction": 5.26196,
            "irrelevancy": 22.39271,
            "logical_agreement": 72.34533,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.67461,
            "nubia_score": 0.64065
        },
        "meteor": 0.3121090489152373
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72156,
        "msttr-100_nopunct": 0.76194,
        "total_length": 7723,
        "mean_pred_length": 21.512534818941504,
        "std_pred_length": 9.55349891325458,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.35374854331218436,
        "vocab_size-1": 2732,
        "unique-1": 1994,
        "entropy-1": 9.124634549184902,
        "distinct-2": 0.8155893536121673,
        "vocab_size-2": 6006,
        "unique-2": 5557,
        "entropy-2": 12.143242720581648,
        "cond_entropy-2": 2.776419083029817,
        "distinct-3": 0.9481798715203427,
        "vocab_size-3": 6642,
        "unique-3": 6504,
        "entropy-3": 12.56742354298717,
        "cond_entropy-3": 0.4432893017890854,
        "total_length-nopunct": 6792,
        "mean_pred_length-nopunct": 18.919220055710305,
        "std_pred_length-nopunct": 8.22365928851851,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4004711425206125,
        "vocab_size-1-nopunct": 2720,
        "unique-1-nopunct": 1991,
        "entropy-1-nopunct": 9.504696468726728,
        "distinct-2-nopunct": 0.8440851857609203,
        "vocab_size-2-nopunct": 5430,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.092331158621885,
        "cond_entropy-2-nopunct": 2.716657921518432,
        "distinct-3-nopunct": 0.9705301284162002,
        "vocab_size-3-nopunct": 5895,
        "unique-3-nopunct": 5792,
        "entropy-3-nopunct": 12.487194869687839,
        "cond_entropy-3-nopunct": 0.4221573916938865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.82119,
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.16711590296495957,
            "3": 0.3710843373493976,
            "4": 0.5626911314984709,
            "5": 0.6828528072837633,
            "6": 0.7971830985915493,
            "7": 0.8688524590163934,
            "8": 0.9071170084439083,
            "9": 0.926984126984127,
            "10": 0.9635658914728682
        },
        "rouge1": {
            "precision": 0.87923,
            "recall": 0.88301,
            "fmeasure": 0.87481
        },
        "rouge2": {
            "precision": 0.76929,
            "recall": 0.78066,
            "fmeasure": 0.76709
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "nist": 12.709964093712534,
        "bleurt": 0.2121,
        "bertscore": {
            "precision": 0.96314,
            "recall": 0.97071,
            "f1": 0.96417
        },
        "nubia": {
            "semantic_relation": 4.27732,
            "contradiction": 2.99509,
            "irrelevancy": 35.42939,
            "logical_agreement": 61.57552,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.73338,
            "nubia_score": 0.65371
        },
        "meteor": 0.5229674536458527
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.56743,
        "msttr-100_nopunct": 0.64459,
        "total_length": 352128,
        "mean_pred_length": 31.117709437963946,
        "std_pred_length": 16.759251179300964,
        "median_pred_length": 28.0,
        "min_pred_length": 2,
        "max_pred_length": 128,
        "distinct-1": 0.039230052708106145,
        "vocab_size-1": 13814,
        "unique-1": 5117,
        "entropy-1": 8.899278655450354,
        "distinct-2": 0.2484096804103142,
        "vocab_size-2": 84661,
        "unique-2": 53897,
        "entropy-2": 14.151320741324062,
        "cond_entropy-2": 5.054147375793211,
        "distinct-3": 0.5693756525117148,
        "vocab_size-3": 187607,
        "unique-3": 149183,
        "entropy-3": 16.591943510435346,
        "cond_entropy-3": 2.442155016044688,
        "total_length-nopunct": 295918,
        "mean_pred_length-nopunct": 26.150406504065042,
        "std_pred_length-nopunct": 14.945080349868404,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 118,
        "distinct-1-nopunct": 0.04660750613345589,
        "vocab_size-1-nopunct": 13792,
        "unique-1-nopunct": 5114,
        "entropy-1-nopunct": 9.775670733274755,
        "distinct-2-nopunct": 0.37247805707619763,
        "vocab_size-2-nopunct": 106008,
        "unique-2-nopunct": 76061,
        "entropy-2-nopunct": 14.92195707054281,
        "cond_entropy-2-nopunct": 5.2664155449932855,
        "distinct-3-nopunct": 0.7064697552389978,
        "vocab_size-3-nopunct": 193069,
        "unique-3-nopunct": 164582,
        "entropy-3-nopunct": 17.04917714290321,
        "cond_entropy-3-nopunct": 2.1686640862963458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "bleu": 14.74014,
        "local_recall": {
            "1": 0.35224766397406193
        },
        "rouge1": {
            "precision": 0.50127,
            "recall": 0.40251,
            "fmeasure": 0.42508
        },
        "rouge2": {
            "precision": 0.22032,
            "recall": 0.1788,
            "fmeasure": 0.18814
        },
        "rougeL": {
            "precision": 0.42901,
            "recall": 0.34663,
            "fmeasure": 0.36491
        },
        "rougeLsum": {
            "precision": 0.42901,
            "recall": 0.34663,
            "fmeasure": 0.36491
        },
        "nist": 4.706585461865509,
        "sari": 70.18366,
        "bleurt": -0.22626,
        "bertscore": {
            "precision": 0.87906,
            "recall": 0.85202,
            "f1": 0.86477
        },
        "nubia": {
            "semantic_relation": 3.17367,
            "contradiction": 11.20642,
            "irrelevancy": 37.92753,
            "logical_agreement": 50.86605,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.69304,
            "nubia_score": 0.47459
        },
        "meteor": 0.19692648699607374
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": 0.44,
        "msttr-100_nopunct": 0.47,
        "total_length": 142,
        "mean_pred_length": 47.333333333333336,
        "std_pred_length": 19.014614262602212,
        "median_pred_length": 37.0,
        "min_pred_length": 31,
        "max_pred_length": 74,
        "distinct-1": 0.4084507042253521,
        "vocab_size-1": 58,
        "unique-1": 43,
        "entropy-1": 4.28914434418837,
        "distinct-2": 0.7841726618705036,
        "vocab_size-2": 109,
        "unique-2": 91,
        "entropy-2": 6.599237252885194,
        "cond_entropy-2": 2.3574440477324154,
        "distinct-3": 0.9044117647058824,
        "vocab_size-3": 123,
        "unique-3": 113,
        "entropy-3": 6.8796344404673135,
        "cond_entropy-3": 0.291861242431517,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 42.666666666666664,
        "std_pred_length-nopunct": 16.579773487261182,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.4296875,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 4.117294428546538,
        "distinct-2-nopunct": 0.784,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.436672560762755,
        "cond_entropy-2-nopunct": 2.367883365925323,
        "distinct-3-nopunct": 0.8934426229508197,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.699059776034289,
        "cond_entropy-3-nopunct": 0.25420994208281555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 0.97678,
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.08333333333333333,
            "3": 0.10714285714285714
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 0.8640220963937975,
        "bleurt": -0.46055,
        "bertscore": {
            "precision": 0.86456,
            "recall": 0.88406,
            "f1": 0.87407
        },
        "nubia": {
            "semantic_relation": 3.21517,
            "contradiction": 33.50254,
            "irrelevancy": 17.61468,
            "logical_agreement": 48.88279,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.58961,
            "nubia_score": 0.11393
        },
        "meteor": 0.13371849809654693
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.44486,
        "msttr-100_nopunct": 0.44058,
        "total_length": 43239,
        "mean_pred_length": 43.85294117647059,
        "std_pred_length": 19.97939294535997,
        "median_pred_length": 42.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.055158537431485466,
        "vocab_size-1": 2385,
        "unique-1": 880,
        "entropy-1": 6.00333628223238,
        "distinct-2": 0.16292334272122688,
        "vocab_size-2": 6884,
        "unique-2": 3411,
        "entropy-2": 10.396850298716943,
        "cond_entropy-2": 4.387334966583086,
        "distinct-3": 0.31143528727554703,
        "vocab_size-3": 12852,
        "unique-3": 7651,
        "entropy-3": 12.220849743003665,
        "cond_entropy-3": 1.8659781870726766,
        "total_length-nopunct": 39852,
        "mean_pred_length-nopunct": 40.41784989858012,
        "std_pred_length-nopunct": 18.826253890228287,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.05959550336244103,
        "vocab_size-1-nopunct": 2375,
        "unique-1-nopunct": 879,
        "entropy-1-nopunct": 5.9146015637481915,
        "distinct-2-nopunct": 0.163073123038131,
        "vocab_size-2-nopunct": 6338,
        "unique-2-nopunct": 3173,
        "entropy-2-nopunct": 10.258344155332868,
        "cond_entropy-2-nopunct": 4.436428796385785,
        "distinct-3-nopunct": 0.3114836325237592,
        "vocab_size-3-nopunct": 11799,
        "unique-3-nopunct": 7139,
        "entropy-3-nopunct": 12.049847497437042,
        "cond_entropy-3-nopunct": 1.8311110025736692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.19986,
        "local_recall": {
            "1": 0.09325704944830404,
            "2": 0.18336189437607103,
            "3": 0.27501055297593924,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.46522,
            "recall": 0.44561,
            "fmeasure": 0.44825
        },
        "rouge2": {
            "precision": 0.24181,
            "recall": 0.23247,
            "fmeasure": 0.2329
        },
        "rougeL": {
            "precision": 0.44318,
            "recall": 0.42558,
            "fmeasure": 0.42734
        },
        "rougeLsum": {
            "precision": 0.44318,
            "recall": 0.42558,
            "fmeasure": 0.42734
        },
        "nist": 1.1767980015826676,
        "bleurt": -0.47405,
        "bertscore": {
            "precision": 0.86268,
            "recall": 0.87391,
            "f1": 0.8678
        },
        "nubia": {
            "semantic_relation": 3.31026,
            "contradiction": 32.98259,
            "irrelevancy": 17.34796,
            "logical_agreement": 49.66945,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.66514,
            "nubia_score": 0.16125
        },
        "meteor": 0.1326934169192191
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.53857,
        "msttr-100_nopunct": 0.54098,
        "total_length": 5603,
        "mean_pred_length": 18.865319865319865,
        "std_pred_length": 6.592162675182554,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.07353203640906657,
        "vocab_size-1": 412,
        "unique-1": 158,
        "entropy-1": 6.143508528698975,
        "distinct-2": 0.21353185073501696,
        "vocab_size-2": 1133,
        "unique-2": 572,
        "entropy-2": 8.757962294187493,
        "cond_entropy-2": 2.5229191776822617,
        "distinct-3": 0.3318027550409263,
        "vocab_size-3": 1662,
        "unique-3": 1019,
        "entropy-3": 9.451301594075014,
        "cond_entropy-3": 0.7122693484716157,
        "total_length-nopunct": 5149,
        "mean_pred_length-nopunct": 17.336700336700336,
        "std_pred_length-nopunct": 6.294225338666039,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.07923868712371335,
        "vocab_size-1-nopunct": 408,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 6.146415657268456,
        "distinct-2-nopunct": 0.21145919208573785,
        "vocab_size-2-nopunct": 1026,
        "unique-2-nopunct": 504,
        "entropy-2-nopunct": 8.641984508282004,
        "cond_entropy-2-nopunct": 2.6033180775135625,
        "distinct-3-nopunct": 0.33106476399560925,
        "vocab_size-3-nopunct": 1508,
        "unique-3-nopunct": 924,
        "entropy-3-nopunct": 9.328393723965487,
        "cond_entropy-3-nopunct": 0.7243776405709516,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 3.33372,
        "local_recall": {
            "1": 0.31302140007254264
        },
        "rouge1": {
            "precision": 0.47626,
            "recall": 0.49713,
            "fmeasure": 0.4687
        },
        "rouge2": {
            "precision": 0.26209,
            "recall": 0.27079,
            "fmeasure": 0.25675
        },
        "rougeL": {
            "precision": 0.41813,
            "recall": 0.43739,
            "fmeasure": 0.41245
        },
        "rougeLsum": {
            "precision": 0.41813,
            "recall": 0.43739,
            "fmeasure": 0.41245
        },
        "nist": 1.451130271775155,
        "bleurt": -0.70163,
        "bertscore": {
            "precision": 0.82254,
            "recall": 0.85317,
            "f1": 0.83732
        },
        "nubia": {
            "semantic_relation": 3.01326,
            "contradiction": 28.72916,
            "irrelevancy": 26.79635,
            "logical_agreement": 44.4745,
            "grammar_ref": 6.65825,
            "grammar_hyp": 5.97045,
            "nubia_score": 0.3214
        },
        "meteor": 0.14267526628498128
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.0,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.879506460812008,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.25533082133206014,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.0068905956085185596,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.80206,
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.38636363636363635
        },
        "rouge1": {
            "precision": 0.67619,
            "recall": 0.47963,
            "fmeasure": 0.55732
        },
        "rouge2": {
            "precision": 0.25714,
            "recall": 0.18678,
            "fmeasure": 0.2162
        },
        "rougeL": {
            "precision": 0.5873,
            "recall": 0.41972,
            "fmeasure": 0.48638
        },
        "rougeLsum": {
            "precision": 0.5873,
            "recall": 0.41972,
            "fmeasure": 0.48638
        },
        "nist": 1.7458927282711474,
        "bleurt": -0.08591,
        "bertscore": {
            "precision": 0.9009,
            "recall": 0.85585,
            "f1": 0.87622
        },
        "nubia": {
            "semantic_relation": 3.66218,
            "contradiction": 46.39822,
            "irrelevancy": 50.384,
            "logical_agreement": 3.21778,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.71231,
            "nubia_score": 0.42546
        },
        "meteor": 0.24139312048196906
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.72437,
        "msttr-100_nopunct": 0.77214,
        "total_length": 6474,
        "mean_pred_length": 18.03342618384401,
        "std_pred_length": 8.286579895657427,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.3894037689218412,
        "vocab_size-1": 2521,
        "unique-1": 1996,
        "entropy-1": 9.048034841591646,
        "distinct-2": 0.8228945216680295,
        "vocab_size-2": 5032,
        "unique-2": 4693,
        "entropy-2": 11.876763031418342,
        "cond_entropy-2": 2.526042314388257,
        "distinct-3": 0.9421473245309242,
        "vocab_size-3": 5423,
        "unique-3": 5313,
        "entropy-3": 12.238178920484026,
        "cond_entropy-3": 0.3913110771034561,
        "total_length-nopunct": 5693,
        "mean_pred_length-nopunct": 15.857938718662952,
        "std_pred_length-nopunct": 7.202165194915475,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4408923239065519,
        "vocab_size-1-nopunct": 2510,
        "unique-1-nopunct": 1992,
        "entropy-1-nopunct": 9.445853085904176,
        "distinct-2-nopunct": 0.8511436070491188,
        "vocab_size-2-nopunct": 4540,
        "unique-2-nopunct": 4262,
        "entropy-2-nopunct": 11.840293780597392,
        "cond_entropy-2-nopunct": 2.55446131346023,
        "distinct-3-nopunct": 0.9692462311557789,
        "vocab_size-3-nopunct": 4822,
        "unique-3-nopunct": 4737,
        "entropy-3-nopunct": 12.194243626310392,
        "cond_entropy-3-nopunct": 0.3864741986391428,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "bleu": 47.70488,
        "local_recall": {
            "1": 0.04695652173913043,
            "2": 0.13736263736263737,
            "3": 0.24970691676436108,
            "4": 0.34560906515580736,
            "5": 0.42363877822045154,
            "6": 0.5036945812807881,
            "7": 0.610730593607306,
            "8": 0.6904761904761905,
            "9": 0.7741007194244605
        },
        "rouge1": {
            "precision": 0.70702,
            "recall": 0.67586,
            "fmeasure": 0.68072
        },
        "rouge2": {
            "precision": 0.48778,
            "recall": 0.47012,
            "fmeasure": 0.46821
        },
        "rougeL": {
            "precision": 0.66522,
            "recall": 0.64263,
            "fmeasure": 0.64312
        },
        "rougeLsum": {
            "precision": 0.66522,
            "recall": 0.64263,
            "fmeasure": 0.64312
        },
        "nist": 9.437206298549446,
        "sari": 48.2993,
        "bleurt": -0.44595,
        "bertscore": {
            "precision": 0.8909,
            "recall": 0.91255,
            "f1": 0.89705
        },
        "nubia": {
            "semantic_relation": 3.66064,
            "contradiction": 9.21484,
            "irrelevancy": 27.98455,
            "logical_agreement": 62.80061,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.80259,
            "nubia_score": 0.44777
        },
        "meteor": 0.3459241927313264
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.54579,
        "msttr-100_nopunct": 0.54889,
        "total_length": 1971,
        "mean_pred_length": 22.91860465116279,
        "std_pred_length": 6.666848068561388,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.15423642820903094,
        "vocab_size-1": 304,
        "unique-1": 142,
        "entropy-1": 6.146066933546395,
        "distinct-2": 0.38885941644562333,
        "vocab_size-2": 733,
        "unique-2": 446,
        "entropy-2": 8.721809703398062,
        "cond_entropy-2": 2.494748987637319,
        "distinct-3": 0.5458588104502501,
        "vocab_size-3": 982,
        "unique-3": 709,
        "entropy-3": 9.34934806249732,
        "cond_entropy-3": 0.6270060939183697,
        "total_length-nopunct": 1817,
        "mean_pred_length-nopunct": 21.127906976744185,
        "std_pred_length-nopunct": 6.145137067042689,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.1651073197578426,
        "vocab_size-1-nopunct": 300,
        "unique-1-nopunct": 141,
        "entropy-1-nopunct": 6.147956310106747,
        "distinct-2-nopunct": 0.39399191218948587,
        "vocab_size-2-nopunct": 682,
        "unique-2-nopunct": 418,
        "entropy-2-nopunct": 8.616965156671968,
        "cond_entropy-2-nopunct": 2.534215700453052,
        "distinct-3-nopunct": 0.5574468085106383,
        "vocab_size-3-nopunct": 917,
        "unique-3-nopunct": 671,
        "entropy-3-nopunct": 9.259768105132002,
        "cond_entropy-3-nopunct": 0.628357335873275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 5.19788,
        "local_recall": {
            "1": 0.3026615969581749
        },
        "rouge1": {
            "precision": 0.55972,
            "recall": 0.46801,
            "fmeasure": 0.49985
        },
        "rouge2": {
            "precision": 0.28926,
            "recall": 0.24318,
            "fmeasure": 0.25847
        },
        "rougeL": {
            "precision": 0.46776,
            "recall": 0.39091,
            "fmeasure": 0.41752
        },
        "rougeLsum": {
            "precision": 0.46776,
            "recall": 0.39091,
            "fmeasure": 0.41752
        },
        "nist": 1.8315884024547529,
        "bleurt": -0.59714,
        "bertscore": {
            "precision": 0.83043,
            "recall": 0.8532,
            "f1": 0.84153
        },
        "nubia": {
            "semantic_relation": 2.78086,
            "contradiction": 25.82867,
            "irrelevancy": 22.81922,
            "logical_agreement": 51.35211,
            "grammar_ref": 6.22337,
            "grammar_hyp": 5.8156,
            "nubia_score": 0.44178
        },
        "meteor": 0.1340664036311862
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.535,
        "msttr-100_nopunct": 0.52,
        "total_length": 228,
        "mean_pred_length": 25.333333333333332,
        "std_pred_length": 5.577733510227171,
        "median_pred_length": 28.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.41228070175438597,
        "vocab_size-1": 94,
        "unique-1": 61,
        "entropy-1": 5.5561825676376,
        "distinct-2": 0.7579908675799086,
        "vocab_size-2": 166,
        "unique-2": 133,
        "entropy-2": 7.205069452429907,
        "cond_entropy-2": 1.6121793140423788,
        "distinct-3": 0.8809523809523809,
        "vocab_size-3": 185,
        "unique-3": 168,
        "entropy-3": 7.4450582556995375,
        "cond_entropy-3": 0.2417629507095393,
        "total_length-nopunct": 213,
        "mean_pred_length-nopunct": 23.666666666666668,
        "std_pred_length-nopunct": 5.557777333511022,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.431924882629108,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.504427001489303,
        "distinct-2-nopunct": 0.7647058823529411,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 7.117237199980413,
        "cond_entropy-2-nopunct": 1.6670873728471394,
        "distinct-3-nopunct": 0.8871794871794871,
        "vocab_size-3-nopunct": 173,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.3520767880531395,
        "cond_entropy-3-nopunct": 0.21643820744294998,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 6.09603,
        "local_recall": {
            "1": 0.3851851851851852
        },
        "rouge1": {
            "precision": 0.54684,
            "recall": 0.48506,
            "fmeasure": 0.50419
        },
        "rouge2": {
            "precision": 0.27685,
            "recall": 0.23975,
            "fmeasure": 0.25157
        },
        "rougeL": {
            "precision": 0.39197,
            "recall": 0.34371,
            "fmeasure": 0.3591
        },
        "rougeLsum": {
            "precision": 0.39197,
            "recall": 0.34371,
            "fmeasure": 0.3591
        },
        "nist": 1.639179430589707,
        "bleurt": -0.59592,
        "bertscore": {
            "precision": 0.83537,
            "recall": 0.86549,
            "f1": 0.85003
        },
        "nubia": {
            "semantic_relation": 3.10394,
            "contradiction": 21.70912,
            "irrelevancy": 28.70763,
            "logical_agreement": 49.58326,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.50498,
            "nubia_score": 0.47154
        },
        "meteor": 0.16875403661456287
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.85516,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "nist": 1.0600905711694244,
        "bleurt": -0.22976,
        "bertscore": {
            "precision": 0.79921,
            "recall": 0.78021,
            "f1": 0.78959
        },
        "nubia": {
            "semantic_relation": 2.27956,
            "contradiction": 0.98439,
            "irrelevancy": 92.54747,
            "logical_agreement": 6.46815,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.65186,
            "nubia_score": 0.24183
        },
        "meteor": 0.11611197449693993
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72367,
        "msttr-100_nopunct": 0.77814,
        "total_length": 4991,
        "mean_pred_length": 16.636666666666667,
        "std_pred_length": 6.091359089362205,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.37868162692847124,
        "vocab_size-1": 1890,
        "unique-1": 1464,
        "entropy-1": 8.804431785803962,
        "distinct-2": 0.7823491792794713,
        "vocab_size-2": 3670,
        "unique-2": 3266,
        "entropy-2": 11.498420036539162,
        "cond_entropy-2": 2.389721143298163,
        "distinct-3": 0.9364609428376224,
        "vocab_size-3": 4112,
        "unique-3": 3937,
        "entropy-3": 11.946096475169881,
        "cond_entropy-3": 0.43982469435420685,
        "total_length-nopunct": 4369,
        "mean_pred_length-nopunct": 14.563333333333333,
        "std_pred_length-nopunct": 5.5105343560211,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.43053330281528956,
        "vocab_size-1-nopunct": 1881,
        "unique-1-nopunct": 1461,
        "entropy-1-nopunct": 9.190504011690619,
        "distinct-2-nopunct": 0.8080609486360285,
        "vocab_size-2-nopunct": 3288,
        "unique-2-nopunct": 2982,
        "entropy-2-nopunct": 11.352724992005902,
        "cond_entropy-2-nopunct": 2.2678096395314076,
        "distinct-3-nopunct": 0.9498540726983284,
        "vocab_size-3-nopunct": 3580,
        "unique-3-nopunct": 3456,
        "entropy-3-nopunct": 11.759915135406365,
        "cond_entropy-3-nopunct": 0.43698555168145514,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.01746,
        "local_recall": {
            "1": 0.17969661610268378,
            "2": 0.4199743918053777,
            "3": 0.8207317073170731
        },
        "rouge1": {
            "precision": 0.77972,
            "recall": 0.77809,
            "fmeasure": 0.76971
        },
        "rouge2": {
            "precision": 0.54973,
            "recall": 0.55043,
            "fmeasure": 0.54264
        },
        "rougeL": {
            "precision": 0.66823,
            "recall": 0.67246,
            "fmeasure": 0.66198
        },
        "rougeLsum": {
            "precision": 0.66823,
            "recall": 0.67246,
            "fmeasure": 0.66198
        },
        "nist": 8.570244694821369,
        "bleurt": 0.37218,
        "bertscore": {
            "precision": 0.93693,
            "recall": 0.93757,
            "f1": 0.93578
        },
        "nubia": {
            "semantic_relation": 4.42869,
            "contradiction": 3.20554,
            "irrelevancy": 26.67282,
            "logical_agreement": 70.12164,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.79241,
            "nubia_score": 0.79935
        },
        "meteor": 0.4121914781032257
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.79,
        "total_length": 672,
        "mean_pred_length": 24.0,
        "std_pred_length": 10.155927192672127,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.5505952380952381,
        "vocab_size-1": 370,
        "unique-1": 299,
        "entropy-1": 7.709163481124124,
        "distinct-2": 0.90527950310559,
        "vocab_size-2": 583,
        "unique-2": 547,
        "entropy-2": 9.098428097970352,
        "cond_entropy-2": 1.243123739554845,
        "distinct-3": 0.9594155844155844,
        "vocab_size-3": 591,
        "unique-3": 575,
        "entropy-3": 9.170221697423159,
        "cond_entropy-3": 0.07424438816068574,
        "total_length-nopunct": 590,
        "mean_pred_length-nopunct": 21.071428571428573,
        "std_pred_length-nopunct": 8.06194132694996,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6169491525423729,
        "vocab_size-1-nopunct": 364,
        "unique-1-nopunct": 299,
        "entropy-1-nopunct": 7.86323634464867,
        "distinct-2-nopunct": 0.9359430604982206,
        "vocab_size-2-nopunct": 526,
        "unique-2-nopunct": 503,
        "entropy-2-nopunct": 8.979633226876345,
        "cond_entropy-2-nopunct": 1.1648266409214765,
        "distinct-3-nopunct": 0.9868913857677902,
        "vocab_size-3-nopunct": 527,
        "unique-3-nopunct": 520,
        "entropy-3-nopunct": 9.034478703223154,
        "cond_entropy-3-nopunct": 0.05921664978065564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 79.75034,
        "local_recall": {
            "1": 0.02697495183044316,
            "2": 0.13157894736842105,
            "3": 0.2894736842105263,
            "4": 0.5645161290322581,
            "5": 0.6451612903225806,
            "6": 0.6984126984126984,
            "7": 0.8888888888888888,
            "8": 0.8387096774193549,
            "9": 0.9181818181818182,
            "10": 0.9302325581395349
        },
        "rouge1": {
            "precision": 0.87164,
            "recall": 0.8646,
            "fmeasure": 0.86134
        },
        "rouge2": {
            "precision": 0.78318,
            "recall": 0.76365,
            "fmeasure": 0.76489
        },
        "rougeL": {
            "precision": 0.85758,
            "recall": 0.84983,
            "fmeasure": 0.84801
        },
        "rougeLsum": {
            "precision": 0.85758,
            "recall": 0.84983,
            "fmeasure": 0.84801
        },
        "nist": 9.569695367138552,
        "bleurt": 0.12302,
        "bertscore": {
            "precision": 0.9631,
            "recall": 0.96495,
            "f1": 0.96035
        },
        "nubia": {
            "semantic_relation": 4.1532,
            "contradiction": 5.14076,
            "irrelevancy": 35.02265,
            "logical_agreement": 59.83659,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.8045,
            "nubia_score": 0.63921
        },
        "meteor": 0.5267712839627409
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.17559,
        "local_recall": {
            "1": 0,
            "2": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.33333,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.21429,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.33333,
            "fmeasure": 0.41667
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.33333,
            "fmeasure": 0.41667
        },
        "nist": 0.6363230859009386,
        "bleurt": -1.16788,
        "bertscore": {
            "precision": 0.77635,
            "recall": 0.77248,
            "f1": 0.77441
        },
        "nubia": {
            "semantic_relation": 2.62454,
            "contradiction": 2.90397,
            "irrelevancy": 96.56254,
            "logical_agreement": 0.53349,
            "grammar_ref": 5.57252,
            "grammar_hyp": 7.17308,
            "nubia_score": 0.11392
        },
        "meteor": 0.1668714976497207
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.69964,
        "msttr-100_nopunct": 0.74245,
        "total_length": 5596,
        "mean_pred_length": 18.653333333333332,
        "std_pred_length": 8.047348769764003,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 91,
        "distinct-1": 0.3531093638313081,
        "vocab_size-1": 1976,
        "unique-1": 1561,
        "entropy-1": 8.58081433228407,
        "distinct-2": 0.7288519637462235,
        "vocab_size-2": 3860,
        "unique-2": 3419,
        "entropy-2": 11.374713219984333,
        "cond_entropy-2": 2.5464080177362267,
        "distinct-3": 0.8997197758206565,
        "vocab_size-3": 4495,
        "unique-3": 4244,
        "entropy-3": 12.013203454941422,
        "cond_entropy-3": 0.6408949068230804,
        "total_length-nopunct": 4918,
        "mean_pred_length-nopunct": 16.393333333333334,
        "std_pred_length-nopunct": 6.909796588097865,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.39934932899552666,
        "vocab_size-1-nopunct": 1964,
        "unique-1-nopunct": 1555,
        "entropy-1-nopunct": 8.903262552145176,
        "distinct-2-nopunct": 0.7466435686444348,
        "vocab_size-2-nopunct": 3448,
        "unique-2-nopunct": 3103,
        "entropy-2-nopunct": 11.211089450114265,
        "cond_entropy-2-nopunct": 2.436263250164595,
        "distinct-3-nopunct": 0.9099119962945809,
        "vocab_size-3-nopunct": 3929,
        "unique-3-nopunct": 3733,
        "entropy-3-nopunct": 11.830417640624526,
        "cond_entropy-3-nopunct": 0.6696628366347355,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.50601,
        "local_recall": {
            "1": 0.21906923950056753,
            "2": 0.3644067796610169,
            "3": 0.8087757313109426
        },
        "rouge1": {
            "precision": 0.77801,
            "recall": 0.77252,
            "fmeasure": 0.7663
        },
        "rouge2": {
            "precision": 0.53613,
            "recall": 0.5304,
            "fmeasure": 0.52705
        },
        "rougeL": {
            "precision": 0.65499,
            "recall": 0.65106,
            "fmeasure": 0.64519
        },
        "rougeLsum": {
            "precision": 0.65499,
            "recall": 0.65106,
            "fmeasure": 0.64519
        },
        "nist": 8.54394451982952,
        "bleurt": 0.31755,
        "bertscore": {
            "precision": 0.93423,
            "recall": 0.93397,
            "f1": 0.93278
        },
        "nubia": {
            "semantic_relation": 4.44364,
            "contradiction": 4.38256,
            "irrelevancy": 27.32437,
            "logical_agreement": 68.29307,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.88287,
            "nubia_score": 0.78425
        },
        "meteor": 0.4029278862064214
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.42,
        "msttr-100_nopunct": 0.41607,
        "total_length": 6127,
        "mean_pred_length": 52.81896551724138,
        "std_pred_length": 13.436054902523974,
        "median_pred_length": 53.0,
        "min_pred_length": 21,
        "max_pred_length": 79,
        "distinct-1": 0.11718622490615309,
        "vocab_size-1": 718,
        "unique-1": 328,
        "entropy-1": 5.448112945034875,
        "distinct-2": 0.28963566794210616,
        "vocab_size-2": 1741,
        "unique-2": 945,
        "entropy-2": 9.407209919331628,
        "cond_entropy-2": 3.9616106226111776,
        "distinct-3": 0.4897370653095844,
        "vocab_size-3": 2887,
        "unique-3": 1878,
        "entropy-3": 10.809572053650191,
        "cond_entropy-3": 1.4260333084048078,
        "total_length-nopunct": 5683,
        "mean_pred_length-nopunct": 48.991379310344826,
        "std_pred_length-nopunct": 12.995686081088317,
        "median_pred_length-nopunct": 48.5,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.12510997712475805,
        "vocab_size-1-nopunct": 711,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 5.322892259717073,
        "distinct-2-nopunct": 0.29064127896533143,
        "vocab_size-2-nopunct": 1618,
        "unique-2-nopunct": 872,
        "entropy-2-nopunct": 9.279078486061245,
        "cond_entropy-2-nopunct": 4.011592157353856,
        "distinct-3-nopunct": 0.4822968262704091,
        "vocab_size-3-nopunct": 2629,
        "unique-3-nopunct": 1709,
        "entropy-3-nopunct": 10.651835839248598,
        "cond_entropy-3-nopunct": 1.3956273707925415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 0.69805,
        "local_recall": {
            "1": 0.07826576576576577,
            "2": 0.17570754716981132,
            "3": 0.19484702093397746
        },
        "rouge1": {
            "precision": 0.13003,
            "recall": 0.133,
            "fmeasure": 0.12921
        },
        "rouge2": {
            "precision": 0.0626,
            "recall": 0.05686,
            "fmeasure": 0.05829
        },
        "rougeL": {
            "precision": 0.12482,
            "recall": 0.1278,
            "fmeasure": 0.12401
        },
        "rougeLsum": {
            "precision": 0.12482,
            "recall": 0.1278,
            "fmeasure": 0.12401
        },
        "nist": 0.79660081348218,
        "bleurt": -0.51712,
        "bertscore": {
            "precision": 0.85305,
            "recall": 0.86709,
            "f1": 0.85951
        },
        "nubia": {
            "semantic_relation": 3.32809,
            "contradiction": 32.78213,
            "irrelevancy": 16.39094,
            "logical_agreement": 50.82693,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.3819,
            "nubia_score": 0.14252
        },
        "meteor": 0.0917953989369313
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.62333,
        "msttr-100_nopunct": 0.685,
        "total_length": 313,
        "mean_pred_length": 31.3,
        "std_pred_length": 10.129659421717987,
        "median_pred_length": 34.0,
        "min_pred_length": 12,
        "max_pred_length": 49,
        "distinct-1": 0.5591054313099042,
        "vocab_size-1": 175,
        "unique-1": 138,
        "entropy-1": 6.770772053522064,
        "distinct-2": 0.8646864686468647,
        "vocab_size-2": 262,
        "unique-2": 235,
        "entropy-2": 7.929992950504028,
        "cond_entropy-2": 1.0997264645899827,
        "distinct-3": 0.9658703071672355,
        "vocab_size-3": 283,
        "unique-3": 274,
        "entropy-3": 8.123921060899548,
        "cond_entropy-3": 0.18838859786142828,
        "total_length-nopunct": 263,
        "mean_pred_length-nopunct": 26.3,
        "std_pred_length-nopunct": 7.975587752636166,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6501901140684411,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 138,
        "entropy-1-nopunct": 6.938432899584591,
        "distinct-2-nopunct": 0.9288537549407114,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 222,
        "entropy-2-nopunct": 7.8185285925818775,
        "cond_entropy-2-nopunct": 0.9041983424102507,
        "distinct-3-nopunct": 0.9753086419753086,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 231,
        "entropy-3-nopunct": 7.87542978755638,
        "cond_entropy-3-nopunct": 0.05955407489680748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.81653,
        "local_recall": {
            "1": 0.2328767123287671,
            "2": 0.5084745762711864,
            "3": 0.7054794520547946
        },
        "rouge1": {
            "precision": 0.69708,
            "recall": 0.65775,
            "fmeasure": 0.66654
        },
        "rouge2": {
            "precision": 0.48201,
            "recall": 0.47445,
            "fmeasure": 0.46792
        },
        "rougeL": {
            "precision": 0.53323,
            "recall": 0.50728,
            "fmeasure": 0.51274
        },
        "rougeLsum": {
            "precision": 0.53323,
            "recall": 0.50728,
            "fmeasure": 0.51274
        },
        "nist": 5.726775567744169,
        "bleurt": -0.02529,
        "bertscore": {
            "precision": 0.91131,
            "recall": 0.9017,
            "f1": 0.90416
        },
        "nubia": {
            "semantic_relation": 3.66178,
            "contradiction": 21.19163,
            "irrelevancy": 37.09732,
            "logical_agreement": 41.71105,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.40744,
            "nubia_score": 0.56401
        },
        "meteor": 0.3640864586899694
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72156,
        "msttr-100_nopunct": 0.76194,
        "total_length": 7723,
        "mean_pred_length": 21.512534818941504,
        "std_pred_length": 9.55349891325458,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.35374854331218436,
        "vocab_size-1": 2732,
        "unique-1": 1994,
        "entropy-1": 9.124634549184902,
        "distinct-2": 0.8155893536121673,
        "vocab_size-2": 6006,
        "unique-2": 5557,
        "entropy-2": 12.143242720581648,
        "cond_entropy-2": 2.776419083029817,
        "distinct-3": 0.9481798715203427,
        "vocab_size-3": 6642,
        "unique-3": 6504,
        "entropy-3": 12.56742354298717,
        "cond_entropy-3": 0.4432893017890854,
        "total_length-nopunct": 6792,
        "mean_pred_length-nopunct": 18.919220055710305,
        "std_pred_length-nopunct": 8.22365928851851,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4004711425206125,
        "vocab_size-1-nopunct": 2720,
        "unique-1-nopunct": 1991,
        "entropy-1-nopunct": 9.504696468726728,
        "distinct-2-nopunct": 0.8440851857609203,
        "vocab_size-2-nopunct": 5430,
        "unique-2-nopunct": 5068,
        "entropy-2-nopunct": 12.092331158621885,
        "cond_entropy-2-nopunct": 2.716657921518432,
        "distinct-3-nopunct": 0.9705301284162002,
        "vocab_size-3-nopunct": 5895,
        "unique-3-nopunct": 5792,
        "entropy-3-nopunct": 12.487194869687839,
        "cond_entropy-3-nopunct": 0.4221573916938865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.82119,
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.16711590296495957,
            "3": 0.3710843373493976,
            "4": 0.5626911314984709,
            "5": 0.6828528072837633,
            "6": 0.7971830985915493,
            "7": 0.8688524590163934,
            "8": 0.9071170084439083,
            "9": 0.926984126984127,
            "10": 0.9635658914728682
        },
        "rouge1": {
            "precision": 0.87923,
            "recall": 0.88301,
            "fmeasure": 0.87481
        },
        "rouge2": {
            "precision": 0.76929,
            "recall": 0.78066,
            "fmeasure": 0.76709
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.86837,
            "fmeasure": 0.85781
        },
        "nist": 12.709964093712534,
        "bleurt": 0.2121,
        "bertscore": {
            "precision": 0.96314,
            "recall": 0.97071,
            "f1": 0.96417
        },
        "nubia": {
            "semantic_relation": 4.27732,
            "contradiction": 2.99509,
            "irrelevancy": 35.42939,
            "logical_agreement": 61.57552,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.73338,
            "nubia_score": 0.65371
        },
        "meteor": 0.5229674536458527
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.70429,
        "msttr-100_nopunct": 0.75833,
        "total_length": 2105,
        "mean_pred_length": 16.4453125,
        "std_pred_length": 6.823452885258588,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.3857482185273159,
        "vocab_size-1": 812,
        "unique-1": 628,
        "entropy-1": 7.986684505748726,
        "distinct-2": 0.7779463834092059,
        "vocab_size-2": 1538,
        "unique-2": 1365,
        "entropy-2": 10.248229284659296,
        "cond_entropy-2": 2.005265908333061,
        "distinct-3": 0.9259058950784208,
        "vocab_size-3": 1712,
        "unique-3": 1631,
        "entropy-3": 10.656192216950181,
        "cond_entropy-3": 0.34020717724532873,
        "total_length-nopunct": 1840,
        "mean_pred_length-nopunct": 14.375,
        "std_pred_length-nopunct": 6.095592670118305,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.4364130434782609,
        "vocab_size-1-nopunct": 803,
        "unique-1-nopunct": 626,
        "entropy-1-nopunct": 8.268775788904458,
        "distinct-2-nopunct": 0.8084112149532711,
        "vocab_size-2-nopunct": 1384,
        "unique-2-nopunct": 1249,
        "entropy-2-nopunct": 10.144533884301838,
        "cond_entropy-2-nopunct": 1.8793661767248044,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 1496,
        "unique-3-nopunct": 1440,
        "entropy-3-nopunct": 10.49476216584159,
        "cond_entropy-3-nopunct": 0.32312155579916085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.92866,
        "local_recall": {
            "1": 0.16363636363636364,
            "2": 0.3222591362126246,
            "3": 0.7894380501015572
        },
        "rouge1": {
            "precision": 0.78599,
            "recall": 0.76129,
            "fmeasure": 0.76316
        },
        "rouge2": {
            "precision": 0.52943,
            "recall": 0.51972,
            "fmeasure": 0.5168
        },
        "rougeL": {
            "precision": 0.6715,
            "recall": 0.65683,
            "fmeasure": 0.65485
        },
        "rougeLsum": {
            "precision": 0.6715,
            "recall": 0.65683,
            "fmeasure": 0.65485
        },
        "nist": 7.435379532419107,
        "bleurt": 0.3554,
        "bertscore": {
            "precision": 0.93296,
            "recall": 0.93188,
            "f1": 0.93064
        },
        "nubia": {
            "semantic_relation": 4.42577,
            "contradiction": 5.14468,
            "irrelevancy": 26.81961,
            "logical_agreement": 68.03571,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.2242,
            "nubia_score": 0.81797
        },
        "meteor": 0.39347617306023197
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.7055,
        "msttr-100_nopunct": 0.75889,
        "total_length": 2079,
        "mean_pred_length": 16.2421875,
        "std_pred_length": 5.845332130413442,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.4213564213564214,
        "vocab_size-1": 876,
        "unique-1": 686,
        "entropy-1": 8.188520844056391,
        "distinct-2": 0.8339313172731933,
        "vocab_size-2": 1627,
        "unique-2": 1478,
        "entropy-2": 10.442001482217385,
        "cond_entropy-2": 1.9815169724772386,
        "distinct-3": 0.9643444871091608,
        "vocab_size-3": 1758,
        "unique-3": 1715,
        "entropy-3": 10.746663516383666,
        "cond_entropy-3": 0.2847228231829342,
        "total_length-nopunct": 1829,
        "mean_pred_length-nopunct": 14.2890625,
        "std_pred_length-nopunct": 5.307942668406824,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4762165117550574,
        "vocab_size-1-nopunct": 871,
        "unique-1-nopunct": 686,
        "entropy-1-nopunct": 8.50899461518521,
        "distinct-2-nopunct": 0.8518518518518519,
        "vocab_size-2-nopunct": 1449,
        "unique-2-nopunct": 1334,
        "entropy-2-nopunct": 10.291813128778355,
        "cond_entropy-2-nopunct": 1.851602668996668,
        "distinct-3-nopunct": 0.9732994278448824,
        "vocab_size-3-nopunct": 1531,
        "unique-3-nopunct": 1501,
        "entropy-3-nopunct": 10.55780959498764,
        "cond_entropy-3-nopunct": 0.27490107190180946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.75462,
        "local_recall": {
            "1": 0.2153392330383481,
            "2": 0.3020408163265306,
            "3": 0.8218623481781376
        },
        "rouge1": {
            "precision": 0.79322,
            "recall": 0.78339,
            "fmeasure": 0.7805
        },
        "rouge2": {
            "precision": 0.54909,
            "recall": 0.54462,
            "fmeasure": 0.54074
        },
        "rougeL": {
            "precision": 0.67701,
            "recall": 0.67195,
            "fmeasure": 0.6674
        },
        "rougeLsum": {
            "precision": 0.67701,
            "recall": 0.67195,
            "fmeasure": 0.6674
        },
        "nist": 7.926656526823146,
        "bleurt": 0.37791,
        "bertscore": {
            "precision": 0.93616,
            "recall": 0.9367,
            "f1": 0.9352
        },
        "nubia": {
            "semantic_relation": 4.48476,
            "contradiction": 3.31132,
            "irrelevancy": 24.58176,
            "logical_agreement": 72.10693,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.5875,
            "nubia_score": 0.82391
        },
        "meteor": 0.40990572696916694
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.44496,
        "msttr-100_nopunct": 0.44165,
        "total_length": 24459,
        "mean_pred_length": 38.098130841121495,
        "std_pred_length": 19.713161857001175,
        "median_pred_length": 34.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.07571854940921542,
        "vocab_size-1": 1852,
        "unique-1": 762,
        "entropy-1": 6.024104313688696,
        "distinct-2": 0.21199143468950749,
        "vocab_size-2": 5049,
        "unique-2": 2699,
        "entropy-2": 10.299128347861297,
        "cond_entropy-2": 4.259634835048834,
        "distinct-3": 0.37596548004314995,
        "vocab_size-3": 8713,
        "unique-3": 5481,
        "entropy-3": 11.93417475342818,
        "cond_entropy-3": 1.6771392412241983,
        "total_length-nopunct": 22484,
        "mean_pred_length-nopunct": 35.021806853582554,
        "std_pred_length-nopunct": 18.4768818551838,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.08196940046255115,
        "vocab_size-1-nopunct": 1843,
        "unique-1-nopunct": 760,
        "entropy-1-nopunct": 5.937062578229176,
        "distinct-2-nopunct": 0.21046607453529897,
        "vocab_size-2-nopunct": 4597,
        "unique-2-nopunct": 2449,
        "entropy-2-nopunct": 10.1427809374132,
        "cond_entropy-2-nopunct": 4.310303960271003,
        "distinct-3-nopunct": 0.37268867924528304,
        "vocab_size-3-nopunct": 7901,
        "unique-3-nopunct": 5007,
        "entropy-3-nopunct": 11.756347405955442,
        "cond_entropy-3-nopunct": 1.6524797631972765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.95026,
        "local_recall": {
            "1": 0.10057176367101597,
            "2": 0.20844686648501362,
            "3": 0.30685794261721483,
            "4": 0.19736842105263158,
            "5": 0.24242424242424243,
            "6": 0.18181818181818182,
            "7": 0.25
        },
        "rouge1": {
            "precision": 0.49593,
            "recall": 0.47167,
            "fmeasure": 0.47574
        },
        "rouge2": {
            "precision": 0.28691,
            "recall": 0.27359,
            "fmeasure": 0.27567
        },
        "rougeL": {
            "precision": 0.46604,
            "recall": 0.44416,
            "fmeasure": 0.44723
        },
        "rougeLsum": {
            "precision": 0.46604,
            "recall": 0.44416,
            "fmeasure": 0.44723
        },
        "nist": 1.351629310503546,
        "bleurt": -0.44582,
        "bertscore": {
            "precision": 0.86741,
            "recall": 0.87743,
            "f1": 0.87196
        },
        "nubia": {
            "semantic_relation": 3.31786,
            "contradiction": 33.24712,
            "irrelevancy": 17.24598,
            "logical_agreement": 49.50691,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.78639,
            "nubia_score": 0.17452
        },
        "meteor": 0.1498984798889368
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.67571,
        "msttr-100_nopunct": 0.70667,
        "total_length": 764,
        "mean_pred_length": 16.977777777777778,
        "std_pred_length": 5.401600128722718,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.45157068062827227,
        "vocab_size-1": 345,
        "unique-1": 261,
        "entropy-1": 7.238345111907018,
        "distinct-2": 0.8052851182197497,
        "vocab_size-2": 579,
        "unique-2": 509,
        "entropy-2": 8.923563731900117,
        "cond_entropy-2": 1.4878964751962345,
        "distinct-3": 0.9510385756676558,
        "vocab_size-3": 641,
        "unique-3": 614,
        "entropy-3": 9.291234528943487,
        "cond_entropy-3": 0.3765328375179941,
        "total_length-nopunct": 681,
        "mean_pred_length-nopunct": 15.133333333333333,
        "std_pred_length-nopunct": 5.298217729681474,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4977973568281938,
        "vocab_size-1-nopunct": 339,
        "unique-1-nopunct": 258,
        "entropy-1-nopunct": 7.397617355341433,
        "distinct-2-nopunct": 0.809748427672956,
        "vocab_size-2-nopunct": 515,
        "unique-2-nopunct": 456,
        "entropy-2-nopunct": 8.744826261355472,
        "cond_entropy-2-nopunct": 1.4113686151975589,
        "distinct-3-nopunct": 0.9526226734348562,
        "vocab_size-3-nopunct": 563,
        "unique-3-nopunct": 539,
        "entropy-3-nopunct": 9.107150445374264,
        "cond_entropy-3-nopunct": 0.398809042270566,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.15918,
        "local_recall": {
            "1": 0.17333333333333334,
            "2": 0.4765625,
            "3": 0.8319838056680162
        },
        "rouge1": {
            "precision": 0.79266,
            "recall": 0.78032,
            "fmeasure": 0.77471
        },
        "rouge2": {
            "precision": 0.55864,
            "recall": 0.55716,
            "fmeasure": 0.54868
        },
        "rougeL": {
            "precision": 0.66438,
            "recall": 0.65999,
            "fmeasure": 0.65122
        },
        "rougeLsum": {
            "precision": 0.66438,
            "recall": 0.65999,
            "fmeasure": 0.65122
        },
        "nist": 7.227645108655263,
        "bleurt": 0.36178,
        "bertscore": {
            "precision": 0.93899,
            "recall": 0.9396,
            "f1": 0.93885
        },
        "nubia": {
            "semantic_relation": 4.46141,
            "contradiction": 3.01017,
            "irrelevancy": 28.83169,
            "logical_agreement": 68.15815,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.79052,
            "nubia_score": 0.80458
        },
        "meteor": 0.4212917554524697
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.43193,
        "msttr-100_nopunct": 0.42439,
        "total_length": 24907,
        "mean_pred_length": 54.14565217391304,
        "std_pred_length": 15.063145443818357,
        "median_pred_length": 57.0,
        "min_pred_length": 11,
        "max_pred_length": 82,
        "distinct-1": 0.06616613803348456,
        "vocab_size-1": 1648,
        "unique-1": 614,
        "entropy-1": 5.759822088144265,
        "distinct-2": 0.18542152411338814,
        "vocab_size-2": 4533,
        "unique-2": 2236,
        "entropy-2": 10.05245077830943,
        "cond_entropy-2": 4.296901492336322,
        "distinct-3": 0.35144036353024555,
        "vocab_size-3": 8430,
        "unique-3": 5028,
        "entropy-3": 11.818099027101109,
        "cond_entropy-3": 1.7969381117279426,
        "total_length-nopunct": 23051,
        "mean_pred_length-nopunct": 50.11086956521739,
        "std_pred_length-nopunct": 14.483524797099777,
        "median_pred_length-nopunct": 52.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.07105982386881263,
        "vocab_size-1-nopunct": 1638,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 5.654214002315125,
        "distinct-2-nopunct": 0.18671152228763668,
        "vocab_size-2-nopunct": 4218,
        "unique-2-nopunct": 2084,
        "entropy-2-nopunct": 9.935894969983575,
        "cond_entropy-2-nopunct": 4.346509875403537,
        "distinct-3-nopunct": 0.351000858524242,
        "vocab_size-3-nopunct": 7768,
        "unique-3-nopunct": 4708,
        "entropy-3-nopunct": 11.660727208410433,
        "cond_entropy-3-nopunct": 1.7551515579275092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.014,
        "local_recall": {
            "1": 0.08261474269819194,
            "2": 0.1559633027522936,
            "3": 0.2187125149940024,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "rouge1": {
            "precision": 0.33783,
            "recall": 0.33041,
            "fmeasure": 0.32942
        },
        "rouge2": {
            "precision": 0.13367,
            "recall": 0.1308,
            "fmeasure": 0.12918
        },
        "rougeL": {
            "precision": 0.331,
            "recall": 0.32455,
            "fmeasure": 0.32308
        },
        "rougeLsum": {
            "precision": 0.331,
            "recall": 0.32455,
            "fmeasure": 0.32308
        },
        "nist": 0.8783834267146127,
        "bleurt": -0.5243,
        "bertscore": {
            "precision": 0.85365,
            "recall": 0.86728,
            "f1": 0.85989
        },
        "nubia": {
            "semantic_relation": 3.30415,
            "contradiction": 32.56285,
            "irrelevancy": 17.24896,
            "logical_agreement": 50.18819,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.4245,
            "nubia_score": 0.13802
        },
        "meteor": 0.10536952646151583
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.70962,
        "msttr-100_nopunct": 0.77136,
        "total_length": 2626,
        "mean_pred_length": 17.506666666666668,
        "std_pred_length": 6.089057580793782,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.41964965727341963,
        "vocab_size-1": 1102,
        "unique-1": 868,
        "entropy-1": 8.383544274168521,
        "distinct-2": 0.7992730210016155,
        "vocab_size-2": 1979,
        "unique-2": 1763,
        "entropy-2": 10.658251703694638,
        "cond_entropy-2": 2.0170108364059796,
        "distinct-3": 0.9307824591573517,
        "vocab_size-3": 2165,
        "unique-3": 2067,
        "entropy-3": 11.01636878672897,
        "cond_entropy-3": 0.3735621442423355,
        "total_length-nopunct": 2297,
        "mean_pred_length-nopunct": 15.313333333333333,
        "std_pred_length-nopunct": 5.446878820837571,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4767087505441881,
        "vocab_size-1-nopunct": 1095,
        "unique-1-nopunct": 867,
        "entropy-1-nopunct": 8.707841156036094,
        "distinct-2-nopunct": 0.8174196553330229,
        "vocab_size-2-nopunct": 1755,
        "unique-2-nopunct": 1601,
        "entropy-2-nopunct": 10.480575868535132,
        "cond_entropy-2-nopunct": 1.8737831036186328,
        "distinct-3-nopunct": 0.9459188783174762,
        "vocab_size-3-nopunct": 1889,
        "unique-3-nopunct": 1824,
        "entropy-3-nopunct": 10.830662571197497,
        "cond_entropy-3-nopunct": 0.37481930026034305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.93595,
        "local_recall": {
            "1": 0.2106430155210643,
            "2": 0.4864864864864865,
            "3": 0.8098510882016037
        },
        "rouge1": {
            "precision": 0.79823,
            "recall": 0.79117,
            "fmeasure": 0.78756
        },
        "rouge2": {
            "precision": 0.57381,
            "recall": 0.57304,
            "fmeasure": 0.56769
        },
        "rougeL": {
            "precision": 0.67939,
            "recall": 0.67754,
            "fmeasure": 0.67176
        },
        "rougeLsum": {
            "precision": 0.67939,
            "recall": 0.67754,
            "fmeasure": 0.67176
        },
        "nist": 8.316683818205865,
        "bleurt": 0.38335,
        "bertscore": {
            "precision": 0.94676,
            "recall": 0.9451,
            "f1": 0.94477
        },
        "nubia": {
            "semantic_relation": 4.53261,
            "contradiction": 5.11307,
            "irrelevancy": 24.01695,
            "logical_agreement": 70.86999,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.08067,
            "nubia_score": 0.81218
        },
        "meteor": 0.42096093418470953
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72333,
        "total_length": 417,
        "mean_pred_length": 29.785714285714285,
        "std_pred_length": 12.036721026144308,
        "median_pred_length": 30.0,
        "min_pred_length": 13,
        "max_pred_length": 53,
        "distinct-1": 0.5587529976019184,
        "vocab_size-1": 233,
        "unique-1": 191,
        "entropy-1": 7.003328333587146,
        "distinct-2": 0.8759305210918115,
        "vocab_size-2": 353,
        "unique-2": 325,
        "entropy-2": 8.344316797694326,
        "cond_entropy-2": 1.2611077032088913,
        "distinct-3": 0.9665809768637532,
        "vocab_size-3": 376,
        "unique-3": 364,
        "entropy-3": 8.534847713875319,
        "cond_entropy-3": 0.1894758563596003,
        "total_length-nopunct": 353,
        "mean_pred_length-nopunct": 25.214285714285715,
        "std_pred_length-nopunct": 9.733437004386856,
        "median_pred_length-nopunct": 26.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6430594900849859,
        "vocab_size-1-nopunct": 227,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 7.1519366836925675,
        "distinct-2-nopunct": 0.8938053097345132,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 282,
        "entropy-2-nopunct": 8.143212296412283,
        "cond_entropy-2-nopunct": 1.0348663653844856,
        "distinct-3-nopunct": 0.9692307692307692,
        "vocab_size-3-nopunct": 315,
        "unique-3-nopunct": 306,
        "entropy-3-nopunct": 8.280434715601432,
        "cond_entropy-3-nopunct": 0.14850552175580448,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.69654,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.5217391304347826,
            "3": 0.7203389830508474
        },
        "rouge1": {
            "precision": 0.68791,
            "recall": 0.71056,
            "fmeasure": 0.68976
        },
        "rouge2": {
            "precision": 0.42901,
            "recall": 0.45756,
            "fmeasure": 0.43753
        },
        "rougeL": {
            "precision": 0.57532,
            "recall": 0.60443,
            "fmeasure": 0.58247
        },
        "rougeLsum": {
            "precision": 0.57532,
            "recall": 0.60443,
            "fmeasure": 0.58247
        },
        "nist": 6.0294110145134825,
        "bleurt": 0.16866,
        "bertscore": {
            "precision": 0.91962,
            "recall": 0.91592,
            "f1": 0.91728
        },
        "nubia": {
            "semantic_relation": 3.66625,
            "contradiction": 22.51397,
            "irrelevancy": 22.57287,
            "logical_agreement": 54.91316,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.09556,
            "nubia_score": 0.60001
        },
        "meteor": 0.3739093301006834
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.6504,
        "msttr-100_nopunct": 0.68597,
        "total_length": 7542,
        "mean_pred_length": 35.40845070422535,
        "std_pred_length": 8.115789048021337,
        "median_pred_length": 35.0,
        "min_pred_length": 18,
        "max_pred_length": 67,
        "distinct-1": 0.13922036595067622,
        "vocab_size-1": 1050,
        "unique-1": 319,
        "entropy-1": 7.9504350002990645,
        "distinct-2": 0.39527902851685087,
        "vocab_size-2": 2897,
        "unique-2": 1564,
        "entropy-2": 10.787620803735438,
        "cond_entropy-2": 2.7227667515968377,
        "distinct-3": 0.5885328836424958,
        "vocab_size-3": 4188,
        "unique-3": 2885,
        "entropy-3": 11.642659866392076,
        "cond_entropy-3": 0.8786025685880401,
        "total_length-nopunct": 6742,
        "mean_pred_length-nopunct": 31.652582159624412,
        "std_pred_length-nopunct": 7.30627458162018,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.15440522100266982,
        "vocab_size-1-nopunct": 1041,
        "unique-1-nopunct": 318,
        "entropy-1-nopunct": 8.188709381189112,
        "distinct-2-nopunct": 0.4130801041507122,
        "vocab_size-2-nopunct": 2697,
        "unique-2-nopunct": 1510,
        "entropy-2-nopunct": 10.733983945806099,
        "cond_entropy-2-nopunct": 2.626544233309932,
        "distinct-3-nopunct": 0.6057631412286257,
        "vocab_size-3-nopunct": 3826,
        "unique-3-nopunct": 2693,
        "entropy-3-nopunct": 11.535062017429818,
        "cond_entropy-3-nopunct": 0.8185283973849236,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 45.01091,
        "local_recall": {
            "1": 0.22461005199306758,
            "2": 0.5315370483772198,
            "3": 0.8734505621216488
        },
        "rouge1": {
            "precision": 0.73563,
            "recall": 0.71405,
            "fmeasure": 0.71959
        },
        "rouge2": {
            "precision": 0.44684,
            "recall": 0.42912,
            "fmeasure": 0.43444
        },
        "rougeL": {
            "precision": 0.52958,
            "recall": 0.50872,
            "fmeasure": 0.51503
        },
        "rougeLsum": {
            "precision": 0.52958,
            "recall": 0.50872,
            "fmeasure": 0.51503
        },
        "nist": 8.471719047003068,
        "bleurt": 0.0927,
        "bertscore": {
            "precision": 0.90999,
            "recall": 0.90752,
            "f1": 0.90744
        },
        "nubia": {
            "semantic_relation": 4.3133,
            "contradiction": 7.14822,
            "irrelevancy": 7.60859,
            "logical_agreement": 85.24319,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.1769,
            "nubia_score": 0.75457
        },
        "meteor": 0.3674380647498589
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.6575,
        "msttr-100_nopunct": 0.68333,
        "total_length": 419,
        "mean_pred_length": 29.928571428571427,
        "std_pred_length": 10.312712582842913,
        "median_pred_length": 28.5,
        "min_pred_length": 14,
        "max_pred_length": 49,
        "distinct-1": 0.5513126491646778,
        "vocab_size-1": 231,
        "unique-1": 182,
        "entropy-1": 7.004554257594717,
        "distinct-2": 0.8790123456790123,
        "vocab_size-2": 356,
        "unique-2": 326,
        "entropy-2": 8.34700292874635,
        "cond_entropy-2": 1.2698179589458691,
        "distinct-3": 0.9616368286445013,
        "vocab_size-3": 376,
        "unique-3": 362,
        "entropy-3": 8.532367796023095,
        "cond_entropy-3": 0.19663558944124793,
        "total_length-nopunct": 368,
        "mean_pred_length-nopunct": 26.285714285714285,
        "std_pred_length-nopunct": 8.987519691443332,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6114130434782609,
        "vocab_size-1-nopunct": 225,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 7.096508259975379,
        "distinct-2-nopunct": 0.8898305084745762,
        "vocab_size-2-nopunct": 315,
        "unique-2-nopunct": 292,
        "entropy-2-nopunct": 8.171760759254717,
        "cond_entropy-2-nopunct": 1.1130880621167618,
        "distinct-3-nopunct": 0.961764705882353,
        "vocab_size-3-nopunct": 327,
        "unique-3-nopunct": 315,
        "entropy-3-nopunct": 8.330700090543083,
        "cond_entropy-3-nopunct": 0.16523882267540124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.66112,
        "local_recall": {
            "1": 0.30952380952380953,
            "2": 0.2647058823529412,
            "3": 0.6121673003802282
        },
        "rouge1": {
            "precision": 0.60414,
            "recall": 0.61731,
            "fmeasure": 0.59881
        },
        "rouge2": {
            "precision": 0.26529,
            "recall": 0.25629,
            "fmeasure": 0.25513
        },
        "rougeL": {
            "precision": 0.38448,
            "recall": 0.39517,
            "fmeasure": 0.38326
        },
        "rougeLsum": {
            "precision": 0.38448,
            "recall": 0.39517,
            "fmeasure": 0.38326
        },
        "nist": 4.704642930624851,
        "bleurt": -0.1156,
        "bertscore": {
            "precision": 0.87679,
            "recall": 0.86128,
            "f1": 0.86827
        },
        "nubia": {
            "semantic_relation": 3.57986,
            "contradiction": 17.05777,
            "irrelevancy": 29.1971,
            "logical_agreement": 53.74513,
            "grammar_ref": 3.91022,
            "grammar_hyp": 3.83531,
            "nubia_score": 0.57989
        },
        "meteor": 0.2676482962495938
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.51205,
        "msttr-100_nopunct": 0.52123,
        "total_length": 8300,
        "mean_pred_length": 33.06772908366534,
        "std_pred_length": 10.51802637887375,
        "median_pred_length": 31.0,
        "min_pred_length": 12,
        "max_pred_length": 67,
        "distinct-1": 0.11927710843373494,
        "vocab_size-1": 990,
        "unique-1": 275,
        "entropy-1": 7.911220024063562,
        "distinct-2": 0.34041495837992297,
        "vocab_size-2": 2740,
        "unique-2": 1344,
        "entropy-2": 10.652698175479896,
        "cond_entropy-2": 2.6206095829940224,
        "distinct-3": 0.5116696588868941,
        "vocab_size-3": 3990,
        "unique-3": 2526,
        "entropy-3": 11.468542910618199,
        "cond_entropy-3": 0.8430869076442162,
        "total_length-nopunct": 7358,
        "mean_pred_length-nopunct": 29.314741035856574,
        "std_pred_length-nopunct": 9.360026785589957,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.13332427290024462,
        "vocab_size-1-nopunct": 981,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 8.165127009202894,
        "distinct-2-nopunct": 0.35936400731672996,
        "vocab_size-2-nopunct": 2554,
        "unique-2-nopunct": 1330,
        "entropy-2-nopunct": 10.584883723215036,
        "cond_entropy-2-nopunct": 2.4996131027452506,
        "distinct-3-nopunct": 0.5315052508751459,
        "vocab_size-3-nopunct": 3644,
        "unique-3-nopunct": 2386,
        "entropy-3-nopunct": 11.355962775737686,
        "cond_entropy-3-nopunct": 0.7897969617143523,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.8476,
        "local_recall": {
            "1": 0.25008108984755106,
            "2": 0.6061611374407583,
            "3": 0.8742937853107344
        },
        "rouge1": {
            "precision": 0.754,
            "recall": 0.73076,
            "fmeasure": 0.7365
        },
        "rouge2": {
            "precision": 0.47075,
            "recall": 0.45448,
            "fmeasure": 0.45835
        },
        "rougeL": {
            "precision": 0.55114,
            "recall": 0.53607,
            "fmeasure": 0.53861
        },
        "rougeLsum": {
            "precision": 0.55114,
            "recall": 0.53607,
            "fmeasure": 0.53861
        },
        "nist": 8.485491321211827,
        "bleurt": 0.15051,
        "bertscore": {
            "precision": 0.91629,
            "recall": 0.91305,
            "f1": 0.91327
        },
        "nubia": {
            "semantic_relation": 4.35795,
            "contradiction": 7.59891,
            "irrelevancy": 7.04541,
            "logical_agreement": 85.35568,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.23122,
            "nubia_score": 0.76831
        },
        "meteor": 0.3792345222947462
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.7725,
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.71282,
            "fmeasure": 0.53737
        },
        "rouge2": {
            "precision": 0.24561,
            "recall": 0.40741,
            "fmeasure": 0.30568
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.71282,
            "fmeasure": 0.53737
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.71282,
            "fmeasure": 0.53737
        },
        "nist": 2.095410677101606,
        "bleurt": 0.28029,
        "bertscore": {
            "precision": 0.90111,
            "recall": 0.94419,
            "f1": 0.92214
        },
        "nubia": {
            "semantic_relation": 3.5067,
            "contradiction": 47.99174,
            "irrelevancy": 9.67307,
            "logical_agreement": 42.33519,
            "grammar_ref": 6.66832,
            "grammar_hyp": 4.7161,
            "nubia_score": 0.38928
        },
        "meteor": 0.40006497332048496
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.418157288156418,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.3334770520072988,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": 0.02160665417993861,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1523912776298655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.25454711376829503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.63327,
        "local_recall": {
            "1": 1.0,
            "2": 0.75,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.65152,
            "recall": 0.61,
            "fmeasure": 0.6285
        },
        "rouge2": {
            "precision": 0.26984,
            "recall": 0.25439,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.42667,
            "fmeasure": 0.43904
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.42667,
            "fmeasure": 0.43904
        },
        "nist": 3.141063334986778,
        "bleurt": -0.34234,
        "bertscore": {
            "precision": 0.87197,
            "recall": 0.88244,
            "f1": 0.87718
        },
        "nubia": {
            "semantic_relation": 3.24733,
            "contradiction": 12.84609,
            "irrelevancy": 72.79194,
            "logical_agreement": 14.36197,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.85772,
            "nubia_score": 0.48874
        },
        "meteor": 0.30570146254472924
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.46053,
        "msttr-100_nopunct": 0.46333,
        "total_length": 1966,
        "mean_pred_length": 67.79310344827586,
        "std_pred_length": 3.356715454796678,
        "median_pred_length": 68.0,
        "min_pred_length": 61,
        "max_pred_length": 75,
        "distinct-1": 0.17293997965412003,
        "vocab_size-1": 340,
        "unique-1": 169,
        "entropy-1": 5.242568949134508,
        "distinct-2": 0.38461538461538464,
        "vocab_size-2": 745,
        "unique-2": 419,
        "entropy-2": 8.69926028802881,
        "cond_entropy-2": 3.4605049963021792,
        "distinct-3": 0.5576519916142557,
        "vocab_size-3": 1064,
        "unique-3": 702,
        "entropy-3": 9.59803239943384,
        "cond_entropy-3": 0.9064280010804702,
        "total_length-nopunct": 1830,
        "mean_pred_length-nopunct": 63.10344827586207,
        "std_pred_length-nopunct": 3.23072349734392,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 58,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.1825136612021858,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 166,
        "entropy-1-nopunct": 5.1231967806614405,
        "distinct-2-nopunct": 0.3931149361465852,
        "vocab_size-2-nopunct": 708,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.640595858097209,
        "cond_entropy-2-nopunct": 3.527140263631355,
        "distinct-3-nopunct": 0.5637697516930023,
        "vocab_size-3-nopunct": 999,
        "unique-3-nopunct": 662,
        "entropy-3-nopunct": 9.518962701974822,
        "cond_entropy-3-nopunct": 0.8901140647511837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.22814,
        "local_recall": {
            "1": 0.07167832167832168,
            "2": 0.14823529411764705,
            "3": 0.21994134897360704
        },
        "rouge1": {
            "precision": 0.66724,
            "recall": 0.56231,
            "fmeasure": 0.58791
        },
        "rouge2": {
            "precision": 0.47126,
            "recall": 0.42277,
            "fmeasure": 0.42077
        },
        "rougeL": {
            "precision": 0.65881,
            "recall": 0.55508,
            "fmeasure": 0.5799
        },
        "rougeLsum": {
            "precision": 0.65881,
            "recall": 0.55508,
            "fmeasure": 0.5799
        },
        "nist": 1.074184983367327,
        "bleurt": -0.51797,
        "bertscore": {
            "precision": 0.86302,
            "recall": 0.86164,
            "f1": 0.8621
        },
        "nubia": {
            "semantic_relation": 3.16045,
            "contradiction": 35.75487,
            "irrelevancy": 21.39055,
            "logical_agreement": 42.85457,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.42571,
            "nubia_score": 0.17557
        },
        "meteor": 0.10398952842200741
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.53915,
        "msttr-100_nopunct": 0.54981,
        "total_length": 5936,
        "mean_pred_length": 37.56962025316456,
        "std_pred_length": 10.698022465199768,
        "median_pred_length": 36.0,
        "min_pred_length": 18,
        "max_pred_length": 75,
        "distinct-1": 0.1443733153638814,
        "vocab_size-1": 857,
        "unique-1": 233,
        "entropy-1": 7.808016216618399,
        "distinct-2": 0.38767739702319143,
        "vocab_size-2": 2240,
        "unique-2": 1180,
        "entropy-2": 10.434226147528076,
        "cond_entropy-2": 2.5222925858634984,
        "distinct-3": 0.5629893238434164,
        "vocab_size-3": 3164,
        "unique-3": 2144,
        "entropy-3": 11.182888229622215,
        "cond_entropy-3": 0.7683250303983022,
        "total_length-nopunct": 5308,
        "mean_pred_length-nopunct": 33.59493670886076,
        "std_pred_length-nopunct": 9.336221808323861,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.15957045968349662,
        "vocab_size-1-nopunct": 847,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 8.015489462743659,
        "distinct-2-nopunct": 0.4077669902912621,
        "vocab_size-2-nopunct": 2100,
        "unique-2-nopunct": 1162,
        "entropy-2-nopunct": 10.389251040904917,
        "cond_entropy-2-nopunct": 2.443202193777816,
        "distinct-3-nopunct": 0.5837339743589743,
        "vocab_size-3-nopunct": 2914,
        "unique-3-nopunct": 2038,
        "entropy-3-nopunct": 11.088972797732144,
        "cond_entropy-3-nopunct": 0.7150401809528624,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 45.2261,
        "local_recall": {
            "1": 0.23270440251572327,
            "2": 0.5274442538593482,
            "3": 0.8621669626998224
        },
        "rouge1": {
            "precision": 0.74176,
            "recall": 0.71362,
            "fmeasure": 0.72171
        },
        "rouge2": {
            "precision": 0.45664,
            "recall": 0.43258,
            "fmeasure": 0.4405
        },
        "rougeL": {
            "precision": 0.5276,
            "recall": 0.5035,
            "fmeasure": 0.51098
        },
        "rougeLsum": {
            "precision": 0.5276,
            "recall": 0.5035,
            "fmeasure": 0.51098
        },
        "nist": 8.160374429069059,
        "bleurt": 0.06338,
        "bertscore": {
            "precision": 0.90848,
            "recall": 0.90256,
            "f1": 0.90399
        },
        "nubia": {
            "semantic_relation": 4.23374,
            "contradiction": 6.78423,
            "irrelevancy": 7.84607,
            "logical_agreement": 85.36971,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.14874,
            "nubia_score": 0.74215
        },
        "meteor": 0.3600976287990204
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7156,
        "msttr-100_nopunct": 0.76591,
        "total_length": 2520,
        "mean_pred_length": 16.8,
        "std_pred_length": 6.7567250449706275,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.4103174603174603,
        "vocab_size-1": 1034,
        "unique-1": 802,
        "entropy-1": 8.26452410574024,
        "distinct-2": 0.8135021097046413,
        "vocab_size-2": 1928,
        "unique-2": 1734,
        "entropy-2": 10.614934459259546,
        "cond_entropy-2": 2.0849587853014806,
        "distinct-3": 0.9513513513513514,
        "vocab_size-3": 2112,
        "unique-3": 2035,
        "entropy-3": 11.00385622501527,
        "cond_entropy-3": 0.39181583589491337,
        "total_length-nopunct": 2214,
        "mean_pred_length-nopunct": 14.76,
        "std_pred_length-nopunct": 5.8852131085741775,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4643179765130985,
        "vocab_size-1-nopunct": 1028,
        "unique-1-nopunct": 801,
        "entropy-1-nopunct": 8.564220635060472,
        "distinct-2-nopunct": 0.8304263565891473,
        "vocab_size-2-nopunct": 1714,
        "unique-2-nopunct": 1569,
        "entropy-2-nopunct": 10.442621406140354,
        "cond_entropy-2-nopunct": 1.9827417837050616,
        "distinct-3-nopunct": 0.9608150470219435,
        "vocab_size-3-nopunct": 1839,
        "unique-3-nopunct": 1787,
        "entropy-3-nopunct": 10.81094683942845,
        "cond_entropy-3-nopunct": 0.3959504133264208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.56555,
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.4486486486486487,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.77367,
            "recall": 0.76419,
            "fmeasure": 0.76106
        },
        "rouge2": {
            "precision": 0.52838,
            "recall": 0.52773,
            "fmeasure": 0.52185
        },
        "rougeL": {
            "precision": 0.65256,
            "recall": 0.65236,
            "fmeasure": 0.6456
        },
        "rougeLsum": {
            "precision": 0.65256,
            "recall": 0.65236,
            "fmeasure": 0.6456
        },
        "nist": 8.10107240544429,
        "bleurt": 0.35304,
        "bertscore": {
            "precision": 0.93513,
            "recall": 0.93521,
            "f1": 0.93344
        },
        "nubia": {
            "semantic_relation": 4.46445,
            "contradiction": 4.10809,
            "irrelevancy": 25.29105,
            "logical_agreement": 70.60086,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.80172,
            "nubia_score": 0.80249
        },
        "meteor": 0.4075013378812956
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.46462,
        "msttr-100_nopunct": 0.4666,
        "total_length": 5206,
        "mean_pred_length": 20.57707509881423,
        "std_pred_length": 6.95261972850679,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.16769112562427968,
        "vocab_size-1": 873,
        "unique-1": 532,
        "entropy-1": 5.667829044315932,
        "distinct-2": 0.3912780133252574,
        "vocab_size-2": 1938,
        "unique-2": 1305,
        "entropy-2": 9.666165595211282,
        "cond_entropy-2": 3.9325158288259514,
        "distinct-3": 0.5865957446808511,
        "vocab_size-3": 2757,
        "unique-3": 2078,
        "entropy-3": 10.785795485815465,
        "cond_entropy-3": 1.1819318925429676,
        "total_length-nopunct": 4752,
        "mean_pred_length-nopunct": 18.782608695652176,
        "std_pred_length-nopunct": 6.812869557952752,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.18223905723905723,
        "vocab_size-1-nopunct": 866,
        "unique-1-nopunct": 531,
        "entropy-1-nopunct": 5.565955597360941,
        "distinct-2-nopunct": 0.37763947543898646,
        "vocab_size-2-nopunct": 1699,
        "unique-2-nopunct": 1117,
        "entropy-2-nopunct": 9.44383008936911,
        "cond_entropy-2-nopunct": 4.078276915992873,
        "distinct-3-nopunct": 0.5718323127649553,
        "vocab_size-3-nopunct": 2428,
        "unique-3-nopunct": 1814,
        "entropy-3-nopunct": 10.569733758006002,
        "cond_entropy-3-nopunct": 1.1921681723695905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 3.24208,
        "local_recall": {
            "1": 0.1098976109215017,
            "2": 0.1896792189679219,
            "3": 0.24573378839590443,
            "4": 0.22857142857142856,
            "5": 0.36363636363636365,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.3336,
            "recall": 0.33462,
            "fmeasure": 0.33221
        },
        "rouge2": {
            "precision": 0.19494,
            "recall": 0.18808,
            "fmeasure": 0.1901
        },
        "rougeL": {
            "precision": 0.33195,
            "recall": 0.33314,
            "fmeasure": 0.33066
        },
        "rougeLsum": {
            "precision": 0.33195,
            "recall": 0.33314,
            "fmeasure": 0.33066
        },
        "nist": 1.0581998852036711,
        "bleurt": -0.375,
        "bertscore": {
            "precision": 0.86967,
            "recall": 0.88054,
            "f1": 0.87465
        },
        "nubia": {
            "semantic_relation": 3.35284,
            "contradiction": 36.18703,
            "irrelevancy": 15.49285,
            "logical_agreement": 48.32011,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.99847,
            "nubia_score": 0.21033
        },
        "meteor": 0.1508028592622676
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.031262576450960075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.78711,
        "local_recall": {
            "1": 0.2,
            "2": 0.32142857142857145
        },
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.30238,
            "fmeasure": 0.38889
        },
        "rouge2": {
            "precision": 0.325,
            "recall": 0.17611,
            "fmeasure": 0.22799
        },
        "rougeL": {
            "precision": 0.45238,
            "recall": 0.25,
            "fmeasure": 0.32143
        },
        "rougeLsum": {
            "precision": 0.45238,
            "recall": 0.25,
            "fmeasure": 0.32143
        },
        "nist": 0.1498686256468975,
        "bleurt": -0.39509,
        "bertscore": {
            "precision": 0.85732,
            "recall": 0.70402,
            "f1": 0.77253
        },
        "nubia": {
            "semantic_relation": 2.7465,
            "contradiction": 4.39555,
            "irrelevancy": 84.31855,
            "logical_agreement": 11.2859,
            "grammar_ref": 3.72412,
            "grammar_hyp": 4.37491,
            "nubia_score": 0.17299
        },
        "meteor": 0.12984378414656017
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.54939,
        "msttr-100_nopunct": 0.56,
        "total_length": 3348,
        "mean_pred_length": 41.85,
        "std_pred_length": 8.934623663031363,
        "median_pred_length": 41.5,
        "min_pred_length": 21,
        "max_pred_length": 69,
        "distinct-1": 0.2078853046594982,
        "vocab_size-1": 696,
        "unique-1": 310,
        "entropy-1": 7.557901567280084,
        "distinct-2": 0.48745410036719705,
        "vocab_size-2": 1593,
        "unique-2": 1007,
        "entropy-2": 10.026213199924102,
        "cond_entropy-2": 2.3777224821876413,
        "distinct-3": 0.6700125470514429,
        "vocab_size-3": 2136,
        "unique-3": 1628,
        "entropy-3": 10.7206650536022,
        "cond_entropy-3": 0.715546325435515,
        "total_length-nopunct": 3011,
        "mean_pred_length-nopunct": 37.6375,
        "std_pred_length-nopunct": 8.515051012765573,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.22849551643972102,
        "vocab_size-1-nopunct": 688,
        "unique-1-nopunct": 308,
        "entropy-1-nopunct": 7.742425244066609,
        "distinct-2-nopunct": 0.5029000341180484,
        "vocab_size-2-nopunct": 1474,
        "unique-2-nopunct": 952,
        "entropy-2-nopunct": 9.973381835543943,
        "cond_entropy-2-nopunct": 2.2943663377149885,
        "distinct-3-nopunct": 0.6822167660470011,
        "vocab_size-3-nopunct": 1945,
        "unique-3-nopunct": 1502,
        "entropy-3-nopunct": 10.603814214002634,
        "cond_entropy-3-nopunct": 0.6458346919857946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 40.25891,
        "local_recall": {
            "1": 0.20485584218512898,
            "2": 0.5589812332439679,
            "3": 0.8441295546558705
        },
        "rouge1": {
            "precision": 0.73296,
            "recall": 0.69681,
            "fmeasure": 0.70964
        },
        "rouge2": {
            "precision": 0.41899,
            "recall": 0.39579,
            "fmeasure": 0.40369
        },
        "rougeL": {
            "precision": 0.49321,
            "recall": 0.47518,
            "fmeasure": 0.48057
        },
        "rougeLsum": {
            "precision": 0.49321,
            "recall": 0.47518,
            "fmeasure": 0.48057
        },
        "nist": 7.797497465216296,
        "bleurt": 0.05926,
        "bertscore": {
            "precision": 0.9018,
            "recall": 0.89373,
            "f1": 0.89651
        },
        "nubia": {
            "semantic_relation": 4.08774,
            "contradiction": 9.99596,
            "irrelevancy": 10.53508,
            "logical_agreement": 79.46896,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.09628,
            "nubia_score": 0.7098
        },
        "meteor": 0.33901070601533945
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 2.9494643027794045,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 1.5147563255163972,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.55,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 2.660964047443681,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 1.6743826263916775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.05403,
        "local_recall": {
            "1": 0.0,
            "2": 0.0
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 0.33362954558566477,
        "bleurt": -0.42313,
        "bertscore": {
            "precision": 0.84806,
            "recall": 0.86478,
            "f1": 0.85634
        },
        "nubia": {
            "semantic_relation": 3.50476,
            "contradiction": 28.24014,
            "irrelevancy": 13.74762,
            "logical_agreement": 58.01224,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.81614,
            "nubia_score": 0.22453
        },
        "meteor": 0.0489795918367347
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.57856,
        "msttr-100_nopunct": 0.65735,
        "total_length": 710113,
        "mean_pred_length": 31.37650229763167,
        "std_pred_length": 16.62766843908446,
        "median_pred_length": 28.0,
        "min_pred_length": 2,
        "max_pred_length": 128,
        "distinct-1": 0.027198488127945834,
        "vocab_size-1": 19314,
        "unique-1": 6984,
        "entropy-1": 9.006026580421137,
        "distinct-2": 0.2109192835874737,
        "vocab_size-2": 145003,
        "unique-2": 90973,
        "entropy-2": 14.526861525141419,
        "cond_entropy-2": 5.3202210799582375,
        "distinct-3": 0.527292663446888,
        "vocab_size-3": 350570,
        "unique-3": 273381,
        "entropy-3": 17.297687021622284,
        "cond_entropy-3": 2.7670929415901346,
        "total_length-nopunct": 596741,
        "mean_pred_length-nopunct": 26.367135030045954,
        "std_pred_length-nopunct": 14.763171762928812,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 119,
        "distinct-1-nopunct": 0.03232725755394719,
        "vocab_size-1-nopunct": 19291,
        "unique-1-nopunct": 6982,
        "entropy-1-nopunct": 9.896956973622945,
        "distinct-2-nopunct": 0.32899675845527593,
        "vocab_size-2-nopunct": 188880,
        "unique-2-nopunct": 132397,
        "entropy-2-nopunct": 15.427767466645644,
        "cond_entropy-2-nopunct": 5.651993632106944,
        "distinct-3-nopunct": 0.6730621725861816,
        "vocab_size-3-nopunct": 371181,
        "unique-3-nopunct": 312061,
        "entropy-3-nopunct": 17.879850694822732,
        "cond_entropy-3-nopunct": 2.4961833635234774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "bleu": 14.43807,
        "local_recall": {
            "1": 0.3505091938253985
        },
        "rouge1": {
            "precision": 0.49465,
            "recall": 0.39921,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.21319,
            "recall": 0.17351,
            "fmeasure": 0.1827
        },
        "rougeL": {
            "precision": 0.41955,
            "recall": 0.34033,
            "fmeasure": 0.35809
        },
        "rougeLsum": {
            "precision": 0.41955,
            "recall": 0.34033,
            "fmeasure": 0.35809
        },
        "nist": 4.723261755586661,
        "sari": 70.05886,
        "bleurt": -0.23849,
        "bertscore": {
            "precision": 0.87678,
            "recall": 0.85129,
            "f1": 0.86331
        },
        "nubia": {
            "semantic_relation": 3.14646,
            "contradiction": 11.62637,
            "irrelevancy": 38.00282,
            "logical_agreement": 50.37081,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.75233,
            "nubia_score": 0.46431
        },
        "meteor": 0.19455408594339238
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.45963,
        "msttr-100_nopunct": 0.4561,
        "total_length": 24299,
        "mean_pred_length": 49.188259109311744,
        "std_pred_length": 16.275679920922748,
        "median_pred_length": 48.0,
        "min_pred_length": 15,
        "max_pred_length": 89,
        "distinct-1": 0.07313058150541174,
        "vocab_size-1": 1777,
        "unique-1": 722,
        "entropy-1": 5.892184767371727,
        "distinct-2": 0.20474690191136316,
        "vocab_size-2": 4874,
        "unique-2": 2586,
        "entropy-2": 10.156760672330508,
        "cond_entropy-2": 4.263386404781512,
        "distinct-3": 0.3781047574106645,
        "vocab_size-3": 8814,
        "unique-3": 5575,
        "entropy-3": 11.902697540784294,
        "cond_entropy-3": 1.7819159794225148,
        "total_length-nopunct": 22380,
        "mean_pred_length-nopunct": 45.30364372469636,
        "std_pred_length-nopunct": 15.425572479438552,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.07899910634495085,
        "vocab_size-1-nopunct": 1768,
        "unique-1-nopunct": 721,
        "entropy-1-nopunct": 5.794248121589201,
        "distinct-2-nopunct": 0.20679886685552407,
        "vocab_size-2-nopunct": 4526,
        "unique-2-nopunct": 2425,
        "entropy-2-nopunct": 10.017656116101051,
        "cond_entropy-2-nopunct": 4.301075511002291,
        "distinct-3-nopunct": 0.37841249065071053,
        "vocab_size-3-nopunct": 8095,
        "unique-3-nopunct": 5210,
        "entropy-3-nopunct": 11.72835371961527,
        "cond_entropy-3-nopunct": 1.7463958974822857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.11454,
        "local_recall": {
            "1": 0.08924611973392461,
            "2": 0.18588992974238877,
            "3": 0.2800147765053565,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "rouge1": {
            "precision": 0.39473,
            "recall": 0.36668,
            "fmeasure": 0.37225
        },
        "rouge2": {
            "precision": 0.18728,
            "recall": 0.17701,
            "fmeasure": 0.17796
        },
        "rougeL": {
            "precision": 0.36665,
            "recall": 0.34205,
            "fmeasure": 0.34609
        },
        "rougeLsum": {
            "precision": 0.36665,
            "recall": 0.34205,
            "fmeasure": 0.34609
        },
        "nist": 1.1307262215310736,
        "bleurt": -0.51456,
        "bertscore": {
            "precision": 0.85856,
            "recall": 0.87106,
            "f1": 0.86428
        },
        "nubia": {
            "semantic_relation": 3.30587,
            "contradiction": 31.91846,
            "irrelevancy": 17.50465,
            "logical_agreement": 50.57689,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.55877,
            "nubia_score": 0.14929
        },
        "meteor": 0.13128348169801463
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.70478,
        "msttr-100_nopunct": 0.75068,
        "total_length": 6770,
        "mean_pred_length": 18.857938718662954,
        "std_pred_length": 8.43981723565001,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.3457902511078287,
        "vocab_size-1": 2341,
        "unique-1": 1695,
        "entropy-1": 8.920884313521853,
        "distinct-2": 0.7948837934799563,
        "vocab_size-2": 5096,
        "unique-2": 4630,
        "entropy-2": 11.852263119534882,
        "cond_entropy-2": 2.6501317504881983,
        "distinct-3": 0.929279576999339,
        "vocab_size-3": 5624,
        "unique-3": 5467,
        "entropy-3": 12.259550041140582,
        "cond_entropy-3": 0.4363312491001904,
        "total_length-nopunct": 5944,
        "mean_pred_length-nopunct": 16.55710306406685,
        "std_pred_length-nopunct": 7.276967784141902,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.3921601615074024,
        "vocab_size-1-nopunct": 2331,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.300283937266359,
        "distinct-2-nopunct": 0.8270367054610565,
        "vocab_size-2-nopunct": 4619,
        "unique-2-nopunct": 4234,
        "entropy-2-nopunct": 11.840849193629444,
        "cond_entropy-2-nopunct": 2.6918554908235937,
        "distinct-3-nopunct": 0.9600076540375048,
        "vocab_size-3-nopunct": 5017,
        "unique-3-nopunct": 4890,
        "entropy-3-nopunct": 12.245442389978551,
        "cond_entropy-3-nopunct": 0.4372658054690704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "bleu": 61.40482,
        "local_recall": {
            "1": 0.04830917874396135,
            "2": 0.15796703296703296,
            "3": 0.2813599062133646,
            "4": 0.39943342776203966,
            "5": 0.50066401062417,
            "6": 0.5862068965517241,
            "7": 0.7123287671232876,
            "8": 0.7966269841269841,
            "9": 0.9028776978417267
        },
        "rouge1": {
            "precision": 0.78831,
            "recall": 0.7632,
            "fmeasure": 0.76527
        },
        "rouge2": {
            "precision": 0.60793,
            "recall": 0.58841,
            "fmeasure": 0.58682
        },
        "rougeL": {
            "precision": 0.74385,
            "recall": 0.72491,
            "fmeasure": 0.72369
        },
        "rougeLsum": {
            "precision": 0.74385,
            "recall": 0.72491,
            "fmeasure": 0.72369
        },
        "nist": 10.961840705978531,
        "sari": 47.75066,
        "bleurt": 0.04104,
        "bertscore": {
            "precision": 0.9373,
            "recall": 0.94075,
            "f1": 0.93476
        },
        "nubia": {
            "semantic_relation": 4.02492,
            "contradiction": 4.04775,
            "irrelevancy": 29.25292,
            "logical_agreement": 66.69933,
            "grammar_ref": 4.57404,
            "grammar_hyp": 4.9858,
            "nubia_score": 0.58212
        },
        "meteor": 0.4196290913707113
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.59571,
        "msttr-100_nopunct": 0.67063,
        "total_length": 16849,
        "mean_pred_length": 37.525612472160354,
        "std_pred_length": 19.553362281663315,
        "median_pred_length": 35.0,
        "min_pred_length": 3,
        "max_pred_length": 118,
        "distinct-1": 0.15377767226541633,
        "vocab_size-1": 2591,
        "unique-1": 1216,
        "entropy-1": 8.372325583205061,
        "distinct-2": 0.510060975609756,
        "vocab_size-2": 8365,
        "unique-2": 5857,
        "entropy-2": 12.162196447029201,
        "cond_entropy-2": 3.6476039067615758,
        "distinct-3": 0.7547489185630994,
        "vocab_size-3": 12039,
        "unique-3": 9899,
        "entropy-3": 13.279671299088752,
        "cond_entropy-3": 1.1261289329650428,
        "total_length-nopunct": 14208,
        "mean_pred_length-nopunct": 31.643652561247215,
        "std_pred_length-nopunct": 16.956973219860426,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 101,
        "distinct-1-nopunct": 0.18144707207207209,
        "vocab_size-1-nopunct": 2578,
        "unique-1-nopunct": 1212,
        "entropy-1-nopunct": 9.090166886377652,
        "distinct-2-nopunct": 0.6105821644014827,
        "vocab_size-2-nopunct": 8401,
        "unique-2-nopunct": 6322,
        "entropy-2-nopunct": 12.46670413563366,
        "cond_entropy-2-nopunct": 3.451803586686516,
        "distinct-3-nopunct": 0.832381667918858,
        "vocab_size-3-nopunct": 11079,
        "unique-3-nopunct": 9509,
        "entropy-3-nopunct": 13.295684014863273,
        "cond_entropy-3-nopunct": 0.8433398887102413,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "bleu": 14.52611,
        "local_recall": {
            "1": 0.286976911976912
        },
        "rouge1": {
            "precision": 0.31836,
            "recall": 0.31444,
            "fmeasure": 0.29351
        },
        "rouge2": {
            "precision": 0.12623,
            "recall": 0.13007,
            "fmeasure": 0.11991
        },
        "rougeL": {
            "precision": 0.26071,
            "recall": 0.25745,
            "fmeasure": 0.23991
        },
        "rougeLsum": {
            "precision": 0.26071,
            "recall": 0.25745,
            "fmeasure": 0.23991
        },
        "nist": 3.2736074186284836,
        "sari": 67.30729,
        "bleurt": -0.58827,
        "bertscore": {
            "precision": 0.82406,
            "recall": 0.8192,
            "f1": 0.82107
        },
        "nubia": {
            "semantic_relation": 2.27427,
            "contradiction": 23.89909,
            "irrelevancy": 52.76299,
            "logical_agreement": 23.33792,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.80069,
            "nubia_score": 0.27115
        },
        "meteor": 0.1540766429583817
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.57353,
        "msttr-100_nopunct": 0.58,
        "total_length": 1705,
        "mean_pred_length": 41.58536585365854,
        "std_pred_length": 7.328446445541885,
        "median_pred_length": 42.0,
        "min_pred_length": 27,
        "max_pred_length": 54,
        "distinct-1": 0.28269794721407626,
        "vocab_size-1": 482,
        "unique-1": 255,
        "entropy-1": 7.398906647355446,
        "distinct-2": 0.5841346153846154,
        "vocab_size-2": 972,
        "unique-2": 673,
        "entropy-2": 9.519241896385806,
        "cond_entropy-2": 2.0332665416602493,
        "distinct-3": 0.7319778188539742,
        "vocab_size-3": 1188,
        "unique-3": 947,
        "entropy-3": 9.985597429665672,
        "cond_entropy-3": 0.4778388657378916,
        "total_length-nopunct": 1536,
        "mean_pred_length-nopunct": 37.46341463414634,
        "std_pred_length-nopunct": 7.288807192640862,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3098958333333333,
        "vocab_size-1-nopunct": 476,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.566613128250632,
        "distinct-2-nopunct": 0.6060200668896321,
        "vocab_size-2-nopunct": 906,
        "unique-2-nopunct": 638,
        "entropy-2-nopunct": 9.470611497641471,
        "cond_entropy-2-nopunct": 1.9543141342497703,
        "distinct-3-nopunct": 0.7475928473177441,
        "vocab_size-3-nopunct": 1087,
        "unique-3-nopunct": 881,
        "entropy-3-nopunct": 9.87798249679922,
        "cond_entropy-3-nopunct": 0.4199544840383495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 43.92976,
        "local_recall": {
            "1": 0.22356495468277945,
            "2": 0.45918367346938777,
            "3": 0.8187919463087249
        },
        "rouge1": {
            "precision": 0.7627,
            "recall": 0.67589,
            "fmeasure": 0.71278
        },
        "rouge2": {
            "precision": 0.45464,
            "recall": 0.40226,
            "fmeasure": 0.42419
        },
        "rougeL": {
            "precision": 0.52371,
            "recall": 0.45981,
            "fmeasure": 0.48685
        },
        "rougeLsum": {
            "precision": 0.52371,
            "recall": 0.45981,
            "fmeasure": 0.48685
        },
        "nist": 7.348041943419755,
        "bleurt": 0.0694,
        "bertscore": {
            "precision": 0.91217,
            "recall": 0.89351,
            "f1": 0.90129
        },
        "nubia": {
            "semantic_relation": 4.0579,
            "contradiction": 10.45341,
            "irrelevancy": 8.78298,
            "logical_agreement": 80.76361,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.00808,
            "nubia_score": 0.70347
        },
        "meteor": 0.33970133718691814
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 1.0,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 18,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 23,
        "unique-1": 12,
        "entropy-1": 4.440404017720928,
        "distinct-2": 0.78125,
        "vocab_size-2": 25,
        "unique-2": 18,
        "entropy-2": 4.5625,
        "cond_entropy-2": 0.1000371587496606,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 25,
        "unique-3": 20,
        "entropy-3": 4.573557262275186,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6774193548387096,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.309035020064295,
        "distinct-2-nopunct": 0.7586206896551724,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.375222374437917,
        "cond_entropy-2-nopunct": 0.11068123646483496,
        "distinct-3-nopunct": 0.8148148148148148,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.384517131793101,
        "cond_entropy-3-nopunct": 0.04505465518404472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.06364,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.6333333333333333
        },
        "rouge1": {
            "precision": 0.88585,
            "recall": 0.68839,
            "fmeasure": 0.77052
        },
        "rouge2": {
            "precision": 0.61779,
            "recall": 0.47251,
            "fmeasure": 0.53202
        },
        "rougeL": {
            "precision": 0.67297,
            "recall": 0.513,
            "fmeasure": 0.57899
        },
        "rougeLsum": {
            "precision": 0.67297,
            "recall": 0.513,
            "fmeasure": 0.57899
        },
        "nist": 3.5991244704210916,
        "bleurt": 0.01967,
        "bertscore": {
            "precision": 0.9491,
            "recall": 0.88911,
            "f1": 0.91764
        },
        "nubia": {
            "semantic_relation": 3.90178,
            "contradiction": 0.37088,
            "irrelevancy": 43.11517,
            "logical_agreement": 56.51395,
            "grammar_ref": 4.80653,
            "grammar_hyp": 5.7868,
            "nubia_score": 0.53185
        },
        "meteor": 0.3797124197466559
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7137,
        "msttr-100_nopunct": 0.77261,
        "total_length": 2706,
        "mean_pred_length": 18.04,
        "std_pred_length": 6.689175335320989,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.41426459719142644,
        "vocab_size-1": 1121,
        "unique-1": 859,
        "entropy-1": 8.369288563735628,
        "distinct-2": 0.8114241001564946,
        "vocab_size-2": 2074,
        "unique-2": 1878,
        "entropy-2": 10.728368279689565,
        "cond_entropy-2": 2.1111495350587077,
        "distinct-3": 0.9517871986699917,
        "vocab_size-3": 2290,
        "unique-3": 2214,
        "entropy-3": 11.119631436359782,
        "cond_entropy-3": 0.3722138946024831,
        "total_length-nopunct": 2325,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.660094227719771,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.4778494623655914,
        "vocab_size-1-nopunct": 1111,
        "unique-1-nopunct": 857,
        "entropy-1-nopunct": 8.725043903879628,
        "distinct-2-nopunct": 0.8418390804597701,
        "vocab_size-2-nopunct": 1831,
        "unique-2-nopunct": 1692,
        "entropy-2-nopunct": 10.57726487331388,
        "cond_entropy-2-nopunct": 1.936654894315456,
        "distinct-3-nopunct": 0.9634567901234568,
        "vocab_size-3-nopunct": 1951,
        "unique-3-nopunct": 1905,
        "entropy-3-nopunct": 10.896798816402706,
        "cond_entropy-3-nopunct": 0.34602559099048164,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.15823,
        "local_recall": {
            "1": 0.1766109785202864,
            "2": 0.3674911660777385,
            "3": 0.8243823845327605
        },
        "rouge1": {
            "precision": 0.8037,
            "recall": 0.79601,
            "fmeasure": 0.79249
        },
        "rouge2": {
            "precision": 0.57023,
            "recall": 0.56376,
            "fmeasure": 0.56131
        },
        "rougeL": {
            "precision": 0.68862,
            "recall": 0.68177,
            "fmeasure": 0.67874
        },
        "rougeLsum": {
            "precision": 0.68862,
            "recall": 0.68177,
            "fmeasure": 0.67874
        },
        "nist": 8.311845563042002,
        "bleurt": 0.38774,
        "bertscore": {
            "precision": 0.93774,
            "recall": 0.93916,
            "f1": 0.9373
        },
        "nubia": {
            "semantic_relation": 4.48082,
            "contradiction": 3.60079,
            "irrelevancy": 22.16745,
            "logical_agreement": 74.23176,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.56045,
            "nubia_score": 0.817
        },
        "meteor": 0.4244533364758908
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.68705,
        "msttr-100_nopunct": 0.71264,
        "total_length": 6143,
        "mean_pred_length": 12.286,
        "std_pred_length": 7.385133986597671,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 51,
        "distinct-1": 0.1640892072277389,
        "vocab_size-1": 1008,
        "unique-1": 570,
        "entropy-1": 7.817966287077382,
        "distinct-2": 0.5000886053517632,
        "vocab_size-2": 2822,
        "unique-2": 2017,
        "entropy-2": 10.687293913026751,
        "cond_entropy-2": 2.6187225789619912,
        "distinct-3": 0.714563484347657,
        "vocab_size-3": 3675,
        "unique-3": 3068,
        "entropy-3": 11.46776005939282,
        "cond_entropy-3": 0.8051639759826092,
        "total_length-nopunct": 5392,
        "mean_pred_length-nopunct": 10.784,
        "std_pred_length-nopunct": 6.767077951376059,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.1847181008902077,
        "vocab_size-1-nopunct": 996,
        "unique-1-nopunct": 566,
        "entropy-1-nopunct": 8.011688804882668,
        "distinct-2-nopunct": 0.5153311529026983,
        "vocab_size-2-nopunct": 2521,
        "unique-2-nopunct": 1846,
        "entropy-2-nopunct": 10.504800617971327,
        "cond_entropy-2-nopunct": 2.625919941292805,
        "distinct-3-nopunct": 0.7252447074891873,
        "vocab_size-3-nopunct": 3186,
        "unique-3-nopunct": 2704,
        "entropy-3-nopunct": 11.252361207373957,
        "cond_entropy-3-nopunct": 0.7798152832584059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "bleu": 31.87915,
        "local_recall": {
            "1": 0.5545987541223891
        },
        "rouge1": {
            "precision": 0.56381,
            "recall": 0.52908,
            "fmeasure": 0.53358
        },
        "rouge2": {
            "precision": 0.3454,
            "recall": 0.32268,
            "fmeasure": 0.32551
        },
        "rougeL": {
            "precision": 0.50637,
            "recall": 0.4733,
            "fmeasure": 0.47847
        },
        "rougeLsum": {
            "precision": 0.50637,
            "recall": 0.4733,
            "fmeasure": 0.47847
        },
        "nist": 6.002813379677847,
        "bleurt": -0.11945,
        "bertscore": {
            "precision": 0.86658,
            "recall": 0.85852,
            "f1": 0.862
        },
        "nubia": {
            "semantic_relation": 3.53802,
            "contradiction": 6.36017,
            "irrelevancy": 24.40943,
            "logical_agreement": 69.2304,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.68215,
            "nubia_score": 0.6155
        },
        "meteor": 0.31186083860220853
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.685,
        "total_length": 244,
        "mean_pred_length": 34.857142857142854,
        "std_pred_length": 6.127888739864919,
        "median_pred_length": 33.0,
        "min_pred_length": 26,
        "max_pred_length": 46,
        "distinct-1": 0.5327868852459017,
        "vocab_size-1": 130,
        "unique-1": 90,
        "entropy-1": 6.356185417120007,
        "distinct-2": 0.8734177215189873,
        "vocab_size-2": 207,
        "unique-2": 187,
        "entropy-2": 7.585299590835451,
        "cond_entropy-2": 1.1927022707141182,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 225,
        "unique-3": 221,
        "entropy-3": 7.798729670500175,
        "cond_entropy-3": 0.22266532143189977,
        "total_length-nopunct": 200,
        "mean_pred_length-nopunct": 28.571428571428573,
        "std_pred_length-nopunct": 5.473498303048005,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.62,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.569341950910772,
        "distinct-2-nopunct": 0.927461139896373,
        "vocab_size-2-nopunct": 179,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.4356453144365044,
        "cond_entropy-2-nopunct": 0.8897313411011415,
        "distinct-3-nopunct": 0.978494623655914,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.492089523462007,
        "cond_entropy-3-nopunct": 0.062345725476117456,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.12413,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.7,
            "3": 0.7717391304347826
        },
        "rouge1": {
            "precision": 0.71183,
            "recall": 0.7444,
            "fmeasure": 0.72053
        },
        "rouge2": {
            "precision": 0.47409,
            "recall": 0.51157,
            "fmeasure": 0.48428
        },
        "rougeL": {
            "precision": 0.61739,
            "recall": 0.66025,
            "fmeasure": 0.62864
        },
        "rougeLsum": {
            "precision": 0.61739,
            "recall": 0.66025,
            "fmeasure": 0.62864
        },
        "nist": 5.379061839950188,
        "bleurt": 0.1516,
        "bertscore": {
            "precision": 0.92099,
            "recall": 0.93299,
            "f1": 0.92497
        },
        "nubia": {
            "semantic_relation": 3.27993,
            "contradiction": 13.26787,
            "irrelevancy": 56.32857,
            "logical_agreement": 30.40356,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.36809,
            "nubia_score": 0.51824
        },
        "meteor": 0.3804914334223083
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.46212,
        "msttr-100_nopunct": 0.45705,
        "total_length": 19839,
        "mean_pred_length": 56.04237288135593,
        "std_pred_length": 14.706196511619197,
        "median_pred_length": 60.0,
        "min_pred_length": 11,
        "max_pred_length": 87,
        "distinct-1": 0.07772569181914411,
        "vocab_size-1": 1542,
        "unique-1": 646,
        "entropy-1": 5.84980862868171,
        "distinct-2": 0.20887862458301257,
        "vocab_size-2": 4070,
        "unique-2": 2152,
        "entropy-2": 10.060097219557532,
        "cond_entropy-2": 4.2149840389633475,
        "distinct-3": 0.376143432125869,
        "vocab_size-3": 7196,
        "unique-3": 4529,
        "entropy-3": 11.682963047691292,
        "cond_entropy-3": 1.6477621274967265,
        "total_length-nopunct": 18383,
        "mean_pred_length-nopunct": 51.929378531073446,
        "std_pred_length-nopunct": 14.13706456549699,
        "median_pred_length-nopunct": 55.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.08344666267747375,
        "vocab_size-1-nopunct": 1534,
        "unique-1-nopunct": 645,
        "entropy-1-nopunct": 5.754835349144883,
        "distinct-2-nopunct": 0.2100504742359532,
        "vocab_size-2-nopunct": 3787,
        "unique-2-nopunct": 2002,
        "entropy-2-nopunct": 9.956543182944296,
        "cond_entropy-2-nopunct": 4.263411390399901,
        "distinct-3-nopunct": 0.37465346534653465,
        "vocab_size-3-nopunct": 6622,
        "unique-3-nopunct": 4189,
        "entropy-3-nopunct": 11.542042307551007,
        "cond_entropy-3-nopunct": 1.6099714639041527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.5663,
        "local_recall": {
            "1": 0.08923539357505167,
            "2": 0.17731629392971246,
            "3": 0.25180161085205593,
            "4": 0.1891891891891892,
            "5": 0.18181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "rouge1": {
            "precision": 0.54913,
            "recall": 0.53389,
            "fmeasure": 0.53395
        },
        "rouge2": {
            "precision": 0.29336,
            "recall": 0.2847,
            "fmeasure": 0.2836
        },
        "rougeL": {
            "precision": 0.5264,
            "recall": 0.51183,
            "fmeasure": 0.51163
        },
        "rougeLsum": {
            "precision": 0.5264,
            "recall": 0.51183,
            "fmeasure": 0.51163
        },
        "nist": 1.077493453071578,
        "bleurt": -0.50256,
        "bertscore": {
            "precision": 0.86034,
            "recall": 0.87095,
            "f1": 0.86511
        },
        "nubia": {
            "semantic_relation": 3.29125,
            "contradiction": 32.12509,
            "irrelevancy": 18.1517,
            "logical_agreement": 49.72321,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.48212,
            "nubia_score": 0.13655
        },
        "meteor": 0.11806055968206951
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.2704790162786152,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.22503715874966052,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.03948,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.73529,
            "recall": 0.73958,
            "fmeasure": 0.7368
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.50588,
            "fmeasure": 0.50244
        },
        "rougeL": {
            "precision": 0.73529,
            "recall": 0.73958,
            "fmeasure": 0.7368
        },
        "rougeLsum": {
            "precision": 0.73529,
            "recall": 0.73958,
            "fmeasure": 0.7368
        },
        "nist": 3.447465232469153,
        "bleurt": 0.60237,
        "bertscore": {
            "precision": 0.95377,
            "recall": 0.95871,
            "f1": 0.95623
        },
        "nubia": {
            "semantic_relation": 4.3085,
            "contradiction": 2.43153,
            "irrelevancy": 37.30976,
            "logical_agreement": 60.25872,
            "grammar_ref": 4.60656,
            "grammar_hyp": 4.87894,
            "nubia_score": 0.67595
        },
        "meteor": 0.4647520764398727
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.71468,
        "msttr-100_nopunct": 0.72579,
        "total_length": 6278,
        "mean_pred_length": 12.556,
        "std_pred_length": 7.049742122943222,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 45,
        "distinct-1": 0.16964001274291177,
        "vocab_size-1": 1065,
        "unique-1": 599,
        "entropy-1": 8.032242411610955,
        "distinct-2": 0.503288335064036,
        "vocab_size-2": 2908,
        "unique-2": 2070,
        "entropy-2": 10.75051075544429,
        "cond_entropy-2": 2.680793327270618,
        "distinct-3": 0.7248957938613111,
        "vocab_size-3": 3826,
        "unique-3": 3173,
        "entropy-3": 11.55705768432366,
        "cond_entropy-3": 0.8531016041782299,
        "total_length-nopunct": 5702,
        "mean_pred_length-nopunct": 11.404,
        "std_pred_length-nopunct": 6.5097453099180465,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.184847421957208,
        "vocab_size-1-nopunct": 1054,
        "unique-1-nopunct": 598,
        "entropy-1-nopunct": 8.114081517911801,
        "distinct-2-nopunct": 0.5153787004998077,
        "vocab_size-2-nopunct": 2681,
        "unique-2-nopunct": 1943,
        "entropy-2-nopunct": 10.623677208623787,
        "cond_entropy-2-nopunct": 2.64871288448212,
        "distinct-3-nopunct": 0.7339430029774564,
        "vocab_size-3-nopunct": 3451,
        "unique-3-nopunct": 2897,
        "entropy-3-nopunct": 11.407545285868961,
        "cond_entropy-3-nopunct": 0.8233363895179998,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "bleu": 28.62626,
        "local_recall": {
            "1": 0.540339877907936
        },
        "rouge1": {
            "precision": 0.57063,
            "recall": 0.52,
            "fmeasure": 0.53249
        },
        "rouge2": {
            "precision": 0.35113,
            "recall": 0.31762,
            "fmeasure": 0.3261
        },
        "rougeL": {
            "precision": 0.50606,
            "recall": 0.45997,
            "fmeasure": 0.47157
        },
        "rougeLsum": {
            "precision": 0.50606,
            "recall": 0.45997,
            "fmeasure": 0.47157
        },
        "nist": 5.866018308074407,
        "bleurt": -0.12974,
        "bertscore": {
            "precision": 0.8662,
            "recall": 0.85012,
            "f1": 0.85759
        },
        "nubia": {
            "semantic_relation": 3.63465,
            "contradiction": 8.01908,
            "irrelevancy": 19.08537,
            "logical_agreement": 72.89555,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.90855,
            "nubia_score": 0.62209
        },
        "meteor": 0.3016075174966246
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.775,
        "total_length": 271,
        "mean_pred_length": 45.166666666666664,
        "std_pred_length": 18.37948735834478,
        "median_pred_length": 34.5,
        "min_pred_length": 30,
        "max_pred_length": 79,
        "distinct-1": 0.6199261992619927,
        "vocab_size-1": 168,
        "unique-1": 141,
        "entropy-1": 6.809283562862624,
        "distinct-2": 0.9169811320754717,
        "vocab_size-2": 243,
        "unique-2": 235,
        "entropy-2": 7.8206823005705175,
        "cond_entropy-2": 0.9816908806008224,
        "distinct-3": 0.9806949806949807,
        "vocab_size-3": 254,
        "unique-3": 252,
        "entropy-3": 7.964261413267844,
        "cond_entropy-3": 0.1411659756057368,
        "total_length-nopunct": 229,
        "mean_pred_length-nopunct": 38.166666666666664,
        "std_pred_length-nopunct": 13.1708854000869,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.7117903930131004,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.962670395470885,
        "distinct-2-nopunct": 0.9596412556053812,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.695027072680687,
        "cond_entropy-2-nopunct": 0.7514562303746254,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.761551232444494,
        "cond_entropy-3-nopunct": 0.06945151904231642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.23891,
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 0.4722222222222222,
            "3": 0.8495575221238938
        },
        "rouge1": {
            "precision": 0.72427,
            "recall": 0.8029,
            "fmeasure": 0.75286
        },
        "rouge2": {
            "precision": 0.59209,
            "recall": 0.65525,
            "fmeasure": 0.61313
        },
        "rougeL": {
            "precision": 0.62733,
            "recall": 0.70531,
            "fmeasure": 0.65366
        },
        "rougeLsum": {
            "precision": 0.62733,
            "recall": 0.70531,
            "fmeasure": 0.65366
        },
        "nist": 5.211959765916377,
        "bleurt": 0.1355,
        "bertscore": {
            "precision": 0.91377,
            "recall": 0.94123,
            "f1": 0.92446
        },
        "nubia": {
            "semantic_relation": 3.69722,
            "contradiction": 26.1626,
            "irrelevancy": 43.58617,
            "logical_agreement": 30.25123,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.45279,
            "nubia_score": 0.56892
        },
        "meteor": 0.4297136592565997
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.59155,
        "msttr-100_nopunct": 0.66079,
        "total_length": 36143,
        "mean_pred_length": 40.15888888888889,
        "std_pred_length": 21.360666835431918,
        "median_pred_length": 36.0,
        "min_pred_length": 0,
        "max_pred_length": 116,
        "distinct-1": 0.1038375342389951,
        "vocab_size-1": 3753,
        "unique-1": 1566,
        "entropy-1": 8.455914138779223,
        "distinct-2": 0.40032345931222335,
        "vocab_size-2": 14109,
        "unique-2": 8863,
        "entropy-2": 12.569266003326485,
        "cond_entropy-2": 3.975594556683032,
        "distinct-3": 0.6406463822972777,
        "vocab_size-3": 22003,
        "unique-3": 16419,
        "entropy-3": 13.95773959028423,
        "cond_entropy-3": 1.395564218259756,
        "total_length-nopunct": 30575,
        "mean_pred_length-nopunct": 33.97222222222222,
        "std_pred_length-nopunct": 18.659531539777483,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 104,
        "distinct-1-nopunct": 0.1220932134096484,
        "vocab_size-1-nopunct": 3733,
        "unique-1-nopunct": 1558,
        "entropy-1-nopunct": 9.16253609156159,
        "distinct-2-nopunct": 0.49164307858201917,
        "vocab_size-2-nopunct": 14590,
        "unique-2-nopunct": 9819,
        "entropy-2-nopunct": 12.977065700047644,
        "cond_entropy-2-nopunct": 3.887253532237983,
        "distinct-3-nopunct": 0.7234345680728335,
        "vocab_size-3-nopunct": 20819,
        "unique-3-nopunct": 16231,
        "entropy-3-nopunct": 14.079923707810966,
        "cond_entropy-3-nopunct": 1.1203246487687848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "bleu": 14.49894,
        "local_recall": {
            "1": 0.2919655343528669
        },
        "rouge1": {
            "precision": 0.30951,
            "recall": 0.31497,
            "fmeasure": 0.29083
        },
        "rouge2": {
            "precision": 0.12223,
            "recall": 0.12545,
            "fmeasure": 0.11685
        },
        "rougeL": {
            "precision": 0.25329,
            "recall": 0.25827,
            "fmeasure": 0.23792
        },
        "rougeLsum": {
            "precision": 0.25329,
            "recall": 0.25827,
            "fmeasure": 0.23792
        },
        "nist": 3.295925527713898,
        "sari": 66.76202,
        "bleurt": -0.59944,
        "bertscore": {
            "precision": 0.82116,
            "recall": 0.82021,
            "f1": 0.81992
        },
        "nubia": {
            "semantic_relation": 2.26377,
            "contradiction": 26.44259,
            "irrelevancy": 51.23076,
            "logical_agreement": 22.21554,
            "grammar_ref": 3.87115,
            "grammar_hyp": 3.70336,
            "nubia_score": 0.2731
        },
        "meteor": 0.157541161522469
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.60996,
        "msttr-100_nopunct": 0.68911,
        "total_length": 62433,
        "mean_pred_length": 31.90240163515585,
        "std_pred_length": 15.940749367572154,
        "median_pred_length": 29.0,
        "min_pred_length": 3,
        "max_pred_length": 133,
        "distinct-1": 0.09208271266798007,
        "vocab_size-1": 5749,
        "unique-1": 2463,
        "entropy-1": 8.741175974155713,
        "distinct-2": 0.39986110192473046,
        "vocab_size-2": 24182,
        "unique-2": 16241,
        "entropy-2": 13.277960114626964,
        "cond_entropy-2": 4.34714288917535,
        "distinct-3": 0.702318904971035,
        "vocab_size-3": 41099,
        "unique-3": 33741,
        "entropy-3": 14.8900626196689,
        "cond_entropy-3": 1.6170811033731325,
        "total_length-nopunct": 52636,
        "mean_pred_length-nopunct": 26.89626980071538,
        "std_pred_length-nopunct": 14.214466904402869,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 123,
        "distinct-1-nopunct": 0.10891785090052436,
        "vocab_size-1-nopunct": 5733,
        "unique-1-nopunct": 2459,
        "entropy-1-nopunct": 9.553459405282815,
        "distinct-2-nopunct": 0.5188539631800154,
        "vocab_size-2-nopunct": 26295,
        "unique-2-nopunct": 19524,
        "entropy-2-nopunct": 13.749526847499183,
        "cond_entropy-2-nopunct": 4.298804173835569,
        "distinct-3-nopunct": 0.8049135913960839,
        "vocab_size-3-nopunct": 39217,
        "unique-3-nopunct": 34051,
        "entropy-3-nopunct": 15.033821754593983,
        "cond_entropy-3-nopunct": 1.3102803877138822,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "bleu": 9.30867,
        "local_recall": {
            "1": 0.24674845115496657
        },
        "rouge1": {
            "precision": 0.32368,
            "recall": 0.2782,
            "fmeasure": 0.27807
        },
        "rouge2": {
            "precision": 0.10593,
            "recall": 0.09209,
            "fmeasure": 0.09218
        },
        "rougeL": {
            "precision": 0.26317,
            "recall": 0.22685,
            "fmeasure": 0.22621
        },
        "rougeLsum": {
            "precision": 0.26317,
            "recall": 0.22685,
            "fmeasure": 0.22621
        },
        "nist": 2.947748940437563,
        "sari": 66.39036,
        "bleurt": -0.49723,
        "bertscore": {
            "precision": 0.83079,
            "recall": 0.81859,
            "f1": 0.8241
        },
        "nubia": {
            "semantic_relation": 2.32423,
            "contradiction": 20.29632,
            "irrelevancy": 52.40496,
            "logical_agreement": 27.29872,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.71746,
            "nubia_score": 0.28688
        },
        "meteor": 0.13757970897469893
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.59908,
        "msttr-100_nopunct": 0.67618,
        "total_length": 126090,
        "mean_pred_length": 32.19045187643605,
        "std_pred_length": 16.922369438523756,
        "median_pred_length": 29.0,
        "min_pred_length": 3,
        "max_pred_length": 115,
        "distinct-1": 0.06345467523197716,
        "vocab_size-1": 8001,
        "unique-1": 3076,
        "entropy-1": 8.808564390316194,
        "distinct-2": 0.32254262398402267,
        "vocab_size-2": 39406,
        "unique-2": 24783,
        "entropy-2": 13.610984074295985,
        "cond_entropy-2": 4.613222234188191,
        "distinct-3": 0.6207296035719118,
        "vocab_size-3": 73405,
        "unique-3": 57244,
        "entropy-3": 15.517272799856086,
        "cond_entropy-3": 1.9095687774154626,
        "total_length-nopunct": 106460,
        "mean_pred_length-nopunct": 27.178963492468725,
        "std_pred_length-nopunct": 14.98125410709456,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 105,
        "distinct-1-nopunct": 0.07496712380236709,
        "vocab_size-1-nopunct": 7981,
        "unique-1-nopunct": 3074,
        "entropy-1-nopunct": 9.615454213621351,
        "distinct-2-nopunct": 0.43457866456023325,
        "vocab_size-2-nopunct": 44563,
        "unique-2-nopunct": 31218,
        "entropy-2-nopunct": 14.182022237163226,
        "cond_entropy-2-nopunct": 4.672119088356774,
        "distinct-3-nopunct": 0.7328696286983148,
        "vocab_size-3-nopunct": 72280,
        "unique-3-nopunct": 60037,
        "entropy-3-nopunct": 15.779695024325333,
        "cond_entropy-3-nopunct": 1.6278918322806752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "bleu": 9.72107,
        "local_recall": {
            "1": 0.2557444540809396
        },
        "rouge1": {
            "precision": 0.33019,
            "recall": 0.28543,
            "fmeasure": 0.28498
        },
        "rouge2": {
            "precision": 0.10956,
            "recall": 0.09701,
            "fmeasure": 0.096
        },
        "rougeL": {
            "precision": 0.26641,
            "recall": 0.23138,
            "fmeasure": 0.23019
        },
        "rougeLsum": {
            "precision": 0.26641,
            "recall": 0.23138,
            "fmeasure": 0.23019
        },
        "nist": 3.1396876090930474,
        "sari": 66.2136,
        "bleurt": -0.50001,
        "bertscore": {
            "precision": 0.83155,
            "recall": 0.81968,
            "f1": 0.82503
        },
        "nubia": {
            "semantic_relation": 2.35359,
            "contradiction": 20.59174,
            "irrelevancy": 50.97848,
            "logical_agreement": 28.42979,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.71405,
            "nubia_score": 0.29014
        },
        "meteor": 0.14123825809805135
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 156,
        "mean_pred_length": 31.2,
        "std_pred_length": 15.535765188750762,
        "median_pred_length": 25.0,
        "min_pred_length": 12,
        "max_pred_length": 51,
        "distinct-1": 0.6410256410256411,
        "vocab_size-1": 100,
        "unique-1": 86,
        "entropy-1": 6.040510037512226,
        "distinct-2": 0.9470198675496688,
        "vocab_size-2": 143,
        "unique-2": 138,
        "entropy-2": 7.117446709480756,
        "cond_entropy-2": 1.0412732311229493,
        "distinct-3": 0.9931506849315068,
        "vocab_size-3": 145,
        "unique-3": 144,
        "entropy-3": 7.176125928743034,
        "cond_entropy-3": 0.06282161754459879,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 25.6,
        "std_pred_length-nopunct": 11.200000000000001,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.7421875,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.248789235012335,
        "distinct-2-nopunct": 0.991869918699187,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.926254342737602,
        "cond_entropy-2-nopunct": 0.680994585205368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.882643049361832,
        "cond_entropy-3-nopunct": -0.04292230343502576,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.25076,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5714285714285714,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.78135,
            "recall": 0.74888,
            "fmeasure": 0.76028
        },
        "rouge2": {
            "precision": 0.55936,
            "recall": 0.53849,
            "fmeasure": 0.54611
        },
        "rougeL": {
            "precision": 0.64573,
            "recall": 0.62124,
            "fmeasure": 0.63035
        },
        "rougeLsum": {
            "precision": 0.64573,
            "recall": 0.62124,
            "fmeasure": 0.63035
        },
        "nist": 4.959296673581195,
        "bleurt": 0.1436,
        "bertscore": {
            "precision": 0.91625,
            "recall": 0.92569,
            "f1": 0.92055
        },
        "nubia": {
            "semantic_relation": 3.96902,
            "contradiction": 19.70055,
            "irrelevancy": 17.28553,
            "logical_agreement": 63.01393,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.79653,
            "nubia_score": 0.72351
        },
        "meteor": 0.35092134350984944
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.65559,
        "msttr-100_nopunct": 0.6998,
        "total_length": 5936,
        "mean_pred_length": 17.008595988538683,
        "std_pred_length": 4.41895312708265,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 53,
        "distinct-1": 0.1694743935309973,
        "vocab_size-1": 1006,
        "unique-1": 429,
        "entropy-1": 7.776586262051717,
        "distinct-2": 0.4370860927152318,
        "vocab_size-2": 2442,
        "unique-2": 1495,
        "entropy-2": 10.568136385594975,
        "cond_entropy-2": 2.5578533786700777,
        "distinct-3": 0.6237113402061856,
        "vocab_size-3": 3267,
        "unique-3": 2393,
        "entropy-3": 11.30508546680407,
        "cond_entropy-3": 0.8156624912411843,
        "total_length-nopunct": 5178,
        "mean_pred_length-nopunct": 14.836676217765042,
        "std_pred_length-nopunct": 3.898310024120991,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.19273850907686366,
        "vocab_size-1-nopunct": 998,
        "unique-1-nopunct": 428,
        "entropy-1-nopunct": 8.076779039297248,
        "distinct-2-nopunct": 0.4367363843445848,
        "vocab_size-2-nopunct": 2109,
        "unique-2-nopunct": 1282,
        "entropy-2-nopunct": 10.376643211598134,
        "cond_entropy-2-nopunct": 2.484476495129434,
        "distinct-3-nopunct": 0.6234375,
        "vocab_size-3-nopunct": 2793,
        "unique-3-nopunct": 2048,
        "entropy-3-nopunct": 11.075272443534995,
        "cond_entropy-3-nopunct": 0.7629489622694474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 51.78662,
        "local_recall": {
            "1": 0.2273994424532059,
            "2": 0.5774932614555256,
            "3": 0.8906356801093643,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.78317,
            "recall": 0.77581,
            "fmeasure": 0.77317
        },
        "rouge2": {
            "precision": 0.54098,
            "recall": 0.53605,
            "fmeasure": 0.53321
        },
        "rougeL": {
            "precision": 0.65039,
            "recall": 0.64248,
            "fmeasure": 0.64069
        },
        "rougeLsum": {
            "precision": 0.65039,
            "recall": 0.64248,
            "fmeasure": 0.64069
        },
        "nist": 8.877602295424209,
        "bleurt": 0.26023,
        "bertscore": {
            "precision": 0.92916,
            "recall": 0.93046,
            "f1": 0.92812
        },
        "nubia": {
            "semantic_relation": 4.56417,
            "contradiction": 8.05589,
            "irrelevancy": 4.92879,
            "logical_agreement": 87.01532,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.75044,
            "nubia_score": 0.82007
        },
        "meteor": 0.4246355574839151
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.58306,
        "msttr-100_nopunct": 0.6573,
        "total_length": 170772,
        "mean_pred_length": 32.294251134644476,
        "std_pred_length": 16.98757079467967,
        "median_pred_length": 29.0,
        "min_pred_length": 3,
        "max_pred_length": 129,
        "distinct-1": 0.05535450776473895,
        "vocab_size-1": 9453,
        "unique-1": 3593,
        "entropy-1": 8.844952056637295,
        "distinct-2": 0.30854946701795943,
        "vocab_size-2": 51060,
        "unique-2": 32745,
        "entropy-2": 13.876033800702615,
        "cond_entropy-2": 4.842315639930444,
        "distinct-3": 0.6377437638892357,
        "vocab_size-3": 102164,
        "unique-3": 82562,
        "entropy-3": 15.984545455224607,
        "cond_entropy-3": 2.110999008195508,
        "total_length-nopunct": 144270,
        "mean_pred_length-nopunct": 27.282526475037823,
        "std_pred_length-nopunct": 15.11273762087992,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 119,
        "distinct-1-nopunct": 0.06539821168642129,
        "vocab_size-1-nopunct": 9435,
        "unique-1-nopunct": 3589,
        "entropy-1-nopunct": 9.664419149515389,
        "distinct-2-nopunct": 0.43221424357110994,
        "vocab_size-2-nopunct": 60070,
        "unique-2-nopunct": 43529,
        "entropy-2-nopunct": 14.49751262091844,
        "cond_entropy-2-nopunct": 4.943670109686632,
        "distinct-3-nopunct": 0.7606549284186276,
        "vocab_size-3-nopunct": 101695,
        "unique-3-nopunct": 87701,
        "entropy-3-nopunct": 16.289007986901062,
        "cond_entropy-3-nopunct": 1.8260767302190513,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "bleu": 11.19606,
        "local_recall": {
            "1": 0.29711547732953575
        },
        "rouge1": {
            "precision": 0.40899,
            "recall": 0.34445,
            "fmeasure": 0.35156
        },
        "rouge2": {
            "precision": 0.15282,
            "recall": 0.13039,
            "fmeasure": 0.13281
        },
        "rougeL": {
            "precision": 0.33793,
            "recall": 0.28662,
            "fmeasure": 0.29136
        },
        "rougeLsum": {
            "precision": 0.33793,
            "recall": 0.28662,
            "fmeasure": 0.29136
        },
        "nist": 3.73436318048374,
        "sari": 69.49138,
        "bleurt": -0.35796,
        "bertscore": {
            "precision": 0.85361,
            "recall": 0.83502,
            "f1": 0.84366
        },
        "nubia": {
            "semantic_relation": 2.78764,
            "contradiction": 16.33728,
            "irrelevancy": 44.60117,
            "logical_agreement": 39.06155,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.68451,
            "nubia_score": 0.3837
        },
        "meteor": 0.1637127644109569
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.46214,
        "msttr-100_nopunct": 0.45911,
        "total_length": 48551,
        "mean_pred_length": 45.16372093023256,
        "std_pred_length": 19.50907207253647,
        "median_pred_length": 45.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.05182179563757698,
        "vocab_size-1": 2516,
        "unique-1": 887,
        "entropy-1": 5.995205284324855,
        "distinct-2": 0.15500463392029656,
        "vocab_size-2": 7359,
        "unique-2": 3555,
        "entropy-2": 10.42539315009245,
        "cond_entropy-2": 4.424995005503802,
        "distinct-3": 0.30167453287644663,
        "vocab_size-3": 13998,
        "unique-3": 8185,
        "entropy-3": 12.300906760698421,
        "cond_entropy-3": 1.9173804840950346,
        "total_length-nopunct": 44800,
        "mean_pred_length-nopunct": 41.674418604651166,
        "std_pred_length-nopunct": 18.41925298365634,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.0559375,
        "vocab_size-1-nopunct": 2506,
        "unique-1-nopunct": 885,
        "entropy-1-nopunct": 5.907483356147106,
        "distinct-2-nopunct": 0.1553344768439108,
        "vocab_size-2-nopunct": 6792,
        "unique-2-nopunct": 3308,
        "entropy-2-nopunct": 10.29259417357127,
        "cond_entropy-2-nopunct": 4.475024562835817,
        "distinct-3-nopunct": 0.3021101992966002,
        "vocab_size-3-nopunct": 12885,
        "unique-3-nopunct": 7668,
        "entropy-3-nopunct": 12.13411714876422,
        "cond_entropy-3-nopunct": 1.8800387062786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.01446,
        "local_recall": {
            "1": 0.09152837162113196,
            "2": 0.1819454163750875,
            "3": 0.2648968678380443,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.43162,
            "recall": 0.41466,
            "fmeasure": 0.41642
        },
        "rouge2": {
            "precision": 0.22221,
            "recall": 0.21375,
            "fmeasure": 0.21408
        },
        "rougeL": {
            "precision": 0.41129,
            "recall": 0.3961,
            "fmeasure": 0.39709
        },
        "rougeLsum": {
            "precision": 0.41129,
            "recall": 0.3961,
            "fmeasure": 0.39709
        },
        "nist": 1.1368122207422495,
        "bleurt": -0.47841,
        "bertscore": {
            "precision": 0.86183,
            "recall": 0.87343,
            "f1": 0.86712
        },
        "nubia": {
            "semantic_relation": 3.31602,
            "contradiction": 32.92532,
            "irrelevancy": 17.2722,
            "logical_agreement": 49.80248,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.62895,
            "nubia_score": 0.15893
        },
        "meteor": 0.12716465483744457
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.70294,
        "msttr-100_nopunct": 0.77,
        "total_length": 1765,
        "mean_pred_length": 16.80952380952381,
        "std_pred_length": 9.140277413832365,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 91,
        "distinct-1": 0.4498583569405099,
        "vocab_size-1": 794,
        "unique-1": 635,
        "entropy-1": 8.041589347778869,
        "distinct-2": 0.8475903614457831,
        "vocab_size-2": 1407,
        "unique-2": 1289,
        "entropy-2": 10.241497659968,
        "cond_entropy-2": 1.947047826687982,
        "distinct-3": 0.9594855305466238,
        "vocab_size-3": 1492,
        "unique-3": 1453,
        "entropy-3": 10.50561340719716,
        "cond_entropy-3": 0.27235033626444455,
        "total_length-nopunct": 1514,
        "mean_pred_length-nopunct": 14.41904761904762,
        "std_pred_length-nopunct": 7.072119575024641,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.5191545574636723,
        "vocab_size-1-nopunct": 786,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 8.383225692303117,
        "distinct-2-nopunct": 0.8694109297374024,
        "vocab_size-2-nopunct": 1225,
        "unique-2-nopunct": 1141,
        "entropy-2-nopunct": 10.049893156346377,
        "cond_entropy-2-nopunct": 1.7821782706649651,
        "distinct-3-nopunct": 0.977760736196319,
        "vocab_size-3-nopunct": 1275,
        "unique-3-nopunct": 1255,
        "entropy-3-nopunct": 10.296976663851284,
        "cond_entropy-3-nopunct": 0.2694064275171438,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.59922,
        "local_recall": {
            "1": 0.2120253164556962,
            "2": 0.288135593220339,
            "3": 0.7933390264731
        },
        "rouge1": {
            "precision": 0.77264,
            "recall": 0.76454,
            "fmeasure": 0.75849
        },
        "rouge2": {
            "precision": 0.51944,
            "recall": 0.51372,
            "fmeasure": 0.50948
        },
        "rougeL": {
            "precision": 0.65437,
            "recall": 0.64512,
            "fmeasure": 0.64092
        },
        "rougeLsum": {
            "precision": 0.65437,
            "recall": 0.64512,
            "fmeasure": 0.64092
        },
        "nist": 7.394259234989943,
        "bleurt": 0.35798,
        "bertscore": {
            "precision": 0.93327,
            "recall": 0.93305,
            "f1": 0.93192
        },
        "nubia": {
            "semantic_relation": 4.4259,
            "contradiction": 5.85652,
            "irrelevancy": 27.54014,
            "logical_agreement": 66.60333,
            "grammar_ref": 5.02637,
            "grammar_hyp": 4.96195,
            "nubia_score": 0.78348
        },
        "meteor": 0.3929210942779903
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.82,
        "total_length": 131,
        "mean_pred_length": 26.2,
        "std_pred_length": 12.432216214336043,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 45,
        "distinct-1": 0.6870229007633588,
        "vocab_size-1": 90,
        "unique-1": 73,
        "entropy-1": 6.111782491469323,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 120,
        "unique-2": 114,
        "entropy-2": 6.88204182826183,
        "cond_entropy-2": 0.7146923691409431,
        "distinct-3": 0.9834710743801653,
        "vocab_size-3": 119,
        "unique-3": 117,
        "entropy-3": 6.885805386034933,
        "cond_entropy-3": -0.008829909365817954,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 21.4,
        "std_pred_length-nopunct": 8.957678270623477,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.8037383177570093,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.260067220005561,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.63320965569699,
        "cond_entropy-2-nopunct": 0.386936541887279,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.599912842187142,
        "cond_entropy-3-nopunct": -0.03127538638230608,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.90429,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.5151515151515151,
            "3": 0.6571428571428571
        },
        "rouge1": {
            "precision": 0.53346,
            "recall": 0.53413,
            "fmeasure": 0.5207
        },
        "rouge2": {
            "precision": 0.27484,
            "recall": 0.26108,
            "fmeasure": 0.26036
        },
        "rougeL": {
            "precision": 0.42765,
            "recall": 0.45396,
            "fmeasure": 0.42452
        },
        "rougeLsum": {
            "precision": 0.42765,
            "recall": 0.45396,
            "fmeasure": 0.42452
        },
        "nist": 3.372005280185319,
        "bleurt": -0.06246,
        "bertscore": {
            "precision": 0.8624,
            "recall": 0.88075,
            "f1": 0.87026
        },
        "nubia": {
            "semantic_relation": 3.33556,
            "contradiction": 29.24945,
            "irrelevancy": 46.03949,
            "logical_agreement": 24.71105,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.42374,
            "nubia_score": 0.48188
        },
        "meteor": 0.27377828841790963
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.71042,
        "msttr-100_nopunct": 0.75651,
        "total_length": 7141,
        "mean_pred_length": 19.891364902506965,
        "std_pred_length": 9.236412625730374,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3492508052093544,
        "vocab_size-1": 2494,
        "unique-1": 1814,
        "entropy-1": 8.995879249258184,
        "distinct-2": 0.8174579769979358,
        "vocab_size-2": 5544,
        "unique-2": 5119,
        "entropy-2": 12.039940348334964,
        "cond_entropy-2": 2.787328037472827,
        "distinct-3": 0.951580258446209,
        "vocab_size-3": 6112,
        "unique-3": 5998,
        "entropy-3": 12.457900293710399,
        "cond_entropy-3": 0.436101940688885,
        "total_length-nopunct": 6318,
        "mean_pred_length-nopunct": 17.598885793871865,
        "std_pred_length-nopunct": 8.180457648440695,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.392687559354226,
        "vocab_size-1-nopunct": 2481,
        "unique-1-nopunct": 1811,
        "entropy-1-nopunct": 9.345816595224964,
        "distinct-2-nopunct": 0.8439335458969626,
        "vocab_size-2-nopunct": 5029,
        "unique-2-nopunct": 4686,
        "entropy-2-nopunct": 11.978383700841528,
        "cond_entropy-2-nopunct": 2.7676009146705702,
        "distinct-3-nopunct": 0.9725,
        "vocab_size-3-nopunct": 5446,
        "unique-3-nopunct": 5356,
        "entropy-3-nopunct": 12.377139309821693,
        "cond_entropy-3-nopunct": 0.4260974171922578,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "bleu": 40.13203,
        "local_recall": {
            "1": 0.06833616298811546,
            "2": 0.1583652618135377,
            "3": 0.3085339168490153,
            "4": 0.3328050713153724,
            "5": 0.4215991692627207,
            "6": 0.5579710144927537,
            "7": 0.720504009163803
        },
        "rouge1": {
            "precision": 0.68723,
            "recall": 0.63286,
            "fmeasure": 0.64721
        },
        "rouge2": {
            "precision": 0.4521,
            "recall": 0.421,
            "fmeasure": 0.42666
        },
        "rougeL": {
            "precision": 0.62963,
            "recall": 0.58454,
            "fmeasure": 0.59443
        },
        "rougeLsum": {
            "precision": 0.62963,
            "recall": 0.58454,
            "fmeasure": 0.59443
        },
        "nist": 8.24895921072523,
        "sari": 44.83236,
        "bleurt": -0.09792,
        "bertscore": {
            "precision": 0.90614,
            "recall": 0.89976,
            "f1": 0.90037
        },
        "nubia": {
            "semantic_relation": 3.65242,
            "contradiction": 12.60024,
            "irrelevancy": 28.11363,
            "logical_agreement": 59.28613,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.04383,
            "nubia_score": 0.53502
        },
        "meteor": 0.33785286198771447
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 17.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.5,
        "vocab_size-1": 37,
        "unique-1": 33,
        "entropy-1": 3.7977640961853125,
        "distinct-2": 0.9571428571428572,
        "vocab_size-2": 67,
        "unique-2": 64,
        "entropy-2": 6.043568731230686,
        "cond_entropy-2": 2.26932973615643,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": 0.00602019332257765,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.4925373134328358,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 3.521835370475248,
        "distinct-2-nopunct": 0.9365079365079365,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.838313455211611,
        "cond_entropy-2-nopunct": 2.382075246015272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.882643049361836,
        "cond_entropy-3-nopunct": 0.03680189708503445,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 0.84755,
        "local_recall": {
            "1": 0.0,
            "2": 0.07692307692307693,
            "3": 0.0
        },
        "rouge1": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.125,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "nist": 0.37709433944074006,
        "bleurt": -0.42339,
        "bertscore": {
            "precision": 0.85013,
            "recall": 0.86551,
            "f1": 0.8574
        },
        "nubia": {
            "semantic_relation": 3.33307,
            "contradiction": 44.09405,
            "irrelevancy": 13.77327,
            "logical_agreement": 42.13268,
            "grammar_ref": 3.0388,
            "grammar_hyp": 2.87593,
            "nubia_score": 0.18934
        },
        "meteor": 0.05549132947976879
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "T5-xl (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.58671,
        "msttr-100_nopunct": 0.66404,
        "total_length": 318736,
        "mean_pred_length": 30.126275992438565,
        "std_pred_length": 15.589825384139141,
        "median_pred_length": 27.0,
        "min_pred_length": 2,
        "max_pred_length": 123,
        "distinct-1": 0.03938055318508107,
        "vocab_size-1": 12552,
        "unique-1": 4619,
        "entropy-1": 8.853161697380953,
        "distinct-2": 0.2502368930022456,
        "vocab_size-2": 77112,
        "unique-2": 47935,
        "entropy-2": 14.067653234932878,
        "cond_entropy-2": 5.010293597212167,
        "distinct-3": 0.5699686802699142,
        "vocab_size-3": 169609,
        "unique-3": 132620,
        "entropy-3": 16.48953341750319,
        "cond_entropy-3": 2.4231523693023145,
        "total_length-nopunct": 267713,
        "mean_pred_length-nopunct": 25.30368620037807,
        "std_pred_length-nopunct": 13.867150042675195,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 110,
        "distinct-1-nopunct": 0.04680385338029905,
        "vocab_size-1-nopunct": 12530,
        "unique-1-nopunct": 4617,
        "entropy-1-nopunct": 9.713924649495617,
        "distinct-2-nopunct": 0.37066809783263915,
        "vocab_size-2-nopunct": 95311,
        "unique-2-nopunct": 66931,
        "entropy-2-nopunct": 14.829586018343548,
        "cond_entropy-2-nopunct": 5.2388139002363685,
        "distinct-3-nopunct": 0.7074944434530086,
        "vocab_size-3-nopunct": 174437,
        "unique-3-nopunct": 147089,
        "entropy-3-nopunct": 16.930749130801406,
        "cond_entropy-3-nopunct": 2.1428805364843484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "bleu": 10.99009,
        "local_recall": {
            "1": 0.29222806872687146
        },
        "rouge1": {
            "precision": 0.41981,
            "recall": 0.33863,
            "fmeasure": 0.35258
        },
        "rouge2": {
            "precision": 0.15753,
            "recall": 0.12952,
            "fmeasure": 0.13435
        },
        "rougeL": {
            "precision": 0.3485,
            "recall": 0.28325,
            "fmeasure": 0.29374
        },
        "rougeLsum": {
            "precision": 0.3485,
            "recall": 0.28325,
            "fmeasure": 0.29374
        },
        "nist": 3.544122496715883,
        "sari": 69.46024,
        "bleurt": -0.36223,
        "bertscore": {
            "precision": 0.85652,
            "recall": 0.83461,
            "f1": 0.84485
        },
        "nubia": {
            "semantic_relation": 2.78777,
            "contradiction": 16.12585,
            "irrelevancy": 42.84749,
            "logical_agreement": 41.02667,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.74319,
            "nubia_score": 0.38425
        },
        "meteor": 0.16219808035631575
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.71769,
        "msttr-100_nopunct": 0.76167,
        "total_length": 1384,
        "mean_pred_length": 17.518987341772153,
        "std_pred_length": 5.593533245131984,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 34,
        "distinct-1": 0.4515895953757225,
        "vocab_size-1": 625,
        "unique-1": 480,
        "entropy-1": 7.925157434053201,
        "distinct-2": 0.8505747126436781,
        "vocab_size-2": 1110,
        "unique-2": 1009,
        "entropy-2": 9.920382924230708,
        "cond_entropy-2": 1.7655316308571267,
        "distinct-3": 0.964110929853181,
        "vocab_size-3": 1182,
        "unique-3": 1148,
        "entropy-3": 10.181407945569056,
        "cond_entropy-3": 0.2652434183275364,
        "total_length-nopunct": 1210,
        "mean_pred_length-nopunct": 15.316455696202532,
        "std_pred_length-nopunct": 5.025364282525975,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5107438016528926,
        "vocab_size-1-nopunct": 618,
        "unique-1-nopunct": 479,
        "entropy-1-nopunct": 8.197093564302742,
        "distinct-2-nopunct": 0.8620689655172413,
        "vocab_size-2-nopunct": 975,
        "unique-2-nopunct": 904,
        "entropy-2-nopunct": 9.724281256706169,
        "cond_entropy-2-nopunct": 1.6027305287270266,
        "distinct-3-nopunct": 0.967680608365019,
        "vocab_size-3-nopunct": 1018,
        "unique-3-nopunct": 991,
        "entropy-3-nopunct": 9.968791196981654,
        "cond_entropy-3-nopunct": 0.2546969528255349,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.53604,
        "local_recall": {
            "1": 0.1856060606060606,
            "2": 0.3932038834951456,
            "3": 0.7982740021574973
        },
        "rouge1": {
            "precision": 0.79623,
            "recall": 0.78098,
            "fmeasure": 0.78154
        },
        "rouge2": {
            "precision": 0.57705,
            "recall": 0.56695,
            "fmeasure": 0.56657
        },
        "rougeL": {
            "precision": 0.67572,
            "recall": 0.65853,
            "fmeasure": 0.66138
        },
        "rougeLsum": {
            "precision": 0.67572,
            "recall": 0.65853,
            "fmeasure": 0.66138
        },
        "nist": 7.48917830218133,
        "bleurt": 0.34314,
        "bertscore": {
            "precision": 0.93535,
            "recall": 0.93779,
            "f1": 0.93557
        },
        "nubia": {
            "semantic_relation": 4.42916,
            "contradiction": 5.55425,
            "irrelevancy": 25.32482,
            "logical_agreement": 69.12094,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.88461,
            "nubia_score": 0.77094
        },
        "meteor": 0.4053719778274971
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.472,
        "msttr-100_nopunct": 0.462,
        "total_length": 580,
        "mean_pred_length": 30.526315789473685,
        "std_pred_length": 17.667598714067786,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 82,
        "distinct-1": 0.2482758620689655,
        "vocab_size-1": 144,
        "unique-1": 82,
        "entropy-1": 4.959729299635462,
        "distinct-2": 0.5508021390374331,
        "vocab_size-2": 309,
        "unique-2": 200,
        "entropy-2": 7.878921415251213,
        "cond_entropy-2": 2.905228691022129,
        "distinct-3": 0.7435424354243543,
        "vocab_size-3": 403,
        "unique-3": 315,
        "entropy-3": 8.472974848549043,
        "cond_entropy-3": 0.608313506664525,
        "total_length-nopunct": 523,
        "mean_pred_length-nopunct": 27.526315789473685,
        "std_pred_length-nopunct": 16.265457170116942,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.26577437858508607,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 4.756183660490233,
        "distinct-2-nopunct": 0.5436507936507936,
        "vocab_size-2-nopunct": 274,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.690061916638339,
        "cond_entropy-2-nopunct": 2.9943299763181046,
        "distinct-3-nopunct": 0.7422680412371134,
        "vocab_size-3-nopunct": 360,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 8.30503091131872,
        "cond_entropy-3-nopunct": 0.6420519102173379,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 3.72868,
        "local_recall": {
            "1": 0.0736196319018405,
            "2": 0.22916666666666666,
            "3": 0.31521739130434784
        },
        "rouge1": {
            "precision": 0.32331,
            "recall": 0.28906,
            "fmeasure": 0.3031
        },
        "rouge2": {
            "precision": 0.24269,
            "recall": 0.22018,
            "fmeasure": 0.2278
        },
        "rougeL": {
            "precision": 0.29825,
            "recall": 0.27109,
            "fmeasure": 0.28118
        },
        "rougeLsum": {
            "precision": 0.29825,
            "recall": 0.27109,
            "fmeasure": 0.28118
        },
        "nist": 1.137006906067441,
        "bleurt": -0.51143,
        "bertscore": {
            "precision": 0.85606,
            "recall": 0.8611,
            "f1": 0.85792
        },
        "nubia": {
            "semantic_relation": 3.07427,
            "contradiction": 35.05061,
            "irrelevancy": 15.66036,
            "logical_agreement": 49.28904,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.93182,
            "nubia_score": 0.17451
        },
        "meteor": 0.17970630641091906
    },
    "dart_validation": {
        "predictions_file": "T5-xl (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.47046,
        "msttr-100_nopunct": 0.47931,
        "total_length": 62662,
        "mean_pred_length": 22.63800578034682,
        "std_pred_length": 9.60151273967493,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 72,
        "distinct-1": 0.05944591618524784,
        "vocab_size-1": 3725,
        "unique-1": 1652,
        "entropy-1": 7.787029190355167,
        "distinct-2": 0.2102714796139847,
        "vocab_size-2": 12594,
        "unique-2": 7779,
        "entropy-2": 10.913857925944047,
        "cond_entropy-2": 2.9561705375217455,
        "distinct-3": 0.34800266078493153,
        "vocab_size-3": 19880,
        "unique-3": 14283,
        "entropy-3": 12.319495807866973,
        "cond_entropy-3": 1.4495208114327662,
        "total_length-nopunct": 56361,
        "mean_pred_length-nopunct": 20.36163294797688,
        "std_pred_length-nopunct": 8.772143850741687,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.06579017405652846,
        "vocab_size-1-nopunct": 3708,
        "unique-1-nopunct": 1647,
        "entropy-1-nopunct": 7.994129564234716,
        "distinct-2-nopunct": 0.21818147892448642,
        "vocab_size-2-nopunct": 11693,
        "unique-2-nopunct": 7415,
        "entropy-2-nopunct": 10.804157488012772,
        "cond_entropy-2-nopunct": 2.931975111444342,
        "distinct-3-nopunct": 0.35329070339399904,
        "vocab_size-3-nopunct": 17956,
        "unique-3-nopunct": 13033,
        "entropy-3-nopunct": 12.212095326552413,
        "cond_entropy-3-nopunct": 1.4474654217119234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "bleu": 0.00528,
        "local_recall": {
            "1": 0.02985715161547422,
            "2": 0.017329460082139637,
            "3": 0.014144271570014143,
            "4": 0.026005164146071562,
            "5": 0.04592171441067133,
            "6": 0.06040637012630423,
            "7": 0.08221476510067115,
            "8": 0.0935483870967742,
            "9": 0.09695603156708005,
            "10": 0.10866372980910426,
            "11": 0.10428100987925357,
            "12": 0.11232449297971919,
            "13": 0.08971553610503283,
            "14": 0.06666666666666667,
            "15": 0.07075471698113207,
            "16": 0.0763888888888889,
            "17": 0.038461538461538464,
            "18": 0.08,
            "19": 0.0625,
            "20": 0.11764705882352941,
            "21": 0.13043478260869565,
            "22": 0.0,
            "23": 0.06666666666666667,
            "24": 0.0,
            "25": 0.3333333333333333,
            "26": 0.25,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "rouge1": {
            "precision": 0.03832,
            "recall": 0.73444,
            "fmeasure": 0.07207
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.03832,
            "recall": 0.73444,
            "fmeasure": 0.07207
        },
        "rougeLsum": {
            "precision": 0.03832,
            "recall": 0.73444,
            "fmeasure": 0.07207
        },
        "nist": 0.5835877572179368,
        "bleurt": 0.1946,
        "bertscore": {
            "precision": 0.90659,
            "recall": 0.90293,
            "f1": 0.90445
        },
        "nubia": {
            "semantic_relation": 4.29101,
            "contradiction": 5.85491,
            "irrelevancy": 20.13558,
            "logical_agreement": 74.00951,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.66648,
            "nubia_score": 0.76155
        },
        "meteor": 0.07687960592732387
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "total_length": 146,
        "mean_pred_length": 29.2,
        "std_pred_length": 8.818163074019441,
        "median_pred_length": 26.0,
        "min_pred_length": 16,
        "max_pred_length": 40,
        "distinct-1": 0.6917808219178082,
        "vocab_size-1": 101,
        "unique-1": 85,
        "entropy-1": 6.24874684344441,
        "distinct-2": 0.9219858156028369,
        "vocab_size-2": 130,
        "unique-2": 123,
        "entropy-2": 6.952568884479622,
        "cond_entropy-2": 0.6548557155227608,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 133,
        "unique-3": 130,
        "entropy-3": 7.043345194191504,
        "cond_entropy-3": 0.09765066515007673,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 25.4,
        "std_pred_length-nopunct": 7.28285658241325,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.7559055118110236,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.275547481809252,
        "distinct-2-nopunct": 0.9426229508196722,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 109,
        "entropy-2-nopunct": 6.809795636725496,
        "cond_entropy-2-nopunct": 0.5634750895458436,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.819082668301332,
        "cond_entropy-3-nopunct": 0.014455480329607655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.09517,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.28125,
            "3": 0.654320987654321
        },
        "rouge1": {
            "precision": 0.57824,
            "recall": 0.56483,
            "fmeasure": 0.56456
        },
        "rouge2": {
            "precision": 0.27588,
            "recall": 0.26732,
            "fmeasure": 0.26844
        },
        "rougeL": {
            "precision": 0.39974,
            "recall": 0.39903,
            "fmeasure": 0.39408
        },
        "rougeLsum": {
            "precision": 0.39974,
            "recall": 0.39903,
            "fmeasure": 0.39408
        },
        "nist": 3.516015342632838,
        "bleurt": 0.02029,
        "bertscore": {
            "precision": 0.9004,
            "recall": 0.86751,
            "f1": 0.88336
        },
        "nubia": {
            "semantic_relation": 3.31298,
            "contradiction": 19.89887,
            "irrelevancy": 33.72445,
            "logical_agreement": 46.37668,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.06379,
            "nubia_score": 0.48343
        },
        "meteor": 0.2670073510534351
    },
    "dart_test": {
        "predictions_file": "T5-xl (Baseline)/dart_test",
        "N": 6959,
        "msttr-100": 0.50419,
        "msttr-100_nopunct": 0.52033,
        "total_length": 151275,
        "mean_pred_length": 21.738037074292283,
        "std_pred_length": 9.970782446678852,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 67,
        "distinct-1": 0.03570980003305239,
        "vocab_size-1": 5402,
        "unique-1": 1146,
        "entropy-1": 8.479657236552464,
        "distinct-2": 0.1294104603786136,
        "vocab_size-2": 18676,
        "unique-2": 4487,
        "entropy-2": 12.044676771299123,
        "cond_entropy-2": 3.350132378993168,
        "distinct-3": 0.22164869646250282,
        "vocab_size-3": 30445,
        "unique-3": 7921,
        "entropy-3": 13.491886751638228,
        "cond_entropy-3": 1.4926863199325608,
        "total_length-nopunct": 134953,
        "mean_pred_length-nopunct": 19.392585141543325,
        "std_pred_length-nopunct": 9.037367599755402,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.039932420916911814,
        "vocab_size-1-nopunct": 5389,
        "unique-1-nopunct": 1145,
        "entropy-1-nopunct": 8.781757415016395,
        "distinct-2-nopunct": 0.13598293670015782,
        "vocab_size-2-nopunct": 17405,
        "unique-2-nopunct": 4279,
        "entropy-2-nopunct": 11.950141772322528,
        "cond_entropy-2-nopunct": 3.3158412477989576,
        "distinct-3-nopunct": 0.22800842731441318,
        "vocab_size-3-nopunct": 27597,
        "unique-3-nopunct": 7268,
        "entropy-3-nopunct": 13.37352787298253,
        "cond_entropy-3-nopunct": 1.4775443862348248
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 113,
        "mean_pred_length": 28.25,
        "std_pred_length": 10.848386976873567,
        "median_pred_length": 32.0,
        "min_pred_length": 11,
        "max_pred_length": 38,
        "distinct-1": 0.6371681415929203,
        "vocab_size-1": 72,
        "unique-1": 57,
        "entropy-1": 5.844614086684867,
        "distinct-2": 0.944954128440367,
        "vocab_size-2": 103,
        "unique-2": 98,
        "entropy-2": 6.651167008243306,
        "cond_entropy-2": 0.7689589720439761,
        "distinct-3": 0.9904761904761905,
        "vocab_size-3": 104,
        "unique-3": 103,
        "entropy-3": 6.695197898618495,
        "cond_entropy-3": 0.04848869290980047,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 8.573214099741124,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7282608695652174,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.83323831470564,
        "distinct-2-nopunct": 0.9659090909090909,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.391249800455487,
        "cond_entropy-2-nopunct": 0.5893898330839998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": 0.0043143755700347005,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.00139,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6071428571428571
        },
        "rouge1": {
            "precision": 0.6506,
            "recall": 0.5755,
            "fmeasure": 0.59741
        },
        "rouge2": {
            "precision": 0.33184,
            "recall": 0.30882,
            "fmeasure": 0.3126
        },
        "rougeL": {
            "precision": 0.52298,
            "recall": 0.46742,
            "fmeasure": 0.4819
        },
        "rougeLsum": {
            "precision": 0.52298,
            "recall": 0.46742,
            "fmeasure": 0.4819
        },
        "nist": 2.9387887828313395,
        "bleurt": -0.05337,
        "bertscore": {
            "precision": 0.87647,
            "recall": 0.85487,
            "f1": 0.86401
        },
        "nubia": {
            "semantic_relation": 3.317,
            "contradiction": 7.21385,
            "irrelevancy": 65.54916,
            "logical_agreement": 27.23699,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.11601,
            "nubia_score": 0.52915
        },
        "meteor": 0.26599847960744955
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.62895,
        "msttr-100_nopunct": 0.66788,
        "total_length": 3846,
        "mean_pred_length": 10.422764227642276,
        "std_pred_length": 2.731949273063147,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.21450858034321374,
        "vocab_size-1": 825,
        "unique-1": 470,
        "entropy-1": 7.421393647760424,
        "distinct-2": 0.5176876617773943,
        "vocab_size-2": 1800,
        "unique-2": 1239,
        "entropy-2": 10.246405500354536,
        "cond_entropy-2": 2.397220390401235,
        "distinct-3": 0.6981981981981982,
        "vocab_size-3": 2170,
        "unique-3": 1734,
        "entropy-3": 10.77915152681273,
        "cond_entropy-3": 0.638018190072878,
        "total_length-nopunct": 3372,
        "mean_pred_length-nopunct": 9.138211382113822,
        "std_pred_length-nopunct": 2.4461413779572223,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.24169632265717675,
        "vocab_size-1-nopunct": 815,
        "unique-1-nopunct": 468,
        "entropy-1-nopunct": 7.6778417416170806,
        "distinct-2-nopunct": 0.48951048951048953,
        "vocab_size-2-nopunct": 1470,
        "unique-2-nopunct": 978,
        "entropy-2-nopunct": 9.927502979206263,
        "cond_entropy-2-nopunct": 2.581309147907858,
        "distinct-3-nopunct": 0.6818526955201215,
        "vocab_size-3-nopunct": 1796,
        "unique-3-nopunct": 1417,
        "entropy-3-nopunct": 10.489535861284061,
        "cond_entropy-3-nopunct": 0.6966010649842999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 57.87032,
        "local_recall": {
            "1": 0.2574152542372881,
            "2": 0.7112561174551386,
            "3": 0.8897742363877822,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.80555,
            "recall": 0.79798,
            "fmeasure": 0.79473
        },
        "rouge2": {
            "precision": 0.57583,
            "recall": 0.57088,
            "fmeasure": 0.5675
        },
        "rougeL": {
            "precision": 0.7087,
            "recall": 0.70414,
            "fmeasure": 0.7001
        },
        "rougeLsum": {
            "precision": 0.7087,
            "recall": 0.70414,
            "fmeasure": 0.7001
        },
        "nist": 9.062507662755754,
        "bleurt": 0.37327,
        "bertscore": {
            "precision": 0.94511,
            "recall": 0.94543,
            "f1": 0.9444
        },
        "nubia": {
            "semantic_relation": 4.57322,
            "contradiction": 8.15421,
            "irrelevancy": 6.73265,
            "logical_agreement": 85.11314,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.21777,
            "nubia_score": 0.8193
        },
        "meteor": 0.4604784664829381
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.66089,
        "msttr-100_nopunct": 0.70214,
        "total_length": 7933,
        "mean_pred_length": 22.665714285714287,
        "std_pred_length": 5.323234401169643,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.13412328249086097,
        "vocab_size-1": 1064,
        "unique-1": 351,
        "entropy-1": 7.920644827901106,
        "distinct-2": 0.3896874587893973,
        "vocab_size-2": 2955,
        "unique-2": 1651,
        "entropy-2": 10.79737998647168,
        "cond_entropy-2": 2.7019348770419827,
        "distinct-3": 0.5860638739112402,
        "vocab_size-3": 4239,
        "unique-3": 2949,
        "entropy-3": 11.649407183384765,
        "cond_entropy-3": 0.8977463810099845,
        "total_length-nopunct": 7013,
        "mean_pred_length-nopunct": 20.037142857142857,
        "std_pred_length-nopunct": 4.798963323426408,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.15029231427349207,
        "vocab_size-1-nopunct": 1054,
        "unique-1-nopunct": 348,
        "entropy-1-nopunct": 8.176343969628805,
        "distinct-2-nopunct": 0.4007203962179199,
        "vocab_size-2-nopunct": 2670,
        "unique-2-nopunct": 1558,
        "entropy-2-nopunct": 10.658945720478009,
        "cond_entropy-2-nopunct": 2.608780169086068,
        "distinct-3-nopunct": 0.5916363060351655,
        "vocab_size-3-nopunct": 3735,
        "unique-3-nopunct": 2657,
        "entropy-3-nopunct": 11.459533144596362,
        "cond_entropy-3-nopunct": 0.8318153605753275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.31223,
        "local_recall": {
            "1": 0.2280130293159609,
            "2": 0.5747188002142475,
            "3": 0.8811007268951194,
            "4": 0.6,
            "5": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.77022,
            "recall": 0.75689,
            "fmeasure": 0.7566
        },
        "rouge2": {
            "precision": 0.50295,
            "recall": 0.49285,
            "fmeasure": 0.49292
        },
        "rougeL": {
            "precision": 0.60757,
            "recall": 0.5966,
            "fmeasure": 0.59589
        },
        "rougeLsum": {
            "precision": 0.60757,
            "recall": 0.5966,
            "fmeasure": 0.59589
        },
        "nist": 8.697416938497145,
        "bleurt": 0.20158,
        "bertscore": {
            "precision": 0.92173,
            "recall": 0.91913,
            "f1": 0.91905
        },
        "nubia": {
            "semantic_relation": 4.46792,
            "contradiction": 8.97217,
            "irrelevancy": 7.88258,
            "logical_agreement": 83.14525,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.5198,
            "nubia_score": 0.79355
        },
        "meteor": 0.3985976168954979
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.50234,
        "local_recall": {
            "1": 0.2,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.45,
            "fmeasure": 0.51667
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.2193,
            "fmeasure": 0.2381
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.35,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.35,
            "fmeasure": 0.4
        },
        "nist": 1.537484243123729,
        "bleurt": -0.41416,
        "bertscore": {
            "precision": 0.86116,
            "recall": 0.82883,
            "f1": 0.83903
        },
        "nubia": {
            "semantic_relation": 3.15719,
            "contradiction": 83.69783,
            "irrelevancy": 5.64752,
            "logical_agreement": 10.65465,
            "grammar_ref": 5.69136,
            "grammar_hyp": 6.77699,
            "nubia_score": 0.22364
        },
        "meteor": 0.29854353876395345
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.13645,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.40238,
            "fmeasure": 0.45353
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.20648,
            "fmeasure": 0.23333
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.2619,
            "fmeasure": 0.3109
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.2619,
            "fmeasure": 0.3109
        },
        "nist": 0.9114921201656901,
        "bleurt": 0.15382,
        "bertscore": {
            "precision": 0.92313,
            "recall": 0.90678,
            "f1": 0.90382
        },
        "nubia": {
            "semantic_relation": 3.92269,
            "contradiction": 17.69819,
            "irrelevancy": 31.00273,
            "logical_agreement": 51.29908,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.6276,
            "nubia_score": 0.53399
        },
        "meteor": 0.24396432821326908
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 9.0,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.964904158123496,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.1651888075032675,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 9.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.8887896794220005,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.12362739319226908,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.42042,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.3684210526315789
        },
        "rouge1": {
            "precision": 0.57372,
            "recall": 0.35605,
            "fmeasure": 0.41825
        },
        "rouge2": {
            "precision": 0.27429,
            "recall": 0.13037,
            "fmeasure": 0.17156
        },
        "rougeL": {
            "precision": 0.49679,
            "recall": 0.26798,
            "fmeasure": 0.33471
        },
        "rougeLsum": {
            "precision": 0.49679,
            "recall": 0.26798,
            "fmeasure": 0.33471
        },
        "nist": 1.484806621415069,
        "bleurt": -0.15718,
        "bertscore": {
            "precision": 0.8998,
            "recall": 0.8109,
            "f1": 0.85119
        },
        "nubia": {
            "semantic_relation": 2.82077,
            "contradiction": 54.97764,
            "irrelevancy": 16.81868,
            "logical_agreement": 28.20368,
            "grammar_ref": 4.17,
            "grammar_hyp": 4.71997,
            "nubia_score": 0.27555
        },
        "meteor": 0.1588431919714226
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.52752,
        "msttr-100_nopunct": 0.53971,
        "total_length": 39156,
        "mean_pred_length": 23.673518742442564,
        "std_pred_length": 12.399138425252968,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.04906016957809786,
        "vocab_size-1": 1921,
        "unique-1": 519,
        "entropy-1": 8.138185955056622,
        "distinct-2": 0.19052317209748815,
        "vocab_size-2": 7145,
        "unique-2": 3177,
        "entropy-2": 11.464455407495148,
        "cond_entropy-2": 3.1420768142686786,
        "distinct-3": 0.35368779290336977,
        "vocab_size-3": 12679,
        "unique-3": 7349,
        "entropy-3": 12.706625574904681,
        "cond_entropy-3": 1.2973815146858565,
        "total_length-nopunct": 34651,
        "mean_pred_length-nopunct": 20.94981862152358,
        "std_pred_length-nopunct": 11.154483944091734,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.05512106432714785,
        "vocab_size-1-nopunct": 1910,
        "unique-1-nopunct": 519,
        "entropy-1-nopunct": 8.424225880393685,
        "distinct-2-nopunct": 0.20507924962875412,
        "vocab_size-2-nopunct": 6767,
        "unique-2-nopunct": 3225,
        "entropy-2-nopunct": 11.375564363093522,
        "cond_entropy-2-nopunct": 3.0907366607108555,
        "distinct-3-nopunct": 0.3705452573142328,
        "vocab_size-3-nopunct": 11614,
        "unique-3-nopunct": 7021,
        "entropy-3-nopunct": 12.575190726601218,
        "cond_entropy-3-nopunct": 1.2447279256424595,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.27136,
        "local_recall": {
            "1": 0.2330879113963879,
            "2": 0.5921440606571188,
            "3": 0.8764870931537598,
            "4": 0.9272727272727272,
            "5": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.77268,
            "recall": 0.75629,
            "fmeasure": 0.75815
        },
        "rouge2": {
            "precision": 0.51124,
            "recall": 0.49966,
            "fmeasure": 0.50063
        },
        "rougeL": {
            "precision": 0.61261,
            "recall": 0.59978,
            "fmeasure": 0.60078
        },
        "rougeLsum": {
            "precision": 0.61261,
            "recall": 0.59978,
            "fmeasure": 0.60078
        },
        "nist": 9.18863594292763,
        "bleurt": 0.21692,
        "bertscore": {
            "precision": 0.92497,
            "recall": 0.92325,
            "f1": 0.9228
        },
        "nubia": {
            "semantic_relation": 4.4535,
            "contradiction": 8.18723,
            "irrelevancy": 6.95149,
            "logical_agreement": 84.86128,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.59962,
            "nubia_score": 0.79143
        },
        "meteor": 0.3899058372567596
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.69152,
        "msttr-100_nopunct": 0.72,
        "total_length": 6628,
        "mean_pred_length": 13.256,
        "std_pred_length": 7.482143008523694,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 47,
        "distinct-1": 0.15691007845503924,
        "vocab_size-1": 1040,
        "unique-1": 574,
        "entropy-1": 7.870043208010372,
        "distinct-2": 0.4931462140992167,
        "vocab_size-2": 3022,
        "unique-2": 2087,
        "entropy-2": 10.8417546421406,
        "cond_entropy-2": 2.7382975815613695,
        "distinct-3": 0.7253020611229567,
        "vocab_size-3": 4082,
        "unique-3": 3362,
        "entropy-3": 11.682132603488075,
        "cond_entropy-3": 0.8717613911372855,
        "total_length-nopunct": 5809,
        "mean_pred_length-nopunct": 11.618,
        "std_pred_length-nopunct": 6.848070969258424,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1771389223618523,
        "vocab_size-1-nopunct": 1029,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 8.075206015146858,
        "distinct-2-nopunct": 0.5123375400263703,
        "vocab_size-2-nopunct": 2720,
        "unique-2-nopunct": 1930,
        "entropy-2-nopunct": 10.684314204418996,
        "cond_entropy-2-nopunct": 2.751540353352401,
        "distinct-3-nopunct": 0.7374220374220374,
        "vocab_size-3-nopunct": 3547,
        "unique-3-nopunct": 2971,
        "entropy-3-nopunct": 11.474870577705326,
        "cond_entropy-3-nopunct": 0.840363647510299,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "bleu": 30.15362,
        "local_recall": {
            "1": 0.5570469798657718
        },
        "rouge1": {
            "precision": 0.56778,
            "recall": 0.54169,
            "fmeasure": 0.54232
        },
        "rouge2": {
            "precision": 0.34422,
            "recall": 0.32334,
            "fmeasure": 0.32462
        },
        "rougeL": {
            "precision": 0.50051,
            "recall": 0.47744,
            "fmeasure": 0.47794
        },
        "rougeLsum": {
            "precision": 0.50051,
            "recall": 0.47744,
            "fmeasure": 0.47794
        },
        "nist": 6.030496098369573,
        "bleurt": -0.1452,
        "bertscore": {
            "precision": 0.86742,
            "recall": 0.86062,
            "f1": 0.86349
        },
        "nubia": {
            "semantic_relation": 3.57583,
            "contradiction": 6.47693,
            "irrelevancy": 24.0979,
            "logical_agreement": 69.42517,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.66542,
            "nubia_score": 0.62412
        },
        "meteor": 0.3081662257876962
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 182,
        "mean_pred_length": 26.0,
        "std_pred_length": 7.578164119928482,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 42,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 130,
        "unique-1": 114,
        "entropy-1": 6.643903015297141,
        "distinct-2": 0.9657142857142857,
        "vocab_size-2": 169,
        "unique-2": 166,
        "entropy-2": 7.362013166264098,
        "cond_entropy-2": 0.6258688159053599,
        "distinct-3": 1.0,
        "vocab_size-3": 168,
        "unique-3": 168,
        "entropy-3": 7.392317422778791,
        "cond_entropy-3": 0.02211607567522208,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 22.857142857142858,
        "std_pred_length-nopunct": 5.642405045180428,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.649555999635236,
        "distinct-2-nopunct": 0.9673202614379085,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.168435944166901,
        "cond_entropy-2-nopunct": 0.5365701711118503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": 0.025653431765699883,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 71.31404,
        "local_recall": {
            "1": 0.01764705882352941,
            "2": 0.13636363636363635,
            "3": 0.5333333333333333,
            "4": 0.6666666666666666,
            "5": 0.8125,
            "6": 0.9166666666666666,
            "7": 0.7333333333333333,
            "8": 0.96,
            "9": 0.9,
            "10": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.84811,
            "recall": 0.83547,
            "fmeasure": 0.84009
        },
        "rouge2": {
            "precision": 0.71529,
            "recall": 0.73101,
            "fmeasure": 0.72055
        },
        "rougeL": {
            "precision": 0.8363,
            "recall": 0.82376,
            "fmeasure": 0.82836
        },
        "rougeLsum": {
            "precision": 0.8363,
            "recall": 0.82376,
            "fmeasure": 0.82836
        },
        "nist": 7.306393171095628,
        "bleurt": 0.2229,
        "bertscore": {
            "precision": 0.96432,
            "recall": 0.96525,
            "f1": 0.96234
        },
        "nubia": {
            "semantic_relation": 4.2677,
            "contradiction": 1.99239,
            "irrelevancy": 52.29119,
            "logical_agreement": 45.71642,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.79202,
            "nubia_score": 0.6131
        },
        "meteor": 0.48930937907105315
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": 0.41,
        "msttr-100_nopunct": 0.43,
        "total_length": 161,
        "mean_pred_length": 40.25,
        "std_pred_length": 14.703315952532613,
        "median_pred_length": 36.0,
        "min_pred_length": 25,
        "max_pred_length": 64,
        "distinct-1": 0.3167701863354037,
        "vocab_size-1": 51,
        "unique-1": 27,
        "entropy-1": 4.216403482952421,
        "distinct-2": 0.6050955414012739,
        "vocab_size-2": 95,
        "unique-2": 56,
        "entropy-2": 6.36147747842018,
        "cond_entropy-2": 2.163591873144603,
        "distinct-3": 0.7189542483660131,
        "vocab_size-3": 110,
        "unique-3": 75,
        "entropy-3": 6.6406262219305425,
        "cond_entropy-3": 0.2762902342322358,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 36.25,
        "std_pred_length-nopunct": 12.577261228105266,
        "median_pred_length-nopunct": 33.5,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.3310344827586207,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 3.988822188856921,
        "distinct-2-nopunct": 0.6028368794326241,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 6.182149093819429,
        "cond_entropy-2-nopunct": 2.187829211749109,
        "distinct-3-nopunct": 0.7153284671532847,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.467634068532779,
        "cond_entropy-3-nopunct": 0.2988397851828336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.92187,
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.23076923076923078,
            "3": 0.3076923076923077
        },
        "rouge1": {
            "precision": 0.66288,
            "recall": 0.71818,
            "fmeasure": 0.68831
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.3375,
            "fmeasure": 0.31667
        },
        "rougeL": {
            "precision": 0.66288,
            "recall": 0.70455,
            "fmeasure": 0.68182
        },
        "rougeLsum": {
            "precision": 0.66288,
            "recall": 0.70455,
            "fmeasure": 0.68182
        },
        "nist": 0.9662876077196972,
        "bleurt": -0.42399,
        "bertscore": {
            "precision": 0.85634,
            "recall": 0.87455,
            "f1": 0.86505
        },
        "nubia": {
            "semantic_relation": 3.37865,
            "contradiction": 21.62614,
            "irrelevancy": 21.54733,
            "logical_agreement": 56.82653,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.70162,
            "nubia_score": 0.15277
        },
        "meteor": 0.14046803242814504
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72097,
        "msttr-100_nopunct": 0.76469,
        "total_length": 7277,
        "mean_pred_length": 20.270194986072422,
        "std_pred_length": 9.085602048622638,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3493197746324035,
        "vocab_size-1": 2542,
        "unique-1": 1841,
        "entropy-1": 9.072573604144493,
        "distinct-2": 0.8193119398670136,
        "vocab_size-2": 5668,
        "unique-2": 5217,
        "entropy-2": 12.091081062961148,
        "cond_entropy-2": 2.760173013699903,
        "distinct-3": 0.950297301417899,
        "vocab_size-3": 6233,
        "unique-3": 6100,
        "entropy-3": 12.486601610005762,
        "cond_entropy-3": 0.4156529258104046,
        "total_length-nopunct": 6448,
        "mean_pred_length-nopunct": 17.96100278551532,
        "std_pred_length-nopunct": 7.974795609364186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3926799007444169,
        "vocab_size-1-nopunct": 2532,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.424989179738812,
        "distinct-2-nopunct": 0.8438167186730169,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4770,
        "entropy-2-nopunct": 12.024778184187973,
        "cond_entropy-2-nopunct": 2.7364381967507607,
        "distinct-3-nopunct": 0.9703315881326352,
        "vocab_size-3-nopunct": 5560,
        "unique-3-nopunct": 5454,
        "entropy-3-nopunct": 12.406012635755967,
        "cond_entropy-3-nopunct": 0.4077793067418675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.56468,
        "local_recall": {
            "1": 0.04987266553480475,
            "2": 0.17113665389527458,
            "3": 0.38293216630196936,
            "4": 0.5213946117274167,
            "5": 0.6240913811007269,
            "6": 0.7379227053140096,
            "7": 0.8652157311951126
        },
        "rouge1": {
            "precision": 0.83092,
            "recall": 0.7738,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.67417,
            "recall": 0.63178,
            "fmeasure": 0.64105
        },
        "rougeL": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "rougeLsum": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "nist": 10.87722683854598,
        "bleurt": 0.17013,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.93981,
            "f1": 0.94171
        },
        "nubia": {
            "semantic_relation": 4.25223,
            "contradiction": 4.92643,
            "irrelevancy": 18.75903,
            "logical_agreement": 76.31454,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.91024,
            "nubia_score": 0.68324
        },
        "meteor": 0.44445575759907224
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.50057,
        "msttr-100_nopunct": 0.51516,
        "total_length": 3539,
        "mean_pred_length": 28.312,
        "std_pred_length": 9.580326508005873,
        "median_pred_length": 28.0,
        "min_pred_length": 8,
        "max_pred_length": 53,
        "distinct-1": 0.13506640293868324,
        "vocab_size-1": 478,
        "unique-1": 145,
        "entropy-1": 7.151838726427331,
        "distinct-2": 0.3655536028119508,
        "vocab_size-2": 1248,
        "unique-2": 643,
        "entropy-2": 9.613402649500468,
        "cond_entropy-2": 2.3436416297542766,
        "distinct-3": 0.5469747643660687,
        "vocab_size-3": 1799,
        "unique-3": 1191,
        "entropy-3": 10.370007152217395,
        "cond_entropy-3": 0.7763630570618053,
        "total_length-nopunct": 3168,
        "mean_pred_length-nopunct": 25.344,
        "std_pred_length-nopunct": 8.835477576226426,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.14898989898989898,
        "vocab_size-1-nopunct": 472,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 7.292327804254571,
        "distinct-2-nopunct": 0.38218862964180084,
        "vocab_size-2-nopunct": 1163,
        "unique-2-nopunct": 622,
        "entropy-2-nopunct": 9.531253002112132,
        "cond_entropy-2-nopunct": 2.3108680175586804,
        "distinct-3-nopunct": 0.5651130911583276,
        "vocab_size-3-nopunct": 1649,
        "unique-3-nopunct": 1116,
        "entropy-3-nopunct": 10.263766625525589,
        "cond_entropy-3-nopunct": 0.7364478165595724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 38.00191,
        "local_recall": {
            "1": 0.21326397919375814,
            "2": 0.4868913857677903,
            "3": 0.8285714285714286
        },
        "rouge1": {
            "precision": 0.71714,
            "recall": 0.68734,
            "fmeasure": 0.6937
        },
        "rouge2": {
            "precision": 0.42614,
            "recall": 0.40513,
            "fmeasure": 0.40932
        },
        "rougeL": {
            "precision": 0.53476,
            "recall": 0.51134,
            "fmeasure": 0.51513
        },
        "rougeLsum": {
            "precision": 0.53476,
            "recall": 0.51134,
            "fmeasure": 0.51513
        },
        "nist": 7.1023360046904696,
        "bleurt": 0.06894,
        "bertscore": {
            "precision": 0.90676,
            "recall": 0.89593,
            "f1": 0.8999
        },
        "nubia": {
            "semantic_relation": 4.11543,
            "contradiction": 11.19965,
            "irrelevancy": 7.99201,
            "logical_agreement": 80.80835,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.31217,
            "nubia_score": 0.69889
        },
        "meteor": 0.34387692793877195
    },
    "xsum_validation": {
        "predictions_file": "T5-xl (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.74059,
        "msttr-100_nopunct": 0.76277,
        "total_length": 23729,
        "mean_pred_length": 21.24350940017905,
        "std_pred_length": 4.953658608614391,
        "median_pred_length": 21.0,
        "min_pred_length": 1,
        "max_pred_length": 42,
        "distinct-1": 0.20582409709637994,
        "vocab_size-1": 4884,
        "unique-1": 2930,
        "entropy-1": 9.299680561987909,
        "distinct-2": 0.6609764726693791,
        "vocab_size-2": 14946,
        "unique-2": 12562,
        "entropy-2": 13.168447231646956,
        "cond_entropy-2": 3.6294118424765203,
        "distinct-3": 0.8890956457015259,
        "vocab_size-3": 19112,
        "unique-3": 17937,
        "entropy-3": 14.071005905182064,
        "cond_entropy-3": 0.8980622292889205,
        "total_length-nopunct": 22052,
        "mean_pred_length-nopunct": 19.742166517457477,
        "std_pred_length-nopunct": 4.7469298335082275,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.22079629965536005,
        "vocab_size-1-nopunct": 4869,
        "unique-1-nopunct": 2927,
        "entropy-1-nopunct": 9.500171363235829,
        "distinct-2-nopunct": 0.6716660298051204,
        "vocab_size-2-nopunct": 14062,
        "unique-2-nopunct": 11882,
        "entropy-2-nopunct": 13.104026689658323,
        "cond_entropy-2-nopunct": 3.7175699445192354,
        "distinct-3-nopunct": 0.9005549949545913,
        "vocab_size-3-nopunct": 17849,
        "unique-3-nopunct": 16821,
        "entropy-3-nopunct": 14.001826690855284,
        "cond_entropy-3-nopunct": 0.9040686376247263,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "bleu": 14.2367,
        "local_recall": {
            "1": 0.4082941814239248
        },
        "rouge1": {
            "precision": 0.46394,
            "recall": 0.43461,
            "fmeasure": 0.441
        },
        "rouge2": {
            "precision": 0.20988,
            "recall": 0.1973,
            "fmeasure": 0.19981
        },
        "rougeL": {
            "precision": 0.37205,
            "recall": 0.34882,
            "fmeasure": 0.35392
        },
        "rougeLsum": {
            "precision": 0.37205,
            "recall": 0.34882,
            "fmeasure": 0.35392
        },
        "nist": 4.659110599902766,
        "bleurt": -0.20216,
        "bertscore": {
            "precision": 0.85151,
            "recall": 0.84181,
            "f1": 0.84633
        },
        "nubia": {
            "semantic_relation": 3.2943,
            "contradiction": 13.70822,
            "irrelevancy": 62.69713,
            "logical_agreement": 23.59465,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.64023,
            "nubia_score": 0.5348
        },
        "meteor": 0.20317439602652276
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.61,
        "msttr-100_nopunct": NaN,
        "total_length": 130,
        "mean_pred_length": 32.5,
        "std_pred_length": 12.99038105676658,
        "median_pred_length": 34.0,
        "min_pred_length": 13,
        "max_pred_length": 49,
        "distinct-1": 0.6076923076923076,
        "vocab_size-1": 79,
        "unique-1": 62,
        "entropy-1": 5.831252937226041,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 108,
        "unique-2": 95,
        "entropy-2": 6.6308395706872,
        "cond_entropy-2": 0.7739077406294841,
        "distinct-3": 0.9426229508196722,
        "vocab_size-3": 115,
        "unique-3": 108,
        "entropy-3": 6.815983239202242,
        "cond_entropy-3": 0.19650236860725878,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 24.75,
        "std_pred_length-nopunct": 7.790218225441442,
        "median_pred_length-nopunct": 27.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7474747474747475,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.966471237196379,
        "distinct-2-nopunct": 0.9263157894736842,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.422487187278316,
        "cond_entropy-2-nopunct": 0.4734005977822892,
        "distinct-3-nopunct": 0.967032967032967,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.441860574264634,
        "cond_entropy-3-nopunct": 0.014862108790825238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.49859,
        "local_recall": {
            "1": 0.0,
            "2": 0.5909090909090909,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73876,
            "recall": 0.66145,
            "fmeasure": 0.69357
        },
        "rouge2": {
            "precision": 0.49896,
            "recall": 0.45534,
            "fmeasure": 0.47207
        },
        "rougeL": {
            "precision": 0.60096,
            "recall": 0.54813,
            "fmeasure": 0.56923
        },
        "rougeLsum": {
            "precision": 0.60096,
            "recall": 0.54813,
            "fmeasure": 0.56923
        },
        "nist": 5.325117739364828,
        "bleurt": 0.09429,
        "bertscore": {
            "precision": 0.92525,
            "recall": 0.91397,
            "f1": 0.91546
        },
        "nubia": {
            "semantic_relation": 4.01213,
            "contradiction": 2.27027,
            "irrelevancy": 18.91838,
            "logical_agreement": 78.81135,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.21072,
            "nubia_score": 0.69857
        },
        "meteor": 0.3797003409470818
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 21,
        "unique-1": 15,
        "entropy-1": 4.254195650150781,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 20,
        "entropy-2": 4.52164063634332,
        "cond_entropy-2": 0.28900874851313696,
        "distinct-3": 0.9259259259259259,
        "vocab_size-3": 25,
        "unique-3": 23,
        "entropy-3": 4.606739354015323,
        "cond_entropy-3": 0.09568072825401269,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.103909910282363,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.403856189774722,
        "cond_entropy-2-nopunct": 0.26040897177786365,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.418295834054489,
        "cond_entropy-3-nopunct": 0.024439644279765044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.6119,
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.56897,
            "recall": 0.41364,
            "fmeasure": 0.46852
        },
        "rouge2": {
            "precision": 0.17857,
            "recall": 0.10856,
            "fmeasure": 0.13265
        },
        "rougeL": {
            "precision": 0.43103,
            "recall": 0.30303,
            "fmeasure": 0.34806
        },
        "rougeLsum": {
            "precision": 0.43103,
            "recall": 0.30303,
            "fmeasure": 0.34806
        },
        "nist": 1.8561582050755836,
        "bleurt": -0.00332,
        "bertscore": {
            "precision": 0.91473,
            "recall": 0.83863,
            "f1": 0.86116
        },
        "nubia": {
            "semantic_relation": 2.29257,
            "contradiction": 89.49826,
            "irrelevancy": 8.18766,
            "logical_agreement": 2.31408,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.2022,
            "nubia_score": 0.17289
        },
        "meteor": 0.18107253557797823
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.51425,
        "msttr-100_nopunct": 0.52403,
        "total_length": 34843,
        "mean_pred_length": 23.074834437086093,
        "std_pred_length": 12.539013124570522,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.05168900496512929,
        "vocab_size-1": 1801,
        "unique-1": 516,
        "entropy-1": 8.086981579421103,
        "distinct-2": 0.19314193141931418,
        "vocab_size-2": 6438,
        "unique-2": 2866,
        "entropy-2": 11.341730624452547,
        "cond_entropy-2": 3.0668745765243584,
        "distinct-3": 0.35266945291141627,
        "vocab_size-3": 11223,
        "unique-3": 6513,
        "entropy-3": 12.532212734145173,
        "cond_entropy-3": 1.2496587848013312,
        "total_length-nopunct": 30871,
        "mean_pred_length-nopunct": 20.44437086092715,
        "std_pred_length-nopunct": 11.28337073164576,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.0579832204982022,
        "vocab_size-1-nopunct": 1790,
        "unique-1-nopunct": 516,
        "entropy-1-nopunct": 8.367575361308145,
        "distinct-2-nopunct": 0.20479547699329043,
        "vocab_size-2-nopunct": 6013,
        "unique-2-nopunct": 2834,
        "entropy-2-nopunct": 11.239128687386023,
        "cond_entropy-2-nopunct": 3.017030295948607,
        "distinct-3-nopunct": 0.36540878244946323,
        "vocab_size-3-nopunct": 10177,
        "unique-3-nopunct": 6083,
        "entropy-3-nopunct": 12.390266738342184,
        "cond_entropy-3-nopunct": 1.1996171067010946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.4983,
        "local_recall": {
            "1": 0.24032166239681185,
            "2": 0.601792875678226,
            "3": 0.8825138349977737,
            "4": 0.9411764705882353,
            "5": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.775,
            "recall": 0.76239,
            "fmeasure": 0.76257
        },
        "rouge2": {
            "precision": 0.51819,
            "recall": 0.50882,
            "fmeasure": 0.50876
        },
        "rougeL": {
            "precision": 0.62054,
            "recall": 0.61101,
            "fmeasure": 0.61046
        },
        "rougeLsum": {
            "precision": 0.62054,
            "recall": 0.61101,
            "fmeasure": 0.61046
        },
        "nist": 9.205930768745162,
        "bleurt": 0.23943,
        "bertscore": {
            "precision": 0.92727,
            "recall": 0.92587,
            "f1": 0.92529
        },
        "nubia": {
            "semantic_relation": 4.47186,
            "contradiction": 8.37168,
            "irrelevancy": 6.72033,
            "logical_agreement": 84.908,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.60727,
            "nubia_score": 0.79911
        },
        "meteor": 0.39591903011317503
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.04514,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.22222,
            "recall": 0.20513,
            "fmeasure": 0.21333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.19306,
            "fmeasure": 0.20598
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.19306,
            "fmeasure": 0.20598
        },
        "nist": 1.0676340391447454,
        "bleurt": -0.52876,
        "bertscore": {
            "precision": 0.73609,
            "recall": 0.73293,
            "f1": 0.7345
        },
        "nubia": {
            "semantic_relation": 1.7206,
            "contradiction": 23.35197,
            "irrelevancy": 69.19117,
            "logical_agreement": 7.45686,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.56427,
            "nubia_score": 0.12882
        },
        "meteor": 0.10613598673300165
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72097,
        "msttr-100_nopunct": 0.76469,
        "total_length": 7277,
        "mean_pred_length": 20.270194986072422,
        "std_pred_length": 9.085602048622638,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3493197746324035,
        "vocab_size-1": 2542,
        "unique-1": 1841,
        "entropy-1": 9.072573604144493,
        "distinct-2": 0.8193119398670136,
        "vocab_size-2": 5668,
        "unique-2": 5217,
        "entropy-2": 12.091081062961148,
        "cond_entropy-2": 2.760173013699903,
        "distinct-3": 0.950297301417899,
        "vocab_size-3": 6233,
        "unique-3": 6100,
        "entropy-3": 12.486601610005762,
        "cond_entropy-3": 0.4156529258104046,
        "total_length-nopunct": 6448,
        "mean_pred_length-nopunct": 17.96100278551532,
        "std_pred_length-nopunct": 7.974795609364186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3926799007444169,
        "vocab_size-1-nopunct": 2532,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.424989179738812,
        "distinct-2-nopunct": 0.8438167186730169,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4770,
        "entropy-2-nopunct": 12.024778184187973,
        "cond_entropy-2-nopunct": 2.7364381967507607,
        "distinct-3-nopunct": 0.9703315881326352,
        "vocab_size-3-nopunct": 5560,
        "unique-3-nopunct": 5454,
        "entropy-3-nopunct": 12.406012635755967,
        "cond_entropy-3-nopunct": 0.4077793067418675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.56468,
        "local_recall": {
            "1": 0.04987266553480475,
            "2": 0.17113665389527458,
            "3": 0.38293216630196936,
            "4": 0.5213946117274167,
            "5": 0.6240913811007269,
            "6": 0.7379227053140096,
            "7": 0.8652157311951126
        },
        "rouge1": {
            "precision": 0.83092,
            "recall": 0.7738,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.67417,
            "recall": 0.63178,
            "fmeasure": 0.64105
        },
        "rougeL": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "rougeLsum": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "nist": 10.87722683854598,
        "bleurt": 0.17013,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.93981,
            "f1": 0.94171
        },
        "nubia": {
            "semantic_relation": 4.25223,
            "contradiction": 4.92643,
            "irrelevancy": 18.75903,
            "logical_agreement": 76.31454,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.91024,
            "nubia_score": 0.68324
        },
        "meteor": 0.44445575759907224
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.73569,
        "msttr-100_nopunct": 0.77762,
        "total_length": 7220,
        "mean_pred_length": 20.11142061281337,
        "std_pred_length": 9.294252450978925,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.371606648199446,
        "vocab_size-1": 2683,
        "unique-1": 2037,
        "entropy-1": 9.157701990174063,
        "distinct-2": 0.8310741874362337,
        "vocab_size-2": 5702,
        "unique-2": 5296,
        "entropy-2": 12.119310485322405,
        "cond_entropy-2": 2.696971166823626,
        "distinct-3": 0.9546293448169794,
        "vocab_size-3": 6207,
        "unique-3": 6093,
        "entropy-3": 12.489165894932759,
        "cond_entropy-3": 0.3916407653260913,
        "total_length-nopunct": 6393,
        "mean_pred_length-nopunct": 17.807799442896936,
        "std_pred_length-nopunct": 8.212996386351822,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4179571406225559,
        "vocab_size-1-nopunct": 2672,
        "unique-1-nopunct": 2035,
        "entropy-1-nopunct": 9.524213826610366,
        "distinct-2-nopunct": 0.8551541266158436,
        "vocab_size-2-nopunct": 5160,
        "unique-2-nopunct": 4826,
        "entropy-2-nopunct": 12.048554756164915,
        "cond_entropy-2-nopunct": 2.6634828570858047,
        "distinct-3-nopunct": 0.9739207048458149,
        "vocab_size-3-nopunct": 5527,
        "unique-3-nopunct": 5437,
        "entropy-3-nopunct": 12.401799112130169,
        "cond_entropy-3-nopunct": 0.3794476690513909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "bleu": 56.54569,
        "local_recall": {
            "1": 0.0500848896434635,
            "2": 0.1698595146871009,
            "3": 0.3413566739606127,
            "4": 0.4643423137876387,
            "5": 0.6012461059190031,
            "6": 0.6950483091787439,
            "7": 0.8064146620847652
        },
        "rouge1": {
            "precision": 0.78328,
            "recall": 0.72943,
            "fmeasure": 0.74406
        },
        "rouge2": {
            "precision": 0.60348,
            "recall": 0.56176,
            "fmeasure": 0.57232
        },
        "rougeL": {
            "precision": 0.75428,
            "recall": 0.7019,
            "fmeasure": 0.71656
        },
        "rougeLsum": {
            "precision": 0.75428,
            "recall": 0.7019,
            "fmeasure": 0.71656
        },
        "nist": 10.003508073510362,
        "sari": 49.20185,
        "bleurt": -0.14233,
        "bertscore": {
            "precision": 0.92265,
            "recall": 0.92522,
            "f1": 0.9214
        },
        "nubia": {
            "semantic_relation": 4.07609,
            "contradiction": 6.77658,
            "irrelevancy": 19.25311,
            "logical_agreement": 73.97032,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.36313,
            "nubia_score": 0.59292
        },
        "meteor": 0.39827569036897686
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.92147,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.65598,
            "fmeasure": 0.64821
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "nist": 3.98168498643785,
        "bleurt": 0.29598,
        "bertscore": {
            "precision": 0.96312,
            "recall": 0.9746,
            "f1": 0.96883
        },
        "nubia": {
            "semantic_relation": 3.27873,
            "contradiction": 24.67563,
            "irrelevancy": 56.4444,
            "logical_agreement": 18.87998,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.15733,
            "nubia_score": 0.49368
        },
        "meteor": 0.47142184089545913
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.54762,
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.47059,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.35294,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.35294,
            "fmeasure": 0.42857
        },
        "nist": 1.5415400784954403,
        "bleurt": 0.10314,
        "bertscore": {
            "precision": 0.91271,
            "recall": 0.85471,
            "f1": 0.88276
        },
        "nubia": {
            "semantic_relation": 2.79502,
            "contradiction": 40.83041,
            "irrelevancy": 6.63763,
            "logical_agreement": 52.53196,
            "grammar_ref": 4.28272,
            "grammar_hyp": 3.96172,
            "nubia_score": 0.32803
        },
        "meteor": 0.24818063453983968
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.63042,
        "msttr-100_nopunct": 0.66581,
        "total_length": 4814,
        "mean_pred_length": 42.228070175438596,
        "std_pred_length": 8.655223641002996,
        "median_pred_length": 42.0,
        "min_pred_length": 21,
        "max_pred_length": 74,
        "distinct-1": 0.1663896967179061,
        "vocab_size-1": 801,
        "unique-1": 294,
        "entropy-1": 7.730746697173714,
        "distinct-2": 0.4153191489361702,
        "vocab_size-2": 1952,
        "unique-2": 1094,
        "entropy-2": 10.279776394878851,
        "cond_entropy-2": 2.45682293171497,
        "distinct-3": 0.5955080680331444,
        "vocab_size-3": 2731,
        "unique-3": 1914,
        "entropy-3": 11.033327452244144,
        "cond_entropy-3": 0.7724911646642477,
        "total_length-nopunct": 4315,
        "mean_pred_length-nopunct": 37.85087719298246,
        "std_pred_length-nopunct": 7.938615876684676,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 64,
        "distinct-1-nopunct": 0.18331402085747392,
        "vocab_size-1-nopunct": 791,
        "unique-1-nopunct": 293,
        "entropy-1-nopunct": 7.931236833526795,
        "distinct-2-nopunct": 0.4337062604141871,
        "vocab_size-2-nopunct": 1822,
        "unique-2-nopunct": 1060,
        "entropy-2-nopunct": 10.230577586323944,
        "cond_entropy-2-nopunct": 2.355521125247355,
        "distinct-3-nopunct": 0.6104722290188402,
        "vocab_size-3-nopunct": 2495,
        "unique-3-nopunct": 1791,
        "entropy-3-nopunct": 10.917732817712297,
        "cond_entropy-3-nopunct": 0.7007926815653804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 42.79057,
        "local_recall": {
            "1": 0.21347678369195924,
            "2": 0.6137992831541219,
            "3": 0.8541353383458646
        },
        "rouge1": {
            "precision": 0.73752,
            "recall": 0.70329,
            "fmeasure": 0.71515
        },
        "rouge2": {
            "precision": 0.43241,
            "recall": 0.40965,
            "fmeasure": 0.41701
        },
        "rougeL": {
            "precision": 0.49823,
            "recall": 0.48091,
            "fmeasure": 0.48574
        },
        "rougeLsum": {
            "precision": 0.49823,
            "recall": 0.48091,
            "fmeasure": 0.48574
        },
        "nist": 7.9945129587489365,
        "bleurt": 0.06771,
        "bertscore": {
            "precision": 0.90736,
            "recall": 0.89999,
            "f1": 0.9024
        },
        "nubia": {
            "semantic_relation": 4.16183,
            "contradiction": 8.1154,
            "irrelevancy": 8.97214,
            "logical_agreement": 82.91246,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.09733,
            "nubia_score": 0.72574
        },
        "meteor": 0.3506356517624765
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.64875,
        "msttr-100_nopunct": 0.69077,
        "total_length": 8880,
        "mean_pred_length": 29.114754098360656,
        "std_pred_length": 6.876661314996669,
        "median_pred_length": 28.0,
        "min_pred_length": 12,
        "max_pred_length": 55,
        "distinct-1": 0.13423423423423422,
        "vocab_size-1": 1192,
        "unique-1": 415,
        "entropy-1": 7.999594939643423,
        "distinct-2": 0.3919533527696793,
        "vocab_size-2": 3361,
        "unique-2": 1878,
        "entropy-2": 10.951708054877162,
        "cond_entropy-2": 2.809393247177813,
        "distinct-3": 0.5931076178960096,
        "vocab_size-3": 4905,
        "unique-3": 3440,
        "entropy-3": 11.852351774425552,
        "cond_entropy-3": 0.9315787906032226,
        "total_length-nopunct": 7867,
        "mean_pred_length-nopunct": 25.79344262295082,
        "std_pred_length-nopunct": 6.266221410969934,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.15037498411084277,
        "vocab_size-1-nopunct": 1183,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 8.267432351595978,
        "distinct-2-nopunct": 0.41073790002644806,
        "vocab_size-2-nopunct": 3106,
        "unique-2-nopunct": 1808,
        "entropy-2-nopunct": 10.88061107763074,
        "cond_entropy-2-nopunct": 2.711743106753336,
        "distinct-3-nopunct": 0.609893895549125,
        "vocab_size-3-nopunct": 4426,
        "unique-3-nopunct": 3189,
        "entropy-3-nopunct": 11.719752510808883,
        "cond_entropy-3-nopunct": 0.8632530544696881,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 44.42918,
        "local_recall": {
            "1": 0.22327923894795748,
            "2": 0.5790424570912376,
            "3": 0.8561079190607045
        },
        "rouge1": {
            "precision": 0.74145,
            "recall": 0.71933,
            "fmeasure": 0.72351
        },
        "rouge2": {
            "precision": 0.4587,
            "recall": 0.44308,
            "fmeasure": 0.4461
        },
        "rougeL": {
            "precision": 0.55463,
            "recall": 0.53628,
            "fmeasure": 0.53966
        },
        "rougeLsum": {
            "precision": 0.55463,
            "recall": 0.53628,
            "fmeasure": 0.53966
        },
        "nist": 8.531681740933692,
        "bleurt": 0.1344,
        "bertscore": {
            "precision": 0.91171,
            "recall": 0.90748,
            "f1": 0.90816
        },
        "nubia": {
            "semantic_relation": 4.30943,
            "contradiction": 9.969,
            "irrelevancy": 7.99353,
            "logical_agreement": 82.03747,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.28274,
            "nubia_score": 0.74613
        },
        "meteor": 0.37102804899383834
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 37.0,
        "std_pred_length": 0.0,
        "median_pred_length": 37.0,
        "min_pred_length": 37,
        "max_pred_length": 37,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.3656890156593935,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.84743498826351,
        "cond_entropy-2": 0.5051838712143853,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.2910620290579914,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 32,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.274397470347699,
        "distinct-2-nopunct": 0.8709677419354839,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.57969177895343,
        "cond_entropy-2-nopunct": 0.32870084182032067,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": 0.33968230103620356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.10467,
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.6129,
            "recall": 0.63333,
            "fmeasure": 0.62295
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "nist": 4.231300971690577,
        "bleurt": 0.16886,
        "bertscore": {
            "precision": 0.97984,
            "recall": 0.98469,
            "f1": 0.98226
        },
        "nubia": {
            "semantic_relation": 2.81049,
            "contradiction": 65.54044,
            "irrelevancy": 27.70076,
            "logical_agreement": 6.75881,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.78477,
            "nubia_score": 0.31902
        },
        "meteor": 0.41111102167313035
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.55538,
        "msttr-100_nopunct": 0.57609,
        "total_length": 7852,
        "mean_pred_length": 29.189591078066915,
        "std_pred_length": 9.106419741145684,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 56,
        "distinct-1": 0.1162761079979623,
        "vocab_size-1": 913,
        "unique-1": 375,
        "entropy-1": 7.646304075720299,
        "distinct-2": 0.34986153237504947,
        "vocab_size-2": 2653,
        "unique-2": 1524,
        "entropy-2": 10.522970453537507,
        "cond_entropy-2": 2.7490943652543693,
        "distinct-3": 0.5468963631391851,
        "vocab_size-3": 4000,
        "unique-3": 2780,
        "entropy-3": 11.472634615583582,
        "cond_entropy-3": 0.9775406335508248,
        "total_length-nopunct": 6948,
        "mean_pred_length-nopunct": 25.828996282527882,
        "std_pred_length-nopunct": 8.389259780320087,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.12996545768566495,
        "vocab_size-1-nopunct": 903,
        "unique-1-nopunct": 371,
        "entropy-1-nopunct": 7.8524213664539815,
        "distinct-2-nopunct": 0.3705644557568498,
        "vocab_size-2-nopunct": 2475,
        "unique-2-nopunct": 1494,
        "entropy-2-nopunct": 10.43709462374341,
        "cond_entropy-2-nopunct": 2.6700369523014484,
        "distinct-3-nopunct": 0.5702028081123245,
        "vocab_size-3-nopunct": 3655,
        "unique-3-nopunct": 2639,
        "entropy-3-nopunct": 11.350294801742052,
        "cond_entropy-3-nopunct": 0.9293329141470053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 38.1751,
        "local_recall": {
            "1": 0.1939591353272135,
            "2": 0.5008246289169873,
            "3": 0.8301137867160624,
            "4": 0.75,
            "5": 1.0
        },
        "rouge1": {
            "precision": 0.73382,
            "recall": 0.69,
            "fmeasure": 0.7034
        },
        "rouge2": {
            "precision": 0.43271,
            "recall": 0.40431,
            "fmeasure": 0.41257
        },
        "rougeL": {
            "precision": 0.53188,
            "recall": 0.49564,
            "fmeasure": 0.50663
        },
        "rougeLsum": {
            "precision": 0.53188,
            "recall": 0.49564,
            "fmeasure": 0.50663
        },
        "nist": 7.62678189921944,
        "bleurt": 0.02177,
        "bertscore": {
            "precision": 0.90355,
            "recall": 0.89586,
            "f1": 0.89819
        },
        "nubia": {
            "semantic_relation": 4.19333,
            "contradiction": 8.55168,
            "irrelevancy": 8.73259,
            "logical_agreement": 82.71573,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.42313,
            "nubia_score": 0.70529
        },
        "meteor": 0.34378654831081557
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.52544,
        "msttr-100_nopunct": 0.54202,
        "total_length": 28516,
        "mean_pred_length": 21.57034795763994,
        "std_pred_length": 11.021364126149019,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.05691541590685931,
        "vocab_size-1": 1623,
        "unique-1": 526,
        "entropy-1": 7.973456878437587,
        "distinct-2": 0.20633227917923072,
        "vocab_size-2": 5611,
        "unique-2": 2609,
        "entropy-2": 11.208493563444165,
        "cond_entropy-2": 3.0366875204739454,
        "distinct-3": 0.37244897959183676,
        "vocab_size-3": 9636,
        "unique-3": 5695,
        "entropy-3": 12.385339628614384,
        "cond_entropy-3": 1.230545316859149,
        "total_length-nopunct": 25307,
        "mean_pred_length-nopunct": 19.142965204236006,
        "std_pred_length-nopunct": 10.036016064107876,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.06369779112498518,
        "vocab_size-1-nopunct": 1612,
        "unique-1-nopunct": 526,
        "entropy-1-nopunct": 8.236776458946226,
        "distinct-2-nopunct": 0.21813633520950595,
        "vocab_size-2-nopunct": 5232,
        "unique-2-nopunct": 2542,
        "entropy-2-nopunct": 11.106041933174875,
        "cond_entropy-2-nopunct": 3.0184295882621495,
        "distinct-3-nopunct": 0.38878347968053656,
        "vocab_size-3-nopunct": 8811,
        "unique-3-nopunct": 5390,
        "entropy-3-nopunct": 12.25705724081987,
        "cond_entropy-3-nopunct": 1.1956013080538384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.20381,
        "local_recall": {
            "1": 0.22915432151020063,
            "2": 0.5835558678847506,
            "3": 0.8648628391545495,
            "4": 0.9411764705882353,
            "5": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.77407,
            "recall": 0.75958,
            "fmeasure": 0.76034
        },
        "rouge2": {
            "precision": 0.51426,
            "recall": 0.50428,
            "fmeasure": 0.50433
        },
        "rougeL": {
            "precision": 0.62323,
            "recall": 0.61296,
            "fmeasure": 0.61249
        },
        "rougeLsum": {
            "precision": 0.62323,
            "recall": 0.61296,
            "fmeasure": 0.61249
        },
        "nist": 8.93068444971405,
        "bleurt": 0.24506,
        "bertscore": {
            "precision": 0.926,
            "recall": 0.92432,
            "f1": 0.92384
        },
        "nubia": {
            "semantic_relation": 4.43783,
            "contradiction": 8.81063,
            "irrelevancy": 7.4082,
            "logical_agreement": 83.78117,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.64363,
            "nubia_score": 0.78662
        },
        "meteor": 0.38825952526691404
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.504,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.6875,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.26667,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.5625,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.5625,
            "fmeasure": 0.5625
        },
        "nist": 3.1667597322123595,
        "bleurt": 0.15613,
        "bertscore": {
            "precision": 0.91756,
            "recall": 0.91056,
            "f1": 0.91405
        },
        "nubia": {
            "semantic_relation": 4.18864,
            "contradiction": 0.11354,
            "irrelevancy": 45.65235,
            "logical_agreement": 54.23411,
            "grammar_ref": 3.92881,
            "grammar_hyp": 4.03035,
            "nubia_score": 0.77948
        },
        "meteor": 0.32942839553573705
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.7096,
        "msttr-100_nopunct": 0.76489,
        "total_length": 10138,
        "mean_pred_length": 11.289532293986637,
        "std_pred_length": 3.947416284977821,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.33221542710593804,
        "vocab_size-1": 3368,
        "unique-1": 2496,
        "entropy-1": 9.078602940763595,
        "distinct-2": 0.703030303030303,
        "vocab_size-2": 6496,
        "unique-2": 5644,
        "entropy-2": 12.042187155613155,
        "cond_entropy-2": 2.420342840026903,
        "distinct-3": 0.8592663629824983,
        "vocab_size-3": 7168,
        "unique-3": 6599,
        "entropy-3": 12.623430997415289,
        "cond_entropy-3": 0.5545865987292963,
        "total_length-nopunct": 8835,
        "mean_pred_length-nopunct": 9.838530066815144,
        "std_pred_length-nopunct": 3.5004910345477236,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.3799660441426146,
        "vocab_size-1-nopunct": 3357,
        "unique-1-nopunct": 2495,
        "entropy-1-nopunct": 9.54876671727182,
        "distinct-2-nopunct": 0.7229431775229935,
        "vocab_size-2-nopunct": 5738,
        "unique-2-nopunct": 5054,
        "entropy-2-nopunct": 11.879642661448718,
        "cond_entropy-2-nopunct": 2.539390252574418,
        "distinct-3-nopunct": 0.8653217786617418,
        "vocab_size-3-nopunct": 6091,
        "unique-3-nopunct": 5629,
        "entropy-3-nopunct": 12.391956311627391,
        "cond_entropy-3-nopunct": 0.5915343717551733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.66246,
        "local_recall": {
            "1": 0.2529928172386273,
            "2": 0.535181236673774,
            "3": 0.7455150730534492
        },
        "rouge1": {
            "precision": 0.73293,
            "recall": 0.71732,
            "fmeasure": 0.71045
        },
        "rouge2": {
            "precision": 0.53725,
            "recall": 0.52758,
            "fmeasure": 0.52097
        },
        "rougeL": {
            "precision": 0.68834,
            "recall": 0.67749,
            "fmeasure": 0.66917
        },
        "rougeLsum": {
            "precision": 0.68834,
            "recall": 0.67749,
            "fmeasure": 0.66917
        },
        "nist": 8.622193701392714,
        "bleurt": 0.28993,
        "bertscore": {
            "precision": 0.92644,
            "recall": 0.92366,
            "f1": 0.92356
        },
        "nubia": {
            "semantic_relation": 4.0714,
            "contradiction": 9.6291,
            "irrelevancy": 32.17628,
            "logical_agreement": 58.19462,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.11054,
            "nubia_score": 0.69454
        },
        "meteor": 0.39452241538829297
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.048968687611256015,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.74723,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.0,
            "3": 0.3888888888888889
        },
        "rouge1": {
            "precision": 0.52143,
            "recall": 0.49751,
            "fmeasure": 0.50795
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.25694,
            "fmeasure": 0.2623
        },
        "rougeL": {
            "precision": 0.4619,
            "recall": 0.47106,
            "fmeasure": 0.46631
        },
        "rougeLsum": {
            "precision": 0.4619,
            "recall": 0.47106,
            "fmeasure": 0.46631
        },
        "nist": 1.9203675900376507,
        "bleurt": -0.22407,
        "bertscore": {
            "precision": 0.83934,
            "recall": 0.8395,
            "f1": 0.83745
        },
        "nubia": {
            "semantic_relation": 3.83179,
            "contradiction": 0.34544,
            "irrelevancy": 68.13844,
            "logical_agreement": 31.51612,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.76263,
            "nubia_score": 0.52054
        },
        "meteor": 0.2019703875977178
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.50518,
        "msttr-100_nopunct": 0.51256,
        "total_length": 14179,
        "mean_pred_length": 31.026258205689278,
        "std_pred_length": 13.006284030890297,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 75,
        "distinct-1": 0.09055645673178644,
        "vocab_size-1": 1284,
        "unique-1": 498,
        "entropy-1": 7.882385421804864,
        "distinct-2": 0.2810085993295438,
        "vocab_size-2": 3856,
        "unique-2": 2093,
        "entropy-2": 10.791320590868766,
        "cond_entropy-2": 2.7830295489492474,
        "distinct-3": 0.44787033546928007,
        "vocab_size-3": 5941,
        "unique-3": 3908,
        "entropy-3": 11.774692187002037,
        "cond_entropy-3": 1.0251389062648855,
        "total_length-nopunct": 12512,
        "mean_pred_length-nopunct": 27.37855579868709,
        "std_pred_length-nopunct": 11.610897115689708,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.10182225063938619,
        "vocab_size-1-nopunct": 1274,
        "unique-1-nopunct": 497,
        "entropy-1-nopunct": 8.134620483351295,
        "distinct-2-nopunct": 0.2954790543343011,
        "vocab_size-2-nopunct": 3562,
        "unique-2-nopunct": 2002,
        "entropy-2-nopunct": 10.693931984409392,
        "cond_entropy-2-nopunct": 2.6513690257951184,
        "distinct-3-nopunct": 0.46016554578375585,
        "vocab_size-3-nopunct": 5337,
        "unique-3-nopunct": 3580,
        "entropy-3-nopunct": 11.623427439666358,
        "cond_entropy-3-nopunct": 0.9589486114717127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.86346,
        "local_recall": {
            "1": 0.23593304843304844,
            "2": 0.5848522941546197,
            "3": 0.8886001948684638,
            "4": 0.75,
            "5": 1.0
        },
        "rouge1": {
            "precision": 0.75345,
            "recall": 0.72793,
            "fmeasure": 0.7342
        },
        "rouge2": {
            "precision": 0.47922,
            "recall": 0.46043,
            "fmeasure": 0.46494
        },
        "rougeL": {
            "precision": 0.56057,
            "recall": 0.53745,
            "fmeasure": 0.54346
        },
        "rougeLsum": {
            "precision": 0.56057,
            "recall": 0.53745,
            "fmeasure": 0.54346
        },
        "nist": 8.626788249024841,
        "bleurt": 0.09504,
        "bertscore": {
            "precision": 0.917,
            "recall": 0.91271,
            "f1": 0.91352
        },
        "nubia": {
            "semantic_relation": 4.40635,
            "contradiction": 7.20783,
            "irrelevancy": 5.91492,
            "logical_agreement": 86.87725,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.39368,
            "nubia_score": 0.78001
        },
        "meteor": 0.38155031035252246
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.6975,
        "msttr-100_nopunct": 0.74315,
        "total_length": 25248,
        "mean_pred_length": 13.647567567567567,
        "std_pred_length": 4.611631244139226,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 41,
        "distinct-1": 0.25451520912547526,
        "vocab_size-1": 6426,
        "unique-1": 4734,
        "entropy-1": 9.192413703496598,
        "distinct-2": 0.621848021198393,
        "vocab_size-2": 14550,
        "unique-2": 12707,
        "entropy-2": 12.644372547600264,
        "cond_entropy-2": 3.022457921191366,
        "distinct-3": 0.7963616112864303,
        "vocab_size-3": 17160,
        "unique-3": 16022,
        "entropy-3": 13.452669633259594,
        "cond_entropy-3": 0.8327301871428047,
        "total_length-nopunct": 21944,
        "mean_pred_length-nopunct": 11.861621621621621,
        "std_pred_length-nopunct": 4.0250952740199715,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.2920160408312067,
        "vocab_size-1-nopunct": 6408,
        "unique-1-nopunct": 4730,
        "entropy-1-nopunct": 9.657895066170484,
        "distinct-2-nopunct": 0.6475564845227431,
        "vocab_size-2-nopunct": 13012,
        "unique-2-nopunct": 11600,
        "entropy-2-nopunct": 12.487684646203737,
        "cond_entropy-2-nopunct": 3.0557577773551055,
        "distinct-3-nopunct": 0.8066213549660163,
        "vocab_size-3-nopunct": 14716,
        "unique-3-nopunct": 13839,
        "entropy-3-nopunct": 13.242752932472238,
        "cond_entropy-3-nopunct": 0.8686759982718916,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.54352,
        "local_recall": {
            "1": 0.23048327137546468,
            "2": 0.488545246277205,
            "3": 0.7794479547721982
        },
        "rouge1": {
            "precision": 0.75155,
            "recall": 0.73741,
            "fmeasure": 0.73133
        },
        "rouge2": {
            "precision": 0.54857,
            "recall": 0.54276,
            "fmeasure": 0.53609
        },
        "rougeL": {
            "precision": 0.68302,
            "recall": 0.67377,
            "fmeasure": 0.66632
        },
        "rougeLsum": {
            "precision": 0.68302,
            "recall": 0.67377,
            "fmeasure": 0.66632
        },
        "nist": 9.474778039337714,
        "bleurt": 0.30506,
        "bertscore": {
            "precision": 0.92697,
            "recall": 0.92581,
            "f1": 0.92458
        },
        "nubia": {
            "semantic_relation": 4.17899,
            "contradiction": 6.96673,
            "irrelevancy": 31.89665,
            "logical_agreement": 61.13662,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.71873,
            "nubia_score": 0.73078
        },
        "meteor": 0.4031743269123544
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.73243,
        "msttr-100_nopunct": 0.788,
        "total_length": 35050,
        "mean_pred_length": 15.781179648806845,
        "std_pred_length": 4.798959313743584,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 50,
        "distinct-1": 0.2484450784593438,
        "vocab_size-1": 8708,
        "unique-1": 6255,
        "entropy-1": 9.69317560287445,
        "distinct-2": 0.6595388223826495,
        "vocab_size-2": 21652,
        "unique-2": 18830,
        "entropy-2": 13.579379470428034,
        "cond_entropy-2": 3.499090641136534,
        "distinct-3": 0.8679103502352327,
        "vocab_size-3": 26565,
        "unique-3": 24896,
        "entropy-3": 14.486325402392401,
        "cond_entropy-3": 0.8938144965084287,
        "total_length-nopunct": 30512,
        "mean_pred_length-nopunct": 13.737955875731652,
        "std_pred_length-nopunct": 4.34381726773867,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.28487152595700055,
        "vocab_size-1-nopunct": 8692,
        "unique-1-nopunct": 6255,
        "entropy-1-nopunct": 10.218281974430887,
        "distinct-2-nopunct": 0.7004701141705842,
        "vocab_size-2-nopunct": 19817,
        "unique-2-nopunct": 17588,
        "entropy-2-nopunct": 13.51531386590337,
        "cond_entropy-2-nopunct": 3.4645259889335405,
        "distinct-3-nopunct": 0.8927502876869966,
        "vocab_size-3-nopunct": 23274,
        "unique-3-nopunct": 22035,
        "entropy-3-nopunct": 14.344537116552846,
        "cond_entropy-3-nopunct": 0.8846434454164642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.66983,
        "local_recall": {
            "1": 0.22309417040358745,
            "2": 0.46351256983240224,
            "3": 0.8082943504857862
        },
        "rouge1": {
            "precision": 0.77658,
            "recall": 0.7696,
            "fmeasure": 0.76269
        },
        "rouge2": {
            "precision": 0.54773,
            "recall": 0.54423,
            "fmeasure": 0.5383
        },
        "rougeL": {
            "precision": 0.66828,
            "recall": 0.6672,
            "fmeasure": 0.65866
        },
        "rougeLsum": {
            "precision": 0.66828,
            "recall": 0.6672,
            "fmeasure": 0.65866
        },
        "nist": 10.232853097357056,
        "bleurt": 0.31587,
        "bertscore": {
            "precision": 0.93219,
            "recall": 0.93331,
            "f1": 0.93115
        },
        "nubia": {
            "semantic_relation": 4.3511,
            "contradiction": 5.0414,
            "irrelevancy": 28.8655,
            "logical_agreement": 66.09309,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.76819,
            "nubia_score": 0.76476
        },
        "meteor": 0.4116506972470831
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 83,
        "mean_pred_length": 16.6,
        "std_pred_length": 4.409081537009721,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.46987951807228917,
        "vocab_size-1": 39,
        "unique-1": 15,
        "entropy-1": 4.9922575044413,
        "distinct-2": 0.6538461538461539,
        "vocab_size-2": 51,
        "unique-2": 29,
        "entropy-2": 5.521176058933569,
        "cond_entropy-2": 0.4375997727517617,
        "distinct-3": 0.7123287671232876,
        "vocab_size-3": 52,
        "unique-3": 31,
        "entropy-3": 5.614482093126591,
        "cond_entropy-3": 0.06345851090046478,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 4.019950248448356,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.9963562571440665,
        "distinct-2-nopunct": 0.676056338028169,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.451019788878814,
        "cond_entropy-2-nopunct": 0.45829531034739096,
        "distinct-3-nopunct": 0.7121212121212122,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 5.4686365436008835,
        "cond_entropy-3-nopunct": 0.040247613102814106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 8.00178,
        "local_recall": {
            "1": 0.48214285714285715
        },
        "rouge1": {
            "precision": 0.36462,
            "recall": 0.52368,
            "fmeasure": 0.41651
        },
        "rouge2": {
            "precision": 0.16679,
            "recall": 0.23485,
            "fmeasure": 0.18849
        },
        "rougeL": {
            "precision": 0.3269,
            "recall": 0.48348,
            "fmeasure": 0.37762
        },
        "rougeLsum": {
            "precision": 0.3269,
            "recall": 0.48348,
            "fmeasure": 0.37762
        },
        "nist": 1.915859924855786,
        "bleurt": -0.62452,
        "bertscore": {
            "precision": 0.8337,
            "recall": 0.84551,
            "f1": 0.83935
        },
        "nubia": {
            "semantic_relation": 2.90959,
            "contradiction": 0.72059,
            "irrelevancy": 98.53862,
            "logical_agreement": 0.74078,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.21028,
            "nubia_score": 0.41272
        },
        "meteor": 0.21156019607848736
    },
    "xsum_test": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.74665,
        "msttr-100_nopunct": 0.77013,
        "total_length": 24824,
        "mean_pred_length": 21.289879931389365,
        "std_pred_length": 4.779532242698746,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 40,
        "distinct-1": 0.20524492426683855,
        "vocab_size-1": 5095,
        "unique-1": 3041,
        "entropy-1": 9.37325337958444,
        "distinct-2": 0.6655254036689492,
        "vocab_size-2": 15745,
        "unique-2": 13234,
        "entropy-2": 13.256194099908267,
        "cond_entropy-2": 3.640660062594055,
        "distinct-3": 0.8900497954828384,
        "vocab_size-3": 20019,
        "unique-3": 18770,
        "entropy-3": 14.147387519029643,
        "cond_entropy-3": 0.8946162490348465,
        "total_length-nopunct": 23106,
        "mean_pred_length-nopunct": 19.81646655231561,
        "std_pred_length-nopunct": 4.573839010633566,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.21994287198130355,
        "vocab_size-1-nopunct": 5082,
        "unique-1-nopunct": 3040,
        "entropy-1-nopunct": 9.574965750191161,
        "distinct-2-nopunct": 0.6741112123974475,
        "vocab_size-2-nopunct": 14790,
        "unique-2-nopunct": 12503,
        "entropy-2-nopunct": 13.180100124675537,
        "cond_entropy-2-nopunct": 3.7281590763668153,
        "distinct-3-nopunct": 0.8978049484933089,
        "vocab_size-3-nopunct": 18651,
        "unique-3-nopunct": 17532,
        "entropy-3-nopunct": 14.065676071045834,
        "cond_entropy-3-nopunct": 0.9016341554817849,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 13.63901,
        "local_recall": {
            "1": 0.40602723353395653
        },
        "rouge1": {
            "precision": 0.46559,
            "recall": 0.43314,
            "fmeasure": 0.44068
        },
        "rouge2": {
            "precision": 0.20848,
            "recall": 0.19421,
            "fmeasure": 0.19724
        },
        "rougeL": {
            "precision": 0.37195,
            "recall": 0.3455,
            "fmeasure": 0.35168
        },
        "rougeLsum": {
            "precision": 0.37195,
            "recall": 0.3455,
            "fmeasure": 0.35168
        },
        "nist": 4.631253502648461,
        "bleurt": -0.20164,
        "bertscore": {
            "precision": 0.85191,
            "recall": 0.84132,
            "f1": 0.84625
        },
        "nubia": {
            "semantic_relation": 3.24573,
            "contradiction": 15.95902,
            "irrelevancy": 61.0355,
            "logical_agreement": 23.00548,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.6121,
            "nubia_score": 0.5184
        },
        "meteor": 0.20164409066721067
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72097,
        "msttr-100_nopunct": 0.76469,
        "total_length": 7277,
        "mean_pred_length": 20.270194986072422,
        "std_pred_length": 9.085602048622638,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3493197746324035,
        "vocab_size-1": 2542,
        "unique-1": 1841,
        "entropy-1": 9.072573604144493,
        "distinct-2": 0.8193119398670136,
        "vocab_size-2": 5668,
        "unique-2": 5217,
        "entropy-2": 12.091081062961148,
        "cond_entropy-2": 2.760173013699903,
        "distinct-3": 0.950297301417899,
        "vocab_size-3": 6233,
        "unique-3": 6100,
        "entropy-3": 12.486601610005762,
        "cond_entropy-3": 0.4156529258104046,
        "total_length-nopunct": 6448,
        "mean_pred_length-nopunct": 17.96100278551532,
        "std_pred_length-nopunct": 7.974795609364186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3926799007444169,
        "vocab_size-1-nopunct": 2532,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.424989179738812,
        "distinct-2-nopunct": 0.8438167186730169,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4770,
        "entropy-2-nopunct": 12.024778184187973,
        "cond_entropy-2-nopunct": 2.7364381967507607,
        "distinct-3-nopunct": 0.9703315881326352,
        "vocab_size-3-nopunct": 5560,
        "unique-3-nopunct": 5454,
        "entropy-3-nopunct": 12.406012635755967,
        "cond_entropy-3-nopunct": 0.4077793067418675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.56468,
        "local_recall": {
            "1": 0.04987266553480475,
            "2": 0.17113665389527458,
            "3": 0.38293216630196936,
            "4": 0.5213946117274167,
            "5": 0.6240913811007269,
            "6": 0.7379227053140096,
            "7": 0.8652157311951126
        },
        "rouge1": {
            "precision": 0.83092,
            "recall": 0.7738,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.67417,
            "recall": 0.63178,
            "fmeasure": 0.64105
        },
        "rougeL": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "rougeLsum": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "nist": 10.87722683854598,
        "bleurt": 0.17013,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.93981,
            "f1": 0.94171
        },
        "nubia": {
            "semantic_relation": 4.25223,
            "contradiction": 4.92643,
            "irrelevancy": 18.75903,
            "logical_agreement": 76.31454,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.91024,
            "nubia_score": 0.68324
        },
        "meteor": 0.44445575759907224
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.72408,
        "msttr-100_nopunct": 0.77845,
        "total_length": 26082,
        "mean_pred_length": 19.051862673484294,
        "std_pred_length": 5.57984200303234,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 49,
        "distinct-1": 0.2491756767119086,
        "vocab_size-1": 6499,
        "unique-1": 4592,
        "entropy-1": 9.524621861699055,
        "distinct-2": 0.6618378990814551,
        "vocab_size-2": 16356,
        "unique-2": 14059,
        "entropy-2": 13.26440405577134,
        "cond_entropy-2": 3.445618124040794,
        "distinct-3": 0.8682745030843043,
        "vocab_size-3": 20269,
        "unique-3": 18888,
        "entropy-3": 14.111562499367912,
        "cond_entropy-3": 0.8437630604608118,
        "total_length-nopunct": 22693,
        "mean_pred_length-nopunct": 16.576333089846603,
        "std_pred_length-nopunct": 4.75508825099326,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.28572687612920283,
        "vocab_size-1-nopunct": 6484,
        "unique-1-nopunct": 4591,
        "entropy-1-nopunct": 10.013378060852972,
        "distinct-2-nopunct": 0.7049334083661601,
        "vocab_size-2-nopunct": 15032,
        "unique-2-nopunct": 13231,
        "entropy-2-nopunct": 13.204129426162975,
        "cond_entropy-2-nopunct": 3.3185627291102477,
        "distinct-3-nopunct": 0.8909045352042094,
        "vocab_size-3-nopunct": 17778,
        "unique-3-nopunct": 16753,
        "entropy-3-nopunct": 13.960817334404439,
        "cond_entropy-3-nopunct": 0.7989815326673234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.37855,
        "local_recall": {
            "1": 0.22802139037433156,
            "2": 0.4627412655753726,
            "3": 0.7932137897723842
        },
        "rouge1": {
            "precision": 0.76402,
            "recall": 0.75266,
            "fmeasure": 0.74875
        },
        "rouge2": {
            "precision": 0.53093,
            "recall": 0.52572,
            "fmeasure": 0.5214
        },
        "rougeL": {
            "precision": 0.64584,
            "recall": 0.64044,
            "fmeasure": 0.63457
        },
        "rougeLsum": {
            "precision": 0.64584,
            "recall": 0.64044,
            "fmeasure": 0.63457
        },
        "nist": 9.90103890939473,
        "bleurt": 0.28146,
        "bertscore": {
            "precision": 0.92951,
            "recall": 0.92956,
            "f1": 0.92792
        },
        "nubia": {
            "semantic_relation": 4.26244,
            "contradiction": 6.68778,
            "irrelevancy": 31.47742,
            "logical_agreement": 61.8348,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.42224,
            "nubia_score": 0.75486
        },
        "meteor": 0.40644869115936205
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.66892,
        "msttr-100_nopunct": 0.69848,
        "total_length": 3744,
        "mean_pred_length": 47.392405063291136,
        "std_pred_length": 10.829422792242388,
        "median_pred_length": 47.0,
        "min_pred_length": 27,
        "max_pred_length": 75,
        "distinct-1": 0.1752136752136752,
        "vocab_size-1": 656,
        "unique-1": 278,
        "entropy-1": 7.6583814035224735,
        "distinct-2": 0.4158253751705321,
        "vocab_size-2": 1524,
        "unique-2": 895,
        "entropy-2": 9.969288568033877,
        "cond_entropy-2": 2.233676849758632,
        "distinct-3": 0.5607919687674289,
        "vocab_size-3": 2011,
        "unique-3": 1406,
        "entropy-3": 10.55529489765985,
        "cond_entropy-3": 0.6015499221102283,
        "total_length-nopunct": 3332,
        "mean_pred_length-nopunct": 42.177215189873415,
        "std_pred_length-nopunct": 9.634799129724968,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.19417767106842737,
        "vocab_size-1-nopunct": 647,
        "unique-1-nopunct": 277,
        "entropy-1-nopunct": 7.856818652569153,
        "distinct-2-nopunct": 0.43590531816784506,
        "vocab_size-2-nopunct": 1418,
        "unique-2-nopunct": 863,
        "entropy-2-nopunct": 9.903884459228236,
        "cond_entropy-2-nopunct": 2.088114457815907,
        "distinct-3-nopunct": 0.5797101449275363,
        "vocab_size-3-nopunct": 1840,
        "unique-3-nopunct": 1319,
        "entropy-3-nopunct": 10.442216435066348,
        "cond_entropy-3-nopunct": 0.5450289442940297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 46.81542,
        "local_recall": {
            "1": 0.26750700280112044,
            "2": 0.4966974900924703,
            "3": 0.8633504859919954
        },
        "rouge1": {
            "precision": 0.76699,
            "recall": 0.69668,
            "fmeasure": 0.72568
        },
        "rouge2": {
            "precision": 0.47051,
            "recall": 0.42538,
            "fmeasure": 0.44374
        },
        "rougeL": {
            "precision": 0.5087,
            "recall": 0.45994,
            "fmeasure": 0.47975
        },
        "rougeLsum": {
            "precision": 0.5087,
            "recall": 0.45994,
            "fmeasure": 0.47975
        },
        "nist": 7.944182367888971,
        "bleurt": -0.00215,
        "bertscore": {
            "precision": 0.91487,
            "recall": 0.89979,
            "f1": 0.90608
        },
        "nubia": {
            "semantic_relation": 4.16164,
            "contradiction": 6.2366,
            "irrelevancy": 5.72002,
            "logical_agreement": 88.04338,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.03277,
            "nubia_score": 0.7479
        },
        "meteor": 0.35490000181741765
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.43366,
        "msttr-100_nopunct": 0.43333,
        "total_length": 8253,
        "mean_pred_length": 24.345132743362832,
        "std_pred_length": 10.17844032262597,
        "median_pred_length": 22.0,
        "min_pred_length": 7,
        "max_pred_length": 62,
        "distinct-1": 0.13449654671028716,
        "vocab_size-1": 1110,
        "unique-1": 630,
        "entropy-1": 5.672316069834824,
        "distinct-2": 0.3272681324235532,
        "vocab_size-2": 2590,
        "unique-2": 1664,
        "entropy-2": 9.781553642606369,
        "cond_entropy-2": 4.063935449178847,
        "distinct-3": 0.5201320132013202,
        "vocab_size-3": 3940,
        "unique-3": 2886,
        "entropy-3": 11.081439106965508,
        "cond_entropy-3": 1.3674338005738016,
        "total_length-nopunct": 7579,
        "mean_pred_length-nopunct": 22.35693215339233,
        "std_pred_length-nopunct": 9.831292404985673,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.14553371157144743,
        "vocab_size-1-nopunct": 1103,
        "unique-1-nopunct": 630,
        "entropy-1-nopunct": 5.561067751868359,
        "distinct-2-nopunct": 0.3149171270718232,
        "vocab_size-2-nopunct": 2280,
        "unique-2-nopunct": 1436,
        "entropy-2-nopunct": 9.561722866457584,
        "cond_entropy-2-nopunct": 4.180673402245385,
        "distinct-3-nopunct": 0.5057238081437473,
        "vocab_size-3-nopunct": 3490,
        "unique-3-nopunct": 2542,
        "entropy-3-nopunct": 10.86213202201444,
        "cond_entropy-3-nopunct": 1.3729586401004363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.32525,
        "local_recall": {
            "1": 0.10069144338807261,
            "2": 0.16228467815049863,
            "3": 0.20812182741116753,
            "4": 0.2222222222222222,
            "5": 0.4,
            "6": 0.16666666666666666,
            "7": 0.25
        },
        "rouge1": {
            "precision": 0.28732,
            "recall": 0.28808,
            "fmeasure": 0.28628
        },
        "rouge2": {
            "precision": 0.14549,
            "recall": 0.14036,
            "fmeasure": 0.14187
        },
        "rougeL": {
            "precision": 0.28609,
            "recall": 0.28697,
            "fmeasure": 0.28512
        },
        "rougeLsum": {
            "precision": 0.28609,
            "recall": 0.28697,
            "fmeasure": 0.28512
        },
        "nist": 0.9364727454022114,
        "bleurt": -0.40479,
        "bertscore": {
            "precision": 0.86608,
            "recall": 0.87817,
            "f1": 0.87166
        },
        "nubia": {
            "semantic_relation": 3.32066,
            "contradiction": 35.66953,
            "irrelevancy": 15.7935,
            "logical_agreement": 48.53696,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.89582,
            "nubia_score": 0.20015
        },
        "meteor": 0.13252303280876146
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72097,
        "msttr-100_nopunct": 0.76469,
        "total_length": 7277,
        "mean_pred_length": 20.270194986072422,
        "std_pred_length": 9.085602048622638,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3493197746324035,
        "vocab_size-1": 2542,
        "unique-1": 1841,
        "entropy-1": 9.072573604144493,
        "distinct-2": 0.8193119398670136,
        "vocab_size-2": 5668,
        "unique-2": 5217,
        "entropy-2": 12.091081062961148,
        "cond_entropy-2": 2.760173013699903,
        "distinct-3": 0.950297301417899,
        "vocab_size-3": 6233,
        "unique-3": 6100,
        "entropy-3": 12.486601610005762,
        "cond_entropy-3": 0.4156529258104046,
        "total_length-nopunct": 6448,
        "mean_pred_length-nopunct": 17.96100278551532,
        "std_pred_length-nopunct": 7.974795609364186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3926799007444169,
        "vocab_size-1-nopunct": 2532,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.424989179738812,
        "distinct-2-nopunct": 0.8438167186730169,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4770,
        "entropy-2-nopunct": 12.024778184187973,
        "cond_entropy-2-nopunct": 2.7364381967507607,
        "distinct-3-nopunct": 0.9703315881326352,
        "vocab_size-3-nopunct": 5560,
        "unique-3-nopunct": 5454,
        "entropy-3-nopunct": 12.406012635755967,
        "cond_entropy-3-nopunct": 0.4077793067418675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.56468,
        "local_recall": {
            "1": 0.04987266553480475,
            "2": 0.17113665389527458,
            "3": 0.38293216630196936,
            "4": 0.5213946117274167,
            "5": 0.6240913811007269,
            "6": 0.7379227053140096,
            "7": 0.8652157311951126
        },
        "rouge1": {
            "precision": 0.83092,
            "recall": 0.7738,
            "fmeasure": 0.78905
        },
        "rouge2": {
            "precision": 0.67417,
            "recall": 0.63178,
            "fmeasure": 0.64105
        },
        "rougeL": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "rougeLsum": {
            "precision": 0.7957,
            "recall": 0.74665,
            "fmeasure": 0.75803
        },
        "nist": 10.87722683854598,
        "bleurt": 0.17013,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.93981,
            "f1": 0.94171
        },
        "nubia": {
            "semantic_relation": 4.25223,
            "contradiction": 4.92643,
            "irrelevancy": 18.75903,
            "logical_agreement": 76.31454,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.91024,
            "nubia_score": 0.68324
        },
        "meteor": 0.44445575759907224
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.53472,
        "msttr-100_nopunct": 0.53975,
        "total_length": 8937,
        "mean_pred_length": 17.874,
        "std_pred_length": 6.3895323772557875,
        "median_pred_length": 17.0,
        "min_pred_length": 2,
        "max_pred_length": 36,
        "distinct-1": 0.06568199619559136,
        "vocab_size-1": 587,
        "unique-1": 239,
        "entropy-1": 6.245089054563523,
        "distinct-2": 0.19106317411402157,
        "vocab_size-2": 1612,
        "unique-2": 841,
        "entropy-2": 8.883229232055118,
        "cond_entropy-2": 2.577495967117964,
        "distinct-3": 0.29784553357691823,
        "vocab_size-3": 2364,
        "unique-3": 1470,
        "entropy-3": 9.599753384030205,
        "cond_entropy-3": 0.7858703278713106,
        "total_length-nopunct": 8148,
        "mean_pred_length-nopunct": 16.296,
        "std_pred_length-nopunct": 6.079505243027594,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.07155130093274423,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 6.226065889974755,
        "distinct-2-nopunct": 0.18606171548117154,
        "vocab_size-2-nopunct": 1423,
        "unique-2-nopunct": 729,
        "entropy-2-nopunct": 8.706648794107261,
        "cond_entropy-2-nopunct": 2.6411153826099105,
        "distinct-3-nopunct": 0.2985032871730312,
        "vocab_size-3-nopunct": 2134,
        "unique-3-nopunct": 1342,
        "entropy-3-nopunct": 9.448434759528753,
        "cond_entropy-3-nopunct": 0.8056043263476967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 3.27758,
        "local_recall": {
            "1": 0.2867458653622176
        },
        "rouge1": {
            "precision": 0.42236,
            "recall": 0.478,
            "fmeasure": 0.42884
        },
        "rouge2": {
            "precision": 0.22211,
            "recall": 0.25411,
            "fmeasure": 0.22572
        },
        "rougeL": {
            "precision": 0.37026,
            "recall": 0.42015,
            "fmeasure": 0.37634
        },
        "rougeLsum": {
            "precision": 0.37026,
            "recall": 0.42015,
            "fmeasure": 0.37634
        },
        "nist": 1.466909428368199,
        "bleurt": -0.69583,
        "bertscore": {
            "precision": 0.82401,
            "recall": 0.85719,
            "f1": 0.83998
        },
        "nubia": {
            "semantic_relation": 2.78536,
            "contradiction": 30.23344,
            "irrelevancy": 26.88591,
            "logical_agreement": 42.88065,
            "grammar_ref": 6.87434,
            "grammar_hyp": 5.97871,
            "nubia_score": 0.27808
        },
        "meteor": 0.13252892023825008
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.622,
        "msttr-100_nopunct": 0.66077,
        "total_length": 3017,
        "mean_pred_length": 10.158249158249157,
        "std_pred_length": 2.682755938607844,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.231024196221412,
        "vocab_size-1": 697,
        "unique-1": 394,
        "entropy-1": 7.301315415857781,
        "distinct-2": 0.5470588235294118,
        "vocab_size-2": 1488,
        "unique-2": 1045,
        "entropy-2": 10.01695624139109,
        "cond_entropy-2": 2.2850422911597708,
        "distinct-3": 0.732150226991333,
        "vocab_size-3": 1774,
        "unique-3": 1447,
        "entropy-3": 10.531845695392494,
        "cond_entropy-3": 0.6060177289645069,
        "total_length-nopunct": 2648,
        "mean_pred_length-nopunct": 8.915824915824915,
        "std_pred_length-nopunct": 2.439086614172009,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.25944108761329304,
        "vocab_size-1-nopunct": 687,
        "unique-1-nopunct": 391,
        "entropy-1-nopunct": 7.559882709069311,
        "distinct-2-nopunct": 0.521054870267971,
        "vocab_size-2-nopunct": 1225,
        "unique-2-nopunct": 839,
        "entropy-2-nopunct": 9.704811774299756,
        "cond_entropy-2-nopunct": 2.463705002540278,
        "distinct-3-nopunct": 0.7161635832521909,
        "vocab_size-3-nopunct": 1471,
        "unique-3-nopunct": 1187,
        "entropy-3-nopunct": 10.242495538795993,
        "cond_entropy-3-nopunct": 0.6685643728778777,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 60.18846,
        "local_recall": {
            "1": 0.25718194254445964,
            "2": 0.7264248704663212,
            "3": 0.8980458793542906,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.81334,
            "recall": 0.80853,
            "fmeasure": 0.80383
        },
        "rouge2": {
            "precision": 0.59397,
            "recall": 0.5898,
            "fmeasure": 0.5858
        },
        "rougeL": {
            "precision": 0.7225,
            "recall": 0.72035,
            "fmeasure": 0.71493
        },
        "rougeLsum": {
            "precision": 0.7225,
            "recall": 0.72035,
            "fmeasure": 0.71493
        },
        "nist": 9.124447690875497,
        "bleurt": 0.41304,
        "bertscore": {
            "precision": 0.95022,
            "recall": 0.95136,
            "f1": 0.95006
        },
        "nubia": {
            "semantic_relation": 4.61094,
            "contradiction": 7.82097,
            "irrelevancy": 5.65083,
            "logical_agreement": 86.5282,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.15517,
            "nubia_score": 0.83746
        },
        "meteor": 0.4727619320886077
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68397,
        "msttr-100_nopunct": 0.71727,
        "total_length": 6392,
        "mean_pred_length": 12.784,
        "std_pred_length": 7.465744704984226,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 41,
        "distinct-1": 0.15769712140175218,
        "vocab_size-1": 1008,
        "unique-1": 558,
        "entropy-1": 7.832138073938464,
        "distinct-2": 0.49355057705363203,
        "vocab_size-2": 2908,
        "unique-2": 2044,
        "entropy-2": 10.730938268866657,
        "cond_entropy-2": 2.640557175891023,
        "distinct-3": 0.7086424332344213,
        "vocab_size-3": 3821,
        "unique-3": 3134,
        "entropy-3": 11.518950588291897,
        "cond_entropy-3": 0.7987570392519394,
        "total_length-nopunct": 5590,
        "mean_pred_length-nopunct": 11.18,
        "std_pred_length-nopunct": 6.862331965155868,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.1779964221824687,
        "vocab_size-1-nopunct": 995,
        "unique-1-nopunct": 554,
        "entropy-1-nopunct": 8.043216743593977,
        "distinct-2-nopunct": 0.5141453831041257,
        "vocab_size-2-nopunct": 2617,
        "unique-2-nopunct": 1898,
        "entropy-2-nopunct": 10.569092243666931,
        "cond_entropy-2-nopunct": 2.6563065996716126,
        "distinct-3-nopunct": 0.7244609017643215,
        "vocab_size-3-nopunct": 3326,
        "unique-3-nopunct": 2797,
        "entropy-3-nopunct": 11.307544937957424,
        "cond_entropy-3-nopunct": 0.7740189616799177,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.32475,
        "local_recall": {
            "1": 0.5771513353115727
        },
        "rouge1": {
            "precision": 0.56434,
            "recall": 0.55482,
            "fmeasure": 0.54748
        },
        "rouge2": {
            "precision": 0.34687,
            "recall": 0.34565,
            "fmeasure": 0.33889
        },
        "rougeL": {
            "precision": 0.51282,
            "recall": 0.5053,
            "fmeasure": 0.49831
        },
        "rougeLsum": {
            "precision": 0.51282,
            "recall": 0.5053,
            "fmeasure": 0.49831
        },
        "nist": 6.067824480775904,
        "bleurt": -0.05351,
        "bertscore": {
            "precision": 0.8724,
            "recall": 0.86854,
            "f1": 0.86996
        },
        "nubia": {
            "semantic_relation": 3.64053,
            "contradiction": 5.5441,
            "irrelevancy": 22.51832,
            "logical_agreement": 71.93758,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.57619,
            "nubia_score": 0.65203
        },
        "meteor": 0.321230601797918
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.6175,
        "msttr-100_nopunct": 0.64,
        "total_length": 829,
        "mean_pred_length": 11.51388888888889,
        "std_pred_length": 2.661416997033491,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.3425814234016888,
        "vocab_size-1": 284,
        "unique-1": 182,
        "entropy-1": 6.688330167261504,
        "distinct-2": 0.6710700132100397,
        "vocab_size-2": 508,
        "unique-2": 394,
        "entropy-2": 8.676668624579682,
        "cond_entropy-2": 1.687495742445043,
        "distinct-3": 0.7781021897810219,
        "vocab_size-3": 533,
        "unique-3": 454,
        "entropy-3": 8.857279475086347,
        "cond_entropy-3": 0.2592949706660221,
        "total_length-nopunct": 724,
        "mean_pred_length-nopunct": 10.055555555555555,
        "std_pred_length-nopunct": 2.2539403083445326,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.3825966850828729,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 180,
        "entropy-1-nopunct": 6.806903957018403,
        "distinct-2-nopunct": 0.6549079754601227,
        "vocab_size-2-nopunct": 427,
        "unique-2-nopunct": 322,
        "entropy-2-nopunct": 8.426398726708232,
        "cond_entropy-2-nopunct": 1.8482887483798505,
        "distinct-3-nopunct": 0.7775862068965518,
        "vocab_size-3-nopunct": 451,
        "unique-3-nopunct": 382,
        "entropy-3-nopunct": 8.62496314177972,
        "cond_entropy-3-nopunct": 0.25939757702517724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.48078,
        "local_recall": {
            "1": 0.25821596244131456,
            "2": 0.6551724137931034,
            "3": 0.8601823708206687
        },
        "rouge1": {
            "precision": 0.77341,
            "recall": 0.75443,
            "fmeasure": 0.75719
        },
        "rouge2": {
            "precision": 0.501,
            "recall": 0.49285,
            "fmeasure": 0.49201
        },
        "rougeL": {
            "precision": 0.65177,
            "recall": 0.63727,
            "fmeasure": 0.63896
        },
        "rougeLsum": {
            "precision": 0.65177,
            "recall": 0.63727,
            "fmeasure": 0.63896
        },
        "nist": 7.072865149362165,
        "bleurt": 0.20924,
        "bertscore": {
            "precision": 0.924,
            "recall": 0.92098,
            "f1": 0.92109
        },
        "nubia": {
            "semantic_relation": 4.41761,
            "contradiction": 9.52883,
            "irrelevancy": 11.19516,
            "logical_agreement": 79.27601,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.47601,
            "nubia_score": 0.7444
        },
        "meteor": 0.41828321165353166
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.65283,
        "msttr-100_nopunct": 0.69067,
        "total_length": 36818,
        "mean_pred_length": 28.43088803088803,
        "std_pred_length": 11.23107810620233,
        "median_pred_length": 27.0,
        "min_pred_length": 7,
        "max_pred_length": 75,
        "distinct-1": 0.048644684665109454,
        "vocab_size-1": 1791,
        "unique-1": 525,
        "entropy-1": 8.107028126105549,
        "distinct-2": 0.18607662641105763,
        "vocab_size-2": 6610,
        "unique-2": 2964,
        "entropy-2": 11.36018861495581,
        "cond_entropy-2": 3.104537310157187,
        "distinct-3": 0.3447177749211172,
        "vocab_size-3": 11799,
        "unique-3": 6733,
        "entropy-3": 12.606895746396912,
        "cond_entropy-3": 1.2890152126403385,
        "total_length-nopunct": 32689,
        "mean_pred_length-nopunct": 25.242471042471042,
        "std_pred_length-nopunct": 10.158202805685633,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.054452568142188504,
        "vocab_size-1-nopunct": 1780,
        "unique-1-nopunct": 524,
        "entropy-1-nopunct": 8.377631879126845,
        "distinct-2-nopunct": 0.2025227750525578,
        "vocab_size-2-nopunct": 6358,
        "unique-2-nopunct": 3043,
        "entropy-2-nopunct": 11.307542853604875,
        "cond_entropy-2-nopunct": 3.040253923918306,
        "distinct-3-nopunct": 0.3646300541546231,
        "vocab_size-3-nopunct": 10975,
        "unique-3-nopunct": 6557,
        "entropy-3-nopunct": 12.504909343292645,
        "cond_entropy-3-nopunct": 1.2277681533749785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 45.98688,
        "local_recall": {
            "1": 0.22849370962257737,
            "2": 0.5648256494266324,
            "3": 0.8695524491953482,
            "4": 0.7647058823529411,
            "5": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.75605,
            "recall": 0.7364,
            "fmeasure": 0.73995
        },
        "rouge2": {
            "precision": 0.48157,
            "recall": 0.46708,
            "fmeasure": 0.46974
        },
        "rougeL": {
            "precision": 0.57368,
            "recall": 0.5578,
            "fmeasure": 0.56044
        },
        "rougeLsum": {
            "precision": 0.57368,
            "recall": 0.5578,
            "fmeasure": 0.56044
        },
        "nist": 8.903250133554678,
        "bleurt": 0.15029,
        "bertscore": {
            "precision": 0.91693,
            "recall": 0.91343,
            "f1": 0.91376
        },
        "nubia": {
            "semantic_relation": 4.37315,
            "contradiction": 8.88555,
            "irrelevancy": 7.28903,
            "logical_agreement": 83.82542,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.39314,
            "nubia_score": 0.76998
        },
        "meteor": 0.37668138911605514
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71412,
        "total_length": 2031,
        "mean_pred_length": 17.660869565217393,
        "std_pred_length": 5.962034897031512,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 53,
        "distinct-1": 0.2619399310684392,
        "vocab_size-1": 532,
        "unique-1": 267,
        "entropy-1": 7.402053580074399,
        "distinct-2": 0.5756784968684759,
        "vocab_size-2": 1103,
        "unique-2": 761,
        "entropy-2": 9.680348797116187,
        "cond_entropy-2": 2.073379198558137,
        "distinct-3": 0.7368128817323709,
        "vocab_size-3": 1327,
        "unique-3": 1055,
        "entropy-3": 10.156605045040715,
        "cond_entropy-3": 0.5171501823899163,
        "total_length-nopunct": 1758,
        "mean_pred_length-nopunct": 15.28695652173913,
        "std_pred_length-nopunct": 5.189898578872155,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.2992036405005688,
        "vocab_size-1-nopunct": 526,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.682948334910424,
        "distinct-2-nopunct": 0.5782105903834449,
        "vocab_size-2-nopunct": 950,
        "unique-2-nopunct": 658,
        "entropy-2-nopunct": 9.468995839438712,
        "cond_entropy-2-nopunct": 1.9111102318354858,
        "distinct-3-nopunct": 0.7356020942408377,
        "vocab_size-3-nopunct": 1124,
        "unique-3-nopunct": 890,
        "entropy-3-nopunct": 9.915175064259868,
        "cond_entropy-3-nopunct": 0.4832661483607309,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 53.46439,
        "local_recall": {
            "1": 0.22248803827751196,
            "2": 0.5980952380952381,
            "3": 0.8946280991735537
        },
        "rouge1": {
            "precision": 0.79411,
            "recall": 0.77161,
            "fmeasure": 0.77577
        },
        "rouge2": {
            "precision": 0.54564,
            "recall": 0.53525,
            "fmeasure": 0.53472
        },
        "rougeL": {
            "precision": 0.65793,
            "recall": 0.64152,
            "fmeasure": 0.64323
        },
        "rougeLsum": {
            "precision": 0.65793,
            "recall": 0.64152,
            "fmeasure": 0.64323
        },
        "nist": 8.263642357957558,
        "bleurt": 0.30463,
        "bertscore": {
            "precision": 0.93107,
            "recall": 0.93303,
            "f1": 0.93037
        },
        "nubia": {
            "semantic_relation": 4.60661,
            "contradiction": 3.70383,
            "irrelevancy": 4.98363,
            "logical_agreement": 91.31254,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.6289,
            "nubia_score": 0.8429
        },
        "meteor": 0.42892225961361574
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.33,
        "msttr-100_nopunct": 0.33412,
        "total_length": 1946,
        "mean_pred_length": 16.216666666666665,
        "std_pred_length": 6.632223525250705,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.08787255909558069,
        "vocab_size-1": 171,
        "unique-1": 33,
        "entropy-1": 6.011564246959243,
        "distinct-2": 0.1955093099671413,
        "vocab_size-2": 357,
        "unique-2": 90,
        "entropy-2": 7.559856037075276,
        "cond_entropy-2": 1.418304078798147,
        "distinct-3": 0.26553341148886284,
        "vocab_size-3": 453,
        "unique-3": 144,
        "entropy-3": 8.143084946119437,
        "cond_entropy-3": 0.6320068152340595,
        "total_length-nopunct": 1779,
        "mean_pred_length-nopunct": 14.825,
        "std_pred_length-nopunct": 6.324110609405879,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.09499718943226532,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 6.0626658993781595,
        "distinct-2-nopunct": 0.1946955997588909,
        "vocab_size-2-nopunct": 323,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 7.38694466367826,
        "cond_entropy-2-nopunct": 1.4478425929636345,
        "distinct-3-nopunct": 0.2683560753736192,
        "vocab_size-3-nopunct": 413,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 8.006821927927039,
        "cond_entropy-3-nopunct": 0.6625926381624132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 21.22146,
        "local_recall": {
            "1": 0.5989340439706862
        },
        "rouge1": {
            "precision": 0.58673,
            "recall": 0.63772,
            "fmeasure": 0.57527
        },
        "rouge2": {
            "precision": 0.34234,
            "recall": 0.37081,
            "fmeasure": 0.33181
        },
        "rougeL": {
            "precision": 0.47785,
            "recall": 0.51407,
            "fmeasure": 0.46515
        },
        "rougeLsum": {
            "precision": 0.47785,
            "recall": 0.51407,
            "fmeasure": 0.46515
        },
        "nist": 3.5432526309298433,
        "bleurt": -0.28517,
        "bertscore": {
            "precision": 0.88113,
            "recall": 0.88199,
            "f1": 0.88046
        },
        "nubia": {
            "semantic_relation": 3.71741,
            "contradiction": 4.5966,
            "irrelevancy": 57.50649,
            "logical_agreement": 37.89691,
            "grammar_ref": 5.42765,
            "grammar_hyp": 5.19707,
            "nubia_score": 0.54757
        },
        "meteor": 0.29652277967044266
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.30917,
        "msttr-100_nopunct": 0.30833,
        "total_length": 7268,
        "mean_pred_length": 18.68380462724936,
        "std_pred_length": 6.103669082634869,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 45,
        "distinct-1": 0.032471106219042374,
        "vocab_size-1": 236,
        "unique-1": 33,
        "entropy-1": 6.222265013118115,
        "distinct-2": 0.11222561418810874,
        "vocab_size-2": 772,
        "unique-2": 190,
        "entropy-2": 8.23885484352735,
        "cond_entropy-2": 1.888605001745424,
        "distinct-3": 0.18135593220338983,
        "vocab_size-3": 1177,
        "unique-3": 353,
        "entropy-3": 9.13772874341037,
        "cond_entropy-3": 0.9142293589643096,
        "total_length-nopunct": 6666,
        "mean_pred_length-nopunct": 17.13624678663239,
        "std_pred_length-nopunct": 5.618958662709237,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.0351035103510351,
        "vocab_size-1-nopunct": 234,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 6.281475595160312,
        "distinct-2-nopunct": 0.11550103552652541,
        "vocab_size-2-nopunct": 725,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 8.124851514105334,
        "cond_entropy-2-nopunct": 1.9117848128552173,
        "distinct-3-nopunct": 0.1871603260869565,
        "vocab_size-3-nopunct": 1102,
        "unique-3-nopunct": 332,
        "entropy-3-nopunct": 9.064260526405759,
        "cond_entropy-3-nopunct": 0.9262376728108959,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 26.97808,
        "local_recall": {
            "1": 0.6350626118067979
        },
        "rouge1": {
            "precision": 0.65874,
            "recall": 0.65243,
            "fmeasure": 0.6386
        },
        "rouge2": {
            "precision": 0.39113,
            "recall": 0.38549,
            "fmeasure": 0.37779
        },
        "rougeL": {
            "precision": 0.50589,
            "recall": 0.4985,
            "fmeasure": 0.48963
        },
        "rougeLsum": {
            "precision": 0.50589,
            "recall": 0.4985,
            "fmeasure": 0.48963
        },
        "nist": 4.333230205140356,
        "bleurt": 0.02699,
        "bertscore": {
            "precision": 0.90063,
            "recall": 0.89555,
            "f1": 0.89755
        },
        "nubia": {
            "semantic_relation": 4.01149,
            "contradiction": 4.70332,
            "irrelevancy": 41.06241,
            "logical_agreement": 54.23427,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.91074,
            "nubia_score": 0.68165
        },
        "meteor": 0.3273937766027013
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.30408,
        "msttr-100_nopunct": 0.29831,
        "total_length": 15788,
        "mean_pred_length": 21.421981004070556,
        "std_pred_length": 4.989781132472482,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 43,
        "distinct-1": 0.017481631618951103,
        "vocab_size-1": 276,
        "unique-1": 61,
        "entropy-1": 6.027171705501262,
        "distinct-2": 0.06790246495249486,
        "vocab_size-2": 1022,
        "unique-2": 320,
        "entropy-2": 8.062985560399435,
        "cond_entropy-2": 1.9334867311773696,
        "distinct-3": 0.12672907642867123,
        "vocab_size-3": 1814,
        "unique-3": 663,
        "entropy-3": 9.171560971233031,
        "cond_entropy-3": 1.1124287895181193,
        "total_length-nopunct": 14290,
        "mean_pred_length-nopunct": 19.38941655359566,
        "std_pred_length-nopunct": 4.498339426630131,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.019174247725682294,
        "vocab_size-1-nopunct": 274,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.077867360497139,
        "distinct-2-nopunct": 0.07238249833985096,
        "vocab_size-2-nopunct": 981,
        "unique-2-nopunct": 308,
        "entropy-2-nopunct": 7.993692062938701,
        "cond_entropy-2-nopunct": 1.9684964236610372,
        "distinct-3-nopunct": 0.13412921348314608,
        "vocab_size-3-nopunct": 1719,
        "unique-3-nopunct": 621,
        "entropy-3-nopunct": 9.15251771629385,
        "cond_entropy-3-nopunct": 1.1417174882386976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 29.23821,
        "local_recall": {
            "1": 0.670935960591133
        },
        "rouge1": {
            "precision": 0.69902,
            "recall": 0.68962,
            "fmeasure": 0.68275
        },
        "rouge2": {
            "precision": 0.42042,
            "recall": 0.41378,
            "fmeasure": 0.41004
        },
        "rougeL": {
            "precision": 0.52822,
            "recall": 0.51965,
            "fmeasure": 0.5154
        },
        "rougeLsum": {
            "precision": 0.52822,
            "recall": 0.51965,
            "fmeasure": 0.5154
        },
        "nist": 4.712524540415365,
        "bleurt": 0.1265,
        "bertscore": {
            "precision": 0.9093,
            "recall": 0.90198,
            "f1": 0.90521
        },
        "nubia": {
            "semantic_relation": 4.14223,
            "contradiction": 3.83634,
            "irrelevancy": 31.70072,
            "logical_agreement": 64.46294,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.61107,
            "nubia_score": 0.73463
        },
        "meteor": 0.34732626971235603
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.43513,
        "msttr-100_nopunct": 0.42891,
        "total_length": 15006,
        "mean_pred_length": 47.4873417721519,
        "std_pred_length": 16.061092756371263,
        "median_pred_length": 46.0,
        "min_pred_length": 15,
        "max_pred_length": 85,
        "distinct-1": 0.09682793549246968,
        "vocab_size-1": 1453,
        "unique-1": 674,
        "entropy-1": 5.8027809938032435,
        "distinct-2": 0.2511232130701157,
        "vocab_size-2": 3689,
        "unique-2": 2069,
        "entropy-2": 10.028039022749242,
        "cond_entropy-2": 4.221007056717723,
        "distinct-3": 0.4448309447613747,
        "vocab_size-3": 6394,
        "unique-3": 4202,
        "entropy-3": 11.666581212811586,
        "cond_entropy-3": 1.6715045487086702,
        "total_length-nopunct": 13846,
        "mean_pred_length-nopunct": 43.81645569620253,
        "std_pred_length-nopunct": 15.420822109294892,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.10436227069189657,
        "vocab_size-1-nopunct": 1445,
        "unique-1-nopunct": 674,
        "entropy-1-nopunct": 5.697371407009357,
        "distinct-2-nopunct": 0.2528455284552846,
        "vocab_size-2-nopunct": 3421,
        "unique-2-nopunct": 1927,
        "entropy-2-nopunct": 9.887704284770743,
        "cond_entropy-2-nopunct": 4.2688876942881215,
        "distinct-3-nopunct": 0.4415771151808688,
        "vocab_size-3-nopunct": 5835,
        "unique-3-nopunct": 3888,
        "entropy-3-nopunct": 11.488534168685582,
        "cond_entropy-3-nopunct": 1.6339741947298672,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.42153,
        "local_recall": {
            "1": 0.09864104967197751,
            "2": 0.18330921369995176,
            "3": 0.23873239436619717,
            "4": 0.15789473684210525,
            "5": 0.18181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "rouge1": {
            "precision": 0.39877,
            "recall": 0.40055,
            "fmeasure": 0.39705
        },
        "rouge2": {
            "precision": 0.1886,
            "recall": 0.18725,
            "fmeasure": 0.18654
        },
        "rougeL": {
            "precision": 0.38263,
            "recall": 0.38601,
            "fmeasure": 0.38156
        },
        "rougeLsum": {
            "precision": 0.38263,
            "recall": 0.38601,
            "fmeasure": 0.38156
        },
        "nist": 0.9949871687383627,
        "bleurt": -0.50387,
        "bertscore": {
            "precision": 0.85796,
            "recall": 0.8723,
            "f1": 0.86452
        },
        "nubia": {
            "semantic_relation": 3.31447,
            "contradiction": 31.4758,
            "irrelevancy": 17.22347,
            "logical_agreement": 51.30073,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.55085,
            "nubia_score": 0.14915
        },
        "meteor": 0.1189871201008349
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.44605,
        "msttr-100_nopunct": 0.4421,
        "total_length": 11439,
        "mean_pred_length": 52.714285714285715,
        "std_pred_length": 13.589825028508061,
        "median_pred_length": 53.0,
        "min_pred_length": 15,
        "max_pred_length": 79,
        "distinct-1": 0.11941603287000611,
        "vocab_size-1": 1366,
        "unique-1": 697,
        "entropy-1": 5.891645335187475,
        "distinct-2": 0.3008376403493139,
        "vocab_size-2": 3376,
        "unique-2": 2054,
        "entropy-2": 10.068043641851876,
        "cond_entropy-2": 4.174960358078719,
        "distinct-3": 0.5078600636074512,
        "vocab_size-3": 5589,
        "unique-3": 3890,
        "entropy-3": 11.62596258253275,
        "cond_entropy-3": 1.5843387724007305,
        "total_length-nopunct": 10547,
        "mean_pred_length-nopunct": 48.6036866359447,
        "std_pred_length-nopunct": 13.179357733959693,
        "median_pred_length-nopunct": 48.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.1287569925097184,
        "vocab_size-1-nopunct": 1358,
        "unique-1-nopunct": 696,
        "entropy-1-nopunct": 5.794862709144298,
        "distinct-2-nopunct": 0.30464666021297193,
        "vocab_size-2-nopunct": 3147,
        "unique-2-nopunct": 1919,
        "entropy-2-nopunct": 9.947410396021144,
        "cond_entropy-2-nopunct": 4.221776112544944,
        "distinct-3-nopunct": 0.5074656382873529,
        "vocab_size-3-nopunct": 5132,
        "unique-3-nopunct": 3603,
        "entropy-3-nopunct": 11.474136399032679,
        "cond_entropy-3-nopunct": 1.5533335322680233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.90252,
        "local_recall": {
            "1": 0.08374233128834356,
            "2": 0.18006430868167203,
            "3": 0.289068231841526,
            "4": 0.18181818181818182
        },
        "rouge1": {
            "precision": 0.50111,
            "recall": 0.49753,
            "fmeasure": 0.49227
        },
        "rouge2": {
            "precision": 0.24603,
            "recall": 0.24509,
            "fmeasure": 0.2419
        },
        "rougeL": {
            "precision": 0.47665,
            "recall": 0.47377,
            "fmeasure": 0.46821
        },
        "rougeLsum": {
            "precision": 0.47665,
            "recall": 0.47377,
            "fmeasure": 0.46821
        },
        "nist": 1.0912644179430835,
        "bleurt": -0.51844,
        "bertscore": {
            "precision": 0.85906,
            "recall": 0.87125,
            "f1": 0.86456
        },
        "nubia": {
            "semantic_relation": 3.31914,
            "contradiction": 30.90586,
            "irrelevancy": 17.39046,
            "logical_agreement": 51.70367,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.51153,
            "nubia_score": 0.13385
        },
        "meteor": 0.12506688623748335
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.45191,
        "msttr-100_nopunct": 0.44659,
        "total_length": 8923,
        "mean_pred_length": 62.3986013986014,
        "std_pred_length": 11.967987521577777,
        "median_pred_length": 64.0,
        "min_pred_length": 32,
        "max_pred_length": 89,
        "distinct-1": 0.12652695281855877,
        "vocab_size-1": 1129,
        "unique-1": 551,
        "entropy-1": 5.924110619498871,
        "distinct-2": 0.3171981776765376,
        "vocab_size-2": 2785,
        "unique-2": 1637,
        "entropy-2": 9.98778694452663,
        "cond_entropy-2": 4.071813615052643,
        "distinct-3": 0.5240245455598008,
        "vocab_size-3": 4526,
        "unique-3": 3108,
        "entropy-3": 11.46500737065821,
        "cond_entropy-3": 1.4936923255200758,
        "total_length-nopunct": 8217,
        "mean_pred_length-nopunct": 57.46153846153846,
        "std_pred_length-nopunct": 11.537575723573479,
        "median_pred_length-nopunct": 59.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.13666788365583546,
        "vocab_size-1-nopunct": 1123,
        "unique-1-nopunct": 551,
        "entropy-1-nopunct": 5.831717499699096,
        "distinct-2-nopunct": 0.3221451572950211,
        "vocab_size-2-nopunct": 2601,
        "unique-2-nopunct": 1527,
        "entropy-2-nopunct": 9.892813607701383,
        "cond_entropy-2-nopunct": 4.110885615081112,
        "distinct-3-nopunct": 0.5241457571554659,
        "vocab_size-3-nopunct": 4157,
        "unique-3-nopunct": 2880,
        "entropy-3-nopunct": 11.322361540654928,
        "cond_entropy-3-nopunct": 1.4485213355196773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.42648,
        "local_recall": {
            "1": 0.08640061991476172,
            "2": 0.2038173142467621,
            "3": 0.2844990548204159
        },
        "rouge1": {
            "precision": 0.5349,
            "recall": 0.47005,
            "fmeasure": 0.4876
        },
        "rouge2": {
            "precision": 0.2971,
            "recall": 0.27553,
            "fmeasure": 0.27865
        },
        "rougeL": {
            "precision": 0.48658,
            "recall": 0.42684,
            "fmeasure": 0.44247
        },
        "rougeLsum": {
            "precision": 0.48658,
            "recall": 0.42684,
            "fmeasure": 0.44247
        },
        "nist": 1.2506213387224163,
        "bleurt": -0.51584,
        "bertscore": {
            "precision": 0.86153,
            "recall": 0.86954,
            "f1": 0.86515
        },
        "nubia": {
            "semantic_relation": 3.3168,
            "contradiction": 32.49912,
            "irrelevancy": 17.98907,
            "logical_agreement": 49.51181,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.48999,
            "nubia_score": 0.12267
        },
        "meteor": 0.1377003052695606
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.618,
        "msttr-100_nopunct": 0.67,
        "total_length": 545,
        "mean_pred_length": 13.292682926829269,
        "std_pred_length": 4.774137145582483,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.45321100917431195,
        "vocab_size-1": 247,
        "unique-1": 196,
        "entropy-1": 6.834641275711644,
        "distinct-2": 0.8115079365079365,
        "vocab_size-2": 409,
        "unique-2": 375,
        "entropy-2": 8.43640601498338,
        "cond_entropy-2": 1.3465847840498713,
        "distinct-3": 0.9071274298056156,
        "vocab_size-3": 420,
        "unique-3": 401,
        "entropy-3": 8.603456659731258,
        "cond_entropy-3": 0.1625391279933596,
        "total_length-nopunct": 460,
        "mean_pred_length-nopunct": 11.21951219512195,
        "std_pred_length-nopunct": 4.0695909491930164,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5239130434782608,
        "vocab_size-1-nopunct": 241,
        "unique-1-nopunct": 195,
        "entropy-1-nopunct": 6.995694104542873,
        "distinct-2-nopunct": 0.8233890214797136,
        "vocab_size-2-nopunct": 345,
        "unique-2-nopunct": 320,
        "entropy-2-nopunct": 8.191520276459128,
        "cond_entropy-2-nopunct": 1.2816936686948202,
        "distinct-3-nopunct": 0.9126984126984127,
        "vocab_size-3-nopunct": 345,
        "unique-3-nopunct": 330,
        "entropy-3-nopunct": 8.325776609445299,
        "cond_entropy-3-nopunct": 0.1355351095067215,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.86995,
        "local_recall": {
            "1": 0.2,
            "2": 0.4462809917355372,
            "3": 0.7848484848484848
        },
        "rouge1": {
            "precision": 0.76392,
            "recall": 0.72496,
            "fmeasure": 0.73513
        },
        "rouge2": {
            "precision": 0.55035,
            "recall": 0.51943,
            "fmeasure": 0.5275
        },
        "rougeL": {
            "precision": 0.6717,
            "recall": 0.6404,
            "fmeasure": 0.64743
        },
        "rougeLsum": {
            "precision": 0.6717,
            "recall": 0.6404,
            "fmeasure": 0.64743
        },
        "nist": 6.435031403591345,
        "bleurt": 0.33072,
        "bertscore": {
            "precision": 0.93209,
            "recall": 0.92958,
            "f1": 0.92945
        },
        "nubia": {
            "semantic_relation": 3.93101,
            "contradiction": 12.51508,
            "irrelevancy": 25.10666,
            "logical_agreement": 62.37826,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.51696,
            "nubia_score": 0.69393
        },
        "meteor": 0.39645737536065306
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.65613,
        "msttr-100_nopunct": 0.6962,
        "total_length": 15570,
        "mean_pred_length": 30.057915057915057,
        "std_pred_length": 14.087719024499606,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.0611432241490045,
        "vocab_size-1": 952,
        "unique-1": 284,
        "entropy-1": 7.714445426886444,
        "distinct-2": 0.19598724422003722,
        "vocab_size-2": 2950,
        "unique-2": 1287,
        "entropy-2": 10.34798552935421,
        "cond_entropy-2": 2.507406083192032,
        "distinct-3": 0.3304664923627357,
        "vocab_size-3": 4803,
        "unique-3": 2647,
        "entropy-3": 11.300704459711964,
        "cond_entropy-3": 0.9898377994374266,
        "total_length-nopunct": 13789,
        "mean_pred_length-nopunct": 26.61969111969112,
        "std_pred_length-nopunct": 12.60600451021428,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.06831532380883312,
        "vocab_size-1-nopunct": 942,
        "unique-1-nopunct": 284,
        "entropy-1-nopunct": 7.947266162925653,
        "distinct-2-nopunct": 0.20895184989827442,
        "vocab_size-2-nopunct": 2773,
        "unique-2-nopunct": 1286,
        "entropy-2-nopunct": 10.242626582596673,
        "cond_entropy-2-nopunct": 2.377147230965667,
        "distinct-3-nopunct": 0.3415666901905434,
        "vocab_size-3-nopunct": 4356,
        "unique-3-nopunct": 2469,
        "entropy-3-nopunct": 11.151281788748232,
        "cond_entropy-3-nopunct": 0.9290361774597307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 55.95425,
        "local_recall": {
            "1": 0.26623490285314194,
            "2": 0.6227614095898325,
            "3": 0.9161188911117462,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.80664,
            "recall": 0.78547,
            "fmeasure": 0.791
        },
        "rouge2": {
            "precision": 0.56834,
            "recall": 0.55314,
            "fmeasure": 0.55679
        },
        "rougeL": {
            "precision": 0.63517,
            "recall": 0.6193,
            "fmeasure": 0.62297
        },
        "rougeLsum": {
            "precision": 0.63517,
            "recall": 0.6193,
            "fmeasure": 0.62297
        },
        "nist": 8.94465537050148,
        "bleurt": 0.28772,
        "bertscore": {
            "precision": 0.93912,
            "recall": 0.93529,
            "f1": 0.93622
        },
        "nubia": {
            "semantic_relation": 4.6518,
            "contradiction": 3.36818,
            "irrelevancy": 3.8336,
            "logical_agreement": 92.79821,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.2748,
            "nubia_score": 0.86466
        },
        "meteor": 0.41530768954052566
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.6359,
        "msttr-100_nopunct": 0.67113,
        "total_length": 26169,
        "mean_pred_length": 22.233644859813083,
        "std_pred_length": 10.412672319287,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.04952424624555772,
        "vocab_size-1": 1296,
        "unique-1": 366,
        "entropy-1": 7.717722491521262,
        "distinct-2": 0.19342189500640206,
        "vocab_size-2": 4834,
        "unique-2": 2210,
        "entropy-2": 10.945611729100245,
        "cond_entropy-2": 3.0494736387388723,
        "distinct-3": 0.36288053747638044,
        "vocab_size-3": 8642,
        "unique-3": 5123,
        "entropy-3": 12.177065065678876,
        "cond_entropy-3": 1.285606455378119,
        "total_length-nopunct": 23189,
        "mean_pred_length-nopunct": 19.7017841971113,
        "std_pred_length-nopunct": 9.475287638435267,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.055414205010996594,
        "vocab_size-1-nopunct": 1285,
        "unique-1-nopunct": 364,
        "entropy-1-nopunct": 7.945437731398175,
        "distinct-2-nopunct": 0.20752316918044703,
        "vocab_size-2-nopunct": 4568,
        "unique-2-nopunct": 2221,
        "entropy-2-nopunct": 10.842940024651211,
        "cond_entropy-2-nopunct": 3.040847992196852,
        "distinct-3-nopunct": 0.38248140148788096,
        "vocab_size-3-nopunct": 7969,
        "unique-3-nopunct": 4926,
        "entropy-3-nopunct": 12.051667670938231,
        "cond_entropy-3-nopunct": 1.2499577961423853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 41.64722,
        "local_recall": {
            "1": 0.21464848970863407,
            "2": 0.5600855092380516,
            "3": 0.8468282193366967,
            "4": 0.6,
            "5": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.75048,
            "recall": 0.73538,
            "fmeasure": 0.73596
        },
        "rouge2": {
            "precision": 0.47413,
            "recall": 0.46354,
            "fmeasure": 0.46361
        },
        "rougeL": {
            "precision": 0.58937,
            "recall": 0.57748,
            "fmeasure": 0.57741
        },
        "rougeLsum": {
            "precision": 0.58937,
            "recall": 0.57748,
            "fmeasure": 0.57741
        },
        "nist": 8.22638873159916,
        "bleurt": 0.16249,
        "bertscore": {
            "precision": 0.91571,
            "recall": 0.91414,
            "f1": 0.91346
        },
        "nubia": {
            "semantic_relation": 4.32928,
            "contradiction": 10.55833,
            "irrelevancy": 8.55716,
            "logical_agreement": 80.88451,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.67176,
            "nubia_score": 0.7498
        },
        "meteor": 0.36698216455994603
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.29794,
        "msttr-100_nopunct": 0.28859,
        "total_length": 28292,
        "mean_pred_length": 23.834877843302444,
        "std_pred_length": 4.9628473138134295,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 51,
        "distinct-1": 0.009932136292945003,
        "vocab_size-1": 281,
        "unique-1": 55,
        "entropy-1": 5.963576128810435,
        "distinct-2": 0.04331304187419295,
        "vocab_size-2": 1174,
        "unique-2": 335,
        "entropy-2": 8.10817362912612,
        "cond_entropy-2": 2.0554958647617676,
        "distinct-3": 0.09024616096921059,
        "vocab_size-3": 2339,
        "unique-3": 764,
        "entropy-3": 9.336420375377058,
        "cond_entropy-3": 1.22701681295723,
        "total_length-nopunct": 25680,
        "mean_pred_length-nopunct": 21.63437236731255,
        "std_pred_length-nopunct": 4.610646410903843,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.010825545171339565,
        "vocab_size-1-nopunct": 278,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.99854549476266,
        "distinct-2-nopunct": 0.04682970644673989,
        "vocab_size-2-nopunct": 1147,
        "unique-2-nopunct": 338,
        "entropy-2-nopunct": 8.029277736525737,
        "cond_entropy-2-nopunct": 2.056510292178916,
        "distinct-3-nopunct": 0.09619840384450357,
        "vocab_size-3-nopunct": 2242,
        "unique-3-nopunct": 741,
        "entropy-3-nopunct": 9.30398731624523,
        "cond_entropy-3-nopunct": 1.2419750602849984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 28.28328,
        "local_recall": {
            "1": 0.6914136522508106
        },
        "rouge1": {
            "precision": 0.72129,
            "recall": 0.70921,
            "fmeasure": 0.70337
        },
        "rouge2": {
            "precision": 0.40404,
            "recall": 0.39675,
            "fmeasure": 0.39341
        },
        "rougeL": {
            "precision": 0.50147,
            "recall": 0.49127,
            "fmeasure": 0.4882
        },
        "rougeLsum": {
            "precision": 0.50147,
            "recall": 0.49127,
            "fmeasure": 0.4882
        },
        "nist": 4.786195810561155,
        "bleurt": 0.12232,
        "bertscore": {
            "precision": 0.9072,
            "recall": 0.90497,
            "f1": 0.90571
        },
        "nubia": {
            "semantic_relation": 4.27696,
            "contradiction": 2.01557,
            "irrelevancy": 24.38914,
            "logical_agreement": 73.59529,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.60354,
            "nubia_score": 0.77255
        },
        "meteor": 0.35531516581761935
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.3132,
        "msttr-100_nopunct": 0.30641,
        "total_length": 37894,
        "mean_pred_length": 26.95163584637269,
        "std_pred_length": 4.577506327722186,
        "median_pred_length": 27.0,
        "min_pred_length": 16,
        "max_pred_length": 45,
        "distinct-1": 0.006808465720166781,
        "vocab_size-1": 258,
        "unique-1": 39,
        "entropy-1": 5.895166144989884,
        "distinct-2": 0.033298618723964044,
        "vocab_size-2": 1215,
        "unique-2": 245,
        "entropy-2": 8.039903489797098,
        "cond_entropy-2": 2.0646924222345575,
        "distinct-3": 0.07639245196967105,
        "vocab_size-3": 2680,
        "unique-3": 654,
        "entropy-3": 9.400157750759462,
        "cond_entropy-3": 1.3614634221603135,
        "total_length-nopunct": 34542,
        "mean_pred_length-nopunct": 24.56756756756757,
        "std_pred_length-nopunct": 4.261465254746525,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.007382317179086329,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.926756508691018,
        "distinct-2-nopunct": 0.03648599710284887,
        "vocab_size-2-nopunct": 1209,
        "unique-2-nopunct": 261,
        "entropy-2-nopunct": 7.997371005474111,
        "cond_entropy-2-nopunct": 2.1017468285443255,
        "distinct-3-nopunct": 0.08197289631263788,
        "vocab_size-3-nopunct": 2601,
        "unique-3-nopunct": 660,
        "entropy-3-nopunct": 9.394818039312826,
        "cond_entropy-3-nopunct": 1.384019396569296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 29.86519,
        "local_recall": {
            "1": 0.6929432850329597
        },
        "rouge1": {
            "precision": 0.76729,
            "recall": 0.71052,
            "fmeasure": 0.72889
        },
        "rouge2": {
            "precision": 0.45802,
            "recall": 0.42475,
            "fmeasure": 0.43535
        },
        "rougeL": {
            "precision": 0.51785,
            "recall": 0.48025,
            "fmeasure": 0.49235
        },
        "rougeLsum": {
            "precision": 0.51785,
            "recall": 0.48025,
            "fmeasure": 0.49235
        },
        "nist": 5.082728706081931,
        "bleurt": 0.22518,
        "bertscore": {
            "precision": 0.91858,
            "recall": 0.90596,
            "f1": 0.91199
        },
        "nubia": {
            "semantic_relation": 4.4531,
            "contradiction": 2.55149,
            "irrelevancy": 12.01181,
            "logical_agreement": 85.4367,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.44542,
            "nubia_score": 0.81696
        },
        "meteor": 0.3607361108491596
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.595,
        "msttr-100_nopunct": 0.64,
        "total_length": 653,
        "mean_pred_length": 11.660714285714286,
        "std_pred_length": 4.830249866778137,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.3093415007656968,
        "vocab_size-1": 202,
        "unique-1": 125,
        "entropy-1": 6.295935735097849,
        "distinct-2": 0.6348408710217756,
        "vocab_size-2": 379,
        "unique-2": 294,
        "entropy-2": 8.181584055573838,
        "cond_entropy-2": 1.6227224532632416,
        "distinct-3": 0.7911275415896488,
        "vocab_size-3": 428,
        "unique-3": 371,
        "entropy-3": 8.53487213816389,
        "cond_entropy-3": 0.3699821938095638,
        "total_length-nopunct": 573,
        "mean_pred_length-nopunct": 10.232142857142858,
        "std_pred_length-nopunct": 4.403695977847031,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.343804537521815,
        "vocab_size-1-nopunct": 197,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.40338156085095,
        "distinct-2-nopunct": 0.632495164410058,
        "vocab_size-2-nopunct": 327,
        "unique-2-nopunct": 253,
        "entropy-2-nopunct": 7.96209345333654,
        "cond_entropy-2-nopunct": 1.6950964738067325,
        "distinct-3-nopunct": 0.7939262472885033,
        "vocab_size-3-nopunct": 366,
        "unique-3-nopunct": 318,
        "entropy-3-nopunct": 8.306219264072503,
        "cond_entropy-3-nopunct": 0.3563878241544728,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 49.73816,
        "local_recall": {
            "1": 0.23410404624277456,
            "2": 0.65625,
            "3": 0.8731884057971014
        },
        "rouge1": {
            "precision": 0.78314,
            "recall": 0.76026,
            "fmeasure": 0.76334
        },
        "rouge2": {
            "precision": 0.53241,
            "recall": 0.51816,
            "fmeasure": 0.51931
        },
        "rougeL": {
            "precision": 0.66993,
            "recall": 0.64986,
            "fmeasure": 0.65233
        },
        "rougeLsum": {
            "precision": 0.66993,
            "recall": 0.64986,
            "fmeasure": 0.65233
        },
        "nist": 6.955232907532667,
        "bleurt": 0.28881,
        "bertscore": {
            "precision": 0.93865,
            "recall": 0.93676,
            "f1": 0.93657
        },
        "nubia": {
            "semantic_relation": 4.53087,
            "contradiction": 4.8981,
            "irrelevancy": 6.17512,
            "logical_agreement": 88.92679,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.28474,
            "nubia_score": 0.80973
        },
        "meteor": 0.43188960302362384
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.53333,
        "msttr-100_nopunct": 0.56,
        "total_length": 303,
        "mean_pred_length": 10.821428571428571,
        "std_pred_length": 4.053689425595365,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.38283828382838286,
        "vocab_size-1": 116,
        "unique-1": 75,
        "entropy-1": 5.8124336761512785,
        "distinct-2": 0.7236363636363636,
        "vocab_size-2": 199,
        "unique-2": 157,
        "entropy-2": 7.416588936078727,
        "cond_entropy-2": 1.357018026259931,
        "distinct-3": 0.8623481781376519,
        "vocab_size-3": 213,
        "unique-3": 190,
        "entropy-3": 7.630030428009438,
        "cond_entropy-3": 0.2477438438463444,
        "total_length-nopunct": 268,
        "mean_pred_length-nopunct": 9.571428571428571,
        "std_pred_length-nopunct": 3.5297568858873816,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.4216417910447761,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 5.886898056930421,
        "distinct-2-nopunct": 0.7083333333333334,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.1731935023189966,
        "cond_entropy-2-nopunct": 1.4634103484487002,
        "distinct-3-nopunct": 0.8584905660377359,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.394763895680703,
        "cond_entropy-3-nopunct": 0.29017189624902534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 60.82744,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6702127659574468,
            "3": 0.8888888888888888,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.80857,
            "recall": 0.77989,
            "fmeasure": 0.78544
        },
        "rouge2": {
            "precision": 0.5927,
            "recall": 0.56965,
            "fmeasure": 0.57278
        },
        "rougeL": {
            "precision": 0.70996,
            "recall": 0.68081,
            "fmeasure": 0.68691
        },
        "rougeLsum": {
            "precision": 0.70996,
            "recall": 0.68081,
            "fmeasure": 0.68691
        },
        "nist": 6.82219874070519,
        "bleurt": 0.39088,
        "bertscore": {
            "precision": 0.94355,
            "recall": 0.93464,
            "f1": 0.93727
        },
        "nubia": {
            "semantic_relation": 4.34262,
            "contradiction": 17.69536,
            "irrelevancy": 3.3345,
            "logical_agreement": 78.97014,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.92287,
            "nubia_score": 0.73656
        },
        "meteor": 0.42799138767746764
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.45333,
        "msttr-100_nopunct": 0.44941,
        "total_length": 3656,
        "mean_pred_length": 65.28571428571429,
        "std_pred_length": 7.916335474633373,
        "median_pred_length": 67.0,
        "min_pred_length": 42,
        "max_pred_length": 87,
        "distinct-1": 0.17231947483588622,
        "vocab_size-1": 630,
        "unique-1": 346,
        "entropy-1": 5.6885982620031355,
        "distinct-2": 0.3902777777777778,
        "vocab_size-2": 1405,
        "unique-2": 893,
        "entropy-2": 9.343524982357293,
        "cond_entropy-2": 3.67793017638771,
        "distinct-3": 0.5877539503386005,
        "vocab_size-3": 2083,
        "unique-3": 1509,
        "entropy-3": 10.493418816302036,
        "cond_entropy-3": 1.1629213479566751,
        "total_length-nopunct": 3412,
        "mean_pred_length-nopunct": 60.92857142857143,
        "std_pred_length-nopunct": 7.880484808457315,
        "median_pred_length-nopunct": 62.5,
        "min_pred_length-nopunct": 37,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.18259085580304807,
        "vocab_size-1-nopunct": 623,
        "unique-1-nopunct": 344,
        "entropy-1-nopunct": 5.5922293287652955,
        "distinct-2-nopunct": 0.39690107270560193,
        "vocab_size-2-nopunct": 1332,
        "unique-2-nopunct": 841,
        "entropy-2-nopunct": 9.267121478873818,
        "cond_entropy-2-nopunct": 3.7224906606426282,
        "distinct-3-nopunct": 0.5881818181818181,
        "vocab_size-3-nopunct": 1941,
        "unique-3-nopunct": 1404,
        "entropy-3-nopunct": 10.394070661626222,
        "cond_entropy-3-nopunct": 1.139729588517508,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 3.12278,
        "local_recall": {
            "1": 0.07621671258034894,
            "2": 0.17647058823529413,
            "3": 0.3262786596119929
        },
        "rouge1": {
            "precision": 0.73936,
            "recall": 0.63688,
            "fmeasure": 0.65837
        },
        "rouge2": {
            "precision": 0.47272,
            "recall": 0.43494,
            "fmeasure": 0.43674
        },
        "rougeL": {
            "precision": 0.68407,
            "recall": 0.58908,
            "fmeasure": 0.60795
        },
        "rougeLsum": {
            "precision": 0.68407,
            "recall": 0.58908,
            "fmeasure": 0.60795
        },
        "nist": 1.3216855483934424,
        "bleurt": -0.5147,
        "bertscore": {
            "precision": 0.86503,
            "recall": 0.87012,
            "f1": 0.86716
        },
        "nubia": {
            "semantic_relation": 3.28178,
            "contradiction": 32.02704,
            "irrelevancy": 21.25257,
            "logical_agreement": 46.72039,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.49056,
            "nubia_score": 0.15375
        },
        "meteor": 0.1434471699704185
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.70476,
        "msttr-100_nopunct": 0.75833,
        "total_length": 2172,
        "mean_pred_length": 15.083333333333334,
        "std_pred_length": 6.925696916396052,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.3669429097605893,
        "vocab_size-1": 797,
        "unique-1": 572,
        "entropy-1": 8.04336028248286,
        "distinct-2": 0.7411242603550295,
        "vocab_size-2": 1503,
        "unique-2": 1293,
        "entropy-2": 10.211852698880321,
        "cond_entropy-2": 1.869135748654993,
        "distinct-3": 0.8736730360934183,
        "vocab_size-3": 1646,
        "unique-3": 1521,
        "entropy-3": 10.55110909404843,
        "cond_entropy-3": 0.33735559254050573,
        "total_length-nopunct": 1885,
        "mean_pred_length-nopunct": 13.090277777777779,
        "std_pred_length-nopunct": 6.080379641889655,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.41750663129973475,
        "vocab_size-1-nopunct": 787,
        "unique-1-nopunct": 569,
        "entropy-1-nopunct": 8.334682549162396,
        "distinct-2-nopunct": 0.76220562894888,
        "vocab_size-2-nopunct": 1327,
        "unique-2-nopunct": 1164,
        "entropy-2-nopunct": 10.040246750605144,
        "cond_entropy-2-nopunct": 1.799119673924013,
        "distinct-3-nopunct": 0.8835316217908579,
        "vocab_size-3-nopunct": 1411,
        "unique-3-nopunct": 1313,
        "entropy-3-nopunct": 10.337892509972493,
        "cond_entropy-3-nopunct": 0.3206897987774473,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.77708,
        "local_recall": {
            "1": 0.2198443579766537,
            "2": 0.5408388520971302,
            "3": 0.757976653696498
        },
        "rouge1": {
            "precision": 0.76696,
            "recall": 0.71943,
            "fmeasure": 0.72603
        },
        "rouge2": {
            "precision": 0.55075,
            "recall": 0.51947,
            "fmeasure": 0.52172
        },
        "rougeL": {
            "precision": 0.68321,
            "recall": 0.64721,
            "fmeasure": 0.64869
        },
        "rougeLsum": {
            "precision": 0.68321,
            "recall": 0.64721,
            "fmeasure": 0.64869
        },
        "nist": 7.6884285416831,
        "bleurt": 0.24158,
        "bertscore": {
            "precision": 0.92875,
            "recall": 0.921,
            "f1": 0.92236
        },
        "nubia": {
            "semantic_relation": 4.09923,
            "contradiction": 6.06774,
            "irrelevancy": 30.95001,
            "logical_agreement": 62.98225,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.77555,
            "nubia_score": 0.70393
        },
        "meteor": 0.3998070918328301
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.45083,
        "msttr-100_nopunct": 0.44273,
        "total_length": 1285,
        "mean_pred_length": 67.63157894736842,
        "std_pred_length": 6.045533595497888,
        "median_pred_length": 70.0,
        "min_pred_length": 46,
        "max_pred_length": 74,
        "distinct-1": 0.177431906614786,
        "vocab_size-1": 228,
        "unique-1": 102,
        "entropy-1": 5.054065561415059,
        "distinct-2": 0.39731437598736175,
        "vocab_size-2": 503,
        "unique-2": 268,
        "entropy-2": 8.27501888133629,
        "cond_entropy-2": 3.244433794035945,
        "distinct-3": 0.5589414595028067,
        "vocab_size-3": 697,
        "unique-3": 445,
        "entropy-3": 9.057996451624621,
        "cond_entropy-3": 0.7893635272098962,
        "total_length-nopunct": 1192,
        "mean_pred_length-nopunct": 62.73684210526316,
        "std_pred_length-nopunct": 5.3196963235761165,
        "median_pred_length-nopunct": 64.0,
        "min_pred_length-nopunct": 44,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.18708053691275167,
        "vocab_size-1-nopunct": 223,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 4.912587376312595,
        "distinct-2-nopunct": 0.40494458653026427,
        "vocab_size-2-nopunct": 475,
        "unique-2-nopunct": 255,
        "entropy-2-nopunct": 8.205057005212696,
        "cond_entropy-2-nopunct": 3.321326052559161,
        "distinct-3-nopunct": 0.561525129982669,
        "vocab_size-3-nopunct": 648,
        "unique-3-nopunct": 416,
        "entropy-3-nopunct": 8.963330131819667,
        "cond_entropy-3-nopunct": 0.7626796083556238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 2.27,
        "local_recall": {
            "1": 0.11186440677966102,
            "2": 0.19172932330827067,
            "3": 0.2376237623762376
        },
        "rouge1": {
            "precision": 0.84524,
            "recall": 0.75369,
            "fmeasure": 0.7779
        },
        "rouge2": {
            "precision": 0.47398,
            "recall": 0.45234,
            "fmeasure": 0.44417
        },
        "rougeL": {
            "precision": 0.7731,
            "recall": 0.68669,
            "fmeasure": 0.70896
        },
        "rougeLsum": {
            "precision": 0.7731,
            "recall": 0.68669,
            "fmeasure": 0.70896
        },
        "nist": 1.2375165604590062,
        "bleurt": -0.48321,
        "bertscore": {
            "precision": 0.86549,
            "recall": 0.86762,
            "f1": 0.86637
        },
        "nubia": {
            "semantic_relation": 3.23727,
            "contradiction": 35.28298,
            "irrelevancy": 21.29402,
            "logical_agreement": 43.423,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.45513,
            "nubia_score": 0.16361
        },
        "meteor": 0.1202108389387237
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.74176,
        "msttr-100_nopunct": 0.77733,
        "total_length": 1781,
        "mean_pred_length": 28.26984126984127,
        "std_pred_length": 8.659715800913013,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 54,
        "distinct-1": 0.4553621560920831,
        "vocab_size-1": 811,
        "unique-1": 639,
        "entropy-1": 8.313685047351052,
        "distinct-2": 0.889988358556461,
        "vocab_size-2": 1529,
        "unique-2": 1453,
        "entropy-2": 10.392661910300948,
        "cond_entropy-2": 1.9350594802435304,
        "distinct-3": 0.9661631419939577,
        "vocab_size-3": 1599,
        "unique-3": 1586,
        "entropy-3": 10.55923665319701,
        "cond_entropy-3": 0.17475469116204628,
        "total_length-nopunct": 1582,
        "mean_pred_length-nopunct": 25.11111111111111,
        "std_pred_length-nopunct": 7.517410714122063,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5075853350189633,
        "vocab_size-1-nopunct": 803,
        "unique-1-nopunct": 637,
        "entropy-1-nopunct": 8.548388403263562,
        "distinct-2-nopunct": 0.924292297564187,
        "vocab_size-2-nopunct": 1404,
        "unique-2-nopunct": 1345,
        "entropy-2-nopunct": 10.354180623687222,
        "cond_entropy-2-nopunct": 1.8641551635529547,
        "distinct-3-nopunct": 0.9903846153846154,
        "vocab_size-3-nopunct": 1442,
        "unique-3-nopunct": 1432,
        "entropy-3-nopunct": 10.486153311212266,
        "cond_entropy-3-nopunct": 0.14057688288292586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "bleu": 80.74443,
        "local_recall": {
            "1": 0.036734693877551024,
            "2": 0.19398907103825136,
            "3": 0.40789473684210525,
            "4": 0.6012269938650306,
            "5": 0.7005988023952096,
            "6": 0.8118279569892473,
            "7": 0.927710843373494,
            "8": 0.9348837209302325,
            "9": 0.9425287356321839,
            "10": 0.9722222222222222
        },
        "rouge1": {
            "precision": 0.85449,
            "recall": 0.87854,
            "fmeasure": 0.86151
        },
        "rouge2": {
            "precision": 0.73625,
            "recall": 0.75575,
            "fmeasure": 0.74096
        },
        "rougeL": {
            "precision": 0.82992,
            "recall": 0.86419,
            "fmeasure": 0.84201
        },
        "rougeLsum": {
            "precision": 0.82992,
            "recall": 0.86419,
            "fmeasure": 0.84201
        },
        "nist": 10.994836066301188,
        "bleurt": 0.10688,
        "bertscore": {
            "precision": 0.95479,
            "recall": 0.97057,
            "f1": 0.96021
        },
        "nubia": {
            "semantic_relation": 4.23028,
            "contradiction": 1.2769,
            "irrelevancy": 44.03571,
            "logical_agreement": 54.6874,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.50976,
            "nubia_score": 0.6053
        },
        "meteor": 0.529222404642687
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.73664,
        "msttr-100_nopunct": 0.75588,
        "total_length": 11045,
        "mean_pred_length": 22.09,
        "std_pred_length": 5.8721290857745965,
        "median_pred_length": 22.0,
        "min_pred_length": 1,
        "max_pred_length": 72,
        "distinct-1": 0.2780443639655953,
        "vocab_size-1": 3071,
        "unique-1": 1998,
        "entropy-1": 9.071517350343736,
        "distinct-2": 0.7403508771929824,
        "vocab_size-2": 7807,
        "unique-2": 6806,
        "entropy-2": 12.443035429966134,
        "cond_entropy-2": 3.1560623227007722,
        "distinct-3": 0.9278319729245471,
        "vocab_size-3": 9321,
        "unique-3": 8884,
        "entropy-3": 13.106110115658577,
        "cond_entropy-3": 0.6810728322129459,
        "total_length-nopunct": 10275,
        "mean_pred_length-nopunct": 20.55,
        "std_pred_length-nopunct": 5.616716122433107,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.29781021897810217,
        "vocab_size-1-nopunct": 3060,
        "unique-1-nopunct": 1997,
        "entropy-1-nopunct": 9.245217782951235,
        "distinct-2-nopunct": 0.744885433715221,
        "vocab_size-2-nopunct": 7282,
        "unique-2-nopunct": 6371,
        "entropy-2-nopunct": 12.34236005199093,
        "cond_entropy-2-nopunct": 3.230229384849107,
        "distinct-3-nopunct": 0.9323057022744422,
        "vocab_size-3-nopunct": 8649,
        "unique-3-nopunct": 8250,
        "entropy-3-nopunct": 13.011902017195915,
        "cond_entropy-3-nopunct": 0.6972623457660979,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "bleu": 10.04915,
        "local_recall": {
            "1": 0.3556049732133832
        },
        "rouge1": {
            "precision": 0.39591,
            "recall": 0.38678,
            "fmeasure": 0.3832
        },
        "rouge2": {
            "precision": 0.15315,
            "recall": 0.15157,
            "fmeasure": 0.14935
        },
        "rougeL": {
            "precision": 0.30971,
            "recall": 0.30352,
            "fmeasure": 0.30024
        },
        "rougeLsum": {
            "precision": 0.30971,
            "recall": 0.30352,
            "fmeasure": 0.30024
        },
        "nist": 3.648503593864975,
        "bleurt": -0.33169,
        "bertscore": {
            "precision": 0.82909,
            "recall": 0.82337,
            "f1": 0.82588
        },
        "nubia": {
            "semantic_relation": 2.87982,
            "contradiction": 17.16777,
            "irrelevancy": 68.92165,
            "logical_agreement": 13.91058,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.60443,
            "nubia_score": 0.43582
        },
        "meteor": 0.171670096218656
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.67,
        "total_length": 244,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 11.585431464655176,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.4959016393442623,
        "vocab_size-1": 121,
        "unique-1": 89,
        "entropy-1": 6.206899045215964,
        "distinct-2": 0.7931034482758621,
        "vocab_size-2": 184,
        "unique-2": 158,
        "entropy-2": 7.330809604938771,
        "cond_entropy-2": 1.0276455144620666,
        "distinct-3": 0.8818181818181818,
        "vocab_size-3": 194,
        "unique-3": 176,
        "entropy-3": 7.510860736232252,
        "cond_entropy-3": 0.1906241162128664,
        "total_length-nopunct": 205,
        "mean_pred_length-nopunct": 17.083333333333332,
        "std_pred_length-nopunct": 9.74216209176496,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5609756097560976,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.188511043788776,
        "distinct-2-nopunct": 0.8134715025906736,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.107747840264775,
        "cond_entropy-2-nopunct": 0.9497633698884402,
        "distinct-3-nopunct": 0.9060773480662984,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.2857304865187364,
        "cond_entropy-3-nopunct": 0.18249375323761788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.17438,
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.4722222222222222,
            "3": 0.8489208633093526
        },
        "rouge1": {
            "precision": 0.75743,
            "recall": 0.75603,
            "fmeasure": 0.75187
        },
        "rouge2": {
            "precision": 0.60129,
            "recall": 0.60135,
            "fmeasure": 0.59809
        },
        "rougeL": {
            "precision": 0.69678,
            "recall": 0.69128,
            "fmeasure": 0.68887
        },
        "rougeLsum": {
            "precision": 0.69678,
            "recall": 0.69128,
            "fmeasure": 0.68887
        },
        "nist": 6.137245394006085,
        "bleurt": 0.37834,
        "bertscore": {
            "precision": 0.93366,
            "recall": 0.93278,
            "f1": 0.93279
        },
        "nubia": {
            "semantic_relation": 4.01127,
            "contradiction": 5.88815,
            "irrelevancy": 22.70996,
            "logical_agreement": 71.40189,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.08597,
            "nubia_score": 0.71653
        },
        "meteor": 0.4442325191062196
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.67286,
        "msttr-100_nopunct": 0.74,
        "total_length": 735,
        "mean_pred_length": 15.638297872340425,
        "std_pred_length": 6.382907801024425,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.454421768707483,
        "vocab_size-1": 334,
        "unique-1": 248,
        "entropy-1": 7.310462436402178,
        "distinct-2": 0.7921511627906976,
        "vocab_size-2": 545,
        "unique-2": 473,
        "entropy-2": 8.872030265842582,
        "cond_entropy-2": 1.3331634836952773,
        "distinct-3": 0.8861154446177847,
        "vocab_size-3": 568,
        "unique-3": 528,
        "entropy-3": 9.03404949611668,
        "cond_entropy-3": 0.17963878327591248,
        "total_length-nopunct": 627,
        "mean_pred_length-nopunct": 13.340425531914894,
        "std_pred_length-nopunct": 5.478299921662609,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5231259968102073,
        "vocab_size-1-nopunct": 328,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.52428853742384,
        "distinct-2-nopunct": 0.8017241379310345,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 409,
        "entropy-2-nopunct": 8.645620458342359,
        "cond_entropy-2-nopunct": 1.2040528519599691,
        "distinct-3-nopunct": 0.8874296435272045,
        "vocab_size-3-nopunct": 473,
        "unique-3-nopunct": 439,
        "entropy-3-nopunct": 8.775960730418687,
        "cond_entropy-3-nopunct": 0.1505498699858043,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.62597,
        "local_recall": {
            "1": 0.22758620689655173,
            "2": 0.3669064748201439,
            "3": 0.7440860215053764
        },
        "rouge1": {
            "precision": 0.74272,
            "recall": 0.73265,
            "fmeasure": 0.72171
        },
        "rouge2": {
            "precision": 0.51083,
            "recall": 0.49401,
            "fmeasure": 0.4913
        },
        "rougeL": {
            "precision": 0.66196,
            "recall": 0.64676,
            "fmeasure": 0.64032
        },
        "rougeLsum": {
            "precision": 0.66196,
            "recall": 0.64676,
            "fmeasure": 0.64032
        },
        "nist": 6.547636828959281,
        "bleurt": 0.26509,
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.91904,
            "f1": 0.91991
        },
        "nubia": {
            "semantic_relation": 3.99764,
            "contradiction": 10.29702,
            "irrelevancy": 29.05556,
            "logical_agreement": 60.64742,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.4601,
            "nubia_score": 0.68173
        },
        "meteor": 0.37483143689796616
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69121,
        "msttr-100_nopunct": 0.72121,
        "total_length": 6602,
        "mean_pred_length": 13.204,
        "std_pred_length": 7.459382280055098,
        "median_pred_length": 11.5,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.15343835201454104,
        "vocab_size-1": 1013,
        "unique-1": 561,
        "entropy-1": 7.865732305792818,
        "distinct-2": 0.48426745329400195,
        "vocab_size-2": 2955,
        "unique-2": 2072,
        "entropy-2": 10.748768008151007,
        "cond_entropy-2": 2.648819328937014,
        "distinct-3": 0.7063548732595502,
        "vocab_size-3": 3957,
        "unique-3": 3249,
        "entropy-3": 11.590689265070925,
        "cond_entropy-3": 0.862820073616342,
        "total_length-nopunct": 5816,
        "mean_pred_length-nopunct": 11.632,
        "std_pred_length-nopunct": 6.852778706481043,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.171767537826685,
        "vocab_size-1-nopunct": 999,
        "unique-1-nopunct": 557,
        "entropy-1-nopunct": 8.045776318857229,
        "distinct-2-nopunct": 0.500752445447705,
        "vocab_size-2-nopunct": 2662,
        "unique-2-nopunct": 1896,
        "entropy-2-nopunct": 10.599745535653813,
        "cond_entropy-2-nopunct": 2.6848705908722335,
        "distinct-3-nopunct": 0.7191197840979863,
        "vocab_size-3-nopunct": 3464,
        "unique-3-nopunct": 2884,
        "entropy-3-nopunct": 11.39816975755341,
        "cond_entropy-3-nopunct": 0.8430137284157343,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 31.68268,
        "local_recall": {
            "1": 0.5658009412584974
        },
        "rouge1": {
            "precision": 0.57657,
            "recall": 0.55914,
            "fmeasure": 0.55654
        },
        "rouge2": {
            "precision": 0.35703,
            "recall": 0.34085,
            "fmeasure": 0.34098
        },
        "rougeL": {
            "precision": 0.51762,
            "recall": 0.49891,
            "fmeasure": 0.49823
        },
        "rougeLsum": {
            "precision": 0.51762,
            "recall": 0.49891,
            "fmeasure": 0.49823
        },
        "nist": 6.1088838909051955,
        "bleurt": -0.07128,
        "bertscore": {
            "precision": 0.87336,
            "recall": 0.86716,
            "f1": 0.86979
        },
        "nubia": {
            "semantic_relation": 3.69385,
            "contradiction": 5.31401,
            "irrelevancy": 22.758,
            "logical_agreement": 71.92799,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.6378,
            "nubia_score": 0.66058
        },
        "meteor": 0.31564000013260335
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.74229,
        "msttr-100_nopunct": 0.76857,
        "total_length": 10547,
        "mean_pred_length": 21.094,
        "std_pred_length": 4.732141587061824,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.28064852564710346,
        "vocab_size-1": 2960,
        "unique-1": 1979,
        "entropy-1": 9.085542428527505,
        "distinct-2": 0.7417139444610331,
        "vocab_size-2": 7452,
        "unique-2": 6491,
        "entropy-2": 12.395470248757874,
        "cond_entropy-2": 3.07867202328964,
        "distinct-3": 0.9244788938933697,
        "vocab_size-3": 8826,
        "unique-3": 8421,
        "entropy-3": 13.020912172002447,
        "cond_entropy-3": 0.6335554128003916,
        "total_length-nopunct": 9816,
        "mean_pred_length-nopunct": 19.632,
        "std_pred_length-nopunct": 4.5695268901714545,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.30052974735126325,
        "vocab_size-1-nopunct": 2950,
        "unique-1-nopunct": 1977,
        "entropy-1-nopunct": 9.272963501024417,
        "distinct-2-nopunct": 0.7489265779304423,
        "vocab_size-2-nopunct": 6977,
        "unique-2-nopunct": 6108,
        "entropy-2-nopunct": 12.308073086558668,
        "cond_entropy-2-nopunct": 3.1531769994677195,
        "distinct-3-nopunct": 0.9304673321234119,
        "vocab_size-3-nopunct": 8203,
        "unique-3-nopunct": 7843,
        "entropy-3-nopunct": 12.930725574755618,
        "cond_entropy-3-nopunct": 0.6388378239649485,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "bleu": 13.46128,
        "local_recall": {
            "1": 0.3960974643423138
        },
        "rouge1": {
            "precision": 0.45891,
            "recall": 0.42389,
            "fmeasure": 0.43289
        },
        "rouge2": {
            "precision": 0.20667,
            "recall": 0.19205,
            "fmeasure": 0.19545
        },
        "rougeL": {
            "precision": 0.36525,
            "recall": 0.33732,
            "fmeasure": 0.34444
        },
        "rougeLsum": {
            "precision": 0.36525,
            "recall": 0.33732,
            "fmeasure": 0.34444
        },
        "nist": 4.33402554830393,
        "bleurt": -0.24114,
        "bertscore": {
            "precision": 0.84962,
            "recall": 0.83921,
            "f1": 0.84407
        },
        "nubia": {
            "semantic_relation": 3.22652,
            "contradiction": 15.28124,
            "irrelevancy": 60.45073,
            "logical_agreement": 24.26804,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.66549,
            "nubia_score": 0.50867
        },
        "meteor": 0.19778172488732074
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.63833,
        "msttr-100_nopunct": 0.684,
        "total_length": 657,
        "mean_pred_length": 16.425,
        "std_pred_length": 7.748830556929219,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 45,
        "distinct-1": 0.4444444444444444,
        "vocab_size-1": 292,
        "unique-1": 238,
        "entropy-1": 6.861988370220614,
        "distinct-2": 0.7909238249594813,
        "vocab_size-2": 488,
        "unique-2": 448,
        "entropy-2": 8.623266988882326,
        "cond_entropy-2": 1.5781883817226772,
        "distinct-3": 0.878682842287695,
        "vocab_size-3": 507,
        "unique-3": 483,
        "entropy-3": 8.822290106740077,
        "cond_entropy-3": 0.23208984248269487,
        "total_length-nopunct": 562,
        "mean_pred_length-nopunct": 14.05,
        "std_pred_length-nopunct": 6.715467221273588,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5088967971530249,
        "vocab_size-1-nopunct": 286,
        "unique-1-nopunct": 237,
        "entropy-1-nopunct": 7.045986501412388,
        "distinct-2-nopunct": 0.7931034482758621,
        "vocab_size-2-nopunct": 414,
        "unique-2-nopunct": 382,
        "entropy-2-nopunct": 8.378538867337127,
        "cond_entropy-2-nopunct": 1.4550535210680022,
        "distinct-3-nopunct": 0.8796680497925311,
        "vocab_size-3-nopunct": 424,
        "unique-3-nopunct": 404,
        "entropy-3-nopunct": 8.563263805327374,
        "cond_entropy-3-nopunct": 0.22581365203144765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.15685,
        "local_recall": {
            "1": 0.2564102564102564,
            "2": 0.4307692307692308,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.76141,
            "recall": 0.7497,
            "fmeasure": 0.74447
        },
        "rouge2": {
            "precision": 0.56789,
            "recall": 0.54932,
            "fmeasure": 0.55108
        },
        "rougeL": {
            "precision": 0.67705,
            "recall": 0.65296,
            "fmeasure": 0.65467
        },
        "rougeLsum": {
            "precision": 0.67705,
            "recall": 0.65296,
            "fmeasure": 0.65467
        },
        "nist": 6.773257898260003,
        "bleurt": 0.36599,
        "bertscore": {
            "precision": 0.93,
            "recall": 0.93169,
            "f1": 0.92948
        },
        "nubia": {
            "semantic_relation": 4.22139,
            "contradiction": 9.33336,
            "irrelevancy": 25.11846,
            "logical_agreement": 65.54818,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.41861,
            "nubia_score": 0.74257
        },
        "meteor": 0.41233869161169834
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69516,
        "msttr-100_nopunct": 0.72648,
        "total_length": 6206,
        "mean_pred_length": 12.412,
        "std_pred_length": 7.383918742781505,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 47,
        "distinct-1": 0.161617789236223,
        "vocab_size-1": 1003,
        "unique-1": 559,
        "entropy-1": 7.836449504426752,
        "distinct-2": 0.5043813529617946,
        "vocab_size-2": 2878,
        "unique-2": 2063,
        "entropy-2": 10.736513389066157,
        "cond_entropy-2": 2.642140553659105,
        "distinct-3": 0.7270457164809835,
        "vocab_size-3": 3785,
        "unique-3": 3196,
        "entropy-3": 11.52876876010577,
        "cond_entropy-3": 0.8138156557343993,
        "total_length-nopunct": 5441,
        "mean_pred_length-nopunct": 10.882,
        "std_pred_length-nopunct": 6.7669842618407205,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.1821356368314648,
        "vocab_size-1-nopunct": 991,
        "unique-1-nopunct": 555,
        "entropy-1-nopunct": 8.03831291019114,
        "distinct-2-nopunct": 0.518113742157458,
        "vocab_size-2-nopunct": 2560,
        "unique-2-nopunct": 1871,
        "entropy-2-nopunct": 10.553562264429415,
        "cond_entropy-2-nopunct": 2.6465368924855923,
        "distinct-3-nopunct": 0.7390814948221521,
        "vocab_size-3-nopunct": 3283,
        "unique-3-nopunct": 2818,
        "entropy-3-nopunct": 11.316614145394114,
        "cond_entropy-3-nopunct": 0.8017242938028084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 32.09814,
        "local_recall": {
            "1": 0.5672407475265665
        },
        "rouge1": {
            "precision": 0.5814,
            "recall": 0.55268,
            "fmeasure": 0.55417
        },
        "rouge2": {
            "precision": 0.36106,
            "recall": 0.34059,
            "fmeasure": 0.3425
        },
        "rougeL": {
            "precision": 0.52361,
            "recall": 0.49632,
            "fmeasure": 0.49837
        },
        "rougeLsum": {
            "precision": 0.52361,
            "recall": 0.49632,
            "fmeasure": 0.49837
        },
        "nist": 6.05658243503489,
        "bleurt": -0.09372,
        "bertscore": {
            "precision": 0.87141,
            "recall": 0.86509,
            "f1": 0.8677
        },
        "nubia": {
            "semantic_relation": 3.56639,
            "contradiction": 6.89047,
            "irrelevancy": 23.66688,
            "logical_agreement": 69.44265,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.68427,
            "nubia_score": 0.62243
        },
        "meteor": 0.3152020963480341
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.45,
        "msttr-100_nopunct": 0.44429,
        "total_length": 804,
        "mean_pred_length": 67.0,
        "std_pred_length": 3.582364210034113,
        "median_pred_length": 66.5,
        "min_pred_length": 61,
        "max_pred_length": 75,
        "distinct-1": 0.23134328358208955,
        "vocab_size-1": 186,
        "unique-1": 104,
        "entropy-1": 4.911352105672396,
        "distinct-2": 0.4936868686868687,
        "vocab_size-2": 391,
        "unique-2": 254,
        "entropy-2": 8.035315211014575,
        "cond_entropy-2": 3.105459663493265,
        "distinct-3": 0.6756410256410257,
        "vocab_size-3": 527,
        "unique-3": 392,
        "entropy-3": 8.75062776835058,
        "cond_entropy-3": 0.714785601645055,
        "total_length-nopunct": 742,
        "mean_pred_length-nopunct": 61.833333333333336,
        "std_pred_length-nopunct": 2.7638539919628333,
        "median_pred_length-nopunct": 61.0,
        "min_pred_length-nopunct": 58,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.24528301886792453,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 4.7676957217699245,
        "distinct-2-nopunct": 0.5095890410958904,
        "vocab_size-2-nopunct": 372,
        "unique-2-nopunct": 243,
        "entropy-2-nopunct": 7.978274259734078,
        "cond_entropy-2-nopunct": 3.1986125069894595,
        "distinct-3-nopunct": 0.6949860724233984,
        "vocab_size-3-nopunct": 499,
        "unique-3-nopunct": 383,
        "entropy-3-nopunct": 8.681425047054717,
        "cond_entropy-3-nopunct": 0.7115935320636774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.01169,
        "local_recall": {
            "1": 0.06862745098039216,
            "2": 0.14942528735632185,
            "3": 0.21518987341772153
        },
        "rouge1": {
            "precision": 0.64028,
            "recall": 0.44977,
            "fmeasure": 0.52038
        },
        "rouge2": {
            "precision": 0.45139,
            "recall": 0.29352,
            "fmeasure": 0.34372
        },
        "rougeL": {
            "precision": 0.62917,
            "recall": 0.44157,
            "fmeasure": 0.51028
        },
        "rougeLsum": {
            "precision": 0.62917,
            "recall": 0.44157,
            "fmeasure": 0.51028
        },
        "nist": 1.0739436470398196,
        "bleurt": -0.55642,
        "bertscore": {
            "precision": 0.86201,
            "recall": 0.85798,
            "f1": 0.8599
        },
        "nubia": {
            "semantic_relation": 3.08809,
            "contradiction": 38.95007,
            "irrelevancy": 22.41058,
            "logical_agreement": 38.63935,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.43231,
            "nubia_score": 0.18662
        },
        "meteor": 0.10117260536940242
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.70203,
        "msttr-100_nopunct": 0.73383,
        "total_length": 6916,
        "mean_pred_length": 13.832,
        "std_pred_length": 7.887951318308195,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 49,
        "distinct-1": 0.1607865818392134,
        "vocab_size-1": 1112,
        "unique-1": 622,
        "entropy-1": 7.952462427949941,
        "distinct-2": 0.5060785536159601,
        "vocab_size-2": 3247,
        "unique-2": 2334,
        "entropy-2": 10.899939879877948,
        "cond_entropy-2": 2.7271054165904767,
        "distinct-3": 0.7268424611223799,
        "vocab_size-3": 4300,
        "unique-3": 3587,
        "entropy-3": 11.726719796626174,
        "cond_entropy-3": 0.8477015381708963,
        "total_length-nopunct": 6092,
        "mean_pred_length-nopunct": 12.184,
        "std_pred_length-nopunct": 7.200982155234104,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.18056467498358503,
        "vocab_size-1-nopunct": 1100,
        "unique-1-nopunct": 620,
        "entropy-1-nopunct": 8.141404893833993,
        "distinct-2-nopunct": 0.5223533619456366,
        "vocab_size-2-nopunct": 2921,
        "unique-2-nopunct": 2135,
        "entropy-2-nopunct": 10.750823024979361,
        "cond_entropy-2-nopunct": 2.7391697963794663,
        "distinct-3-nopunct": 0.7423409269442263,
        "vocab_size-3-nopunct": 3780,
        "unique-3-nopunct": 3201,
        "entropy-3-nopunct": 11.546859742794322,
        "cond_entropy-3-nopunct": 0.824666615405368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 31.91912,
        "local_recall": {
            "1": 0.5688830226035307
        },
        "rouge1": {
            "precision": 0.57999,
            "recall": 0.55255,
            "fmeasure": 0.55353
        },
        "rouge2": {
            "precision": 0.35931,
            "recall": 0.33756,
            "fmeasure": 0.33993
        },
        "rougeL": {
            "precision": 0.51856,
            "recall": 0.49114,
            "fmeasure": 0.49365
        },
        "rougeLsum": {
            "precision": 0.51856,
            "recall": 0.49114,
            "fmeasure": 0.49365
        },
        "nist": 6.196612803544466,
        "bleurt": -0.06056,
        "bertscore": {
            "precision": 0.87429,
            "recall": 0.86672,
            "f1": 0.87
        },
        "nubia": {
            "semantic_relation": 3.70135,
            "contradiction": 7.33765,
            "irrelevancy": 19.50911,
            "logical_agreement": 73.15324,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.62976,
            "nubia_score": 0.65876
        },
        "meteor": 0.3166743150038589
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.33887,
        "msttr-100_nopunct": 0.32974,
        "total_length": 25761,
        "mean_pred_length": 33.28294573643411,
        "std_pred_length": 4.406219893693168,
        "median_pred_length": 33.0,
        "min_pred_length": 21,
        "max_pred_length": 52,
        "distinct-1": 0.007763673770428167,
        "vocab_size-1": 200,
        "unique-1": 24,
        "entropy-1": 5.980145895029755,
        "distinct-2": 0.03737943730739985,
        "vocab_size-2": 934,
        "unique-2": 155,
        "entropy-2": 8.069460929332203,
        "cond_entropy-2": 2.0257253064071943,
        "distinct-3": 0.08020484863503077,
        "vocab_size-3": 1942,
        "unique-3": 373,
        "entropy-3": 9.355898312286099,
        "cond_entropy-3": 1.2843765770368007,
        "total_length-nopunct": 23589,
        "mean_pred_length-nopunct": 30.476744186046513,
        "std_pred_length-nopunct": 3.9553518180215863,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.008351350205604307,
        "vocab_size-1-nopunct": 197,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 6.0060627452805235,
        "distinct-2-nopunct": 0.039886039886039885,
        "vocab_size-2-nopunct": 910,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 8.024916892782397,
        "cond_entropy-2-nopunct": 2.037075478330762,
        "distinct-3-nopunct": 0.08452429563086974,
        "vocab_size-3-nopunct": 1863,
        "unique-3-nopunct": 365,
        "entropy-3-nopunct": 9.347286473168761,
        "cond_entropy-3-nopunct": 1.3008190940138529,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 32.3703,
        "local_recall": {
            "1": 0.7235083143136616
        },
        "rouge1": {
            "precision": 0.7737,
            "recall": 0.74164,
            "fmeasure": 0.75208
        },
        "rouge2": {
            "precision": 0.46316,
            "recall": 0.4427,
            "fmeasure": 0.44952
        },
        "rougeL": {
            "precision": 0.50313,
            "recall": 0.48311,
            "fmeasure": 0.48954
        },
        "rougeLsum": {
            "precision": 0.50313,
            "recall": 0.48311,
            "fmeasure": 0.48954
        },
        "nist": 5.425334816787731,
        "bleurt": 0.25537,
        "bertscore": {
            "precision": 0.91769,
            "recall": 0.9096,
            "f1": 0.91346
        },
        "nubia": {
            "semantic_relation": 4.49658,
            "contradiction": 3.61179,
            "irrelevancy": 12.53574,
            "logical_agreement": 83.85246,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.21557,
            "nubia_score": 0.83579
        },
        "meteor": 0.3701649657464561
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69091,
        "msttr-100_nopunct": 0.72086,
        "total_length": 6628,
        "mean_pred_length": 13.256,
        "std_pred_length": 7.429297678784987,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 47,
        "distinct-1": 0.15660832830416416,
        "vocab_size-1": 1038,
        "unique-1": 576,
        "entropy-1": 7.874196155039751,
        "distinct-2": 0.4939621409921671,
        "vocab_size-2": 3027,
        "unique-2": 2097,
        "entropy-2": 10.841815197096265,
        "cond_entropy-2": 2.7352192517157756,
        "distinct-3": 0.7244136460554371,
        "vocab_size-3": 4077,
        "unique-3": 3352,
        "entropy-3": 11.671079016808521,
        "cond_entropy-3": 0.8625561022577224,
        "total_length-nopunct": 5811,
        "mean_pred_length-nopunct": 11.622,
        "std_pred_length-nopunct": 6.794933112253571,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1767337807606264,
        "vocab_size-1-nopunct": 1027,
        "unique-1-nopunct": 574,
        "entropy-1-nopunct": 8.0760481452415,
        "distinct-2-nopunct": 0.5127094709094333,
        "vocab_size-2-nopunct": 2723,
        "unique-2-nopunct": 1942,
        "entropy-2-nopunct": 10.681573236591612,
        "cond_entropy-2-nopunct": 2.750095152415474,
        "distinct-3-nopunct": 0.7366999168744804,
        "vocab_size-3-nopunct": 3545,
        "unique-3-nopunct": 2960,
        "entropy-3-nopunct": 11.467792500092038,
        "cond_entropy-3-nopunct": 0.8343999989322535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 31.25124,
        "local_recall": {
            "1": 0.561349165376011
        },
        "rouge1": {
            "precision": 0.56803,
            "recall": 0.54259,
            "fmeasure": 0.54265
        },
        "rouge2": {
            "precision": 0.34734,
            "recall": 0.32757,
            "fmeasure": 0.32822
        },
        "rougeL": {
            "precision": 0.50645,
            "recall": 0.48348,
            "fmeasure": 0.48363
        },
        "rougeLsum": {
            "precision": 0.50645,
            "recall": 0.48348,
            "fmeasure": 0.48363
        },
        "nist": 6.082494288400164,
        "bleurt": -0.13396,
        "bertscore": {
            "precision": 0.86803,
            "recall": 0.86179,
            "f1": 0.86437
        },
        "nubia": {
            "semantic_relation": 3.57014,
            "contradiction": 6.54252,
            "irrelevancy": 24.81185,
            "logical_agreement": 68.64563,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.66649,
            "nubia_score": 0.62323
        },
        "meteor": 0.311877018148857
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74585,
        "msttr-100_nopunct": 0.7703,
        "total_length": 10632,
        "mean_pred_length": 21.264,
        "std_pred_length": 4.79482053887317,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 39,
        "distinct-1": 0.2818848758465011,
        "vocab_size-1": 2997,
        "unique-1": 1938,
        "entropy-1": 9.133951128424561,
        "distinct-2": 0.75,
        "vocab_size-2": 7599,
        "unique-2": 6654,
        "entropy-2": 12.445168469867886,
        "cond_entropy-2": 3.0807250919644686,
        "distinct-3": 0.9286752491694352,
        "vocab_size-3": 8945,
        "unique-3": 8527,
        "entropy-3": 13.053572022168913,
        "cond_entropy-3": 0.6162433500347886,
        "total_length-nopunct": 9903,
        "mean_pred_length-nopunct": 19.806,
        "std_pred_length-nopunct": 4.58436080604483,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.30132283146521255,
        "vocab_size-1-nopunct": 2984,
        "unique-1-nopunct": 1936,
        "entropy-1-nopunct": 9.31587357710036,
        "distinct-2-nopunct": 0.7550781665425927,
        "vocab_size-2-nopunct": 7100,
        "unique-2-nopunct": 6241,
        "entropy-2-nopunct": 12.350797757367406,
        "cond_entropy-2-nopunct": 3.1538527411035426,
        "distinct-3-nopunct": 0.9345164551274852,
        "vocab_size-3-nopunct": 8320,
        "unique-3-nopunct": 7947,
        "entropy-3-nopunct": 12.962054536260585,
        "cond_entropy-3-nopunct": 0.625809257614907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 13.61051,
        "local_recall": {
            "1": 0.4087738805215809
        },
        "rouge1": {
            "precision": 0.4649,
            "recall": 0.43773,
            "fmeasure": 0.44198
        },
        "rouge2": {
            "precision": 0.20734,
            "recall": 0.1956,
            "fmeasure": 0.19698
        },
        "rougeL": {
            "precision": 0.3717,
            "recall": 0.34929,
            "fmeasure": 0.35296
        },
        "rougeLsum": {
            "precision": 0.3717,
            "recall": 0.34929,
            "fmeasure": 0.35296
        },
        "nist": 4.4073417023701955,
        "bleurt": -0.19483,
        "bertscore": {
            "precision": 0.85082,
            "recall": 0.84224,
            "f1": 0.84614
        },
        "nubia": {
            "semantic_relation": 3.28104,
            "contradiction": 14.39541,
            "irrelevancy": 63.17319,
            "logical_agreement": 22.4314,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.63041,
            "nubia_score": 0.52755
        },
        "meteor": 0.20110457526814535
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.70556,
        "msttr-100_nopunct": 0.74375,
        "total_length": 966,
        "mean_pred_length": 16.372881355932204,
        "std_pred_length": 5.048571890987189,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.4865424430641822,
        "vocab_size-1": 470,
        "unique-1": 386,
        "entropy-1": 7.666156136468734,
        "distinct-2": 0.8379272326350606,
        "vocab_size-2": 760,
        "unique-2": 702,
        "entropy-2": 9.360623408964699,
        "cond_entropy-2": 1.455018726060748,
        "distinct-3": 0.9209905660377359,
        "vocab_size-3": 781,
        "unique-3": 744,
        "entropy-3": 9.534196479357123,
        "cond_entropy-3": 0.18758959109757425,
        "total_length-nopunct": 846,
        "mean_pred_length-nopunct": 14.338983050847459,
        "std_pred_length-nopunct": 4.5940645918716685,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5449172576832151,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 383,
        "entropy-1-nopunct": 7.861585477736406,
        "distinct-2-nopunct": 0.8310038119440915,
        "vocab_size-2-nopunct": 654,
        "unique-2-nopunct": 605,
        "entropy-2-nopunct": 9.126080710867038,
        "cond_entropy-2-nopunct": 1.345145081382125,
        "distinct-3-nopunct": 0.9203296703296703,
        "vocab_size-3-nopunct": 670,
        "unique-3-nopunct": 638,
        "entropy-3-nopunct": 9.311684535843616,
        "cond_entropy-3-nopunct": 0.2033584802969831,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.80675,
        "local_recall": {
            "1": 0.18867924528301888,
            "2": 0.5714285714285714,
            "3": 0.7871674491392802
        },
        "rouge1": {
            "precision": 0.76235,
            "recall": 0.74585,
            "fmeasure": 0.74357
        },
        "rouge2": {
            "precision": 0.53432,
            "recall": 0.52796,
            "fmeasure": 0.52277
        },
        "rougeL": {
            "precision": 0.6702,
            "recall": 0.66431,
            "fmeasure": 0.65854
        },
        "rougeLsum": {
            "precision": 0.6702,
            "recall": 0.66431,
            "fmeasure": 0.65854
        },
        "nist": 7.205989042554504,
        "bleurt": 0.34971,
        "bertscore": {
            "precision": 0.93196,
            "recall": 0.93044,
            "f1": 0.92935
        },
        "nubia": {
            "semantic_relation": 4.27546,
            "contradiction": 2.19894,
            "irrelevancy": 33.16012,
            "logical_agreement": 64.64094,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.47887,
            "nubia_score": 0.78295
        },
        "meteor": 0.4041559225837281
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.7475,
        "msttr-100_nopunct": 0.77072,
        "total_length": 10452,
        "mean_pred_length": 20.904,
        "std_pred_length": 4.372503173240701,
        "median_pred_length": 21.0,
        "min_pred_length": 3,
        "max_pred_length": 32,
        "distinct-1": 0.28788748564867966,
        "vocab_size-1": 3009,
        "unique-1": 2027,
        "entropy-1": 9.117577917151658,
        "distinct-2": 0.744975884244373,
        "vocab_size-2": 7414,
        "unique-2": 6489,
        "entropy-2": 12.39583479201885,
        "cond_entropy-2": 3.041567931881287,
        "distinct-3": 0.9220270842149809,
        "vocab_size-3": 8715,
        "unique-3": 8281,
        "entropy-3": 13.004896753898887,
        "cond_entropy-3": 0.6188412490165242,
        "total_length-nopunct": 9727,
        "mean_pred_length-nopunct": 19.454,
        "std_pred_length-nopunct": 4.182808147644354,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.3083170556183818,
        "vocab_size-1-nopunct": 2999,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.308919764348639,
        "distinct-2-nopunct": 0.7499729056031212,
        "vocab_size-2-nopunct": 6920,
        "unique-2-nopunct": 6077,
        "entropy-2-nopunct": 12.301924311853323,
        "cond_entropy-2-nopunct": 3.1119150419970047,
        "distinct-3-nopunct": 0.9284977655551736,
        "vocab_size-3-nopunct": 8103,
        "unique-3-nopunct": 7725,
        "entropy-3-nopunct": 12.911937847798157,
        "cond_entropy-3-nopunct": 0.6252181742165644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "bleu": 12.06079,
        "local_recall": {
            "1": 0.3805256869772999
        },
        "rouge1": {
            "precision": 0.44116,
            "recall": 0.40793,
            "fmeasure": 0.41653
        },
        "rouge2": {
            "precision": 0.18862,
            "recall": 0.17528,
            "fmeasure": 0.1783
        },
        "rougeL": {
            "precision": 0.3518,
            "recall": 0.32482,
            "fmeasure": 0.33184
        },
        "rougeLsum": {
            "precision": 0.3518,
            "recall": 0.32482,
            "fmeasure": 0.33184
        },
        "nist": 4.1108680352339135,
        "bleurt": -0.3044,
        "bertscore": {
            "precision": 0.84241,
            "recall": 0.83261,
            "f1": 0.83716
        },
        "nubia": {
            "semantic_relation": 3.08775,
            "contradiction": 17.05884,
            "irrelevancy": 62.78145,
            "logical_agreement": 20.15971,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.81482,
            "nubia_score": 0.47102
        },
        "meteor": 0.18780651574923132
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.74811,
        "msttr-100_nopunct": 0.77061,
        "total_length": 10660,
        "mean_pred_length": 21.32,
        "std_pred_length": 4.833797678844244,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.27945590994371483,
        "vocab_size-1": 2979,
        "unique-1": 1940,
        "entropy-1": 9.126190610992372,
        "distinct-2": 0.7478346456692914,
        "vocab_size-2": 7598,
        "unique-2": 6629,
        "entropy-2": 12.444920337762778,
        "cond_entropy-2": 3.0906327400252978,
        "distinct-3": 0.931055900621118,
        "vocab_size-3": 8994,
        "unique-3": 8578,
        "entropy-3": 13.065052607417359,
        "cond_entropy-3": 0.6234713961502443,
        "total_length-nopunct": 9925,
        "mean_pred_length-nopunct": 19.85,
        "std_pred_length-nopunct": 4.615571470576531,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.2989420654911839,
        "vocab_size-1-nopunct": 2967,
        "unique-1-nopunct": 1938,
        "entropy-1-nopunct": 9.30947592576242,
        "distinct-2-nopunct": 0.7539522546419098,
        "vocab_size-2-nopunct": 7106,
        "unique-2-nopunct": 6217,
        "entropy-2-nopunct": 12.357806354100983,
        "cond_entropy-2-nopunct": 3.161482048029481,
        "distinct-3-nopunct": 0.9373669467787115,
        "vocab_size-3-nopunct": 8366,
        "unique-3-nopunct": 8002,
        "entropy-3-nopunct": 12.972816321127699,
        "cond_entropy-3-nopunct": 0.6275739860671249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "bleu": 14.05995,
        "local_recall": {
            "1": 0.41030534351145037
        },
        "rouge1": {
            "precision": 0.46596,
            "recall": 0.43938,
            "fmeasure": 0.44443
        },
        "rouge2": {
            "precision": 0.21125,
            "recall": 0.19849,
            "fmeasure": 0.20097
        },
        "rougeL": {
            "precision": 0.37513,
            "recall": 0.35127,
            "fmeasure": 0.35645
        },
        "rougeLsum": {
            "precision": 0.37513,
            "recall": 0.35127,
            "fmeasure": 0.35645
        },
        "nist": 4.476718330149218,
        "bleurt": -0.19095,
        "bertscore": {
            "precision": 0.85298,
            "recall": 0.8428,
            "f1": 0.84755
        },
        "nubia": {
            "semantic_relation": 3.23391,
            "contradiction": 15.40477,
            "irrelevancy": 61.96515,
            "logical_agreement": 22.63008,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.61637,
            "nubia_score": 0.51675
        },
        "meteor": 0.20501736147081218
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.71688,
        "msttr-100_nopunct": 0.76077,
        "total_length": 1613,
        "mean_pred_length": 15.361904761904762,
        "std_pred_length": 7.655839737492407,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.4203347799132052,
        "vocab_size-1": 678,
        "unique-1": 512,
        "entropy-1": 7.962735556866538,
        "distinct-2": 0.8057029177718833,
        "vocab_size-2": 1215,
        "unique-2": 1072,
        "entropy-2": 10.015369578575031,
        "cond_entropy-2": 1.7716737065435497,
        "distinct-3": 0.9194583036350678,
        "vocab_size-3": 1290,
        "unique-3": 1212,
        "entropy-3": 10.264029182830445,
        "cond_entropy-3": 0.237504461475335,
        "total_length-nopunct": 1379,
        "mean_pred_length-nopunct": 13.133333333333333,
        "std_pred_length-nopunct": 6.3771417192921565,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.485859318346628,
        "vocab_size-1-nopunct": 670,
        "unique-1-nopunct": 510,
        "entropy-1-nopunct": 8.255876593394596,
        "distinct-2-nopunct": 0.8335949764521193,
        "vocab_size-2-nopunct": 1062,
        "unique-2-nopunct": 954,
        "entropy-2-nopunct": 9.84791537215014,
        "cond_entropy-2-nopunct": 1.6812907418720746,
        "distinct-3-nopunct": 0.9298545765611634,
        "vocab_size-3-nopunct": 1087,
        "unique-3-nopunct": 1030,
        "entropy-3-nopunct": 10.025477617052944,
        "cond_entropy-3-nopunct": 0.19172330848603414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.23921,
        "local_recall": {
            "1": 0.2543352601156069,
            "2": 0.3931888544891641,
            "3": 0.6881720430107527
        },
        "rouge1": {
            "precision": 0.63322,
            "recall": 0.60589,
            "fmeasure": 0.59968
        },
        "rouge2": {
            "precision": 0.3923,
            "recall": 0.38825,
            "fmeasure": 0.37941
        },
        "rougeL": {
            "precision": 0.53365,
            "recall": 0.51973,
            "fmeasure": 0.5096
        },
        "rougeLsum": {
            "precision": 0.53365,
            "recall": 0.51973,
            "fmeasure": 0.5096
        },
        "nist": 6.512584218847456,
        "bleurt": 0.0933,
        "bertscore": {
            "precision": 0.89341,
            "recall": 0.88703,
            "f1": 0.88811
        },
        "nubia": {
            "semantic_relation": 3.55769,
            "contradiction": 15.69428,
            "irrelevancy": 34.23403,
            "logical_agreement": 50.07169,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.94507,
            "nubia_score": 0.59188
        },
        "meteor": 0.33916892098692974
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.71828,
        "msttr-100_nopunct": 0.7708,
        "total_length": 2938,
        "mean_pred_length": 16.885057471264368,
        "std_pred_length": 7.122774364801224,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 40,
        "distinct-1": 0.4264805990469707,
        "vocab_size-1": 1253,
        "unique-1": 974,
        "entropy-1": 8.501384326613458,
        "distinct-2": 0.8603473227206947,
        "vocab_size-2": 2378,
        "unique-2": 2237,
        "entropy-2": 10.971713585890647,
        "cond_entropy-2": 2.183857443697503,
        "distinct-3": 0.962934362934363,
        "vocab_size-3": 2494,
        "unique-3": 2453,
        "entropy-3": 11.226377667656891,
        "cond_entropy-3": 0.273310232319879,
        "total_length-nopunct": 2581,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 6.154227902247116,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.48237117396358,
        "vocab_size-1-nopunct": 1245,
        "unique-1-nopunct": 972,
        "entropy-1-nopunct": 8.835893120504943,
        "distinct-2-nopunct": 0.8716244287494807,
        "vocab_size-2-nopunct": 2098,
        "unique-2-nopunct": 1984,
        "entropy-2-nopunct": 10.805611146274764,
        "cond_entropy-2-nopunct": 2.1083421057423863,
        "distinct-3-nopunct": 0.9731303179579042,
        "vocab_size-3-nopunct": 2173,
        "unique-3-nopunct": 2138,
        "entropy-3-nopunct": 11.056053775952119,
        "cond_entropy-3-nopunct": 0.27491577923773675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 67.78114,
        "local_recall": {
            "1": 0.049842602308499476,
            "2": 0.15841584158415842,
            "3": 0.3862433862433862,
            "4": 0.5282258064516129,
            "5": 0.631578947368421,
            "6": 0.7492537313432835,
            "7": 0.8742616033755274
        },
        "rouge1": {
            "precision": 0.85316,
            "recall": 0.79175,
            "fmeasure": 0.80848
        },
        "rouge2": {
            "precision": 0.70047,
            "recall": 0.64935,
            "fmeasure": 0.66112
        },
        "rougeL": {
            "precision": 0.81507,
            "recall": 0.75865,
            "fmeasure": 0.77282
        },
        "rougeLsum": {
            "precision": 0.81507,
            "recall": 0.75865,
            "fmeasure": 0.77282
        },
        "nist": 10.18312444208655,
        "bleurt": 0.22278,
        "bertscore": {
            "precision": 0.95464,
            "recall": 0.94309,
            "f1": 0.94663
        },
        "nubia": {
            "semantic_relation": 4.2862,
            "contradiction": 5.57067,
            "irrelevancy": 16.73301,
            "logical_agreement": 77.69632,
            "grammar_ref": 4.58509,
            "grammar_hyp": 4.97484,
            "nubia_score": 0.69224
        },
        "meteor": 0.4580558993609489
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.70917,
        "msttr-100_nopunct": 0.76273,
        "total_length": 1271,
        "mean_pred_length": 16.506493506493506,
        "std_pred_length": 5.9796698354396565,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 38,
        "distinct-1": 0.4704956726986625,
        "vocab_size-1": 598,
        "unique-1": 476,
        "entropy-1": 7.855082423530798,
        "distinct-2": 0.8634840871021775,
        "vocab_size-2": 1031,
        "unique-2": 948,
        "entropy-2": 9.838155808971342,
        "cond_entropy-2": 1.7361615787329119,
        "distinct-3": 0.9579230080572964,
        "vocab_size-3": 1070,
        "unique-3": 1043,
        "entropy-3": 10.022554157153149,
        "cond_entropy-3": 0.18150606845465167,
        "total_length-nopunct": 1100,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 5.386026033899935,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5363636363636364,
        "vocab_size-1-nopunct": 590,
        "unique-1-nopunct": 474,
        "entropy-1-nopunct": 8.135407838295286,
        "distinct-2-nopunct": 0.8885630498533724,
        "vocab_size-2-nopunct": 909,
        "unique-2-nopunct": 855,
        "entropy-2-nopunct": 9.668286578408427,
        "cond_entropy-2-nopunct": 1.622537475351374,
        "distinct-3-nopunct": 0.9682875264270613,
        "vocab_size-3-nopunct": 916,
        "unique-3-nopunct": 897,
        "entropy-3-nopunct": 9.811035495450197,
        "cond_entropy-3-nopunct": 0.16329161952908408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.04118,
        "local_recall": {
            "1": 0.22568093385214008,
            "2": 0.39147286821705424,
            "3": 0.7893368010403121
        },
        "rouge1": {
            "precision": 0.76684,
            "recall": 0.73624,
            "fmeasure": 0.73963
        },
        "rouge2": {
            "precision": 0.54703,
            "recall": 0.51879,
            "fmeasure": 0.52444
        },
        "rougeL": {
            "precision": 0.68198,
            "recall": 0.64783,
            "fmeasure": 0.65471
        },
        "rougeLsum": {
            "precision": 0.68198,
            "recall": 0.64783,
            "fmeasure": 0.65471
        },
        "nist": 7.35820904606149,
        "bleurt": 0.27962,
        "bertscore": {
            "precision": 0.93226,
            "recall": 0.92887,
            "f1": 0.92868
        },
        "nubia": {
            "semantic_relation": 4.14079,
            "contradiction": 5.87897,
            "irrelevancy": 29.06092,
            "logical_agreement": 65.0601,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.63073,
            "nubia_score": 0.72631
        },
        "meteor": 0.3956010365819047
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74302,
        "msttr-100_nopunct": 0.76556,
        "total_length": 10664,
        "mean_pred_length": 21.328,
        "std_pred_length": 4.629947731886398,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.277006751687922,
        "vocab_size-1": 2954,
        "unique-1": 1917,
        "entropy-1": 9.081694000861226,
        "distinct-2": 0.7375049193231011,
        "vocab_size-2": 7496,
        "unique-2": 6524,
        "entropy-2": 12.395857446012409,
        "cond_entropy-2": 3.086792874990177,
        "distinct-3": 0.9214610927152318,
        "vocab_size-3": 8905,
        "unique-3": 8450,
        "entropy-3": 13.035941697758176,
        "cond_entropy-3": 0.6428956569163629,
        "total_length-nopunct": 9922,
        "mean_pred_length-nopunct": 19.844,
        "std_pred_length-nopunct": 4.439781976629032,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.2967143721023987,
        "vocab_size-1-nopunct": 2944,
        "unique-1-nopunct": 1916,
        "entropy-1-nopunct": 9.269428513548203,
        "distinct-2-nopunct": 0.7466567607726597,
        "vocab_size-2-nopunct": 7035,
        "unique-2-nopunct": 6152,
        "entropy-2-nopunct": 12.317205640813539,
        "cond_entropy-2-nopunct": 3.1587435983462444,
        "distinct-3-nopunct": 0.928491369648061,
        "vocab_size-3-nopunct": 8284,
        "unique-3-nopunct": 7882,
        "entropy-3-nopunct": 12.947739547226595,
        "cond_entropy-3-nopunct": 0.6414556013721632,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 14.25278,
        "local_recall": {
            "1": 0.4081814580031696
        },
        "rouge1": {
            "precision": 0.46727,
            "recall": 0.4351,
            "fmeasure": 0.443
        },
        "rouge2": {
            "precision": 0.21392,
            "recall": 0.20062,
            "fmeasure": 0.20324
        },
        "rougeL": {
            "precision": 0.37351,
            "recall": 0.34811,
            "fmeasure": 0.35423
        },
        "rougeLsum": {
            "precision": 0.37351,
            "recall": 0.34811,
            "fmeasure": 0.35423
        },
        "nist": 4.455040618773275,
        "bleurt": -0.19995,
        "bertscore": {
            "precision": 0.85189,
            "recall": 0.84203,
            "f1": 0.84661
        },
        "nubia": {
            "semantic_relation": 3.24709,
            "contradiction": 16.22376,
            "irrelevancy": 61.00223,
            "logical_agreement": 22.77401,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.56009,
            "nubia_score": 0.5238
        },
        "meteor": 0.20322607658060493
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.7016,
        "msttr-100_nopunct": 0.7581,
        "total_length": 2505,
        "mean_pred_length": 15.462962962962964,
        "std_pred_length": 6.3110122144920435,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.34770459081836325,
        "vocab_size-1": 871,
        "unique-1": 638,
        "entropy-1": 8.057594798598844,
        "distinct-2": 0.7639778062313274,
        "vocab_size-2": 1790,
        "unique-2": 1566,
        "entropy-2": 10.49208716696728,
        "cond_entropy-2": 2.143982868419023,
        "distinct-3": 0.9119669876203577,
        "vocab_size-3": 1989,
        "unique-3": 1887,
        "entropy-3": 10.864245750358009,
        "cond_entropy-3": 0.37428566991910645,
        "total_length-nopunct": 2171,
        "mean_pred_length-nopunct": 13.401234567901234,
        "std_pred_length-nopunct": 5.465333934816059,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.3975126669737448,
        "vocab_size-1-nopunct": 863,
        "unique-1-nopunct": 636,
        "entropy-1-nopunct": 8.403362598779765,
        "distinct-2-nopunct": 0.7904430064708811,
        "vocab_size-2-nopunct": 1588,
        "unique-2-nopunct": 1417,
        "entropy-2-nopunct": 10.335893621193145,
        "cond_entropy-2-nopunct": 2.0305007478412835,
        "distinct-3-nopunct": 0.9236599891716297,
        "vocab_size-3-nopunct": 1706,
        "unique-3-nopunct": 1635,
        "entropy-3-nopunct": 10.650961096988691,
        "cond_entropy-3-nopunct": 0.3350024855890646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.89992,
        "local_recall": {
            "1": 0.22324159021406728,
            "2": 0.416289592760181,
            "3": 0.7666878575969485
        },
        "rouge1": {
            "precision": 0.7393,
            "recall": 0.73598,
            "fmeasure": 0.72538
        },
        "rouge2": {
            "precision": 0.49137,
            "recall": 0.49317,
            "fmeasure": 0.4818
        },
        "rougeL": {
            "precision": 0.61692,
            "recall": 0.62077,
            "fmeasure": 0.60748
        },
        "rougeLsum": {
            "precision": 0.61692,
            "recall": 0.62077,
            "fmeasure": 0.60748
        },
        "nist": 7.603388928623716,
        "bleurt": 0.26258,
        "bertscore": {
            "precision": 0.92389,
            "recall": 0.92332,
            "f1": 0.9213
        },
        "nubia": {
            "semantic_relation": 4.2629,
            "contradiction": 4.35723,
            "irrelevancy": 31.26776,
            "logical_agreement": 64.375,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.51287,
            "nubia_score": 0.76535
        },
        "meteor": 0.3918682364681811
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74934,
        "msttr-100_nopunct": 0.77242,
        "total_length": 10641,
        "mean_pred_length": 21.282,
        "std_pred_length": 4.638801138225264,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.28051874823794753,
        "vocab_size-1": 2985,
        "unique-1": 1956,
        "entropy-1": 9.125536587165577,
        "distinct-2": 0.7514051868652006,
        "vocab_size-2": 7620,
        "unique-2": 6711,
        "entropy-2": 12.443460388521464,
        "cond_entropy-2": 3.0871457389918384,
        "distinct-3": 0.9310237527227466,
        "vocab_size-3": 8976,
        "unique-3": 8588,
        "entropy-3": 13.058700661871809,
        "cond_entropy-3": 0.621021468123429,
        "total_length-nopunct": 9901,
        "mean_pred_length-nopunct": 19.802,
        "std_pred_length-nopunct": 4.430213990316946,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.30027269972730025,
        "vocab_size-1-nopunct": 2973,
        "unique-1-nopunct": 1954,
        "entropy-1-nopunct": 9.31099488048146,
        "distinct-2-nopunct": 0.7580044676098288,
        "vocab_size-2-nopunct": 7126,
        "unique-2-nopunct": 6306,
        "entropy-2-nopunct": 12.353236061423576,
        "cond_entropy-2-nopunct": 3.1588700043183384,
        "distinct-3-nopunct": 0.9366363329962926,
        "vocab_size-3-nopunct": 8337,
        "unique-3-nopunct": 7995,
        "entropy-3-nopunct": 12.962757806092185,
        "cond_entropy-3-nopunct": 0.6243940960936207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 13.58288,
        "local_recall": {
            "1": 0.40402230187176424
        },
        "rouge1": {
            "precision": 0.46419,
            "recall": 0.43272,
            "fmeasure": 0.44008
        },
        "rouge2": {
            "precision": 0.20354,
            "recall": 0.19134,
            "fmeasure": 0.1934
        },
        "rougeL": {
            "precision": 0.37009,
            "recall": 0.3446,
            "fmeasure": 0.35052
        },
        "rougeLsum": {
            "precision": 0.37009,
            "recall": 0.3446,
            "fmeasure": 0.35052
        },
        "nist": 4.397780097579156,
        "bleurt": -0.20961,
        "bertscore": {
            "precision": 0.85095,
            "recall": 0.84025,
            "f1": 0.84522
        },
        "nubia": {
            "semantic_relation": 3.21114,
            "contradiction": 16.89754,
            "irrelevancy": 62.08371,
            "logical_agreement": 21.01875,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.63377,
            "nubia_score": 0.51209
        },
        "meteor": 0.20114141830759275
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.71909,
        "msttr-100_nopunct": 0.759,
        "total_length": 1191,
        "mean_pred_length": 20.53448275862069,
        "std_pred_length": 9.122188782344796,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 50,
        "distinct-1": 0.5037783375314862,
        "vocab_size-1": 600,
        "unique-1": 490,
        "entropy-1": 8.01588826481047,
        "distinct-2": 0.9082082965578111,
        "vocab_size-2": 1029,
        "unique-2": 978,
        "entropy-2": 9.893623314387302,
        "cond_entropy-2": 1.6799299781473933,
        "distinct-3": 0.9748837209302326,
        "vocab_size-3": 1048,
        "unique-3": 1036,
        "entropy-3": 9.995875793287821,
        "cond_entropy-3": 0.11586542050342491,
        "total_length-nopunct": 1074,
        "mean_pred_length-nopunct": 18.517241379310345,
        "std_pred_length-nopunct": 8.31956849699663,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5521415270018621,
        "vocab_size-1-nopunct": 593,
        "unique-1-nopunct": 486,
        "entropy-1-nopunct": 8.211275839005259,
        "distinct-2-nopunct": 0.9271653543307087,
        "vocab_size-2-nopunct": 942,
        "unique-2-nopunct": 897,
        "entropy-2-nopunct": 9.804336772418456,
        "cond_entropy-2-nopunct": 1.6863958259970946,
        "distinct-3-nopunct": 0.9895615866388309,
        "vocab_size-3-nopunct": 948,
        "unique-3-nopunct": 939,
        "entropy-3-nopunct": 9.882217036234882,
        "cond_entropy-3-nopunct": 0.08634291155337008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 64.57046,
        "local_recall": {
            "1": 0.04337631887456037,
            "2": 0.14788732394366197,
            "3": 0.33766233766233766,
            "4": 0.5480769230769231,
            "5": 0.6201117318435754,
            "6": 0.7777777777777778,
            "7": 0.852112676056338
        },
        "rouge1": {
            "precision": 0.83924,
            "recall": 0.77193,
            "fmeasure": 0.79238
        },
        "rouge2": {
            "precision": 0.69974,
            "recall": 0.64288,
            "fmeasure": 0.6602
        },
        "rougeL": {
            "precision": 0.82334,
            "recall": 0.75962,
            "fmeasure": 0.77894
        },
        "rougeLsum": {
            "precision": 0.82334,
            "recall": 0.75962,
            "fmeasure": 0.77894
        },
        "nist": 9.137242609863183,
        "bleurt": 0.16934,
        "bertscore": {
            "precision": 0.95087,
            "recall": 0.94007,
            "f1": 0.94334
        },
        "nubia": {
            "semantic_relation": 4.25722,
            "contradiction": 4.74166,
            "irrelevancy": 16.25817,
            "logical_agreement": 79.00016,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.91129,
            "nubia_score": 0.69691
        },
        "meteor": 0.44898181797327236
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.62833,
        "msttr-100_nopunct": 0.68,
        "total_length": 622,
        "mean_pred_length": 17.27777777777778,
        "std_pred_length": 8.029844024744714,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.4180064308681672,
        "vocab_size-1": 260,
        "unique-1": 210,
        "entropy-1": 6.8458178756233785,
        "distinct-2": 0.7679180887372014,
        "vocab_size-2": 450,
        "unique-2": 398,
        "entropy-2": 8.527113850603566,
        "cond_entropy-2": 1.5132772107315464,
        "distinct-3": 0.9072727272727272,
        "vocab_size-3": 499,
        "unique-3": 470,
        "entropy-3": 8.87799071205153,
        "cond_entropy-3": 0.35045956259531125,
        "total_length-nopunct": 514,
        "mean_pred_length-nopunct": 14.277777777777779,
        "std_pred_length-nopunct": 6.36662788431081,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.49416342412451364,
        "vocab_size-1-nopunct": 254,
        "unique-1-nopunct": 209,
        "entropy-1-nopunct": 7.012511770538569,
        "distinct-2-nopunct": 0.8284518828451883,
        "vocab_size-2-nopunct": 396,
        "unique-2-nopunct": 359,
        "entropy-2-nopunct": 8.456479995298265,
        "cond_entropy-2-nopunct": 1.523777101985106,
        "distinct-3-nopunct": 0.9321266968325792,
        "vocab_size-3-nopunct": 412,
        "unique-3-nopunct": 394,
        "entropy-3-nopunct": 8.627509226835793,
        "cond_entropy-3-nopunct": 0.18310196266611284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.98903,
        "local_recall": {
            "1": 0.24561403508771928,
            "2": 0.46226415094339623,
            "3": 0.7419354838709677
        },
        "rouge1": {
            "precision": 0.75692,
            "recall": 0.72403,
            "fmeasure": 0.73461
        },
        "rouge2": {
            "precision": 0.54242,
            "recall": 0.52921,
            "fmeasure": 0.53147
        },
        "rougeL": {
            "precision": 0.67723,
            "recall": 0.65798,
            "fmeasure": 0.66235
        },
        "rougeLsum": {
            "precision": 0.67723,
            "recall": 0.65798,
            "fmeasure": 0.66235
        },
        "nist": 6.262570139612269,
        "bleurt": 0.33161,
        "bertscore": {
            "precision": 0.93141,
            "recall": 0.9239,
            "f1": 0.92649
        },
        "nubia": {
            "semantic_relation": 4.05238,
            "contradiction": 13.15973,
            "irrelevancy": 22.67543,
            "logical_agreement": 64.16485,
            "grammar_ref": 3.9304,
            "grammar_hyp": 4.10971,
            "nubia_score": 0.71369
        },
        "meteor": 0.41149788006209714
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.4,
        "msttr-100_nopunct": 0.4,
        "total_length": 2432,
        "mean_pred_length": 33.31506849315068,
        "std_pred_length": 3.9651796495042864,
        "median_pred_length": 33.0,
        "min_pred_length": 26,
        "max_pred_length": 41,
        "distinct-1": 0.04975328947368421,
        "vocab_size-1": 121,
        "unique-1": 17,
        "entropy-1": 5.806012569178079,
        "distinct-2": 0.16744383213225944,
        "vocab_size-2": 395,
        "unique-2": 132,
        "entropy-2": 7.59577693003289,
        "cond_entropy-2": 1.7327170649473755,
        "distinct-3": 0.2983377077865267,
        "vocab_size-3": 682,
        "unique-3": 318,
        "entropy-3": 8.624832254894677,
        "cond_entropy-3": 1.036916755690954,
        "total_length-nopunct": 2249,
        "mean_pred_length-nopunct": 30.80821917808219,
        "std_pred_length-nopunct": 3.564119266206139,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.052912405513561585,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 5.812776956114493,
        "distinct-2-nopunct": 0.1714154411764706,
        "vocab_size-2-nopunct": 373,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 7.544197523220397,
        "cond_entropy-2-nopunct": 1.7515032967690902,
        "distinct-3-nopunct": 0.3095577746077033,
        "vocab_size-3-nopunct": 651,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 8.604774594965882,
        "cond_entropy-3-nopunct": 1.0385205936746829,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 41.62298,
        "local_recall": {
            "1": 0.7876016260162602
        },
        "rouge1": {
            "precision": 0.79311,
            "recall": 0.79691,
            "fmeasure": 0.79145
        },
        "rouge2": {
            "precision": 0.52534,
            "recall": 0.52732,
            "fmeasure": 0.524
        },
        "rougeL": {
            "precision": 0.57135,
            "recall": 0.57817,
            "fmeasure": 0.57241
        },
        "rougeLsum": {
            "precision": 0.57135,
            "recall": 0.57817,
            "fmeasure": 0.57241
        },
        "nist": 5.680932077312099,
        "bleurt": 0.33647,
        "bertscore": {
            "precision": 0.92807,
            "recall": 0.92372,
            "f1": 0.92578
        },
        "nubia": {
            "semantic_relation": 4.53189,
            "contradiction": 5.34833,
            "irrelevancy": 14.13556,
            "logical_agreement": 80.51611,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.36937,
            "nubia_score": 0.85714
        },
        "meteor": 0.4096108159299701
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.74083,
        "msttr-100_nopunct": 0.809,
        "total_length": 1257,
        "mean_pred_length": 16.539473684210527,
        "std_pred_length": 6.520092002647791,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.5234685759745425,
        "vocab_size-1": 658,
        "unique-1": 547,
        "entropy-1": 8.143777826941776,
        "distinct-2": 0.9043183742591024,
        "vocab_size-2": 1068,
        "unique-2": 1005,
        "entropy-2": 9.950918577993141,
        "cond_entropy-2": 1.5435580526149362,
        "distinct-3": 0.9809954751131221,
        "vocab_size-3": 1084,
        "unique-3": 1067,
        "entropy-3": 10.067871805431007,
        "cond_entropy-3": 0.11424367725705356,
        "total_length-nopunct": 1080,
        "mean_pred_length-nopunct": 14.210526315789474,
        "std_pred_length-nopunct": 5.694678470369195,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6027777777777777,
        "vocab_size-1-nopunct": 651,
        "unique-1-nopunct": 546,
        "entropy-1-nopunct": 8.48514558481874,
        "distinct-2-nopunct": 0.9262948207171314,
        "vocab_size-2-nopunct": 930,
        "unique-2-nopunct": 891,
        "entropy-2-nopunct": 9.766351055476475,
        "cond_entropy-2-nopunct": 1.3576948808443208,
        "distinct-3-nopunct": 0.9859913793103449,
        "vocab_size-3-nopunct": 915,
        "unique-3-nopunct": 903,
        "entropy-3-nopunct": 9.8291502973881,
        "cond_entropy-3-nopunct": 0.07466310762664889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.23535,
        "local_recall": {
            "1": 0.2140468227424749,
            "2": 0.483739837398374,
            "3": 0.7229916897506925
        },
        "rouge1": {
            "precision": 0.71359,
            "recall": 0.68445,
            "fmeasure": 0.68271
        },
        "rouge2": {
            "precision": 0.45903,
            "recall": 0.4458,
            "fmeasure": 0.43964
        },
        "rougeL": {
            "precision": 0.61347,
            "recall": 0.59549,
            "fmeasure": 0.58988
        },
        "rougeLsum": {
            "precision": 0.61347,
            "recall": 0.59549,
            "fmeasure": 0.58988
        },
        "nist": 6.8083698294534605,
        "bleurt": 0.18045,
        "bertscore": {
            "precision": 0.91637,
            "recall": 0.91768,
            "f1": 0.91456
        },
        "nubia": {
            "semantic_relation": 4.07921,
            "contradiction": 4.16221,
            "irrelevancy": 36.22587,
            "logical_agreement": 59.61192,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.88114,
            "nubia_score": 0.66894
        },
        "meteor": 0.3664160509195956
    },
    "web_nlg_en_test": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.65256,
        "msttr-100_nopunct": 0.69291,
        "total_length": 42695,
        "mean_pred_length": 23.999437886453062,
        "std_pred_length": 12.279694354688475,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.04553226373111605,
        "vocab_size-1": 1944,
        "unique-1": 515,
        "entropy-1": 8.126989180202404,
        "distinct-2": 0.1806139407566722,
        "vocab_size-2": 7390,
        "unique-2": 3250,
        "entropy-2": 11.473191277346778,
        "cond_entropy-2": 3.1650084079840877,
        "distinct-3": 0.3410072310090196,
        "vocab_size-3": 13346,
        "unique-3": 7648,
        "entropy-3": 12.747013290277856,
        "cond_entropy-3": 1.3275540650076232,
        "total_length-nopunct": 37819,
        "mean_pred_length-nopunct": 21.258572231590783,
        "std_pred_length-nopunct": 11.064658878395681,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.051111874983473915,
        "vocab_size-1-nopunct": 1933,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.408653169427845,
        "distinct-2-nopunct": 0.19503329633740288,
        "vocab_size-2-nopunct": 7029,
        "unique-2-nopunct": 3300,
        "entropy-2-nopunct": 11.390835907153772,
        "cond_entropy-2-nopunct": 3.119159010615845,
        "distinct-3-nopunct": 0.3586293453197513,
        "vocab_size-3-nopunct": 12287,
        "unique-3-nopunct": 7334,
        "entropy-3-nopunct": 12.625048107240504,
        "cond_entropy-3-nopunct": 1.276974433410807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 47.42833,
        "local_recall": {
            "1": 0.23133857364163177,
            "2": 0.583956492182189,
            "3": 0.8723589743589744,
            "4": 0.9272727272727272,
            "5": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.76878,
            "recall": 0.75145,
            "fmeasure": 0.75362
        },
        "rouge2": {
            "precision": 0.50526,
            "recall": 0.49302,
            "fmeasure": 0.49421
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.59356,
            "fmeasure": 0.59476
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.59356,
            "fmeasure": 0.59476
        },
        "nist": 9.120658926622234,
        "bleurt": 0.20652,
        "bertscore": {
            "precision": 0.92369,
            "recall": 0.92133,
            "f1": 0.92119
        },
        "nubia": {
            "semantic_relation": 4.42974,
            "contradiction": 8.39889,
            "irrelevancy": 7.0246,
            "logical_agreement": 84.57651,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.57942,
            "nubia_score": 0.78492
        },
        "meteor": 0.3860072970767332
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.163856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.4411063109464316,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.001822825622231,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.4358696625802845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.84518,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.6087,
            "recall": 0.73684,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.38889,
            "fmeasure": 0.35
        },
        "rougeL": {
            "precision": 0.52174,
            "recall": 0.63158,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.52174,
            "recall": 0.63158,
            "fmeasure": 0.57143
        },
        "nist": 2.504719249629807,
        "bleurt": 0.3612,
        "bertscore": {
            "precision": 0.89988,
            "recall": 0.9102,
            "f1": 0.90501
        },
        "nubia": {
            "semantic_relation": 4.60428,
            "contradiction": 0.28736,
            "irrelevancy": 14.02664,
            "logical_agreement": 85.686,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.94557,
            "nubia_score": 0.7768
        },
        "meteor": 0.3675799360168742
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.5,
        "median_pred_length": 18.5,
        "min_pred_length": 15,
        "max_pred_length": 22,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.648510460165075,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.3985407228064016,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.024282836980452648,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7714285714285715,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.593429088311723,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.42283496611541005,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.02568167993932012,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.63574,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.71273,
            "recall": 0.83766,
            "fmeasure": 0.76909
        },
        "rouge2": {
            "precision": 0.54196,
            "recall": 0.65,
            "fmeasure": 0.59006
        },
        "rougeL": {
            "precision": 0.69099,
            "recall": 0.81385,
            "fmeasure": 0.74636
        },
        "rougeLsum": {
            "precision": 0.69099,
            "recall": 0.81385,
            "fmeasure": 0.74636
        },
        "nist": 3.4173820656404073,
        "bleurt": 0.6529,
        "bertscore": {
            "precision": 0.93705,
            "recall": 0.96247,
            "f1": 0.94952
        },
        "nubia": {
            "semantic_relation": 4.92814,
            "contradiction": 0.20461,
            "irrelevancy": 2.68557,
            "logical_agreement": 97.10982,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.47063,
            "nubia_score": 0.97736
        },
        "meteor": 0.41729832131420247
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 6.715805299167519,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.7156862745098039,
        "vocab_size-1": 73,
        "unique-1": 61,
        "entropy-1": 5.876726719827085,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.5238489506155258,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.08769671696637776,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 12.571428571428571,
        "std_pred_length-nopunct": 5.851914042361155,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.8372169879309,
        "distinct-2-nopunct": 0.9876543209876543,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.315158644859922,
        "cond_entropy-2-nopunct": 0.5317132916814453,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.1033696102286483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.90122,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.2413793103448276,
            "3": 0.711864406779661
        },
        "rouge1": {
            "precision": 0.73993,
            "recall": 0.68231,
            "fmeasure": 0.69518
        },
        "rouge2": {
            "precision": 0.51947,
            "recall": 0.47928,
            "fmeasure": 0.48604
        },
        "rougeL": {
            "precision": 0.66666,
            "recall": 0.61817,
            "fmeasure": 0.62746
        },
        "rougeLsum": {
            "precision": 0.66666,
            "recall": 0.61817,
            "fmeasure": 0.62746
        },
        "nist": 3.799966949487076,
        "bleurt": 0.06303,
        "bertscore": {
            "precision": 0.90258,
            "recall": 0.89245,
            "f1": 0.89672
        },
        "nubia": {
            "semantic_relation": 4.25818,
            "contradiction": 2.23349,
            "irrelevancy": 15.48899,
            "logical_agreement": 82.27752,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.78083,
            "nubia_score": 0.71415
        },
        "meteor": 0.310252613412044
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.72192,
        "msttr-100_nopunct": 0.76727,
        "total_length": 2660,
        "mean_pred_length": 16.835443037974684,
        "std_pred_length": 6.289292447267948,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 38,
        "distinct-1": 0.41654135338345866,
        "vocab_size-1": 1108,
        "unique-1": 873,
        "entropy-1": 8.416790569634236,
        "distinct-2": 0.8129496402877698,
        "vocab_size-2": 2034,
        "unique-2": 1839,
        "entropy-2": 10.724318854941892,
        "cond_entropy-2": 2.0321013128088454,
        "distinct-3": 0.9343003412969283,
        "vocab_size-3": 2190,
        "unique-3": 2112,
        "entropy-3": 11.024016119064395,
        "cond_entropy-3": 0.3028415795318026,
        "total_length-nopunct": 2294,
        "mean_pred_length-nopunct": 14.518987341772151,
        "std_pred_length-nopunct": 5.374248865958617,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4777680906713165,
        "vocab_size-1-nopunct": 1096,
        "unique-1-nopunct": 871,
        "entropy-1-nopunct": 8.746454295907046,
        "distinct-2-nopunct": 0.8361423220973783,
        "vocab_size-2-nopunct": 1786,
        "unique-2-nopunct": 1641,
        "entropy-2-nopunct": 10.55992461869199,
        "cond_entropy-2-nopunct": 1.928314699062297,
        "distinct-3-nopunct": 0.9373104145601617,
        "vocab_size-3-nopunct": 1854,
        "unique-3-nopunct": 1794,
        "entropy-3-nopunct": 10.785294160836367,
        "cond_entropy-3-nopunct": 0.2545818866598374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.27963,
        "local_recall": {
            "1": 0.25618374558303886,
            "2": 0.4288537549407115,
            "3": 0.7614276768941766
        },
        "rouge1": {
            "precision": 0.73414,
            "recall": 0.72434,
            "fmeasure": 0.71626
        },
        "rouge2": {
            "precision": 0.4862,
            "recall": 0.48221,
            "fmeasure": 0.47521
        },
        "rougeL": {
            "precision": 0.61501,
            "recall": 0.60919,
            "fmeasure": 0.60041
        },
        "rougeLsum": {
            "precision": 0.61501,
            "recall": 0.60919,
            "fmeasure": 0.60041
        },
        "nist": 7.68438385693299,
        "bleurt": 0.20512,
        "bertscore": {
            "precision": 0.91982,
            "recall": 0.91702,
            "f1": 0.91675
        },
        "nubia": {
            "semantic_relation": 4.10296,
            "contradiction": 6.12957,
            "irrelevancy": 35.13407,
            "logical_agreement": 58.73636,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.64919,
            "nubia_score": 0.7096
        },
        "meteor": 0.37926441574671876
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.7365,
        "msttr-100_nopunct": 0.78111,
        "total_length": 2092,
        "mean_pred_length": 17.147540983606557,
        "std_pred_length": 6.857653533536472,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 46,
        "distinct-1": 0.4541108986615679,
        "vocab_size-1": 950,
        "unique-1": 761,
        "entropy-1": 8.358428269041294,
        "distinct-2": 0.8639593908629442,
        "vocab_size-2": 1702,
        "unique-2": 1562,
        "entropy-2": 10.575644614745121,
        "cond_entropy-2": 1.953492074950578,
        "distinct-3": 0.9659090909090909,
        "vocab_size-3": 1785,
        "unique-3": 1736,
        "entropy-3": 10.776787285456837,
        "cond_entropy-3": 0.19671490614037632,
        "total_length-nopunct": 1837,
        "mean_pred_length-nopunct": 15.057377049180328,
        "std_pred_length-nopunct": 6.232252415404027,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5111594991834513,
        "vocab_size-1-nopunct": 939,
        "unique-1-nopunct": 757,
        "entropy-1-nopunct": 8.646355524476085,
        "distinct-2-nopunct": 0.8810495626822158,
        "vocab_size-2-nopunct": 1511,
        "unique-2-nopunct": 1405,
        "entropy-2-nopunct": 10.419011747803506,
        "cond_entropy-2-nopunct": 1.869327662460604,
        "distinct-3-nopunct": 0.9673571876961707,
        "vocab_size-3-nopunct": 1541,
        "unique-3-nopunct": 1502,
        "entropy-3-nopunct": 10.564853566270402,
        "cond_entropy-3-nopunct": 0.16068657415869955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.54336,
        "local_recall": {
            "1": 0.1707865168539326,
            "2": 0.41543026706231456,
            "3": 0.7757216876387861
        },
        "rouge1": {
            "precision": 0.74801,
            "recall": 0.73802,
            "fmeasure": 0.73187
        },
        "rouge2": {
            "precision": 0.50952,
            "recall": 0.49624,
            "fmeasure": 0.49478
        },
        "rougeL": {
            "precision": 0.64217,
            "recall": 0.63168,
            "fmeasure": 0.62718
        },
        "rougeLsum": {
            "precision": 0.64217,
            "recall": 0.63168,
            "fmeasure": 0.62718
        },
        "nist": 7.439055554838723,
        "bleurt": 0.2623,
        "bertscore": {
            "precision": 0.92342,
            "recall": 0.92447,
            "f1": 0.9226
        },
        "nubia": {
            "semantic_relation": 4.24683,
            "contradiction": 4.71347,
            "irrelevancy": 31.82474,
            "logical_agreement": 63.46179,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.62521,
            "nubia_score": 0.74095
        },
        "meteor": 0.39230456891483584
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.618,
        "msttr-100_nopunct": 0.6275,
        "total_length": 558,
        "mean_pred_length": 15.942857142857143,
        "std_pred_length": 5.869742545548348,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.3888888888888889,
        "vocab_size-1": 217,
        "unique-1": 171,
        "entropy-1": 6.597580558054252,
        "distinct-2": 0.7323135755258127,
        "vocab_size-2": 383,
        "unique-2": 338,
        "entropy-2": 8.240159680129432,
        "cond_entropy-2": 1.465679602632802,
        "distinct-3": 0.8504098360655737,
        "vocab_size-3": 415,
        "unique-3": 384,
        "entropy-3": 8.51786636540411,
        "cond_entropy-3": 0.29003512074533294,
        "total_length-nopunct": 469,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 4.998285420307362,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.44989339019189767,
        "vocab_size-1-nopunct": 211,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 6.71258716610701,
        "distinct-2-nopunct": 0.7626728110599078,
        "vocab_size-2-nopunct": 331,
        "unique-2-nopunct": 294,
        "entropy-2-nopunct": 8.074453833253694,
        "cond_entropy-2-nopunct": 1.4285930032352696,
        "distinct-3-nopunct": 0.8621553884711779,
        "vocab_size-3-nopunct": 344,
        "unique-3-nopunct": 321,
        "entropy-3-nopunct": 8.256599165653478,
        "cond_entropy-3-nopunct": 0.22907886843180386,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.10674,
        "local_recall": {
            "1": 0.1839080459770115,
            "2": 0.4230769230769231,
            "3": 0.7809798270893372
        },
        "rouge1": {
            "precision": 0.78457,
            "recall": 0.74785,
            "fmeasure": 0.75557
        },
        "rouge2": {
            "precision": 0.5358,
            "recall": 0.49723,
            "fmeasure": 0.50929
        },
        "rougeL": {
            "precision": 0.65128,
            "recall": 0.62278,
            "fmeasure": 0.62879
        },
        "rougeLsum": {
            "precision": 0.65128,
            "recall": 0.62278,
            "fmeasure": 0.62879
        },
        "nist": 6.234413409956195,
        "bleurt": 0.35715,
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.92272,
            "f1": 0.92265
        },
        "nubia": {
            "semantic_relation": 4.16807,
            "contradiction": 2.50976,
            "irrelevancy": 26.55668,
            "logical_agreement": 70.93356,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.29473,
            "nubia_score": 0.75781
        },
        "meteor": 0.4044336568721873
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.71286,
        "msttr-100_nopunct": 0.75833,
        "total_length": 1424,
        "mean_pred_length": 18.025316455696203,
        "std_pred_length": 8.599344519536276,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 51,
        "distinct-1": 0.42907303370786515,
        "vocab_size-1": 611,
        "unique-1": 481,
        "entropy-1": 7.862649054108367,
        "distinct-2": 0.7717472118959108,
        "vocab_size-2": 1038,
        "unique-2": 924,
        "entropy-2": 9.689071481931348,
        "cond_entropy-2": 1.6075269003462238,
        "distinct-3": 0.8775671406003159,
        "vocab_size-3": 1111,
        "unique-3": 1042,
        "entropy-3": 9.946452864672692,
        "cond_entropy-3": 0.2741876000312792,
        "total_length-nopunct": 1237,
        "mean_pred_length-nopunct": 15.658227848101266,
        "std_pred_length-nopunct": 7.358601401149314,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.48827809215844786,
        "vocab_size-1-nopunct": 604,
        "unique-1-nopunct": 481,
        "entropy-1-nopunct": 8.104792960336635,
        "distinct-2-nopunct": 0.7867012089810017,
        "vocab_size-2-nopunct": 911,
        "unique-2-nopunct": 819,
        "entropy-2-nopunct": 9.518039883073854,
        "cond_entropy-2-nopunct": 1.5146544835679974,
        "distinct-3-nopunct": 0.8869323447636701,
        "vocab_size-3-nopunct": 957,
        "unique-3-nopunct": 906,
        "entropy-3-nopunct": 9.739854028268297,
        "cond_entropy-3-nopunct": 0.25379378396912033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.55698,
        "local_recall": {
            "1": 0.20647773279352227,
            "2": 0.44565217391304346,
            "3": 0.8088737201365188
        },
        "rouge1": {
            "precision": 0.77773,
            "recall": 0.7461,
            "fmeasure": 0.75046
        },
        "rouge2": {
            "precision": 0.56534,
            "recall": 0.54409,
            "fmeasure": 0.54646
        },
        "rougeL": {
            "precision": 0.6712,
            "recall": 0.6451,
            "fmeasure": 0.64759
        },
        "rougeLsum": {
            "precision": 0.6712,
            "recall": 0.6451,
            "fmeasure": 0.64759
        },
        "nist": 7.534659144747798,
        "bleurt": 0.2664,
        "bertscore": {
            "precision": 0.93008,
            "recall": 0.92766,
            "f1": 0.92737
        },
        "nubia": {
            "semantic_relation": 4.10983,
            "contradiction": 12.01943,
            "irrelevancy": 31.52368,
            "logical_agreement": 56.45688,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.47102,
            "nubia_score": 0.71253
        },
        "meteor": 0.4065062285339941
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.65591,
        "msttr-100_nopunct": 0.69105,
        "total_length": 2291,
        "mean_pred_length": 16.845588235294116,
        "std_pred_length": 6.4224773904195125,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 54,
        "distinct-1": 0.3640331732867743,
        "vocab_size-1": 834,
        "unique-1": 649,
        "entropy-1": 7.736765588664549,
        "distinct-2": 0.7127610208816705,
        "vocab_size-2": 1536,
        "unique-2": 1400,
        "entropy-2": 9.912361779692485,
        "cond_entropy-2": 1.9437943876632011,
        "distinct-3": 0.821198613174839,
        "vocab_size-3": 1658,
        "unique-3": 1576,
        "entropy-3": 10.290773905924773,
        "cond_entropy-3": 0.4312238143879357,
        "total_length-nopunct": 1986,
        "mean_pred_length-nopunct": 14.602941176470589,
        "std_pred_length-nopunct": 5.54165962050007,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.4149043303121853,
        "vocab_size-1-nopunct": 824,
        "unique-1-nopunct": 647,
        "entropy-1-nopunct": 7.990359135613909,
        "distinct-2-nopunct": 0.7151351351351352,
        "vocab_size-2-nopunct": 1323,
        "unique-2-nopunct": 1219,
        "entropy-2-nopunct": 9.686254001736826,
        "cond_entropy-2-nopunct": 1.8416407782240594,
        "distinct-3-nopunct": 0.823803967327888,
        "vocab_size-3-nopunct": 1412,
        "unique-3-nopunct": 1344,
        "entropy-3-nopunct": 10.070391874886592,
        "cond_entropy-3-nopunct": 0.45356790855371776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.08908,
        "local_recall": {
            "1": 0.3090909090909091,
            "2": 0.4837662337662338,
            "3": 0.8046057222609909
        },
        "rouge1": {
            "precision": 0.75521,
            "recall": 0.76341,
            "fmeasure": 0.75028
        },
        "rouge2": {
            "precision": 0.53768,
            "recall": 0.54302,
            "fmeasure": 0.5338
        },
        "rougeL": {
            "precision": 0.65526,
            "recall": 0.66614,
            "fmeasure": 0.65277
        },
        "rougeLsum": {
            "precision": 0.65526,
            "recall": 0.66614,
            "fmeasure": 0.65277
        },
        "nist": 7.806534947866569,
        "bleurt": 0.35334,
        "bertscore": {
            "precision": 0.93133,
            "recall": 0.93343,
            "f1": 0.93044
        },
        "nubia": {
            "semantic_relation": 4.26623,
            "contradiction": 5.81997,
            "irrelevancy": 29.04017,
            "logical_agreement": 65.13986,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.39823,
            "nubia_score": 0.77243
        },
        "meteor": 0.4153786911048185
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.666,
        "msttr-100_nopunct": 0.70412,
        "total_length": 2003,
        "mean_pred_length": 18.045045045045047,
        "std_pred_length": 8.35732120902169,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 53,
        "distinct-1": 0.38941587618572143,
        "vocab_size-1": 780,
        "unique-1": 622,
        "entropy-1": 7.791351744114166,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 1376,
        "unique-2": 1240,
        "entropy-2": 9.87005327637245,
        "cond_entropy-2": 1.8664509400718685,
        "distinct-3": 0.8343627175743964,
        "vocab_size-3": 1486,
        "unique-3": 1412,
        "entropy-3": 10.194694928970014,
        "cond_entropy-3": 0.35268342477278847,
        "total_length-nopunct": 1719,
        "mean_pred_length-nopunct": 15.486486486486486,
        "std_pred_length-nopunct": 7.135578746788461,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.447934845840605,
        "vocab_size-1-nopunct": 770,
        "unique-1-nopunct": 619,
        "entropy-1-nopunct": 8.048450762270969,
        "distinct-2-nopunct": 0.7437810945273632,
        "vocab_size-2-nopunct": 1196,
        "unique-2-nopunct": 1099,
        "entropy-2-nopunct": 9.66133948118769,
        "cond_entropy-2-nopunct": 1.7252506741519231,
        "distinct-3-nopunct": 0.8416833667334669,
        "vocab_size-3-nopunct": 1260,
        "unique-3-nopunct": 1203,
        "entropy-3-nopunct": 9.961071830782759,
        "cond_entropy-3-nopunct": 0.34614613095488106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.13499,
        "local_recall": {
            "1": 0.23636363636363636,
            "2": 0.44814814814814813,
            "3": 0.8148443735035914
        },
        "rouge1": {
            "precision": 0.79169,
            "recall": 0.78602,
            "fmeasure": 0.78021
        },
        "rouge2": {
            "precision": 0.60801,
            "recall": 0.60277,
            "fmeasure": 0.59971
        },
        "rougeL": {
            "precision": 0.71376,
            "recall": 0.70834,
            "fmeasure": 0.70322
        },
        "rougeLsum": {
            "precision": 0.71376,
            "recall": 0.70834,
            "fmeasure": 0.70322
        },
        "nist": 7.875173564495798,
        "bleurt": 0.40085,
        "bertscore": {
            "precision": 0.93914,
            "recall": 0.94017,
            "f1": 0.93843
        },
        "nubia": {
            "semantic_relation": 4.35244,
            "contradiction": 3.49557,
            "irrelevancy": 26.15444,
            "logical_agreement": 70.34999,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.42349,
            "nubia_score": 0.78826
        },
        "meteor": 0.426076606527358
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "T5-xl (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.71126,
        "msttr-100_nopunct": 0.73045,
        "total_length": 9587,
        "mean_pred_length": 23.90773067331671,
        "std_pred_length": 4.944980586895147,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.19860227391258997,
        "vocab_size-1": 1904,
        "unique-1": 1148,
        "entropy-1": 8.367570506083188,
        "distinct-2": 0.5830611800566079,
        "vocab_size-2": 5356,
        "unique-2": 4310,
        "entropy-2": 11.591085756160693,
        "cond_entropy-2": 3.0616686883873134,
        "distinct-3": 0.8075128059191804,
        "vocab_size-3": 7094,
        "unique-3": 6380,
        "entropy-3": 12.512543406620116,
        "cond_entropy-3": 0.9047635797124707,
        "total_length-nopunct": 8879,
        "mean_pred_length-nopunct": 22.14214463840399,
        "std_pred_length-nopunct": 4.6656001572102195,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.21319968464917222,
        "vocab_size-1-nopunct": 1893,
        "unique-1-nopunct": 1145,
        "entropy-1-nopunct": 8.506384970411586,
        "distinct-2-nopunct": 0.6020287803727294,
        "vocab_size-2-nopunct": 5104,
        "unique-2-nopunct": 4166,
        "entropy-2-nopunct": 11.544865354568635,
        "cond_entropy-2-nopunct": 3.089907511341854,
        "distinct-3-nopunct": 0.8249350006190417,
        "vocab_size-3-nopunct": 6663,
        "unique-3-nopunct": 6047,
        "entropy-3-nopunct": 12.446707749784487,
        "cond_entropy-3-nopunct": 0.8826460559723694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "bleu": 8.98528,
        "local_recall": {
            "1": 0.3267659778952427
        },
        "rouge1": {
            "precision": 0.3493,
            "recall": 0.34734,
            "fmeasure": 0.34155
        },
        "rouge2": {
            "precision": 0.12421,
            "recall": 0.12574,
            "fmeasure": 0.12262
        },
        "rougeL": {
            "precision": 0.26938,
            "recall": 0.26884,
            "fmeasure": 0.26379
        },
        "rougeLsum": {
            "precision": 0.26938,
            "recall": 0.26884,
            "fmeasure": 0.26379
        },
        "nist": 3.0193336131105712,
        "bleurt": -0.42455,
        "bertscore": {
            "precision": 0.81059,
            "recall": 0.80689,
            "f1": 0.80846
        },
        "nubia": {
            "semantic_relation": 2.66175,
            "contradiction": 14.10653,
            "irrelevancy": 72.23209,
            "logical_agreement": 13.66138,
            "grammar_ref": 4.04957,
            "grammar_hyp": 3.68933,
            "nubia_score": 0.39336
        },
        "meteor": 0.1548354972787063
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74581,
        "msttr-100_nopunct": 0.77082,
        "total_length": 10597,
        "mean_pred_length": 21.194,
        "std_pred_length": 4.834497285137308,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.2802680003774653,
        "vocab_size-1": 2970,
        "unique-1": 1936,
        "entropy-1": 9.115451874753694,
        "distinct-2": 0.7479449341388531,
        "vocab_size-2": 7552,
        "unique-2": 6601,
        "entropy-2": 12.43149674920012,
        "cond_entropy-2": 3.0866348834712447,
        "distinct-3": 0.9300823173908513,
        "vocab_size-3": 8926,
        "unique-3": 8507,
        "entropy-3": 13.052473830564116,
        "cond_entropy-3": 0.6201326251753149,
        "total_length-nopunct": 9864,
        "mean_pred_length-nopunct": 19.728,
        "std_pred_length-nopunct": 4.606735937732919,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.29987834549878345,
        "vocab_size-1-nopunct": 2958,
        "unique-1-nopunct": 1934,
        "entropy-1-nopunct": 9.298088202691341,
        "distinct-2-nopunct": 0.7552328064929518,
        "vocab_size-2-nopunct": 7072,
        "unique-2-nopunct": 6204,
        "entropy-2-nopunct": 12.348095862145753,
        "cond_entropy-2-nopunct": 3.1605563271081607,
        "distinct-3-nopunct": 0.9367102888086642,
        "vocab_size-3-nopunct": 8303,
        "unique-3-nopunct": 7932,
        "entropy-3-nopunct": 12.961715603921512,
        "cond_entropy-3-nopunct": 0.6232865084374294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 13.91592,
        "local_recall": {
            "1": 0.4093009240658899
        },
        "rouge1": {
            "precision": 0.46622,
            "recall": 0.43813,
            "fmeasure": 0.44389
        },
        "rouge2": {
            "precision": 0.21069,
            "recall": 0.19715,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.37435,
            "recall": 0.3499,
            "fmeasure": 0.3553
        },
        "rougeLsum": {
            "precision": 0.37435,
            "recall": 0.3499,
            "fmeasure": 0.3553
        },
        "nist": 4.476025046049924,
        "bleurt": -0.19038,
        "bertscore": {
            "precision": 0.85339,
            "recall": 0.84243,
            "f1": 0.84754
        },
        "nubia": {
            "semantic_relation": 3.22695,
            "contradiction": 15.43555,
            "irrelevancy": 61.52316,
            "logical_agreement": 23.0413,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.61441,
            "nubia_score": 0.51732
        },
        "meteor": 0.2048462788547221
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.44348,
        "msttr-100_nopunct": 0.43597,
        "total_length": 22412,
        "mean_pred_length": 44.824,
        "std_pred_length": 20.108431664354136,
        "median_pred_length": 44.0,
        "min_pred_length": 7,
        "max_pred_length": 89,
        "distinct-1": 0.08102802070319472,
        "vocab_size-1": 1816,
        "unique-1": 781,
        "entropy-1": 5.905666784659342,
        "distinct-2": 0.2195600584154801,
        "vocab_size-2": 4811,
        "unique-2": 2579,
        "entropy-2": 10.21223279047432,
        "cond_entropy-2": 4.302107838539717,
        "distinct-3": 0.39603960396039606,
        "vocab_size-3": 8480,
        "unique-3": 5412,
        "entropy-3": 11.912125976899727,
        "cond_entropy-3": 1.7410523748833553,
        "total_length-nopunct": 20687,
        "mean_pred_length-nopunct": 41.374,
        "std_pred_length-nopunct": 18.845533263879798,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.08739788272828346,
        "vocab_size-1-nopunct": 1808,
        "unique-1-nopunct": 781,
        "entropy-1-nopunct": 5.812958487023157,
        "distinct-2-nopunct": 0.21925001238420766,
        "vocab_size-2-nopunct": 4426,
        "unique-2-nopunct": 2385,
        "entropy-2-nopunct": 10.072484652479739,
        "cond_entropy-2-nopunct": 4.346954260789643,
        "distinct-3-nopunct": 0.39274648245034793,
        "vocab_size-3-nopunct": 7732,
        "unique-3-nopunct": 4976,
        "entropy-3-nopunct": 11.739925591155743,
        "cond_entropy-3-nopunct": 1.7042168935665563,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.96332,
        "local_recall": {
            "1": 0.09338331160365058,
            "2": 0.18303030303030304,
            "3": 0.257396449704142,
            "4": 0.17777777777777778,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.42502,
            "recall": 0.4045,
            "fmeasure": 0.4075
        },
        "rouge2": {
            "precision": 0.21397,
            "recall": 0.20424,
            "fmeasure": 0.20529
        },
        "rougeL": {
            "precision": 0.40699,
            "recall": 0.38754,
            "fmeasure": 0.39014
        },
        "rougeLsum": {
            "precision": 0.40699,
            "recall": 0.38754,
            "fmeasure": 0.39014
        },
        "nist": 1.1021804708398786,
        "bleurt": -0.48208,
        "bertscore": {
            "precision": 0.8606,
            "recall": 0.87275,
            "f1": 0.8662
        },
        "nubia": {
            "semantic_relation": 3.31052,
            "contradiction": 33.3151,
            "irrelevancy": 17.13858,
            "logical_agreement": 49.54632,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.63689,
            "nubia_score": 0.15921
        },
        "meteor": 0.12608945088172063
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.52833,
        "msttr-100_nopunct": 0.54679,
        "total_length": 12006,
        "mean_pred_length": 24.012,
        "std_pred_length": 12.267512217234593,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 74,
        "distinct-1": 0.11136098617357988,
        "vocab_size-1": 1337,
        "unique-1": 437,
        "entropy-1": 8.02818612674585,
        "distinct-2": 0.3440813488614636,
        "vocab_size-2": 3959,
        "unique-2": 2099,
        "entropy-2": 11.077694569004958,
        "cond_entropy-2": 2.8719134448241697,
        "distinct-3": 0.5450663274577503,
        "vocab_size-3": 5999,
        "unique-3": 4069,
        "entropy-3": 12.044272742987333,
        "cond_entropy-3": 1.0111449993154642,
        "total_length-nopunct": 10653,
        "mean_pred_length-nopunct": 21.306,
        "std_pred_length-nopunct": 11.101187504046583,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 64,
        "distinct-1-nopunct": 0.12456584999530648,
        "vocab_size-1-nopunct": 1327,
        "unique-1-nopunct": 435,
        "entropy-1-nopunct": 8.298226032957526,
        "distinct-2-nopunct": 0.35890869693686595,
        "vocab_size-2-nopunct": 3644,
        "unique-2-nopunct": 2015,
        "entropy-2-nopunct": 10.977857821054327,
        "cond_entropy-2-nopunct": 2.8078121734944927,
        "distinct-3-nopunct": 0.5599295555785766,
        "vocab_size-3-nopunct": 5405,
        "unique-3-nopunct": 3765,
        "entropy-3-nopunct": 11.901372916136433,
        "cond_entropy-3-nopunct": 0.9595006341400112,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "bleu": 48.18735,
        "local_recall": {
            "1": 0.23344534492982802,
            "2": 0.5931455717678995,
            "3": 0.8780852655198205,
            "4": 0.6,
            "5": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.76851,
            "recall": 0.75433,
            "fmeasure": 0.75524
        },
        "rouge2": {
            "precision": 0.50687,
            "recall": 0.49626,
            "fmeasure": 0.497
        },
        "rougeL": {
            "precision": 0.60838,
            "recall": 0.59849,
            "fmeasure": 0.59831
        },
        "rougeLsum": {
            "precision": 0.60838,
            "recall": 0.59849,
            "fmeasure": 0.59831
        },
        "nist": 8.988320101813024,
        "bleurt": 0.22199,
        "bertscore": {
            "precision": 0.92432,
            "recall": 0.92231,
            "f1": 0.92203
        },
        "nubia": {
            "semantic_relation": 4.44298,
            "contradiction": 9.03568,
            "irrelevancy": 6.58613,
            "logical_agreement": 84.37819,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.57816,
            "nubia_score": 0.79001
        },
        "meteor": 0.3864781328028413
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.755,
        "total_length": 489,
        "mean_pred_length": 22.227272727272727,
        "std_pred_length": 9.922114044266877,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5603271983640081,
        "vocab_size-1": 274,
        "unique-1": 220,
        "entropy-1": 7.2627559204618315,
        "distinct-2": 0.9143468950749465,
        "vocab_size-2": 427,
        "unique-2": 402,
        "entropy-2": 8.658961368156975,
        "cond_entropy-2": 1.2561534733561932,
        "distinct-3": 0.9820224719101124,
        "vocab_size-3": 437,
        "unique-3": 431,
        "entropy-3": 8.758313716855254,
        "cond_entropy-3": 0.10965118504481206,
        "total_length-nopunct": 434,
        "mean_pred_length-nopunct": 19.727272727272727,
        "std_pred_length-nopunct": 8.729166461205676,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.619815668202765,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 220,
        "entropy-1-nopunct": 7.3917647070144685,
        "distinct-2-nopunct": 0.9174757281553398,
        "vocab_size-2-nopunct": 378,
        "unique-2-nopunct": 357,
        "entropy-2-nopunct": 8.48316451380742,
        "cond_entropy-2-nopunct": 1.14856082878015,
        "distinct-3-nopunct": 0.9897435897435898,
        "vocab_size-3-nopunct": 386,
        "unique-3-nopunct": 382,
        "entropy-3-nopunct": 8.586817493236826,
        "cond_entropy-3-nopunct": 0.11255911351720665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 69.01961,
        "local_recall": {
            "1": 0.04666666666666667,
            "2": 0.2033898305084746,
            "3": 0.4375,
            "4": 0.3877551020408163,
            "5": 0.6081081081081081,
            "6": 0.7272727272727273,
            "7": 0.8869047619047619
        },
        "rouge1": {
            "precision": 0.82956,
            "recall": 0.77785,
            "fmeasure": 0.79163
        },
        "rouge2": {
            "precision": 0.65443,
            "recall": 0.63675,
            "fmeasure": 0.63811
        },
        "rougeL": {
            "precision": 0.80186,
            "recall": 0.75295,
            "fmeasure": 0.7647
        },
        "rougeLsum": {
            "precision": 0.80186,
            "recall": 0.75295,
            "fmeasure": 0.7647
        },
        "nist": 8.260543764805618,
        "bleurt": 0.27364,
        "bertscore": {
            "precision": 0.95626,
            "recall": 0.94551,
            "f1": 0.94851
        },
        "nubia": {
            "semantic_relation": 4.32196,
            "contradiction": 2.39493,
            "irrelevancy": 14.84398,
            "logical_agreement": 82.7611,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.75344,
            "nubia_score": 0.71526
        },
        "meteor": 0.44586137612947263
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 10.208928554075703,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.847457627118644,
        "vocab_size-1": 50,
        "unique-1": 43,
        "entropy-1": 5.551968896746126,
        "distinct-2": 0.9821428571428571,
        "vocab_size-2": 55,
        "unique-2": 54,
        "entropy-2": 5.771640636343323,
        "cond_entropy-2": 0.15247772094868173,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.04169861843780112,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 9.463379711052259,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.9056603773584906,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.539241209280178,
        "distinct-2-nopunct": 0.98,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.603856189774728,
        "cond_entropy-2-nopunct": 0.03593573521152548,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.04671414660772557,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 58.28401,
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.4,
            "3": 0.25,
            "4": 0.5714285714285714,
            "5": 0.6666666666666666,
            "6": 0.5714285714285714,
            "7": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.83072,
            "recall": 0.72357,
            "fmeasure": 0.75678
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.50061,
            "fmeasure": 0.52216
        },
        "rougeL": {
            "precision": 0.73072,
            "recall": 0.63374,
            "fmeasure": 0.66216
        },
        "rougeLsum": {
            "precision": 0.73072,
            "recall": 0.63374,
            "fmeasure": 0.66216
        },
        "nist": 5.899849294400604,
        "bleurt": 0.27333,
        "bertscore": {
            "precision": 0.94858,
            "recall": 0.92555,
            "f1": 0.93197
        },
        "nubia": {
            "semantic_relation": 4.44028,
            "contradiction": 1.40799,
            "irrelevancy": 13.48088,
            "logical_agreement": 85.11113,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.59661,
            "nubia_score": 0.77897
        },
        "meteor": 0.4447109598436815
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.742,
        "msttr-100_nopunct": 0.8125,
        "total_length": 569,
        "mean_pred_length": 18.35483870967742,
        "std_pred_length": 6.245247933283272,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.6028119507908611,
        "vocab_size-1": 343,
        "unique-1": 293,
        "entropy-1": 7.60356941764977,
        "distinct-2": 0.9219330855018587,
        "vocab_size-2": 496,
        "unique-2": 470,
        "entropy-2": 8.885516079996597,
        "cond_entropy-2": 1.0857200685594541,
        "distinct-3": 0.9822485207100592,
        "vocab_size-3": 498,
        "unique-3": 492,
        "entropy-3": 8.944905275263487,
        "cond_entropy-3": 0.061380215497959925,
        "total_length-nopunct": 482,
        "mean_pred_length-nopunct": 15.548387096774194,
        "std_pred_length-nopunct": 5.266073457198228,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6950207468879668,
        "vocab_size-1-nopunct": 335,
        "unique-1-nopunct": 289,
        "entropy-1-nopunct": 7.873054421063899,
        "distinct-2-nopunct": 0.9423503325942351,
        "vocab_size-2-nopunct": 425,
        "unique-2-nopunct": 409,
        "entropy-2-nopunct": 8.678337669789723,
        "cond_entropy-2-nopunct": 0.8621566852434386,
        "distinct-3-nopunct": 0.9976190476190476,
        "vocab_size-3-nopunct": 419,
        "unique-3-nopunct": 418,
        "entropy-3-nopunct": 8.709483612904231,
        "cond_entropy-3-nopunct": 0.03899838253688597,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.52958,
        "local_recall": {
            "1": 0.22123893805309736,
            "2": 0.5,
            "3": 0.8154269972451791
        },
        "rouge1": {
            "precision": 0.79482,
            "recall": 0.7932,
            "fmeasure": 0.78352
        },
        "rouge2": {
            "precision": 0.60469,
            "recall": 0.61157,
            "fmeasure": 0.60051
        },
        "rougeL": {
            "precision": 0.68542,
            "recall": 0.68966,
            "fmeasure": 0.67891
        },
        "rougeLsum": {
            "precision": 0.68542,
            "recall": 0.68966,
            "fmeasure": 0.67891
        },
        "nist": 7.184411422023167,
        "bleurt": 0.35587,
        "bertscore": {
            "precision": 0.93326,
            "recall": 0.93655,
            "f1": 0.93382
        },
        "nubia": {
            "semantic_relation": 4.28206,
            "contradiction": 12.52582,
            "irrelevancy": 22.73976,
            "logical_agreement": 64.73442,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.72662,
            "nubia_score": 0.75062
        },
        "meteor": 0.4476886338173345
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.45508,
        "msttr-100_nopunct": 0.45435,
        "total_length": 12610,
        "mean_pred_length": 58.925233644859816,
        "std_pred_length": 12.222012418674451,
        "median_pred_length": 60.0,
        "min_pred_length": 30,
        "max_pred_length": 89,
        "distinct-1": 0.11467089611419508,
        "vocab_size-1": 1446,
        "unique-1": 733,
        "entropy-1": 5.901806226894462,
        "distinct-2": 0.28985156502097453,
        "vocab_size-2": 3593,
        "unique-2": 2124,
        "entropy-2": 10.103502653273342,
        "cond_entropy-2": 4.206403125710163,
        "distinct-3": 0.49729108520768345,
        "vocab_size-3": 6058,
        "unique-3": 4156,
        "entropy-3": 11.722438994736002,
        "cond_entropy-3": 1.6438401653897734,
        "total_length-nopunct": 11595,
        "mean_pred_length-nopunct": 54.1822429906542,
        "std_pred_length-nopunct": 11.882188925470833,
        "median_pred_length-nopunct": 54.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.1239327296248383,
        "vocab_size-1-nopunct": 1437,
        "unique-1-nopunct": 731,
        "entropy-1-nopunct": 5.804613342342883,
        "distinct-2-nopunct": 0.2939109041384764,
        "vocab_size-2-nopunct": 3345,
        "unique-2-nopunct": 1992,
        "entropy-2-nopunct": 9.993986539976444,
        "cond_entropy-2-nopunct": 4.252936726819038,
        "distinct-3-nopunct": 0.4968209904181965,
        "vocab_size-3-nopunct": 5548,
        "unique-3-nopunct": 3849,
        "entropy-3-nopunct": 11.567281423797967,
        "cond_entropy-3-nopunct": 1.5989358357782926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "bleu": 1.9999,
        "local_recall": {
            "1": 0.08886389201349831,
            "2": 0.18307522123893805,
            "3": 0.2652014652014652
        },
        "rouge1": {
            "precision": 0.4417,
            "recall": 0.4088,
            "fmeasure": 0.41602
        },
        "rouge2": {
            "precision": 0.22245,
            "recall": 0.20942,
            "fmeasure": 0.21143
        },
        "rougeL": {
            "precision": 0.40698,
            "recall": 0.378,
            "fmeasure": 0.3835
        },
        "rougeLsum": {
            "precision": 0.40698,
            "recall": 0.378,
            "fmeasure": 0.3835
        },
        "nist": 1.105945744716476,
        "bleurt": -0.52791,
        "bertscore": {
            "precision": 0.857,
            "recall": 0.86885,
            "f1": 0.86249
        },
        "nubia": {
            "semantic_relation": 3.36091,
            "contradiction": 31.52385,
            "irrelevancy": 17.39387,
            "logical_agreement": 51.08228,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.4452,
            "nubia_score": 0.13013
        },
        "meteor": 0.12859991081734784
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.75167,
        "total_length": 686,
        "mean_pred_length": 22.866666666666667,
        "std_pred_length": 10.594757613503429,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 51,
        "distinct-1": 0.521865889212828,
        "vocab_size-1": 358,
        "unique-1": 280,
        "entropy-1": 7.630120928748722,
        "distinct-2": 0.8978658536585366,
        "vocab_size-2": 589,
        "unique-2": 547,
        "entropy-2": 9.11462784846519,
        "cond_entropy-2": 1.3300260738010126,
        "distinct-3": 0.9616613418530351,
        "vocab_size-3": 602,
        "unique-3": 587,
        "entropy-3": 9.198191461221048,
        "cond_entropy-3": 0.09201045730004151,
        "total_length-nopunct": 605,
        "mean_pred_length-nopunct": 20.166666666666668,
        "std_pred_length-nopunct": 8.744839748229936,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5801652892561984,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.764345035207828,
        "distinct-2-nopunct": 0.9217391304347826,
        "vocab_size-2-nopunct": 530,
        "unique-2-nopunct": 498,
        "entropy-2-nopunct": 8.988932597165372,
        "cond_entropy-2-nopunct": 1.281898064402413,
        "distinct-3-nopunct": 0.9853211009174312,
        "vocab_size-3-nopunct": 537,
        "unique-3-nopunct": 529,
        "entropy-3-nopunct": 9.0607546214992,
        "cond_entropy-3-nopunct": 0.07981205453546919,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 57.61346,
        "local_recall": {
            "1": 0.04524886877828054,
            "2": 0.2222222222222222,
            "3": 0.3728813559322034,
            "4": 0.42028985507246375,
            "5": 0.5543478260869565,
            "6": 0.6688311688311688,
            "7": 0.863013698630137
        },
        "rouge1": {
            "precision": 0.76593,
            "recall": 0.71031,
            "fmeasure": 0.71899
        },
        "rouge2": {
            "precision": 0.5851,
            "recall": 0.55154,
            "fmeasure": 0.55332
        },
        "rougeL": {
            "precision": 0.7237,
            "recall": 0.68867,
            "fmeasure": 0.68759
        },
        "rougeLsum": {
            "precision": 0.7237,
            "recall": 0.68867,
            "fmeasure": 0.68759
        },
        "nist": 7.9044987349321,
        "bleurt": 0.06858,
        "bertscore": {
            "precision": 0.9356,
            "recall": 0.92593,
            "f1": 0.92717
        },
        "nubia": {
            "semantic_relation": 4.09285,
            "contradiction": 4.82945,
            "irrelevancy": 24.94637,
            "logical_agreement": 70.22418,
            "grammar_ref": 4.65355,
            "grammar_hyp": 4.9769,
            "nubia_score": 0.63086
        },
        "meteor": 0.4163639556418181
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.70111,
        "msttr-100_nopunct": 0.7475,
        "total_length": 922,
        "mean_pred_length": 18.44,
        "std_pred_length": 11.191353805505392,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 79,
        "distinct-1": 0.5162689804772235,
        "vocab_size-1": 476,
        "unique-1": 393,
        "entropy-1": 7.713308021100668,
        "distinct-2": 0.8784403669724771,
        "vocab_size-2": 766,
        "unique-2": 713,
        "entropy-2": 9.436591575624064,
        "cond_entropy-2": 1.5221057293829898,
        "distinct-3": 0.9732360097323601,
        "vocab_size-3": 800,
        "unique-3": 784,
        "entropy-3": 9.622320249155209,
        "cond_entropy-3": 0.1888669186132929,
        "total_length-nopunct": 802,
        "mean_pred_length-nopunct": 16.04,
        "std_pred_length-nopunct": 9.236795981291348,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.5860349127182045,
        "vocab_size-1-nopunct": 470,
        "unique-1-nopunct": 392,
        "entropy-1-nopunct": 7.945215207424047,
        "distinct-2-nopunct": 0.9082446808510638,
        "vocab_size-2-nopunct": 683,
        "unique-2-nopunct": 650,
        "entropy-2-nopunct": 9.293744225611661,
        "cond_entropy-2-nopunct": 1.4271096178456186,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 693,
        "unique-3-nopunct": 685,
        "entropy-3-nopunct": 9.428610856341468,
        "cond_entropy-3-nopunct": 0.14917180352648254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.53756,
        "local_recall": {
            "1": 0.19333333333333333,
            "2": 0.5786163522012578,
            "3": 0.7390510948905109
        },
        "rouge1": {
            "precision": 0.76304,
            "recall": 0.73858,
            "fmeasure": 0.73936
        },
        "rouge2": {
            "precision": 0.5475,
            "recall": 0.54198,
            "fmeasure": 0.53639
        },
        "rougeL": {
            "precision": 0.66343,
            "recall": 0.65682,
            "fmeasure": 0.64947
        },
        "rougeLsum": {
            "precision": 0.66343,
            "recall": 0.65682,
            "fmeasure": 0.64947
        },
        "nist": 6.8012119553212,
        "bleurt": 0.23043,
        "bertscore": {
            "precision": 0.92239,
            "recall": 0.91833,
            "f1": 0.91906
        },
        "nubia": {
            "semantic_relation": 4.20921,
            "contradiction": 6.60944,
            "irrelevancy": 24.49595,
            "logical_agreement": 68.89461,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.72275,
            "nubia_score": 0.72523
        },
        "meteor": 0.3800425604311544
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.66125,
        "msttr-100_nopunct": 0.70857,
        "total_length": 842,
        "mean_pred_length": 11.859154929577464,
        "std_pred_length": 4.495054480071819,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.4418052256532066,
        "vocab_size-1": 372,
        "unique-1": 296,
        "entropy-1": 7.1830290011399045,
        "distinct-2": 0.8067444876783398,
        "vocab_size-2": 622,
        "unique-2": 558,
        "entropy-2": 9.012203671389159,
        "cond_entropy-2": 1.4944085118244201,
        "distinct-3": 0.9157142857142857,
        "vocab_size-3": 641,
        "unique-3": 600,
        "entropy-3": 9.254012397521944,
        "cond_entropy-3": 0.2387314960276152,
        "total_length-nopunct": 746,
        "mean_pred_length-nopunct": 10.507042253521126,
        "std_pred_length-nopunct": 4.027627265845344,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.49195710455764075,
        "vocab_size-1-nopunct": 367,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.3702902232784915,
        "distinct-2-nopunct": 0.8074074074074075,
        "vocab_size-2-nopunct": 545,
        "unique-2-nopunct": 489,
        "entropy-2-nopunct": 8.821026038023676,
        "cond_entropy-2-nopunct": 1.5908151894643365,
        "distinct-3-nopunct": 0.9089403973509934,
        "vocab_size-3-nopunct": 549,
        "unique-3-nopunct": 511,
        "entropy-3-nopunct": 9.024358029862881,
        "cond_entropy-3-nopunct": 0.2538718930506238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.25827,
        "local_recall": {
            "1": 0.27932960893854747,
            "2": 0.5526315789473685,
            "3": 0.7751004016064257
        },
        "rouge1": {
            "precision": 0.74181,
            "recall": 0.73647,
            "fmeasure": 0.71984
        },
        "rouge2": {
            "precision": 0.55065,
            "recall": 0.55607,
            "fmeasure": 0.53729
        },
        "rougeL": {
            "precision": 0.70503,
            "recall": 0.70675,
            "fmeasure": 0.68707
        },
        "rougeLsum": {
            "precision": 0.70503,
            "recall": 0.70675,
            "fmeasure": 0.68707
        },
        "nist": 6.880833307837285,
        "bleurt": 0.27913,
        "bertscore": {
            "precision": 0.93523,
            "recall": 0.93507,
            "f1": 0.93307
        },
        "nubia": {
            "semantic_relation": 4.02257,
            "contradiction": 5.90388,
            "irrelevancy": 43.13748,
            "logical_agreement": 50.95864,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.36303,
            "nubia_score": 0.6673
        },
        "meteor": 0.40117359060826024
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.74,
        "total_length": 298,
        "mean_pred_length": 21.285714285714285,
        "std_pred_length": 20.285211261368893,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 91,
        "distinct-1": 0.5503355704697986,
        "vocab_size-1": 164,
        "unique-1": 131,
        "entropy-1": 6.585258820473577,
        "distinct-2": 0.8697183098591549,
        "vocab_size-2": 247,
        "unique-2": 224,
        "entropy-2": 7.819203799149325,
        "cond_entropy-2": 1.1268033127990653,
        "distinct-3": 0.9407407407407408,
        "vocab_size-3": 254,
        "unique-3": 238,
        "entropy-3": 7.958297078532324,
        "cond_entropy-3": 0.06734367377180532,
        "total_length-nopunct": 241,
        "mean_pred_length-nopunct": 17.214285714285715,
        "std_pred_length-nopunct": 14.919682931467081,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.6639004149377593,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.812242198473084,
        "distinct-2-nopunct": 0.920704845814978,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.640360546733672,
        "cond_entropy-2-nopunct": 0.873224669525625,
        "distinct-3-nopunct": 0.9577464788732394,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.650202577972356,
        "cond_entropy-3-nopunct": 0.012690064890277282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.81671,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.4074074074074074,
            "3": 0.6764705882352942
        },
        "rouge1": {
            "precision": 0.71686,
            "recall": 0.67663,
            "fmeasure": 0.67763
        },
        "rouge2": {
            "precision": 0.42863,
            "recall": 0.40528,
            "fmeasure": 0.40762
        },
        "rougeL": {
            "precision": 0.58205,
            "recall": 0.55451,
            "fmeasure": 0.55275
        },
        "rougeLsum": {
            "precision": 0.58205,
            "recall": 0.55451,
            "fmeasure": 0.55275
        },
        "nist": 4.547572791553164,
        "bleurt": 0.32568,
        "bertscore": {
            "precision": 0.91852,
            "recall": 0.91958,
            "f1": 0.91798
        },
        "nubia": {
            "semantic_relation": 4.4109,
            "contradiction": 17.64015,
            "irrelevancy": 8.34641,
            "logical_agreement": 74.01344,
            "grammar_ref": 4.7817,
            "grammar_hyp": 5.01791,
            "nubia_score": 0.75964
        },
        "meteor": 0.33810152931314397
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.77446,
        "total_length": 10522,
        "mean_pred_length": 21.784679089026916,
        "std_pred_length": 5.541786794929322,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.3122980421973009,
        "vocab_size-1": 3286,
        "unique-1": 2427,
        "entropy-1": 9.185267850789955,
        "distinct-2": 0.7371252116744695,
        "vocab_size-2": 7400,
        "unique-2": 6467,
        "entropy-2": 12.380351492773848,
        "cond_entropy-2": 2.967471293211124,
        "distinct-3": 0.9152365006278778,
        "vocab_size-3": 8746,
        "unique-3": 8271,
        "entropy-3": 13.005983102630593,
        "cond_entropy-3": 0.6241440440744573,
        "total_length-nopunct": 9267,
        "mean_pred_length-nopunct": 19.18633540372671,
        "std_pred_length-nopunct": 4.989270021676725,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.3531887342181936,
        "vocab_size-1-nopunct": 3273,
        "unique-1-nopunct": 2424,
        "entropy-1-nopunct": 9.573234561500938,
        "distinct-2-nopunct": 0.76775956284153,
        "vocab_size-2-nopunct": 6744,
        "unique-2-nopunct": 6012,
        "entropy-2-nopunct": 12.274618391595208,
        "cond_entropy-2-nopunct": 2.797436995527372,
        "distinct-3-nopunct": 0.9255511384170582,
        "vocab_size-3-nopunct": 7683,
        "unique-3-nopunct": 7321,
        "entropy-3-nopunct": 12.827856459831038,
        "cond_entropy-3-nopunct": 0.5759022216370195,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.40363,
        "local_recall": {
            "1": 0.23327515997673065,
            "2": 0.41935483870967744,
            "3": 0.7793345008756567
        },
        "rouge1": {
            "precision": 0.74927,
            "recall": 0.74444,
            "fmeasure": 0.73747
        },
        "rouge2": {
            "precision": 0.49319,
            "recall": 0.49013,
            "fmeasure": 0.48525
        },
        "rougeL": {
            "precision": 0.60617,
            "recall": 0.60235,
            "fmeasure": 0.59621
        },
        "rougeLsum": {
            "precision": 0.60617,
            "recall": 0.60235,
            "fmeasure": 0.59621
        },
        "nist": 8.807408102623368,
        "bleurt": 0.20866,
        "bertscore": {
            "precision": 0.92241,
            "recall": 0.92373,
            "f1": 0.92132
        },
        "nubia": {
            "semantic_relation": 4.19665,
            "contradiction": 7.51964,
            "irrelevancy": 36.42286,
            "logical_agreement": 56.0575,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.26361,
            "nubia_score": 0.73904
        },
        "meteor": 0.3888076223881044
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 11.346805717910216,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 38,
        "distinct-1": 0.7702702702702703,
        "vocab_size-1": 57,
        "unique-1": 49,
        "entropy-1": 5.61128225067638,
        "distinct-2": 0.9857142857142858,
        "vocab_size-2": 69,
        "unique-2": 68,
        "entropy-2": 6.100711588373543,
        "cond_entropy-2": 0.40932482998016545,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.05458586728348304,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 9.300537618869138,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.859375,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.675704882778696,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.906890595608517,
        "cond_entropy-2-nopunct": 0.23613872064457653,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.807354922057609,
        "cond_entropy-3-nopunct": -0.09953567355091447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 82.02839,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8181818181818182,
            "3": 0.9777777777777777
        },
        "rouge1": {
            "precision": 0.90545,
            "recall": 0.96303,
            "fmeasure": 0.92666
        },
        "rouge2": {
            "precision": 0.76411,
            "recall": 0.813,
            "fmeasure": 0.78209
        },
        "rougeL": {
            "precision": 0.79244,
            "recall": 0.83285,
            "fmeasure": 0.80708
        },
        "rougeLsum": {
            "precision": 0.79244,
            "recall": 0.83285,
            "fmeasure": 0.80708
        },
        "nist": 5.896573264369757,
        "bleurt": 0.61727,
        "bertscore": {
            "precision": 0.97568,
            "recall": 0.98431,
            "f1": 0.97995
        },
        "nubia": {
            "semantic_relation": 4.55256,
            "contradiction": 2.11512,
            "irrelevancy": 41.32635,
            "logical_agreement": 56.55854,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.16124,
            "nubia_score": 0.86043
        },
        "meteor": 0.5677364185049677
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "total_length": 179,
        "mean_pred_length": 16.272727272727273,
        "std_pred_length": 3.9101478486557393,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6759776536312849,
        "vocab_size-1": 121,
        "unique-1": 100,
        "entropy-1": 6.48185360526146,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 160,
        "unique-2": 153,
        "entropy-2": 7.2925859495516265,
        "cond_entropy-2": 0.6498266067128707,
        "distinct-3": 0.9936305732484076,
        "vocab_size-3": 156,
        "unique-3": 155,
        "entropy-3": 7.281881895388438,
        "cond_entropy-3": -0.003716498714117834,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 3.7921188390207656,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7452229299363057,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.576352239525328,
        "distinct-2-nopunct": 0.952054794520548,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.088763685577531,
        "cond_entropy-2-nopunct": 0.5419730289447166,
        "distinct-3-nopunct": 0.9925925925925926,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.062000782236041,
        "cond_entropy-3-nopunct": -0.025935721072419878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.97292,
        "local_recall": {
            "1": 0.13953488372093023,
            "2": 0.3684210526315789,
            "3": 0.7205882352941176
        },
        "rouge1": {
            "precision": 0.75586,
            "recall": 0.68939,
            "fmeasure": 0.71704
        },
        "rouge2": {
            "precision": 0.54093,
            "recall": 0.49294,
            "fmeasure": 0.51272
        },
        "rougeL": {
            "precision": 0.60767,
            "recall": 0.54132,
            "fmeasure": 0.5695
        },
        "rougeLsum": {
            "precision": 0.60767,
            "recall": 0.54132,
            "fmeasure": 0.5695
        },
        "nist": 5.338115185753477,
        "bleurt": 0.1958,
        "bertscore": {
            "precision": 0.91986,
            "recall": 0.90808,
            "f1": 0.91273
        },
        "nubia": {
            "semantic_relation": 4.18295,
            "contradiction": 16.42924,
            "irrelevancy": 19.36274,
            "logical_agreement": 64.20803,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.73177,
            "nubia_score": 0.69954
        },
        "meteor": 0.37496566794609604
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.54,
        "msttr-100_nopunct": 0.56667,
        "total_length": 739,
        "mean_pred_length": 15.395833333333334,
        "std_pred_length": 6.346716944391188,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.33288227334235454,
        "vocab_size-1": 246,
        "unique-1": 195,
        "entropy-1": 6.368503573493527,
        "distinct-2": 0.6034732272069464,
        "vocab_size-2": 417,
        "unique-2": 362,
        "entropy-2": 8.017970092766866,
        "cond_entropy-2": 1.4790156112468202,
        "distinct-3": 0.7200622083981337,
        "vocab_size-3": 463,
        "unique-3": 414,
        "entropy-3": 8.431582887210226,
        "cond_entropy-3": 0.45497590153068523,
        "total_length-nopunct": 634,
        "mean_pred_length-nopunct": 13.208333333333334,
        "std_pred_length-nopunct": 5.045453123577923,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.3801261829652997,
        "vocab_size-1-nopunct": 241,
        "unique-1-nopunct": 195,
        "entropy-1-nopunct": 6.474602018908217,
        "distinct-2-nopunct": 0.6143344709897611,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 314,
        "entropy-2-nopunct": 7.831107711458467,
        "cond_entropy-2-nopunct": 1.4612461124009963,
        "distinct-3-nopunct": 0.724907063197026,
        "vocab_size-3-nopunct": 390,
        "unique-3-nopunct": 348,
        "entropy-3-nopunct": 8.19117446587309,
        "cond_entropy-3-nopunct": 0.4408242030880121,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 67.40397,
        "local_recall": {
            "1": 0.33783783783783783,
            "2": 0.6875,
            "3": 0.8165680473372781
        },
        "rouge1": {
            "precision": 0.8297,
            "recall": 0.81234,
            "fmeasure": 0.81406
        },
        "rouge2": {
            "precision": 0.65977,
            "recall": 0.65362,
            "fmeasure": 0.6524
        },
        "rougeL": {
            "precision": 0.76974,
            "recall": 0.76343,
            "fmeasure": 0.76072
        },
        "rougeLsum": {
            "precision": 0.76974,
            "recall": 0.76343,
            "fmeasure": 0.76072
        },
        "nist": 7.563111647780914,
        "bleurt": 0.56405,
        "bertscore": {
            "precision": 0.95434,
            "recall": 0.94921,
            "f1": 0.95079
        },
        "nubia": {
            "semantic_relation": 4.46926,
            "contradiction": 0.76003,
            "irrelevancy": 20.286,
            "logical_agreement": 78.95397,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.03748,
            "nubia_score": 0.86068
        },
        "meteor": 0.4642639832797303
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 199,
        "mean_pred_length": 22.11111111111111,
        "std_pred_length": 8.986959001729419,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.7085427135678392,
        "vocab_size-1": 141,
        "unique-1": 121,
        "entropy-1": 6.720080504194541,
        "distinct-2": 0.9631578947368421,
        "vocab_size-2": 183,
        "unique-2": 180,
        "entropy-2": 7.467172581992396,
        "cond_entropy-2": 0.626639511899991,
        "distinct-3": 1.0,
        "vocab_size-3": 181,
        "unique-3": 181,
        "entropy-3": 7.499845887083174,
        "cond_entropy-3": 0.037779090930859224,
        "total_length-nopunct": 175,
        "mean_pred_length-nopunct": 19.444444444444443,
        "std_pred_length-nopunct": 7.365250408522911,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7657142857142857,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.726475361294387,
        "distinct-2-nopunct": 0.9578313253012049,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.257510666260602,
        "cond_entropy-2-nopunct": 0.558280014332729,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 157,
        "unique-3-nopunct": 157,
        "entropy-3-nopunct": 7.294620748891623,
        "cond_entropy-3-nopunct": 0.043847400374810094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 61.93883,
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.18181818181818182,
            "3": 0.5,
            "4": 0.75,
            "5": 0.5882352941176471,
            "6": 0.72,
            "7": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.84296,
            "recall": 0.73901,
            "fmeasure": 0.7739
        },
        "rouge2": {
            "precision": 0.65245,
            "recall": 0.57946,
            "fmeasure": 0.60442
        },
        "rougeL": {
            "precision": 0.80514,
            "recall": 0.70873,
            "fmeasure": 0.74218
        },
        "rougeLsum": {
            "precision": 0.80514,
            "recall": 0.70873,
            "fmeasure": 0.74218
        },
        "nist": 7.0800238473461174,
        "bleurt": 0.1054,
        "bertscore": {
            "precision": 0.94955,
            "recall": 0.92497,
            "f1": 0.93539
        },
        "nubia": {
            "semantic_relation": 4.33317,
            "contradiction": 5.9977,
            "irrelevancy": 29.21907,
            "logical_agreement": 64.78323,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.13462,
            "nubia_score": 0.64791
        },
        "meteor": 0.4291300463223153
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.78,
        "total_length": 265,
        "mean_pred_length": 18.928571428571427,
        "std_pred_length": 8.232898168014588,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.6452830188679245,
        "vocab_size-1": 171,
        "unique-1": 145,
        "entropy-1": 6.867576305774837,
        "distinct-2": 0.9641434262948207,
        "vocab_size-2": 242,
        "unique-2": 234,
        "entropy-2": 7.896822886611469,
        "cond_entropy-2": 0.8828276266639116,
        "distinct-3": 0.9957805907172996,
        "vocab_size-3": 236,
        "unique-3": 235,
        "entropy-3": 7.880304430332904,
        "cond_entropy-3": -0.02054339576068386,
        "total_length-nopunct": 236,
        "mean_pred_length-nopunct": 16.857142857142858,
        "std_pred_length-nopunct": 7.079720967636495,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.7033898305084746,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 6.950670897411644,
        "distinct-2-nopunct": 0.9684684684684685,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.727952409133141,
        "cond_entropy-2-nopunct": 0.81540154607546,
        "distinct-3-nopunct": 0.9951923076923077,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.690824333525683,
        "cond_entropy-3-nopunct": -0.04027458570207962,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.85962,
        "local_recall": {
            "1": 0.22033898305084745,
            "2": 0.2391304347826087,
            "3": 0.703030303030303
        },
        "rouge1": {
            "precision": 0.6964,
            "recall": 0.67023,
            "fmeasure": 0.67171
        },
        "rouge2": {
            "precision": 0.46221,
            "recall": 0.45222,
            "fmeasure": 0.4476
        },
        "rougeL": {
            "precision": 0.62267,
            "recall": 0.61303,
            "fmeasure": 0.60645
        },
        "rougeLsum": {
            "precision": 0.62267,
            "recall": 0.61303,
            "fmeasure": 0.60645
        },
        "nist": 5.010887226230988,
        "bleurt": 0.15668,
        "bertscore": {
            "precision": 0.90412,
            "recall": 0.90797,
            "f1": 0.90428
        },
        "nubia": {
            "semantic_relation": 4.00154,
            "contradiction": 10.01167,
            "irrelevancy": 36.68051,
            "logical_agreement": 53.30783,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.43894,
            "nubia_score": 0.68723
        },
        "meteor": 0.3365061649447046
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.72412,
        "msttr-100_nopunct": 0.74933,
        "total_length": 1715,
        "mean_pred_length": 27.22222222222222,
        "std_pred_length": 8.014757112331283,
        "median_pred_length": 27.0,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.439067055393586,
        "vocab_size-1": 753,
        "unique-1": 575,
        "entropy-1": 8.192021935638847,
        "distinct-2": 0.8692493946731235,
        "vocab_size-2": 1436,
        "unique-2": 1352,
        "entropy-2": 10.237301100621767,
        "cond_entropy-2": 1.8926369559305452,
        "distinct-3": 0.9477658904971681,
        "vocab_size-3": 1506,
        "unique-3": 1484,
        "entropy-3": 10.41811844195025,
        "cond_entropy-3": 0.1949897156897214,
        "total_length-nopunct": 1526,
        "mean_pred_length-nopunct": 24.22222222222222,
        "std_pred_length-nopunct": 6.986255087032928,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4875491480996068,
        "vocab_size-1-nopunct": 744,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 8.419810182655587,
        "distinct-2-nopunct": 0.9056732740943267,
        "vocab_size-2-nopunct": 1325,
        "unique-2-nopunct": 1256,
        "entropy-2-nopunct": 10.2328836403791,
        "cond_entropy-2-nopunct": 1.8830346974108763,
        "distinct-3-nopunct": 0.9842857142857143,
        "vocab_size-3-nopunct": 1378,
        "unique-3-nopunct": 1363,
        "entropy-3-nopunct": 10.414697243633503,
        "cond_entropy-3-nopunct": 0.19193528437249424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "bleu": 60.4247,
        "local_recall": {
            "1": 0.05689488910318226,
            "2": 0.15527950310559005,
            "3": 0.40425531914893614,
            "4": 0.5522388059701493,
            "5": 0.6509803921568628,
            "6": 0.72544080604534,
            "7": 0.8566037735849057
        },
        "rouge1": {
            "precision": 0.79153,
            "recall": 0.76214,
            "fmeasure": 0.76848
        },
        "rouge2": {
            "precision": 0.63496,
            "recall": 0.62323,
            "fmeasure": 0.62167
        },
        "rougeL": {
            "precision": 0.75066,
            "recall": 0.73775,
            "fmeasure": 0.73598
        },
        "rougeLsum": {
            "precision": 0.75066,
            "recall": 0.73775,
            "fmeasure": 0.73598
        },
        "nist": 8.88612767082791,
        "bleurt": 0.04201,
        "bertscore": {
            "precision": 0.9326,
            "recall": 0.93793,
            "f1": 0.93251
        },
        "nubia": {
            "semantic_relation": 4.18485,
            "contradiction": 4.26191,
            "irrelevancy": 23.83492,
            "logical_agreement": 71.90317,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.73676,
            "nubia_score": 0.66006
        },
        "meteor": 0.4298814476289402
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.64737,
        "msttr-100_nopunct": 0.69294,
        "total_length": 1985,
        "mean_pred_length": 16.13821138211382,
        "std_pred_length": 8.168276134670531,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 53,
        "distinct-1": 0.3904282115869018,
        "vocab_size-1": 775,
        "unique-1": 639,
        "entropy-1": 7.689717579562027,
        "distinct-2": 0.7277121374865736,
        "vocab_size-2": 1355,
        "unique-2": 1244,
        "entropy-2": 9.826775373406143,
        "cond_entropy-2": 1.894142121705157,
        "distinct-3": 0.8372627947096032,
        "vocab_size-3": 1456,
        "unique-3": 1393,
        "entropy-3": 10.189291254675855,
        "cond_entropy-3": 0.3721958678511447,
        "total_length-nopunct": 1720,
        "mean_pred_length-nopunct": 13.983739837398375,
        "std_pred_length-nopunct": 6.8098252067839145,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.44651162790697674,
        "vocab_size-1-nopunct": 768,
        "unique-1-nopunct": 638,
        "entropy-1-nopunct": 7.95954077413444,
        "distinct-2-nopunct": 0.7470256731371321,
        "vocab_size-2-nopunct": 1193,
        "unique-2-nopunct": 1105,
        "entropy-2-nopunct": 9.673079622374638,
        "cond_entropy-2-nopunct": 1.8218238035341927,
        "distinct-3-nopunct": 0.8514246947082768,
        "vocab_size-3-nopunct": 1255,
        "unique-3-nopunct": 1205,
        "entropy-3-nopunct": 10.000342044485626,
        "cond_entropy-3-nopunct": 0.36763989375164724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.29055,
        "local_recall": {
            "1": 0.26855123674911663,
            "2": 0.4280936454849498,
            "3": 0.7859892224788299
        },
        "rouge1": {
            "precision": 0.78383,
            "recall": 0.76896,
            "fmeasure": 0.76685
        },
        "rouge2": {
            "precision": 0.57377,
            "recall": 0.56696,
            "fmeasure": 0.56338
        },
        "rougeL": {
            "precision": 0.69488,
            "recall": 0.67876,
            "fmeasure": 0.67858
        },
        "rougeLsum": {
            "precision": 0.69488,
            "recall": 0.67876,
            "fmeasure": 0.67858
        },
        "nist": 7.846400816091936,
        "bleurt": 0.4096,
        "bertscore": {
            "precision": 0.93765,
            "recall": 0.93328,
            "f1": 0.93416
        },
        "nubia": {
            "semantic_relation": 4.29003,
            "contradiction": 6.3214,
            "irrelevancy": 27.21509,
            "logical_agreement": 66.46351,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.61763,
            "nubia_score": 0.78086
        },
        "meteor": 0.42442315351559123
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.534,
        "msttr-100_nopunct": 0.535,
        "total_length": 515,
        "mean_pred_length": 17.75862068965517,
        "std_pred_length": 9.34272784655233,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.32427184466019415,
        "vocab_size-1": 167,
        "unique-1": 119,
        "entropy-1": 6.081743963732141,
        "distinct-2": 0.588477366255144,
        "vocab_size-2": 286,
        "unique-2": 230,
        "entropy-2": 7.536078628848345,
        "cond_entropy-2": 1.3390927026328838,
        "distinct-3": 0.6892778993435449,
        "vocab_size-3": 315,
        "unique-3": 266,
        "entropy-3": 7.8376180727387945,
        "cond_entropy-3": 0.3634065825511813,
        "total_length-nopunct": 440,
        "mean_pred_length-nopunct": 15.172413793103448,
        "std_pred_length-nopunct": 7.808346398818874,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.36363636363636365,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.081507096778151,
        "distinct-2-nopunct": 0.5815085158150851,
        "vocab_size-2-nopunct": 239,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.256372709438025,
        "cond_entropy-2-nopunct": 1.30557194143497,
        "distinct-3-nopunct": 0.6910994764397905,
        "vocab_size-3-nopunct": 264,
        "unique-3-nopunct": 225,
        "entropy-3-nopunct": 7.573931570901372,
        "cond_entropy-3-nopunct": 0.39879494614963956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.36259,
        "local_recall": {
            "1": 0.25,
            "2": 0.5614035087719298,
            "3": 0.8727810650887574
        },
        "rouge1": {
            "precision": 0.88572,
            "recall": 0.86521,
            "fmeasure": 0.87076
        },
        "rouge2": {
            "precision": 0.7374,
            "recall": 0.71912,
            "fmeasure": 0.72424
        },
        "rougeL": {
            "precision": 0.83739,
            "recall": 0.82226,
            "fmeasure": 0.82542
        },
        "rougeLsum": {
            "precision": 0.83739,
            "recall": 0.82226,
            "fmeasure": 0.82542
        },
        "nist": 7.274552645926773,
        "bleurt": 0.42645,
        "bertscore": {
            "precision": 0.95232,
            "recall": 0.94699,
            "f1": 0.94772
        },
        "nubia": {
            "semantic_relation": 4.39901,
            "contradiction": 4.36344,
            "irrelevancy": 17.71676,
            "logical_agreement": 77.9198,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.39782,
            "nubia_score": 0.81015
        },
        "meteor": 0.4673765807453018
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.14,
        "msttr-100_nopunct": 0.12,
        "total_length": 2533,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.005527043031977891,
        "vocab_size-1": 14,
        "unique-1": 0,
        "entropy-1": 3.6168746059562227,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 16,
        "unique-2": 0,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.4125371587496607,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 15,
        "unique-3": 0,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 2235,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.005369127516778523,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.373557262275185,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.4718928978776571,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 0.09455,
        "local_recall": {
            "1": 0.03485254691689008
        },
        "rouge1": {
            "precision": 0.16727,
            "recall": 0.30216,
            "fmeasure": 0.21071
        },
        "rouge2": {
            "precision": 0.05872,
            "recall": 0.11966,
            "fmeasure": 0.07665
        },
        "rougeL": {
            "precision": 0.13784,
            "recall": 0.25528,
            "fmeasure": 0.17498
        },
        "rougeLsum": {
            "precision": 0.13784,
            "recall": 0.25528,
            "fmeasure": 0.17498
        },
        "nist": 0.231203932783707,
        "bleurt": -0.79245,
        "bertscore": {
            "precision": 0.80989,
            "recall": 0.85225,
            "f1": 0.83051
        },
        "nubia": {
            "semantic_relation": 1.6953,
            "contradiction": 30.25725,
            "irrelevancy": 29.89404,
            "logical_agreement": 39.84871,
            "grammar_ref": 6.81129,
            "grammar_hyp": 5.23593,
            "nubia_score": 0.02113
        },
        "meteor": 0.03001564584307903
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.66143,
        "msttr-100_nopunct": 0.70833,
        "total_length": 793,
        "mean_pred_length": 15.25,
        "std_pred_length": 5.504805592878337,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.43883984867591425,
        "vocab_size-1": 348,
        "unique-1": 256,
        "entropy-1": 7.245308425912804,
        "distinct-2": 0.7948717948717948,
        "vocab_size-2": 589,
        "unique-2": 522,
        "entropy-2": 8.953977679507709,
        "cond_entropy-2": 1.474139300979332,
        "distinct-3": 0.8984034833091437,
        "vocab_size-3": 619,
        "unique-3": 583,
        "entropy-3": 9.165599765110779,
        "cond_entropy-3": 0.20232888057061207,
        "total_length-nopunct": 687,
        "mean_pred_length-nopunct": 13.211538461538462,
        "std_pred_length-nopunct": 4.92379051318712,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4992721979621543,
        "vocab_size-1-nopunct": 343,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 7.425476585973439,
        "distinct-2-nopunct": 0.8173228346456692,
        "vocab_size-2-nopunct": 519,
        "unique-2-nopunct": 466,
        "entropy-2-nopunct": 8.802948343680598,
        "cond_entropy-2-nopunct": 1.4422206623155116,
        "distinct-3-nopunct": 0.9125214408233276,
        "vocab_size-3-nopunct": 532,
        "unique-3-nopunct": 504,
        "entropy-3-nopunct": 8.965125696911562,
        "cond_entropy-3-nopunct": 0.19030522763028704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.31129,
        "local_recall": {
            "1": 0.29605263157894735,
            "2": 0.5567567567567567,
            "3": 0.7994858611825193
        },
        "rouge1": {
            "precision": 0.70297,
            "recall": 0.73837,
            "fmeasure": 0.7055
        },
        "rouge2": {
            "precision": 0.52528,
            "recall": 0.52043,
            "fmeasure": 0.51161
        },
        "rougeL": {
            "precision": 0.6606,
            "recall": 0.69669,
            "fmeasure": 0.6637
        },
        "rougeLsum": {
            "precision": 0.6606,
            "recall": 0.69669,
            "fmeasure": 0.6637
        },
        "nist": 6.612193375863149,
        "bleurt": 0.26589,
        "bertscore": {
            "precision": 0.92192,
            "recall": 0.92753,
            "f1": 0.92245
        },
        "nubia": {
            "semantic_relation": 3.9359,
            "contradiction": 13.33569,
            "irrelevancy": 32.50688,
            "logical_agreement": 54.15743,
            "grammar_ref": 5.15177,
            "grammar_hyp": 5.02689,
            "nubia_score": 0.64563
        },
        "meteor": 0.41862665035161684
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.682,
        "msttr-100_nopunct": 0.7325,
        "total_length": 554,
        "mean_pred_length": 15.38888888888889,
        "std_pred_length": 5.396901259970997,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.516245487364621,
        "vocab_size-1": 286,
        "unique-1": 235,
        "entropy-1": 7.18673757795775,
        "distinct-2": 0.8185328185328186,
        "vocab_size-2": 424,
        "unique-2": 380,
        "entropy-2": 8.530103714599068,
        "cond_entropy-2": 1.1152422833762863,
        "distinct-3": 0.9107883817427386,
        "vocab_size-3": 439,
        "unique-3": 411,
        "entropy-3": 8.70377317955051,
        "cond_entropy-3": 0.1851245782940521,
        "total_length-nopunct": 479,
        "mean_pred_length-nopunct": 13.305555555555555,
        "std_pred_length-nopunct": 4.6116967499587656,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5782881002087683,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 7.300356315529471,
        "distinct-2-nopunct": 0.8103837471783296,
        "vocab_size-2-nopunct": 359,
        "unique-2-nopunct": 321,
        "entropy-2-nopunct": 8.276235193613104,
        "cond_entropy-2-nopunct": 1.0711771717249314,
        "distinct-3-nopunct": 0.9066339066339066,
        "vocab_size-3-nopunct": 369,
        "unique-3-nopunct": 344,
        "entropy-3-nopunct": 8.449513454745006,
        "cond_entropy-3-nopunct": 0.1913801579782923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.52452,
        "local_recall": {
            "1": 0.15841584158415842,
            "2": 0.46825396825396826,
            "3": 0.7390029325513197
        },
        "rouge1": {
            "precision": 0.7315,
            "recall": 0.69272,
            "fmeasure": 0.69919
        },
        "rouge2": {
            "precision": 0.5012,
            "recall": 0.47837,
            "fmeasure": 0.48117
        },
        "rougeL": {
            "precision": 0.6602,
            "recall": 0.62434,
            "fmeasure": 0.63119
        },
        "rougeLsum": {
            "precision": 0.6602,
            "recall": 0.62434,
            "fmeasure": 0.63119
        },
        "nist": 6.223784728785321,
        "bleurt": 0.18811,
        "bertscore": {
            "precision": 0.92096,
            "recall": 0.90264,
            "f1": 0.90968
        },
        "nubia": {
            "semantic_relation": 3.97582,
            "contradiction": 13.12574,
            "irrelevancy": 36.50423,
            "logical_agreement": 50.37004,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.56427,
            "nubia_score": 0.67983
        },
        "meteor": 0.36121623807008446
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.53776,
        "msttr-100_nopunct": 0.55214,
        "total_length": 10734,
        "mean_pred_length": 17.625615763546797,
        "std_pred_length": 6.951466797064305,
        "median_pred_length": 17.0,
        "min_pred_length": 2,
        "max_pred_length": 37,
        "distinct-1": 0.06269796907024408,
        "vocab_size-1": 673,
        "unique-1": 261,
        "entropy-1": 6.327211682585812,
        "distinct-2": 0.19130864197530864,
        "vocab_size-2": 1937,
        "unique-2": 995,
        "entropy-2": 9.217863644780003,
        "cond_entropy-2": 2.7880700309396005,
        "distinct-3": 0.3117906683480454,
        "vocab_size-3": 2967,
        "unique-3": 1860,
        "entropy-3": 10.076256826854499,
        "cond_entropy-3": 0.9535618716933127,
        "total_length-nopunct": 9858,
        "mean_pred_length-nopunct": 16.1871921182266,
        "std_pred_length-nopunct": 6.620942553227588,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.06786366402921486,
        "vocab_size-1-nopunct": 669,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 6.353538416269377,
        "distinct-2-nopunct": 0.1839117742458644,
        "vocab_size-2-nopunct": 1701,
        "unique-2-nopunct": 864,
        "entropy-2-nopunct": 9.023429718377992,
        "cond_entropy-2-nopunct": 2.8864608494179094,
        "distinct-3-nopunct": 0.3084133780812406,
        "vocab_size-3-nopunct": 2665,
        "unique-3-nopunct": 1684,
        "entropy-3-nopunct": 9.901481043478677,
        "cond_entropy-3-nopunct": 0.9928955605723331,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 4.58834,
        "local_recall": {
            "1": 0.3280667495118054
        },
        "rouge1": {
            "precision": 0.47961,
            "recall": 0.51997,
            "fmeasure": 0.47815
        },
        "rouge2": {
            "precision": 0.25795,
            "recall": 0.28127,
            "fmeasure": 0.25695
        },
        "rougeL": {
            "precision": 0.42714,
            "recall": 0.46146,
            "fmeasure": 0.42551
        },
        "rougeLsum": {
            "precision": 0.42714,
            "recall": 0.46146,
            "fmeasure": 0.42551
        },
        "nist": 1.7492795335936746,
        "bleurt": -0.65054,
        "bertscore": {
            "precision": 0.82918,
            "recall": 0.85918,
            "f1": 0.84354
        },
        "nubia": {
            "semantic_relation": 3.08692,
            "contradiction": 28.88101,
            "irrelevancy": 26.69587,
            "logical_agreement": 44.42312,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.24583,
            "nubia_score": 0.3432
        },
        "meteor": 0.1506279851909577
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 251,
        "mean_pred_length": 17.928571428571427,
        "std_pred_length": 6.595066183078353,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.6294820717131474,
        "vocab_size-1": 158,
        "unique-1": 130,
        "entropy-1": 6.723655819857433,
        "distinct-2": 0.9493670886075949,
        "vocab_size-2": 225,
        "unique-2": 216,
        "entropy-2": 7.772246875588436,
        "cond_entropy-2": 0.897398901167673,
        "distinct-3": 0.9865470852017937,
        "vocab_size-3": 220,
        "unique-3": 217,
        "entropy-3": 7.773994070323902,
        "cond_entropy-3": 9.225853073060758e-05,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 15.785714285714286,
        "std_pred_length-nopunct": 6.084859094842019,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6968325791855203,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 6.82456634970831,
        "distinct-2-nopunct": 0.9516908212560387,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.579430723323278,
        "cond_entropy-2-nopunct": 0.793037052044169,
        "distinct-3-nopunct": 0.9896373056994818,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 189,
        "entropy-3-nopunct": 7.571731648667022,
        "cond_entropy-3-nopunct": -0.009788259741934908,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.15673,
        "local_recall": {
            "1": 0.18032786885245902,
            "2": 0.37142857142857144,
            "3": 0.6855345911949685
        },
        "rouge1": {
            "precision": 0.6914,
            "recall": 0.68368,
            "fmeasure": 0.67981
        },
        "rouge2": {
            "precision": 0.44734,
            "recall": 0.44147,
            "fmeasure": 0.43835
        },
        "rougeL": {
            "precision": 0.55369,
            "recall": 0.54122,
            "fmeasure": 0.54007
        },
        "rougeLsum": {
            "precision": 0.55369,
            "recall": 0.54122,
            "fmeasure": 0.54007
        },
        "nist": 5.159683677499567,
        "bleurt": 0.21092,
        "bertscore": {
            "precision": 0.91211,
            "recall": 0.91244,
            "f1": 0.90989
        },
        "nubia": {
            "semantic_relation": 4.10129,
            "contradiction": 1.04902,
            "irrelevancy": 49.0789,
            "logical_agreement": 49.87209,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.55099,
            "nubia_score": 0.73007
        },
        "meteor": 0.35454683187141306
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.73629,
        "msttr-100_nopunct": 0.78597,
        "total_length": 7092,
        "mean_pred_length": 19.754874651810585,
        "std_pred_length": 9.355621694802839,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.39805414551607443,
        "vocab_size-1": 2823,
        "unique-1": 2242,
        "entropy-1": 9.248915704190516,
        "distinct-2": 0.840190108421209,
        "vocab_size-2": 5657,
        "unique-2": 5303,
        "entropy-2": 12.121349160579165,
        "cond_entropy-2": 2.5974447562696996,
        "distinct-3": 0.9576404141826169,
        "vocab_size-3": 6104,
        "unique-3": 6007,
        "entropy-3": 12.471074495962188,
        "cond_entropy-3": 0.3672383080640162,
        "total_length-nopunct": 6271,
        "mean_pred_length-nopunct": 17.467966573816156,
        "std_pred_length-nopunct": 8.241376283838003,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.448413331207144,
        "vocab_size-1-nopunct": 2812,
        "unique-1-nopunct": 2242,
        "entropy-1-nopunct": 9.629794749549207,
        "distinct-2-nopunct": 0.8638362652232747,
        "vocab_size-2-nopunct": 5107,
        "unique-2-nopunct": 4818,
        "entropy-2-nopunct": 12.044252448779414,
        "cond_entropy-2-nopunct": 2.551306937255554,
        "distinct-3-nopunct": 0.975148568341437,
        "vocab_size-3-nopunct": 5415,
        "unique-3-nopunct": 5337,
        "entropy-3-nopunct": 12.370310513600725,
        "cond_entropy-3-nopunct": 0.3508486532539055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "bleu": 47.51493,
        "local_recall": {
            "1": 0.04966044142614601,
            "2": 0.13793103448275862,
            "3": 0.33698030634573306,
            "4": 0.42789223454833597,
            "5": 0.5160955347871236,
            "6": 0.6467391304347826,
            "7": 0.7434135166093929
        },
        "rouge1": {
            "precision": 0.73895,
            "recall": 0.67526,
            "fmeasure": 0.69286
        },
        "rouge2": {
            "precision": 0.53338,
            "recall": 0.49056,
            "fmeasure": 0.50016
        },
        "rougeL": {
            "precision": 0.70546,
            "recall": 0.648,
            "fmeasure": 0.6629
        },
        "rougeLsum": {
            "precision": 0.70546,
            "recall": 0.648,
            "fmeasure": 0.6629
        },
        "nist": 9.054802836058366,
        "sari": 50.20683,
        "bleurt": -0.39988,
        "bertscore": {
            "precision": 0.89704,
            "recall": 0.90752,
            "f1": 0.89947
        },
        "nubia": {
            "semantic_relation": 3.8822,
            "contradiction": 8.3288,
            "irrelevancy": 20.50417,
            "logical_agreement": 71.16703,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.74495,
            "nubia_score": 0.5211
        },
        "meteor": 0.35469441130132734
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.78714,
        "total_length": 813,
        "mean_pred_length": 16.9375,
        "std_pred_length": 6.322599182034764,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.5498154981549815,
        "vocab_size-1": 447,
        "unique-1": 373,
        "entropy-1": 7.7167254931818166,
        "distinct-2": 0.9241830065359478,
        "vocab_size-2": 707,
        "unique-2": 670,
        "entropy-2": 9.38519372390168,
        "cond_entropy-2": 1.4404163749188494,
        "distinct-3": 0.9888423988842399,
        "vocab_size-3": 709,
        "unique-3": 702,
        "entropy-3": 9.46246126476576,
        "cond_entropy-3": 0.08747376995292983,
        "total_length-nopunct": 712,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 5.676462121975467,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6193820224719101,
        "vocab_size-1-nopunct": 441,
        "unique-1-nopunct": 371,
        "entropy-1-nopunct": 7.958267951793072,
        "distinct-2-nopunct": 0.9262048192771084,
        "vocab_size-2-nopunct": 615,
        "unique-2-nopunct": 586,
        "entropy-2-nopunct": 9.179634904296023,
        "cond_entropy-2-nopunct": 1.3094670925591232,
        "distinct-3-nopunct": 0.9967532467532467,
        "vocab_size-3-nopunct": 614,
        "unique-3-nopunct": 612,
        "entropy-3-nopunct": 9.260293034201354,
        "cond_entropy-3-nopunct": 0.09588445668864835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.54884,
        "local_recall": {
            "1": 0.22818791946308725,
            "2": 0.41875,
            "3": 0.8158415841584158
        },
        "rouge1": {
            "precision": 0.74926,
            "recall": 0.75468,
            "fmeasure": 0.74473
        },
        "rouge2": {
            "precision": 0.49163,
            "recall": 0.50566,
            "fmeasure": 0.49322
        },
        "rougeL": {
            "precision": 0.6062,
            "recall": 0.61194,
            "fmeasure": 0.60268
        },
        "rougeLsum": {
            "precision": 0.6062,
            "recall": 0.61194,
            "fmeasure": 0.60268
        },
        "nist": 7.154106726352157,
        "bleurt": 0.28784,
        "bertscore": {
            "precision": 0.92407,
            "recall": 0.93066,
            "f1": 0.92636
        },
        "nubia": {
            "semantic_relation": 4.30279,
            "contradiction": 4.09767,
            "irrelevancy": 31.80143,
            "logical_agreement": 64.1009,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.79853,
            "nubia_score": 0.75064
        },
        "meteor": 0.3981115359162967
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.72027,
        "msttr-100_nopunct": 0.76431,
        "total_length": 7390,
        "mean_pred_length": 20.584958217270195,
        "std_pred_length": 9.238884577125745,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.34709066305818675,
        "vocab_size-1": 2565,
        "unique-1": 1851,
        "entropy-1": 9.070760995409605,
        "distinct-2": 0.8153889916085906,
        "vocab_size-2": 5733,
        "unique-2": 5267,
        "entropy-2": 12.088270066836326,
        "cond_entropy-2": 2.7641325046726926,
        "distinct-3": 0.9467925659472423,
        "vocab_size-3": 6317,
        "unique-3": 6178,
        "entropy-3": 12.491246861815377,
        "cond_entropy-3": 0.4256209886235341,
        "total_length-nopunct": 6542,
        "mean_pred_length-nopunct": 18.22284122562674,
        "std_pred_length-nopunct": 8.10209448864455,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3905533476001223,
        "vocab_size-1-nopunct": 2555,
        "unique-1-nopunct": 1851,
        "entropy-1-nopunct": 9.425162019372348,
        "distinct-2-nopunct": 0.841500889535824,
        "vocab_size-2-nopunct": 5203,
        "unique-2-nopunct": 4823,
        "entropy-2-nopunct": 12.032064808929293,
        "cond_entropy-2-nopunct": 2.744579033553019,
        "distinct-3-nopunct": 0.9685782967032966,
        "vocab_size-3-nopunct": 5641,
        "unique-3-nopunct": 5531,
        "entropy-3-nopunct": 12.422760297053824,
        "cond_entropy-3-nopunct": 0.4172100192917162,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "bleu": 64.89732,
        "local_recall": {
            "1": 0.05178268251273345,
            "2": 0.1724137931034483,
            "3": 0.38293216630196936,
            "4": 0.5229793977812995,
            "5": 0.6303219106957425,
            "6": 0.7542270531400966,
            "7": 0.872852233676976
        },
        "rouge1": {
            "precision": 0.8325,
            "recall": 0.78366,
            "fmeasure": 0.79626
        },
        "rouge2": {
            "precision": 0.67947,
            "recall": 0.64341,
            "fmeasure": 0.65063
        },
        "rougeL": {
            "precision": 0.79827,
            "recall": 0.75824,
            "fmeasure": 0.76629
        },
        "rougeLsum": {
            "precision": 0.79827,
            "recall": 0.75824,
            "fmeasure": 0.76629
        },
        "nist": 10.944963067699305,
        "sari": 48.1821,
        "bleurt": 0.16872,
        "bertscore": {
            "precision": 0.94848,
            "recall": 0.94204,
            "f1": 0.94287
        },
        "nubia": {
            "semantic_relation": 4.28119,
            "contradiction": 4.72231,
            "irrelevancy": 18.17272,
            "logical_agreement": 77.10496,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.9233,
            "nubia_score": 0.68688
        },
        "meteor": 0.45018933287716295
    },
    "cs_restaurants_validation": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.54886,
        "msttr-100_nopunct": 0.55609,
        "total_length": 14024,
        "mean_pred_length": 17.956466069142124,
        "std_pred_length": 6.683681643782116,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.035082715345122646,
        "vocab_size-1": 492,
        "unique-1": 131,
        "entropy-1": 6.294453468298377,
        "distinct-2": 0.11606131541191574,
        "vocab_size-2": 1537,
        "unique-2": 542,
        "entropy-2": 9.102572235606878,
        "cond_entropy-2": 2.7275010255256307,
        "distinct-3": 0.20189375702134488,
        "vocab_size-3": 2516,
        "unique-3": 1140,
        "entropy-3": 9.98069631918206,
        "cond_entropy-3": 0.8739607155835877,
        "total_length-nopunct": 12858,
        "mean_pred_length-nopunct": 16.46350832266325,
        "std_pred_length-nopunct": 6.459190316770841,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.0379530253538653,
        "vocab_size-1-nopunct": 488,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.280118706149393,
        "distinct-2-nopunct": 0.11782727498550964,
        "vocab_size-2-nopunct": 1423,
        "unique-2-nopunct": 499,
        "entropy-2-nopunct": 9.005475325131588,
        "cond_entropy-2-nopunct": 2.7601614119982054,
        "distinct-3-nopunct": 0.20821529745042494,
        "vocab_size-3-nopunct": 2352,
        "unique-3-nopunct": 1088,
        "entropy-3-nopunct": 9.895486643415026,
        "cond_entropy-3-nopunct": 0.8547536809453714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "bleu": 2.78692,
        "local_recall": {
            "1": 0.2695266272189349
        },
        "rouge1": {
            "precision": 0.43235,
            "recall": 0.46199,
            "fmeasure": 0.42725
        },
        "rouge2": {
            "precision": 0.234,
            "recall": 0.24833,
            "fmeasure": 0.22953
        },
        "rougeL": {
            "precision": 0.38821,
            "recall": 0.41742,
            "fmeasure": 0.38491
        },
        "rougeLsum": {
            "precision": 0.38821,
            "recall": 0.41742,
            "fmeasure": 0.38491
        },
        "nist": 1.2959210175998612,
        "bleurt": -0.75423,
        "bertscore": {
            "precision": 0.81324,
            "recall": 0.84719,
            "f1": 0.82954
        },
        "nubia": {
            "semantic_relation": 2.64772,
            "contradiction": 32.8763,
            "irrelevancy": 26.57652,
            "logical_agreement": 40.54717,
            "grammar_ref": 6.54085,
            "grammar_hyp": 5.99523,
            "nubia_score": 0.25095
        },
        "meteor": 0.12484276638201347
    },
    "cs_restaurants_test": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.5353,
        "msttr-100_nopunct": 0.54193,
        "total_length": 14908,
        "mean_pred_length": 17.705463182897862,
        "std_pred_length": 6.301505576362647,
        "median_pred_length": 17.0,
        "min_pred_length": 2,
        "max_pred_length": 37,
        "distinct-1": 0.048430372954118596,
        "vocab_size-1": 722,
        "unique-1": 271,
        "entropy-1": 6.2965318276897015,
        "distinct-2": 0.15242428551116166,
        "vocab_size-2": 2144,
        "unique-2": 1071,
        "entropy-2": 9.019391728820763,
        "cond_entropy-2": 2.6599341098447207,
        "distinct-3": 0.25173926194797336,
        "vocab_size-3": 3329,
        "unique-3": 2023,
        "entropy-3": 9.809068146677232,
        "cond_entropy-3": 0.8668490089690444,
        "total_length-nopunct": 13578,
        "mean_pred_length-nopunct": 16.125890736342043,
        "std_pred_length-nopunct": 5.995510551396722,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.052879658270732065,
        "vocab_size-1-nopunct": 718,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 6.283305245198935,
        "distinct-2-nopunct": 0.14839824120603015,
        "vocab_size-2-nopunct": 1890,
        "unique-2-nopunct": 939,
        "entropy-2-nopunct": 8.838558395981268,
        "cond_entropy-2-nopunct": 2.728021504566373,
        "distinct-3-nopunct": 0.251786464901219,
        "vocab_size-3-nopunct": 2995,
        "unique-3-nopunct": 1839,
        "entropy-3-nopunct": 9.653547061959596,
        "cond_entropy-3-nopunct": 0.8900384718601673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 3.61795,
        "local_recall": {
            "1": 0.285674702133555
        },
        "rouge1": {
            "precision": 0.41752,
            "recall": 0.47196,
            "fmeasure": 0.42371
        },
        "rouge2": {
            "precision": 0.21899,
            "recall": 0.24826,
            "fmeasure": 0.2214
        },
        "rougeL": {
            "precision": 0.36722,
            "recall": 0.41452,
            "fmeasure": 0.37246
        },
        "rougeLsum": {
            "precision": 0.36722,
            "recall": 0.41452,
            "fmeasure": 0.37246
        },
        "nist": 1.5103738093535264,
        "bleurt": -0.68607,
        "bertscore": {
            "precision": 0.82454,
            "recall": 0.85703,
            "f1": 0.84017
        },
        "nubia": {
            "semantic_relation": 2.76985,
            "contradiction": 29.91708,
            "irrelevancy": 27.27671,
            "logical_agreement": 42.80622,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.02089,
            "nubia_score": 0.27882
        },
        "meteor": 0.1316143456365679
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.70111,
        "msttr-100_nopunct": 0.77,
        "total_length": 926,
        "mean_pred_length": 18.897959183673468,
        "std_pred_length": 7.431990690991687,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 49,
        "distinct-1": 0.521598272138229,
        "vocab_size-1": 483,
        "unique-1": 396,
        "entropy-1": 7.770205298080315,
        "distinct-2": 0.9144811858608894,
        "vocab_size-2": 802,
        "unique-2": 762,
        "entropy-2": 9.541526226893595,
        "cond_entropy-2": 1.5724606527298375,
        "distinct-3": 0.9842995169082126,
        "vocab_size-3": 815,
        "unique-3": 805,
        "entropy-3": 9.659350891670183,
        "cond_entropy-3": 0.11057908321585884,
        "total_length-nopunct": 788,
        "mean_pred_length-nopunct": 16.081632653061224,
        "std_pred_length-nopunct": 6.163873466413322,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6015228426395939,
        "vocab_size-1-nopunct": 474,
        "unique-1-nopunct": 394,
        "entropy-1-nopunct": 8.00847109895617,
        "distinct-2-nopunct": 0.9336941813261164,
        "vocab_size-2-nopunct": 690,
        "unique-2-nopunct": 667,
        "entropy-2-nopunct": 9.331543096828623,
        "cond_entropy-2-nopunct": 1.4003935713515863,
        "distinct-3-nopunct": 0.9927536231884058,
        "vocab_size-3-nopunct": 685,
        "unique-3-nopunct": 681,
        "entropy-3-nopunct": 9.41486575818415,
        "cond_entropy-3-nopunct": 0.0890351220892348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.99162,
        "local_recall": {
            "1": 0.26804123711340205,
            "2": 0.45664739884393063,
            "3": 0.8064516129032258
        },
        "rouge1": {
            "precision": 0.776,
            "recall": 0.7447,
            "fmeasure": 0.75065
        },
        "rouge2": {
            "precision": 0.54029,
            "recall": 0.51173,
            "fmeasure": 0.5182
        },
        "rougeL": {
            "precision": 0.65606,
            "recall": 0.62554,
            "fmeasure": 0.63174
        },
        "rougeLsum": {
            "precision": 0.65606,
            "recall": 0.62554,
            "fmeasure": 0.63174
        },
        "nist": 7.297938308971847,
        "bleurt": 0.24719,
        "bertscore": {
            "precision": 0.92822,
            "recall": 0.9249,
            "f1": 0.92426
        },
        "nubia": {
            "semantic_relation": 4.33292,
            "contradiction": 4.12252,
            "irrelevancy": 26.85573,
            "logical_agreement": 69.02176,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.77645,
            "nubia_score": 0.76148
        },
        "meteor": 0.392343857206609
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.70889,
        "msttr-100_nopunct": 0.74562,
        "total_length": 1856,
        "mean_pred_length": 16.571428571428573,
        "std_pred_length": 5.83051438204072,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.4380387931034483,
        "vocab_size-1": 813,
        "unique-1": 667,
        "entropy-1": 8.04726341115442,
        "distinct-2": 0.8102064220183486,
        "vocab_size-2": 1413,
        "unique-2": 1306,
        "entropy-2": 10.141496342341695,
        "cond_entropy-2": 1.8367445857831368,
        "distinct-3": 0.9117647058823529,
        "vocab_size-3": 1488,
        "unique-3": 1439,
        "entropy-3": 10.409128634168399,
        "cond_entropy-3": 0.28154473703285543,
        "total_length-nopunct": 1627,
        "mean_pred_length-nopunct": 14.526785714285714,
        "std_pred_length-nopunct": 5.226921761126597,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.49354640442532266,
        "vocab_size-1-nopunct": 803,
        "unique-1-nopunct": 663,
        "entropy-1-nopunct": 8.301079826536126,
        "distinct-2-nopunct": 0.8184818481848185,
        "vocab_size-2-nopunct": 1240,
        "unique-2-nopunct": 1157,
        "entropy-2-nopunct": 9.949223352342516,
        "cond_entropy-2-nopunct": 1.756854478084158,
        "distinct-3-nopunct": 0.9123307198859587,
        "vocab_size-3-nopunct": 1280,
        "unique-3-nopunct": 1235,
        "entropy-3-nopunct": 10.196268963798609,
        "cond_entropy-3-nopunct": 0.28107910940750364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.51001,
        "local_recall": {
            "1": 0.258160237388724,
            "2": 0.4551282051282051,
            "3": 0.8276465441819773
        },
        "rouge1": {
            "precision": 0.76034,
            "recall": 0.76471,
            "fmeasure": 0.75012
        },
        "rouge2": {
            "precision": 0.54871,
            "recall": 0.55106,
            "fmeasure": 0.54153
        },
        "rougeL": {
            "precision": 0.66109,
            "recall": 0.66085,
            "fmeasure": 0.65107
        },
        "rougeLsum": {
            "precision": 0.66109,
            "recall": 0.66085,
            "fmeasure": 0.65107
        },
        "nist": 7.853453388196022,
        "bleurt": 0.29811,
        "bertscore": {
            "precision": 0.92791,
            "recall": 0.92977,
            "f1": 0.92738
        },
        "nubia": {
            "semantic_relation": 4.21481,
            "contradiction": 6.09208,
            "irrelevancy": 29.90267,
            "logical_agreement": 64.00525,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.66447,
            "nubia_score": 0.74188
        },
        "meteor": 0.40998085254141203
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.08959,
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "nist": 1.6476388007204534,
        "bleurt": 0.27507,
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        },
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "meteor": 0.3387350864807313
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72789,
        "msttr-100_nopunct": 0.7775,
        "total_length": 1920,
        "mean_pred_length": 16.842105263157894,
        "std_pred_length": 7.159313584867165,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 50,
        "distinct-1": 0.46458333333333335,
        "vocab_size-1": 892,
        "unique-1": 694,
        "entropy-1": 8.343078615111432,
        "distinct-2": 0.8593576965669989,
        "vocab_size-2": 1552,
        "unique-2": 1410,
        "entropy-2": 10.434484712348736,
        "cond_entropy-2": 1.821929410727015,
        "distinct-3": 0.9639479905437353,
        "vocab_size-3": 1631,
        "unique-3": 1578,
        "entropy-3": 10.647250817687011,
        "cond_entropy-3": 0.20670701018863957,
        "total_length-nopunct": 1671,
        "mean_pred_length-nopunct": 14.657894736842104,
        "std_pred_length-nopunct": 6.510219964710844,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.528426092160383,
        "vocab_size-1-nopunct": 883,
        "unique-1-nopunct": 692,
        "entropy-1-nopunct": 8.643189419895778,
        "distinct-2-nopunct": 0.8786127167630058,
        "vocab_size-2-nopunct": 1368,
        "unique-2-nopunct": 1262,
        "entropy-2-nopunct": 10.268259781969745,
        "cond_entropy-2-nopunct": 1.7295539016450692,
        "distinct-3-nopunct": 0.9702009702009702,
        "vocab_size-3-nopunct": 1400,
        "unique-3-nopunct": 1360,
        "entropy-3-nopunct": 10.432756041542602,
        "cond_entropy-3-nopunct": 0.1805105591433492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.70629,
        "local_recall": {
            "1": 0.1890547263681592,
            "2": 0.4289340101522843,
            "3": 0.7699736611062336
        },
        "rouge1": {
            "precision": 0.74194,
            "recall": 0.71161,
            "fmeasure": 0.7142
        },
        "rouge2": {
            "precision": 0.48391,
            "recall": 0.46967,
            "fmeasure": 0.46829
        },
        "rougeL": {
            "precision": 0.62909,
            "recall": 0.60822,
            "fmeasure": 0.60773
        },
        "rougeLsum": {
            "precision": 0.62909,
            "recall": 0.60822,
            "fmeasure": 0.60773
        },
        "nist": 7.1794081900536515,
        "bleurt": 0.18674,
        "bertscore": {
            "precision": 0.91856,
            "recall": 0.91862,
            "f1": 0.91697
        },
        "nubia": {
            "semantic_relation": 4.1839,
            "contradiction": 7.23745,
            "irrelevancy": 31.17201,
            "logical_agreement": 61.59054,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.73112,
            "nubia_score": 0.7122
        },
        "meteor": 0.37397660858062765
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.70571,
        "msttr-100_nopunct": 0.75417,
        "total_length": 1477,
        "mean_pred_length": 16.23076923076923,
        "std_pred_length": 7.813874562086359,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 56,
        "distinct-1": 0.4041976980365606,
        "vocab_size-1": 597,
        "unique-1": 471,
        "entropy-1": 7.7110837641191,
        "distinct-2": 0.7481962481962482,
        "vocab_size-2": 1037,
        "unique-2": 913,
        "entropy-2": 9.665406638328433,
        "cond_entropy-2": 1.709963025532719,
        "distinct-3": 0.8694980694980695,
        "vocab_size-3": 1126,
        "unique-3": 1045,
        "entropy-3": 9.982657077747541,
        "cond_entropy-3": 0.3169103280394975,
        "total_length-nopunct": 1276,
        "mean_pred_length-nopunct": 14.021978021978022,
        "std_pred_length-nopunct": 6.662966408601677,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.46238244514106586,
        "vocab_size-1-nopunct": 590,
        "unique-1-nopunct": 469,
        "entropy-1-nopunct": 7.975499485906874,
        "distinct-2-nopunct": 0.7662447257383966,
        "vocab_size-2-nopunct": 908,
        "unique-2-nopunct": 810,
        "entropy-2-nopunct": 9.489761911356306,
        "cond_entropy-2-nopunct": 1.6060320821140628,
        "distinct-3-nopunct": 0.8775137111517367,
        "vocab_size-3-nopunct": 960,
        "unique-3-nopunct": 896,
        "entropy-3-nopunct": 9.759588893187397,
        "cond_entropy-3-nopunct": 0.30698255633202043,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.50638,
        "local_recall": {
            "1": 0.23873873873873874,
            "2": 0.42857142857142855,
            "3": 0.7983193277310925
        },
        "rouge1": {
            "precision": 0.79028,
            "recall": 0.75643,
            "fmeasure": 0.76404
        },
        "rouge2": {
            "precision": 0.58312,
            "recall": 0.55837,
            "fmeasure": 0.56399
        },
        "rougeL": {
            "precision": 0.69721,
            "recall": 0.66985,
            "fmeasure": 0.67565
        },
        "rougeLsum": {
            "precision": 0.69721,
            "recall": 0.66985,
            "fmeasure": 0.67565
        },
        "nist": 7.728802889981424,
        "bleurt": 0.32272,
        "bertscore": {
            "precision": 0.93746,
            "recall": 0.92875,
            "f1": 0.93175
        },
        "nubia": {
            "semantic_relation": 4.26464,
            "contradiction": 3.04157,
            "irrelevancy": 26.3356,
            "logical_agreement": 70.62283,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.41338,
            "nubia_score": 0.77076
        },
        "meteor": 0.4207254621947946
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.2875,
        "msttr-100_nopunct": 0.26,
        "total_length": 421,
        "mean_pred_length": 19.136363636363637,
        "std_pred_length": 5.387658072310476,
        "median_pred_length": 20.5,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.07125890736342043,
        "vocab_size-1": 30,
        "unique-1": 0,
        "entropy-1": 4.4043517808200185,
        "distinct-2": 0.10526315789473684,
        "vocab_size-2": 42,
        "unique-2": 0,
        "entropy-2": 5.268360573130834,
        "cond_entropy-2": 0.855952768549912,
        "distinct-3": 0.11140583554376658,
        "vocab_size-3": 42,
        "unique-3": 0,
        "entropy-3": 5.269149932593279,
        "cond_entropy-3": -0.005718824518458342,
        "total_length-nopunct": 368,
        "mean_pred_length-nopunct": 16.727272727272727,
        "std_pred_length-nopunct": 4.937627496000098,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.07608695652173914,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.272958442052361,
        "distinct-2-nopunct": 0.1069364161849711,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.070148462024879,
        "cond_entropy-2-nopunct": 0.7595625144965121,
        "distinct-3-nopunct": 0.11419753086419752,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.0720005512093005,
        "cond_entropy-3-nopunct": -0.006223486449386351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 1.1288,
        "local_recall": {
            "1": 0.18857142857142858
        },
        "rouge1": {
            "precision": 0.34242,
            "recall": 0.38931,
            "fmeasure": 0.3584
        },
        "rouge2": {
            "precision": 0.20009,
            "recall": 0.21335,
            "fmeasure": 0.20214
        },
        "rougeL": {
            "precision": 0.31616,
            "recall": 0.35786,
            "fmeasure": 0.32997
        },
        "rougeLsum": {
            "precision": 0.31616,
            "recall": 0.35786,
            "fmeasure": 0.32997
        },
        "nist": 0.7389566611931874,
        "bleurt": -0.68774,
        "bertscore": {
            "precision": 0.83424,
            "recall": 0.87263,
            "f1": 0.85292
        },
        "nubia": {
            "semantic_relation": 2.12394,
            "contradiction": 41.1854,
            "irrelevancy": 29.66461,
            "logical_agreement": 29.14999,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.81375,
            "nubia_score": 0.2192
        },
        "meteor": 0.1053994360474657
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.53845,
        "msttr-100_nopunct": 0.54316,
        "total_length": 8463,
        "mean_pred_length": 16.926,
        "std_pred_length": 5.839565394787527,
        "median_pred_length": 17.0,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.0674701642443578,
        "vocab_size-1": 571,
        "unique-1": 234,
        "entropy-1": 6.251605638440847,
        "distinct-2": 0.1987944242119804,
        "vocab_size-2": 1583,
        "unique-2": 846,
        "entropy-2": 8.900754148050561,
        "cond_entropy-2": 2.5700830056112713,
        "distinct-3": 0.3119388985662602,
        "vocab_size-3": 2328,
        "unique-3": 1477,
        "entropy-3": 9.641702318798082,
        "cond_entropy-3": 0.8055848668999948,
        "total_length-nopunct": 7698,
        "mean_pred_length-nopunct": 15.396,
        "std_pred_length-nopunct": 5.561581070163412,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.07365549493374902,
        "vocab_size-1-nopunct": 567,
        "unique-1-nopunct": 234,
        "entropy-1-nopunct": 6.23749410817016,
        "distinct-2-nopunct": 0.19199777716032232,
        "vocab_size-2-nopunct": 1382,
        "unique-2-nopunct": 715,
        "entropy-2-nopunct": 8.719266660280654,
        "cond_entropy-2-nopunct": 2.6356929596868435,
        "distinct-3-nopunct": 0.30929989550679204,
        "vocab_size-3-nopunct": 2072,
        "unique-3-nopunct": 1301,
        "entropy-3-nopunct": 9.480828445503775,
        "cond_entropy-3-nopunct": 0.8232454407087282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "bleu": 3.45573,
        "local_recall": {
            "1": 0.282087118565106
        },
        "rouge1": {
            "precision": 0.43434,
            "recall": 0.47022,
            "fmeasure": 0.4325
        },
        "rouge2": {
            "precision": 0.2315,
            "recall": 0.25189,
            "fmeasure": 0.23029
        },
        "rougeL": {
            "precision": 0.38443,
            "recall": 0.4168,
            "fmeasure": 0.38325
        },
        "rougeLsum": {
            "precision": 0.38443,
            "recall": 0.4168,
            "fmeasure": 0.38325
        },
        "nist": 1.5335570860298395,
        "bleurt": -0.70133,
        "bertscore": {
            "precision": 0.82505,
            "recall": 0.85475,
            "f1": 0.83933
        },
        "nubia": {
            "semantic_relation": 2.80974,
            "contradiction": 29.18526,
            "irrelevancy": 26.58465,
            "logical_agreement": 44.23009,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.03066,
            "nubia_score": 0.30052
        },
        "meteor": 0.1306813084598188
    },
    "totto_validation": {
        "predictions_file": "T5-xl (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.72148,
        "msttr-100_nopunct": 0.77637,
        "total_length": 130714,
        "mean_pred_length": 16.975844155844158,
        "std_pred_length": 7.101321506912904,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 61,
        "distinct-1": 0.1684287834508928,
        "vocab_size-1": 22016,
        "unique-1": 15031,
        "entropy-1": 10.060342973746545,
        "distinct-2": 0.5498398556261889,
        "vocab_size-2": 67638,
        "unique-2": 56510,
        "entropy-2": 14.703875597704235,
        "cond_entropy-2": 4.268442332237024,
        "distinct-3": 0.7928265431777581,
        "vocab_size-3": 91424,
        "unique-3": 83505,
        "entropy-3": 16.039946858955574,
        "cond_entropy-3": 1.3138279946608848,
        "total_length-nopunct": 113454,
        "mean_pred_length-nopunct": 14.734285714285715,
        "std_pred_length-nopunct": 6.084047146809524,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.1938671179508876,
        "vocab_size-1-nopunct": 21995,
        "unique-1-nopunct": 15027,
        "entropy-1-nopunct": 10.635900197025732,
        "distinct-2-nopunct": 0.5982279630084915,
        "vocab_size-2-nopunct": 63265,
        "unique-2-nopunct": 54127,
        "entropy-2-nopunct": 14.726652154751834,
        "cond_entropy-2-nopunct": 4.2592502335690625,
        "distinct-3-nopunct": 0.8212821506516818,
        "vocab_size-3-nopunct": 80530,
        "unique-3-nopunct": 74561,
        "entropy-3-nopunct": 15.915721348699536,
        "cond_entropy-3-nopunct": 1.2564316544754028,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "bleu": 47.24478,
        "local_recall": {
            "1": 0.22809394760614274,
            "2": 0.47133922794910504,
            "3": 0.781397621762502
        },
        "rouge1": {
            "precision": 0.75273,
            "recall": 0.7435,
            "fmeasure": 0.73709
        },
        "rouge2": {
            "precision": 0.53042,
            "recall": 0.5266,
            "fmeasure": 0.5205
        },
        "rougeL": {
            "precision": 0.65431,
            "recall": 0.65029,
            "fmeasure": 0.64243
        },
        "rougeLsum": {
            "precision": 0.65431,
            "recall": 0.65029,
            "fmeasure": 0.64243
        },
        "nist": 10.796290033115866,
        "bleurt": 0.27711,
        "bertscore": {
            "precision": 0.92712,
            "recall": 0.92669,
            "f1": 0.92525
        },
        "nubia": {
            "semantic_relation": 4.20686,
            "contradiction": 7.08979,
            "irrelevancy": 31.48006,
            "logical_agreement": 61.43015,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.60842,
            "nubia_score": 0.73586
        },
        "meteor": 0.3989667927992434
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.64667,
        "msttr-100_nopunct": 0.665,
        "total_length": 316,
        "mean_pred_length": 18.58823529411765,
        "std_pred_length": 10.688414968220124,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 46,
        "distinct-1": 0.5379746835443038,
        "vocab_size-1": 170,
        "unique-1": 129,
        "entropy-1": 6.584752706667169,
        "distinct-2": 0.8595317725752508,
        "vocab_size-2": 257,
        "unique-2": 230,
        "entropy-2": 7.870241013626773,
        "cond_entropy-2": 1.1461396503748689,
        "distinct-3": 0.9432624113475178,
        "vocab_size-3": 266,
        "unique-3": 251,
        "entropy-3": 8.023399269057823,
        "cond_entropy-3": 0.17448425269946138,
        "total_length-nopunct": 276,
        "mean_pred_length-nopunct": 16.235294117647058,
        "std_pred_length-nopunct": 9.545737649151897,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5978260869565217,
        "vocab_size-1-nopunct": 165,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.665936735433281,
        "distinct-2-nopunct": 0.8532818532818532,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 198,
        "entropy-2-nopunct": 7.639300806949781,
        "cond_entropy-2-nopunct": 1.0552253192693,
        "distinct-3-nopunct": 0.9421487603305785,
        "vocab_size-3-nopunct": 228,
        "unique-3-nopunct": 215,
        "entropy-3-nopunct": 7.800041388092102,
        "cond_entropy-3-nopunct": 0.183127470284957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.89849,
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.46875,
            "3": 0.7953216374269005
        },
        "rouge1": {
            "precision": 0.72451,
            "recall": 0.6811,
            "fmeasure": 0.68106
        },
        "rouge2": {
            "precision": 0.49692,
            "recall": 0.4531,
            "fmeasure": 0.46209
        },
        "rougeL": {
            "precision": 0.6424,
            "recall": 0.60741,
            "fmeasure": 0.60653
        },
        "rougeLsum": {
            "precision": 0.6424,
            "recall": 0.60741,
            "fmeasure": 0.60653
        },
        "nist": 6.013617446560291,
        "bleurt": 0.1922,
        "bertscore": {
            "precision": 0.91708,
            "recall": 0.90203,
            "f1": 0.90794
        },
        "nubia": {
            "semantic_relation": 4.05913,
            "contradiction": 2.57485,
            "irrelevancy": 27.46922,
            "logical_agreement": 69.95593,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.34112,
            "nubia_score": 0.67339
        },
        "meteor": 0.3998307164352724
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.78,
        "total_length": 436,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 4.844813951249544,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.591743119266055,
        "vocab_size-1": 258,
        "unique-1": 217,
        "entropy-1": 7.157427425841882,
        "distinct-2": 0.9223300970873787,
        "vocab_size-2": 380,
        "unique-2": 359,
        "entropy-2": 8.495551414408782,
        "cond_entropy-2": 1.1648692933172162,
        "distinct-3": 0.9845360824742269,
        "vocab_size-3": 382,
        "unique-3": 376,
        "entropy-3": 8.568985007135552,
        "cond_entropy-3": 0.08524487805302516,
        "total_length-nopunct": 380,
        "mean_pred_length-nopunct": 15.833333333333334,
        "std_pred_length-nopunct": 4.561310727801336,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6657894736842105,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 215,
        "entropy-1-nopunct": 7.370789897539524,
        "distinct-2-nopunct": 0.9157303370786517,
        "vocab_size-2-nopunct": 326,
        "unique-2-nopunct": 307,
        "entropy-2-nopunct": 8.265983334160083,
        "cond_entropy-2-nopunct": 0.9704113497076007,
        "distinct-3-nopunct": 0.9849397590361446,
        "vocab_size-3-nopunct": 327,
        "unique-3-nopunct": 322,
        "entropy-3-nopunct": 8.344918949419203,
        "cond_entropy-3-nopunct": 0.09409827285961474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.16181,
        "local_recall": {
            "1": 0.13392857142857142,
            "2": 0.4731182795698925,
            "3": 0.8559670781893004
        },
        "rouge1": {
            "precision": 0.77093,
            "recall": 0.77891,
            "fmeasure": 0.76268
        },
        "rouge2": {
            "precision": 0.48281,
            "recall": 0.48966,
            "fmeasure": 0.47932
        },
        "rougeL": {
            "precision": 0.61413,
            "recall": 0.61282,
            "fmeasure": 0.60468
        },
        "rougeLsum": {
            "precision": 0.61413,
            "recall": 0.61282,
            "fmeasure": 0.60468
        },
        "nist": 6.461897241320927,
        "bleurt": 0.14397,
        "bertscore": {
            "precision": 0.9196,
            "recall": 0.92523,
            "f1": 0.91996
        },
        "nubia": {
            "semantic_relation": 4.27977,
            "contradiction": 3.18721,
            "irrelevancy": 34.74535,
            "logical_agreement": 62.06744,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.63166,
            "nubia_score": 0.75382
        },
        "meteor": 0.4010231997934419
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.66667,
        "msttr-100_nopunct": 0.71,
        "total_length": 386,
        "mean_pred_length": 21.444444444444443,
        "std_pred_length": 13.687878750608439,
        "median_pred_length": 19.5,
        "min_pred_length": 6,
        "max_pred_length": 64,
        "distinct-1": 0.572538860103627,
        "vocab_size-1": 221,
        "unique-1": 180,
        "entropy-1": 6.984910384412894,
        "distinct-2": 0.9184782608695652,
        "vocab_size-2": 338,
        "unique-2": 315,
        "entropy-2": 8.338060155767709,
        "cond_entropy-2": 1.2203811138640197,
        "distinct-3": 0.9828571428571429,
        "vocab_size-3": 344,
        "unique-3": 338,
        "entropy-3": 8.416925397546638,
        "cond_entropy-3": 0.08269104865100285,
        "total_length-nopunct": 339,
        "mean_pred_length-nopunct": 18.833333333333332,
        "std_pred_length-nopunct": 12.047360245667466,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.6342182890855457,
        "vocab_size-1-nopunct": 215,
        "unique-1-nopunct": 178,
        "entropy-1-nopunct": 7.095837485718695,
        "distinct-2-nopunct": 0.9221183800623053,
        "vocab_size-2-nopunct": 296,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 8.147271309538684,
        "cond_entropy-2-nopunct": 1.1043388365702131,
        "distinct-3-nopunct": 0.9867986798679867,
        "vocab_size-3-nopunct": 299,
        "unique-3-nopunct": 295,
        "entropy-3-nopunct": 8.216771343208926,
        "cond_entropy-3-nopunct": 0.07684276369166025,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.38083,
        "local_recall": {
            "1": 0.2524271844660194,
            "2": 0.38636363636363635,
            "3": 0.7193877551020408
        },
        "rouge1": {
            "precision": 0.64928,
            "recall": 0.65539,
            "fmeasure": 0.62198
        },
        "rouge2": {
            "precision": 0.4158,
            "recall": 0.41067,
            "fmeasure": 0.3927
        },
        "rougeL": {
            "precision": 0.52828,
            "recall": 0.54816,
            "fmeasure": 0.51242
        },
        "rougeLsum": {
            "precision": 0.52828,
            "recall": 0.54816,
            "fmeasure": 0.51242
        },
        "nist": 4.9522164303238565,
        "bleurt": -0.06799,
        "bertscore": {
            "precision": 0.88302,
            "recall": 0.88958,
            "f1": 0.88412
        },
        "nubia": {
            "semantic_relation": 3.70699,
            "contradiction": 7.07574,
            "irrelevancy": 48.5689,
            "logical_agreement": 44.35536,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.42817,
            "nubia_score": 0.55658
        },
        "meteor": 0.34144073411284015
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.69,
        "total_length": 119,
        "mean_pred_length": 17.0,
        "std_pred_length": 9.710083124552245,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.6218487394957983,
        "vocab_size-1": 74,
        "unique-1": 54,
        "entropy-1": 5.850113772091123,
        "distinct-2": 0.8660714285714286,
        "vocab_size-2": 97,
        "unique-2": 86,
        "entropy-2": 6.508160502376103,
        "cond_entropy-2": 0.5478810471074421,
        "distinct-3": 0.9428571428571428,
        "vocab_size-3": 99,
        "unique-3": 94,
        "entropy-3": 6.5927703985978905,
        "cond_entropy-3": 0.10455619086721821,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 8.764492371530267,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.693069306930693,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.9043603393120065,
        "distinct-2-nopunct": 0.8829787234042553,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.291238984633333,
        "cond_entropy-2-nopunct": 0.4430164964285464,
        "distinct-3-nopunct": 0.9540229885057471,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.350989472860217,
        "cond_entropy-3-nopunct": 0.08093955798906158,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.30899,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.46153846153846156,
            "3": 0.6533333333333333
        },
        "rouge1": {
            "precision": 0.69376,
            "recall": 0.6561,
            "fmeasure": 0.66662
        },
        "rouge2": {
            "precision": 0.3835,
            "recall": 0.36485,
            "fmeasure": 0.36891
        },
        "rougeL": {
            "precision": 0.55105,
            "recall": 0.51699,
            "fmeasure": 0.52744
        },
        "rougeLsum": {
            "precision": 0.55105,
            "recall": 0.51699,
            "fmeasure": 0.52744
        },
        "nist": 4.250100988230588,
        "bleurt": 0.25013,
        "bertscore": {
            "precision": 0.90367,
            "recall": 0.89762,
            "f1": 0.89697
        },
        "nubia": {
            "semantic_relation": 4.31119,
            "contradiction": 0.64176,
            "irrelevancy": 24.82119,
            "logical_agreement": 74.53705,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.55086,
            "nubia_score": 0.76674
        },
        "meteor": 0.3209023267769785
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.738,
        "msttr-100_nopunct": 0.7775,
        "total_length": 524,
        "mean_pred_length": 18.06896551724138,
        "std_pred_length": 6.6276902643522995,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 37,
        "distinct-1": 0.5763358778625954,
        "vocab_size-1": 302,
        "unique-1": 250,
        "entropy-1": 7.37510407512109,
        "distinct-2": 0.9272727272727272,
        "vocab_size-2": 459,
        "unique-2": 438,
        "entropy-2": 8.764610719019709,
        "cond_entropy-2": 1.1991862834812612,
        "distinct-3": 0.9957081545064378,
        "vocab_size-3": 464,
        "unique-3": 462,
        "entropy-3": 8.855602453667098,
        "cond_entropy-3": 0.09831694040384853,
        "total_length-nopunct": 462,
        "mean_pred_length-nopunct": 15.931034482758621,
        "std_pred_length-nopunct": 5.836455197692604,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6428571428571429,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.561389258244616,
        "distinct-2-nopunct": 0.9399538106235565,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 392,
        "entropy-2-nopunct": 8.599115009208079,
        "cond_entropy-2-nopunct": 1.1048864523701347,
        "distinct-3-nopunct": 0.9975247524752475,
        "vocab_size-3-nopunct": 403,
        "unique-3-nopunct": 402,
        "entropy-3-nopunct": 8.653260987702254,
        "cond_entropy-3-nopunct": 0.06309186453393403,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.62895,
        "local_recall": {
            "1": 0.27184466019417475,
            "2": 0.43023255813953487,
            "3": 0.7913907284768212
        },
        "rouge1": {
            "precision": 0.72973,
            "recall": 0.76789,
            "fmeasure": 0.73543
        },
        "rouge2": {
            "precision": 0.51042,
            "recall": 0.54048,
            "fmeasure": 0.51635
        },
        "rougeL": {
            "precision": 0.63603,
            "recall": 0.66351,
            "fmeasure": 0.63937
        },
        "rougeLsum": {
            "precision": 0.63603,
            "recall": 0.66351,
            "fmeasure": 0.63937
        },
        "nist": 6.217726331699592,
        "bleurt": 0.29146,
        "bertscore": {
            "precision": 0.9235,
            "recall": 0.92927,
            "f1": 0.92473
        },
        "nubia": {
            "semantic_relation": 4.28168,
            "contradiction": 3.76014,
            "irrelevancy": 37.21809,
            "logical_agreement": 59.02177,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.4935,
            "nubia_score": 0.75535
        },
        "meteor": 0.38640712484901335
    },
    "totto_test": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.72237,
        "msttr-100_nopunct": 0.77665,
        "total_length": 130090,
        "mean_pred_length": 16.894805194805194,
        "std_pred_length": 7.077592152443983,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 91,
        "distinct-1": 0.1677684679837036,
        "vocab_size-1": 21825,
        "unique-1": 14951,
        "entropy-1": 10.044281070936574,
        "distinct-2": 0.5475365634447259,
        "vocab_size-2": 67013,
        "unique-2": 55907,
        "entropy-2": 14.683759261206795,
        "cond_entropy-2": 4.263195691310735,
        "distinct-3": 0.790243264452001,
        "vocab_size-3": 90633,
        "unique-3": 82642,
        "entropy-3": 16.02404961041993,
        "cond_entropy-3": 1.317489119573338,
        "total_length-nopunct": 113086,
        "mean_pred_length-nopunct": 14.686493506493507,
        "std_pred_length-nopunct": 6.098149552466186,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.19282669826503723,
        "vocab_size-1-nopunct": 21806,
        "unique-1-nopunct": 14949,
        "entropy-1-nopunct": 10.614768203919416,
        "distinct-2-nopunct": 0.5945381739509992,
        "vocab_size-2-nopunct": 62656,
        "unique-2-nopunct": 53447,
        "entropy-2-nopunct": 14.702957869361445,
        "cond_entropy-2-nopunct": 4.259982530856516,
        "distinct-3-nopunct": 0.8182544069774584,
        "vocab_size-3-nopunct": 79932,
        "unique-3-nopunct": 73861,
        "entropy-3-nopunct": 15.900671418014436,
        "cond_entropy-3-nopunct": 1.268362864023277,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.24759,
        "local_recall": {
            "1": 0.23053224694961288,
            "2": 0.47327249022164275,
            "3": 0.7844045914650993
        },
        "rouge1": {
            "precision": 0.75648,
            "recall": 0.74446,
            "fmeasure": 0.73906
        },
        "rouge2": {
            "precision": 0.53224,
            "recall": 0.52646,
            "fmeasure": 0.52107
        },
        "rougeL": {
            "precision": 0.65727,
            "recall": 0.65106,
            "fmeasure": 0.64398
        },
        "rougeLsum": {
            "precision": 0.65727,
            "recall": 0.65106,
            "fmeasure": 0.64398
        },
        "nist": 10.81651810735298,
        "bleurt": 0.27899,
        "bertscore": {
            "precision": 0.92764,
            "recall": 0.92682,
            "f1": 0.92555
        },
        "nubia": {
            "semantic_relation": 4.21026,
            "contradiction": 7.06897,
            "irrelevancy": 31.26688,
            "logical_agreement": 61.66415,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.63379,
            "nubia_score": 0.73538
        },
        "meteor": 0.3985683495595373
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.7825,
        "total_length": 929,
        "mean_pred_length": 16.89090909090909,
        "std_pred_length": 6.40361468170404,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.527448869752422,
        "vocab_size-1": 490,
        "unique-1": 398,
        "entropy-1": 7.802608694069264,
        "distinct-2": 0.8901601830663616,
        "vocab_size-2": 778,
        "unique-2": 719,
        "entropy-2": 9.498974520410538,
        "cond_entropy-2": 1.4619907128783018,
        "distinct-3": 0.9633699633699634,
        "vocab_size-3": 789,
        "unique-3": 766,
        "entropy-3": 9.598007538447819,
        "cond_entropy-3": 0.08362237301360133,
        "total_length-nopunct": 802,
        "mean_pred_length-nopunct": 14.581818181818182,
        "std_pred_length-nopunct": 5.67191136323521,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.600997506234414,
        "vocab_size-1-nopunct": 482,
        "unique-1-nopunct": 397,
        "entropy-1-nopunct": 8.040461716444655,
        "distinct-2-nopunct": 0.9049531459170014,
        "vocab_size-2-nopunct": 676,
        "unique-2-nopunct": 634,
        "entropy-2-nopunct": 9.30425019245717,
        "cond_entropy-2-nopunct": 1.336011008197962,
        "distinct-3-nopunct": 0.9682080924855492,
        "vocab_size-3-nopunct": 670,
        "unique-3-nopunct": 655,
        "entropy-3-nopunct": 9.363408267354794,
        "cond_entropy-3-nopunct": 0.06792882376589553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.22437,
        "local_recall": {
            "1": 0.3137254901960784,
            "2": 0.47540983606557374,
            "3": 0.7843866171003717
        },
        "rouge1": {
            "precision": 0.75508,
            "recall": 0.73786,
            "fmeasure": 0.73584
        },
        "rouge2": {
            "precision": 0.5152,
            "recall": 0.5005,
            "fmeasure": 0.5007
        },
        "rougeL": {
            "precision": 0.66007,
            "recall": 0.64542,
            "fmeasure": 0.6427
        },
        "rougeLsum": {
            "precision": 0.66007,
            "recall": 0.64542,
            "fmeasure": 0.6427
        },
        "nist": 7.289207779497051,
        "bleurt": 0.22068,
        "bertscore": {
            "precision": 0.92726,
            "recall": 0.92852,
            "f1": 0.92702
        },
        "nubia": {
            "semantic_relation": 4.18881,
            "contradiction": 5.50992,
            "irrelevancy": 35.96212,
            "logical_agreement": 58.52797,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.78323,
            "nubia_score": 0.72997
        },
        "meteor": 0.4049418386938897
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.71393,
        "msttr-100_nopunct": 0.76875,
        "total_length": 2894,
        "mean_pred_length": 17.124260355029588,
        "std_pred_length": 6.774644047307446,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 41,
        "distinct-1": 0.40704906703524535,
        "vocab_size-1": 1178,
        "unique-1": 905,
        "entropy-1": 8.436900709512411,
        "distinct-2": 0.796697247706422,
        "vocab_size-2": 2171,
        "unique-2": 1947,
        "entropy-2": 10.76783629859607,
        "cond_entropy-2": 2.0597492131299786,
        "distinct-3": 0.9135367762128326,
        "vocab_size-3": 2335,
        "unique-3": 2225,
        "entropy-3": 11.077887584101939,
        "cond_entropy-3": 0.31615931818550075,
        "total_length-nopunct": 2498,
        "mean_pred_length-nopunct": 14.781065088757396,
        "std_pred_length-nopunct": 5.8708483547139485,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.466773418734988,
        "vocab_size-1-nopunct": 1166,
        "unique-1-nopunct": 903,
        "entropy-1-nopunct": 8.770106503235905,
        "distinct-2-nopunct": 0.8175182481751825,
        "vocab_size-2-nopunct": 1904,
        "unique-2-nopunct": 1735,
        "entropy-2-nopunct": 10.589802691941998,
        "cond_entropy-2-nopunct": 1.9321771088352109,
        "distinct-3-nopunct": 0.9212962962962963,
        "vocab_size-3-nopunct": 1990,
        "unique-3-nopunct": 1906,
        "entropy-3-nopunct": 10.854670044072739,
        "cond_entropy-3-nopunct": 0.2936188885006019,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.24282,
        "local_recall": {
            "1": 0.22384937238493724,
            "2": 0.4584269662921348,
            "3": 0.7991452991452992
        },
        "rouge1": {
            "precision": 0.77811,
            "recall": 0.76228,
            "fmeasure": 0.76076
        },
        "rouge2": {
            "precision": 0.56325,
            "recall": 0.55141,
            "fmeasure": 0.55016
        },
        "rougeL": {
            "precision": 0.67957,
            "recall": 0.6667,
            "fmeasure": 0.66471
        },
        "rougeLsum": {
            "precision": 0.67957,
            "recall": 0.6667,
            "fmeasure": 0.66471
        },
        "nist": 8.266290378418777,
        "bleurt": 0.32722,
        "bertscore": {
            "precision": 0.93378,
            "recall": 0.93118,
            "f1": 0.93114
        },
        "nubia": {
            "semantic_relation": 4.25751,
            "contradiction": 5.70211,
            "irrelevancy": 29.60971,
            "logical_agreement": 64.68818,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.64086,
            "nubia_score": 0.75847
        },
        "meteor": 0.4086872209841878
    },
    "totto_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "total_length": 147,
        "mean_pred_length": 13.363636363636363,
        "std_pred_length": 3.5998163405860604,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.6462585034013606,
        "vocab_size-1": 95,
        "unique-1": 83,
        "entropy-1": 5.947810830748507,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 128,
        "unique-2": 122,
        "entropy-2": 6.955109900073858,
        "cond_entropy-2": 0.8287456049867991,
        "distinct-3": 0.992,
        "vocab_size-3": 124,
        "unique-3": 123,
        "entropy-3": 6.949784284662096,
        "cond_entropy-3": 0.0063214434117475,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 11.727272727272727,
        "std_pred_length-nopunct": 3.221826390303518,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6976744186046512,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 5.932041152603551,
        "distinct-2-nopunct": 0.940677966101695,
        "vocab_size-2-nopunct": 111,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.74704982902285,
        "cond_entropy-2-nopunct": 0.9156107707499477,
        "distinct-3-nopunct": 0.9906542056074766,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.722775397616091,
        "cond_entropy-3-nopunct": -0.01033494146536707,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.65522,
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.45161290322580644,
            "3": 0.7934782608695652
        },
        "rouge1": {
            "precision": 0.78877,
            "recall": 0.71818,
            "fmeasure": 0.73494
        },
        "rouge2": {
            "precision": 0.60146,
            "recall": 0.58667,
            "fmeasure": 0.57881
        },
        "rougeL": {
            "precision": 0.69753,
            "recall": 0.6771,
            "fmeasure": 0.66743
        },
        "rougeLsum": {
            "precision": 0.69753,
            "recall": 0.6771,
            "fmeasure": 0.66743
        },
        "nist": 6.142554460156119,
        "bleurt": 0.22509,
        "bertscore": {
            "precision": 0.94405,
            "recall": 0.9404,
            "f1": 0.93961
        },
        "nubia": {
            "semantic_relation": 4.02645,
            "contradiction": 2.54491,
            "irrelevancy": 36.63457,
            "logical_agreement": 60.82051,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.63728,
            "nubia_score": 0.68621
        },
        "meteor": 0.43551344741641146
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.77,
        "total_length": 368,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 5.617433182117572,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.6059782608695652,
        "vocab_size-1": 223,
        "unique-1": 188,
        "entropy-1": 7.046382999536934,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 336,
        "unique-2": 329,
        "entropy-2": 8.377558686381859,
        "cond_entropy-2": 1.1143535791100148,
        "distinct-3": 1.0,
        "vocab_size-3": 320,
        "unique-3": 320,
        "entropy-3": 8.321928094887326,
        "cond_entropy-3": -0.058227636370475205,
        "total_length-nopunct": 318,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 4.683748498798798,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6886792452830188,
        "vocab_size-1-nopunct": 219,
        "unique-1-nopunct": 188,
        "entropy-1-nopunct": 7.235826018315385,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 287,
        "unique-2-nopunct": 281,
        "entropy-2-nopunct": 8.14948565265209,
        "cond_entropy-2-nopunct": 0.9913785679668863,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 270,
        "unique-3-nopunct": 270,
        "entropy-3-nopunct": 8.076815597050842,
        "cond_entropy-3-nopunct": -0.07191271999974304,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.85813,
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.37209302325581395,
            "3": 0.7805907172995781
        },
        "rouge1": {
            "precision": 0.78272,
            "recall": 0.73708,
            "fmeasure": 0.74787
        },
        "rouge2": {
            "precision": 0.54865,
            "recall": 0.50203,
            "fmeasure": 0.51291
        },
        "rougeL": {
            "precision": 0.71705,
            "recall": 0.66641,
            "fmeasure": 0.68043
        },
        "rougeLsum": {
            "precision": 0.71705,
            "recall": 0.66641,
            "fmeasure": 0.68043
        },
        "nist": 6.060826402499479,
        "bleurt": 0.25709,
        "bertscore": {
            "precision": 0.93394,
            "recall": 0.92672,
            "f1": 0.92926
        },
        "nubia": {
            "semantic_relation": 4.25413,
            "contradiction": 7.93307,
            "irrelevancy": 28.23929,
            "logical_agreement": 63.82763,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.80726,
            "nubia_score": 0.72071
        },
        "meteor": 0.3896986773843959
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.67,
        "total_length": 142,
        "mean_pred_length": 12.909090909090908,
        "std_pred_length": 2.5028908905338554,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.6197183098591549,
        "vocab_size-1": 88,
        "unique-1": 63,
        "entropy-1": 6.069199050559161,
        "distinct-2": 0.8778625954198473,
        "vocab_size-2": 115,
        "unique-2": 101,
        "entropy-2": 6.777623192344116,
        "cond_entropy-2": 0.5086705612764879,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 110,
        "unique-3": 100,
        "entropy-3": 6.740223928941868,
        "cond_entropy-3": -0.03061761422620741,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 11.454545454545455,
        "std_pred_length-nopunct": 2.3879864611933996,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.099270475221425,
        "distinct-2-nopunct": 0.8782608695652174,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.588883311776328,
        "cond_entropy-2-nopunct": 0.5322495011540264,
        "distinct-3-nopunct": 0.9134615384615384,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.527362795064178,
        "cond_entropy-3-nopunct": -0.03437941930013955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.21686,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.2413793103448276,
            "3": 0.6774193548387096
        },
        "rouge1": {
            "precision": 0.64253,
            "recall": 0.64503,
            "fmeasure": 0.63318
        },
        "rouge2": {
            "precision": 0.37172,
            "recall": 0.39461,
            "fmeasure": 0.37482
        },
        "rougeL": {
            "precision": 0.5746,
            "recall": 0.5892,
            "fmeasure": 0.57148
        },
        "rougeLsum": {
            "precision": 0.5746,
            "recall": 0.5892,
            "fmeasure": 0.57148
        },
        "nist": 4.625235240497038,
        "bleurt": 0.27995,
        "bertscore": {
            "precision": 0.90321,
            "recall": 0.91218,
            "f1": 0.90563
        },
        "nubia": {
            "semantic_relation": 4.29813,
            "contradiction": 8.40257,
            "irrelevancy": 54.62464,
            "logical_agreement": 36.97279,
            "grammar_ref": 5.00152,
            "grammar_hyp": 5.06405,
            "nubia_score": 0.71984
        },
        "meteor": 0.36568814205306105
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.4775,
        "msttr-100_nopunct": 0.49,
        "total_length": 439,
        "mean_pred_length": 27.4375,
        "std_pred_length": 5.544916027317276,
        "median_pred_length": 28.5,
        "min_pred_length": 18,
        "max_pred_length": 36,
        "distinct-1": 0.22779043280182232,
        "vocab_size-1": 100,
        "unique-1": 40,
        "entropy-1": 5.450821202255212,
        "distinct-2": 0.48226950354609927,
        "vocab_size-2": 204,
        "unique-2": 114,
        "entropy-2": 7.252209441258051,
        "cond_entropy-2": 1.7759416546919349,
        "distinct-3": 0.601965601965602,
        "vocab_size-3": 245,
        "unique-3": 158,
        "entropy-3": 7.659829148683432,
        "cond_entropy-3": 0.4292462014981355,
        "total_length-nopunct": 400,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 5.196152422706632,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.245,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.412297622058054,
        "distinct-2-nopunct": 0.4921875,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 7.163111514528208,
        "cond_entropy-2-nopunct": 1.7994845227593956,
        "distinct-3-nopunct": 0.6195652173913043,
        "vocab_size-3-nopunct": 228,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.572769190940909,
        "cond_entropy-3-nopunct": 0.4044615831553944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 4.75382,
        "local_recall": {
            "1": 0.2874493927125506
        },
        "rouge1": {
            "precision": 0.46642,
            "recall": 0.4731,
            "fmeasure": 0.45778
        },
        "rouge2": {
            "precision": 0.22419,
            "recall": 0.24673,
            "fmeasure": 0.22769
        },
        "rougeL": {
            "precision": 0.33802,
            "recall": 0.35615,
            "fmeasure": 0.33768
        },
        "rougeLsum": {
            "precision": 0.33802,
            "recall": 0.35615,
            "fmeasure": 0.33768
        },
        "nist": 1.2597340832777015,
        "bleurt": -0.66108,
        "bertscore": {
            "precision": 0.80942,
            "recall": 0.84631,
            "f1": 0.82733
        },
        "nubia": {
            "semantic_relation": 2.52618,
            "contradiction": 35.14805,
            "irrelevancy": 28.02115,
            "logical_agreement": 36.83081,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.58058,
            "nubia_score": 0.28028
        },
        "meteor": 0.12847432462532088
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.785,
        "total_length": 471,
        "mean_pred_length": 15.193548387096774,
        "std_pred_length": 5.057216847996404,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5456475583864119,
        "vocab_size-1": 257,
        "unique-1": 200,
        "entropy-1": 7.192064959080917,
        "distinct-2": 0.8909090909090909,
        "vocab_size-2": 392,
        "unique-2": 362,
        "entropy-2": 8.511146411275645,
        "cond_entropy-2": 1.088929137159504,
        "distinct-3": 0.9731051344743277,
        "vocab_size-3": 398,
        "unique-3": 387,
        "entropy-3": 8.62216730189045,
        "cond_entropy-3": 0.12172165435493947,
        "total_length-nopunct": 413,
        "mean_pred_length-nopunct": 13.32258064516129,
        "std_pred_length-nopunct": 4.546442045792999,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6101694915254238,
        "vocab_size-1-nopunct": 252,
        "unique-1-nopunct": 199,
        "entropy-1-nopunct": 7.357837246982227,
        "distinct-2-nopunct": 0.8926701570680629,
        "vocab_size-2-nopunct": 341,
        "unique-2-nopunct": 318,
        "entropy-2-nopunct": 8.30283758984315,
        "cond_entropy-2-nopunct": 1.0186313833219351,
        "distinct-3-nopunct": 0.9772079772079773,
        "vocab_size-3-nopunct": 343,
        "unique-3-nopunct": 335,
        "entropy-3-nopunct": 8.409743174720532,
        "cond_entropy-3-nopunct": 0.11357909878772691,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.88369,
        "local_recall": {
            "1": 0.23469387755102042,
            "2": 0.5051546391752577,
            "3": 0.8355704697986577
        },
        "rouge1": {
            "precision": 0.78653,
            "recall": 0.74681,
            "fmeasure": 0.75654
        },
        "rouge2": {
            "precision": 0.54151,
            "recall": 0.51324,
            "fmeasure": 0.52143
        },
        "rougeL": {
            "precision": 0.6513,
            "recall": 0.62653,
            "fmeasure": 0.63173
        },
        "rougeLsum": {
            "precision": 0.6513,
            "recall": 0.62653,
            "fmeasure": 0.63173
        },
        "nist": 6.8022012554501385,
        "bleurt": 0.36309,
        "bertscore": {
            "precision": 0.94231,
            "recall": 0.93741,
            "f1": 0.93876
        },
        "nubia": {
            "semantic_relation": 4.34246,
            "contradiction": 2.46782,
            "irrelevancy": 27.44942,
            "logical_agreement": 70.08276,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.46904,
            "nubia_score": 0.78396
        },
        "meteor": 0.4131909059053234
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.695,
        "total_length": 279,
        "mean_pred_length": 18.6,
        "std_pred_length": 7.391887445030532,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.5376344086021505,
        "vocab_size-1": 150,
        "unique-1": 109,
        "entropy-1": 6.608659761661625,
        "distinct-2": 0.8863636363636364,
        "vocab_size-2": 234,
        "unique-2": 213,
        "entropy-2": 7.7858158522884215,
        "cond_entropy-2": 1.0412794403176409,
        "distinct-3": 0.9558232931726908,
        "vocab_size-3": 238,
        "unique-3": 229,
        "entropy-3": 7.865585164982432,
        "cond_entropy-3": 0.09534631673438038,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 16.733333333333334,
        "std_pred_length-nopunct": 7.196912918436317,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5776892430278885,
        "vocab_size-1-nopunct": 145,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.632059834577771,
        "distinct-2-nopunct": 0.8771186440677966,
        "vocab_size-2-nopunct": 207,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.601860581113978,
        "cond_entropy-2-nopunct": 1.039746904544163,
        "distinct-3-nopunct": 0.9547511312217195,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.690573260729299,
        "cond_entropy-3-nopunct": 0.10777031320680067,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.88211,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.4,
            "3": 0.7543859649122807
        },
        "rouge1": {
            "precision": 0.7146,
            "recall": 0.68951,
            "fmeasure": 0.69496
        },
        "rouge2": {
            "precision": 0.43283,
            "recall": 0.4288,
            "fmeasure": 0.42673
        },
        "rougeL": {
            "precision": 0.58657,
            "recall": 0.58525,
            "fmeasure": 0.58046
        },
        "rougeLsum": {
            "precision": 0.58657,
            "recall": 0.58525,
            "fmeasure": 0.58046
        },
        "nist": 5.619926135133374,
        "bleurt": 0.17706,
        "bertscore": {
            "precision": 0.90032,
            "recall": 0.91002,
            "f1": 0.90238
        },
        "nubia": {
            "semantic_relation": 4.14525,
            "contradiction": 10.75936,
            "irrelevancy": 35.72203,
            "logical_agreement": 53.51862,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.62963,
            "nubia_score": 0.69909
        },
        "meteor": 0.3703532923519019
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.68,
        "total_length": 144,
        "mean_pred_length": 24.0,
        "std_pred_length": 12.7148207485071,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 46,
        "distinct-1": 0.5972222222222222,
        "vocab_size-1": 86,
        "unique-1": 66,
        "entropy-1": 5.9540655235823134,
        "distinct-2": 0.8913043478260869,
        "vocab_size-2": 123,
        "unique-2": 113,
        "entropy-2": 6.850483583775001,
        "cond_entropy-2": 0.8272226060971555,
        "distinct-3": 0.9621212121212122,
        "vocab_size-3": 127,
        "unique-3": 122,
        "entropy-3": 6.968636543600869,
        "cond_entropy-3": 0.12988209041692741,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 8.478731561317938,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6896551724137931,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.942351689881316,
        "distinct-2-nopunct": 0.9181818181818182,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.584908436484333,
        "cond_entropy-2-nopunct": 0.6780914132462396,
        "distinct-3-nopunct": 0.9807692307692307,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.661978179679561,
        "cond_entropy-3-nopunct": 0.08840347071678638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.69935,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.4166666666666667,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.79215,
            "recall": 0.81719,
            "fmeasure": 0.79642
        },
        "rouge2": {
            "precision": 0.56057,
            "recall": 0.58944,
            "fmeasure": 0.56741
        },
        "rougeL": {
            "precision": 0.66319,
            "recall": 0.70839,
            "fmeasure": 0.67676
        },
        "rougeLsum": {
            "precision": 0.66319,
            "recall": 0.70839,
            "fmeasure": 0.67676
        },
        "nist": 5.060461306514745,
        "bleurt": 0.41269,
        "bertscore": {
            "precision": 0.93888,
            "recall": 0.9501,
            "f1": 0.94367
        },
        "nubia": {
            "semantic_relation": 4.63722,
            "contradiction": 1.01032,
            "irrelevancy": 21.74999,
            "logical_agreement": 77.2397,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.83179,
            "nubia_score": 0.8647
        },
        "meteor": 0.4060575624227565
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "T5-xl (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.50833,
        "msttr-100_nopunct": 0.538,
        "total_length": 622,
        "mean_pred_length": 18.294117647058822,
        "std_pred_length": 4.455858085742499,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.22347266881028938,
        "vocab_size-1": 139,
        "unique-1": 66,
        "entropy-1": 5.416900453163029,
        "distinct-2": 0.4642857142857143,
        "vocab_size-2": 273,
        "unique-2": 167,
        "entropy-2": 7.581331174932474,
        "cond_entropy-2": 2.1023309207756538,
        "distinct-3": 0.5830324909747292,
        "vocab_size-3": 323,
        "unique-3": 223,
        "entropy-3": 7.97938546157093,
        "cond_entropy-3": 0.38749983604894367,
        "total_length-nopunct": 577,
        "mean_pred_length-nopunct": 16.970588235294116,
        "std_pred_length-nopunct": 4.239071028349372,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.23570190641247835,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.364569069126497,
        "distinct-2-nopunct": 0.46593001841620624,
        "vocab_size-2-nopunct": 253,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.473198439322275,
        "cond_entropy-2-nopunct": 2.1078064829779213,
        "distinct-3-nopunct": 0.5795677799607073,
        "vocab_size-3-nopunct": 295,
        "unique-3-nopunct": 205,
        "entropy-3-nopunct": 7.841592182417179,
        "cond_entropy-3-nopunct": 0.3726481117712227,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "bleu": 1.0694,
        "local_recall": {
            "1": 0.20597014925373133
        },
        "rouge1": {
            "precision": 0.45971,
            "recall": 0.44376,
            "fmeasure": 0.43912
        },
        "rouge2": {
            "precision": 0.24778,
            "recall": 0.24722,
            "fmeasure": 0.23853
        },
        "rougeL": {
            "precision": 0.36872,
            "recall": 0.35978,
            "fmeasure": 0.35325
        },
        "rougeLsum": {
            "precision": 0.36872,
            "recall": 0.35978,
            "fmeasure": 0.35325
        },
        "nist": 0.852183984184777,
        "bleurt": -0.84534,
        "bertscore": {
            "precision": 0.81196,
            "recall": 0.83967,
            "f1": 0.82545
        },
        "nubia": {
            "semantic_relation": 2.53084,
            "contradiction": 33.13935,
            "irrelevancy": 23.38075,
            "logical_agreement": 43.4799,
            "grammar_ref": 6.46033,
            "grammar_hyp": 5.59763,
            "nubia_score": 0.32854
        },
        "meteor": 0.09778319945500447
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.75333,
        "msttr-100_nopunct": 0.81,
        "total_length": 336,
        "mean_pred_length": 16.8,
        "std_pred_length": 4.106093033529563,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.625,
        "vocab_size-1": 210,
        "unique-1": 178,
        "entropy-1": 7.0825240100981395,
        "distinct-2": 0.9525316455696202,
        "vocab_size-2": 301,
        "unique-2": 291,
        "entropy-2": 8.195348271890765,
        "cond_entropy-2": 0.922182826209946,
        "distinct-3": 0.9898648648648649,
        "vocab_size-3": 293,
        "unique-3": 290,
        "entropy-3": 8.18918309535864,
        "cond_entropy-3": -0.014902466992994617,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 14.45,
        "std_pred_length-nopunct": 3.470950878361721,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7024221453287197,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 177,
        "entropy-1-nopunct": 7.187336776599526,
        "distinct-2-nopunct": 0.9553903345724907,
        "vocab_size-2-nopunct": 257,
        "unique-2-nopunct": 249,
        "entropy-2-nopunct": 7.969195540979171,
        "cond_entropy-2-nopunct": 0.8552854488332755,
        "distinct-3-nopunct": 0.9879518072289156,
        "vocab_size-3-nopunct": 246,
        "unique-3-nopunct": 243,
        "entropy-3-nopunct": 7.935905546525915,
        "cond_entropy-3-nopunct": -0.025075791916948944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.44951,
        "local_recall": {
            "1": 0.25,
            "2": 0.36363636363636365,
            "3": 0.8398058252427184
        },
        "rouge1": {
            "precision": 0.78555,
            "recall": 0.77648,
            "fmeasure": 0.76707
        },
        "rouge2": {
            "precision": 0.60476,
            "recall": 0.59303,
            "fmeasure": 0.58744
        },
        "rougeL": {
            "precision": 0.7042,
            "recall": 0.69577,
            "fmeasure": 0.68693
        },
        "rougeLsum": {
            "precision": 0.7042,
            "recall": 0.69577,
            "fmeasure": 0.68693
        },
        "nist": 6.298508687163944,
        "bleurt": 0.36739,
        "bertscore": {
            "precision": 0.93437,
            "recall": 0.93566,
            "f1": 0.93243
        },
        "nubia": {
            "semantic_relation": 4.32888,
            "contradiction": 10.49754,
            "irrelevancy": 29.04768,
            "logical_agreement": 60.45478,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.48004,
            "nubia_score": 0.76671
        },
        "meteor": 0.42987369129424113
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 126,
        "mean_pred_length": 21.0,
        "std_pred_length": 12.396235987858034,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 91,
        "unique-1": 75,
        "entropy-1": 6.222697332867988,
        "distinct-2": 0.975,
        "vocab_size-2": 117,
        "unique-2": 114,
        "entropy-2": 6.856890595608535,
        "cond_entropy-2": 0.5426742672360757,
        "distinct-3": 0.9912280701754386,
        "vocab_size-3": 113,
        "unique-3": 112,
        "entropy-3": 6.81534615451563,
        "cond_entropy-3": -0.038912862145531114,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 11.015141094572204,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.7631578947368421,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.187559914030567,
        "distinct-2-nopunct": 0.9907407407407407,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.736368983644939,
        "cond_entropy-2-nopunct": 0.57540148258481,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.062854317054718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.48456,
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.3888888888888889,
            "3": 0.7012987012987013
        },
        "rouge1": {
            "precision": 0.67729,
            "recall": 0.63406,
            "fmeasure": 0.63949
        },
        "rouge2": {
            "precision": 0.37299,
            "recall": 0.35321,
            "fmeasure": 0.35666
        },
        "rougeL": {
            "precision": 0.52969,
            "recall": 0.49179,
            "fmeasure": 0.49823
        },
        "rougeLsum": {
            "precision": 0.52969,
            "recall": 0.49179,
            "fmeasure": 0.49823
        },
        "nist": 4.520143082283223,
        "bleurt": 0.05195,
        "bertscore": {
            "precision": 0.894,
            "recall": 0.89063,
            "f1": 0.88866
        },
        "nubia": {
            "semantic_relation": 4.07213,
            "contradiction": 16.68854,
            "irrelevancy": 29.4059,
            "logical_agreement": 53.90556,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.33712,
            "nubia_score": 0.62844
        },
        "meteor": 0.33413709113734
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.772,
        "total_length": 582,
        "mean_pred_length": 16.62857142857143,
        "std_pred_length": 7.131762812680083,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 40,
        "distinct-1": 0.5618556701030928,
        "vocab_size-1": 327,
        "unique-1": 260,
        "entropy-1": 7.431866459938353,
        "distinct-2": 0.9049360146252285,
        "vocab_size-2": 495,
        "unique-2": 457,
        "entropy-2": 8.873411790680633,
        "cond_entropy-2": 1.2255131649486335,
        "distinct-3": 0.970703125,
        "vocab_size-3": 497,
        "unique-3": 482,
        "entropy-3": 8.94140625,
        "cond_entropy-3": 0.07145048104576493,
        "total_length-nopunct": 514,
        "mean_pred_length-nopunct": 14.685714285714285,
        "std_pred_length-nopunct": 6.337062990608407,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6206225680933852,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 256,
        "entropy-1-nopunct": 7.603620931390288,
        "distinct-2-nopunct": 0.9039665970772442,
        "vocab_size-2-nopunct": 433,
        "unique-2-nopunct": 400,
        "entropy-2-nopunct": 8.677011210113925,
        "cond_entropy-2-nopunct": 1.1438083927534015,
        "distinct-3-nopunct": 0.9707207207207207,
        "vocab_size-3-nopunct": 431,
        "unique-3-nopunct": 418,
        "entropy-3-nopunct": 8.735857307791566,
        "cond_entropy-3-nopunct": 0.06997328742261227,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.93047,
        "local_recall": {
            "1": 0.26804123711340205,
            "2": 0.42342342342342343,
            "3": 0.7402234636871509
        },
        "rouge1": {
            "precision": 0.75213,
            "recall": 0.70251,
            "fmeasure": 0.71574
        },
        "rouge2": {
            "precision": 0.54408,
            "recall": 0.49743,
            "fmeasure": 0.51255
        },
        "rougeL": {
            "precision": 0.66083,
            "recall": 0.60647,
            "fmeasure": 0.62395
        },
        "rougeLsum": {
            "precision": 0.66083,
            "recall": 0.60647,
            "fmeasure": 0.62395
        },
        "nist": 6.9175452410581615,
        "bleurt": 0.21422,
        "bertscore": {
            "precision": 0.93436,
            "recall": 0.91711,
            "f1": 0.92432
        },
        "nubia": {
            "semantic_relation": 4.00979,
            "contradiction": 12.37414,
            "irrelevancy": 34.62806,
            "logical_agreement": 52.99779,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.78378,
            "nubia_score": 0.6623
        },
        "meteor": 0.3707641319393049
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.75,
        "total_length": 1021,
        "mean_pred_length": 17.912280701754387,
        "std_pred_length": 6.974340695129027,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.5024485798237023,
        "vocab_size-1": 513,
        "unique-1": 411,
        "entropy-1": 7.806765434388229,
        "distinct-2": 0.8630705394190872,
        "vocab_size-2": 832,
        "unique-2": 762,
        "entropy-2": 9.526645239840084,
        "cond_entropy-2": 1.5044216799669987,
        "distinct-3": 0.9592061742006616,
        "vocab_size-3": 870,
        "unique-3": 841,
        "entropy-3": 9.735631783518008,
        "cond_entropy-3": 0.21478701334920536,
        "total_length-nopunct": 920,
        "mean_pred_length-nopunct": 16.140350877192983,
        "std_pred_length-nopunct": 6.543883166318685,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5489130434782609,
        "vocab_size-1-nopunct": 505,
        "unique-1-nopunct": 407,
        "entropy-1-nopunct": 7.946218446495929,
        "distinct-2-nopunct": 0.8632676709154113,
        "vocab_size-2-nopunct": 745,
        "unique-2-nopunct": 685,
        "entropy-2-nopunct": 9.358281020424023,
        "cond_entropy-2-nopunct": 1.4964025843802258,
        "distinct-3-nopunct": 0.9590570719602978,
        "vocab_size-3-nopunct": 773,
        "unique-3-nopunct": 748,
        "entropy-3-nopunct": 9.5640410533312,
        "cond_entropy-3-nopunct": 0.22551980218530576,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.47136,
        "local_recall": {
            "1": 0.24423963133640553,
            "2": 0.551219512195122,
            "3": 0.8311195445920304
        },
        "rouge1": {
            "precision": 0.75667,
            "recall": 0.78886,
            "fmeasure": 0.75754
        },
        "rouge2": {
            "precision": 0.55558,
            "recall": 0.58229,
            "fmeasure": 0.55742
        },
        "rougeL": {
            "precision": 0.66532,
            "recall": 0.68758,
            "fmeasure": 0.66306
        },
        "rougeLsum": {
            "precision": 0.66532,
            "recall": 0.68758,
            "fmeasure": 0.66306
        },
        "nist": 6.953837503255631,
        "bleurt": 0.22209,
        "bertscore": {
            "precision": 0.91797,
            "recall": 0.93045,
            "f1": 0.92184
        },
        "nubia": {
            "semantic_relation": 4.23299,
            "contradiction": 6.26096,
            "irrelevancy": 40.01882,
            "logical_agreement": 53.72023,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.68949,
            "nubia_score": 0.73844
        },
        "meteor": 0.41765600559338445
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.57516,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.28571,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "nist": 1.5646391913613216,
        "bleurt": 0.38735,
        "bertscore": {
            "precision": 0.93879,
            "recall": 0.93004,
            "f1": 0.9344
        },
        "nubia": {
            "semantic_relation": 4.57626,
            "contradiction": 0.31578,
            "irrelevancy": 0.96507,
            "logical_agreement": 98.71915,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.45359,
            "nubia_score": 0.91559
        },
        "meteor": 0.24530360196822065
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 13.8,
        "std_pred_length": 4.833218389437829,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.8115942028985508,
        "vocab_size-1": 56,
        "unique-1": 50,
        "entropy-1": 5.628532928100429,
        "distinct-2": 0.984375,
        "vocab_size-2": 63,
        "unique-2": 62,
        "entropy-2": 5.96875,
        "cond_entropy-2": 0.1963157776644396,
        "distinct-3": 1.0,
        "vocab_size-3": 59,
        "unique-3": 59,
        "entropy-3": 5.882643049361836,
        "cond_entropy-3": -0.08345864555341295,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 3.9698866482558417,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.864406779661017,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.551968896746127,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.717850465126429,
        "cond_entropy-2-nopunct": 0.1964995454743482,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.09936133151764788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.84341,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.673469387755102
        },
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.71529,
            "fmeasure": 0.72956
        },
        "rouge2": {
            "precision": 0.53928,
            "recall": 0.50862,
            "fmeasure": 0.5162
        },
        "rougeL": {
            "precision": 0.68984,
            "recall": 0.67381,
            "fmeasure": 0.66843
        },
        "rougeLsum": {
            "precision": 0.68984,
            "recall": 0.67381,
            "fmeasure": 0.66843
        },
        "nist": 4.833812988461836,
        "bleurt": 0.38538,
        "bertscore": {
            "precision": 0.94179,
            "recall": 0.9409,
            "f1": 0.9376
        },
        "nubia": {
            "semantic_relation": 4.135,
            "contradiction": 39.48356,
            "irrelevancy": 26.80748,
            "logical_agreement": 33.70895,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.52231,
            "nubia_score": 0.6453
        },
        "meteor": 0.3834230363301357
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.74429,
        "msttr-100_nopunct": 0.795,
        "total_length": 758,
        "mean_pred_length": 17.227272727272727,
        "std_pred_length": 6.765096372234459,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.5329815303430079,
        "vocab_size-1": 404,
        "unique-1": 318,
        "entropy-1": 7.706596938687656,
        "distinct-2": 0.9033613445378151,
        "vocab_size-2": 645,
        "unique-2": 596,
        "entropy-2": 9.252640116263471,
        "cond_entropy-2": 1.3241960083281685,
        "distinct-3": 0.9716417910447761,
        "vocab_size-3": 651,
        "unique-3": 634,
        "entropy-3": 9.32904747190588,
        "cond_entropy-3": 0.07639864892857035,
        "total_length-nopunct": 650,
        "mean_pred_length-nopunct": 14.772727272727273,
        "std_pred_length-nopunct": 5.563123862313153,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6123076923076923,
        "vocab_size-1-nopunct": 398,
        "unique-1-nopunct": 318,
        "entropy-1-nopunct": 7.953822477147758,
        "distinct-2-nopunct": 0.9108910891089109,
        "vocab_size-2-nopunct": 552,
        "unique-2-nopunct": 518,
        "entropy-2-nopunct": 9.025058363828208,
        "cond_entropy-2-nopunct": 1.1259574723985712,
        "distinct-3-nopunct": 0.9750889679715302,
        "vocab_size-3-nopunct": 548,
        "unique-3-nopunct": 536,
        "entropy-3-nopunct": 9.081917823772017,
        "cond_entropy-3-nopunct": 0.05909653692148791,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.82303,
        "local_recall": {
            "1": 0.25742574257425743,
            "2": 0.584,
            "3": 0.7796976241900648
        },
        "rouge1": {
            "precision": 0.7737,
            "recall": 0.77104,
            "fmeasure": 0.76249
        },
        "rouge2": {
            "precision": 0.53929,
            "recall": 0.54639,
            "fmeasure": 0.53621
        },
        "rougeL": {
            "precision": 0.69514,
            "recall": 0.69433,
            "fmeasure": 0.68663
        },
        "rougeLsum": {
            "precision": 0.69514,
            "recall": 0.69433,
            "fmeasure": 0.68663
        },
        "nist": 6.918210951693723,
        "bleurt": 0.34551,
        "bertscore": {
            "precision": 0.93133,
            "recall": 0.93616,
            "f1": 0.93303
        },
        "nubia": {
            "semantic_relation": 4.43527,
            "contradiction": 4.18078,
            "irrelevancy": 23.91665,
            "logical_agreement": 71.90257,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.69791,
            "nubia_score": 0.78582
        },
        "meteor": 0.41400362074487507
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.745,
        "total_length": 345,
        "mean_pred_length": 19.166666666666668,
        "std_pred_length": 10.72510036213078,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 57,
        "distinct-1": 0.5797101449275363,
        "vocab_size-1": 200,
        "unique-1": 164,
        "entropy-1": 6.896819861893613,
        "distinct-2": 0.8899082568807339,
        "vocab_size-2": 291,
        "unique-2": 271,
        "entropy-2": 8.079801021261789,
        "cond_entropy-2": 1.0378641513863356,
        "distinct-3": 0.9579288025889967,
        "vocab_size-3": 296,
        "unique-3": 285,
        "entropy-3": 8.182434629832104,
        "cond_entropy-3": 0.10316867968384487,
        "total_length-nopunct": 294,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 7.0710678118654755,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6530612244897959,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 161,
        "entropy-1-nopunct": 6.96932503521769,
        "distinct-2-nopunct": 0.9021739130434783,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.859867969520555,
        "cond_entropy-2-nopunct": 0.9369429399921881,
        "distinct-3-nopunct": 0.9573643410852714,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 238,
        "entropy-3-nopunct": 7.920104096491723,
        "cond_entropy-3-nopunct": 0.07758425398913038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.32896,
        "local_recall": {
            "1": 0.3939393939393939,
            "2": 0.29411764705882354,
            "3": 0.8558951965065502
        },
        "rouge1": {
            "precision": 0.79621,
            "recall": 0.80013,
            "fmeasure": 0.79168
        },
        "rouge2": {
            "precision": 0.64304,
            "recall": 0.63365,
            "fmeasure": 0.63109
        },
        "rougeL": {
            "precision": 0.75843,
            "recall": 0.76099,
            "fmeasure": 0.75329
        },
        "rougeLsum": {
            "precision": 0.75843,
            "recall": 0.76099,
            "fmeasure": 0.75329
        },
        "nist": 7.189719668178145,
        "bleurt": 0.39172,
        "bertscore": {
            "precision": 0.94592,
            "recall": 0.95156,
            "f1": 0.94821
        },
        "nubia": {
            "semantic_relation": 4.38726,
            "contradiction": 13.12134,
            "irrelevancy": 29.44751,
            "logical_agreement": 57.43115,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.39312,
            "nubia_score": 0.78212
        },
        "meteor": 0.47817337419234907
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 573,
        "mean_pred_length": 17.363636363636363,
        "std_pred_length": 6.568142497523071,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 40,
        "distinct-1": 0.5602094240837696,
        "vocab_size-1": 321,
        "unique-1": 276,
        "entropy-1": 7.31917202902651,
        "distinct-2": 0.9111111111111111,
        "vocab_size-2": 492,
        "unique-2": 463,
        "entropy-2": 8.849809906647085,
        "cond_entropy-2": 1.3350105275322905,
        "distinct-3": 0.9822485207100592,
        "vocab_size-3": 498,
        "unique-3": 492,
        "entropy-3": 8.944905275263487,
        "cond_entropy-3": 0.0965476374153572,
        "total_length-nopunct": 505,
        "mean_pred_length-nopunct": 15.303030303030303,
        "std_pred_length-nopunct": 6.450204828717849,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6237623762376238,
        "vocab_size-1-nopunct": 315,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 7.4556814658491755,
        "distinct-2-nopunct": 0.9194915254237288,
        "vocab_size-2-nopunct": 434,
        "unique-2-nopunct": 414,
        "entropy-2-nopunct": 8.666905368607987,
        "cond_entropy-2-nopunct": 1.3001376054837048,
        "distinct-3-nopunct": 0.9863325740318907,
        "vocab_size-3-nopunct": 433,
        "unique-3-nopunct": 430,
        "entropy-3-nopunct": 8.74446690743469,
        "cond_entropy-3-nopunct": 0.09150081779006347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.00057,
        "local_recall": {
            "1": 0.2,
            "2": 0.19402985074626866,
            "3": 0.8439024390243902
        },
        "rouge1": {
            "precision": 0.80761,
            "recall": 0.7929,
            "fmeasure": 0.79385
        },
        "rouge2": {
            "precision": 0.59385,
            "recall": 0.5913,
            "fmeasure": 0.58766
        },
        "rougeL": {
            "precision": 0.71393,
            "recall": 0.70558,
            "fmeasure": 0.70377
        },
        "rougeLsum": {
            "precision": 0.71393,
            "recall": 0.70558,
            "fmeasure": 0.70377
        },
        "nist": 7.4127283498369625,
        "bleurt": 0.41543,
        "bertscore": {
            "precision": 0.94618,
            "recall": 0.93636,
            "f1": 0.94001
        },
        "nubia": {
            "semantic_relation": 4.51198,
            "contradiction": 5.97345,
            "irrelevancy": 16.5163,
            "logical_agreement": 77.51025,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.92189,
            "nubia_score": 0.7997
        },
        "meteor": 0.44457674512575934
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.7278,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "nist": 1.7887305126316566,
        "bleurt": -0.26935,
        "bertscore": {
            "precision": 0.86484,
            "recall": 0.88864,
            "f1": 0.87658
        },
        "nubia": {
            "semantic_relation": 3.92325,
            "contradiction": 0.65628,
            "irrelevancy": 96.75888,
            "logical_agreement": 2.58483,
            "grammar_ref": 6.33221,
            "grammar_hyp": 6.20705,
            "nubia_score": 0.56012
        },
        "meteor": 0.3279709129282155
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.71167,
        "msttr-100_nopunct": 0.766,
        "total_length": 603,
        "mean_pred_length": 16.75,
        "std_pred_length": 6.006362367430797,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 37,
        "distinct-1": 0.5655058043117744,
        "vocab_size-1": 341,
        "unique-1": 288,
        "entropy-1": 7.4351406136745695,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 525,
        "unique-2": 495,
        "entropy-2": 8.970985970866657,
        "cond_entropy-2": 1.3219373303211,
        "distinct-3": 0.9905838041431262,
        "vocab_size-3": 526,
        "unique-3": 521,
        "entropy-3": 9.033735659090471,
        "cond_entropy-3": 0.05586434424402216,
        "total_length-nopunct": 524,
        "mean_pred_length-nopunct": 14.555555555555555,
        "std_pred_length-nopunct": 5.433662793919465,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6374045801526718,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.633215486631933,
        "distinct-2-nopunct": 0.9344262295081968,
        "vocab_size-2-nopunct": 456,
        "unique-2-nopunct": 436,
        "entropy-2-nopunct": 8.766974741331653,
        "cond_entropy-2-nopunct": 1.193580586480547,
        "distinct-3-nopunct": 0.9889380530973452,
        "vocab_size-3-nopunct": 447,
        "unique-3-nopunct": 442,
        "entropy-3-nopunct": 8.798055068609838,
        "cond_entropy-3-nopunct": 0.044123365916225704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.22332,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6016949152542372,
            "3": 0.8492307692307692
        },
        "rouge1": {
            "precision": 0.77197,
            "recall": 0.80757,
            "fmeasure": 0.77596
        },
        "rouge2": {
            "precision": 0.56951,
            "recall": 0.60123,
            "fmeasure": 0.57265
        },
        "rougeL": {
            "precision": 0.67135,
            "recall": 0.7073,
            "fmeasure": 0.67609
        },
        "rougeLsum": {
            "precision": 0.67135,
            "recall": 0.7073,
            "fmeasure": 0.67609
        },
        "nist": 6.854350634890232,
        "bleurt": 0.26435,
        "bertscore": {
            "precision": 0.93207,
            "recall": 0.93896,
            "f1": 0.93293
        },
        "nubia": {
            "semantic_relation": 4.12845,
            "contradiction": 11.60574,
            "irrelevancy": 44.77488,
            "logical_agreement": 43.61939,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.33895,
            "nubia_score": 0.7196
        },
        "meteor": 0.43068458229261586
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.52807,
        "msttr-100_nopunct": 0.54217,
        "total_length": 11952,
        "mean_pred_length": 23.904,
        "std_pred_length": 12.493629736789865,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 74,
        "distinct-1": 0.11286813922356091,
        "vocab_size-1": 1349,
        "unique-1": 446,
        "entropy-1": 8.030705950564721,
        "distinct-2": 0.35513447432762835,
        "vocab_size-2": 4067,
        "unique-2": 2262,
        "entropy-2": 11.112715228038885,
        "cond_entropy-2": 2.904142652827071,
        "distinct-3": 0.5589846603360117,
        "vocab_size-3": 6122,
        "unique-3": 4270,
        "entropy-3": 12.084241198552423,
        "cond_entropy-3": 1.0158066695163204,
        "total_length-nopunct": 10614,
        "mean_pred_length-nopunct": 21.228,
        "std_pred_length-nopunct": 11.331196582885676,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.12615413604673073,
        "vocab_size-1-nopunct": 1339,
        "unique-1-nopunct": 444,
        "entropy-1-nopunct": 8.29330043834301,
        "distinct-2-nopunct": 0.36770812734823016,
        "vocab_size-2-nopunct": 3719,
        "unique-2-nopunct": 2155,
        "entropy-2-nopunct": 10.997057421078528,
        "cond_entropy-2-nopunct": 2.833377024798376,
        "distinct-3-nopunct": 0.5712502600374454,
        "vocab_size-3-nopunct": 5492,
        "unique-3-nopunct": 3926,
        "entropy-3-nopunct": 11.931611811253282,
        "cond_entropy-3-nopunct": 0.9681709757408606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "bleu": 46.72702,
        "local_recall": {
            "1": 0.22474797390788692,
            "2": 0.5873769935527655,
            "3": 0.87509349289454,
            "4": 0.4,
            "5": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.7628,
            "recall": 0.75099,
            "fmeasure": 0.75017
        },
        "rouge2": {
            "precision": 0.49655,
            "recall": 0.48808,
            "fmeasure": 0.4874
        },
        "rougeL": {
            "precision": 0.59646,
            "recall": 0.58652,
            "fmeasure": 0.58577
        },
        "rougeLsum": {
            "precision": 0.59646,
            "recall": 0.58652,
            "fmeasure": 0.58577
        },
        "nist": 8.87141471187345,
        "bleurt": 0.20289,
        "bertscore": {
            "precision": 0.92206,
            "recall": 0.92025,
            "f1": 0.91991
        },
        "nubia": {
            "semantic_relation": 4.42663,
            "contradiction": 8.70215,
            "irrelevancy": 7.44406,
            "logical_agreement": 83.85379,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.59089,
            "nubia_score": 0.78513
        },
        "meteor": 0.38236646299998633
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.76,
        "total_length": 564,
        "mean_pred_length": 18.8,
        "std_pred_length": 6.273754856543249,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5851063829787234,
        "vocab_size-1": 330,
        "unique-1": 264,
        "entropy-1": 7.526468727661776,
        "distinct-2": 0.897003745318352,
        "vocab_size-2": 479,
        "unique-2": 445,
        "entropy-2": 8.804388775431725,
        "cond_entropy-2": 1.090217031722148,
        "distinct-3": 0.9682539682539683,
        "vocab_size-3": 488,
        "unique-3": 475,
        "entropy-3": 8.90929448201872,
        "cond_entropy-3": 0.1082573230308708,
        "total_length-nopunct": 502,
        "mean_pred_length-nopunct": 16.733333333333334,
        "std_pred_length-nopunct": 5.397118572802426,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6434262948207171,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.676541523832038,
        "distinct-2-nopunct": 0.9004237288135594,
        "vocab_size-2-nopunct": 425,
        "unique-2-nopunct": 399,
        "entropy-2-nopunct": 8.626566732750378,
        "cond_entropy-2-nopunct": 1.007790247907458,
        "distinct-3-nopunct": 0.9705882352941176,
        "vocab_size-3-nopunct": 429,
        "unique-3-nopunct": 419,
        "entropy-3-nopunct": 8.723955359150475,
        "cond_entropy-3-nopunct": 0.11024448499367945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.59998,
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.40186915887850466,
            "3": 0.826865671641791
        },
        "rouge1": {
            "precision": 0.72785,
            "recall": 0.7428,
            "fmeasure": 0.72687
        },
        "rouge2": {
            "precision": 0.5133,
            "recall": 0.53074,
            "fmeasure": 0.51558
        },
        "rougeL": {
            "precision": 0.62051,
            "recall": 0.64762,
            "fmeasure": 0.62588
        },
        "rougeLsum": {
            "precision": 0.62051,
            "recall": 0.64762,
            "fmeasure": 0.62588
        },
        "nist": 6.348714897305251,
        "bleurt": 0.28305,
        "bertscore": {
            "precision": 0.92588,
            "recall": 0.92865,
            "f1": 0.92429
        },
        "nubia": {
            "semantic_relation": 4.09572,
            "contradiction": 9.47256,
            "irrelevancy": 37.9572,
            "logical_agreement": 52.57024,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.71267,
            "nubia_score": 0.68838
        },
        "meteor": 0.4093446278661528
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.775,
        "total_length": 311,
        "mean_pred_length": 15.55,
        "std_pred_length": 6.184456322103019,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.6109324758842444,
        "vocab_size-1": 190,
        "unique-1": 159,
        "entropy-1": 6.865562774381378,
        "distinct-2": 0.9243986254295533,
        "vocab_size-2": 269,
        "unique-2": 253,
        "entropy-2": 8.004784717627986,
        "cond_entropy-2": 0.9346096114920064,
        "distinct-3": 0.977859778597786,
        "vocab_size-3": 265,
        "unique-3": 259,
        "entropy-3": 8.03786859854941,
        "cond_entropy-3": 0.031614554373878404,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 5.620275793944635,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6981132075471698,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 159,
        "entropy-1-nopunct": 7.026121523542869,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.788040502445183,
        "cond_entropy-2-nopunct": 0.8155299605972272,
        "distinct-3-nopunct": 0.9911111111111112,
        "vocab_size-3-nopunct": 223,
        "unique-3-nopunct": 221,
        "entropy-3-nopunct": 7.796003413439214,
        "cond_entropy-3-nopunct": 0.012282683132540885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.11765,
        "local_recall": {
            "1": 0.28,
            "2": 0.45901639344262296,
            "3": 0.675392670157068
        },
        "rouge1": {
            "precision": 0.7251,
            "recall": 0.691,
            "fmeasure": 0.69129
        },
        "rouge2": {
            "precision": 0.46801,
            "recall": 0.44397,
            "fmeasure": 0.4468
        },
        "rougeL": {
            "precision": 0.57346,
            "recall": 0.54462,
            "fmeasure": 0.54585
        },
        "rougeLsum": {
            "precision": 0.57346,
            "recall": 0.54462,
            "fmeasure": 0.54585
        },
        "nist": 5.32475952049286,
        "bleurt": 0.24423,
        "bertscore": {
            "precision": 0.91673,
            "recall": 0.90552,
            "f1": 0.90968
        },
        "nubia": {
            "semantic_relation": 4.06554,
            "contradiction": 3.48017,
            "irrelevancy": 23.84534,
            "logical_agreement": 72.67449,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.77281,
            "nubia_score": 0.65677
        },
        "meteor": 0.35584397415668545
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.755,
        "total_length": 318,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 5.320989115762973,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5880503144654088,
        "vocab_size-1": 187,
        "unique-1": 152,
        "entropy-1": 6.899228316618599,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 279,
        "unique-2": 272,
        "entropy-2": 8.050584472709584,
        "cond_entropy-2": 0.940743636002167,
        "distinct-3": 0.9927536231884058,
        "vocab_size-3": 274,
        "unique-3": 273,
        "entropy-3": 8.09129660350942,
        "cond_entropy-3": 0.016938317792357015,
        "total_length-nopunct": 276,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 4.569940233908602,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6594202898550725,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 7.000937975825523,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 243,
        "unique-2-nopunct": 239,
        "entropy-2-nopunct": 7.861513033012097,
        "cond_entropy-2-nopunct": 0.912572375225768,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 234,
        "unique-3-nopunct": 234,
        "entropy-3-nopunct": 7.87036471958339,
        "cond_entropy-3-nopunct": 0.00045322921498987874,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.43886,
        "local_recall": {
            "1": 0.2753623188405797,
            "2": 0.4528301886792453,
            "3": 0.8191489361702128
        },
        "rouge1": {
            "precision": 0.7449,
            "recall": 0.763,
            "fmeasure": 0.74647
        },
        "rouge2": {
            "precision": 0.54193,
            "recall": 0.54576,
            "fmeasure": 0.53962
        },
        "rougeL": {
            "precision": 0.64959,
            "recall": 0.67127,
            "fmeasure": 0.65414
        },
        "rougeLsum": {
            "precision": 0.64959,
            "recall": 0.67127,
            "fmeasure": 0.65414
        },
        "nist": 6.030431705689952,
        "bleurt": 0.28043,
        "bertscore": {
            "precision": 0.93206,
            "recall": 0.93149,
            "f1": 0.93008
        },
        "nubia": {
            "semantic_relation": 4.08897,
            "contradiction": 8.93733,
            "irrelevancy": 37.37826,
            "logical_agreement": 53.68441,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.92212,
            "nubia_score": 0.69895
        },
        "meteor": 0.39924421196871746
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.70429,
        "msttr-100_nopunct": 0.76167,
        "total_length": 723,
        "mean_pred_length": 16.813953488372093,
        "std_pred_length": 7.00251055960443,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.5131396957123098,
        "vocab_size-1": 371,
        "unique-1": 288,
        "entropy-1": 7.52498430549231,
        "distinct-2": 0.8911764705882353,
        "vocab_size-2": 606,
        "unique-2": 556,
        "entropy-2": 9.145054750899781,
        "cond_entropy-2": 1.401693856290534,
        "distinct-3": 0.9654631083202512,
        "vocab_size-3": 615,
        "unique-3": 597,
        "entropy-3": 9.239796344046026,
        "cond_entropy-3": 0.08432786624709804,
        "total_length-nopunct": 622,
        "mean_pred_length-nopunct": 14.465116279069768,
        "std_pred_length-nopunct": 5.903679724443456,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5836012861736335,
        "vocab_size-1-nopunct": 363,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.732900517195549,
        "distinct-2-nopunct": 0.9101899827288429,
        "vocab_size-2-nopunct": 527,
        "unique-2-nopunct": 494,
        "entropy-2-nopunct": 8.951178228041577,
        "cond_entropy-2-nopunct": 1.294981019915548,
        "distinct-3-nopunct": 0.9776119402985075,
        "vocab_size-3-nopunct": 524,
        "unique-3-nopunct": 514,
        "entropy-3-nopunct": 9.017581727771226,
        "cond_entropy-3-nopunct": 0.05780000406705436,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.77721,
        "local_recall": {
            "1": 0.22413793103448276,
            "2": 0.43609022556390975,
            "3": 0.8514150943396226
        },
        "rouge1": {
            "precision": 0.78606,
            "recall": 0.79153,
            "fmeasure": 0.77697
        },
        "rouge2": {
            "precision": 0.5866,
            "recall": 0.59224,
            "fmeasure": 0.58069
        },
        "rougeL": {
            "precision": 0.69671,
            "recall": 0.71356,
            "fmeasure": 0.69383
        },
        "rougeLsum": {
            "precision": 0.69671,
            "recall": 0.71356,
            "fmeasure": 0.69383
        },
        "nist": 6.79946896739548,
        "bleurt": 0.3455,
        "bertscore": {
            "precision": 0.93828,
            "recall": 0.939,
            "f1": 0.93633
        },
        "nubia": {
            "semantic_relation": 4.32803,
            "contradiction": 4.39539,
            "irrelevancy": 33.15738,
            "logical_agreement": 62.44722,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.42502,
            "nubia_score": 0.76077
        },
        "meteor": 0.4193798458319661
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.72909,
        "msttr-100_nopunct": 0.77556,
        "total_length": 1123,
        "mean_pred_length": 17.015151515151516,
        "std_pred_length": 8.267300362275067,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.4924309884238646,
        "vocab_size-1": 553,
        "unique-1": 446,
        "entropy-1": 7.8957590625131155,
        "distinct-2": 0.8599810785241249,
        "vocab_size-2": 909,
        "unique-2": 832,
        "entropy-2": 9.656155447586185,
        "cond_entropy-2": 1.5226833065631524,
        "distinct-3": 0.9576185671039354,
        "vocab_size-3": 949,
        "unique-3": 920,
        "entropy-3": 9.846219024371829,
        "cond_entropy-3": 0.1558057461410318,
        "total_length-nopunct": 974,
        "mean_pred_length-nopunct": 14.757575757575758,
        "std_pred_length-nopunct": 7.041135854608165,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5585215605749486,
        "vocab_size-1-nopunct": 544,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 8.150446437962458,
        "distinct-2-nopunct": 0.8832599118942731,
        "vocab_size-2-nopunct": 802,
        "unique-2-nopunct": 743,
        "entropy-2-nopunct": 9.507311052526582,
        "cond_entropy-2-nopunct": 1.3970965492076768,
        "distinct-3-nopunct": 0.9691211401425178,
        "vocab_size-3-nopunct": 816,
        "unique-3-nopunct": 794,
        "entropy-3-nopunct": 9.651750324486509,
        "cond_entropy-3-nopunct": 0.10396890276903291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.76602,
        "local_recall": {
            "1": 0.19402985074626866,
            "2": 0.4489795918367347,
            "3": 0.7658045977011494
        },
        "rouge1": {
            "precision": 0.74898,
            "recall": 0.73134,
            "fmeasure": 0.72919
        },
        "rouge2": {
            "precision": 0.51746,
            "recall": 0.5137,
            "fmeasure": 0.50781
        },
        "rougeL": {
            "precision": 0.65509,
            "recall": 0.64225,
            "fmeasure": 0.638
        },
        "rougeLsum": {
            "precision": 0.65509,
            "recall": 0.64225,
            "fmeasure": 0.638
        },
        "nist": 6.888892506348742,
        "bleurt": 0.25324,
        "bertscore": {
            "precision": 0.92057,
            "recall": 0.92095,
            "f1": 0.91873
        },
        "nubia": {
            "semantic_relation": 4.1879,
            "contradiction": 7.9079,
            "irrelevancy": 31.23574,
            "logical_agreement": 60.85635,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.37612,
            "nubia_score": 0.74581
        },
        "meteor": 0.39053817088879017
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.36323,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.7963,
            "recall": 0.5119,
            "fmeasure": 0.62319
        },
        "rouge2": {
            "precision": 0.56863,
            "recall": 0.38827,
            "fmeasure": 0.45946
        },
        "rougeL": {
            "precision": 0.57407,
            "recall": 0.44841,
            "fmeasure": 0.5013
        },
        "rougeLsum": {
            "precision": 0.57407,
            "recall": 0.44841,
            "fmeasure": 0.5013
        },
        "nist": 2.449168228420069,
        "bleurt": 0.01855,
        "bertscore": {
            "precision": 0.92539,
            "recall": 0.87961,
            "f1": 0.90192
        },
        "nubia": {
            "semantic_relation": 3.94592,
            "contradiction": 0.109,
            "irrelevancy": 62.15442,
            "logical_agreement": 37.73659,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.91254,
            "nubia_score": 0.67006
        },
        "meteor": 0.2701792732679323
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.0,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.932138039759376,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.144219710220949,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.852168723603279,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.10003715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.02644273772481475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.50206,
        "local_recall": {
            "1": 0.3,
            "2": 0.25,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.69801,
            "fmeasure": 0.68013
        },
        "rouge2": {
            "precision": 0.4413,
            "recall": 0.41598,
            "fmeasure": 0.42071
        },
        "rougeL": {
            "precision": 0.59343,
            "recall": 0.59117,
            "fmeasure": 0.58183
        },
        "rougeLsum": {
            "precision": 0.59343,
            "recall": 0.59117,
            "fmeasure": 0.58183
        },
        "nist": 3.594787138469367,
        "bleurt": 0.25899,
        "bertscore": {
            "precision": 0.86469,
            "recall": 0.8985,
            "f1": 0.88013
        },
        "nubia": {
            "semantic_relation": 4.20089,
            "contradiction": 0.30996,
            "irrelevancy": 50.11518,
            "logical_agreement": 49.57486,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.16279,
            "nubia_score": 0.73034
        },
        "meteor": 0.2932255395953343
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.72833,
        "msttr-100_nopunct": 0.788,
        "total_length": 633,
        "mean_pred_length": 20.419354838709676,
        "std_pred_length": 7.525330101208451,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5560821484992101,
        "vocab_size-1": 352,
        "unique-1": 281,
        "entropy-1": 7.6004634683731265,
        "distinct-2": 0.9036544850498339,
        "vocab_size-2": 544,
        "unique-2": 502,
        "entropy-2": 9.002389843743044,
        "cond_entropy-2": 1.2452267524205114,
        "distinct-3": 0.9737302977232924,
        "vocab_size-3": 556,
        "unique-3": 542,
        "entropy-3": 9.103485486147152,
        "cond_entropy-3": 0.10664402213006592,
        "total_length-nopunct": 541,
        "mean_pred_length-nopunct": 17.451612903225808,
        "std_pred_length-nopunct": 6.313522148109739,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6395563770794824,
        "vocab_size-1-nopunct": 346,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.829211482454533,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 433,
        "entropy-2-nopunct": 8.776832462408667,
        "cond_entropy-2-nopunct": 0.997794602191669,
        "distinct-3-nopunct": 0.9791231732776617,
        "vocab_size-3-nopunct": 469,
        "unique-3-nopunct": 459,
        "entropy-3-nopunct": 8.862128192291507,
        "cond_entropy-3-nopunct": 0.09102255703921723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.95864,
        "local_recall": {
            "1": 0.24299065420560748,
            "2": 0.43037974683544306,
            "3": 0.7925407925407926
        },
        "rouge1": {
            "precision": 0.8075,
            "recall": 0.77138,
            "fmeasure": 0.77929
        },
        "rouge2": {
            "precision": 0.57475,
            "recall": 0.56237,
            "fmeasure": 0.56276
        },
        "rougeL": {
            "precision": 0.68345,
            "recall": 0.65945,
            "fmeasure": 0.66063
        },
        "rougeLsum": {
            "precision": 0.68345,
            "recall": 0.65945,
            "fmeasure": 0.66063
        },
        "nist": 7.063110770827252,
        "bleurt": 0.32584,
        "bertscore": {
            "precision": 0.93463,
            "recall": 0.93275,
            "f1": 0.93214
        },
        "nubia": {
            "semantic_relation": 4.27909,
            "contradiction": 3.37805,
            "irrelevancy": 26.03379,
            "logical_agreement": 70.58816,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.65172,
            "nubia_score": 0.75269
        },
        "meteor": 0.4170709365057423
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.70267,
        "msttr-100_nopunct": 0.75917,
        "total_length": 1505,
        "mean_pred_length": 18.8125,
        "std_pred_length": 9.238633218718016,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.4584717607973422,
        "vocab_size-1": 690,
        "unique-1": 537,
        "entropy-1": 8.048310239474622,
        "distinct-2": 0.8442105263157895,
        "vocab_size-2": 1203,
        "unique-2": 1089,
        "entropy-2": 10.05927534746308,
        "cond_entropy-2": 1.7979067189186868,
        "distinct-3": 0.9509293680297398,
        "vocab_size-3": 1279,
        "unique-3": 1228,
        "entropy-3": 10.285736935124698,
        "cond_entropy-3": 0.22705129473119393,
        "total_length-nopunct": 1294,
        "mean_pred_length-nopunct": 16.175,
        "std_pred_length-nopunct": 7.486279115822493,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.5278207109737248,
        "vocab_size-1-nopunct": 683,
        "unique-1-nopunct": 535,
        "entropy-1-nopunct": 8.341165196953229,
        "distinct-2-nopunct": 0.8640856672158155,
        "vocab_size-2-nopunct": 1049,
        "unique-2-nopunct": 966,
        "entropy-2-nopunct": 9.874840905145202,
        "cond_entropy-2-nopunct": 1.6160494386849091,
        "distinct-3-nopunct": 0.955026455026455,
        "vocab_size-3-nopunct": 1083,
        "unique-3-nopunct": 1044,
        "entropy-3-nopunct": 10.047972715936252,
        "cond_entropy-3-nopunct": 0.19311147929969305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.34921,
        "local_recall": {
            "1": 0.2570621468926554,
            "2": 0.5175438596491229,
            "3": 0.7658473479948253
        },
        "rouge1": {
            "precision": 0.72733,
            "recall": 0.7218,
            "fmeasure": 0.71318
        },
        "rouge2": {
            "precision": 0.47978,
            "recall": 0.48581,
            "fmeasure": 0.47467
        },
        "rougeL": {
            "precision": 0.62123,
            "recall": 0.63069,
            "fmeasure": 0.61534
        },
        "rougeLsum": {
            "precision": 0.62123,
            "recall": 0.63069,
            "fmeasure": 0.61534
        },
        "nist": 7.184768667701286,
        "bleurt": 0.16461,
        "bertscore": {
            "precision": 0.91241,
            "recall": 0.91861,
            "f1": 0.91333
        },
        "nubia": {
            "semantic_relation": 4.04218,
            "contradiction": 6.45743,
            "irrelevancy": 40.76275,
            "logical_agreement": 52.77982,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.52949,
            "nubia_score": 0.67751
        },
        "meteor": 0.37947435350544173
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.65669,
        "msttr-100_nopunct": 0.69495,
        "total_length": 12129,
        "mean_pred_length": 24.258,
        "std_pred_length": 12.369455768141137,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.11666254431527744,
        "vocab_size-1": 1415,
        "unique-1": 540,
        "entropy-1": 8.044485864344043,
        "distinct-2": 0.34981511737896637,
        "vocab_size-2": 4068,
        "unique-2": 2265,
        "entropy-2": 11.113787594880344,
        "cond_entropy-2": 2.893556111245419,
        "distinct-3": 0.5501842034324738,
        "vocab_size-3": 6123,
        "unique-3": 4214,
        "entropy-3": 12.082323037246931,
        "cond_entropy-3": 1.0129154634195159,
        "total_length-nopunct": 10737,
        "mean_pred_length-nopunct": 21.474,
        "std_pred_length-nopunct": 11.075076704023317,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.13076278290025148,
        "vocab_size-1-nopunct": 1404,
        "unique-1-nopunct": 539,
        "entropy-1-nopunct": 8.30947485053431,
        "distinct-2-nopunct": 0.3653414086158054,
        "vocab_size-2-nopunct": 3740,
        "unique-2-nopunct": 2159,
        "entropy-2-nopunct": 11.006147761036292,
        "cond_entropy-2-nopunct": 2.820108510852913,
        "distinct-3-nopunct": 0.564855705042621,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 3882,
        "entropy-3-nopunct": 11.933071242586347,
        "cond_entropy-3-nopunct": 0.9625426349228751,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "bleu": 47.70361,
        "local_recall": {
            "1": 0.22642692870583317,
            "2": 0.5806673546611627,
            "3": 0.8614447033518552,
            "4": 0.7777777777777778,
            "5": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.75928,
            "recall": 0.7361,
            "fmeasure": 0.74082
        },
        "rouge2": {
            "precision": 0.49806,
            "recall": 0.48267,
            "fmeasure": 0.48536
        },
        "rougeL": {
            "precision": 0.59659,
            "recall": 0.57849,
            "fmeasure": 0.58167
        },
        "rougeLsum": {
            "precision": 0.59659,
            "recall": 0.57849,
            "fmeasure": 0.58167
        },
        "nist": 8.770423003266078,
        "bleurt": 0.17379,
        "bertscore": {
            "precision": 0.92153,
            "recall": 0.91932,
            "f1": 0.91892
        },
        "nubia": {
            "semantic_relation": 4.21527,
            "contradiction": 21.46161,
            "irrelevancy": 6.55562,
            "logical_agreement": 71.98277,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.56337,
            "nubia_score": 0.72117
        },
        "meteor": 0.3824375807631335
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.71583,
        "msttr-100_nopunct": 0.777,
        "total_length": 1260,
        "mean_pred_length": 17.26027397260274,
        "std_pred_length": 7.237700757402598,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.47063492063492063,
        "vocab_size-1": 593,
        "unique-1": 453,
        "entropy-1": 7.984478461806458,
        "distinct-2": 0.8466722830665543,
        "vocab_size-2": 1005,
        "unique-2": 898,
        "entropy-2": 9.813088217338821,
        "cond_entropy-2": 1.5890858818505598,
        "distinct-3": 0.9416517055655296,
        "vocab_size-3": 1049,
        "unique-3": 991,
        "entropy-3": 9.99921335351031,
        "cond_entropy-3": 0.1670899442606267,
        "total_length-nopunct": 1072,
        "mean_pred_length-nopunct": 14.684931506849315,
        "std_pred_length-nopunct": 6.150791712774773,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5438432835820896,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 450,
        "entropy-1-nopunct": 8.268692861803817,
        "distinct-2-nopunct": 0.8628628628628628,
        "vocab_size-2-nopunct": 862,
        "unique-2-nopunct": 782,
        "entropy-2-nopunct": 9.600584038194238,
        "cond_entropy-2-nopunct": 1.403846949064438,
        "distinct-3-nopunct": 0.9503239740820735,
        "vocab_size-3-nopunct": 880,
        "unique-3-nopunct": 839,
        "entropy-3-nopunct": 9.750910864354646,
        "cond_entropy-3-nopunct": 0.15830125764981912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.49208,
        "local_recall": {
            "1": 0.2651162790697674,
            "2": 0.45180722891566266,
            "3": 0.7915151515151515
        },
        "rouge1": {
            "precision": 0.78668,
            "recall": 0.76094,
            "fmeasure": 0.76506
        },
        "rouge2": {
            "precision": 0.56184,
            "recall": 0.5474,
            "fmeasure": 0.54782
        },
        "rougeL": {
            "precision": 0.69408,
            "recall": 0.67568,
            "fmeasure": 0.67703
        },
        "rougeLsum": {
            "precision": 0.69408,
            "recall": 0.67568,
            "fmeasure": 0.67703
        },
        "nist": 7.55967939079842,
        "bleurt": 0.26959,
        "bertscore": {
            "precision": 0.93682,
            "recall": 0.93232,
            "f1": 0.9326
        },
        "nubia": {
            "semantic_relation": 4.2533,
            "contradiction": 3.91934,
            "irrelevancy": 30.72566,
            "logical_agreement": 65.355,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.64459,
            "nubia_score": 0.76089
        },
        "meteor": 0.4085164990015339
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.72182,
        "msttr-100_nopunct": 0.76222,
        "total_length": 1113,
        "mean_pred_length": 17.390625,
        "std_pred_length": 6.355650014701486,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.4968553459119497,
        "vocab_size-1": 553,
        "unique-1": 439,
        "entropy-1": 7.851516630829368,
        "distinct-2": 0.9018112488083889,
        "vocab_size-2": 946,
        "unique-2": 890,
        "entropy-2": 9.769500013297478,
        "cond_entropy-2": 1.6903362516549871,
        "distinct-3": 0.9796954314720813,
        "vocab_size-3": 965,
        "unique-3": 950,
        "entropy-3": 9.899538861033507,
        "cond_entropy-3": 0.13712426169901482,
        "total_length-nopunct": 963,
        "mean_pred_length-nopunct": 15.046875,
        "std_pred_length-nopunct": 5.663561400247639,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5669781931464174,
        "vocab_size-1-nopunct": 546,
        "unique-1-nopunct": 438,
        "entropy-1-nopunct": 8.128399436257155,
        "distinct-2-nopunct": 0.9165739710789766,
        "vocab_size-2-nopunct": 824,
        "unique-2-nopunct": 788,
        "entropy-2-nopunct": 9.573257591621044,
        "cond_entropy-2-nopunct": 1.5423216372386457,
        "distinct-3-nopunct": 0.9868263473053892,
        "vocab_size-3-nopunct": 824,
        "unique-3-nopunct": 817,
        "entropy-3-nopunct": 9.675668854416712,
        "cond_entropy-3-nopunct": 0.11572974984690557,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.52929,
        "local_recall": {
            "1": 0.1581196581196581,
            "2": 0.4581497797356828,
            "3": 0.7594405594405594
        },
        "rouge1": {
            "precision": 0.7637,
            "recall": 0.73017,
            "fmeasure": 0.73649
        },
        "rouge2": {
            "precision": 0.51539,
            "recall": 0.50179,
            "fmeasure": 0.50139
        },
        "rougeL": {
            "precision": 0.6442,
            "recall": 0.62561,
            "fmeasure": 0.62605
        },
        "rougeLsum": {
            "precision": 0.6442,
            "recall": 0.62561,
            "fmeasure": 0.62605
        },
        "nist": 7.115803457482453,
        "bleurt": 0.29207,
        "bertscore": {
            "precision": 0.93182,
            "recall": 0.92605,
            "f1": 0.92714
        },
        "nubia": {
            "semantic_relation": 4.27875,
            "contradiction": 8.09424,
            "irrelevancy": 26.17331,
            "logical_agreement": 65.73244,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.64082,
            "nubia_score": 0.74773
        },
        "meteor": 0.3941700175067366
    },
    "e2e_nlg_validation": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.32401,
        "msttr-100_nopunct": 0.31636,
        "total_length": 106808,
        "mean_pred_length": 24.84484763898581,
        "std_pred_length": 7.045816124515314,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 57,
        "distinct-1": 0.005111976630963973,
        "vocab_size-1": 546,
        "unique-1": 93,
        "entropy-1": 6.208443231167247,
        "distinct-2": 0.02919743632266435,
        "vocab_size-2": 2993,
        "unique-2": 779,
        "entropy-2": 8.582241802118931,
        "cond_entropy-2": 2.2790213351404485,
        "distinct-3": 0.06377151002952856,
        "vocab_size-3": 6263,
        "unique-3": 1944,
        "entropy-3": 10.099191830095524,
        "cond_entropy-3": 1.5316348140391622,
        "total_length-nopunct": 97393,
        "mean_pred_length-nopunct": 22.654803442661084,
        "std_pred_length-nopunct": 6.492462183431024,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.005565081679381475,
        "vocab_size-1-nopunct": 542,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.268418780009367,
        "distinct-2-nopunct": 0.032386619975508624,
        "vocab_size-2-nopunct": 3015,
        "unique-2-nopunct": 807,
        "entropy-2-nopunct": 8.533785617970558,
        "cond_entropy-2-nopunct": 2.3129046405574956,
        "distinct-3-nopunct": 0.06841601441522609,
        "vocab_size-3-nopunct": 6075,
        "unique-3-nopunct": 1911,
        "entropy-3-nopunct": 10.092514417913318,
        "cond_entropy-3-nopunct": 1.5549250632386096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "bleu": 28.65086,
        "local_recall": {
            "1": 0.6777996523100658
        },
        "rouge1": {
            "precision": 0.68001,
            "recall": 0.69108,
            "fmeasure": 0.67461
        },
        "rouge2": {
            "precision": 0.39242,
            "recall": 0.39886,
            "fmeasure": 0.38933
        },
        "rougeL": {
            "precision": 0.48276,
            "recall": 0.49184,
            "fmeasure": 0.47952
        },
        "rougeLsum": {
            "precision": 0.48276,
            "recall": 0.49184,
            "fmeasure": 0.47952
        },
        "nist": 4.7947277574730895,
        "bleurt": 0.12985,
        "bertscore": {
            "precision": 0.89884,
            "recall": 0.89774,
            "f1": 0.89798
        },
        "nubia": {
            "semantic_relation": 4.20791,
            "contradiction": 3.85134,
            "irrelevancy": 27.44754,
            "logical_agreement": 68.70112,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.51703,
            "nubia_score": 0.74317
        },
        "meteor": 0.35116176371893276
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.71444,
        "msttr-100_nopunct": 0.77857,
        "total_length": 908,
        "mean_pred_length": 17.80392156862745,
        "std_pred_length": 8.019631813569815,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 53,
        "distinct-1": 0.539647577092511,
        "vocab_size-1": 490,
        "unique-1": 413,
        "entropy-1": 7.750585976895425,
        "distinct-2": 0.9078179696616102,
        "vocab_size-2": 778,
        "unique-2": 737,
        "entropy-2": 9.476124334729047,
        "cond_entropy-2": 1.509846015249037,
        "distinct-3": 0.9851116625310173,
        "vocab_size-3": 794,
        "unique-3": 782,
        "entropy-3": 9.624859353590075,
        "cond_entropy-3": 0.14390698539230087,
        "total_length-nopunct": 793,
        "mean_pred_length-nopunct": 15.549019607843137,
        "std_pred_length-nopunct": 6.9149276589872795,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6103404791929382,
        "vocab_size-1-nopunct": 484,
        "unique-1-nopunct": 411,
        "entropy-1-nopunct": 7.983871996498297,
        "distinct-2-nopunct": 0.9123989218328841,
        "vocab_size-2-nopunct": 677,
        "unique-2-nopunct": 646,
        "entropy-2-nopunct": 9.271363463031879,
        "cond_entropy-2-nopunct": 1.3736340817822412,
        "distinct-3-nopunct": 0.9869753979739508,
        "vocab_size-3-nopunct": 682,
        "unique-3-nopunct": 673,
        "entropy-3-nopunct": 9.406492696336327,
        "cond_entropy-3-nopunct": 0.15316035861984606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.31276,
        "local_recall": {
            "1": 0.21354166666666666,
            "2": 0.5507246376811594,
            "3": 0.8426763110307414
        },
        "rouge1": {
            "precision": 0.79697,
            "recall": 0.79039,
            "fmeasure": 0.78013
        },
        "rouge2": {
            "precision": 0.56918,
            "recall": 0.56894,
            "fmeasure": 0.55916
        },
        "rougeL": {
            "precision": 0.67864,
            "recall": 0.68337,
            "fmeasure": 0.66917
        },
        "rougeLsum": {
            "precision": 0.67864,
            "recall": 0.68337,
            "fmeasure": 0.66917
        },
        "nist": 7.566882128140928,
        "bleurt": 0.36108,
        "bertscore": {
            "precision": 0.93604,
            "recall": 0.93262,
            "f1": 0.93251
        },
        "nubia": {
            "semantic_relation": 4.344,
            "contradiction": 1.20645,
            "irrelevancy": 27.03966,
            "logical_agreement": 71.75389,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.90232,
            "nubia_score": 0.74428
        },
        "meteor": 0.4247692534148011
    },
    "e2e_nlg_test": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.32287,
        "msttr-100_nopunct": 0.31586,
        "total_length": 119534,
        "mean_pred_length": 25.470701044108246,
        "std_pred_length": 6.720013479306696,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.00412434955744809,
        "vocab_size-1": 493,
        "unique-1": 76,
        "entropy-1": 6.140791567004517,
        "distinct-2": 0.02324082862392351,
        "vocab_size-2": 2669,
        "unique-2": 586,
        "entropy-2": 8.496473438583752,
        "cond_entropy-2": 2.264953662074914,
        "distinct-3": 0.05519846025347714,
        "vocab_size-3": 6080,
        "unique-3": 1560,
        "entropy-3": 10.012323639551438,
        "cond_entropy-3": 1.519282960448932,
        "total_length-nopunct": 108937,
        "mean_pred_length-nopunct": 23.212657148945237,
        "std_pred_length-nopunct": 6.2027634212806895,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.00448883299521742,
        "vocab_size-1-nopunct": 489,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.192164790243229,
        "distinct-2-nopunct": 0.025900771267411075,
        "vocab_size-2-nopunct": 2700,
        "unique-2-nopunct": 619,
        "entropy-2-nopunct": 8.456289851457568,
        "cond_entropy-2-nopunct": 2.304867548394882,
        "distinct-3-nopunct": 0.059577502988418,
        "vocab_size-3-nopunct": 5931,
        "unique-3-nopunct": 1556,
        "entropy-3-nopunct": 10.024980715771799,
        "cond_entropy-3-nopunct": 1.5514154714528163,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "bleu": 30.05204,
        "local_recall": {
            "1": 0.693026891188634
        },
        "rouge1": {
            "precision": 0.73239,
            "recall": 0.7065,
            "fmeasure": 0.70826
        },
        "rouge2": {
            "precision": 0.43162,
            "recall": 0.41571,
            "fmeasure": 0.41686
        },
        "rougeL": {
            "precision": 0.51148,
            "recall": 0.49354,
            "fmeasure": 0.49461
        },
        "rougeLsum": {
            "precision": 0.51148,
            "recall": 0.49354,
            "fmeasure": 0.49461
        },
        "nist": 5.222673198947388,
        "bleurt": 0.15994,
        "bertscore": {
            "precision": 0.91172,
            "recall": 0.90442,
            "f1": 0.90772
        },
        "nubia": {
            "semantic_relation": 4.31085,
            "contradiction": 3.06497,
            "irrelevancy": 22.01252,
            "logical_agreement": 74.92251,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.53098,
            "nubia_score": 0.7779
        },
        "meteor": 0.3577491464124574
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73778,
        "msttr-100_nopunct": 0.7875,
        "total_length": 953,
        "mean_pred_length": 17.017857142857142,
        "std_pred_length": 6.356917130823971,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.5015739769150053,
        "vocab_size-1": 478,
        "unique-1": 388,
        "entropy-1": 7.771256831876801,
        "distinct-2": 0.8818283166109253,
        "vocab_size-2": 791,
        "unique-2": 731,
        "entropy-2": 9.51421382384552,
        "cond_entropy-2": 1.5114769376102062,
        "distinct-3": 0.9667063020214031,
        "vocab_size-3": 813,
        "unique-3": 792,
        "entropy-3": 9.641492084805442,
        "cond_entropy-3": 0.1350143128747655,
        "total_length-nopunct": 832,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 5.810792211260783,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5661057692307693,
        "vocab_size-1-nopunct": 471,
        "unique-1-nopunct": 388,
        "entropy-1-nopunct": 7.999148783465236,
        "distinct-2-nopunct": 0.8853092783505154,
        "vocab_size-2-nopunct": 687,
        "unique-2-nopunct": 641,
        "entropy-2-nopunct": 9.306567252739741,
        "cond_entropy-2-nopunct": 1.3943361614550307,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 696,
        "unique-3-nopunct": 679,
        "entropy-3-nopunct": 9.415979220658809,
        "cond_entropy-3-nopunct": 0.1286375102915966,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.28972,
        "local_recall": {
            "1": 0.19576719576719576,
            "2": 0.46835443037974683,
            "3": 0.8068535825545171
        },
        "rouge1": {
            "precision": 0.78615,
            "recall": 0.748,
            "fmeasure": 0.7547
        },
        "rouge2": {
            "precision": 0.56097,
            "recall": 0.53473,
            "fmeasure": 0.53915
        },
        "rougeL": {
            "precision": 0.69695,
            "recall": 0.65744,
            "fmeasure": 0.66607
        },
        "rougeLsum": {
            "precision": 0.69695,
            "recall": 0.65744,
            "fmeasure": 0.66607
        },
        "nist": 7.274210522463847,
        "bleurt": 0.31255,
        "bertscore": {
            "precision": 0.93466,
            "recall": 0.92932,
            "f1": 0.93059
        },
        "nubia": {
            "semantic_relation": 4.32166,
            "contradiction": 7.76137,
            "irrelevancy": 26.59246,
            "logical_agreement": 65.64617,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.83542,
            "nubia_score": 0.75442
        },
        "meteor": 0.4096292047342947
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 157,
        "mean_pred_length": 13.083333333333334,
        "std_pred_length": 5.314419587834174,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6815286624203821,
        "vocab_size-1": 107,
        "unique-1": 87,
        "entropy-1": 6.360308348292514,
        "distinct-2": 0.9793103448275862,
        "vocab_size-2": 142,
        "unique-2": 140,
        "entropy-2": 7.133323658965553,
        "cond_entropy-2": 0.5536511644560189,
        "distinct-3": 1.0,
        "vocab_size-3": 133,
        "unique-3": 133,
        "entropy-3": 7.055282435501199,
        "cond_entropy-3": -0.07383802667792921,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 4.058598553961973,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.753731343283582,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.4089410082863605,
        "distinct-2-nopunct": 0.9754098360655737,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.875369407217299,
        "cond_entropy-2-nopunct": 0.5146724824231997,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 6.781359713524669,
        "cond_entropy-3-nopunct": -0.08796955583674052,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.12984,
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.6428571428571429,
            "3": 0.8043478260869565
        },
        "rouge1": {
            "precision": 0.80521,
            "recall": 0.77255,
            "fmeasure": 0.77478
        },
        "rouge2": {
            "precision": 0.57902,
            "recall": 0.5334,
            "fmeasure": 0.545
        },
        "rougeL": {
            "precision": 0.69976,
            "recall": 0.66788,
            "fmeasure": 0.67129
        },
        "rougeLsum": {
            "precision": 0.69976,
            "recall": 0.66788,
            "fmeasure": 0.67129
        },
        "nist": 5.482012844504334,
        "bleurt": 0.22987,
        "bertscore": {
            "precision": 0.9209,
            "recall": 0.92819,
            "f1": 0.92314
        },
        "nubia": {
            "semantic_relation": 4.32119,
            "contradiction": 2.9949,
            "irrelevancy": 34.08708,
            "logical_agreement": 62.91801,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.33281,
            "nubia_score": 0.75994
        },
        "meteor": 0.3950597827225617
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.72133,
        "msttr-100_nopunct": 0.77923,
        "total_length": 1541,
        "mean_pred_length": 18.566265060240966,
        "std_pred_length": 6.987411694955673,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.4828033744321869,
        "vocab_size-1": 744,
        "unique-1": 611,
        "entropy-1": 8.105580545459457,
        "distinct-2": 0.8641975308641975,
        "vocab_size-2": 1260,
        "unique-2": 1163,
        "entropy-2": 10.11915428695252,
        "cond_entropy-2": 1.7901158623353313,
        "distinct-3": 0.9672727272727273,
        "vocab_size-3": 1330,
        "unique-3": 1295,
        "entropy-3": 10.352845157841548,
        "cond_entropy-3": 0.23015436690885713,
        "total_length-nopunct": 1333,
        "mean_pred_length-nopunct": 16.06024096385542,
        "std_pred_length-nopunct": 5.881048586098988,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5513878469617405,
        "vocab_size-1-nopunct": 735,
        "unique-1-nopunct": 607,
        "entropy-1-nopunct": 8.395063154804937,
        "distinct-2-nopunct": 0.8824,
        "vocab_size-2-nopunct": 1103,
        "unique-2-nopunct": 1033,
        "entropy-2-nopunct": 9.937543204826225,
        "cond_entropy-2-nopunct": 1.634122730521227,
        "distinct-3-nopunct": 0.9734361610968295,
        "vocab_size-3-nopunct": 1136,
        "unique-3-nopunct": 1111,
        "entropy-3-nopunct": 10.1303197797264,
        "cond_entropy-3-nopunct": 0.21226424705679975,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.07369,
        "local_recall": {
            "1": 0.25,
            "2": 0.5121951219512195,
            "3": 0.8012820512820513
        },
        "rouge1": {
            "precision": 0.74513,
            "recall": 0.7493,
            "fmeasure": 0.73765
        },
        "rouge2": {
            "precision": 0.51422,
            "recall": 0.51107,
            "fmeasure": 0.50569
        },
        "rougeL": {
            "precision": 0.63706,
            "recall": 0.64017,
            "fmeasure": 0.62992
        },
        "rougeLsum": {
            "precision": 0.63706,
            "recall": 0.64017,
            "fmeasure": 0.62992
        },
        "nist": 7.681161469425849,
        "bleurt": 0.32292,
        "bertscore": {
            "precision": 0.92888,
            "recall": 0.93187,
            "f1": 0.92914
        },
        "nubia": {
            "semantic_relation": 4.32847,
            "contradiction": 5.33584,
            "irrelevancy": 30.96884,
            "logical_agreement": 63.69532,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.57848,
            "nubia_score": 0.76404
        },
        "meteor": 0.40357642149690875
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.6023,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.9011,
            "fmeasure": 0.84729
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.59829,
            "fmeasure": 0.5584
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "nist": 3.7910972535534957,
        "bleurt": 0.56433,
        "bertscore": {
            "precision": 0.93731,
            "recall": 0.95564,
            "f1": 0.94638
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2069,
            "irrelevancy": 0.44767,
            "logical_agreement": 99.34544,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.95929,
            "nubia_score": 1.0
        },
        "meteor": 0.47897116126030975
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.73158,
        "msttr-100_nopunct": 0.78176,
        "total_length": 1958,
        "mean_pred_length": 17.17543859649123,
        "std_pred_length": 6.732020387063875,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.46629213483146065,
        "vocab_size-1": 913,
        "unique-1": 724,
        "entropy-1": 8.357721942774312,
        "distinct-2": 0.8768980477223427,
        "vocab_size-2": 1617,
        "unique-2": 1495,
        "entropy-2": 10.513417245912287,
        "cond_entropy-2": 1.8895386906388618,
        "distinct-3": 0.9751445086705203,
        "vocab_size-3": 1687,
        "unique-3": 1649,
        "entropy-3": 10.70409684997954,
        "cond_entropy-3": 0.1838439677419847,
        "total_length-nopunct": 1709,
        "mean_pred_length-nopunct": 14.991228070175438,
        "std_pred_length-nopunct": 5.831697435830473,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5283791691047396,
        "vocab_size-1-nopunct": 903,
        "unique-1-nopunct": 721,
        "entropy-1-nopunct": 8.66637649498441,
        "distinct-2-nopunct": 0.8896551724137931,
        "vocab_size-2-nopunct": 1419,
        "unique-2-nopunct": 1325,
        "entropy-2-nopunct": 10.333358827364107,
        "cond_entropy-2-nopunct": 1.7538778103966417,
        "distinct-3-nopunct": 0.9763673193787981,
        "vocab_size-3-nopunct": 1446,
        "unique-3-nopunct": 1415,
        "entropy-3-nopunct": 10.482389686261383,
        "cond_entropy-3-nopunct": 0.16571688824574907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.82994,
        "local_recall": {
            "1": 0.24,
            "2": 0.5197044334975369,
            "3": 0.775022143489814
        },
        "rouge1": {
            "precision": 0.73088,
            "recall": 0.72446,
            "fmeasure": 0.71748
        },
        "rouge2": {
            "precision": 0.47728,
            "recall": 0.47396,
            "fmeasure": 0.46846
        },
        "rougeL": {
            "precision": 0.60306,
            "recall": 0.60872,
            "fmeasure": 0.59597
        },
        "rougeLsum": {
            "precision": 0.60306,
            "recall": 0.60872,
            "fmeasure": 0.59597
        },
        "nist": 7.309263857743342,
        "bleurt": 0.25864,
        "bertscore": {
            "precision": 0.91971,
            "recall": 0.91939,
            "f1": 0.91819
        },
        "nubia": {
            "semantic_relation": 4.207,
            "contradiction": 6.05399,
            "irrelevancy": 30.96896,
            "logical_agreement": 62.97705,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.71314,
            "nubia_score": 0.72999
        },
        "meteor": 0.37827896319426746
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.51189,
        "msttr-100_nopunct": 0.52241,
        "total_length": 12751,
        "mean_pred_length": 25.502,
        "std_pred_length": 6.752036433550992,
        "median_pred_length": 25.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.0223511881421065,
        "vocab_size-1": 285,
        "unique-1": 68,
        "entropy-1": 6.1059461537789685,
        "distinct-2": 0.10382825891763937,
        "vocab_size-2": 1272,
        "unique-2": 546,
        "entropy-2": 8.352253088768308,
        "cond_entropy-2": 2.1577236738543943,
        "distinct-3": 0.21615181686664964,
        "vocab_size-3": 2540,
        "unique-3": 1338,
        "entropy-3": 9.70557423507672,
        "cond_entropy-3": 1.354492144730073,
        "total_length-nopunct": 11612,
        "mean_pred_length-nopunct": 23.224,
        "std_pred_length-nopunct": 6.248345701063601,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.024371339993110575,
        "vocab_size-1-nopunct": 283,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.159326433067432,
        "distinct-2-nopunct": 0.11096112311015119,
        "vocab_size-2-nopunct": 1233,
        "unique-2-nopunct": 551,
        "entropy-2-nopunct": 8.320045773821557,
        "cond_entropy-2-nopunct": 2.198959142363532,
        "distinct-3-nopunct": 0.2289860535243121,
        "vocab_size-3-nopunct": 2430,
        "unique-3-nopunct": 1284,
        "entropy-3-nopunct": 9.726956603548393,
        "cond_entropy-3-nopunct": 1.3855573912015242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "bleu": 29.56706,
        "local_recall": {
            "1": 0.6855761182925695
        },
        "rouge1": {
            "precision": 0.72535,
            "recall": 0.70093,
            "fmeasure": 0.70167
        },
        "rouge2": {
            "precision": 0.42531,
            "recall": 0.40988,
            "fmeasure": 0.41073
        },
        "rougeL": {
            "precision": 0.50925,
            "recall": 0.49092,
            "fmeasure": 0.49191
        },
        "rougeLsum": {
            "precision": 0.50925,
            "recall": 0.49092,
            "fmeasure": 0.49191
        },
        "nist": 5.109545829707824,
        "bleurt": 0.15732,
        "bertscore": {
            "precision": 0.91075,
            "recall": 0.90306,
            "f1": 0.90657
        },
        "nubia": {
            "semantic_relation": 4.2808,
            "contradiction": 3.00831,
            "irrelevancy": 22.74055,
            "logical_agreement": 74.25114,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.51797,
            "nubia_score": 0.77065
        },
        "meteor": 0.3547695453775438
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.788,
        "total_length": 617,
        "mean_pred_length": 19.903225806451612,
        "std_pred_length": 7.411215732012583,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5478119935170178,
        "vocab_size-1": 338,
        "unique-1": 268,
        "entropy-1": 7.518360560272345,
        "distinct-2": 0.9180887372013652,
        "vocab_size-2": 538,
        "unique-2": 505,
        "entropy-2": 9.00227564705117,
        "cond_entropy-2": 1.312027287606736,
        "distinct-3": 0.9783783783783784,
        "vocab_size-3": 543,
        "unique-3": 534,
        "entropy-3": 9.06902024500954,
        "cond_entropy-3": 0.06668498972149206,
        "total_length-nopunct": 538,
        "mean_pred_length-nopunct": 17.35483870967742,
        "std_pred_length-nopunct": 6.4184632222422024,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6189591078066915,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.723849021517847,
        "distinct-2-nopunct": 0.9270216962524654,
        "vocab_size-2-nopunct": 470,
        "unique-2-nopunct": 447,
        "entropy-2-nopunct": 8.808250023754322,
        "cond_entropy-2-nopunct": 1.1365433366926572,
        "distinct-3-nopunct": 0.9789915966386554,
        "vocab_size-3-nopunct": 466,
        "unique-3-nopunct": 459,
        "entropy-3-nopunct": 8.848043262243959,
        "cond_entropy-3-nopunct": 0.05135909838615249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.43636,
        "local_recall": {
            "1": 0.22522522522522523,
            "2": 0.4819277108433735,
            "3": 0.8213333333333334
        },
        "rouge1": {
            "precision": 0.74708,
            "recall": 0.7797,
            "fmeasure": 0.75124
        },
        "rouge2": {
            "precision": 0.53043,
            "recall": 0.54294,
            "fmeasure": 0.52742
        },
        "rougeL": {
            "precision": 0.66498,
            "recall": 0.69064,
            "fmeasure": 0.66751
        },
        "rougeLsum": {
            "precision": 0.66498,
            "recall": 0.69064,
            "fmeasure": 0.66751
        },
        "nist": 6.791614172119733,
        "bleurt": 0.32931,
        "bertscore": {
            "precision": 0.9313,
            "recall": 0.93782,
            "f1": 0.93368
        },
        "nubia": {
            "semantic_relation": 4.39795,
            "contradiction": 4.13949,
            "irrelevancy": 32.40718,
            "logical_agreement": 63.45333,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.66368,
            "nubia_score": 0.81371
        },
        "meteor": 0.4114594603763729
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.1593090185301998,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": 0.02961067210860201,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9841837197791885,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548847,
        "cond_entropy-2-nopunct": 0.17625665551219521,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.71354,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.86905,
            "fmeasure": 0.73203
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.58803,
            "fmeasure": 0.4902
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.82143,
            "fmeasure": 0.69281
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.82143,
            "fmeasure": 0.69281
        },
        "nist": 2.733356251016174,
        "bleurt": 0.23641,
        "bertscore": {
            "precision": 0.9179,
            "recall": 0.96187,
            "f1": 0.93937
        },
        "nubia": {
            "semantic_relation": 3.67332,
            "contradiction": 0.2744,
            "irrelevancy": 37.37906,
            "logical_agreement": 62.34654,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.1548,
            "nubia_score": 0.70245
        },
        "meteor": 0.47658130566457096
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.76857,
        "total_length": 831,
        "mean_pred_length": 17.680851063829788,
        "std_pred_length": 6.119749622811632,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5186522262334536,
        "vocab_size-1": 431,
        "unique-1": 342,
        "entropy-1": 7.677235548666372,
        "distinct-2": 0.8992346938775511,
        "vocab_size-2": 705,
        "unique-2": 648,
        "entropy-2": 9.367210992052243,
        "cond_entropy-2": 1.4763476513158382,
        "distinct-3": 0.966078697421981,
        "vocab_size-3": 712,
        "unique-3": 687,
        "entropy-3": 9.457678203939,
        "cond_entropy-3": 0.09539590394499992,
        "total_length-nopunct": 733,
        "mean_pred_length-nopunct": 15.595744680851064,
        "std_pred_length-nopunct": 5.358070367443087,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5811732605729877,
        "vocab_size-1-nopunct": 426,
        "unique-1-nopunct": 342,
        "entropy-1-nopunct": 7.878156922772451,
        "distinct-2-nopunct": 0.902332361516035,
        "vocab_size-2-nopunct": 619,
        "unique-2-nopunct": 574,
        "entropy-2-nopunct": 9.174194357984383,
        "cond_entropy-2-nopunct": 1.368399563888252,
        "distinct-3-nopunct": 0.9702660406885759,
        "vocab_size-3-nopunct": 620,
        "unique-3-nopunct": 601,
        "entropy-3-nopunct": 9.260204202324193,
        "cond_entropy-3-nopunct": 0.09798153320502317,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.35166,
        "local_recall": {
            "1": 0.1953125,
            "2": 0.43410852713178294,
            "3": 0.7872727272727272
        },
        "rouge1": {
            "precision": 0.76031,
            "recall": 0.74344,
            "fmeasure": 0.73755
        },
        "rouge2": {
            "precision": 0.5221,
            "recall": 0.51428,
            "fmeasure": 0.50731
        },
        "rougeL": {
            "precision": 0.65158,
            "recall": 0.64313,
            "fmeasure": 0.63455
        },
        "rougeLsum": {
            "precision": 0.65158,
            "recall": 0.64313,
            "fmeasure": 0.63455
        },
        "nist": 6.783059082625668,
        "bleurt": 0.24647,
        "bertscore": {
            "precision": 0.92184,
            "recall": 0.91768,
            "f1": 0.91869
        },
        "nubia": {
            "semantic_relation": 4.16045,
            "contradiction": 7.49149,
            "irrelevancy": 30.47055,
            "logical_agreement": 62.03795,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.35345,
            "nubia_score": 0.72437
        },
        "meteor": 0.3951918380344988
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.805,
        "total_length": 257,
        "mean_pred_length": 15.117647058823529,
        "std_pred_length": 6.406635833178123,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.6342412451361867,
        "vocab_size-1": 163,
        "unique-1": 133,
        "entropy-1": 6.785277143983549,
        "distinct-2": 0.9708333333333333,
        "vocab_size-2": 233,
        "unique-2": 227,
        "entropy-2": 7.8454118976828795,
        "cond_entropy-2": 0.8570474103131416,
        "distinct-3": 0.9955156950672646,
        "vocab_size-3": 222,
        "unique-3": 221,
        "entropy-3": 7.791931290054844,
        "cond_entropy-3": -0.04879389074577654,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 13.176470588235293,
        "std_pred_length-nopunct": 5.6384738665043574,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.979055565344743,
        "distinct-2-nopunct": 0.9710144927536232,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.631869143479187,
        "cond_entropy-2-nopunct": 0.701514491487673,
        "distinct-3-nopunct": 0.9947368421052631,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.559329292541485,
        "cond_entropy-3-nopunct": -0.06702667810435946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.87455,
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.36065573770491804,
            "3": 0.6956521739130435
        },
        "rouge1": {
            "precision": 0.6562,
            "recall": 0.61866,
            "fmeasure": 0.62304
        },
        "rouge2": {
            "precision": 0.34802,
            "recall": 0.33592,
            "fmeasure": 0.33623
        },
        "rougeL": {
            "precision": 0.54953,
            "recall": 0.51993,
            "fmeasure": 0.5232
        },
        "rougeLsum": {
            "precision": 0.54953,
            "recall": 0.51993,
            "fmeasure": 0.5232
        },
        "nist": 4.957098351901444,
        "bleurt": 0.21482,
        "bertscore": {
            "precision": 0.91271,
            "recall": 0.90799,
            "f1": 0.90824
        },
        "nubia": {
            "semantic_relation": 4.00186,
            "contradiction": 15.3898,
            "irrelevancy": 31.67517,
            "logical_agreement": 52.93503,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.75331,
            "nubia_score": 0.67273
        },
        "meteor": 0.329833213440266
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.742,
        "msttr-100_nopunct": 0.7825,
        "total_length": 518,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.038566528099671,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.5791505791505791,
        "vocab_size-1": 300,
        "unique-1": 243,
        "entropy-1": 7.395344542643672,
        "distinct-2": 0.9163265306122449,
        "vocab_size-2": 449,
        "unique-2": 422,
        "entropy-2": 8.730935923656727,
        "cond_entropy-2": 1.1535404566121468,
        "distinct-3": 0.987012987012987,
        "vocab_size-3": 456,
        "unique-3": 450,
        "entropy-3": 8.825775015442078,
        "cond_entropy-3": 0.0986478719361512,
        "total_length-nopunct": 463,
        "mean_pred_length-nopunct": 16.535714285714285,
        "std_pred_length-nopunct": 5.267705808964271,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6393088552915767,
        "vocab_size-1-nopunct": 296,
        "unique-1-nopunct": 243,
        "entropy-1-nopunct": 7.531744986144778,
        "distinct-2-nopunct": 0.9172413793103448,
        "vocab_size-2-nopunct": 399,
        "unique-2-nopunct": 376,
        "entropy-2-nopunct": 8.557885153914656,
        "cond_entropy-2-nopunct": 1.0915711852837076,
        "distinct-3-nopunct": 0.9877149877149877,
        "vocab_size-3-nopunct": 402,
        "unique-3-nopunct": 397,
        "entropy-3-nopunct": 8.644314959696212,
        "cond_entropy-3-nopunct": 0.09821265647194408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.94991,
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.5466666666666666,
            "3": 0.7280701754385965
        },
        "rouge1": {
            "precision": 0.7452,
            "recall": 0.7085,
            "fmeasure": 0.72184
        },
        "rouge2": {
            "precision": 0.53935,
            "recall": 0.52152,
            "fmeasure": 0.52644
        },
        "rougeL": {
            "precision": 0.62368,
            "recall": 0.60579,
            "fmeasure": 0.61017
        },
        "rougeLsum": {
            "precision": 0.62368,
            "recall": 0.60579,
            "fmeasure": 0.61017
        },
        "nist": 6.286305633736527,
        "bleurt": 0.2257,
        "bertscore": {
            "precision": 0.91579,
            "recall": 0.91477,
            "f1": 0.91294
        },
        "nubia": {
            "semantic_relation": 4.13126,
            "contradiction": 6.96249,
            "irrelevancy": 33.52012,
            "logical_agreement": 59.51739,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.45926,
            "nubia_score": 0.72466
        },
        "meteor": 0.37402789501082145
    },
    "common_gen_validation": {
        "predictions_file": "T5-xl (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.59412,
        "msttr-100_nopunct": 0.6219,
        "total_length": 11434,
        "mean_pred_length": 11.51460221550856,
        "std_pred_length": 2.9799663866449673,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.13389889802343888,
        "vocab_size-1": 1531,
        "unique-1": 782,
        "entropy-1": 7.384700269267881,
        "distinct-2": 0.4742840724068576,
        "vocab_size-2": 4952,
        "unique-2": 3629,
        "entropy-2": 11.10225429437202,
        "cond_entropy-2": 3.488872603555136,
        "distinct-3": 0.7399449618966977,
        "vocab_size-3": 6991,
        "unique-3": 6006,
        "entropy-3": 12.361140641874629,
        "cond_entropy-3": 1.32985062404581,
        "total_length-nopunct": 10565,
        "mean_pred_length-nopunct": 10.639476334340383,
        "std_pred_length-nopunct": 2.825387090857846,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14472314245149076,
        "vocab_size-1-nopunct": 1529,
        "unique-1-nopunct": 782,
        "entropy-1-nopunct": 7.548096666060023,
        "distinct-2-nopunct": 0.4727329711659005,
        "vocab_size-2-nopunct": 4525,
        "unique-2-nopunct": 3357,
        "entropy-2-nopunct": 10.915521401661172,
        "cond_entropy-2-nopunct": 3.6778495685972055,
        "distinct-3-nopunct": 0.7448420561837044,
        "vocab_size-3-nopunct": 6390,
        "unique-3-nopunct": 5527,
        "entropy-3-nopunct": 12.223102010922664,
        "cond_entropy-3-nopunct": 1.3958000028102313,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "bleu": 25.5103,
        "local_recall": {
            "1": 0.10761154855643044,
            "2": 0.33297872340425533,
            "3": 0.5267656320287899,
            "4": 0.7924161400097229,
            "5": 0.851931330472103,
            "6": 0.8333333333333334,
            "7": 1.0,
            "8": 1.0
        },
        "rouge1": {
            "precision": 0.62141,
            "recall": 0.63793,
            "fmeasure": 0.61778
        },
        "rouge2": {
            "precision": 0.31062,
            "recall": 0.31354,
            "fmeasure": 0.30479
        },
        "rougeL": {
            "precision": 0.54072,
            "recall": 0.55327,
            "fmeasure": 0.53678
        },
        "rougeLsum": {
            "precision": 0.54072,
            "recall": 0.55327,
            "fmeasure": 0.53678
        },
        "nist": 6.829766996280772,
        "bleurt": -0.44744,
        "bertscore": {
            "precision": 0.8797,
            "recall": 0.88581,
            "f1": 0.88131
        },
        "nubia": {
            "semantic_relation": 3.1057,
            "contradiction": 29.83958,
            "irrelevancy": 32.00961,
            "logical_agreement": 38.15081,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.49931,
            "nubia_score": 0.45631
        },
        "meteor": 0.26434430750220433
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.82,
        "total_length": 316,
        "mean_pred_length": 18.58823529411765,
        "std_pred_length": 7.866973583049671,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.6012658227848101,
        "vocab_size-1": 190,
        "unique-1": 154,
        "entropy-1": 6.937163905878413,
        "distinct-2": 0.8996655518394648,
        "vocab_size-2": 269,
        "unique-2": 246,
        "entropy-2": 7.999522023767415,
        "cond_entropy-2": 0.902972704158484,
        "distinct-3": 0.9645390070921985,
        "vocab_size-3": 272,
        "unique-3": 262,
        "entropy-3": 8.068629366583226,
        "cond_entropy-3": 0.058686302231186004,
        "total_length-nopunct": 260,
        "mean_pred_length-nopunct": 15.294117647058824,
        "std_pred_length-nopunct": 5.559990540431574,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7115384615384616,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.179971661647533,
        "distinct-2-nopunct": 0.9300411522633745,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.766933787652677,
        "cond_entropy-2-nopunct": 0.6376647374186405,
        "distinct-3-nopunct": 0.9734513274336283,
        "vocab_size-3-nopunct": 220,
        "unique-3-nopunct": 214,
        "entropy-3-nopunct": 7.7670816172824715,
        "cond_entropy-3-nopunct": 0.012023662245691466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.88803,
        "local_recall": {
            "1": 0.23404255319148937,
            "2": 0.3157894736842105,
            "3": 0.8433179723502304
        },
        "rouge1": {
            "precision": 0.81806,
            "recall": 0.78282,
            "fmeasure": 0.79329
        },
        "rouge2": {
            "precision": 0.61477,
            "recall": 0.59411,
            "fmeasure": 0.59929
        },
        "rougeL": {
            "precision": 0.69583,
            "recall": 0.66859,
            "fmeasure": 0.67598
        },
        "rougeLsum": {
            "precision": 0.69583,
            "recall": 0.66859,
            "fmeasure": 0.67598
        },
        "nist": 7.1432157303496195,
        "bleurt": 0.39851,
        "bertscore": {
            "precision": 0.9449,
            "recall": 0.94388,
            "f1": 0.94316
        },
        "nubia": {
            "semantic_relation": 4.4551,
            "contradiction": 1.20322,
            "irrelevancy": 24.68177,
            "logical_agreement": 74.11501,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.55726,
            "nubia_score": 0.82734
        },
        "meteor": 0.4784715288920311
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.68571,
        "msttr-100_nopunct": 0.74,
        "total_length": 722,
        "mean_pred_length": 16.790697674418606,
        "std_pred_length": 5.593011168579503,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5,
        "vocab_size-1": 361,
        "unique-1": 283,
        "entropy-1": 7.304582558771207,
        "distinct-2": 0.8762886597938144,
        "vocab_size-2": 595,
        "unique-2": 548,
        "entropy-2": 9.066172053685126,
        "cond_entropy-2": 1.5525689249387777,
        "distinct-3": 0.9654088050314465,
        "vocab_size-3": 614,
        "unique-3": 594,
        "entropy-3": 9.241326705277405,
        "cond_entropy-3": 0.1813059535607787,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 14.604651162790697,
        "std_pred_length-nopunct": 5.331518981092955,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5668789808917197,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 282,
        "entropy-1-nopunct": 7.514639088725501,
        "distinct-2-nopunct": 0.8786324786324786,
        "vocab_size-2-nopunct": 514,
        "unique-2-nopunct": 478,
        "entropy-2-nopunct": 8.843413818803,
        "cond_entropy-2-nopunct": 1.4316796213327434,
        "distinct-3-nopunct": 0.966789667896679,
        "vocab_size-3-nopunct": 524,
        "unique-3-nopunct": 508,
        "entropy-3-nopunct": 9.012942814408673,
        "cond_entropy-3-nopunct": 0.18321319175500556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.50757,
        "local_recall": {
            "1": 0.23255813953488372,
            "2": 0.6724137931034483,
            "3": 0.8122270742358079
        },
        "rouge1": {
            "precision": 0.82473,
            "recall": 0.79127,
            "fmeasure": 0.79948
        },
        "rouge2": {
            "precision": 0.60915,
            "recall": 0.58866,
            "fmeasure": 0.5926
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.68863,
            "fmeasure": 0.69058
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.68863,
            "fmeasure": 0.69058
        },
        "nist": 7.672420420595472,
        "bleurt": 0.40387,
        "bertscore": {
            "precision": 0.94729,
            "recall": 0.94253,
            "f1": 0.94343
        },
        "nubia": {
            "semantic_relation": 4.42855,
            "contradiction": 5.88404,
            "irrelevancy": 23.08405,
            "logical_agreement": 71.03191,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.51025,
            "nubia_score": 0.81463
        },
        "meteor": 0.44309191442395723
    },
    "common_gen_test": {
        "predictions_file": "T5-xl (Baseline)/common_gen_test",
        "N": 1497
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.77667,
        "total_length": 372,
        "mean_pred_length": 18.6,
        "std_pred_length": 7.391887445030532,
        "median_pred_length": 19.5,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5752688172043011,
        "vocab_size-1": 214,
        "unique-1": 171,
        "entropy-1": 7.0257357548554,
        "distinct-2": 0.8892045454545454,
        "vocab_size-2": 313,
        "unique-2": 287,
        "entropy-2": 8.206140381432526,
        "cond_entropy-2": 1.0208304766547416,
        "distinct-3": 0.9548192771084337,
        "vocab_size-3": 317,
        "unique-3": 306,
        "entropy-3": 8.275582955417232,
        "cond_entropy-3": 0.07037913194232016,
        "total_length-nopunct": 320,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.9497899122574065,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.653125,
        "vocab_size-1-nopunct": 209,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.185799152238206,
        "distinct-2-nopunct": 0.9033333333333333,
        "vocab_size-2-nopunct": 271,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 8.005839180530666,
        "cond_entropy-2-nopunct": 0.8624486244689887,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 270,
        "unique-3-nopunct": 263,
        "entropy-3-nopunct": 8.049766365136085,
        "cond_entropy-3-nopunct": 0.056282863888695106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.02872,
        "local_recall": {
            "1": 0.13725490196078433,
            "2": 0.42592592592592593,
            "3": 0.9022222222222223
        },
        "rouge1": {
            "precision": 0.77196,
            "recall": 0.81341,
            "fmeasure": 0.78607
        },
        "rouge2": {
            "precision": 0.61188,
            "recall": 0.63533,
            "fmeasure": 0.61886
        },
        "rougeL": {
            "precision": 0.66669,
            "recall": 0.69657,
            "fmeasure": 0.67594
        },
        "rougeLsum": {
            "precision": 0.66669,
            "recall": 0.69657,
            "fmeasure": 0.67594
        },
        "nist": 6.269272364381581,
        "bleurt": 0.44405,
        "bertscore": {
            "precision": 0.93396,
            "recall": 0.94663,
            "f1": 0.93937
        },
        "nubia": {
            "semantic_relation": 4.50341,
            "contradiction": 2.45758,
            "irrelevancy": 29.03203,
            "logical_agreement": 68.5104,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.37683,
            "nubia_score": 0.84686
        },
        "meteor": 0.45211725290100363
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 161,
        "mean_pred_length": 14.636363636363637,
        "std_pred_length": 6.183154935684345,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.6894409937888198,
        "vocab_size-1": 111,
        "unique-1": 96,
        "entropy-1": 6.382216289921619,
        "distinct-2": 0.9733333333333334,
        "vocab_size-2": 146,
        "unique-2": 142,
        "entropy-2": 7.17548535716253,
        "cond_entropy-2": 0.6091487916750007,
        "distinct-3": 1.0,
        "vocab_size-3": 139,
        "unique-3": 139,
        "entropy-3": 7.118941072723523,
        "cond_entropy-3": -0.05232366093784101,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 13.181818181818182,
        "std_pred_length-nopunct": 5.407371766532019,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7517241379310344,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.469030425052028,
        "distinct-2-nopunct": 0.9776119402985075,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.021313071054795,
        "cond_entropy-2-nopunct": 0.6106383573057012,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.942514505339227,
        "cond_entropy-3-nopunct": -0.07479419731365478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.3992,
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.2727272727272727,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.74847,
            "recall": 0.67932,
            "fmeasure": 0.69719
        },
        "rouge2": {
            "precision": 0.4725,
            "recall": 0.46837,
            "fmeasure": 0.46165
        },
        "rougeL": {
            "precision": 0.63169,
            "recall": 0.60085,
            "fmeasure": 0.60267
        },
        "rougeLsum": {
            "precision": 0.63169,
            "recall": 0.60085,
            "fmeasure": 0.60267
        },
        "nist": 4.912479511874843,
        "bleurt": 0.09718,
        "bertscore": {
            "precision": 0.91309,
            "recall": 0.89873,
            "f1": 0.90408
        },
        "nubia": {
            "semantic_relation": 4.05428,
            "contradiction": 16.08977,
            "irrelevancy": 35.3512,
            "logical_agreement": 48.55903,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.69716,
            "nubia_score": 0.65321
        },
        "meteor": 0.3747210970009498
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "T5-xl (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.625,
        "msttr-100_nopunct": 0.7,
        "total_length": 297,
        "mean_pred_length": 17.470588235294116,
        "std_pred_length": 6.687280701704617,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 165,
        "unique-1": 130,
        "entropy-1": 6.594692156234648,
        "distinct-2": 0.9071428571428571,
        "vocab_size-2": 254,
        "unique-2": 235,
        "entropy-2": 7.919444133008681,
        "cond_entropy-2": 1.1749190842610693,
        "distinct-3": 0.973384030418251,
        "vocab_size-3": 256,
        "unique-3": 249,
        "entropy-3": 7.98568705012883,
        "cond_entropy-3": 0.07220208452286235,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 14.647058823529411,
        "std_pred_length-nopunct": 5.0286377113323555,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6465863453815262,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 6.7709079828806935,
        "distinct-2-nopunct": 0.9224137931034483,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.676946512368932,
        "cond_entropy-2-nopunct": 0.971618689558027,
        "distinct-3-nopunct": 0.9813953488372092,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.710983547263854,
        "cond_entropy-3-nopunct": 0.03439790097351615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.22161,
        "local_recall": {
            "1": 0.14583333333333334,
            "2": 0.4583333333333333,
            "3": 0.7703349282296651
        },
        "rouge1": {
            "precision": 0.81126,
            "recall": 0.75598,
            "fmeasure": 0.7783
        },
        "rouge2": {
            "precision": 0.54635,
            "recall": 0.49691,
            "fmeasure": 0.51599
        },
        "rougeL": {
            "precision": 0.7031,
            "recall": 0.65784,
            "fmeasure": 0.67568
        },
        "rougeLsum": {
            "precision": 0.7031,
            "recall": 0.65784,
            "fmeasure": 0.67568
        },
        "nist": 6.346891359883306,
        "bleurt": 0.2921,
        "bertscore": {
            "precision": 0.94309,
            "recall": 0.92765,
            "f1": 0.93469
        },
        "nubia": {
            "semantic_relation": 4.22031,
            "contradiction": 6.24211,
            "irrelevancy": 28.93227,
            "logical_agreement": 64.82561,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.65744,
            "nubia_score": 0.70918
        },
        "meteor": 0.3876038408859558
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.4195,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.5,
            "fmeasure": 0.57778
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.20202,
            "fmeasure": 0.23611
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.18333,
            "fmeasure": 0.21111
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.18333,
            "fmeasure": 0.21111
        },
        "nist": 2.0453613026581388,
        "bleurt": -0.00079,
        "bertscore": {
            "precision": 0.90428,
            "recall": 0.83975,
            "f1": 0.87082
        },
        "nubia": {
            "semantic_relation": 3.3815,
            "contradiction": 2.20161,
            "irrelevancy": 1.33583,
            "logical_agreement": 96.46256,
            "grammar_ref": 5.93899,
            "grammar_hyp": 5.88918,
            "nubia_score": 0.44169
        },
        "meteor": 0.2595142549192319
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 19.5,
        "std_pred_length": 6.34428877022476,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.717948717948718,
        "vocab_size-1": 56,
        "unique-1": 45,
        "entropy-1": 5.585027981899552,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 70,
        "unique-2": 67,
        "entropy-2": 6.091144075059178,
        "cond_entropy-2": 0.4358660519143668,
        "distinct-3": 0.9857142857142858,
        "vocab_size-3": 69,
        "unique-3": 68,
        "entropy-3": 6.100711588373543,
        "cond_entropy-3": -0.012243384367362324,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 17.25,
        "std_pred_length-nopunct": 6.378675411086537,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.60099474650782,
        "distinct-2-nopunct": 0.9538461538461539,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.918446466841328,
        "cond_entropy-2-nopunct": 0.2999162409433329,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.032860598404565865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.98502,
        "local_recall": {
            "1": 0.1,
            "2": 0.375,
            "3": 0.6896551724137931
        },
        "rouge1": {
            "precision": 0.73869,
            "recall": 0.72639,
            "fmeasure": 0.72512
        },
        "rouge2": {
            "precision": 0.48864,
            "recall": 0.52671,
            "fmeasure": 0.50135
        },
        "rougeL": {
            "precision": 0.63631,
            "recall": 0.66389,
            "fmeasure": 0.64291
        },
        "rougeLsum": {
            "precision": 0.63631,
            "recall": 0.66389,
            "fmeasure": 0.64291
        },
        "nist": 4.315020115559659,
        "bleurt": 0.13516,
        "bertscore": {
            "precision": 0.91129,
            "recall": 0.90716,
            "f1": 0.90697
        },
        "nubia": {
            "semantic_relation": 4.23958,
            "contradiction": 16.52222,
            "irrelevancy": 46.33354,
            "logical_agreement": 37.14424,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.22513,
            "nubia_score": 0.78116
        },
        "meteor": 0.34320583970178625
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 147,
        "mean_pred_length": 18.375,
        "std_pred_length": 8.092241654819757,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.6870748299319728,
        "vocab_size-1": 101,
        "unique-1": 83,
        "entropy-1": 6.276891797273471,
        "distinct-2": 0.9496402877697842,
        "vocab_size-2": 132,
        "unique-2": 125,
        "entropy-2": 7.018221648263091,
        "cond_entropy-2": 0.6217776522881834,
        "distinct-3": 0.9847328244274809,
        "vocab_size-3": 129,
        "unique-3": 127,
        "entropy-3": 7.002888650392412,
        "cond_entropy-3": -0.009182193323461514,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 6.609652033201143,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7698412698412699,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.349348054620847,
        "distinct-2-nopunct": 0.9661016949152542,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.8148464391923405,
        "cond_entropy-2-nopunct": 0.5080700366989064,
        "distinct-3-nopunct": 0.990909090909091,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.76317789534285,
        "cond_entropy-3-nopunct": -0.046737881291727096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.82254,
        "local_recall": {
            "1": 0.15,
            "2": 0.5128205128205128,
            "3": 0.7241379310344828
        },
        "rouge1": {
            "precision": 0.75105,
            "recall": 0.64885,
            "fmeasure": 0.68247
        },
        "rouge2": {
            "precision": 0.5165,
            "recall": 0.44622,
            "fmeasure": 0.46807
        },
        "rougeL": {
            "precision": 0.63082,
            "recall": 0.55377,
            "fmeasure": 0.57285
        },
        "rougeLsum": {
            "precision": 0.63082,
            "recall": 0.55377,
            "fmeasure": 0.57285
        },
        "nist": 4.594270729923701,
        "bleurt": 0.06327,
        "bertscore": {
            "precision": 0.91499,
            "recall": 0.90325,
            "f1": 0.90814
        },
        "nubia": {
            "semantic_relation": 3.80021,
            "contradiction": 15.45702,
            "irrelevancy": 47.61012,
            "logical_agreement": 36.93285,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.35894,
            "nubia_score": 0.60204
        },
        "meteor": 0.33783581209534985
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.748,
        "total_length": 650,
        "mean_pred_length": 20.3125,
        "std_pred_length": 8.8932470869756,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.5215384615384615,
        "vocab_size-1": 339,
        "unique-1": 262,
        "entropy-1": 7.458188565210658,
        "distinct-2": 0.8446601941747572,
        "vocab_size-2": 522,
        "unique-2": 461,
        "entropy-2": 8.88494519385802,
        "cond_entropy-2": 1.2655194683992084,
        "distinct-3": 0.9163822525597269,
        "vocab_size-3": 537,
        "unique-3": 489,
        "entropy-3": 9.026233155613122,
        "cond_entropy-3": 0.15556879910909366,
        "total_length-nopunct": 571,
        "mean_pred_length-nopunct": 17.84375,
        "std_pred_length-nopunct": 7.198564852628612,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5831873905429071,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.613802565939367,
        "distinct-2-nopunct": 0.8460111317254174,
        "vocab_size-2-nopunct": 456,
        "unique-2-nopunct": 404,
        "entropy-2-nopunct": 8.684812202210795,
        "cond_entropy-2-nopunct": 1.1351648099826237,
        "distinct-3-nopunct": 0.9171597633136095,
        "vocab_size-3-nopunct": 465,
        "unique-3-nopunct": 424,
        "entropy-3-nopunct": 8.818672533646122,
        "cond_entropy-3-nopunct": 0.1505438350591214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.31659,
        "local_recall": {
            "1": 0.24489795918367346,
            "2": 0.39759036144578314,
            "3": 0.8188775510204082
        },
        "rouge1": {
            "precision": 0.7733,
            "recall": 0.77798,
            "fmeasure": 0.76507
        },
        "rouge2": {
            "precision": 0.5682,
            "recall": 0.57553,
            "fmeasure": 0.56371
        },
        "rougeL": {
            "precision": 0.67258,
            "recall": 0.6849,
            "fmeasure": 0.66885
        },
        "rougeLsum": {
            "precision": 0.67258,
            "recall": 0.6849,
            "fmeasure": 0.66885
        },
        "nist": 6.450904142370981,
        "bleurt": 0.21099,
        "bertscore": {
            "precision": 0.92358,
            "recall": 0.92862,
            "f1": 0.92447
        },
        "nubia": {
            "semantic_relation": 4.3458,
            "contradiction": 11.56914,
            "irrelevancy": 25.99952,
            "logical_agreement": 62.43134,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.42276,
            "nubia_score": 0.7599
        },
        "meteor": 0.3995735078651983
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 0.5,
        "median_pred_length": 18.5,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.8648648648648649,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.918780730435346,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.11282643709211579,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.024282836980452634,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.879143374026008,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.11980466308510701,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.02568167993932012,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.02732,
        "local_recall": {
            "1": 0.25,
            "2": 0.7272727272727273,
            "3": 0.4230769230769231
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.55037,
            "fmeasure": 0.53874
        },
        "rouge2": {
            "precision": 0.28992,
            "recall": 0.29167,
            "fmeasure": 0.27577
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.45425,
            "fmeasure": 0.43829
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.45425,
            "fmeasure": 0.43829
        },
        "nist": 2.5183723578663524,
        "bleurt": -0.31559,
        "bertscore": {
            "precision": 0.8941,
            "recall": 0.88064,
            "f1": 0.88594
        },
        "nubia": {
            "semantic_relation": 3.22242,
            "contradiction": 35.04459,
            "irrelevancy": 51.42353,
            "logical_agreement": 13.53188,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.32088,
            "nubia_score": 0.34638
        },
        "meteor": 0.23965083979922303
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 25,
        "distinct-1": 0.7166666666666667,
        "vocab_size-1": 43,
        "unique-1": 33,
        "entropy-1": 5.235812887167011,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 54,
        "unique-2": 51,
        "entropy-2": 5.727626856270001,
        "cond_entropy-2": 0.44371476950932764,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": 0.03310859910983794,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 4.642796092394707,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7735849056603774,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.208868095990992,
        "distinct-2-nopunct": 0.94,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.523856189774728,
        "cond_entropy-2-nopunct": 0.3461312352980642,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": 0.03839223637099783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.08187,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.70599,
            "recall": 0.78638,
            "fmeasure": 0.74038
        },
        "rouge2": {
            "precision": 0.3661,
            "recall": 0.40491,
            "fmeasure": 0.3828
        },
        "rougeL": {
            "precision": 0.53473,
            "recall": 0.59084,
            "fmeasure": 0.55774
        },
        "rougeLsum": {
            "precision": 0.53473,
            "recall": 0.59084,
            "fmeasure": 0.55774
        },
        "nist": 4.004470227688848,
        "bleurt": 0.33454,
        "bertscore": {
            "precision": 0.90984,
            "recall": 0.94765,
            "f1": 0.92596
        },
        "nubia": {
            "semantic_relation": 4.38815,
            "contradiction": 0.16508,
            "irrelevancy": 35.13153,
            "logical_agreement": 64.7034,
            "grammar_ref": 4.57112,
            "grammar_hyp": 3.9543,
            "nubia_score": 0.83688
        },
        "meteor": 0.4471814304917673
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "nist": 5.016137706633773,
        "bleurt": 0.95532,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "T5-xl (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "T5-xl (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.77333,
        "total_length": 366,
        "mean_pred_length": 15.91304347826087,
        "std_pred_length": 3.809747720487777,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5792349726775956,
        "vocab_size-1": 212,
        "unique-1": 173,
        "entropy-1": 6.967086851535996,
        "distinct-2": 0.9300291545189504,
        "vocab_size-2": 319,
        "unique-2": 301,
        "entropy-2": 8.263567600060249,
        "cond_entropy-2": 1.0969943744889505,
        "distinct-3": 0.975,
        "vocab_size-3": 312,
        "unique-3": 304,
        "entropy-3": 8.271928094887327,
        "cond_entropy-3": 0.013502478641425744,
        "total_length-nopunct": 323,
        "mean_pred_length-nopunct": 14.043478260869565,
        "std_pred_length-nopunct": 3.4950680887758945,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6439628482972136,
        "vocab_size-1-nopunct": 208,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.135106211862665,
        "distinct-2-nopunct": 0.93,
        "vocab_size-2-nopunct": 279,
        "unique-2-nopunct": 264,
        "entropy-2-nopunct": 8.067603597240604,
        "cond_entropy-2-nopunct": 0.9911858363282929,
        "distinct-3-nopunct": 0.9783393501805054,
        "vocab_size-3-nopunct": 271,
        "unique-3-nopunct": 265,
        "entropy-3-nopunct": 8.070420866410247,
        "cond_entropy-3-nopunct": 0.0017629267323696846,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.7944,
        "local_recall": {
            "1": 0.19480519480519481,
            "2": 0.5652173913043478,
            "3": 0.7850877192982456
        },
        "rouge1": {
            "precision": 0.77305,
            "recall": 0.73351,
            "fmeasure": 0.74574
        },
        "rouge2": {
            "precision": 0.56871,
            "recall": 0.5481,
            "fmeasure": 0.55369
        },
        "rougeL": {
            "precision": 0.68263,
            "recall": 0.66209,
            "fmeasure": 0.66689
        },
        "rougeLsum": {
            "precision": 0.68263,
            "recall": 0.66209,
            "fmeasure": 0.66689
        },
        "nist": 6.307969689583018,
        "bleurt": 0.25501,
        "bertscore": {
            "precision": 0.93469,
            "recall": 0.93296,
            "f1": 0.93264
        },
        "nubia": {
            "semantic_relation": 4.2676,
            "contradiction": 6.60568,
            "irrelevancy": 29.57725,
            "logical_agreement": 63.81708,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.84096,
            "nubia_score": 0.75052
        },
        "meteor": 0.41095172801008784
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.9180788932265,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7818181818181819,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.258543577121685,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.2980242069206296,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.9180788932265,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.265466763497704,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.30248026507132214,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.1283240969755395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.69398,
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.8285714285714286,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.7395,
            "recall": 0.86316,
            "fmeasure": 0.76664
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.63652,
            "fmeasure": 0.54928
        },
        "rougeL": {
            "precision": 0.67186,
            "recall": 0.82318,
            "fmeasure": 0.71869
        },
        "rougeLsum": {
            "precision": 0.67186,
            "recall": 0.82318,
            "fmeasure": 0.71869
        },
        "nist": 5.109915898119955,
        "bleurt": 0.19534,
        "bertscore": {
            "precision": 0.91574,
            "recall": 0.92995,
            "f1": 0.9168
        },
        "nubia": {
            "semantic_relation": 4.18902,
            "contradiction": 1.38358,
            "irrelevancy": 47.62979,
            "logical_agreement": 50.98663,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.94792,
            "nubia_score": 0.69758
        },
        "meteor": 0.4793445411257307
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.78667,
        "total_length": 459,
        "mean_pred_length": 15.827586206896552,
        "std_pred_length": 4.556684862070619,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5708061002178649,
        "vocab_size-1": 262,
        "unique-1": 214,
        "entropy-1": 7.183574158186586,
        "distinct-2": 0.9395348837209302,
        "vocab_size-2": 404,
        "unique-2": 385,
        "entropy-2": 8.60804247166742,
        "cond_entropy-2": 1.2054094346411965,
        "distinct-3": 0.9925187032418953,
        "vocab_size-3": 398,
        "unique-3": 395,
        "entropy-3": 8.632495832938629,
        "cond_entropy-3": 0.03458892476194479,
        "total_length-nopunct": 391,
        "mean_pred_length-nopunct": 13.482758620689655,
        "std_pred_length-nopunct": 3.7748778436976576,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6547314578005116,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 7.414631987607524,
        "distinct-2-nopunct": 0.9392265193370166,
        "vocab_size-2-nopunct": 340,
        "unique-2-nopunct": 325,
        "entropy-2-nopunct": 8.35546836634703,
        "cond_entropy-2-nopunct": 1.019636009899386,
        "distinct-3-nopunct": 0.996996996996997,
        "vocab_size-3-nopunct": 332,
        "unique-3-nopunct": 331,
        "entropy-3-nopunct": 8.373372361065288,
        "cond_entropy-3-nopunct": 0.02747440943697635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.44773,
        "local_recall": {
            "1": 0.2,
            "2": 0.3469387755102041,
            "3": 0.8328358208955224
        },
        "rouge1": {
            "precision": 0.8383,
            "recall": 0.79775,
            "fmeasure": 0.81072
        },
        "rouge2": {
            "precision": 0.62887,
            "recall": 0.59232,
            "fmeasure": 0.60472
        },
        "rougeL": {
            "precision": 0.72026,
            "recall": 0.68549,
            "fmeasure": 0.69628
        },
        "rougeLsum": {
            "precision": 0.72026,
            "recall": 0.68549,
            "fmeasure": 0.69628
        },
        "nist": 7.31663821687279,
        "bleurt": 0.49788,
        "bertscore": {
            "precision": 0.95418,
            "recall": 0.95175,
            "f1": 0.95173
        },
        "nubia": {
            "semantic_relation": 4.57325,
            "contradiction": 8.43177,
            "irrelevancy": 16.68553,
            "logical_agreement": 74.8827,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.50929,
            "nubia_score": 0.84967
        },
        "meteor": 0.43270899738974417
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.78,
        "total_length": 281,
        "mean_pred_length": 17.5625,
        "std_pred_length": 6.432036516531914,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.6120996441281139,
        "vocab_size-1": 172,
        "unique-1": 146,
        "entropy-1": 6.760013187243233,
        "distinct-2": 0.9509433962264151,
        "vocab_size-2": 252,
        "unique-2": 242,
        "entropy-2": 7.941339540008388,
        "cond_entropy-2": 1.0228003532468755,
        "distinct-3": 1.0,
        "vocab_size-3": 249,
        "unique-3": 249,
        "entropy-3": 7.960001932068083,
        "cond_entropy-3": 0.025634858529822665,
        "total_length-nopunct": 245,
        "mean_pred_length-nopunct": 15.3125,
        "std_pred_length-nopunct": 5.708751505364374,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6857142857142857,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.927856549856592,
        "distinct-2-nopunct": 0.9606986899563319,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 214,
        "entropy-2-nopunct": 7.74857109158095,
        "cond_entropy-2-nopunct": 0.8755422261157128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.734709620225879,
        "cond_entropy-3-nopunct": -0.00705338147597198,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.82708,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.3,
            "3": 0.8716577540106952
        },
        "rouge1": {
            "precision": 0.81387,
            "recall": 0.80561,
            "fmeasure": 0.79052
        },
        "rouge2": {
            "precision": 0.5912,
            "recall": 0.60518,
            "fmeasure": 0.58634
        },
        "rougeL": {
            "precision": 0.69292,
            "recall": 0.69108,
            "fmeasure": 0.67798
        },
        "rougeLsum": {
            "precision": 0.69292,
            "recall": 0.69108,
            "fmeasure": 0.67798
        },
        "nist": 6.528936926254052,
        "bleurt": 0.28614,
        "bertscore": {
            "precision": 0.93934,
            "recall": 0.93901,
            "f1": 0.93723
        },
        "nubia": {
            "semantic_relation": 4.38384,
            "contradiction": 0.7283,
            "irrelevancy": 27.19268,
            "logical_agreement": 72.07902,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.82298,
            "nubia_score": 0.78578
        },
        "meteor": 0.4163160556595744
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 288,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.6075346137535735,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.6180555555555556,
        "vocab_size-1": 178,
        "unique-1": 153,
        "entropy-1": 6.709725596053759,
        "distinct-2": 0.9481481481481482,
        "vocab_size-2": 256,
        "unique-2": 246,
        "entropy-2": 7.9569469749152875,
        "cond_entropy-2": 1.0665730057912406,
        "distinct-3": 0.9880952380952381,
        "vocab_size-3": 249,
        "unique-3": 246,
        "entropy-3": 7.953470399690404,
        "cond_entropy-3": 0.005085469213372422,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 13.944444444444445,
        "std_pred_length-nopunct": 5.071403730967308,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6892430278884463,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 6.8501141566362795,
        "distinct-2-nopunct": 0.9484978540772532,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.742449973080922,
        "cond_entropy-2-nopunct": 0.9746780016448656,
        "distinct-3-nopunct": 0.9906976744186047,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.7295881984266455,
        "cond_entropy-3-nopunct": -0.0026699091271441687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.57375,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.42857142857142855,
            "3": 0.7578947368421053
        },
        "rouge1": {
            "precision": 0.706,
            "recall": 0.7162,
            "fmeasure": 0.70231
        },
        "rouge2": {
            "precision": 0.45272,
            "recall": 0.4497,
            "fmeasure": 0.44643
        },
        "rougeL": {
            "precision": 0.5994,
            "recall": 0.6169,
            "fmeasure": 0.60074
        },
        "rougeLsum": {
            "precision": 0.5994,
            "recall": 0.6169,
            "fmeasure": 0.60074
        },
        "nist": 5.494943946538652,
        "bleurt": 0.30551,
        "bertscore": {
            "precision": 0.9102,
            "recall": 0.91868,
            "f1": 0.91318
        },
        "nubia": {
            "semantic_relation": 4.2067,
            "contradiction": 5.7653,
            "irrelevancy": 33.97279,
            "logical_agreement": 60.26191,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.84042,
            "nubia_score": 0.7275
        },
        "meteor": 0.3750673081404557
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.77,
        "total_length": 232,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 11.2644968324772,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.6206896551724138,
        "vocab_size-1": 144,
        "unique-1": 118,
        "entropy-1": 6.60272243333187,
        "distinct-2": 0.95,
        "vocab_size-2": 209,
        "unique-2": 201,
        "entropy-2": 7.671065793040598,
        "cond_entropy-2": 0.9412685994037048,
        "distinct-3": 0.9951923076923077,
        "vocab_size-3": 207,
        "unique-3": 206,
        "entropy-3": 7.690824333525683,
        "cond_entropy-3": 0.0261216512822518,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 9.29605651158956,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.7070707070707071,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.812377456290713,
        "distinct-2-nopunct": 0.978494623655914,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.496148058419875,
        "cond_entropy-2-nopunct": 0.710097803042351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 174,
        "unique-3-nopunct": 174,
        "entropy-3-nopunct": 7.4429434958487075,
        "cond_entropy-3-nopunct": -0.05023830376505027,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.74216,
        "local_recall": {
            "1": 0.23214285714285715,
            "2": 0.525,
            "3": 0.8153846153846154
        },
        "rouge1": {
            "precision": 0.75571,
            "recall": 0.73554,
            "fmeasure": 0.73131
        },
        "rouge2": {
            "precision": 0.50563,
            "recall": 0.49377,
            "fmeasure": 0.48902
        },
        "rougeL": {
            "precision": 0.62531,
            "recall": 0.62017,
            "fmeasure": 0.61167
        },
        "rougeLsum": {
            "precision": 0.62531,
            "recall": 0.62017,
            "fmeasure": 0.61167
        },
        "nist": 5.961818254219055,
        "bleurt": 0.25625,
        "bertscore": {
            "precision": 0.92587,
            "recall": 0.92928,
            "f1": 0.9269
        },
        "nubia": {
            "semantic_relation": 4.18286,
            "contradiction": 4.1921,
            "irrelevancy": 42.42681,
            "logical_agreement": 53.38109,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.30905,
            "nubia_score": 0.77698
        },
        "meteor": 0.3909522434621959
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.78,
        "total_length": 409,
        "mean_pred_length": 17.782608695652176,
        "std_pred_length": 7.27686340539617,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 43,
        "distinct-1": 0.6063569682151589,
        "vocab_size-1": 248,
        "unique-1": 211,
        "entropy-1": 7.197007829704163,
        "distinct-2": 0.9481865284974094,
        "vocab_size-2": 366,
        "unique-2": 351,
        "entropy-2": 8.472600398650206,
        "cond_entropy-2": 1.0941778194257668,
        "distinct-3": 0.9944903581267218,
        "vocab_size-3": 361,
        "unique-3": 359,
        "entropy-3": 8.492806454249216,
        "cond_entropy-3": 0.01678099413397994,
        "total_length-nopunct": 351,
        "mean_pred_length-nopunct": 15.26086956521739,
        "std_pred_length-nopunct": 5.534220744048464,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6894586894586895,
        "vocab_size-1-nopunct": 242,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.368745490308941,
        "distinct-2-nopunct": 0.9603658536585366,
        "vocab_size-2-nopunct": 315,
        "unique-2-nopunct": 306,
        "entropy-2-nopunct": 8.26148561740978,
        "cond_entropy-2-nopunct": 0.9475918947529792,
        "distinct-3-nopunct": 0.9967213114754099,
        "vocab_size-3-nopunct": 304,
        "unique-3-nopunct": 303,
        "entropy-3-nopunct": 8.246108055401024,
        "cond_entropy-3-nopunct": -0.00813321149791062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.87076,
        "local_recall": {
            "1": 0.2976190476190476,
            "2": 0.39759036144578314,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.7717,
            "recall": 0.74643,
            "fmeasure": 0.74322
        },
        "rouge2": {
            "precision": 0.5659,
            "recall": 0.55424,
            "fmeasure": 0.54846
        },
        "rougeL": {
            "precision": 0.68278,
            "recall": 0.67299,
            "fmeasure": 0.6642
        },
        "rougeLsum": {
            "precision": 0.68278,
            "recall": 0.67299,
            "fmeasure": 0.6642
        },
        "nist": 6.536774022367034,
        "bleurt": 0.21223,
        "bertscore": {
            "precision": 0.92655,
            "recall": 0.92506,
            "f1": 0.92428
        },
        "nubia": {
            "semantic_relation": 4.1596,
            "contradiction": 9.40889,
            "irrelevancy": 34.38062,
            "logical_agreement": 56.21048,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.38886,
            "nubia_score": 0.71775
        },
        "meteor": 0.39806683360990014
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.745,
        "total_length": 329,
        "mean_pred_length": 17.31578947368421,
        "std_pred_length": 6.751628509820874,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5805471124620061,
        "vocab_size-1": 191,
        "unique-1": 154,
        "entropy-1": 6.897383294523389,
        "distinct-2": 0.9225806451612903,
        "vocab_size-2": 286,
        "unique-2": 271,
        "entropy-2": 8.086997984361012,
        "cond_entropy-2": 1.0190212264492746,
        "distinct-3": 0.9862542955326461,
        "vocab_size-3": 287,
        "unique-3": 283,
        "entropy-3": 8.157383933973575,
        "cond_entropy-3": 0.07586155785085236,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 15.210526315789474,
        "std_pred_length-nopunct": 6.194895584425863,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.643598615916955,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.0222274994374265,
        "distinct-2-nopunct": 0.9222222222222223,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.884688548973334,
        "cond_entropy-2-nopunct": 0.9168034450459029,
        "distinct-3-nopunct": 0.9840637450199203,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 243,
        "entropy-3-nopunct": 7.939671043990606,
        "cond_entropy-3-nopunct": 0.06554191299925244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.92131,
        "local_recall": {
            "1": 0.16883116883116883,
            "2": 0.4117647058823529,
            "3": 0.6982758620689655
        },
        "rouge1": {
            "precision": 0.74145,
            "recall": 0.68669,
            "fmeasure": 0.70051
        },
        "rouge2": {
            "precision": 0.53474,
            "recall": 0.50832,
            "fmeasure": 0.51371
        },
        "rougeL": {
            "precision": 0.64605,
            "recall": 0.60989,
            "fmeasure": 0.6171
        },
        "rougeLsum": {
            "precision": 0.64605,
            "recall": 0.60989,
            "fmeasure": 0.6171
        },
        "nist": 6.00566361745881,
        "bleurt": 0.22655,
        "bertscore": {
            "precision": 0.92271,
            "recall": 0.90735,
            "f1": 0.91293
        },
        "nubia": {
            "semantic_relation": 4.13971,
            "contradiction": 4.87952,
            "irrelevancy": 38.49029,
            "logical_agreement": 56.63019,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.50787,
            "nubia_score": 0.70315
        },
        "meteor": 0.3811713390362773
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.73143,
        "msttr-100_nopunct": 0.76667,
        "total_length": 730,
        "mean_pred_length": 17.38095238095238,
        "std_pred_length": 6.141011165971739,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5232876712328767,
        "vocab_size-1": 382,
        "unique-1": 297,
        "entropy-1": 7.593863189137453,
        "distinct-2": 0.8968023255813954,
        "vocab_size-2": 617,
        "unique-2": 567,
        "entropy-2": 9.165897481523126,
        "cond_entropy-2": 1.3599325856382842,
        "distinct-3": 0.9814241486068112,
        "vocab_size-3": 634,
        "unique-3": 622,
        "entropy-3": 9.298238651907443,
        "cond_entropy-3": 0.13688517266536948,
        "total_length-nopunct": 649,
        "mean_pred_length-nopunct": 15.452380952380953,
        "std_pred_length-nopunct": 5.399304985927889,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5793528505392912,
        "vocab_size-1-nopunct": 376,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.796439889132697,
        "distinct-2-nopunct": 0.9011532125205931,
        "vocab_size-2-nopunct": 547,
        "unique-2-nopunct": 506,
        "entropy-2-nopunct": 8.989172296135779,
        "cond_entropy-2-nopunct": 1.2678177623729658,
        "distinct-3-nopunct": 0.984070796460177,
        "vocab_size-3-nopunct": 556,
        "unique-3-nopunct": 547,
        "entropy-3-nopunct": 9.11024865022277,
        "cond_entropy-3-nopunct": 0.1284799199708701,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.83029,
        "local_recall": {
            "1": 0.3103448275862069,
            "2": 0.4716981132075472,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.74241,
            "recall": 0.7766,
            "fmeasure": 0.7496
        },
        "rouge2": {
            "precision": 0.51006,
            "recall": 0.5303,
            "fmeasure": 0.51275
        },
        "rougeL": {
            "precision": 0.62146,
            "recall": 0.65557,
            "fmeasure": 0.62859
        },
        "rougeLsum": {
            "precision": 0.62146,
            "recall": 0.65557,
            "fmeasure": 0.62859
        },
        "nist": 6.575345597242211,
        "bleurt": 0.26463,
        "bertscore": {
            "precision": 0.9287,
            "recall": 0.93301,
            "f1": 0.92922
        },
        "nubia": {
            "semantic_relation": 4.27901,
            "contradiction": 6.36478,
            "irrelevancy": 32.53806,
            "logical_agreement": 61.09716,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.49733,
            "nubia_score": 0.75276
        },
        "meteor": 0.39959110361041755
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 18.4,
        "std_pred_length": 8.380930735902785,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.7717391304347826,
        "vocab_size-1": 71,
        "unique-1": 64,
        "entropy-1": 5.90694178265267,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 84,
        "unique-2": 82,
        "entropy-2": 6.365301110766384,
        "cond_entropy-2": 0.36035312572964917,
        "distinct-3": 1.0,
        "vocab_size-3": 82,
        "unique-3": 82,
        "entropy-3": 6.357552004618087,
        "cond_entropy-3": -0.0030148143749926357,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 7.83836717690617,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8313253012048193,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.9278175581088135,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.198801097039648,
        "cond_entropy-2-nopunct": 0.29965160772814753,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.0030449544731425597,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.97877,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.74396,
            "recall": 0.69593,
            "fmeasure": 0.71398
        },
        "rouge2": {
            "precision": 0.46909,
            "recall": 0.44393,
            "fmeasure": 0.45224
        },
        "rougeL": {
            "precision": 0.54879,
            "recall": 0.51483,
            "fmeasure": 0.52718
        },
        "rougeLsum": {
            "precision": 0.54879,
            "recall": 0.51483,
            "fmeasure": 0.52718
        },
        "nist": 4.768254380798949,
        "bleurt": 0.33022,
        "bertscore": {
            "precision": 0.92377,
            "recall": 0.91106,
            "f1": 0.91715
        },
        "nubia": {
            "semantic_relation": 4.5243,
            "contradiction": 0.4264,
            "irrelevancy": 20.88856,
            "logical_agreement": 78.68503,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.64269,
            "nubia_score": 0.83653
        },
        "meteor": 0.3831566447286331
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 4.5,
        "median_pred_length": 22.5,
        "min_pred_length": 18,
        "max_pred_length": 27,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 26,
        "entropy-1": 4.819305040629888,
        "distinct-2": 0.9069767441860465,
        "vocab_size-2": 39,
        "unique-2": 35,
        "entropy-2": 5.240218243074191,
        "cond_entropy-2": 0.37847532128051864,
        "distinct-3": 0.926829268292683,
        "vocab_size-3": 38,
        "unique-3": 35,
        "entropy-3": 5.211210541203447,
        "cond_entropy-3": -0.01993226227913626,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7560975609756098,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.735362370366206,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.080274013734042,
        "cond_entropy-2-nopunct": 0.3768188040987018,
        "distinct-3-nopunct": 0.918918918918919,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.047291203466791,
        "cond_entropy-3-nopunct": -0.02189479917924466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.90317,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8148148148148148
        },
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.75195,
            "fmeasure": 0.73933
        },
        "rouge2": {
            "precision": 0.49653,
            "recall": 0.51525,
            "fmeasure": 0.49236
        },
        "rougeL": {
            "precision": 0.57804,
            "recall": 0.60709,
            "fmeasure": 0.57822
        },
        "rougeLsum": {
            "precision": 0.57804,
            "recall": 0.60709,
            "fmeasure": 0.57822
        },
        "nist": 3.999313639153687,
        "bleurt": 0.20935,
        "bertscore": {
            "precision": 0.91681,
            "recall": 0.94542,
            "f1": 0.92979
        },
        "nubia": {
            "semantic_relation": 4.07058,
            "contradiction": 0.15645,
            "irrelevancy": 43.20835,
            "logical_agreement": 56.6352,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.25553,
            "nubia_score": 0.78158
        },
        "meteor": 0.39897160786502756
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 143,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 5.258737584977436,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6713286713286714,
        "vocab_size-1": 96,
        "unique-1": 80,
        "entropy-1": 6.161946690594915,
        "distinct-2": 0.9701492537313433,
        "vocab_size-2": 130,
        "unique-2": 127,
        "entropy-2": 7.000754209098351,
        "cond_entropy-2": 0.6827177346352632,
        "distinct-3": 1.0,
        "vocab_size-3": 125,
        "unique-3": 125,
        "entropy-3": 6.965784284662096,
        "cond_entropy-3": -0.03026580577837782,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 14.11111111111111,
        "std_pred_length-nopunct": 5.258737584977436,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7244094488188977,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.1895985178322785,
        "distinct-2-nopunct": 0.9661016949152542,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.808449087479091,
        "cond_entropy-2-nopunct": 0.6713232435490016,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.7681843247769145,
        "cond_entropy-3-nopunct": -0.0341386557577274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.80019,
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5,
            "3": 0.7910447761194029
        },
        "rouge1": {
            "precision": 0.70754,
            "recall": 0.72985,
            "fmeasure": 0.70612
        },
        "rouge2": {
            "precision": 0.44064,
            "recall": 0.46184,
            "fmeasure": 0.44158
        },
        "rougeL": {
            "precision": 0.57101,
            "recall": 0.60155,
            "fmeasure": 0.57369
        },
        "rougeLsum": {
            "precision": 0.57101,
            "recall": 0.60155,
            "fmeasure": 0.57369
        },
        "nist": 4.777401137023583,
        "bleurt": 0.30365,
        "bertscore": {
            "precision": 0.91144,
            "recall": 0.93009,
            "f1": 0.91902
        },
        "nubia": {
            "semantic_relation": 4.31374,
            "contradiction": 0.4447,
            "irrelevancy": 32.01281,
            "logical_agreement": 67.54248,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.98977,
            "nubia_score": 0.75093
        },
        "meteor": 0.3524285939777334
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.7625,
        "total_length": 476,
        "mean_pred_length": 18.307692307692307,
        "std_pred_length": 6.2865499329259755,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5840336134453782,
        "vocab_size-1": 278,
        "unique-1": 227,
        "entropy-1": 7.325361642865045,
        "distinct-2": 0.9244444444444444,
        "vocab_size-2": 416,
        "unique-2": 394,
        "entropy-2": 8.63438328909885,
        "cond_entropy-2": 1.1281203717001493,
        "distinct-3": 0.9929245283018868,
        "vocab_size-3": 421,
        "unique-3": 418,
        "entropy-3": 8.713769511167026,
        "cond_entropy-3": 0.08095307455654044,
        "total_length-nopunct": 419,
        "mean_pred_length-nopunct": 16.115384615384617,
        "std_pred_length-nopunct": 5.65227607712778,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.649164677804296,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 226,
        "entropy-1-nopunct": 7.452122319363089,
        "distinct-2-nopunct": 0.9363867684478372,
        "vocab_size-2-nopunct": 368,
        "unique-2-nopunct": 354,
        "entropy-2-nopunct": 8.460690417141507,
        "cond_entropy-2-nopunct": 1.0619291651335028,
        "distinct-3-nopunct": 0.9918256130790191,
        "vocab_size-3-nopunct": 364,
        "unique-3-nopunct": 361,
        "entropy-3-nopunct": 8.50328747900118,
        "cond_entropy-3-nopunct": 0.05104412511059291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.79687,
        "local_recall": {
            "1": 0.24705882352941178,
            "2": 0.5746268656716418,
            "3": 0.7322834645669292
        },
        "rouge1": {
            "precision": 0.73378,
            "recall": 0.71106,
            "fmeasure": 0.71001
        },
        "rouge2": {
            "precision": 0.50405,
            "recall": 0.48572,
            "fmeasure": 0.48602
        },
        "rougeL": {
            "precision": 0.61012,
            "recall": 0.60407,
            "fmeasure": 0.59694
        },
        "rougeLsum": {
            "precision": 0.61012,
            "recall": 0.60407,
            "fmeasure": 0.59694
        },
        "nist": 6.400314884136532,
        "bleurt": 0.15589,
        "bertscore": {
            "precision": 0.91544,
            "recall": 0.9194,
            "f1": 0.91543
        },
        "nubia": {
            "semantic_relation": 4.11214,
            "contradiction": 11.72718,
            "irrelevancy": 40.62926,
            "logical_agreement": 47.64357,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.70675,
            "nubia_score": 0.67985
        },
        "meteor": 0.38646679142267804
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 17.2,
        "std_pred_length": 5.491812087098393,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6046511627906976,
        "vocab_size-1": 52,
        "unique-1": 35,
        "entropy-1": 5.4280267147955366,
        "distinct-2": 0.9135802469135802,
        "vocab_size-2": 74,
        "unique-2": 68,
        "entropy-2": 6.157690897919633,
        "cond_entropy-2": 0.6479549204709716,
        "distinct-3": 0.9868421052631579,
        "vocab_size-3": 75,
        "unique-3": 74,
        "entropy-3": 6.221611723969907,
        "cond_entropy-3": 0.07590497769269039,
        "total_length-nopunct": 79,
        "mean_pred_length-nopunct": 15.8,
        "std_pred_length-nopunct": 5.344155686354955,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6329113924050633,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.389365166436249,
        "distinct-2-nopunct": 0.9054054054054054,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.010062993978097,
        "cond_entropy-2-nopunct": 0.626132326288627,
        "distinct-3-nopunct": 0.9855072463768116,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.079538949531787,
        "cond_entropy-3-nopunct": 0.04646130856142681,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.8848,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.37037037037037035,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.68255,
            "recall": 0.78306,
            "fmeasure": 0.71868
        },
        "rouge2": {
            "precision": 0.46312,
            "recall": 0.54041,
            "fmeasure": 0.49104
        },
        "rougeL": {
            "precision": 0.52537,
            "recall": 0.5941,
            "fmeasure": 0.55012
        },
        "rougeLsum": {
            "precision": 0.52537,
            "recall": 0.5941,
            "fmeasure": 0.55012
        },
        "nist": 3.390041117604263,
        "bleurt": 0.06565,
        "bertscore": {
            "precision": 0.89236,
            "recall": 0.92675,
            "f1": 0.9089
        },
        "nubia": {
            "semantic_relation": 4.31859,
            "contradiction": 6.12675,
            "irrelevancy": 17.24062,
            "logical_agreement": 76.63263,
            "grammar_ref": 3.91039,
            "grammar_hyp": 4.07495,
            "nubia_score": 0.74624
        },
        "meteor": 0.3465799747355802
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.74,
        "total_length": 170,
        "mean_pred_length": 14.166666666666666,
        "std_pred_length": 5.683797634993311,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5941176470588235,
        "vocab_size-1": 101,
        "unique-1": 78,
        "entropy-1": 6.103743650058139,
        "distinct-2": 0.9050632911392406,
        "vocab_size-2": 143,
        "unique-2": 131,
        "entropy-2": 7.091061504668023,
        "cond_entropy-2": 0.8054348850861919,
        "distinct-3": 0.9726027397260274,
        "vocab_size-3": 142,
        "unique-3": 138,
        "entropy-3": 7.135030038332074,
        "cond_entropy-3": 0.047753676966180186,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 12.083333333333334,
        "std_pred_length-nopunct": 4.97423919364113,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6689655172413793,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.174017212099854,
        "distinct-2-nopunct": 0.924812030075188,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.877766341708438,
        "cond_entropy-2-nopunct": 0.7600328892646819,
        "distinct-3-nopunct": 0.9917355371900827,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 119,
        "entropy-3-nopunct": 6.9023343116547675,
        "cond_entropy-3-nopunct": 0.02564394619023789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.86338,
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.4523809523809524,
            "3": 0.6728971962616822
        },
        "rouge1": {
            "precision": 0.78503,
            "recall": 0.69439,
            "fmeasure": 0.72671
        },
        "rouge2": {
            "precision": 0.50396,
            "recall": 0.43282,
            "fmeasure": 0.45673
        },
        "rougeL": {
            "precision": 0.65008,
            "recall": 0.58192,
            "fmeasure": 0.60548
        },
        "rougeLsum": {
            "precision": 0.65008,
            "recall": 0.58192,
            "fmeasure": 0.60548
        },
        "nist": 5.0978550349805705,
        "bleurt": 0.08217,
        "bertscore": {
            "precision": 0.9039,
            "recall": 0.90144,
            "f1": 0.89999
        },
        "nubia": {
            "semantic_relation": 4.36413,
            "contradiction": 4.13569,
            "irrelevancy": 14.19565,
            "logical_agreement": 81.66866,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.20855,
            "nubia_score": 0.76454
        },
        "meteor": 0.3554176410300276
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.77333,
        "total_length": 448,
        "mean_pred_length": 17.92,
        "std_pred_length": 6.6327671450157215,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5825892857142857,
        "vocab_size-1": 261,
        "unique-1": 216,
        "entropy-1": 7.234352393654648,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 405,
        "unique-2": 397,
        "entropy-2": 8.609216217344109,
        "cond_entropy-2": 1.1900271103479603,
        "distinct-3": 0.992462311557789,
        "vocab_size-3": 395,
        "unique-3": 392,
        "entropy-3": 8.62154924365925,
        "cond_entropy-3": 0.019575340120098473,
        "total_length-nopunct": 395,
        "mean_pred_length-nopunct": 15.8,
        "std_pred_length-nopunct": 5.4845236803208355,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6455696202531646,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.350037093396883,
        "distinct-2-nopunct": 0.9540540540540541,
        "vocab_size-2-nopunct": 353,
        "unique-2-nopunct": 346,
        "entropy-2-nopunct": 8.404973622859128,
        "cond_entropy-2-nopunct": 1.1357251611965613,
        "distinct-3-nopunct": 0.9942028985507246,
        "vocab_size-3-nopunct": 343,
        "unique-3-nopunct": 341,
        "entropy-3-nopunct": 8.41885834876693,
        "cond_entropy-3-nopunct": 0.0201461634192686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.82826,
        "local_recall": {
            "1": 0.25,
            "2": 0.484375,
            "3": 0.8207885304659498
        },
        "rouge1": {
            "precision": 0.76729,
            "recall": 0.78931,
            "fmeasure": 0.76856
        },
        "rouge2": {
            "precision": 0.55018,
            "recall": 0.56512,
            "fmeasure": 0.55114
        },
        "rougeL": {
            "precision": 0.6693,
            "recall": 0.6944,
            "fmeasure": 0.67458
        },
        "rougeLsum": {
            "precision": 0.6693,
            "recall": 0.6944,
            "fmeasure": 0.67458
        },
        "nist": 6.795841581961892,
        "bleurt": 0.36794,
        "bertscore": {
            "precision": 0.94202,
            "recall": 0.94303,
            "f1": 0.94033
        },
        "nubia": {
            "semantic_relation": 4.32286,
            "contradiction": 6.74047,
            "irrelevancy": 31.12213,
            "logical_agreement": 62.13741,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.63721,
            "nubia_score": 0.76754
        },
        "meteor": 0.4300447368010358
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.67667,
        "msttr-100_nopunct": 0.72333,
        "total_length": 367,
        "mean_pred_length": 19.31578947368421,
        "std_pred_length": 6.585891072500104,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.547683923705722,
        "vocab_size-1": 201,
        "unique-1": 156,
        "entropy-1": 6.899349194291469,
        "distinct-2": 0.882183908045977,
        "vocab_size-2": 307,
        "unique-2": 275,
        "entropy-2": 8.179223847829173,
        "cond_entropy-2": 1.1323712636227508,
        "distinct-3": 0.9452887537993921,
        "vocab_size-3": 311,
        "unique-3": 293,
        "entropy-3": 8.252521281334042,
        "cond_entropy-3": 0.06799587061798401,
        "total_length-nopunct": 320,
        "mean_pred_length-nopunct": 16.842105263157894,
        "std_pred_length-nopunct": 5.304051657829104,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6125,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 6.98759213350655,
        "distinct-2-nopunct": 0.893687707641196,
        "vocab_size-2-nopunct": 269,
        "unique-2-nopunct": 245,
        "entropy-2-nopunct": 7.991029809621282,
        "cond_entropy-2-nopunct": 1.0477977534112064,
        "distinct-3-nopunct": 0.9468085106382979,
        "vocab_size-3-nopunct": 267,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 8.033168373675423,
        "cond_entropy-3-nopunct": 0.043696303324238975,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.5994,
        "local_recall": {
            "1": 0.26229508196721313,
            "2": 0.4745762711864407,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.71799,
            "recall": 0.74918,
            "fmeasure": 0.72615
        },
        "rouge2": {
            "precision": 0.46933,
            "recall": 0.48949,
            "fmeasure": 0.47361
        },
        "rougeL": {
            "precision": 0.64847,
            "recall": 0.67609,
            "fmeasure": 0.65518
        },
        "rougeLsum": {
            "precision": 0.64847,
            "recall": 0.67609,
            "fmeasure": 0.65518
        },
        "nist": 5.900630669108097,
        "bleurt": 0.17046,
        "bertscore": {
            "precision": 0.91437,
            "recall": 0.92084,
            "f1": 0.91567
        },
        "nubia": {
            "semantic_relation": 4.06295,
            "contradiction": 1.69883,
            "irrelevancy": 49.27718,
            "logical_agreement": 49.024,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.2537,
            "nubia_score": 0.73801
        },
        "meteor": 0.3870604716685113
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096009,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.61476,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.81871,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.46187,
            "fmeasure": 0.42864
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "nist": 2.0191720233723887,
        "bleurt": 0.34712,
        "bertscore": {
            "precision": 0.87466,
            "recall": 0.89871,
            "f1": 0.88624
        },
        "nubia": {
            "semantic_relation": 4.90495,
            "contradiction": 0.11756,
            "irrelevancy": 2.39,
            "logical_agreement": 97.49245,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.73909,
            "nubia_score": 0.9185
        },
        "meteor": 0.32614378270778793
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.81,
        "total_length": 200,
        "mean_pred_length": 18.181818181818183,
        "std_pred_length": 7.929440904493282,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.67,
        "vocab_size-1": 134,
        "unique-1": 116,
        "entropy-1": 6.502074759578576,
        "distinct-2": 0.9417989417989417,
        "vocab_size-2": 178,
        "unique-2": 173,
        "entropy-2": 7.408699831582702,
        "cond_entropy-2": 0.7644293483227779,
        "distinct-3": 1.0,
        "vocab_size-3": 178,
        "unique-3": 178,
        "entropy-3": 7.47573343096637,
        "cond_entropy-3": 0.07652218656922322,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 15.727272727272727,
        "std_pred_length-nopunct": 7.758759379400679,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.7514450867052023,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.606402862171015,
        "distinct-2-nopunct": 0.9320987654320988,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.16071697813983,
        "cond_entropy-2-nopunct": 0.6105516407844066,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.238404739325059,
        "cond_entropy-3-nopunct": 0.09073718682889004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.52505,
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.6,
            "3": 0.6974789915966386
        },
        "rouge1": {
            "precision": 0.69388,
            "recall": 0.67034,
            "fmeasure": 0.66729
        },
        "rouge2": {
            "precision": 0.43829,
            "recall": 0.41535,
            "fmeasure": 0.41373
        },
        "rougeL": {
            "precision": 0.5437,
            "recall": 0.50809,
            "fmeasure": 0.51285
        },
        "rougeLsum": {
            "precision": 0.5437,
            "recall": 0.50809,
            "fmeasure": 0.51285
        },
        "nist": 4.9321330095487275,
        "bleurt": -0.08318,
        "bertscore": {
            "precision": 0.90175,
            "recall": 0.89038,
            "f1": 0.89361
        },
        "nubia": {
            "semantic_relation": 3.60363,
            "contradiction": 16.19025,
            "irrelevancy": 33.84034,
            "logical_agreement": 49.96941,
            "grammar_ref": 4.70623,
            "grammar_hyp": 4.91009,
            "nubia_score": 0.58962
        },
        "meteor": 0.32572141815727845
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.22589,
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.21026,
            "fmeasure": 0.23854
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.33333,
            "fmeasure": 0.35238
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.33333,
            "fmeasure": 0.35238
        },
        "nist": 2.885795781571516,
        "bleurt": 0.22723,
        "bertscore": {
            "precision": 0.8974,
            "recall": 0.89369,
            "f1": 0.8879
        },
        "nubia": {
            "semantic_relation": 4.24379,
            "contradiction": 12.84788,
            "irrelevancy": 56.51851,
            "logical_agreement": 30.6336,
            "grammar_ref": 5.89248,
            "grammar_hyp": 4.78784,
            "nubia_score": 0.71891
        },
        "meteor": 0.21904349398114073
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.75571,
        "msttr-100_nopunct": 0.80333,
        "total_length": 712,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 5.560709271604278,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.523876404494382,
        "vocab_size-1": 373,
        "unique-1": 296,
        "entropy-1": 7.593357621173807,
        "distinct-2": 0.8832335329341318,
        "vocab_size-2": 590,
        "unique-2": 541,
        "entropy-2": 9.104260743820777,
        "cond_entropy-2": 1.275288668172066,
        "distinct-3": 0.9391025641025641,
        "vocab_size-3": 586,
        "unique-3": 558,
        "entropy-3": 9.151509790942894,
        "cond_entropy-3": 0.04530311945620406,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 5.267238522498536,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5828025477707006,
        "vocab_size-1-nopunct": 366,
        "unique-1-nopunct": 293,
        "entropy-1-nopunct": 7.792781359570794,
        "distinct-2-nopunct": 0.8852739726027398,
        "vocab_size-2-nopunct": 517,
        "unique-2-nopunct": 477,
        "entropy-2-nopunct": 8.910443539194883,
        "cond_entropy-2-nopunct": 1.1954347053645547,
        "distinct-3-nopunct": 0.9425925925925925,
        "vocab_size-3-nopunct": 509,
        "unique-3-nopunct": 487,
        "entropy-3-nopunct": 8.94941932386656,
        "cond_entropy-3-nopunct": 0.04737926127162218,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.18672,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.5897435897435898,
            "3": 0.7657004830917874
        },
        "rouge1": {
            "precision": 0.76552,
            "recall": 0.75285,
            "fmeasure": 0.74691
        },
        "rouge2": {
            "precision": 0.5318,
            "recall": 0.53328,
            "fmeasure": 0.52296
        },
        "rougeL": {
            "precision": 0.70008,
            "recall": 0.68707,
            "fmeasure": 0.68164
        },
        "rougeLsum": {
            "precision": 0.70008,
            "recall": 0.68707,
            "fmeasure": 0.68164
        },
        "nist": 6.6930104219409,
        "bleurt": 0.28576,
        "bertscore": {
            "precision": 0.92689,
            "recall": 0.93251,
            "f1": 0.92801
        },
        "nubia": {
            "semantic_relation": 4.3017,
            "contradiction": 7.23186,
            "irrelevancy": 34.04505,
            "logical_agreement": 58.72309,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.53881,
            "nubia_score": 0.74841
        },
        "meteor": 0.4068511675933094
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.458591205867174,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2532445236699313,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.323856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.274439644279765,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.80698,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.62069,
            "recall": 0.69231,
            "fmeasure": 0.65455
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.4,
            "fmeasure": 0.37736
        },
        "rougeL": {
            "precision": 0.34483,
            "recall": 0.38462,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.34483,
            "recall": 0.38462,
            "fmeasure": 0.36364
        },
        "nist": 2.786761584781111,
        "bleurt": -0.18108,
        "bertscore": {
            "precision": 0.86967,
            "recall": 0.91075,
            "f1": 0.88974
        },
        "nubia": {
            "semantic_relation": 3.03967,
            "contradiction": 0.53746,
            "irrelevancy": 98.5064,
            "logical_agreement": 0.95615,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.92525,
            "nubia_score": 0.39433
        },
        "meteor": 0.34765580509142796
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "total_length": 132,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.7196969696969697,
        "vocab_size-1": 95,
        "unique-1": 79,
        "entropy-1": 6.253457543647023,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 120,
        "unique-2": 116,
        "entropy-2": 6.889680181354603,
        "cond_entropy-2": 0.49370241678574517,
        "distinct-3": 1.0,
        "vocab_size-3": 116,
        "unique-3": 116,
        "entropy-3": 6.857980995127556,
        "cond_entropy-3": -0.0272497980179236,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 5.2855936279664935,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7711864406779662,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.269052981616851,
        "distinct-2-nopunct": 0.9636363636363636,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 102,
        "entropy-2-nopunct": 6.708632440797395,
        "cond_entropy-2-nopunct": 0.4697954413736077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.03050299900414439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.43162,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.4583333333333333,
            "3": 0.8157894736842105
        },
        "rouge1": {
            "precision": 0.70312,
            "recall": 0.74193,
            "fmeasure": 0.71269
        },
        "rouge2": {
            "precision": 0.44833,
            "recall": 0.48654,
            "fmeasure": 0.46033
        },
        "rougeL": {
            "precision": 0.60636,
            "recall": 0.64753,
            "fmeasure": 0.61706
        },
        "rougeLsum": {
            "precision": 0.60636,
            "recall": 0.64753,
            "fmeasure": 0.61706
        },
        "nist": 5.074734752095266,
        "bleurt": 0.19639,
        "bertscore": {
            "precision": 0.90271,
            "recall": 0.91353,
            "f1": 0.90524
        },
        "nubia": {
            "semantic_relation": 3.86116,
            "contradiction": 12.327,
            "irrelevancy": 58.92669,
            "logical_agreement": 28.74632,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.36352,
            "nubia_score": 0.67646
        },
        "meteor": 0.3852570984172286
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 19.0,
        "min_pred_length": 17,
        "max_pred_length": 20,
        "distinct-1": 0.7321428571428571,
        "vocab_size-1": 41,
        "unique-1": 34,
        "entropy-1": 5.094566583470221,
        "distinct-2": 0.9622641509433962,
        "vocab_size-2": 51,
        "unique-2": 49,
        "entropy-2": 5.652448756449988,
        "cond_entropy-2": 0.5085138241797491,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.0040642647884745345,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.78,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.0357287506433925,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.469482468698917,
        "cond_entropy-2-nopunct": 0.4725703631064594,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.00424814213124944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.06238,
        "local_recall": {
            "1": 0.7,
            "2": 0.18181818181818182,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.62109,
            "recall": 0.60626,
            "fmeasure": 0.60071
        },
        "rouge2": {
            "precision": 0.43493,
            "recall": 0.49794,
            "fmeasure": 0.45273
        },
        "rougeL": {
            "precision": 0.49932,
            "recall": 0.5531,
            "fmeasure": 0.5108
        },
        "rougeLsum": {
            "precision": 0.49932,
            "recall": 0.5531,
            "fmeasure": 0.5108
        },
        "nist": 4.229135585515368,
        "bleurt": -0.03994,
        "bertscore": {
            "precision": 0.91029,
            "recall": 0.91173,
            "f1": 0.89848
        },
        "nubia": {
            "semantic_relation": 4.14577,
            "contradiction": 0.18792,
            "irrelevancy": 52.81647,
            "logical_agreement": 46.99562,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.87133,
            "nubia_score": 0.71657
        },
        "meteor": 0.31296168000475344
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 13.571428571428571,
        "std_pred_length": 2.8713930346059686,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 70,
        "unique-1": 59,
        "entropy-1": 5.8670040300870845,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 86,
        "unique-2": 84,
        "entropy-2": 6.41397707318276,
        "cond_entropy-2": 0.37956936801957397,
        "distinct-3": 0.9876543209876543,
        "vocab_size-3": 80,
        "unique-3": 79,
        "entropy-3": 6.315158644859923,
        "cond_entropy-3": -0.09489025772798124,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 11.857142857142858,
        "std_pred_length-nopunct": 2.587252896610691,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8072289156626506,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.903721172566644,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.36130144365934147,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.108524456778164,
        "cond_entropy-3-nopunct": -0.11041754941903972,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.90529,
        "local_recall": {
            "1": 0.20512820512820512,
            "2": 0.2222222222222222,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.72121,
            "recall": 0.70242,
            "fmeasure": 0.70771
        },
        "rouge2": {
            "precision": 0.5123,
            "recall": 0.49921,
            "fmeasure": 0.50218
        },
        "rougeL": {
            "precision": 0.67523,
            "recall": 0.65123,
            "fmeasure": 0.65942
        },
        "rougeLsum": {
            "precision": 0.67523,
            "recall": 0.65123,
            "fmeasure": 0.65942
        },
        "nist": 5.045200880815989,
        "bleurt": 0.29393,
        "bertscore": {
            "precision": 0.93605,
            "recall": 0.94376,
            "f1": 0.93966
        },
        "nubia": {
            "semantic_relation": 4.29735,
            "contradiction": 4.56368,
            "irrelevancy": 24.03798,
            "logical_agreement": 71.39834,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.39553,
            "nubia_score": 0.78431
        },
        "meteor": 0.4031840086699547
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77545,
        "total_length": 1359,
        "mean_pred_length": 16.9875,
        "std_pred_length": 6.936306203592803,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.49816041206769685,
        "vocab_size-1": 677,
        "unique-1": 556,
        "entropy-1": 8.056427295850327,
        "distinct-2": 0.9077404222048475,
        "vocab_size-2": 1161,
        "unique-2": 1107,
        "entropy-2": 10.046755662725252,
        "cond_entropy-2": 1.7408867682530864,
        "distinct-3": 0.9849874895746455,
        "vocab_size-3": 1181,
        "unique-3": 1168,
        "entropy-3": 10.194034073100276,
        "cond_entropy-3": 0.1422105128709496,
        "total_length-nopunct": 1169,
        "mean_pred_length-nopunct": 14.6125,
        "std_pred_length-nopunct": 5.97807190906901,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 668,
        "unique-1-nopunct": 552,
        "entropy-1-nopunct": 8.360307296975684,
        "distinct-2-nopunct": 0.9247015610651974,
        "vocab_size-2-nopunct": 1007,
        "unique-2-nopunct": 972,
        "entropy-2-nopunct": 9.853864111140293,
        "cond_entropy-2-nopunct": 1.5936344947111707,
        "distinct-3-nopunct": 0.9910802775024777,
        "vocab_size-3-nopunct": 1000,
        "unique-3-nopunct": 993,
        "entropy-3-nopunct": 9.959374705881187,
        "cond_entropy-3-nopunct": 0.12314580802751303,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.80145,
        "local_recall": {
            "1": 0.2966101694915254,
            "2": 0.4084507042253521,
            "3": 0.7347391786903441
        },
        "rouge1": {
            "precision": 0.73287,
            "recall": 0.69589,
            "fmeasure": 0.70312
        },
        "rouge2": {
            "precision": 0.48606,
            "recall": 0.45293,
            "fmeasure": 0.46064
        },
        "rougeL": {
            "precision": 0.62868,
            "recall": 0.59828,
            "fmeasure": 0.60281
        },
        "rougeLsum": {
            "precision": 0.62868,
            "recall": 0.59828,
            "fmeasure": 0.60281
        },
        "nist": 7.291947835078992,
        "bleurt": 0.2404,
        "bertscore": {
            "precision": 0.92351,
            "recall": 0.91838,
            "f1": 0.91901
        },
        "nubia": {
            "semantic_relation": 4.20188,
            "contradiction": 6.3134,
            "irrelevancy": 32.49613,
            "logical_agreement": 61.19046,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.74411,
            "nubia_score": 0.72715
        },
        "meteor": 0.38009736454887294
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.82,
        "total_length": 144,
        "mean_pred_length": 20.571428571428573,
        "std_pred_length": 4.435478484645721,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 29,
        "distinct-1": 0.7152777777777778,
        "vocab_size-1": 103,
        "unique-1": 85,
        "entropy-1": 6.388360158081324,
        "distinct-2": 0.9854014598540146,
        "vocab_size-2": 135,
        "unique-2": 133,
        "entropy-2": 7.06883500266854,
        "cond_entropy-2": 0.5671241431531365,
        "distinct-3": 1.0,
        "vocab_size-3": 130,
        "unique-3": 130,
        "entropy-3": 7.022367813028455,
        "cond_entropy-3": -0.04489503916284148,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 18.142857142857142,
        "std_pred_length-nopunct": 3.7958086444532637,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7716535433070866,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.413601517955953,
        "distinct-2-nopunct": 0.9833333333333333,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.8735572622752015,
        "cond_entropy-2-nopunct": 0.48029424166082085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.8201789624152065,
        "cond_entropy-3-nopunct": -0.051313403104835335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.70395,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.8387096774193549,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.78969,
            "recall": 0.76703,
            "fmeasure": 0.77441
        },
        "rouge2": {
            "precision": 0.52222,
            "recall": 0.49388,
            "fmeasure": 0.50582
        },
        "rougeL": {
            "precision": 0.63033,
            "recall": 0.61198,
            "fmeasure": 0.61745
        },
        "rougeLsum": {
            "precision": 0.63033,
            "recall": 0.61198,
            "fmeasure": 0.61745
        },
        "nist": 5.593198524398138,
        "bleurt": 0.28713,
        "bertscore": {
            "precision": 0.93346,
            "recall": 0.9229,
            "f1": 0.92628
        },
        "nubia": {
            "semantic_relation": 4.51704,
            "contradiction": 8.01565,
            "irrelevancy": 11.89168,
            "logical_agreement": 80.09268,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.55017,
            "nubia_score": 0.79124
        },
        "meteor": 0.42275386020029726
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.78667,
        "total_length": 444,
        "mean_pred_length": 17.76,
        "std_pred_length": 6.494797918334334,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 259,
        "unique-1": 208,
        "entropy-1": 7.291378695335247,
        "distinct-2": 0.9355608591885441,
        "vocab_size-2": 392,
        "unique-2": 371,
        "entropy-2": 8.567908335892826,
        "cond_entropy-2": 1.0891299377676364,
        "distinct-3": 0.9898477157360406,
        "vocab_size-3": 390,
        "unique-3": 386,
        "entropy-3": 8.601747250928506,
        "cond_entropy-3": 0.0378299110893274,
        "total_length-nopunct": 381,
        "mean_pred_length-nopunct": 15.24,
        "std_pred_length-nopunct": 5.217508984180094,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6640419947506562,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 208,
        "entropy-1-nopunct": 7.47620610201418,
        "distinct-2-nopunct": 0.949438202247191,
        "vocab_size-2-nopunct": 338,
        "unique-2-nopunct": 326,
        "entropy-2-nopunct": 8.358108984390787,
        "cond_entropy-2-nopunct": 0.9403897287048611,
        "distinct-3-nopunct": 0.9939577039274925,
        "vocab_size-3-nopunct": 329,
        "unique-3-nopunct": 327,
        "entropy-3-nopunct": 8.358602814662147,
        "cond_entropy-3-nopunct": 0.006356703879875061,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.49506,
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.4057971014492754,
            "3": 0.7773851590106007
        },
        "rouge1": {
            "precision": 0.72939,
            "recall": 0.74212,
            "fmeasure": 0.72599
        },
        "rouge2": {
            "precision": 0.50971,
            "recall": 0.51997,
            "fmeasure": 0.50757
        },
        "rougeL": {
            "precision": 0.61983,
            "recall": 0.64394,
            "fmeasure": 0.62314
        },
        "rougeLsum": {
            "precision": 0.61983,
            "recall": 0.64394,
            "fmeasure": 0.62314
        },
        "nist": 6.313153281460783,
        "bleurt": 0.22468,
        "bertscore": {
            "precision": 0.92595,
            "recall": 0.93161,
            "f1": 0.92808
        },
        "nubia": {
            "semantic_relation": 4.24783,
            "contradiction": 4.25726,
            "irrelevancy": 32.38529,
            "logical_agreement": 63.35745,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.77739,
            "nubia_score": 0.7152
        },
        "meteor": 0.40311123343690103
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 3.960744879438715,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 17,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 25,
        "entropy-1": 4.880524762900186,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.29276659132077315,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.09404458493507994,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.2015621187164243,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8157894736842105,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.859641000228759,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.1386507690256454,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.14723891230848743,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.98073,
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.6774193548387096
        },
        "rouge1": {
            "precision": 0.79621,
            "recall": 0.68527,
            "fmeasure": 0.70691
        },
        "rouge2": {
            "precision": 0.58595,
            "recall": 0.52717,
            "fmeasure": 0.53107
        },
        "rougeL": {
            "precision": 0.79621,
            "recall": 0.68527,
            "fmeasure": 0.70691
        },
        "rougeLsum": {
            "precision": 0.79621,
            "recall": 0.68527,
            "fmeasure": 0.70691
        },
        "nist": 3.6176811147892054,
        "bleurt": 0.30554,
        "bertscore": {
            "precision": 0.94126,
            "recall": 0.92514,
            "f1": 0.92962
        },
        "nubia": {
            "semantic_relation": 4.32966,
            "contradiction": 0.59881,
            "irrelevancy": 60.1194,
            "logical_agreement": 39.28179,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.26035,
            "nubia_score": 0.83854
        },
        "meteor": 0.357263750079309
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.765,
        "total_length": 266,
        "mean_pred_length": 17.733333333333334,
        "std_pred_length": 5.859086011391955,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6090225563909775,
        "vocab_size-1": 162,
        "unique-1": 132,
        "entropy-1": 6.669167741232611,
        "distinct-2": 0.9402390438247012,
        "vocab_size-2": 236,
        "unique-2": 226,
        "entropy-2": 7.83307786669115,
        "cond_entropy-2": 1.0132661472908522,
        "distinct-3": 0.9957627118644068,
        "vocab_size-3": 235,
        "unique-3": 234,
        "entropy-3": 7.874168473090631,
        "cond_entropy-3": 0.04989139160667708,
        "total_length-nopunct": 233,
        "mean_pred_length-nopunct": 15.533333333333333,
        "std_pred_length-nopunct": 5.414384134465854,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6781115879828327,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.779206827776554,
        "distinct-2-nopunct": 0.9495412844036697,
        "vocab_size-2-nopunct": 207,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.654629794950477,
        "cond_entropy-2-nopunct": 0.9382198811759977,
        "distinct-3-nopunct": 0.9950738916256158,
        "vocab_size-3-nopunct": 202,
        "unique-3-nopunct": 201,
        "entropy-3-nopunct": 7.655483700436413,
        "cond_entropy-3-nopunct": 0.009244634290828535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.19992,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.4230769230769231,
            "3": 0.78125
        },
        "rouge1": {
            "precision": 0.82349,
            "recall": 0.77396,
            "fmeasure": 0.79049
        },
        "rouge2": {
            "precision": 0.64158,
            "recall": 0.60457,
            "fmeasure": 0.61651
        },
        "rougeL": {
            "precision": 0.78284,
            "recall": 0.7315,
            "fmeasure": 0.74902
        },
        "rougeLsum": {
            "precision": 0.78284,
            "recall": 0.7315,
            "fmeasure": 0.74902
        },
        "nist": 6.345767052357647,
        "bleurt": 0.44732,
        "bertscore": {
            "precision": 0.94937,
            "recall": 0.94218,
            "f1": 0.94313
        },
        "nubia": {
            "semantic_relation": 4.34327,
            "contradiction": 8.13351,
            "irrelevancy": 25.91035,
            "logical_agreement": 65.95615,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.38566,
            "nubia_score": 0.76636
        },
        "meteor": 0.4151243850573874
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.025555977074987163,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.0224469564457176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.85321,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.63158,
            "recall": 0.92308,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.83333,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.92308,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.92308,
            "fmeasure": 0.75
        },
        "nist": 2.5,
        "bleurt": 0.52222,
        "bertscore": {
            "precision": 0.9054,
            "recall": 0.98094,
            "f1": 0.94165
        },
        "nubia": {
            "semantic_relation": 3.82338,
            "contradiction": 0.18427,
            "irrelevancy": 99.70305,
            "logical_agreement": 0.11269,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.30958,
            "nubia_score": 0.80209
        },
        "meteor": 0.5478416766663161
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "T5-xl (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.25876,
        "msttr-100_nopunct": 0.24478,
        "total_length": 385553,
        "mean_pred_length": 19.27765,
        "std_pred_length": 8.855894109433558,
        "median_pred_length": 18.0,
        "min_pred_length": 3,
        "max_pred_length": 83,
        "distinct-1": 0.022152596400494873,
        "vocab_size-1": 8541,
        "unique-1": 25,
        "entropy-1": 9.757410612835951,
        "distinct-2": 0.0722166142802822,
        "vocab_size-2": 26399,
        "unique-2": 141,
        "entropy-2": 13.993118471555821,
        "cond_entropy-2": 3.9366331615262524,
        "distinct-3": 0.09428654938605656,
        "vocab_size-3": 32581,
        "unique-3": 239,
        "entropy-3": 14.848755385697864,
        "cond_entropy-3": 0.8738170684078754,
        "total_length-nopunct": 340466,
        "mean_pred_length-nopunct": 17.0233,
        "std_pred_length-nopunct": 7.831644598039418,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.025036273812950486,
        "vocab_size-1-nopunct": 8524,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 10.20100509311443,
        "distinct-2-nopunct": 0.07509376969787747,
        "vocab_size-2-nopunct": 24065,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 13.93613392307928,
        "cond_entropy-2-nopunct": 3.913431154110776,
        "distinct-3-nopunct": 0.0957845480021034,
        "vocab_size-3-nopunct": 28780,
        "unique-3-nopunct": 210,
        "entropy-3-nopunct": 14.713820716031321,
        "cond_entropy-3-nopunct": 0.8241999091958951,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "bleu": 45.30727,
        "local_recall": {
            "1": 0.7089004687556223
        },
        "rouge1": {
            "precision": 0.73028,
            "recall": 0.72606,
            "fmeasure": 0.70898
        },
        "rouge2": {
            "precision": 0.53885,
            "recall": 0.53395,
            "fmeasure": 0.52129
        },
        "rougeL": {
            "precision": 0.68366,
            "recall": 0.67976,
            "fmeasure": 0.66401
        },
        "rougeLsum": {
            "precision": 0.68366,
            "recall": 0.67976,
            "fmeasure": 0.66401
        },
        "nist": 9.635181045380786,
        "sari": 46.54511,
        "bleurt": 0.29838,
        "bertscore": {
            "precision": 0.92229,
            "recall": 0.92189,
            "f1": 0.9212
        },
        "nubia": {
            "semantic_relation": 4.32019,
            "contradiction": 2.91799,
            "irrelevancy": 25.59259,
            "logical_agreement": 71.48941,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.73829,
            "nubia_score": 0.70034
        },
        "meteor": 0.38740477847873406
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 16.25,
        "std_pred_length": 4.085033659592048,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.8615384615384616,
        "vocab_size-1": 56,
        "unique-1": 51,
        "entropy-1": 5.691448197577274,
        "distinct-2": 0.9836065573770492,
        "vocab_size-2": 60,
        "unique-2": 59,
        "entropy-2": 5.897950452316981,
        "cond_entropy-2": 0.09705436067093874,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.06275960409989875,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.082207001484488,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.65101764523326,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.022986478817400673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.07381055075326923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.29348,
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8035714285714286
        },
        "rouge1": {
            "precision": 0.83983,
            "recall": 0.76318,
            "fmeasure": 0.79522
        },
        "rouge2": {
            "precision": 0.70321,
            "recall": 0.6529,
            "fmeasure": 0.67367
        },
        "rougeL": {
            "precision": 0.75866,
            "recall": 0.69906,
            "fmeasure": 0.72398
        },
        "rougeLsum": {
            "precision": 0.75866,
            "recall": 0.69906,
            "fmeasure": 0.72398
        },
        "nist": 4.826164284124395,
        "bleurt": 0.46918,
        "bertscore": {
            "precision": 0.95728,
            "recall": 0.9445,
            "f1": 0.95048
        },
        "nubia": {
            "semantic_relation": 4.38951,
            "contradiction": 0.55419,
            "irrelevancy": 23.84987,
            "logical_agreement": 75.59594,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.76197,
            "nubia_score": 0.77602
        },
        "meteor": 0.42735640608766196
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 6.649979114420002,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.8409090909090909,
        "vocab_size-1": 37,
        "unique-1": 31,
        "entropy-1": 5.124093266315398,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.09324233720029855,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.056992912227129496,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 6.342099196813483,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412737,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838574,
        "cond_entropy-2-nopunct": 0.02506829915080152,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.65501,
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.60967,
            "recall": 0.58413,
            "fmeasure": 0.58998
        },
        "rouge2": {
            "precision": 0.34392,
            "recall": 0.36243,
            "fmeasure": 0.34843
        },
        "rougeL": {
            "precision": 0.53391,
            "recall": 0.5246,
            "fmeasure": 0.52332
        },
        "rougeLsum": {
            "precision": 0.53391,
            "recall": 0.5246,
            "fmeasure": 0.52332
        },
        "nist": 2.34795135469418,
        "bleurt": 0.01664,
        "bertscore": {
            "precision": 0.88671,
            "recall": 0.89956,
            "f1": 0.89295
        },
        "nubia": {
            "semantic_relation": 3.52325,
            "contradiction": 8.73415,
            "irrelevancy": 44.21069,
            "logical_agreement": 47.05516,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.79739,
            "nubia_score": 0.50908
        },
        "meteor": 0.2776359299724473
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.73143,
        "msttr-100_nopunct": 0.792,
        "total_length": 701,
        "mean_pred_length": 17.974358974358974,
        "std_pred_length": 8.657254789280607,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.5663338088445078,
        "vocab_size-1": 397,
        "unique-1": 331,
        "entropy-1": 7.59353590327873,
        "distinct-2": 0.904833836858006,
        "vocab_size-2": 599,
        "unique-2": 554,
        "entropy-2": 9.138073840520178,
        "cond_entropy-2": 1.3364250596133078,
        "distinct-3": 0.971107544141252,
        "vocab_size-3": 605,
        "unique-3": 587,
        "entropy-3": 9.225303441306416,
        "cond_entropy-3": 0.09858101183803752,
        "total_length-nopunct": 592,
        "mean_pred_length-nopunct": 15.179487179487179,
        "std_pred_length-nopunct": 6.713445349071059,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6621621621621622,
        "vocab_size-1-nopunct": 392,
        "unique-1-nopunct": 331,
        "entropy-1-nopunct": 7.930614871656664,
        "distinct-2-nopunct": 0.9240506329113924,
        "vocab_size-2-nopunct": 511,
        "unique-2-nopunct": 478,
        "entropy-2-nopunct": 8.93035055549498,
        "cond_entropy-2-nopunct": 1.0744006725619932,
        "distinct-3-nopunct": 0.9747081712062257,
        "vocab_size-3-nopunct": 501,
        "unique-3-nopunct": 488,
        "entropy-3-nopunct": 8.95504089160636,
        "cond_entropy-3-nopunct": 0.03062539345535223,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.24503,
        "local_recall": {
            "1": 0.12781954887218044,
            "2": 0.6402116402116402,
            "3": 0.7196029776674938
        },
        "rouge1": {
            "precision": 0.76879,
            "recall": 0.67473,
            "fmeasure": 0.70678
        },
        "rouge2": {
            "precision": 0.50266,
            "recall": 0.45174,
            "fmeasure": 0.46802
        },
        "rougeL": {
            "precision": 0.62516,
            "recall": 0.55947,
            "fmeasure": 0.58023
        },
        "rougeLsum": {
            "precision": 0.62516,
            "recall": 0.55947,
            "fmeasure": 0.58023
        },
        "nist": 6.785658598515938,
        "bleurt": 0.28749,
        "bertscore": {
            "precision": 0.92605,
            "recall": 0.91636,
            "f1": 0.91957
        },
        "nubia": {
            "semantic_relation": 4.19154,
            "contradiction": 8.01166,
            "irrelevancy": 27.02238,
            "logical_agreement": 64.96596,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.46364,
            "nubia_score": 0.71555
        },
        "meteor": 0.37993404212566445
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 123,
        "mean_pred_length": 12.3,
        "std_pred_length": 4.712748667179271,
        "median_pred_length": 11.5,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.6341463414634146,
        "vocab_size-1": 78,
        "unique-1": 62,
        "entropy-1": 5.8762426326500385,
        "distinct-2": 0.911504424778761,
        "vocab_size-2": 103,
        "unique-2": 96,
        "entropy-2": 6.6188082765553515,
        "cond_entropy-2": 0.5429500490204939,
        "distinct-3": 0.9611650485436893,
        "vocab_size-3": 99,
        "unique-3": 95,
        "entropy-3": 6.608830624270614,
        "cond_entropy-3": -0.029262051715819058,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 10.6,
        "std_pred_length-nopunct": 4.340506882842141,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7169811320754716,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.989423521190604,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.439129167387827,
        "cond_entropy-2-nopunct": 0.4849657434235192,
        "distinct-3-nopunct": 0.9767441860465116,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.379753126795122,
        "cond_entropy-3-nopunct": -0.042418676251616425,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.97315,
        "local_recall": {
            "1": 0.06779661016949153,
            "2": 0.19230769230769232,
            "3": 0.5098039215686274
        },
        "rouge1": {
            "precision": 0.64137,
            "recall": 0.52681,
            "fmeasure": 0.54256
        },
        "rouge2": {
            "precision": 0.29777,
            "recall": 0.2963,
            "fmeasure": 0.27841
        },
        "rougeL": {
            "precision": 0.48085,
            "recall": 0.41695,
            "fmeasure": 0.41724
        },
        "rougeLsum": {
            "precision": 0.48085,
            "recall": 0.41695,
            "fmeasure": 0.41724
        },
        "nist": 2.937651273923352,
        "bleurt": 0.08228,
        "bertscore": {
            "precision": 0.89229,
            "recall": 0.87468,
            "f1": 0.88055
        },
        "nubia": {
            "semantic_relation": 3.72243,
            "contradiction": 9.43334,
            "irrelevancy": 30.7026,
            "logical_agreement": 59.86406,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.96413,
            "nubia_score": 0.56022
        },
        "meteor": 0.25401896792455186
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.71538,
        "msttr-100_nopunct": 0.77083,
        "total_length": 1382,
        "mean_pred_length": 18.426666666666666,
        "std_pred_length": 6.880258393080565,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.4717800289435601,
        "vocab_size-1": 652,
        "unique-1": 498,
        "entropy-1": 8.05160951925161,
        "distinct-2": 0.8408569242540168,
        "vocab_size-2": 1099,
        "unique-2": 992,
        "entropy-2": 9.901034775256926,
        "cond_entropy-2": 1.6253738116062828,
        "distinct-3": 0.9439935064935064,
        "vocab_size-3": 1163,
        "unique-3": 1115,
        "entropy-3": 10.138529017587404,
        "cond_entropy-3": 0.23652516666629836,
        "total_length-nopunct": 1203,
        "mean_pred_length-nopunct": 16.04,
        "std_pred_length-nopunct": 5.629541129908666,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5353283458021613,
        "vocab_size-1-nopunct": 644,
        "unique-1-nopunct": 497,
        "entropy-1-nopunct": 8.304775408182005,
        "distinct-2-nopunct": 0.8546099290780141,
        "vocab_size-2-nopunct": 964,
        "unique-2-nopunct": 886,
        "entropy-2-nopunct": 9.708971681527254,
        "cond_entropy-2-nopunct": 1.4923184903865874,
        "distinct-3-nopunct": 0.949667616334283,
        "vocab_size-3-nopunct": 1000,
        "unique-3-nopunct": 963,
        "entropy-3-nopunct": 9.924669012609767,
        "cond_entropy-3-nopunct": 0.2287872649011339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.75586,
        "local_recall": {
            "1": 0.30943396226415093,
            "2": 0.4444444444444444,
            "3": 0.7872611464968153
        },
        "rouge1": {
            "precision": 0.73568,
            "recall": 0.75216,
            "fmeasure": 0.7319
        },
        "rouge2": {
            "precision": 0.51708,
            "recall": 0.53493,
            "fmeasure": 0.5167
        },
        "rougeL": {
            "precision": 0.62543,
            "recall": 0.64786,
            "fmeasure": 0.62626
        },
        "rougeLsum": {
            "precision": 0.62543,
            "recall": 0.64786,
            "fmeasure": 0.62626
        },
        "nist": 7.086573166460218,
        "bleurt": 0.16178,
        "bertscore": {
            "precision": 0.9147,
            "recall": 0.91994,
            "f1": 0.91493
        },
        "nubia": {
            "semantic_relation": 4.15332,
            "contradiction": 7.17372,
            "irrelevancy": 38.26867,
            "logical_agreement": 54.55761,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.91096,
            "nubia_score": 0.68185
        },
        "meteor": 0.3878626085303281
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.83,
        "total_length": 279,
        "mean_pred_length": 17.4375,
        "std_pred_length": 9.360613962235597,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.6021505376344086,
        "vocab_size-1": 168,
        "unique-1": 140,
        "entropy-1": 6.685329718065742,
        "distinct-2": 0.9277566539923955,
        "vocab_size-2": 244,
        "unique-2": 231,
        "entropy-2": 7.8564094835889025,
        "cond_entropy-2": 1.0099438721399068,
        "distinct-3": 0.9838056680161943,
        "vocab_size-3": 243,
        "unique-3": 239,
        "entropy-3": 7.915978567617096,
        "cond_entropy-3": 0.07139156213043206,
        "total_length-nopunct": 220,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.981214711292819,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7454545454545455,
        "vocab_size-1-nopunct": 164,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 7.020496400565657,
        "distinct-2-nopunct": 0.9656862745098039,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.603797890991104,
        "cond_entropy-2-nopunct": 0.6331731228143773,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 188,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.554588851677659,
        "cond_entropy-3-nopunct": -0.04336840518747507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.16887,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3170731707317073,
            "3": 0.7945945945945946
        },
        "rouge1": {
            "precision": 0.81692,
            "recall": 0.7755,
            "fmeasure": 0.78416
        },
        "rouge2": {
            "precision": 0.57614,
            "recall": 0.55969,
            "fmeasure": 0.56023
        },
        "rougeL": {
            "precision": 0.72401,
            "recall": 0.68533,
            "fmeasure": 0.69412
        },
        "rougeLsum": {
            "precision": 0.72401,
            "recall": 0.68533,
            "fmeasure": 0.69412
        },
        "nist": 6.626286466973531,
        "bleurt": 0.38531,
        "bertscore": {
            "precision": 0.94026,
            "recall": 0.94236,
            "f1": 0.93947
        },
        "nubia": {
            "semantic_relation": 4.49812,
            "contradiction": 3.1666,
            "irrelevancy": 32.79629,
            "logical_agreement": 64.03711,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.28566,
            "nubia_score": 0.85278
        },
        "meteor": 0.42233137275928573
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.72,
        "total_length": 208,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 9.01233722306385,
        "median_pred_length": 12.5,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.5817307692307693,
        "vocab_size-1": 121,
        "unique-1": 94,
        "entropy-1": 6.248165509943062,
        "distinct-2": 0.923469387755102,
        "vocab_size-2": 181,
        "unique-2": 167,
        "entropy-2": 7.457797152777626,
        "cond_entropy-2": 1.079058890231107,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 180,
        "unique-3": 176,
        "entropy-3": 7.480083695187461,
        "cond_entropy-3": 0.03251997880138852,
        "total_length-nopunct": 178,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 7.335227028221795,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6685393258426966,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.442054581131708,
        "distinct-2-nopunct": 0.9337349397590361,
        "vocab_size-2-nopunct": 155,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.237961795791708,
        "cond_entropy-2-nopunct": 0.8405105050094966,
        "distinct-3-nopunct": 0.974025974025974,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.214838488746867,
        "cond_entropy-3-nopunct": -0.018935439339273615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.45664,
        "local_recall": {
            "1": 0.3,
            "2": 0.3870967741935484,
            "3": 0.7251908396946565
        },
        "rouge1": {
            "precision": 0.75737,
            "recall": 0.71666,
            "fmeasure": 0.72597
        },
        "rouge2": {
            "precision": 0.55222,
            "recall": 0.54463,
            "fmeasure": 0.54151
        },
        "rougeL": {
            "precision": 0.64312,
            "recall": 0.60973,
            "fmeasure": 0.61623
        },
        "rougeLsum": {
            "precision": 0.64312,
            "recall": 0.60973,
            "fmeasure": 0.61623
        },
        "nist": 5.414483457028075,
        "bleurt": 0.1487,
        "bertscore": {
            "precision": 0.92745,
            "recall": 0.92631,
            "f1": 0.92582
        },
        "nubia": {
            "semantic_relation": 3.93471,
            "contradiction": 9.17414,
            "irrelevancy": 39.21843,
            "logical_agreement": 51.60743,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.62017,
            "nubia_score": 0.65371
        },
        "meteor": 0.3734056942871497
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.082207001484488,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.092562016709616,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.37639029246416483,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.12553088208385924,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.8722813232690143,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8043478260869565,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.010308902264906,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.3832707161130998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.14438990933517482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.66042,
        "local_recall": {
            "1": 0.125,
            "2": 0.2857142857142857,
            "3": 0.7297297297297297
        },
        "rouge1": {
            "precision": 0.73116,
            "recall": 0.75571,
            "fmeasure": 0.73997
        },
        "rouge2": {
            "precision": 0.46995,
            "recall": 0.4719,
            "fmeasure": 0.46799
        },
        "rougeL": {
            "precision": 0.63741,
            "recall": 0.66047,
            "fmeasure": 0.64574
        },
        "rougeLsum": {
            "precision": 0.63741,
            "recall": 0.66047,
            "fmeasure": 0.64574
        },
        "nist": 3.9698180881634344,
        "bleurt": 0.25342,
        "bertscore": {
            "precision": 0.9302,
            "recall": 0.92301,
            "f1": 0.92191
        },
        "nubia": {
            "semantic_relation": 3.76939,
            "contradiction": 25.68915,
            "irrelevancy": 35.56046,
            "logical_agreement": 38.75039,
            "grammar_ref": 5.13429,
            "grammar_hyp": 5.04804,
            "nubia_score": 0.60815
        },
        "meteor": 0.3890751380401629
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 89,
        "mean_pred_length": 22.25,
        "std_pred_length": 8.347903928532,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.6966292134831461,
        "vocab_size-1": 62,
        "unique-1": 47,
        "entropy-1": 5.733721071221374,
        "distinct-2": 0.8705882352941177,
        "vocab_size-2": 74,
        "unique-2": 65,
        "entropy-2": 6.132805347851507,
        "cond_entropy-2": 0.3123572111724357,
        "distinct-3": 0.9135802469135802,
        "vocab_size-3": 74,
        "unique-3": 67,
        "entropy-3": 6.167010496711775,
        "cond_entropy-3": 0.04786369642997152,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 6.832825184358224,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7532467532467533,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.714457644422426,
        "distinct-2-nopunct": 0.8904109589041096,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.960305552001074,
        "cond_entropy-2-nopunct": 0.25440068955629663,
        "distinct-3-nopunct": 0.9420289855072463,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.992582427792657,
        "cond_entropy-3-nopunct": 0.031089571842549832,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.99915,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.7,
            "3": 0.8775510204081632
        },
        "rouge1": {
            "precision": 0.74291,
            "recall": 0.82569,
            "fmeasure": 0.77723
        },
        "rouge2": {
            "precision": 0.60415,
            "recall": 0.67196,
            "fmeasure": 0.63217
        },
        "rougeL": {
            "precision": 0.66389,
            "recall": 0.75952,
            "fmeasure": 0.70569
        },
        "rougeLsum": {
            "precision": 0.66389,
            "recall": 0.75952,
            "fmeasure": 0.70569
        },
        "nist": 4.874863939343968,
        "bleurt": 0.20447,
        "bertscore": {
            "precision": 0.93406,
            "recall": 0.91552,
            "f1": 0.92398
        },
        "nubia": {
            "semantic_relation": 4.12593,
            "contradiction": 21.35711,
            "irrelevancy": 18.32057,
            "logical_agreement": 60.32232,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.89367,
            "nubia_score": 0.71037
        },
        "meteor": 0.42247575144086047
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.738,
        "total_length": 641,
        "mean_pred_length": 18.314285714285713,
        "std_pred_length": 7.497700327705932,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.5241809672386896,
        "vocab_size-1": 336,
        "unique-1": 263,
        "entropy-1": 7.378869926577061,
        "distinct-2": 0.8976897689768977,
        "vocab_size-2": 544,
        "unique-2": 506,
        "entropy-2": 8.991246111360093,
        "cond_entropy-2": 1.4216309846691195,
        "distinct-3": 0.968476357267951,
        "vocab_size-3": 553,
        "unique-3": 541,
        "entropy-3": 9.085508844279394,
        "cond_entropy-3": 0.10620226973883072,
        "total_length-nopunct": 550,
        "mean_pred_length-nopunct": 15.714285714285714,
        "std_pred_length-nopunct": 6.614146866793193,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5981818181818181,
        "vocab_size-1-nopunct": 329,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.5741420503562225,
        "distinct-2-nopunct": 0.912621359223301,
        "vocab_size-2-nopunct": 470,
        "unique-2-nopunct": 444,
        "entropy-2-nopunct": 8.78723754828761,
        "cond_entropy-2-nopunct": 1.2995422970225066,
        "distinct-3-nopunct": 0.98125,
        "vocab_size-3-nopunct": 471,
        "unique-3-nopunct": 465,
        "entropy-3-nopunct": 8.86467254872003,
        "cond_entropy-3-nopunct": 0.09356351622907137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.19644,
        "local_recall": {
            "1": 0.19148936170212766,
            "2": 0.5575221238938053,
            "3": 0.7531486146095718
        },
        "rouge1": {
            "precision": 0.78396,
            "recall": 0.76596,
            "fmeasure": 0.76494
        },
        "rouge2": {
            "precision": 0.53787,
            "recall": 0.52599,
            "fmeasure": 0.52555
        },
        "rougeL": {
            "precision": 0.67727,
            "recall": 0.67726,
            "fmeasure": 0.66888
        },
        "rougeLsum": {
            "precision": 0.67727,
            "recall": 0.67726,
            "fmeasure": 0.66888
        },
        "nist": 6.647308712747948,
        "bleurt": 0.26243,
        "bertscore": {
            "precision": 0.93171,
            "recall": 0.92508,
            "f1": 0.92574
        },
        "nubia": {
            "semantic_relation": 4.14302,
            "contradiction": 15.35068,
            "irrelevancy": 27.90177,
            "logical_agreement": 56.74755,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.59741,
            "nubia_score": 0.70817
        },
        "meteor": 0.375082269146195
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.67714,
        "msttr-100_nopunct": 0.73,
        "total_length": 704,
        "mean_pred_length": 19.555555555555557,
        "std_pred_length": 8.39789803212832,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 49,
        "distinct-1": 0.5284090909090909,
        "vocab_size-1": 372,
        "unique-1": 294,
        "entropy-1": 7.515645733976024,
        "distinct-2": 0.8982035928143712,
        "vocab_size-2": 600,
        "unique-2": 560,
        "entropy-2": 9.127517639858635,
        "cond_entropy-2": 1.4380081211459534,
        "distinct-3": 0.9746835443037974,
        "vocab_size-3": 616,
        "unique-3": 606,
        "entropy-3": 9.245981183283142,
        "cond_entropy-3": 0.1146867697215482,
        "total_length-nopunct": 602,
        "mean_pred_length-nopunct": 16.72222222222222,
        "std_pred_length-nopunct": 6.392752454977222,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.606312292358804,
        "vocab_size-1-nopunct": 365,
        "unique-1-nopunct": 293,
        "entropy-1-nopunct": 7.729903698365642,
        "distinct-2-nopunct": 0.9151943462897526,
        "vocab_size-2-nopunct": 518,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.933954389534769,
        "cond_entropy-2-nopunct": 1.2908594813142797,
        "distinct-3-nopunct": 0.9849056603773585,
        "vocab_size-3-nopunct": 522,
        "unique-3-nopunct": 517,
        "entropy-3-nopunct": 9.015386922079838,
        "cond_entropy-3-nopunct": 0.0919709074860213,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.96427,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.4852941176470588,
            "3": 0.7537688442211056
        },
        "rouge1": {
            "precision": 0.74675,
            "recall": 0.70486,
            "fmeasure": 0.71643
        },
        "rouge2": {
            "precision": 0.46636,
            "recall": 0.44715,
            "fmeasure": 0.4501
        },
        "rougeL": {
            "precision": 0.61776,
            "recall": 0.59254,
            "fmeasure": 0.59729
        },
        "rougeLsum": {
            "precision": 0.61776,
            "recall": 0.59254,
            "fmeasure": 0.59729
        },
        "nist": 6.54585386786572,
        "bleurt": 0.25005,
        "bertscore": {
            "precision": 0.9237,
            "recall": 0.91732,
            "f1": 0.91893
        },
        "nubia": {
            "semantic_relation": 4.14748,
            "contradiction": 11.57146,
            "irrelevancy": 22.75135,
            "logical_agreement": 65.67719,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.71718,
            "nubia_score": 0.72294
        },
        "meteor": 0.36347736811279163
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.70909,
        "msttr-100_nopunct": 0.76333,
        "total_length": 1118,
        "mean_pred_length": 18.032258064516128,
        "std_pred_length": 8.208901034332625,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.45706618962432916,
        "vocab_size-1": 511,
        "unique-1": 378,
        "entropy-1": 7.821628085384348,
        "distinct-2": 0.8409090909090909,
        "vocab_size-2": 888,
        "unique-2": 787,
        "entropy-2": 9.648901369808538,
        "cond_entropy-2": 1.611670425300701,
        "distinct-3": 0.9416498993963782,
        "vocab_size-3": 936,
        "unique-3": 893,
        "entropy-3": 9.825518553112275,
        "cond_entropy-3": 0.15991812394061405,
        "total_length-nopunct": 952,
        "mean_pred_length-nopunct": 15.35483870967742,
        "std_pred_length-nopunct": 6.851175491778526,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5273109243697479,
        "vocab_size-1-nopunct": 502,
        "unique-1-nopunct": 375,
        "entropy-1-nopunct": 8.118357741222184,
        "distinct-2-nopunct": 0.8606741573033708,
        "vocab_size-2-nopunct": 766,
        "unique-2-nopunct": 694,
        "entropy-2-nopunct": 9.445412786486102,
        "cond_entropy-2-nopunct": 1.3853713548360664,
        "distinct-3-nopunct": 0.9504830917874396,
        "vocab_size-3-nopunct": 787,
        "unique-3-nopunct": 755,
        "entropy-3-nopunct": 9.585655782964084,
        "cond_entropy-3-nopunct": 0.14184885014521065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.52088,
        "local_recall": {
            "1": 0.20348837209302326,
            "2": 0.4293785310734463,
            "3": 0.8104956268221575
        },
        "rouge1": {
            "precision": 0.76806,
            "recall": 0.76196,
            "fmeasure": 0.75395
        },
        "rouge2": {
            "precision": 0.53039,
            "recall": 0.52071,
            "fmeasure": 0.51859
        },
        "rougeL": {
            "precision": 0.66445,
            "recall": 0.65814,
            "fmeasure": 0.65144
        },
        "rougeLsum": {
            "precision": 0.66445,
            "recall": 0.65814,
            "fmeasure": 0.65144
        },
        "nist": 7.150137603553224,
        "bleurt": 0.27609,
        "bertscore": {
            "precision": 0.92711,
            "recall": 0.92608,
            "f1": 0.92393
        },
        "nubia": {
            "semantic_relation": 4.27273,
            "contradiction": 4.27222,
            "irrelevancy": 33.67122,
            "logical_agreement": 62.05656,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.47354,
            "nubia_score": 0.75599
        },
        "meteor": 0.40150342305465975
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.69875,
        "msttr-100_nopunct": 0.76286,
        "total_length": 844,
        "mean_pred_length": 17.583333333333332,
        "std_pred_length": 7.155514578902686,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.523696682464455,
        "vocab_size-1": 442,
        "unique-1": 364,
        "entropy-1": 7.7054952503668686,
        "distinct-2": 0.9095477386934674,
        "vocab_size-2": 724,
        "unique-2": 677,
        "entropy-2": 9.414501505028044,
        "cond_entropy-2": 1.4937685524069506,
        "distinct-3": 0.9799465240641712,
        "vocab_size-3": 733,
        "unique-3": 718,
        "entropy-3": 9.506787508015933,
        "cond_entropy-3": 0.09216170090590264,
        "total_length-nopunct": 734,
        "mean_pred_length-nopunct": 15.291666666666666,
        "std_pred_length-nopunct": 6.393220150197308,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5940054495912807,
        "vocab_size-1-nopunct": 436,
        "unique-1-nopunct": 362,
        "entropy-1-nopunct": 7.947734565879567,
        "distinct-2-nopunct": 0.9169096209912536,
        "vocab_size-2-nopunct": 629,
        "unique-2-nopunct": 596,
        "entropy-2-nopunct": 9.209156438988753,
        "cond_entropy-2-nopunct": 1.3340512005024763,
        "distinct-3-nopunct": 0.9858934169278997,
        "vocab_size-3-nopunct": 629,
        "unique-3-nopunct": 620,
        "entropy-3-nopunct": 9.289199447620664,
        "cond_entropy-3-nopunct": 0.0944937918684079,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.66005,
        "local_recall": {
            "1": 0.2046783625730994,
            "2": 0.6025641025641025,
            "3": 0.7355212355212355
        },
        "rouge1": {
            "precision": 0.75601,
            "recall": 0.71734,
            "fmeasure": 0.72289
        },
        "rouge2": {
            "precision": 0.49395,
            "recall": 0.48947,
            "fmeasure": 0.48366
        },
        "rougeL": {
            "precision": 0.64521,
            "recall": 0.61552,
            "fmeasure": 0.61928
        },
        "rougeLsum": {
            "precision": 0.64521,
            "recall": 0.61552,
            "fmeasure": 0.61928
        },
        "nist": 6.90345661097875,
        "bleurt": 0.22227,
        "bertscore": {
            "precision": 0.92999,
            "recall": 0.91843,
            "f1": 0.92134
        },
        "nubia": {
            "semantic_relation": 4.10518,
            "contradiction": 11.65579,
            "irrelevancy": 26.60437,
            "logical_agreement": 61.73984,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.61328,
            "nubia_score": 0.70561
        },
        "meteor": 0.3782680631953168
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.71846,
        "msttr-100_nopunct": 0.77636,
        "total_length": 1347,
        "mean_pred_length": 17.26923076923077,
        "std_pred_length": 6.975549012347963,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.46919079435783223,
        "vocab_size-1": 632,
        "unique-1": 473,
        "entropy-1": 8.0528564741765,
        "distinct-2": 0.8565799842395587,
        "vocab_size-2": 1087,
        "unique-2": 971,
        "entropy-2": 9.934328408539303,
        "cond_entropy-2": 1.639129526568401,
        "distinct-3": 0.9546599496221663,
        "vocab_size-3": 1137,
        "unique-3": 1083,
        "entropy-3": 10.127277597108396,
        "cond_entropy-3": 0.18862943019568312,
        "total_length-nopunct": 1164,
        "mean_pred_length-nopunct": 14.923076923076923,
        "std_pred_length-nopunct": 6.010182024568126,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5352233676975945,
        "vocab_size-1-nopunct": 623,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.320147689167065,
        "distinct-2-nopunct": 0.8683241252302025,
        "vocab_size-2-nopunct": 943,
        "unique-2-nopunct": 854,
        "entropy-2-nopunct": 9.731082240817965,
        "cond_entropy-2-nopunct": 1.4899322010670033,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 966,
        "unique-3-nopunct": 924,
        "entropy-3-nopunct": 9.893946590166413,
        "cond_entropy-3-nopunct": 0.18031538056393773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.46447,
        "local_recall": {
            "1": 0.24892703862660945,
            "2": 0.4723404255319149,
            "3": 0.791970802919708
        },
        "rouge1": {
            "precision": 0.76252,
            "recall": 0.73352,
            "fmeasure": 0.73786
        },
        "rouge2": {
            "precision": 0.53168,
            "recall": 0.51101,
            "fmeasure": 0.51451
        },
        "rougeL": {
            "precision": 0.68997,
            "recall": 0.66036,
            "fmeasure": 0.66564
        },
        "rougeLsum": {
            "precision": 0.68997,
            "recall": 0.66036,
            "fmeasure": 0.66564
        },
        "nist": 7.485315662054961,
        "bleurt": 0.3175,
        "bertscore": {
            "precision": 0.93241,
            "recall": 0.93115,
            "f1": 0.93036
        },
        "nubia": {
            "semantic_relation": 4.34308,
            "contradiction": 5.77401,
            "irrelevancy": 30.21232,
            "logical_agreement": 64.01367,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.62493,
            "nubia_score": 0.77475
        },
        "meteor": 0.4090116720489562
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.745,
        "total_length": 291,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 5.4594464513864,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6013745704467354,
        "vocab_size-1": 175,
        "unique-1": 140,
        "entropy-1": 6.76520755410453,
        "distinct-2": 0.9120879120879121,
        "vocab_size-2": 249,
        "unique-2": 233,
        "entropy-2": 7.874772617094447,
        "cond_entropy-2": 0.9282294225961946,
        "distinct-3": 0.9647058823529412,
        "vocab_size-3": 246,
        "unique-3": 237,
        "entropy-3": 7.923765201564753,
        "cond_entropy-3": 0.06437972732852323,
        "total_length-nopunct": 259,
        "mean_pred_length-nopunct": 14.38888888888889,
        "std_pred_length-nopunct": 5.165471785367925,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6563706563706564,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.858464933590316,
        "distinct-2-nopunct": 0.9045643153526971,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 203,
        "entropy-2-nopunct": 7.674259564427803,
        "cond_entropy-2-nopunct": 0.8642604207639509,
        "distinct-3-nopunct": 0.9641255605381166,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.7291510209965475,
        "cond_entropy-3-nopunct": 0.05359268254059345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.48604,
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.48214285714285715,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.70161,
            "recall": 0.71522,
            "fmeasure": 0.7031
        },
        "rouge2": {
            "precision": 0.46398,
            "recall": 0.4767,
            "fmeasure": 0.466
        },
        "rougeL": {
            "precision": 0.60314,
            "recall": 0.62076,
            "fmeasure": 0.60663
        },
        "rougeLsum": {
            "precision": 0.60314,
            "recall": 0.62076,
            "fmeasure": 0.60663
        },
        "nist": 5.582140471353229,
        "bleurt": 0.1509,
        "bertscore": {
            "precision": 0.91185,
            "recall": 0.92521,
            "f1": 0.91701
        },
        "nubia": {
            "semantic_relation": 4.21383,
            "contradiction": 1.31847,
            "irrelevancy": 43.03518,
            "logical_agreement": 55.64636,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.67124,
            "nubia_score": 0.72992
        },
        "meteor": 0.3713989835234982
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.41126,
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.37963,
            "fmeasure": 0.45679
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.20175,
            "fmeasure": 0.24381
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.37963,
            "fmeasure": 0.45679
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.37963,
            "fmeasure": 0.45679
        },
        "nist": 0.13663652175556448,
        "bleurt": -0.34849,
        "bertscore": {
            "precision": 0.90423,
            "recall": 0.85927,
            "f1": 0.87691
        },
        "nubia": {
            "semantic_relation": 3.63885,
            "contradiction": 0.2176,
            "irrelevancy": 15.227,
            "logical_agreement": 84.5554,
            "grammar_ref": 4.8547,
            "grammar_hyp": 4.91093,
            "nubia_score": 0.53876
        },
        "meteor": 0.19617533630002662
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7070707070707071,
        "vocab_size-1": 70,
        "unique-1": 57,
        "entropy-1": 5.85926741848843,
        "distinct-2": 0.978494623655914,
        "vocab_size-2": 91,
        "unique-2": 89,
        "entropy-2": 6.496148058419865,
        "cond_entropy-2": 0.519792039987567,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.0502383037650501,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 3.435921354681384,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7764705882352941,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.836107924923581,
        "distinct-2-nopunct": 0.9746835443037974,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.2531478367847,
        "cond_entropy-2-nopunct": 0.4479221658773834,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.059161668749140355,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.62756,
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.0,
            "3": 0.8205128205128205
        },
        "rouge1": {
            "precision": 0.77929,
            "recall": 0.80202,
            "fmeasure": 0.78042
        },
        "rouge2": {
            "precision": 0.49894,
            "recall": 0.53124,
            "fmeasure": 0.50676
        },
        "rougeL": {
            "precision": 0.67096,
            "recall": 0.69227,
            "fmeasure": 0.67353
        },
        "rougeLsum": {
            "precision": 0.67096,
            "recall": 0.69227,
            "fmeasure": 0.67353
        },
        "nist": 5.203472966198186,
        "bleurt": 0.33113,
        "bertscore": {
            "precision": 0.94197,
            "recall": 0.94879,
            "f1": 0.94294
        },
        "nubia": {
            "semantic_relation": 4.52541,
            "contradiction": 0.36008,
            "irrelevancy": 19.76643,
            "logical_agreement": 79.87349,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.93989,
            "nubia_score": 0.79563
        },
        "meteor": 0.4360710335957117
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74167,
        "total_length": 692,
        "mean_pred_length": 19.22222222222222,
        "std_pred_length": 7.098947931094795,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.5433526011560693,
        "vocab_size-1": 376,
        "unique-1": 310,
        "entropy-1": 7.4334581754879405,
        "distinct-2": 0.9039634146341463,
        "vocab_size-2": 593,
        "unique-2": 560,
        "entropy-2": 9.087832954359612,
        "cond_entropy-2": 1.4804796901909782,
        "distinct-3": 0.9774193548387097,
        "vocab_size-3": 606,
        "unique-3": 595,
        "entropy-3": 9.227310433489597,
        "cond_entropy-3": 0.1442436054317884,
        "total_length-nopunct": 613,
        "mean_pred_length-nopunct": 17.02777777777778,
        "std_pred_length-nopunct": 6.877847334058621,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.601957585644372,
        "vocab_size-1-nopunct": 369,
        "unique-1-nopunct": 309,
        "entropy-1-nopunct": 7.560785036358459,
        "distinct-2-nopunct": 0.8977469670710572,
        "vocab_size-2-nopunct": 518,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.880952968840536,
        "cond_entropy-2-nopunct": 1.418941886004791,
        "distinct-3-nopunct": 0.9759704251386322,
        "vocab_size-3-nopunct": 528,
        "unique-3-nopunct": 518,
        "entropy-3-nopunct": 9.027239566624443,
        "cond_entropy-3-nopunct": 0.16568231577448322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.45541,
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.43820224719101125,
            "3": 0.837772397094431
        },
        "rouge1": {
            "precision": 0.76541,
            "recall": 0.77918,
            "fmeasure": 0.76101
        },
        "rouge2": {
            "precision": 0.53349,
            "recall": 0.54313,
            "fmeasure": 0.52938
        },
        "rougeL": {
            "precision": 0.62673,
            "recall": 0.65415,
            "fmeasure": 0.63008
        },
        "rougeLsum": {
            "precision": 0.62673,
            "recall": 0.65415,
            "fmeasure": 0.63008
        },
        "nist": 7.031123346396229,
        "bleurt": 0.29972,
        "bertscore": {
            "precision": 0.92874,
            "recall": 0.93494,
            "f1": 0.93006
        },
        "nubia": {
            "semantic_relation": 4.39141,
            "contradiction": 8.43189,
            "irrelevancy": 29.21163,
            "logical_agreement": 62.35648,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.76655,
            "nubia_score": 0.77941
        },
        "meteor": 0.4105070455222794
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.23606797749979,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.6274509803921569,
        "vocab_size-1": 64,
        "unique-1": 48,
        "entropy-1": 5.630457940623519,
        "distinct-2": 0.8854166666666666,
        "vocab_size-2": 85,
        "unique-2": 74,
        "entropy-2": 6.355795834054493,
        "cond_entropy-2": 0.6289006997201503,
        "distinct-3": 0.9,
        "vocab_size-3": 81,
        "unique-3": 72,
        "entropy-3": 6.291853096329667,
        "cond_entropy-3": -0.07088718216925965,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.134374745810949,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6739130434782609,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.623878261131291,
        "distinct-2-nopunct": 0.8837209302325582,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.193706615167215,
        "cond_entropy-2-nopunct": 0.6093411699609793,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.121928094887357,
        "cond_entropy-3-nopunct": -0.07933665981473573,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.51986,
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5,
            "3": 0.7916666666666666
        },
        "rouge1": {
            "precision": 0.75146,
            "recall": 0.77462,
            "fmeasure": 0.75841
        },
        "rouge2": {
            "precision": 0.54486,
            "recall": 0.5769,
            "fmeasure": 0.55614
        },
        "rougeL": {
            "precision": 0.65701,
            "recall": 0.67596,
            "fmeasure": 0.66193
        },
        "rougeLsum": {
            "precision": 0.65701,
            "recall": 0.67596,
            "fmeasure": 0.66193
        },
        "nist": 5.295519903934055,
        "bleurt": 0.3776,
        "bertscore": {
            "precision": 0.93808,
            "recall": 0.9428,
            "f1": 0.93974
        },
        "nubia": {
            "semantic_relation": 4.27659,
            "contradiction": 17.74364,
            "irrelevancy": 30.48873,
            "logical_agreement": 51.76764,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.14958,
            "nubia_score": 0.78427
        },
        "meteor": 0.43493822020669226
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.73667,
        "total_length": 361,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.986831266792264,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.590027700831025,
        "vocab_size-1": 213,
        "unique-1": 177,
        "entropy-1": 6.979576052921199,
        "distinct-2": 0.9269005847953217,
        "vocab_size-2": 317,
        "unique-2": 299,
        "entropy-2": 8.244988726936288,
        "cond_entropy-2": 1.11365442182191,
        "distinct-3": 0.978328173374613,
        "vocab_size-3": 316,
        "unique-3": 309,
        "entropy-3": 8.292046701443171,
        "cond_entropy-3": 0.057226432621537086,
        "total_length-nopunct": 324,
        "mean_pred_length-nopunct": 17.05263157894737,
        "std_pred_length-nopunct": 7.067149236994372,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6419753086419753,
        "vocab_size-1-nopunct": 208,
        "unique-1-nopunct": 176,
        "entropy-1-nopunct": 7.036958762658324,
        "distinct-2-nopunct": 0.9311475409836065,
        "vocab_size-2-nopunct": 284,
        "unique-2-nopunct": 270,
        "entropy-2-nopunct": 8.085060791536225,
        "cond_entropy-2-nopunct": 1.1240691471191544,
        "distinct-3-nopunct": 0.9790209790209791,
        "vocab_size-3-nopunct": 280,
        "unique-3-nopunct": 274,
        "entropy-3-nopunct": 8.117913294820395,
        "cond_entropy-3-nopunct": 0.04398707733081136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.58055,
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.45054945054945056,
            "3": 0.7687861271676301
        },
        "rouge1": {
            "precision": 0.67192,
            "recall": 0.69654,
            "fmeasure": 0.67406
        },
        "rouge2": {
            "precision": 0.44737,
            "recall": 0.46017,
            "fmeasure": 0.44662
        },
        "rougeL": {
            "precision": 0.59777,
            "recall": 0.6166,
            "fmeasure": 0.59878
        },
        "rougeLsum": {
            "precision": 0.59777,
            "recall": 0.6166,
            "fmeasure": 0.59878
        },
        "nist": 5.30069166146005,
        "bleurt": 0.09125,
        "bertscore": {
            "precision": 0.89711,
            "recall": 0.9059,
            "f1": 0.9002
        },
        "nubia": {
            "semantic_relation": 3.97901,
            "contradiction": 5.3229,
            "irrelevancy": 47.79595,
            "logical_agreement": 46.88115,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.70408,
            "nubia_score": 0.65188
        },
        "meteor": 0.3519608530880855
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7,
        "total_length": 201,
        "mean_pred_length": 20.1,
        "std_pred_length": 10.024470060806205,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 46,
        "distinct-1": 0.6169154228855721,
        "vocab_size-1": 124,
        "unique-1": 96,
        "entropy-1": 6.448953471473891,
        "distinct-2": 0.9267015706806283,
        "vocab_size-2": 177,
        "unique-2": 164,
        "entropy-2": 7.426879678809761,
        "cond_entropy-2": 0.8914950931163472,
        "distinct-3": 0.9779005524861878,
        "vocab_size-3": 177,
        "unique-3": 173,
        "entropy-3": 7.455646992055552,
        "cond_entropy-3": 0.02603522204283521,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 17.4,
        "std_pred_length-nopunct": 8.452218643646175,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6839080459770115,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.4916280111452895,
        "distinct-2-nopunct": 0.9390243902439024,
        "vocab_size-2-nopunct": 154,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.235600785105908,
        "cond_entropy-2-nopunct": 0.7958822547351835,
        "distinct-3-nopunct": 0.974025974025974,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.214838488746868,
        "cond_entropy-3-nopunct": -0.012843386001104611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.03028,
        "local_recall": {
            "1": 0.4838709677419355,
            "2": 0.425,
            "3": 0.7837837837837838
        },
        "rouge1": {
            "precision": 0.76948,
            "recall": 0.79658,
            "fmeasure": 0.77682
        },
        "rouge2": {
            "precision": 0.51534,
            "recall": 0.51968,
            "fmeasure": 0.51268
        },
        "rougeL": {
            "precision": 0.65798,
            "recall": 0.68027,
            "fmeasure": 0.66361
        },
        "rougeLsum": {
            "precision": 0.65798,
            "recall": 0.68027,
            "fmeasure": 0.66361
        },
        "nist": 5.921625782168321,
        "bleurt": 0.24141,
        "bertscore": {
            "precision": 0.9277,
            "recall": 0.94138,
            "f1": 0.93326
        },
        "nubia": {
            "semantic_relation": 4.29049,
            "contradiction": 1.78077,
            "irrelevancy": 37.82027,
            "logical_agreement": 60.39896,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.66911,
            "nubia_score": 0.75877
        },
        "meteor": 0.39548346719859995
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.87433,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.875,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.28571,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.625,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.625,
            "fmeasure": 0.43478
        },
        "nist": 1.5849625007211563,
        "bleurt": 0.14182,
        "bertscore": {
            "precision": 0.85605,
            "recall": 0.9331,
            "f1": 0.89292
        },
        "nubia": {
            "semantic_relation": 4.15134,
            "contradiction": 0.07865,
            "irrelevancy": 99.77725,
            "logical_agreement": 0.1441,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.01083,
            "nubia_score": 0.75443
        },
        "meteor": 0.4283151649548783
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "total_length": 198,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.179143806533246,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6212121212121212,
        "vocab_size-1": 123,
        "unique-1": 100,
        "entropy-1": 6.396123538201774,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 176,
        "unique-2": 167,
        "entropy-2": 7.418552213898312,
        "cond_entropy-2": 0.8914758205930531,
        "distinct-3": 1.0,
        "vocab_size-3": 176,
        "unique-3": 176,
        "entropy-3": 7.459431618637307,
        "cond_entropy-3": 0.04890079511329719,
        "total_length-nopunct": 175,
        "mean_pred_length-nopunct": 15.909090909090908,
        "std_pred_length-nopunct": 5.631963091539468,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6742857142857143,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.436370669581925,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.247795907057128,
        "cond_entropy-2-nopunct": 0.8672986817724562,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 153,
        "entropy-3-nopunct": 7.257387842692632,
        "cond_entropy-3-nopunct": 0.01748289689809762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.3614,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.23809523809523808,
            "3": 0.7007874015748031
        },
        "rouge1": {
            "precision": 0.66559,
            "recall": 0.68651,
            "fmeasure": 0.66472
        },
        "rouge2": {
            "precision": 0.38556,
            "recall": 0.4109,
            "fmeasure": 0.39153
        },
        "rougeL": {
            "precision": 0.57419,
            "recall": 0.59894,
            "fmeasure": 0.57613
        },
        "rougeLsum": {
            "precision": 0.57419,
            "recall": 0.59894,
            "fmeasure": 0.57613
        },
        "nist": 5.089520581730619,
        "bleurt": 0.14897,
        "bertscore": {
            "precision": 0.90425,
            "recall": 0.91414,
            "f1": 0.90638
        },
        "nubia": {
            "semantic_relation": 3.84305,
            "contradiction": 19.69953,
            "irrelevancy": 37.48376,
            "logical_agreement": 42.81671,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.35707,
            "nubia_score": 0.63141
        },
        "meteor": 0.3421919137108019
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.74429,
        "msttr-100_nopunct": 0.78167,
        "total_length": 761,
        "mean_pred_length": 16.543478260869566,
        "std_pred_length": 7.1100251382761455,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.5532194480946123,
        "vocab_size-1": 421,
        "unique-1": 337,
        "entropy-1": 7.739221257847958,
        "distinct-2": 0.9118881118881119,
        "vocab_size-2": 652,
        "unique-2": 611,
        "entropy-2": 9.25648553684695,
        "cond_entropy-2": 1.2797993751689132,
        "distinct-3": 0.9745889387144993,
        "vocab_size-3": 652,
        "unique-3": 635,
        "entropy-3": 9.3350402780704,
        "cond_entropy-3": 0.0820890299555681,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 14.673913043478262,
        "std_pred_length-nopunct": 6.603866943021657,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6148148148148148,
        "vocab_size-1-nopunct": 415,
        "unique-1-nopunct": 336,
        "entropy-1-nopunct": 7.9300672774904175,
        "distinct-2-nopunct": 0.9125596184419714,
        "vocab_size-2-nopunct": 574,
        "unique-2-nopunct": 540,
        "entropy-2-nopunct": 9.067433619767407,
        "cond_entropy-2-nopunct": 1.207331951624007,
        "distinct-3-nopunct": 0.9759862778730704,
        "vocab_size-3-nopunct": 569,
        "unique-3-nopunct": 555,
        "entropy-3-nopunct": 9.139324628946756,
        "cond_entropy-3-nopunct": 0.0848518994144507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.92954,
        "local_recall": {
            "1": 0.15454545454545454,
            "2": 0.3357664233576642,
            "3": 0.758893280632411
        },
        "rouge1": {
            "precision": 0.77875,
            "recall": 0.74244,
            "fmeasure": 0.75086
        },
        "rouge2": {
            "precision": 0.56434,
            "recall": 0.53682,
            "fmeasure": 0.54278
        },
        "rougeL": {
            "precision": 0.70666,
            "recall": 0.67834,
            "fmeasure": 0.68371
        },
        "rougeLsum": {
            "precision": 0.70666,
            "recall": 0.67834,
            "fmeasure": 0.68371
        },
        "nist": 6.541723856073463,
        "bleurt": 0.27937,
        "bertscore": {
            "precision": 0.93036,
            "recall": 0.92348,
            "f1": 0.92601
        },
        "nubia": {
            "semantic_relation": 4.23759,
            "contradiction": 11.55057,
            "irrelevancy": 35.1076,
            "logical_agreement": 53.34183,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.76429,
            "nubia_score": 0.71334
        },
        "meteor": 0.3815649910655407
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.856267428111155,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6774193548387096,
        "vocab_size-1": 63,
        "unique-1": 51,
        "entropy-1": 5.638186231088453,
        "distinct-2": 0.9540229885057471,
        "vocab_size-2": 83,
        "unique-2": 79,
        "entropy-2": 6.350989472860218,
        "cond_entropy-2": 0.5966660058613171,
        "distinct-3": 1.0,
        "vocab_size-3": 81,
        "unique-3": 81,
        "entropy-3": 6.339850002884614,
        "cond_entropy-3": -0.004328060865337993,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 4.017323597731316,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7532467532467533,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.635238612343076,
        "distinct-2-nopunct": 0.9577464788732394,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.065240077251155,
        "cond_entropy-2-nopunct": 0.46928720533218443,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.050456229553150746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.33459,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.6538461538461539,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.80282,
            "recall": 0.66105,
            "fmeasure": 0.7159
        },
        "rouge2": {
            "precision": 0.42045,
            "recall": 0.34391,
            "fmeasure": 0.3734
        },
        "rougeL": {
            "precision": 0.51696,
            "recall": 0.44983,
            "fmeasure": 0.47297
        },
        "rougeLsum": {
            "precision": 0.51696,
            "recall": 0.44983,
            "fmeasure": 0.47297
        },
        "nist": 4.974857648286616,
        "bleurt": 0.25808,
        "bertscore": {
            "precision": 0.93434,
            "recall": 0.90742,
            "f1": 0.92009
        },
        "nubia": {
            "semantic_relation": 4.24406,
            "contradiction": 3.6328,
            "irrelevancy": 44.7472,
            "logical_agreement": 51.62,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.11586,
            "nubia_score": 0.78369
        },
        "meteor": 0.33292556400845985
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.77417,
        "total_length": 1447,
        "mean_pred_length": 17.864197530864196,
        "std_pred_length": 7.6638530850434305,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 43,
        "distinct-1": 0.4692467173462336,
        "vocab_size-1": 679,
        "unique-1": 523,
        "entropy-1": 8.113157666097676,
        "distinct-2": 0.8550512445095169,
        "vocab_size-2": 1168,
        "unique-2": 1050,
        "entropy-2": 10.041962559734735,
        "cond_entropy-2": 1.6912231246254257,
        "distinct-3": 0.9424124513618677,
        "vocab_size-3": 1211,
        "unique-3": 1150,
        "entropy-3": 10.203693877157937,
        "cond_entropy-3": 0.14359303490773934,
        "total_length-nopunct": 1244,
        "mean_pred_length-nopunct": 15.358024691358025,
        "std_pred_length-nopunct": 6.742730226916288,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5393890675241158,
        "vocab_size-1-nopunct": 671,
        "unique-1-nopunct": 521,
        "entropy-1-nopunct": 8.416511856830796,
        "distinct-2-nopunct": 0.8701633705932932,
        "vocab_size-2-nopunct": 1012,
        "unique-2-nopunct": 922,
        "entropy-2-nopunct": 9.847978116230125,
        "cond_entropy-2-nopunct": 1.5171204508200615,
        "distinct-3-nopunct": 0.944547134935305,
        "vocab_size-3-nopunct": 1022,
        "unique-3-nopunct": 974,
        "entropy-3-nopunct": 9.958963870708494,
        "cond_entropy-3-nopunct": 0.1285627540009598,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.64685,
        "local_recall": {
            "1": 0.22525597269624573,
            "2": 0.49224806201550386,
            "3": 0.8243559718969555
        },
        "rouge1": {
            "precision": 0.78245,
            "recall": 0.76381,
            "fmeasure": 0.75988
        },
        "rouge2": {
            "precision": 0.58279,
            "recall": 0.56984,
            "fmeasure": 0.56593
        },
        "rougeL": {
            "precision": 0.68855,
            "recall": 0.67375,
            "fmeasure": 0.6693
        },
        "rougeLsum": {
            "precision": 0.68855,
            "recall": 0.67375,
            "fmeasure": 0.6693
        },
        "nist": 7.789513777181004,
        "bleurt": 0.32525,
        "bertscore": {
            "precision": 0.93754,
            "recall": 0.93537,
            "f1": 0.9352
        },
        "nubia": {
            "semantic_relation": 4.23172,
            "contradiction": 5.27017,
            "irrelevancy": 28.21982,
            "logical_agreement": 66.51001,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.60734,
            "nubia_score": 0.74527
        },
        "meteor": 0.42603080583980635
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "total_length": 316,
        "mean_pred_length": 18.58823529411765,
        "std_pred_length": 7.933983670629348,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.5632911392405063,
        "vocab_size-1": 178,
        "unique-1": 143,
        "entropy-1": 6.668929315991166,
        "distinct-2": 0.903010033444816,
        "vocab_size-2": 270,
        "unique-2": 252,
        "entropy-2": 7.986004150924717,
        "cond_entropy-2": 1.1776287013078706,
        "distinct-3": 0.9539007092198581,
        "vocab_size-3": 269,
        "unique-3": 258,
        "entropy-3": 8.040260572256987,
        "cond_entropy-3": 0.06860378975646934,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 16.058823529411764,
        "std_pred_length-nopunct": 6.863977480383445,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6373626373626373,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 6.788480458709049,
        "distinct-2-nopunct": 0.91015625,
        "vocab_size-2-nopunct": 233,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.779662609544662,
        "cond_entropy-2-nopunct": 1.0738880242636522,
        "distinct-3-nopunct": 0.9623430962343096,
        "vocab_size-3-nopunct": 230,
        "unique-3-nopunct": 221,
        "entropy-3-nopunct": 7.825553000449419,
        "cond_entropy-3-nopunct": 0.0573788245354211,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.47553,
        "local_recall": {
            "1": 0.18461538461538463,
            "2": 0.6140350877192983,
            "3": 0.8372093023255814
        },
        "rouge1": {
            "precision": 0.7748,
            "recall": 0.79345,
            "fmeasure": 0.77568
        },
        "rouge2": {
            "precision": 0.54376,
            "recall": 0.56799,
            "fmeasure": 0.54998
        },
        "rougeL": {
            "precision": 0.63335,
            "recall": 0.65197,
            "fmeasure": 0.63537
        },
        "rougeLsum": {
            "precision": 0.63335,
            "recall": 0.65197,
            "fmeasure": 0.63537
        },
        "nist": 5.975979193782544,
        "bleurt": 0.22397,
        "bertscore": {
            "precision": 0.93988,
            "recall": 0.94108,
            "f1": 0.93918
        },
        "nubia": {
            "semantic_relation": 4.34087,
            "contradiction": 5.14874,
            "irrelevancy": 18.19324,
            "logical_agreement": 76.65803,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.69992,
            "nubia_score": 0.76951
        },
        "meteor": 0.41142152503094814
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.8924071185928746,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.18615790478558614,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.794653473544342,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.037537158749660585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.19557,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.48148,
            "fmeasure": 0.34948
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "nist": 1.5652175776270818,
        "bleurt": 0.19996,
        "bertscore": {
            "precision": 0.86048,
            "recall": 0.91595,
            "f1": 0.88735
        },
        "nubia": {
            "semantic_relation": 3.96037,
            "contradiction": 0.18805,
            "irrelevancy": 41.18447,
            "logical_agreement": 58.62748,
            "grammar_ref": 5.00001,
            "grammar_hyp": 3.99765,
            "nubia_score": 0.56163
        },
        "meteor": 0.3765336700589018
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 8.0,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.8409090909090909,
        "vocab_size-1": 37,
        "unique-1": 35,
        "entropy-1": 4.967352426491768,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.40077829115106406,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.07038932789139805,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.087462841250338,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": -0.08746284125033942,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.39382,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5263157894736842
        },
        "rouge1": {
            "precision": 0.66827,
            "recall": 0.50487,
            "fmeasure": 0.56175
        },
        "rouge2": {
            "precision": 0.38587,
            "recall": 0.28669,
            "fmeasure": 0.32081
        },
        "rougeL": {
            "precision": 0.5016,
            "recall": 0.40682,
            "fmeasure": 0.43843
        },
        "rougeLsum": {
            "precision": 0.5016,
            "recall": 0.40682,
            "fmeasure": 0.43843
        },
        "nist": 3.191671130126946,
        "bleurt": -0.18939,
        "bertscore": {
            "precision": 0.90792,
            "recall": 0.86926,
            "f1": 0.8877
        },
        "nubia": {
            "semantic_relation": 3.80492,
            "contradiction": 19.36459,
            "irrelevancy": 64.27841,
            "logical_agreement": 16.357,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.32163,
            "nubia_score": 0.52557
        },
        "meteor": 0.29636278788369574
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "total_length": 293,
        "mean_pred_length": 17.235294117647058,
        "std_pred_length": 4.98856824637981,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.5938566552901023,
        "vocab_size-1": 174,
        "unique-1": 134,
        "entropy-1": 6.830439883141476,
        "distinct-2": 0.9239130434782609,
        "vocab_size-2": 255,
        "unique-2": 235,
        "entropy-2": 7.953615444089133,
        "cond_entropy-2": 0.9503663706841551,
        "distinct-3": 0.9768339768339769,
        "vocab_size-3": 253,
        "unique-3": 247,
        "entropy-3": 7.970476241354475,
        "cond_entropy-3": 0.01158455485496181,
        "total_length-nopunct": 259,
        "mean_pred_length-nopunct": 15.235294117647058,
        "std_pred_length-nopunct": 4.976762611373522,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6525096525096525,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.925563211415097,
        "distinct-2-nopunct": 0.9256198347107438,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 207,
        "entropy-2-nopunct": 7.766983536852434,
        "cond_entropy-2-nopunct": 0.8743385229410063,
        "distinct-3-nopunct": 0.9822222222222222,
        "vocab_size-3-nopunct": 221,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.778225635661439,
        "cond_entropy-3-nopunct": 0.013828565063169047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.84144,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.6122448979591837,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.78369,
            "recall": 0.81056,
            "fmeasure": 0.78901
        },
        "rouge2": {
            "precision": 0.5897,
            "recall": 0.62737,
            "fmeasure": 0.60003
        },
        "rougeL": {
            "precision": 0.7126,
            "recall": 0.7434,
            "fmeasure": 0.71955
        },
        "rougeLsum": {
            "precision": 0.7126,
            "recall": 0.7434,
            "fmeasure": 0.71955
        },
        "nist": 6.6125731324785395,
        "bleurt": 0.38798,
        "bertscore": {
            "precision": 0.9406,
            "recall": 0.94602,
            "f1": 0.9399
        },
        "nubia": {
            "semantic_relation": 4.35234,
            "contradiction": 15.45462,
            "irrelevancy": 24.07214,
            "logical_agreement": 60.47324,
            "grammar_ref": 4.21928,
            "grammar_hyp": 3.9738,
            "nubia_score": 0.80422
        },
        "meteor": 0.43373109707169727
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.73,
        "total_length": 343,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.167142829935082,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5860058309037901,
        "vocab_size-1": 201,
        "unique-1": 163,
        "entropy-1": 6.888649687381314,
        "distinct-2": 0.937888198757764,
        "vocab_size-2": 302,
        "unique-2": 290,
        "entropy-2": 8.174375350299236,
        "cond_entropy-2": 1.0992755100491174,
        "distinct-3": 0.9966777408637874,
        "vocab_size-3": 300,
        "unique-3": 299,
        "entropy-3": 8.226975158487248,
        "cond_entropy-3": 0.056876791856270176,
        "total_length-nopunct": 298,
        "mean_pred_length-nopunct": 14.19047619047619,
        "std_pred_length-nopunct": 3.580623085163326,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6577181208053692,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 7.028812604886508,
        "distinct-2-nopunct": 0.9386281588447654,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 250,
        "entropy-2-nopunct": 7.956155579571242,
        "cond_entropy-2-nopunct": 0.999536022435893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 256,
        "unique-3-nopunct": 256,
        "entropy-3-nopunct": 8.0,
        "cond_entropy-3-nopunct": 0.05286519510082409,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.24118,
        "local_recall": {
            "1": 0.25757575757575757,
            "2": 0.4574468085106383,
            "3": 0.7474226804123711
        },
        "rouge1": {
            "precision": 0.71965,
            "recall": 0.68031,
            "fmeasure": 0.69302
        },
        "rouge2": {
            "precision": 0.46385,
            "recall": 0.4499,
            "fmeasure": 0.45321
        },
        "rougeL": {
            "precision": 0.59559,
            "recall": 0.57094,
            "fmeasure": 0.57872
        },
        "rougeLsum": {
            "precision": 0.59559,
            "recall": 0.57094,
            "fmeasure": 0.57872
        },
        "nist": 6.11939897837025,
        "bleurt": 0.24659,
        "bertscore": {
            "precision": 0.92913,
            "recall": 0.92392,
            "f1": 0.9247
        },
        "nubia": {
            "semantic_relation": 4.08582,
            "contradiction": 14.85135,
            "irrelevancy": 30.95559,
            "logical_agreement": 54.19306,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.74536,
            "nubia_score": 0.70131
        },
        "meteor": 0.3668661009339081
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.58257569495584,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6964285714285714,
        "vocab_size-1": 78,
        "unique-1": 64,
        "entropy-1": 5.955337761653841,
        "distinct-2": 0.9134615384615384,
        "vocab_size-2": 95,
        "unique-2": 87,
        "entropy-2": 6.520104261389527,
        "cond_entropy-2": 0.39953705053596084,
        "distinct-3": 0.9479166666666666,
        "vocab_size-3": 91,
        "unique-3": 86,
        "entropy-3": 6.4807958340544936,
        "cond_entropy-3": -0.02428047260573311,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 12.125,
        "std_pred_length-nopunct": 3.9823830805184977,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7835051546391752,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 6.066155754446753,
        "distinct-2-nopunct": 0.9213483146067416,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.309948178133111,
        "cond_entropy-2-nopunct": 0.29177058887650453,
        "distinct-3-nopunct": 0.9506172839506173,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.241084570785849,
        "cond_entropy-3-nopunct": -0.052489755215557335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.87873,
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.7666666666666667,
            "3": 0.85
        },
        "rouge1": {
            "precision": 0.85525,
            "recall": 0.82032,
            "fmeasure": 0.8201
        },
        "rouge2": {
            "precision": 0.58542,
            "recall": 0.58129,
            "fmeasure": 0.57043
        },
        "rougeL": {
            "precision": 0.70355,
            "recall": 0.66881,
            "fmeasure": 0.66974
        },
        "rougeLsum": {
            "precision": 0.70355,
            "recall": 0.66881,
            "fmeasure": 0.66974
        },
        "nist": 5.923487933904472,
        "bleurt": 0.34886,
        "bertscore": {
            "precision": 0.94442,
            "recall": 0.93467,
            "f1": 0.93529
        },
        "nubia": {
            "semantic_relation": 4.25951,
            "contradiction": 7.04462,
            "irrelevancy": 24.44677,
            "logical_agreement": 68.50862,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.2748,
            "nubia_score": 0.70373
        },
        "meteor": 0.42694844982267444
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "total_length": 139,
        "mean_pred_length": 17.375,
        "std_pred_length": 4.608077147791691,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7266187050359713,
        "vocab_size-1": 101,
        "unique-1": 89,
        "entropy-1": 6.265930820707054,
        "distinct-2": 0.9618320610687023,
        "vocab_size-2": 126,
        "unique-2": 123,
        "entropy-2": 6.941819948102336,
        "cond_entropy-2": 0.5343981503311189,
        "distinct-3": 1.0,
        "vocab_size-3": 123,
        "unique-3": 123,
        "entropy-3": 6.942514505339227,
        "cond_entropy-3": 0.0066524794115454845,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 3.897114317029974,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7950819672131147,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.319841230899122,
        "distinct-2-nopunct": 0.956140350877193,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.727626856270016,
        "cond_entropy-2-nopunct": 0.4506555275929154,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": 0.008237987568268875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.99961,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6,
            "3": 0.7671232876712328
        },
        "rouge1": {
            "precision": 0.70009,
            "recall": 0.73314,
            "fmeasure": 0.70322
        },
        "rouge2": {
            "precision": 0.46279,
            "recall": 0.49888,
            "fmeasure": 0.4709
        },
        "rougeL": {
            "precision": 0.51571,
            "recall": 0.58344,
            "fmeasure": 0.54014
        },
        "rougeLsum": {
            "precision": 0.51571,
            "recall": 0.58344,
            "fmeasure": 0.54014
        },
        "nist": 4.925423645159763,
        "bleurt": 0.05824,
        "bertscore": {
            "precision": 0.89227,
            "recall": 0.91525,
            "f1": 0.90105
        },
        "nubia": {
            "semantic_relation": 3.89434,
            "contradiction": 10.67117,
            "irrelevancy": 38.78185,
            "logical_agreement": 50.54699,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.58349,
            "nubia_score": 0.67238
        },
        "meteor": 0.38503701349702474
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 17.833333333333332,
        "std_pred_length": 7.425556469981821,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.7009345794392523,
        "vocab_size-1": 75,
        "unique-1": 61,
        "entropy-1": 5.943484949155772,
        "distinct-2": 0.9702970297029703,
        "vocab_size-2": 98,
        "unique-2": 95,
        "entropy-2": 6.598805542157722,
        "cond_entropy-2": 0.5491633377459673,
        "distinct-3": 0.9894736842105263,
        "vocab_size-3": 94,
        "unique-3": 93,
        "entropy-3": 6.548802976752,
        "cond_entropy-3": -0.04625061126295195,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 7.023769168568493,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7395833333333334,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.906635256150706,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.425186429662996,
        "cond_entropy-2-nopunct": 0.5637729898170046,
        "distinct-3-nopunct": 0.9880952380952381,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.368507898969236,
        "cond_entropy-3-nopunct": -0.051916625931866606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.53252,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.25,
            "3": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.65005,
            "recall": 0.67094,
            "fmeasure": 0.65646
        },
        "rouge2": {
            "precision": 0.36938,
            "recall": 0.40405,
            "fmeasure": 0.38037
        },
        "rougeL": {
            "precision": 0.53577,
            "recall": 0.5922,
            "fmeasure": 0.55602
        },
        "rougeLsum": {
            "precision": 0.53577,
            "recall": 0.5922,
            "fmeasure": 0.55602
        },
        "nist": 4.122766320804085,
        "bleurt": 0.22301,
        "bertscore": {
            "precision": 0.90859,
            "recall": 0.91411,
            "f1": 0.90939
        },
        "nubia": {
            "semantic_relation": 4.12282,
            "contradiction": 20.24475,
            "irrelevancy": 39.70266,
            "logical_agreement": 40.05259,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.10099,
            "nubia_score": 0.7229
        },
        "meteor": 0.355756179434698
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.7,
        "total_length": 146,
        "mean_pred_length": 14.6,
        "std_pred_length": 4.2708313008125245,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6301369863013698,
        "vocab_size-1": 92,
        "unique-1": 78,
        "entropy-1": 5.903607394639182,
        "distinct-2": 0.9044117647058824,
        "vocab_size-2": 123,
        "unique-2": 113,
        "entropy-2": 6.869744896585351,
        "cond_entropy-2": 0.8164528746927618,
        "distinct-3": 0.9603174603174603,
        "vocab_size-3": 121,
        "unique-3": 116,
        "entropy-3": 6.897914844134847,
        "cond_entropy-3": 0.045449149507011975,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 3.6660605559646724,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6984126984126984,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 5.941022581989697,
        "distinct-2-nopunct": 0.9137931034482759,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.65444961172724,
        "cond_entropy-2-nopunct": 0.8027595591781007,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.69018460550658,
        "cond_entropy-3-nopunct": 0.05493606768503079,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.184,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.29411764705882354,
            "3": 0.7830188679245284
        },
        "rouge1": {
            "precision": 0.77001,
            "recall": 0.74177,
            "fmeasure": 0.74658
        },
        "rouge2": {
            "precision": 0.50954,
            "recall": 0.52764,
            "fmeasure": 0.51132
        },
        "rougeL": {
            "precision": 0.65888,
            "recall": 0.66112,
            "fmeasure": 0.64981
        },
        "rougeLsum": {
            "precision": 0.65888,
            "recall": 0.66112,
            "fmeasure": 0.64981
        },
        "nist": 5.848730840267367,
        "bleurt": 0.36605,
        "bertscore": {
            "precision": 0.93089,
            "recall": 0.92942,
            "f1": 0.92813
        },
        "nubia": {
            "semantic_relation": 4.62876,
            "contradiction": 0.66539,
            "irrelevancy": 23.40248,
            "logical_agreement": 75.93212,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.12153,
            "nubia_score": 0.852
        },
        "meteor": 0.4087764035459226
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 12.25,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.7040816326530612,
        "vocab_size-1": 69,
        "unique-1": 53,
        "entropy-1": 5.853187492246944,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 86,
        "unique-2": 82,
        "entropy-2": 6.402964207440774,
        "cond_entropy-2": 0.35080092424880693,
        "distinct-3": 0.975609756097561,
        "vocab_size-3": 80,
        "unique-3": 78,
        "entropy-3": 6.308771516813209,
        "cond_entropy-3": -0.0855206039067132,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 10.875,
        "std_pred_length-nopunct": 2.315032397181517,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7701149425287356,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.915652656987492,
        "distinct-2-nopunct": 0.9493670886075949,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.202514925392294,
        "cond_entropy-2-nopunct": 0.3402588090489726,
        "distinct-3-nopunct": 0.971830985915493,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.093409091335663,
        "cond_entropy-3-nopunct": -0.09769560050340705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.76118,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.1,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.77949,
            "recall": 0.73365,
            "fmeasure": 0.74447
        },
        "rouge2": {
            "precision": 0.55083,
            "recall": 0.53858,
            "fmeasure": 0.5378
        },
        "rougeL": {
            "precision": 0.69427,
            "recall": 0.65856,
            "fmeasure": 0.66506
        },
        "rougeLsum": {
            "precision": 0.69427,
            "recall": 0.65856,
            "fmeasure": 0.66506
        },
        "nist": 4.926744906875745,
        "bleurt": 0.3198,
        "bertscore": {
            "precision": 0.93821,
            "recall": 0.92407,
            "f1": 0.93039
        },
        "nubia": {
            "semantic_relation": 3.76939,
            "contradiction": 47.9797,
            "irrelevancy": 14.47857,
            "logical_agreement": 37.54173,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.2922,
            "nubia_score": 0.56539
        },
        "meteor": 0.3911457629841789
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 218,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 9.956851354162566,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 49,
        "distinct-1": 0.6559633027522935,
        "vocab_size-1": 143,
        "unique-1": 118,
        "entropy-1": 6.663477845962795,
        "distinct-2": 0.9660194174757282,
        "vocab_size-2": 199,
        "unique-2": 193,
        "entropy-2": 7.614874859696988,
        "cond_entropy-2": 0.8069160804192077,
        "distinct-3": 1.0,
        "vocab_size-3": 194,
        "unique-3": 194,
        "entropy-3": 7.599912842187102,
        "cond_entropy-3": -0.02084084220143359,
        "total_length-nopunct": 192,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 8.246211251235321,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.71875,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.710970509196047,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 175,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.432103721317642,
        "cond_entropy-2-nopunct": 0.7562330948819563,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 168,
        "unique-3-nopunct": 168,
        "entropy-3-nopunct": 7.392317422778791,
        "cond_entropy-3-nopunct": -0.03551848603803652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.33051,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5483870967741935,
            "3": 0.6826923076923077
        },
        "rouge1": {
            "precision": 0.64971,
            "recall": 0.72121,
            "fmeasure": 0.66555
        },
        "rouge2": {
            "precision": 0.40155,
            "recall": 0.46737,
            "fmeasure": 0.41795
        },
        "rougeL": {
            "precision": 0.55402,
            "recall": 0.63651,
            "fmeasure": 0.57645
        },
        "rougeLsum": {
            "precision": 0.55402,
            "recall": 0.63651,
            "fmeasure": 0.57645
        },
        "nist": 4.495317596645154,
        "bleurt": 0.19722,
        "bertscore": {
            "precision": 0.90685,
            "recall": 0.92464,
            "f1": 0.91181
        },
        "nubia": {
            "semantic_relation": 4.14295,
            "contradiction": 8.47101,
            "irrelevancy": 44.63204,
            "logical_agreement": 46.89695,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.55768,
            "nubia_score": 0.64592
        },
        "meteor": 0.3788145130965434
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "total_length": 138,
        "mean_pred_length": 19.714285714285715,
        "std_pred_length": 6.385570468179146,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.6304347826086957,
        "vocab_size-1": 87,
        "unique-1": 67,
        "entropy-1": 6.055340942550228,
        "distinct-2": 0.9083969465648855,
        "vocab_size-2": 119,
        "unique-2": 107,
        "entropy-2": 6.850216894667222,
        "cond_entropy-2": 0.701141602080292,
        "distinct-3": 0.9435483870967742,
        "vocab_size-3": 117,
        "unique-3": 110,
        "entropy-3": 6.84129308458041,
        "cond_entropy-3": 0.0014184701397475913,
        "total_length-nopunct": 124,
        "mean_pred_length-nopunct": 17.714285714285715,
        "std_pred_length-nopunct": 5.547567953985029,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6774193548387096,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.065663524058435,
        "distinct-2-nopunct": 0.905982905982906,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.682330531549198,
        "cond_entropy-2-nopunct": 0.6612800801770872,
        "distinct-3-nopunct": 0.9454545454545454,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.6722688044337595,
        "cond_entropy-3-nopunct": -0.007186824240562892,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.55454,
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.5714285714285714,
            "3": 0.8111111111111111
        },
        "rouge1": {
            "precision": 0.75873,
            "recall": 0.76485,
            "fmeasure": 0.75638
        },
        "rouge2": {
            "precision": 0.53932,
            "recall": 0.5735,
            "fmeasure": 0.55199
        },
        "rougeL": {
            "precision": 0.61865,
            "recall": 0.63846,
            "fmeasure": 0.62479
        },
        "rougeLsum": {
            "precision": 0.61865,
            "recall": 0.63846,
            "fmeasure": 0.62479
        },
        "nist": 5.52880639328575,
        "bleurt": 0.30212,
        "bertscore": {
            "precision": 0.93238,
            "recall": 0.93955,
            "f1": 0.93307
        },
        "nubia": {
            "semantic_relation": 4.24856,
            "contradiction": 0.55391,
            "irrelevancy": 44.5124,
            "logical_agreement": 54.93369,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.42885,
            "nubia_score": 0.78347
        },
        "meteor": 0.4319546141200542
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.735,
        "total_length": 255,
        "mean_pred_length": 18.214285714285715,
        "std_pred_length": 6.794730851692271,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6039215686274509,
        "vocab_size-1": 154,
        "unique-1": 120,
        "entropy-1": 6.6206800910888095,
        "distinct-2": 0.9128630705394191,
        "vocab_size-2": 220,
        "unique-2": 206,
        "entropy-2": 7.704322271887706,
        "cond_entropy-2": 0.9422664875705528,
        "distinct-3": 0.986784140969163,
        "vocab_size-3": 224,
        "unique-3": 221,
        "entropy-3": 7.800116769229221,
        "cond_entropy-3": 0.09984709161817948,
        "total_length-nopunct": 236,
        "mean_pred_length-nopunct": 16.857142857142858,
        "std_pred_length-nopunct": 6.833291853200799,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6440677966101694,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.673430787547754,
        "distinct-2-nopunct": 0.9099099099099099,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.57700747668122,
        "cond_entropy-2-nopunct": 0.9565453677999248,
        "distinct-3-nopunct": 0.9855769230769231,
        "vocab_size-3-nopunct": 205,
        "unique-3-nopunct": 202,
        "entropy-3-nopunct": 7.671593564294913,
        "cond_entropy-3-nopunct": 0.10921934461065189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.94339,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.4230769230769231,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.69197,
            "recall": 0.77937,
            "fmeasure": 0.71546
        },
        "rouge2": {
            "precision": 0.44815,
            "recall": 0.50422,
            "fmeasure": 0.46204
        },
        "rougeL": {
            "precision": 0.58676,
            "recall": 0.64992,
            "fmeasure": 0.60039
        },
        "rougeLsum": {
            "precision": 0.58676,
            "recall": 0.64992,
            "fmeasure": 0.60039
        },
        "nist": 5.043597219410258,
        "bleurt": 0.08221,
        "bertscore": {
            "precision": 0.90269,
            "recall": 0.92399,
            "f1": 0.91218
        },
        "nubia": {
            "semantic_relation": 4.28421,
            "contradiction": 10.15224,
            "irrelevancy": 35.85236,
            "logical_agreement": 53.99539,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.70906,
            "nubia_score": 0.69066
        },
        "meteor": 0.38246171227457226
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "total_length": 169,
        "mean_pred_length": 21.125,
        "std_pred_length": 9.93022532473458,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 45,
        "distinct-1": 0.6094674556213018,
        "vocab_size-1": 103,
        "unique-1": 81,
        "entropy-1": 6.221670576979052,
        "distinct-2": 0.9254658385093167,
        "vocab_size-2": 149,
        "unique-2": 141,
        "entropy-2": 7.160048710385864,
        "cond_entropy-2": 0.8479040394591516,
        "distinct-3": 0.9869281045751634,
        "vocab_size-3": 151,
        "unique-3": 149,
        "entropy-3": 7.231244051842958,
        "cond_entropy-3": 0.08012962473703411,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 18.75,
        "std_pred_length-nopunct": 7.964766161036995,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.66,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.2010394788727705,
        "distinct-2-nopunct": 0.9366197183098591,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.003585939911988,
        "cond_entropy-2-nopunct": 0.8281610469002126,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.06608919045778,
        "cond_entropy-3-nopunct": 0.0712292911184896,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.90989,
        "local_recall": {
            "1": 0.39285714285714285,
            "2": 0.72,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.8456,
            "recall": 0.81015,
            "fmeasure": 0.82031
        },
        "rouge2": {
            "precision": 0.58892,
            "recall": 0.57087,
            "fmeasure": 0.57438
        },
        "rougeL": {
            "precision": 0.71549,
            "recall": 0.71353,
            "fmeasure": 0.70866
        },
        "rougeLsum": {
            "precision": 0.71549,
            "recall": 0.71353,
            "fmeasure": 0.70866
        },
        "nist": 6.410239542861087,
        "bleurt": 0.22977,
        "bertscore": {
            "precision": 0.94914,
            "recall": 0.94323,
            "f1": 0.94594
        },
        "nubia": {
            "semantic_relation": 4.54562,
            "contradiction": 0.85038,
            "irrelevancy": 40.35034,
            "logical_agreement": 58.79927,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.87509,
            "nubia_score": 0.82445
        },
        "meteor": 0.4231769062860819
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "total_length": 168,
        "mean_pred_length": 16.8,
        "std_pred_length": 4.6000000000000005,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6547619047619048,
        "vocab_size-1": 110,
        "unique-1": 90,
        "entropy-1": 6.2744886037481695,
        "distinct-2": 0.9620253164556962,
        "vocab_size-2": 152,
        "unique-2": 148,
        "entropy-2": 7.21517315324041,
        "cond_entropy-2": 0.8011845953240949,
        "distinct-3": 0.9932432432432432,
        "vocab_size-3": 147,
        "unique-3": 146,
        "entropy-3": 7.195939852115433,
        "cond_entropy-3": -0.013246301467072032,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.381780460041329,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.275709889336991,
        "distinct-2-nopunct": 0.9571428571428572,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.029283016944978,
        "cond_entropy-2-nopunct": 0.8073666134050265,
        "distinct-3-nopunct": 0.9923076923076923,
        "vocab_size-3-nopunct": 129,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.00698319764384,
        "cond_entropy-3-nopunct": -0.014607511608819887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.4991,
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.3870967741935484,
            "3": 0.8163265306122449
        },
        "rouge1": {
            "precision": 0.70703,
            "recall": 0.73464,
            "fmeasure": 0.70191
        },
        "rouge2": {
            "precision": 0.44562,
            "recall": 0.47769,
            "fmeasure": 0.44975
        },
        "rougeL": {
            "precision": 0.60152,
            "recall": 0.62509,
            "fmeasure": 0.59817
        },
        "rougeLsum": {
            "precision": 0.60152,
            "recall": 0.62509,
            "fmeasure": 0.59817
        },
        "nist": 5.413348514929101,
        "bleurt": 0.24764,
        "bertscore": {
            "precision": 0.91133,
            "recall": 0.91366,
            "f1": 0.90874
        },
        "nubia": {
            "semantic_relation": 4.118,
            "contradiction": 1.10201,
            "irrelevancy": 57.1435,
            "logical_agreement": 41.7545,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.4016,
            "nubia_score": 0.68781
        },
        "meteor": 0.395447709096789
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 142,
        "mean_pred_length": 17.75,
        "std_pred_length": 6.2599920127744575,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.6971830985915493,
        "vocab_size-1": 99,
        "unique-1": 88,
        "entropy-1": 6.192069789349471,
        "distinct-2": 0.9701492537313433,
        "vocab_size-2": 130,
        "unique-2": 127,
        "entropy-2": 7.000754209098351,
        "cond_entropy-2": 0.6867547081163514,
        "distinct-3": 1.0,
        "vocab_size-3": 126,
        "unique-3": 126,
        "entropy-3": 6.977279923499926,
        "cond_entropy-3": -0.019326032813701467,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.361902647381804,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.250466429498807,
        "distinct-2-nopunct": 0.9732142857142857,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.747043426502561,
        "cond_entropy-2-nopunct": 0.5434644374401889,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.7004397181411,
        "cond_entropy-3-nopunct": -0.04196436254955577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.18366,
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.5625,
            "3": 0.9270833333333334
        },
        "rouge1": {
            "precision": 0.90995,
            "recall": 0.90035,
            "fmeasure": 0.90276
        },
        "rouge2": {
            "precision": 0.71527,
            "recall": 0.70361,
            "fmeasure": 0.70742
        },
        "rougeL": {
            "precision": 0.71788,
            "recall": 0.70302,
            "fmeasure": 0.70846
        },
        "rougeLsum": {
            "precision": 0.71788,
            "recall": 0.70302,
            "fmeasure": 0.70846
        },
        "nist": 6.2884886740577475,
        "bleurt": 0.35045,
        "bertscore": {
            "precision": 0.95976,
            "recall": 0.96528,
            "f1": 0.96153
        },
        "nubia": {
            "semantic_relation": 4.35607,
            "contradiction": 7.26591,
            "irrelevancy": 11.68004,
            "logical_agreement": 81.05405,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.10161,
            "nubia_score": 0.75424
        },
        "meteor": 0.4927891942452009
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "total_length": 122,
        "mean_pred_length": 13.555555555555555,
        "std_pred_length": 4.524282904778296,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.7049180327868853,
        "vocab_size-1": 86,
        "unique-1": 76,
        "entropy-1": 6.028989235363349,
        "distinct-2": 0.9734513274336283,
        "vocab_size-2": 110,
        "unique-2": 107,
        "entropy-2": 6.767081617282463,
        "cond_entropy-2": 0.5574411244572932,
        "distinct-3": 1.0,
        "vocab_size-3": 104,
        "unique-3": 104,
        "entropy-3": 6.7004397181411,
        "cond_entropy-3": -0.062046936581788045,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 12.222222222222221,
        "std_pred_length-nopunct": 4.262961354055751,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7454545454545455,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.040596591203174,
        "distinct-2-nopunct": 0.9702970297029703,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.598805542157719,
        "cond_entropy-2-nopunct": 0.6242175460129175,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.523561956057027,
        "cond_entropy-3-nopunct": -0.06943213539043404,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.05455,
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.35714285714285715,
            "3": 0.6623376623376623
        },
        "rouge1": {
            "precision": 0.70564,
            "recall": 0.6729,
            "fmeasure": 0.66164
        },
        "rouge2": {
            "precision": 0.39699,
            "recall": 0.41249,
            "fmeasure": 0.38605
        },
        "rougeL": {
            "precision": 0.63608,
            "recall": 0.61582,
            "fmeasure": 0.59999
        },
        "rougeLsum": {
            "precision": 0.63608,
            "recall": 0.61582,
            "fmeasure": 0.59999
        },
        "nist": 3.7017118720793,
        "bleurt": 0.18318,
        "bertscore": {
            "precision": 0.91069,
            "recall": 0.89968,
            "f1": 0.90395
        },
        "nubia": {
            "semantic_relation": 3.89796,
            "contradiction": 14.37033,
            "irrelevancy": 33.79582,
            "logical_agreement": 51.83385,
            "grammar_ref": 5.16318,
            "grammar_hyp": 5.12749,
            "nubia_score": 0.59794
        },
        "meteor": 0.3108996639405173
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.19067,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.52222,
            "fmeasure": 0.63179
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.25714,
            "fmeasure": 0.31522
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.52222,
            "fmeasure": 0.63179
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.52222,
            "fmeasure": 0.63179
        },
        "nist": 0.4977396409522949,
        "bleurt": 0.20829,
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.90851,
            "f1": 0.91562
        },
        "nubia": {
            "semantic_relation": 4.39989,
            "contradiction": 0.38434,
            "irrelevancy": 0.57436,
            "logical_agreement": 99.0413,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.15597,
            "nubia_score": 0.89505
        },
        "meteor": 0.21952403715545904
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.71167,
        "msttr-100_nopunct": 0.76,
        "total_length": 686,
        "mean_pred_length": 18.54054054054054,
        "std_pred_length": 7.779371872769866,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 48,
        "distinct-1": 0.5612244897959183,
        "vocab_size-1": 385,
        "unique-1": 313,
        "entropy-1": 7.669656292987065,
        "distinct-2": 0.9183359013867488,
        "vocab_size-2": 596,
        "unique-2": 559,
        "entropy-2": 9.147561831392808,
        "cond_entropy-2": 1.280816692457486,
        "distinct-3": 0.9820261437908496,
        "vocab_size-3": 601,
        "unique-3": 590,
        "entropy-3": 9.221440130274424,
        "cond_entropy-3": 0.0791021141665971,
        "total_length-nopunct": 609,
        "mean_pred_length-nopunct": 16.45945945945946,
        "std_pred_length-nopunct": 6.696487964535386,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6223316912972086,
        "vocab_size-1-nopunct": 379,
        "unique-1-nopunct": 311,
        "entropy-1-nopunct": 7.86081447667669,
        "distinct-2-nopunct": 0.9178321678321678,
        "vocab_size-2-nopunct": 525,
        "unique-2-nopunct": 494,
        "entropy-2-nopunct": 8.960153100838708,
        "cond_entropy-2-nopunct": 1.1654678957088451,
        "distinct-3-nopunct": 0.983177570093458,
        "vocab_size-3-nopunct": 526,
        "unique-3-nopunct": 517,
        "entropy-3-nopunct": 9.029750221475428,
        "cond_entropy-3-nopunct": 0.083409409851293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.74387,
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.5102040816326531,
            "3": 0.7463768115942029
        },
        "rouge1": {
            "precision": 0.71049,
            "recall": 0.74892,
            "fmeasure": 0.7201
        },
        "rouge2": {
            "precision": 0.48751,
            "recall": 0.51129,
            "fmeasure": 0.49166
        },
        "rougeL": {
            "precision": 0.60893,
            "recall": 0.63897,
            "fmeasure": 0.615
        },
        "rougeLsum": {
            "precision": 0.60893,
            "recall": 0.63897,
            "fmeasure": 0.615
        },
        "nist": 6.131730788613283,
        "bleurt": 0.2314,
        "bertscore": {
            "precision": 0.92533,
            "recall": 0.92777,
            "f1": 0.92504
        },
        "nubia": {
            "semantic_relation": 4.09834,
            "contradiction": 9.92728,
            "irrelevancy": 44.59988,
            "logical_agreement": 45.47284,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.62147,
            "nubia_score": 0.71759
        },
        "meteor": 0.39357189010264876
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.725480556997868,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 0.9375,
        "vocab_size-3": 15,
        "unique-3": 14,
        "entropy-3": 3.875,
        "cond_entropy-3": 0.037537158749660585,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6168746059562227,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.75,
        "cond_entropy-2-nopunct": 0.1625371587496606,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.773557262275185,
        "cond_entropy-3-nopunct": 0.04022392894185189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.37855,
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.51692,
            "fmeasure": 0.54199
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.33333,
            "fmeasure": 0.34815
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.39286,
            "fmeasure": 0.46809
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.39286,
            "fmeasure": 0.46809
        },
        "nist": 1.5645761763065238,
        "bleurt": -0.30715,
        "bertscore": {
            "precision": 0.88789,
            "recall": 0.87049,
            "f1": 0.87453
        },
        "nubia": {
            "semantic_relation": 3.30216,
            "contradiction": 9.47358,
            "irrelevancy": 6.33994,
            "logical_agreement": 84.18649,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.42297,
            "nubia_score": 0.369
        },
        "meteor": 0.3448380771142934
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.765,
        "total_length": 314,
        "mean_pred_length": 17.444444444444443,
        "std_pred_length": 6.833107494009687,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.6146496815286624,
        "vocab_size-1": 193,
        "unique-1": 165,
        "entropy-1": 6.918899031740484,
        "distinct-2": 0.9256756756756757,
        "vocab_size-2": 274,
        "unique-2": 261,
        "entropy-2": 8.027782968632907,
        "cond_entropy-2": 0.9389661696044994,
        "distinct-3": 0.9928057553956835,
        "vocab_size-3": 276,
        "unique-3": 274,
        "entropy-3": 8.10455258351483,
        "cond_entropy-3": 0.07142853446381608,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 5.580223014261069,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6886446886446886,
        "vocab_size-1-nopunct": 188,
        "unique-1-nopunct": 164,
        "entropy-1-nopunct": 7.020672385601239,
        "distinct-2-nopunct": 0.9294117647058824,
        "vocab_size-2-nopunct": 237,
        "unique-2-nopunct": 227,
        "entropy-2-nopunct": 7.817806181922973,
        "cond_entropy-2-nopunct": 0.8649672300304616,
        "distinct-3-nopunct": 0.9915611814345991,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 233,
        "entropy-3-nopunct": 7.8718656117675,
        "cond_entropy-3-nopunct": 0.06324867283540905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.07616,
        "local_recall": {
            "1": 0.2,
            "2": 0.3,
            "3": 0.7373737373737373
        },
        "rouge1": {
            "precision": 0.7141,
            "recall": 0.70599,
            "fmeasure": 0.69629
        },
        "rouge2": {
            "precision": 0.51982,
            "recall": 0.53456,
            "fmeasure": 0.51666
        },
        "rougeL": {
            "precision": 0.60941,
            "recall": 0.60991,
            "fmeasure": 0.59778
        },
        "rougeLsum": {
            "precision": 0.60941,
            "recall": 0.60991,
            "fmeasure": 0.59778
        },
        "nist": 5.807734955881925,
        "bleurt": 0.16004,
        "bertscore": {
            "precision": 0.90618,
            "recall": 0.90775,
            "f1": 0.90234
        },
        "nubia": {
            "semantic_relation": 3.98397,
            "contradiction": 10.45428,
            "irrelevancy": 28.39293,
            "logical_agreement": 61.15279,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.25862,
            "nubia_score": 0.69958
        },
        "meteor": 0.39528253820806564
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.73,
        "total_length": 201,
        "mean_pred_length": 15.461538461538462,
        "std_pred_length": 6.4880408873721676,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5920398009950248,
        "vocab_size-1": 119,
        "unique-1": 97,
        "entropy-1": 6.250454007443415,
        "distinct-2": 0.925531914893617,
        "vocab_size-2": 174,
        "unique-2": 166,
        "entropy-2": 7.360937937015068,
        "cond_entropy-2": 0.9440592269217063,
        "distinct-3": 0.9942857142857143,
        "vocab_size-3": 174,
        "unique-3": 173,
        "entropy-3": 7.439782540403735,
        "cond_entropy-3": 0.0932300999065011,
        "total_length-nopunct": 168,
        "mean_pred_length-nopunct": 12.923076923076923,
        "std_pred_length-nopunct": 5.4696581029634395,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6904761904761905,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.480659592445023,
        "distinct-2-nopunct": 0.9225806451612903,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.0670510378125355,
        "cond_entropy-2-nopunct": 0.6499498440406706,
        "distinct-3-nopunct": 0.9929577464788732,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.135662612462435,
        "cond_entropy-3-nopunct": 0.0877520942062663,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.73046,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.058823529411764705,
            "3": 0.7973856209150327
        },
        "rouge1": {
            "precision": 0.77121,
            "recall": 0.7431,
            "fmeasure": 0.75031
        },
        "rouge2": {
            "precision": 0.55802,
            "recall": 0.55237,
            "fmeasure": 0.55245
        },
        "rougeL": {
            "precision": 0.60217,
            "recall": 0.58121,
            "fmeasure": 0.58669
        },
        "rougeLsum": {
            "precision": 0.60217,
            "recall": 0.58121,
            "fmeasure": 0.58669
        },
        "nist": 5.604311494689667,
        "bleurt": 0.4015,
        "bertscore": {
            "precision": 0.93062,
            "recall": 0.92566,
            "f1": 0.92765
        },
        "nubia": {
            "semantic_relation": 4.18137,
            "contradiction": 3.7555,
            "irrelevancy": 24.58865,
            "logical_agreement": 71.65585,
            "grammar_ref": 4.72277,
            "grammar_hyp": 5.00285,
            "nubia_score": 0.74349
        },
        "meteor": 0.411459820053707
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 6.018490028422596,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7547169811320755,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.103025822888409,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.48322629474353096,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8222222222222222,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.039308030183001,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.3853340401776634,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.61021,
        "local_recall": {
            "1": 0.75,
            "2": 0.16666666666666666,
            "3": 0.8787878787878788
        },
        "rouge1": {
            "precision": 0.78077,
            "recall": 0.82706,
            "fmeasure": 0.80185
        },
        "rouge2": {
            "precision": 0.52899,
            "recall": 0.56112,
            "fmeasure": 0.54363
        },
        "rougeL": {
            "precision": 0.61125,
            "recall": 0.64412,
            "fmeasure": 0.62629
        },
        "rougeLsum": {
            "precision": 0.61125,
            "recall": 0.64412,
            "fmeasure": 0.62629
        },
        "nist": 4.493489359873862,
        "bleurt": 0.49812,
        "bertscore": {
            "precision": 0.94617,
            "recall": 0.96026,
            "f1": 0.9517
        },
        "nubia": {
            "semantic_relation": 4.63141,
            "contradiction": 0.66773,
            "irrelevancy": 43.7928,
            "logical_agreement": 55.53947,
            "grammar_ref": 5.15044,
            "grammar_hyp": 4.83965,
            "nubia_score": 0.87603
        },
        "meteor": 0.44080903157428164
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.28642554229237843,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.175735869100492,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.2995060262166482,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.7654,
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.47041,
            "fmeasure": 0.53444
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.18773,
            "fmeasure": 0.21437
        },
        "rougeL": {
            "precision": 0.39683,
            "recall": 0.36508,
            "fmeasure": 0.37897
        },
        "rougeLsum": {
            "precision": 0.39683,
            "recall": 0.36508,
            "fmeasure": 0.37897
        },
        "nist": 2.0756148866956705,
        "bleurt": -0.36501,
        "bertscore": {
            "precision": 0.8276,
            "recall": 0.8255,
            "f1": 0.82655
        },
        "nubia": {
            "semantic_relation": 3.03349,
            "contradiction": 0.10373,
            "irrelevancy": 99.74484,
            "logical_agreement": 0.15143,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.43122,
            "nubia_score": 0.43744
        },
        "meteor": 0.22360489106421885
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.725,
        "total_length": 283,
        "mean_pred_length": 15.722222222222221,
        "std_pred_length": 4.305107503568749,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5653710247349824,
        "vocab_size-1": 160,
        "unique-1": 127,
        "entropy-1": 6.5825225214477,
        "distinct-2": 0.8981132075471698,
        "vocab_size-2": 238,
        "unique-2": 223,
        "entropy-2": 7.782701426735531,
        "cond_entropy-2": 1.0230460485291906,
        "distinct-3": 0.97165991902834,
        "vocab_size-3": 240,
        "unique-3": 235,
        "entropy-3": 7.885574620231158,
        "cond_entropy-3": 0.12234140486749366,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 3.7749172176353745,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6345381526104418,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 127,
        "entropy-1-nopunct": 6.743031011884316,
        "distinct-2-nopunct": 0.8874458874458875,
        "vocab_size-2-nopunct": 205,
        "unique-2-nopunct": 191,
        "entropy-2-nopunct": 7.553939571634769,
        "cond_entropy-2-nopunct": 0.8815601357789957,
        "distinct-3-nopunct": 0.971830985915493,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.671283446496645,
        "cond_entropy-3-nopunct": 0.13781603662735867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.04469,
        "local_recall": {
            "1": 0.19318181818181818,
            "2": 0.5423728813559322,
            "3": 0.7577639751552795
        },
        "rouge1": {
            "precision": 0.75203,
            "recall": 0.74642,
            "fmeasure": 0.73446
        },
        "rouge2": {
            "precision": 0.50041,
            "recall": 0.50648,
            "fmeasure": 0.49321
        },
        "rougeL": {
            "precision": 0.62019,
            "recall": 0.61359,
            "fmeasure": 0.60577
        },
        "rougeLsum": {
            "precision": 0.62019,
            "recall": 0.61359,
            "fmeasure": 0.60577
        },
        "nist": 6.005164513916578,
        "bleurt": 0.23745,
        "bertscore": {
            "precision": 0.92356,
            "recall": 0.92582,
            "f1": 0.92182
        },
        "nubia": {
            "semantic_relation": 4.39461,
            "contradiction": 3.0604,
            "irrelevancy": 35.79597,
            "logical_agreement": 61.14362,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.57744,
            "nubia_score": 0.79458
        },
        "meteor": 0.3861648559263714
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.745,
        "total_length": 331,
        "mean_pred_length": 19.470588235294116,
        "std_pred_length": 7.941830038464787,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.56797583081571,
        "vocab_size-1": 188,
        "unique-1": 143,
        "entropy-1": 6.924334249072403,
        "distinct-2": 0.9012738853503185,
        "vocab_size-2": 283,
        "unique-2": 259,
        "entropy-2": 8.075656139012146,
        "cond_entropy-2": 1.0083318752270676,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 288,
        "unique-3": 279,
        "entropy-3": 8.153713060194734,
        "cond_entropy-3": 0.0771222355527876,
        "total_length-nopunct": 287,
        "mean_pred_length-nopunct": 16.88235294117647,
        "std_pred_length-nopunct": 6.542911323051451,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6376306620209059,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 7.013471249360376,
        "distinct-2-nopunct": 0.8962962962962963,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.844390087783571,
        "cond_entropy-2-nopunct": 0.884898121809677,
        "distinct-3-nopunct": 0.9683794466403162,
        "vocab_size-3-nopunct": 245,
        "unique-3-nopunct": 237,
        "entropy-3-nopunct": 7.919752467974908,
        "cond_entropy-3-nopunct": 0.08702733535954037,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.52183,
        "local_recall": {
            "1": 0.24,
            "2": 0.47619047619047616,
            "3": 0.8301886792452831
        },
        "rouge1": {
            "precision": 0.75946,
            "recall": 0.80663,
            "fmeasure": 0.77134
        },
        "rouge2": {
            "precision": 0.53017,
            "recall": 0.57201,
            "fmeasure": 0.54047
        },
        "rougeL": {
            "precision": 0.65739,
            "recall": 0.70151,
            "fmeasure": 0.66865
        },
        "rougeLsum": {
            "precision": 0.65739,
            "recall": 0.70151,
            "fmeasure": 0.66865
        },
        "nist": 6.4196321846412685,
        "bleurt": 0.26869,
        "bertscore": {
            "precision": 0.9279,
            "recall": 0.94052,
            "f1": 0.93047
        },
        "nubia": {
            "semantic_relation": 4.31232,
            "contradiction": 3.91497,
            "irrelevancy": 41.45066,
            "logical_agreement": 54.63437,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.45015,
            "nubia_score": 0.77004
        },
        "meteor": 0.4351261053762648
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.454211490264017,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7564102564102564,
        "vocab_size-1": 59,
        "unique-1": 51,
        "entropy-1": 5.610669007540577,
        "distinct-2": 0.9726027397260274,
        "vocab_size-2": 71,
        "unique-2": 69,
        "entropy-2": 6.135030038332083,
        "cond_entropy-2": 0.41153946342398584,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.04353818821791301,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 4.166533331199932,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7887323943661971,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.572006978537724,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.983788058752401,
        "cond_entropy-2-nopunct": 0.45554927271216333,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.04808301130376398,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.63343,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3333333333333333,
            "3": 0.88
        },
        "rouge1": {
            "precision": 0.76717,
            "recall": 0.80603,
            "fmeasure": 0.77805
        },
        "rouge2": {
            "precision": 0.52225,
            "recall": 0.56203,
            "fmeasure": 0.53416
        },
        "rougeL": {
            "precision": 0.63172,
            "recall": 0.69129,
            "fmeasure": 0.65232
        },
        "rougeLsum": {
            "precision": 0.63172,
            "recall": 0.69129,
            "fmeasure": 0.65232
        },
        "nist": 5.35902317522514,
        "bleurt": 0.41917,
        "bertscore": {
            "precision": 0.95379,
            "recall": 0.94426,
            "f1": 0.94896
        },
        "nubia": {
            "semantic_relation": 4.63141,
            "contradiction": 2.87385,
            "irrelevancy": 11.51966,
            "logical_agreement": 85.60649,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.89803,
            "nubia_score": 0.81023
        },
        "meteor": 0.4471142333751731
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1986532337201607,
        "bleurt": 0.99035,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 195,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.1622776601683795,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.6410256410256411,
        "vocab_size-1": 125,
        "unique-1": 104,
        "entropy-1": 6.497076338304596,
        "distinct-2": 0.945054945054945,
        "vocab_size-2": 172,
        "unique-2": 166,
        "entropy-2": 7.378620052262851,
        "cond_entropy-2": 0.6965304466228331,
        "distinct-3": 0.9940828402366864,
        "vocab_size-3": 168,
        "unique-3": 167,
        "entropy-3": 7.389045116755549,
        "cond_entropy-3": 0.02036157125702032,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 13.153846153846153,
        "std_pred_length-nopunct": 2.983187604563895,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7134502923976608,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.627358199522878,
        "distinct-2-nopunct": 0.9430379746835443,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.167642931694036,
        "cond_entropy-2-nopunct": 0.5989962897642941,
        "distinct-3-nopunct": 0.993103448275862,
        "vocab_size-3-nopunct": 144,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.166115986566681,
        "cond_entropy-3-nopunct": 0.01067851428146566,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.139,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.18181818181818182,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.81526,
            "recall": 0.84585,
            "fmeasure": 0.81964
        },
        "rouge2": {
            "precision": 0.58457,
            "recall": 0.60456,
            "fmeasure": 0.5889
        },
        "rougeL": {
            "precision": 0.70757,
            "recall": 0.72149,
            "fmeasure": 0.70529
        },
        "rougeLsum": {
            "precision": 0.70757,
            "recall": 0.72149,
            "fmeasure": 0.70529
        },
        "nist": 6.330149895723001,
        "bleurt": 0.51372,
        "bertscore": {
            "precision": 0.95533,
            "recall": 0.9545,
            "f1": 0.95424
        },
        "nubia": {
            "semantic_relation": 4.62533,
            "contradiction": 0.26879,
            "irrelevancy": 17.09577,
            "logical_agreement": 82.63544,
            "grammar_ref": 5.1809,
            "grammar_hyp": 4.98883,
            "nubia_score": 0.86724
        },
        "meteor": 0.4561002039968663
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 9.5,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.926427859887888,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.24837547109102542,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 9.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.2875371587496607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.77061,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.59295,
            "recall": 0.71082,
            "fmeasure": 0.6354
        },
        "rouge2": {
            "precision": 0.25238,
            "recall": 0.3494,
            "fmeasure": 0.28712
        },
        "rougeL": {
            "precision": 0.40224,
            "recall": 0.51597,
            "fmeasure": 0.44326
        },
        "rougeLsum": {
            "precision": 0.40224,
            "recall": 0.51597,
            "fmeasure": 0.44326
        },
        "nist": 2.8556792799264445,
        "bleurt": -0.0841,
        "bertscore": {
            "precision": 0.89919,
            "recall": 0.93228,
            "f1": 0.91513
        },
        "nubia": {
            "semantic_relation": 3.61046,
            "contradiction": 14.76055,
            "irrelevancy": 71.92982,
            "logical_agreement": 13.30963,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.94467,
            "nubia_score": 0.5075
        },
        "meteor": 0.3527938927160939
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.77,
        "total_length": 337,
        "mean_pred_length": 15.318181818181818,
        "std_pred_length": 5.903668841078738,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5816023738872403,
        "vocab_size-1": 196,
        "unique-1": 154,
        "entropy-1": 6.979293732653936,
        "distinct-2": 0.8793650793650793,
        "vocab_size-2": 277,
        "unique-2": 247,
        "entropy-2": 8.03721016120317,
        "cond_entropy-2": 0.8454508649225703,
        "distinct-3": 0.9419795221843004,
        "vocab_size-3": 276,
        "unique-3": 259,
        "entropy-3": 8.078715898790897,
        "cond_entropy-3": 0.03812370808553987,
        "total_length-nopunct": 290,
        "mean_pred_length-nopunct": 13.181818181818182,
        "std_pred_length-nopunct": 5.005781781067711,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6551724137931034,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.106503928682676,
        "distinct-2-nopunct": 0.8955223880597015,
        "vocab_size-2-nopunct": 240,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.838404302365747,
        "cond_entropy-2-nopunct": 0.7656789972841841,
        "distinct-3-nopunct": 0.9552845528455285,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.853083611030333,
        "cond_entropy-3-nopunct": 0.009960375886392321,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.67172,
        "local_recall": {
            "1": 0.11904761904761904,
            "2": 0.2777777777777778,
            "3": 0.8774703557312253
        },
        "rouge1": {
            "precision": 0.86548,
            "recall": 0.84857,
            "fmeasure": 0.85224
        },
        "rouge2": {
            "precision": 0.69573,
            "recall": 0.68843,
            "fmeasure": 0.68852
        },
        "rougeL": {
            "precision": 0.81412,
            "recall": 0.80168,
            "fmeasure": 0.80342
        },
        "rougeLsum": {
            "precision": 0.81412,
            "recall": 0.80168,
            "fmeasure": 0.80342
        },
        "nist": 6.910054610912254,
        "bleurt": 0.4787,
        "bertscore": {
            "precision": 0.95794,
            "recall": 0.9577,
            "f1": 0.95729
        },
        "nubia": {
            "semantic_relation": 4.5809,
            "contradiction": 1.8631,
            "irrelevancy": 24.07821,
            "logical_agreement": 74.05869,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.50082,
            "nubia_score": 0.84712
        },
        "meteor": 0.4973837519990264
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 203,
        "mean_pred_length": 18.454545454545453,
        "std_pred_length": 5.176233034722458,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 31,
        "distinct-1": 0.6945812807881774,
        "vocab_size-1": 141,
        "unique-1": 123,
        "entropy-1": 6.640137795778583,
        "distinct-2": 0.9791666666666666,
        "vocab_size-2": 188,
        "unique-2": 185,
        "entropy-2": 7.5393641283140775,
        "cond_entropy-2": 0.7597650384233005,
        "distinct-3": 1.0,
        "vocab_size-3": 181,
        "unique-3": 181,
        "entropy-3": 7.499845887083174,
        "cond_entropy-3": -0.03674706942710294,
        "total_length-nopunct": 178,
        "mean_pred_length-nopunct": 16.181818181818183,
        "std_pred_length-nopunct": 4.706246947470831,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7696629213483146,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.7294289933728075,
        "distinct-2-nopunct": 0.9820359281437125,
        "vocab_size-2-nopunct": 164,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.343255864317361,
        "cond_entropy-2-nopunct": 0.6510086003668887,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 156,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.285402218862266,
        "cond_entropy-3-nopunct": -0.05500151270049943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.82708,
        "local_recall": {
            "1": 0.1875,
            "2": 0.42105263157894735,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.74819,
            "recall": 0.79187,
            "fmeasure": 0.75218
        },
        "rouge2": {
            "precision": 0.55722,
            "recall": 0.58883,
            "fmeasure": 0.55871
        },
        "rougeL": {
            "precision": 0.66185,
            "recall": 0.68474,
            "fmeasure": 0.65851
        },
        "rougeLsum": {
            "precision": 0.66185,
            "recall": 0.68474,
            "fmeasure": 0.65851
        },
        "nist": 5.588445930775956,
        "bleurt": 0.23751,
        "bertscore": {
            "precision": 0.91969,
            "recall": 0.93595,
            "f1": 0.92539
        },
        "nubia": {
            "semantic_relation": 4.22302,
            "contradiction": 9.18106,
            "irrelevancy": 31.78418,
            "logical_agreement": 59.03476,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.36813,
            "nubia_score": 0.68783
        },
        "meteor": 0.4355553029051718
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 144,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.545268253204709,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7013888888888888,
        "vocab_size-1": 101,
        "unique-1": 84,
        "entropy-1": 6.330384355681345,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 128,
        "unique-2": 122,
        "entropy-2": 6.955109900073857,
        "cond_entropy-2": 0.4976397000255345,
        "distinct-3": 0.9765625,
        "vocab_size-3": 125,
        "unique-3": 122,
        "entropy-3": 6.953125,
        "cond_entropy-3": 0.006287158749660594,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 16.125,
        "std_pred_length-nopunct": 5.109733358992424,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7596899224806202,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.380342929956155,
        "distinct-2-nopunct": 0.9504132231404959,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.80316075793576,
        "cond_entropy-2-nopunct": 0.4562647255311276,
        "distinct-3-nopunct": 0.9911504424778761,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.802479847370959,
        "cond_entropy-3-nopunct": 0.0075104154060801126,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.13924,
        "local_recall": {
            "1": 0.0625,
            "2": 0.5,
            "3": 0.8613861386138614
        },
        "rouge1": {
            "precision": 0.84142,
            "recall": 0.8929,
            "fmeasure": 0.85727
        },
        "rouge2": {
            "precision": 0.73122,
            "recall": 0.76306,
            "fmeasure": 0.73662
        },
        "rougeL": {
            "precision": 0.79791,
            "recall": 0.8595,
            "fmeasure": 0.81826
        },
        "rougeLsum": {
            "precision": 0.79791,
            "recall": 0.8595,
            "fmeasure": 0.81826
        },
        "nist": 5.965326373327717,
        "bleurt": 0.46562,
        "bertscore": {
            "precision": 0.94816,
            "recall": 0.96048,
            "f1": 0.95214
        },
        "nubia": {
            "semantic_relation": 4.60905,
            "contradiction": 0.20682,
            "irrelevancy": 30.5878,
            "logical_agreement": 69.20538,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.67314,
            "nubia_score": 0.87024
        },
        "meteor": 0.49507339984885523
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "total_length": 162,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.039570693980958,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6851851851851852,
        "vocab_size-1": 111,
        "unique-1": 98,
        "entropy-1": 6.3113363838354894,
        "distinct-2": 0.9869281045751634,
        "vocab_size-2": 151,
        "unique-2": 150,
        "entropy-2": 7.22631014660006,
        "cond_entropy-2": 0.7890083873296849,
        "distinct-3": 1.0,
        "vocab_size-3": 144,
        "unique-3": 144,
        "entropy-3": 7.169925001442332,
        "cond_entropy-3": -0.05444278915198201,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 15.444444444444445,
        "std_pred_length-nopunct": 6.550845765770522,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.762589928057554,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.335281922980737,
        "distinct-2-nopunct": 0.9846153846153847,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 6.9857917553195055,
        "cond_entropy-2-nopunct": 0.7047631580902024,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 121,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.918863237274603,
        "cond_entropy-3-nopunct": -0.06420798482688932,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.01308,
        "local_recall": {
            "1": 0.20754716981132076,
            "2": 0.42857142857142855,
            "3": 0.6901408450704225
        },
        "rouge1": {
            "precision": 0.57476,
            "recall": 0.56302,
            "fmeasure": 0.55829
        },
        "rouge2": {
            "precision": 0.33002,
            "recall": 0.33869,
            "fmeasure": 0.32582
        },
        "rougeL": {
            "precision": 0.50539,
            "recall": 0.49152,
            "fmeasure": 0.48711
        },
        "rougeLsum": {
            "precision": 0.50539,
            "recall": 0.49152,
            "fmeasure": 0.48711
        },
        "nist": 4.697005782332382,
        "bleurt": -0.0832,
        "bertscore": {
            "precision": 0.88473,
            "recall": 0.88473,
            "f1": 0.88041
        },
        "nubia": {
            "semantic_relation": 3.49284,
            "contradiction": 1.87216,
            "irrelevancy": 62.89904,
            "logical_agreement": 35.2288,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.90963,
            "nubia_score": 0.52836
        },
        "meteor": 0.3171823777629972
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.734,
        "msttr-100_nopunct": 0.766,
        "total_length": 585,
        "mean_pred_length": 18.870967741935484,
        "std_pred_length": 7.67375895391759,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.5623931623931624,
        "vocab_size-1": 329,
        "unique-1": 276,
        "entropy-1": 7.389741270759954,
        "distinct-2": 0.9115523465703971,
        "vocab_size-2": 505,
        "unique-2": 471,
        "entropy-2": 8.908600035197745,
        "cond_entropy-2": 1.3425031908511094,
        "distinct-3": 0.9751434034416826,
        "vocab_size-3": 510,
        "unique-3": 497,
        "entropy-3": 8.980953943130354,
        "cond_entropy-3": 0.07686520058349722,
        "total_length-nopunct": 518,
        "mean_pred_length-nopunct": 16.70967741935484,
        "std_pred_length-nopunct": 6.811723993741193,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6216216216216216,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 7.534286574800428,
        "distinct-2-nopunct": 0.919917864476386,
        "vocab_size-2-nopunct": 448,
        "unique-2-nopunct": 421,
        "entropy-2-nopunct": 8.74289274644105,
        "cond_entropy-2-nopunct": 1.2844956441240787,
        "distinct-3-nopunct": 0.9714912280701754,
        "vocab_size-3-nopunct": 443,
        "unique-3-nopunct": 430,
        "entropy-3-nopunct": 8.775872470305146,
        "cond_entropy-3-nopunct": 0.04554867492737247,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.24847,
        "local_recall": {
            "1": 0.17721518987341772,
            "2": 0.4888888888888889,
            "3": 0.7605633802816901
        },
        "rouge1": {
            "precision": 0.72183,
            "recall": 0.75369,
            "fmeasure": 0.72765
        },
        "rouge2": {
            "precision": 0.50279,
            "recall": 0.52978,
            "fmeasure": 0.5077
        },
        "rougeL": {
            "precision": 0.60056,
            "recall": 0.63102,
            "fmeasure": 0.60745
        },
        "rougeLsum": {
            "precision": 0.60056,
            "recall": 0.63102,
            "fmeasure": 0.60745
        },
        "nist": 6.05605044762961,
        "bleurt": 0.19414,
        "bertscore": {
            "precision": 0.91759,
            "recall": 0.92306,
            "f1": 0.91831
        },
        "nubia": {
            "semantic_relation": 4.10975,
            "contradiction": 6.34994,
            "irrelevancy": 45.32152,
            "logical_agreement": 48.32854,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.56883,
            "nubia_score": 0.69066
        },
        "meteor": 0.39137583424377614
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "total_length": 176,
        "mean_pred_length": 17.6,
        "std_pred_length": 4.294182110716778,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.5795454545454546,
        "vocab_size-1": 102,
        "unique-1": 81,
        "entropy-1": 6.079702239241306,
        "distinct-2": 0.8734939759036144,
        "vocab_size-2": 145,
        "unique-2": 129,
        "entropy-2": 7.096336645163234,
        "cond_entropy-2": 0.8996344833019871,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 153,
        "unique-3": 150,
        "entropy-3": 7.246940680400726,
        "cond_entropy-3": 0.16846959845436438,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.09878030638384,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.66,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.222087151224576,
        "distinct-2-nopunct": 0.8785714285714286,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.861356052628355,
        "cond_entropy-2-nopunct": 0.7111782970659966,
        "distinct-3-nopunct": 0.9846153846153847,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.991598582259225,
        "cond_entropy-3-nopunct": 0.15085229611677195,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.69243,
        "local_recall": {
            "1": 0.25,
            "2": 0.6923076923076923,
            "3": 0.908256880733945
        },
        "rouge1": {
            "precision": 0.86561,
            "recall": 0.87509,
            "fmeasure": 0.85718
        },
        "rouge2": {
            "precision": 0.73545,
            "recall": 0.74052,
            "fmeasure": 0.72698
        },
        "rougeL": {
            "precision": 0.74454,
            "recall": 0.79299,
            "fmeasure": 0.75646
        },
        "rougeLsum": {
            "precision": 0.74454,
            "recall": 0.79299,
            "fmeasure": 0.75646
        },
        "nist": 6.245275812358613,
        "bleurt": 0.56575,
        "bertscore": {
            "precision": 0.95963,
            "recall": 0.96351,
            "f1": 0.95968
        },
        "nubia": {
            "semantic_relation": 4.40779,
            "contradiction": 10.75936,
            "irrelevancy": 30.74723,
            "logical_agreement": 58.49341,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.67937,
            "nubia_score": 0.78278
        },
        "meteor": 0.48102503141585073
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.85,
        "total_length": 171,
        "mean_pred_length": 17.1,
        "std_pred_length": 6.1392181912683315,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.7076023391812866,
        "vocab_size-1": 121,
        "unique-1": 106,
        "entropy-1": 6.517966571646294,
        "distinct-2": 0.9627329192546584,
        "vocab_size-2": 155,
        "unique-2": 151,
        "entropy-2": 7.247005232124994,
        "cond_entropy-2": 0.5786012597552465,
        "distinct-3": 0.9933774834437086,
        "vocab_size-3": 150,
        "unique-3": 149,
        "entropy-3": 7.225159706212477,
        "cond_entropy-3": -0.016288463264194294,
        "total_length-nopunct": 153,
        "mean_pred_length-nopunct": 15.3,
        "std_pred_length-nopunct": 5.040833264451424,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7712418300653595,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.597193523145614,
        "distinct-2-nopunct": 0.965034965034965,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.0793833996852005,
        "cond_entropy-2-nopunct": 0.5283573114729229,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.055282435501199,
        "cond_entropy-3-nopunct": -0.018049239590531084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.73318,
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.5263157894736842,
            "3": 0.8316831683168316
        },
        "rouge1": {
            "precision": 0.75533,
            "recall": 0.75269,
            "fmeasure": 0.75152
        },
        "rouge2": {
            "precision": 0.54064,
            "recall": 0.52426,
            "fmeasure": 0.53099
        },
        "rougeL": {
            "precision": 0.62669,
            "recall": 0.61159,
            "fmeasure": 0.61644
        },
        "rougeLsum": {
            "precision": 0.62669,
            "recall": 0.61159,
            "fmeasure": 0.61644
        },
        "nist": 5.650647179137639,
        "bleurt": 0.32885,
        "bertscore": {
            "precision": 0.93004,
            "recall": 0.92724,
            "f1": 0.92817
        },
        "nubia": {
            "semantic_relation": 4.22959,
            "contradiction": 10.26182,
            "irrelevancy": 8.40221,
            "logical_agreement": 81.33598,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.86613,
            "nubia_score": 0.75295
        },
        "meteor": 0.4231568813033886
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.5,
        "median_pred_length": 18.5,
        "min_pred_length": 15,
        "max_pred_length": 22,
        "distinct-1": 0.8108108108108109,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.77702093319652,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.31982965131601665,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.675698135367986,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.3500371587496607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.69602,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.80139,
            "recall": 0.94028,
            "fmeasure": 0.85794
        },
        "rouge2": {
            "precision": 0.67184,
            "recall": 0.76443,
            "fmeasure": 0.70909
        },
        "rougeL": {
            "precision": 0.75278,
            "recall": 0.84196,
            "fmeasure": 0.79044
        },
        "rougeLsum": {
            "precision": 0.75278,
            "recall": 0.84196,
            "fmeasure": 0.79044
        },
        "nist": 4.698105096483898,
        "bleurt": 0.64978,
        "bertscore": {
            "precision": 0.95588,
            "recall": 0.97301,
            "f1": 0.96414
        },
        "nubia": {
            "semantic_relation": 4.9242,
            "contradiction": 0.3312,
            "irrelevancy": 31.64353,
            "logical_agreement": 68.02527,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.65496,
            "nubia_score": 0.92663
        },
        "meteor": 0.5186872317214436
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.765,
        "total_length": 232,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.330127018922194,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5991379310344828,
        "vocab_size-1": 139,
        "unique-1": 111,
        "entropy-1": 6.511654739908383,
        "distinct-2": 0.9398148148148148,
        "vocab_size-2": 203,
        "unique-2": 193,
        "entropy-2": 7.621763022986781,
        "cond_entropy-2": 0.9135398575390715,
        "distinct-3": 0.965,
        "vocab_size-3": 193,
        "unique-3": 186,
        "entropy-3": 7.57385618977474,
        "cond_entropy-3": -0.03725687487792657,
        "total_length-nopunct": 201,
        "mean_pred_length-nopunct": 12.5625,
        "std_pred_length-nopunct": 3.8563057127255873,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6716417910447762,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.624713664284217,
        "distinct-2-nopunct": 0.9405405405405406,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 166,
        "entropy-2-nopunct": 7.397571257801904,
        "cond_entropy-2-nopunct": 0.8400003417896823,
        "distinct-3-nopunct": 0.9704142011834319,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 159,
        "entropy-3-nopunct": 7.34170783864904,
        "cond_entropy-3-nopunct": -0.04319499759410705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.14856,
        "local_recall": {
            "1": 0.1951219512195122,
            "2": 0.4782608695652174,
            "3": 0.823170731707317
        },
        "rouge1": {
            "precision": 0.82214,
            "recall": 0.80795,
            "fmeasure": 0.81133
        },
        "rouge2": {
            "precision": 0.56984,
            "recall": 0.57277,
            "fmeasure": 0.56867
        },
        "rougeL": {
            "precision": 0.72518,
            "recall": 0.708,
            "fmeasure": 0.71354
        },
        "rougeLsum": {
            "precision": 0.72518,
            "recall": 0.708,
            "fmeasure": 0.71354
        },
        "nist": 6.212449488758145,
        "bleurt": 0.44787,
        "bertscore": {
            "precision": 0.93651,
            "recall": 0.94413,
            "f1": 0.93854
        },
        "nubia": {
            "semantic_relation": 4.62869,
            "contradiction": 0.62673,
            "irrelevancy": 25.89631,
            "logical_agreement": 73.47696,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.58059,
            "nubia_score": 0.85802
        },
        "meteor": 0.41991928981526205
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.31618,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47222,
            "fmeasure": 0.48529
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.26786,
            "fmeasure": 0.27619
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.47222,
            "fmeasure": 0.48529
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.47222,
            "fmeasure": 0.48529
        },
        "nist": 2.046877465539865,
        "bleurt": -0.03414,
        "bertscore": {
            "precision": 0.85264,
            "recall": 0.84002,
            "f1": 0.84628
        },
        "nubia": {
            "semantic_relation": 3.36294,
            "contradiction": 0.65621,
            "irrelevancy": 60.33127,
            "logical_agreement": 39.01252,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.49648,
            "nubia_score": 0.40936
        },
        "meteor": 0.28661167322755027
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.24930976183687525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.10005,
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.6049,
            "recall": 0.6121,
            "fmeasure": 0.58549
        },
        "rouge2": {
            "precision": 0.26736,
            "recall": 0.28969,
            "fmeasure": 0.26911
        },
        "rougeL": {
            "precision": 0.41275,
            "recall": 0.43178,
            "fmeasure": 0.40576
        },
        "rougeLsum": {
            "precision": 0.41275,
            "recall": 0.43178,
            "fmeasure": 0.40576
        },
        "nist": 2.589014056413084,
        "bleurt": -0.15794,
        "bertscore": {
            "precision": 0.88894,
            "recall": 0.88612,
            "f1": 0.88122
        },
        "nubia": {
            "semantic_relation": 3.92693,
            "contradiction": 0.24769,
            "irrelevancy": 40.89148,
            "logical_agreement": 58.86083,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.58765,
            "nubia_score": 0.61991
        },
        "meteor": 0.3433765149872545
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.81,
        "total_length": 337,
        "mean_pred_length": 15.318181818181818,
        "std_pred_length": 4.3837132831379755,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6172106824925816,
        "vocab_size-1": 208,
        "unique-1": 176,
        "entropy-1": 6.924259074645271,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 297,
        "unique-2": 288,
        "entropy-2": 8.147933464563733,
        "cond_entropy-2": 1.0150525166924056,
        "distinct-3": 0.9965870307167235,
        "vocab_size-3": 292,
        "unique-3": 291,
        "entropy-3": 8.187930915855741,
        "cond_entropy-3": 0.05135595021381956,
        "total_length-nopunct": 297,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.142353305681556,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6801346801346801,
        "vocab_size-1-nopunct": 202,
        "unique-1-nopunct": 174,
        "entropy-1-nopunct": 7.032320947453484,
        "distinct-2-nopunct": 0.9418181818181818,
        "vocab_size-2-nopunct": 259,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 7.944555137668743,
        "cond_entropy-2-nopunct": 0.9995213168103368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 253,
        "entropy-3-nopunct": 7.982993574694275,
        "cond_entropy-3-nopunct": 0.05224127795977138,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.5886,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.4727272727272727,
            "3": 0.8097826086956522
        },
        "rouge1": {
            "precision": 0.70848,
            "recall": 0.75943,
            "fmeasure": 0.72191
        },
        "rouge2": {
            "precision": 0.4933,
            "recall": 0.52125,
            "fmeasure": 0.49626
        },
        "rougeL": {
            "precision": 0.62461,
            "recall": 0.66764,
            "fmeasure": 0.63635
        },
        "rougeLsum": {
            "precision": 0.62461,
            "recall": 0.66764,
            "fmeasure": 0.63635
        },
        "nist": 5.826608391992826,
        "bleurt": 0.27528,
        "bertscore": {
            "precision": 0.92278,
            "recall": 0.93378,
            "f1": 0.92745
        },
        "nubia": {
            "semantic_relation": 4.24991,
            "contradiction": 5.90403,
            "irrelevancy": 38.06551,
            "logical_agreement": 56.03046,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.0102,
            "nubia_score": 0.71627
        },
        "meteor": 0.3849939782890511
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.005945690289794,
        "distinct-2": 0.94,
        "vocab_size-2": 47,
        "unique-2": 44,
        "entropy-2": 5.523856189774728,
        "cond_entropy-2": 0.4661312352980641,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": 0.03839223637099784,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.74,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.973660689688187,
        "distinct-2-nopunct": 0.9361702127659575,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.426929277209555,
        "cond_entropy-2-nopunct": 0.47477042795242197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": 0.04120640332329605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.76959,
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.76572,
            "recall": 0.78152,
            "fmeasure": 0.76705
        },
        "rouge2": {
            "precision": 0.51831,
            "recall": 0.52213,
            "fmeasure": 0.51483
        },
        "rougeL": {
            "precision": 0.60037,
            "recall": 0.62418,
            "fmeasure": 0.60623
        },
        "rougeLsum": {
            "precision": 0.60037,
            "recall": 0.62418,
            "fmeasure": 0.60623
        },
        "nist": 4.09169614955416,
        "bleurt": 0.27031,
        "bertscore": {
            "precision": 0.90638,
            "recall": 0.91845,
            "f1": 0.91177
        },
        "nubia": {
            "semantic_relation": 4.66536,
            "contradiction": 0.30241,
            "irrelevancy": 6.17877,
            "logical_agreement": 93.51882,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.20587,
            "nubia_score": 0.88925
        },
        "meteor": 0.3640166559577514
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.36858,
        "local_recall": {
            "1": 0,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "nist": 1.1385968363511052,
        "bleurt": -0.59749,
        "bertscore": {
            "precision": 0.80999,
            "recall": 0.83938,
            "f1": 0.82442
        },
        "nubia": {
            "semantic_relation": 2.73211,
            "contradiction": 0.25615,
            "irrelevancy": 99.66569,
            "logical_agreement": 0.07816,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.08527,
            "nubia_score": 0.23745
        },
        "meteor": 0.2248648934411714
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 140,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.769696007084728,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6642857142857143,
        "vocab_size-1": 93,
        "unique-1": 75,
        "entropy-1": 6.129498054331375,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 126,
        "unique-2": 122,
        "entropy-2": 6.9420473390226345,
        "cond_entropy-2": 0.6913241309102818,
        "distinct-3": 0.9919354838709677,
        "vocab_size-3": 123,
        "unique-3": 122,
        "entropy-3": 6.938067278128796,
        "cond_entropy-3": 0.0026229571923488118,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.520785330006281,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7295081967213115,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.140080618205707,
        "distinct-2-nopunct": 0.956140350877193,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.731927075530305,
        "cond_entropy-2-nopunct": 0.6297872797356286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.005820738806005242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.41928,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4166666666666667,
            "3": 0.6338028169014085
        },
        "rouge1": {
            "precision": 0.64881,
            "recall": 0.63146,
            "fmeasure": 0.62792
        },
        "rouge2": {
            "precision": 0.41291,
            "recall": 0.4061,
            "fmeasure": 0.40261
        },
        "rougeL": {
            "precision": 0.54584,
            "recall": 0.53658,
            "fmeasure": 0.53196
        },
        "rougeLsum": {
            "precision": 0.54584,
            "recall": 0.53658,
            "fmeasure": 0.53196
        },
        "nist": 4.295573298357064,
        "bleurt": 0.25429,
        "bertscore": {
            "precision": 0.90284,
            "recall": 0.89626,
            "f1": 0.89726
        },
        "nubia": {
            "semantic_relation": 3.81287,
            "contradiction": 6.97113,
            "irrelevancy": 52.08801,
            "logical_agreement": 40.94086,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.0879,
            "nubia_score": 0.67142
        },
        "meteor": 0.2861427453612236
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 20.8,
        "std_pred_length": 12.874781551544865,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.7403846153846154,
        "vocab_size-1": 77,
        "unique-1": 66,
        "entropy-1": 6.00071952647603,
        "distinct-2": 0.9595959595959596,
        "vocab_size-2": 95,
        "unique-2": 92,
        "entropy-2": 6.540923412987059,
        "cond_entropy-2": 0.45827419442909,
        "distinct-3": 1.0,
        "vocab_size-3": 94,
        "unique-3": 94,
        "entropy-3": 6.554588851677623,
        "cond_entropy-3": 0.018369332684873323,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 8.42852300228219,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8674698795180723,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.067692744547811,
        "distinct-2-nopunct": 0.9871794871794872,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.259761193221231,
        "cond_entropy-2-nopunct": 0.21177015936566912,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.06818039970825863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.27345,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.75,
            "3": 0.9347826086956522
        },
        "rouge1": {
            "precision": 0.73716,
            "recall": 0.88591,
            "fmeasure": 0.79822
        },
        "rouge2": {
            "precision": 0.5934,
            "recall": 0.69642,
            "fmeasure": 0.63364
        },
        "rougeL": {
            "precision": 0.72049,
            "recall": 0.86498,
            "fmeasure": 0.77966
        },
        "rougeLsum": {
            "precision": 0.72049,
            "recall": 0.86498,
            "fmeasure": 0.77966
        },
        "nist": 5.619213049601388,
        "bleurt": 0.50478,
        "bertscore": {
            "precision": 0.94559,
            "recall": 0.96879,
            "f1": 0.95689
        },
        "nubia": {
            "semantic_relation": 4.3253,
            "contradiction": 0.67335,
            "irrelevancy": 36.32859,
            "logical_agreement": 62.99806,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.41315,
            "nubia_score": 0.78597
        },
        "meteor": 0.4628205690391138
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 23.75,
        "std_pred_length": 6.179603547154137,
        "median_pred_length": 24.0,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.631578947368421,
        "vocab_size-1": 60,
        "unique-1": 44,
        "entropy-1": 5.590533898439817,
        "distinct-2": 0.967032967032967,
        "vocab_size-2": 88,
        "unique-2": 85,
        "entropy-2": 6.441860574264637,
        "cond_entropy-2": 0.8064616960398078,
        "distinct-3": 0.9885057471264368,
        "vocab_size-3": 86,
        "unique-3": 85,
        "entropy-3": 6.419954990101596,
        "cond_entropy-3": -0.018874132855715025,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 5.172040216394301,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7051282051282052,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.524067885717969,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.155399311574901,
        "cond_entropy-2-nopunct": 0.6589711195404061,
        "distinct-3-nopunct": 0.9857142857142858,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.100711588373543,
        "cond_entropy-3-nopunct": -0.05159892011255472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.42973,
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.5333333333333333,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.58692,
            "recall": 0.81336,
            "fmeasure": 0.67557
        },
        "rouge2": {
            "precision": 0.38634,
            "recall": 0.51415,
            "fmeasure": 0.4358
        },
        "rougeL": {
            "precision": 0.50418,
            "recall": 0.69254,
            "fmeasure": 0.57836
        },
        "rougeLsum": {
            "precision": 0.50418,
            "recall": 0.69254,
            "fmeasure": 0.57836
        },
        "nist": 4.56946393589184,
        "bleurt": 0.295,
        "bertscore": {
            "precision": 0.89899,
            "recall": 0.93994,
            "f1": 0.91502
        },
        "nubia": {
            "semantic_relation": 4.16394,
            "contradiction": 0.38566,
            "irrelevancy": 39.72327,
            "logical_agreement": 59.89107,
            "grammar_ref": 4.83213,
            "grammar_hyp": 3.93772,
            "nubia_score": 0.76294
        },
        "meteor": 0.4148295508432573
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.77,
        "total_length": 183,
        "mean_pred_length": 16.636363636363637,
        "std_pred_length": 6.944883365376101,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6338797814207651,
        "vocab_size-1": 116,
        "unique-1": 96,
        "entropy-1": 6.386449384437019,
        "distinct-2": 0.8953488372093024,
        "vocab_size-2": 154,
        "unique-2": 140,
        "entropy-2": 7.196556760490867,
        "cond_entropy-2": 0.6610841620265878,
        "distinct-3": 0.9440993788819876,
        "vocab_size-3": 152,
        "unique-3": 144,
        "entropy-3": 7.214426893629115,
        "cond_entropy-3": 0.033564468146453655,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 14.636363636363637,
        "std_pred_length-nopunct": 6.094300277125225,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6770186335403726,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.380051597091825,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.96542019046702,
        "cond_entropy-2-nopunct": 0.6550987139835348,
        "distinct-3-nopunct": 0.935251798561151,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.984013824506517,
        "cond_entropy-3-nopunct": 0.03943811965326307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.263,
        "local_recall": {
            "1": 0.375,
            "2": 0.4375,
            "3": 0.9186991869918699
        },
        "rouge1": {
            "precision": 0.84872,
            "recall": 0.88818,
            "fmeasure": 0.86508
        },
        "rouge2": {
            "precision": 0.70212,
            "recall": 0.73569,
            "fmeasure": 0.71583
        },
        "rougeL": {
            "precision": 0.78387,
            "recall": 0.82673,
            "fmeasure": 0.80185
        },
        "rougeLsum": {
            "precision": 0.78387,
            "recall": 0.82673,
            "fmeasure": 0.80185
        },
        "nist": 6.518595730485753,
        "bleurt": 0.54757,
        "bertscore": {
            "precision": 0.96449,
            "recall": 0.9679,
            "f1": 0.96583
        },
        "nubia": {
            "semantic_relation": 4.72545,
            "contradiction": 0.46768,
            "irrelevancy": 12.40403,
            "logical_agreement": 87.12829,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.02236,
            "nubia_score": 0.93127
        },
        "meteor": 0.4940414650086909
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.69,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 7.6983963344614175,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.616,
        "vocab_size-1": 77,
        "unique-1": 61,
        "entropy-1": 5.8145336619186185,
        "distinct-2": 0.940677966101695,
        "vocab_size-2": 111,
        "unique-2": 105,
        "entropy-2": 6.7576016298519725,
        "cond_entropy-2": 0.8448244925503247,
        "distinct-3": 0.990990990990991,
        "vocab_size-3": 110,
        "unique-3": 109,
        "entropy-3": 6.7763978483321035,
        "cond_entropy-3": 0.026681713404151805,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 15.428571428571429,
        "std_pred_length-nopunct": 6.758214955722783,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.786337882403019,
        "distinct-2-nopunct": 0.9405940594059405,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.5319254678788745,
        "cond_entropy-2-nopunct": 0.797022088818457,
        "distinct-3-nopunct": 0.9893617021276596,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.533312255932943,
        "cond_entropy-3-nopunct": 0.000152767885028441,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.0124,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.5882352941176471,
            "3": 0.7246376811594203
        },
        "rouge1": {
            "precision": 0.64487,
            "recall": 0.70347,
            "fmeasure": 0.66854
        },
        "rouge2": {
            "precision": 0.42402,
            "recall": 0.47802,
            "fmeasure": 0.44671
        },
        "rougeL": {
            "precision": 0.54563,
            "recall": 0.59633,
            "fmeasure": 0.56622
        },
        "rougeLsum": {
            "precision": 0.54563,
            "recall": 0.59633,
            "fmeasure": 0.56622
        },
        "nist": 4.291462949945976,
        "bleurt": 0.16327,
        "bertscore": {
            "precision": 0.90449,
            "recall": 0.91325,
            "f1": 0.90642
        },
        "nubia": {
            "semantic_relation": 3.98555,
            "contradiction": 0.26406,
            "irrelevancy": 76.92062,
            "logical_agreement": 22.81532,
            "grammar_ref": 4.06397,
            "grammar_hyp": 3.92426,
            "nubia_score": 0.76871
        },
        "meteor": 0.3825203587382173
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 135,
        "mean_pred_length": 16.875,
        "std_pred_length": 6.173279112432873,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7111111111111111,
        "vocab_size-1": 96,
        "unique-1": 80,
        "entropy-1": 6.260971408255161,
        "distinct-2": 0.9606299212598425,
        "vocab_size-2": 122,
        "unique-2": 117,
        "entropy-2": 6.909944529291836,
        "cond_entropy-2": 0.5113885030080872,
        "distinct-3": 0.9747899159663865,
        "vocab_size-3": 116,
        "unique-3": 113,
        "entropy-3": 6.844397595240716,
        "cond_entropy-3": -0.06025347808607097,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.5901699437494745,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.318314008249441,
        "distinct-2-nopunct": 0.9553571428571429,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 102,
        "entropy-2-nopunct": 6.7180692077718795,
        "cond_entropy-2-nopunct": 0.4417963843338249,
        "distinct-3-nopunct": 0.9711538461538461,
        "vocab_size-3-nopunct": 101,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.642747410448792,
        "cond_entropy-3-nopunct": -0.06845366545497375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.22126,
        "local_recall": {
            "1": 0.043478260869565216,
            "2": 0.38461538461538464,
            "3": 0.7788461538461539
        },
        "rouge1": {
            "precision": 0.84476,
            "recall": 0.7277,
            "fmeasure": 0.7796
        },
        "rouge2": {
            "precision": 0.59446,
            "recall": 0.49696,
            "fmeasure": 0.53631
        },
        "rougeL": {
            "precision": 0.65733,
            "recall": 0.54856,
            "fmeasure": 0.59284
        },
        "rougeLsum": {
            "precision": 0.65733,
            "recall": 0.54856,
            "fmeasure": 0.59284
        },
        "nist": 4.95436769234514,
        "bleurt": 0.33548,
        "bertscore": {
            "precision": 0.94146,
            "recall": 0.92579,
            "f1": 0.932
        },
        "nubia": {
            "semantic_relation": 4.36547,
            "contradiction": 0.21338,
            "irrelevancy": 21.59056,
            "logical_agreement": 78.19606,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.78638,
            "nubia_score": 0.76608
        },
        "meteor": 0.3838117842845699
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.0,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.11813,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.63462,
            "recall": 0.94192,
            "fmeasure": 0.74444
        },
        "rouge2": {
            "precision": 0.47348,
            "recall": 0.73939,
            "fmeasure": 0.56357
        },
        "rougeL": {
            "precision": 0.55769,
            "recall": 0.85354,
            "fmeasure": 0.66222
        },
        "rougeLsum": {
            "precision": 0.55769,
            "recall": 0.85354,
            "fmeasure": 0.66222
        },
        "nist": 2.909469560537806,
        "bleurt": 0.2205,
        "bertscore": {
            "precision": 0.89027,
            "recall": 0.95242,
            "f1": 0.91981
        },
        "nubia": {
            "semantic_relation": 4.07991,
            "contradiction": 0.43376,
            "irrelevancy": 52.06061,
            "logical_agreement": 47.50563,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.90675,
            "nubia_score": 0.75166
        },
        "meteor": 0.49422175364828413
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 182,
        "mean_pred_length": 20.22222222222222,
        "std_pred_length": 10.063992777088224,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 117,
        "unique-1": 97,
        "entropy-1": 6.359546533720285,
        "distinct-2": 0.9421965317919075,
        "vocab_size-2": 163,
        "unique-2": 155,
        "entropy-2": 7.310294268074142,
        "cond_entropy-2": 0.8455737918412948,
        "distinct-3": 0.9817073170731707,
        "vocab_size-3": 161,
        "unique-3": 158,
        "entropy-3": 7.320966638764445,
        "cond_entropy-3": 0.017495575788230622,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 8.768630958643937,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.691358024691358,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.374097963587746,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.129872973383307,
        "cond_entropy-2-nopunct": 0.7995120578587802,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.128258334775664,
        "cond_entropy-3-nopunct": 0.0063550407241531985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.26356,
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.1875,
            "3": 0.7739130434782608
        },
        "rouge1": {
            "precision": 0.77307,
            "recall": 0.75018,
            "fmeasure": 0.75611
        },
        "rouge2": {
            "precision": 0.54102,
            "recall": 0.52019,
            "fmeasure": 0.52723
        },
        "rougeL": {
            "precision": 0.68279,
            "recall": 0.64353,
            "fmeasure": 0.65926
        },
        "rougeLsum": {
            "precision": 0.68279,
            "recall": 0.64353,
            "fmeasure": 0.65926
        },
        "nist": 5.391594635481391,
        "bleurt": 0.32897,
        "bertscore": {
            "precision": 0.93494,
            "recall": 0.92801,
            "f1": 0.93077
        },
        "nubia": {
            "semantic_relation": 4.38559,
            "contradiction": 0.61494,
            "irrelevancy": 23.3638,
            "logical_agreement": 76.02126,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.46847,
            "nubia_score": 0.82688
        },
        "meteor": 0.3815620458257171
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.66,
        "total_length": 191,
        "mean_pred_length": 13.642857142857142,
        "std_pred_length": 4.9223563297200155,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 22,
        "distinct-1": 0.5916230366492147,
        "vocab_size-1": 113,
        "unique-1": 94,
        "entropy-1": 6.162079942819013,
        "distinct-2": 0.9209039548022598,
        "vocab_size-2": 163,
        "unique-2": 154,
        "entropy-2": 7.282549688488865,
        "cond_entropy-2": 0.9312715280666074,
        "distinct-3": 0.9877300613496932,
        "vocab_size-3": 161,
        "unique-3": 159,
        "entropy-3": 7.32418827693049,
        "cond_entropy-3": 0.04526301827178234,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 4.494895063586363,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6453488372093024,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.2319680820674686,
        "distinct-2-nopunct": 0.9367088607594937,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.151882013999903,
        "cond_entropy-2-nopunct": 0.9814338902671123,
        "distinct-3-nopunct": 0.9930555555555556,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.156036112553442,
        "cond_entropy-3-nopunct": 0.005033142154098441,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.08797,
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.36666666666666664,
            "3": 0.71875
        },
        "rouge1": {
            "precision": 0.73756,
            "recall": 0.72179,
            "fmeasure": 0.7193
        },
        "rouge2": {
            "precision": 0.4968,
            "recall": 0.51374,
            "fmeasure": 0.49371
        },
        "rougeL": {
            "precision": 0.65115,
            "recall": 0.66387,
            "fmeasure": 0.6424
        },
        "rougeLsum": {
            "precision": 0.65115,
            "recall": 0.66387,
            "fmeasure": 0.6424
        },
        "nist": 5.261420932603062,
        "bleurt": 0.28054,
        "bertscore": {
            "precision": 0.92521,
            "recall": 0.92493,
            "f1": 0.92348
        },
        "nubia": {
            "semantic_relation": 4.25574,
            "contradiction": 7.80911,
            "irrelevancy": 12.3519,
            "logical_agreement": 79.83899,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.26117,
            "nubia_score": 0.76298
        },
        "meteor": 0.40742973152653816
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "total_length": 192,
        "mean_pred_length": 14.76923076923077,
        "std_pred_length": 6.116231194425914,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 128,
        "unique-1": 100,
        "entropy-1": 6.625701742884061,
        "distinct-2": 0.9050279329608939,
        "vocab_size-2": 162,
        "unique-2": 145,
        "entropy-2": 7.293871643186035,
        "cond_entropy-2": 0.497504201102159,
        "distinct-3": 0.9397590361445783,
        "vocab_size-3": 156,
        "unique-3": 146,
        "entropy-3": 7.2545575036360646,
        "cond_entropy-3": -0.03648718929082572,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 13.23076923076923,
        "std_pred_length-nopunct": 5.576790449351341,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7209302325581395,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.695748821610539,
        "distinct-2-nopunct": 0.89937106918239,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.111625093649107,
        "cond_entropy-2-nopunct": 0.45673606531021016,
        "distinct-3-nopunct": 0.9383561643835616,
        "vocab_size-3-nopunct": 137,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.0665368876471435,
        "cond_entropy-3-nopunct": -0.04771593065091323,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.26037,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.45098039215686275,
            "3": 0.8048780487804879
        },
        "rouge1": {
            "precision": 0.7734,
            "recall": 0.70294,
            "fmeasure": 0.71694
        },
        "rouge2": {
            "precision": 0.55693,
            "recall": 0.50536,
            "fmeasure": 0.51395
        },
        "rougeL": {
            "precision": 0.64633,
            "recall": 0.58269,
            "fmeasure": 0.59593
        },
        "rougeLsum": {
            "precision": 0.64633,
            "recall": 0.58269,
            "fmeasure": 0.59593
        },
        "nist": 5.311366397402353,
        "bleurt": 0.13612,
        "bertscore": {
            "precision": 0.91941,
            "recall": 0.9089,
            "f1": 0.91289
        },
        "nubia": {
            "semantic_relation": 4.01818,
            "contradiction": 4.51955,
            "irrelevancy": 31.04373,
            "logical_agreement": 64.43672,
            "grammar_ref": 4.86507,
            "grammar_hyp": 5.10867,
            "nubia_score": 0.65918
        },
        "meteor": 0.39790418536282574
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.81,
        "total_length": 176,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.954336943068623,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 120,
        "unique-1": 101,
        "entropy-1": 6.498236992262635,
        "distinct-2": 0.9575757575757575,
        "vocab_size-2": 158,
        "unique-2": 153,
        "entropy-2": 7.272323577855949,
        "cond_entropy-2": 0.6075374527758193,
        "distinct-3": 1.0,
        "vocab_size-3": 154,
        "unique-3": 154,
        "entropy-3": 7.2667865406949215,
        "cond_entropy-3": 0.001177151152507289,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 14.636363636363637,
        "std_pred_length-nopunct": 4.772510817602432,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7329192546583851,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.566218080369689,
        "distinct-2-nopunct": 0.9533333333333334,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.125420190467017,
        "cond_entropy-2-nopunct": 0.6152800219319605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 139,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.118941072723523,
        "cond_entropy-3-nopunct": 0.001703497366669325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.02372,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.631578947368421,
            "3": 0.8064516129032258
        },
        "rouge1": {
            "precision": 0.75463,
            "recall": 0.78916,
            "fmeasure": 0.76269
        },
        "rouge2": {
            "precision": 0.52053,
            "recall": 0.5575,
            "fmeasure": 0.53085
        },
        "rougeL": {
            "precision": 0.638,
            "recall": 0.6654,
            "fmeasure": 0.64335
        },
        "rougeLsum": {
            "precision": 0.638,
            "recall": 0.6654,
            "fmeasure": 0.64335
        },
        "nist": 5.564058589007854,
        "bleurt": 0.49515,
        "bertscore": {
            "precision": 0.94086,
            "recall": 0.94349,
            "f1": 0.94168
        },
        "nubia": {
            "semantic_relation": 4.64093,
            "contradiction": 0.33352,
            "irrelevancy": 19.81302,
            "logical_agreement": 79.85346,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.36035,
            "nubia_score": 0.89406
        },
        "meteor": 0.4152568389643335
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.49468036840891,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.10789104611122459,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.10276,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6666666666666666,
            "3": 0.8235294117647058
        },
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.78242,
            "fmeasure": 0.73975
        },
        "rouge2": {
            "precision": 0.49339,
            "recall": 0.54808,
            "fmeasure": 0.51785
        },
        "rougeL": {
            "precision": 0.70556,
            "recall": 0.78242,
            "fmeasure": 0.73975
        },
        "rougeLsum": {
            "precision": 0.70556,
            "recall": 0.78242,
            "fmeasure": 0.73975
        },
        "nist": 3.6555733658346834,
        "bleurt": 0.38004,
        "bertscore": {
            "precision": 0.92606,
            "recall": 0.92344,
            "f1": 0.92464
        },
        "nubia": {
            "semantic_relation": 4.0895,
            "contradiction": 1.17373,
            "irrelevancy": 71.97242,
            "logical_agreement": 26.85385,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.8011,
            "nubia_score": 0.74388
        },
        "meteor": 0.45754370802657496
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.08165,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.77576,
            "fmeasure": 0.71673
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.53704,
            "fmeasure": 0.49206
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.67879,
            "fmeasure": 0.62714
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.67879,
            "fmeasure": 0.62714
        },
        "nist": 2.1139542422010487,
        "bleurt": 0.12087,
        "bertscore": {
            "precision": 0.89315,
            "recall": 0.93691,
            "f1": 0.91451
        },
        "nubia": {
            "semantic_relation": 3.98148,
            "contradiction": 0.30912,
            "irrelevancy": 96.13237,
            "logical_agreement": 3.55851,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.14303,
            "nubia_score": 0.8105
        },
        "meteor": 0.35915012182129735
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 25.5,
        "std_pred_length": 13.5,
        "median_pred_length": 25.5,
        "min_pred_length": 12,
        "max_pred_length": 39,
        "distinct-1": 0.6470588235294118,
        "vocab_size-1": 33,
        "unique-1": 24,
        "entropy-1": 4.780583313434949,
        "distinct-2": 0.8775510204081632,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.354406017540444,
        "cond_entropy-2": 0.5694080930253563,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.0836000182467583,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.739097917988784,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.3737076928764665,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.27093,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.75818,
            "recall": 0.763,
            "fmeasure": 0.75928
        },
        "rouge2": {
            "precision": 0.58194,
            "recall": 0.58049,
            "fmeasure": 0.58014
        },
        "rougeL": {
            "precision": 0.73818,
            "recall": 0.74515,
            "fmeasure": 0.74041
        },
        "rougeLsum": {
            "precision": 0.73818,
            "recall": 0.74515,
            "fmeasure": 0.74041
        },
        "nist": 5.307571952340734,
        "bleurt": 0.36943,
        "bertscore": {
            "precision": 0.94451,
            "recall": 0.91354,
            "f1": 0.92871
        },
        "nubia": {
            "semantic_relation": 4.41574,
            "contradiction": 0.5911,
            "irrelevancy": 13.47661,
            "logical_agreement": 85.93229,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.37716,
            "nubia_score": 0.7572
        },
        "meteor": 0.4383149683200865
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 4.672979209656036,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6886792452830188,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.87277703084532,
        "distinct-2": 0.9595959595959596,
        "vocab_size-2": 95,
        "unique-2": 91,
        "entropy-2": 6.548548539271537,
        "cond_entropy-2": 0.5377363519779358,
        "distinct-3": 0.967391304347826,
        "vocab_size-3": 89,
        "unique-3": 86,
        "entropy-3": 6.458344564752678,
        "cond_entropy-3": -0.10579466402259652,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 4.199125273342591,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7634408602150538,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.9425572685772385,
        "distinct-2-nopunct": 0.9651162790697675,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.3564973128416336,
        "cond_entropy-2-nopunct": 0.43924482098202045,
        "distinct-3-nopunct": 0.9746835443037974,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.2531478367846995,
        "cond_entropy-3-nopunct": -0.12248400652499519,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.59038,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.45,
            "3": 0.8153846153846154
        },
        "rouge1": {
            "precision": 0.71084,
            "recall": 0.73301,
            "fmeasure": 0.7162
        },
        "rouge2": {
            "precision": 0.54168,
            "recall": 0.53671,
            "fmeasure": 0.53162
        },
        "rougeL": {
            "precision": 0.64578,
            "recall": 0.62859,
            "fmeasure": 0.6286
        },
        "rougeLsum": {
            "precision": 0.64578,
            "recall": 0.62859,
            "fmeasure": 0.6286
        },
        "nist": 5.132904632547899,
        "bleurt": 0.01203,
        "bertscore": {
            "precision": 0.90283,
            "recall": 0.9014,
            "f1": 0.90146
        },
        "nubia": {
            "semantic_relation": 4.0814,
            "contradiction": 3.52667,
            "irrelevancy": 50.91797,
            "logical_agreement": 45.55537,
            "grammar_ref": 5.24762,
            "grammar_hyp": 5.33728,
            "nubia_score": 0.65661
        },
        "meteor": 0.3830128604366613
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.5,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.9629629629629629,
        "vocab_size-1": 26,
        "unique-1": 25,
        "entropy-1": 4.680813428089397,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.11103131238874399,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.22711,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.82292,
            "recall": 0.72622,
            "fmeasure": 0.77004
        },
        "rouge2": {
            "precision": 0.49524,
            "recall": 0.4537,
            "fmeasure": 0.4719
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.69756,
            "fmeasure": 0.74024
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.69756,
            "fmeasure": 0.74024
        },
        "nist": 4.23730328074342,
        "bleurt": 0.44515,
        "bertscore": {
            "precision": 0.96495,
            "recall": 0.9482,
            "f1": 0.95266
        },
        "nubia": {
            "semantic_relation": 4.32346,
            "contradiction": 0.23315,
            "irrelevancy": 2.24449,
            "logical_agreement": 97.52237,
            "grammar_ref": 4.57807,
            "grammar_hyp": 4.55487,
            "nubia_score": 0.82072
        },
        "meteor": 0.4240742662506391
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.52469,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.96296,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.85185,
            "fmeasure": 0.76667
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.85185,
            "fmeasure": 0.76667
        },
        "nist": 3.44224370100313,
        "bleurt": 0.69725,
        "bertscore": {
            "precision": 0.96099,
            "recall": 0.9435,
            "f1": 0.95217
        },
        "nubia": {
            "semantic_relation": 4.99032,
            "contradiction": 0.15607,
            "irrelevancy": 0.74583,
            "logical_agreement": 99.09809,
            "grammar_ref": 4.07798,
            "grammar_hyp": 3.86255,
            "nubia_score": 0.99365
        },
        "meteor": 0.45670090545296693
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.62,
        "msttr-100_nopunct": NaN,
        "total_length": 116,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.1213203435596424,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.603448275862069,
        "vocab_size-1": 70,
        "unique-1": 50,
        "entropy-1": 5.734148857398253,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 90,
        "unique-2": 74,
        "entropy-2": 6.40303565031161,
        "cond_entropy-2": 0.5299113957081212,
        "distinct-3": 0.87,
        "vocab_size-3": 87,
        "unique-3": 74,
        "entropy-3": 6.383856189774736,
        "cond_entropy-3": -0.011031312388743941,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6770833333333334,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.747832000964908,
        "distinct-2-nopunct": 0.8522727272727273,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.141249800455485,
        "cond_entropy-2-nopunct": 0.42406602674114424,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.121928094887358,
        "cond_entropy-3-nopunct": -0.012503523749935012,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.86733,
        "local_recall": {
            "1": 0.34146341463414637,
            "2": 0.7619047619047619,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.78466,
            "recall": 0.80197,
            "fmeasure": 0.78541
        },
        "rouge2": {
            "precision": 0.59792,
            "recall": 0.64454,
            "fmeasure": 0.6113
        },
        "rougeL": {
            "precision": 0.68352,
            "recall": 0.70685,
            "fmeasure": 0.68859
        },
        "rougeLsum": {
            "precision": 0.68352,
            "recall": 0.70685,
            "fmeasure": 0.68859
        },
        "nist": 5.7097735182333675,
        "bleurt": 0.23106,
        "bertscore": {
            "precision": 0.94586,
            "recall": 0.9531,
            "f1": 0.94674
        },
        "nubia": {
            "semantic_relation": 4.15154,
            "contradiction": 19.95282,
            "irrelevancy": 37.12408,
            "logical_agreement": 42.9231,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.84902,
            "nubia_score": 0.73032
        },
        "meteor": 0.4670705284686308
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.7825,
        "total_length": 504,
        "mean_pred_length": 17.379310344827587,
        "std_pred_length": 6.482942037023793,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 37,
        "distinct-1": 0.5396825396825397,
        "vocab_size-1": 272,
        "unique-1": 210,
        "entropy-1": 7.300685943861492,
        "distinct-2": 0.8905263157894737,
        "vocab_size-2": 423,
        "unique-2": 389,
        "entropy-2": 8.63727032850333,
        "cond_entropy-2": 1.1423523352751408,
        "distinct-3": 0.9596412556053812,
        "vocab_size-3": 428,
        "unique-3": 415,
        "entropy-3": 8.71062038757396,
        "cond_entropy-3": 0.0747536473318758,
        "total_length-nopunct": 427,
        "mean_pred_length-nopunct": 14.724137931034482,
        "std_pred_length-nopunct": 4.455887633419932,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6229508196721312,
        "vocab_size-1-nopunct": 266,
        "unique-1-nopunct": 209,
        "entropy-1-nopunct": 7.5082280016419745,
        "distinct-2-nopunct": 0.914572864321608,
        "vocab_size-2-nopunct": 364,
        "unique-2-nopunct": 339,
        "entropy-2-nopunct": 8.445320687158192,
        "cond_entropy-2-nopunct": 0.9978319075892074,
        "distinct-3-nopunct": 0.975609756097561,
        "vocab_size-3-nopunct": 360,
        "unique-3-nopunct": 352,
        "entropy-3-nopunct": 8.476650752666965,
        "cond_entropy-3-nopunct": 0.043654764880579754,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.56202,
        "local_recall": {
            "1": 0.35526315789473684,
            "2": 0.5522388059701493,
            "3": 0.855457227138643
        },
        "rouge1": {
            "precision": 0.86557,
            "recall": 0.84536,
            "fmeasure": 0.84796
        },
        "rouge2": {
            "precision": 0.70895,
            "recall": 0.69201,
            "fmeasure": 0.69449
        },
        "rougeL": {
            "precision": 0.81286,
            "recall": 0.79144,
            "fmeasure": 0.79513
        },
        "rougeLsum": {
            "precision": 0.81286,
            "recall": 0.79144,
            "fmeasure": 0.79513
        },
        "nist": 7.6820765071776895,
        "bleurt": 0.53073,
        "bertscore": {
            "precision": 0.9638,
            "recall": 0.95881,
            "f1": 0.96074
        },
        "nubia": {
            "semantic_relation": 4.51512,
            "contradiction": 9.71081,
            "irrelevancy": 18.0006,
            "logical_agreement": 72.28859,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.71483,
            "nubia_score": 0.83179
        },
        "meteor": 0.47143605123024057
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.764857659740294,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.24101678429722817,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.7068905956085185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.11475004073479989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.9565,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.77602,
            "recall": 0.80739,
            "fmeasure": 0.79072
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.61756,
            "fmeasure": 0.60486
        },
        "rougeL": {
            "precision": 0.74661,
            "recall": 0.77798,
            "fmeasure": 0.76131
        },
        "rougeLsum": {
            "precision": 0.74661,
            "recall": 0.77798,
            "fmeasure": 0.76131
        },
        "nist": 4.4328882106527026,
        "bleurt": 0.45862,
        "bertscore": {
            "precision": 0.95051,
            "recall": 0.95963,
            "f1": 0.95497
        },
        "nubia": {
            "semantic_relation": 4.5397,
            "contradiction": 0.30604,
            "irrelevancy": 30.34409,
            "logical_agreement": 69.34987,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.68863,
            "nubia_score": 0.85417
        },
        "meteor": 0.43727432672521516
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.74811,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.6,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "nist": 2.9200645816166895,
        "bleurt": 0.23343,
        "bertscore": {
            "precision": 0.91707,
            "recall": 0.92055,
            "f1": 0.9188
        },
        "nubia": {
            "semantic_relation": 4.21403,
            "contradiction": 0.09879,
            "irrelevancy": 97.63404,
            "logical_agreement": 2.26717,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.70904,
            "nubia_score": 0.86604
        },
        "meteor": 0.41559324940305037
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.8,
        "total_length": 226,
        "mean_pred_length": 15.066666666666666,
        "std_pred_length": 7.758579480520615,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.6327433628318584,
        "vocab_size-1": 143,
        "unique-1": 119,
        "entropy-1": 6.578230578879067,
        "distinct-2": 0.9383886255924171,
        "vocab_size-2": 198,
        "unique-2": 187,
        "entropy-2": 7.590721108117982,
        "cond_entropy-2": 0.8230396610821004,
        "distinct-3": 0.9846938775510204,
        "vocab_size-3": 193,
        "unique-3": 191,
        "entropy-3": 7.580246132369461,
        "cond_entropy-3": -0.03496077316340533,
        "total_length-nopunct": 197,
        "mean_pred_length-nopunct": 13.133333333333333,
        "std_pred_length-nopunct": 6.751460747291819,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7106598984771574,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.72328316089602,
        "distinct-2-nopunct": 0.9505494505494505,
        "vocab_size-2-nopunct": 173,
        "unique-2-nopunct": 165,
        "entropy-2-nopunct": 7.404745807769244,
        "cond_entropy-2-nopunct": 0.7064995555259233,
        "distinct-3-nopunct": 0.9820359281437125,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.3477761487614535,
        "cond_entropy-3-nopunct": -0.07618615610787766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.8812,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.2727272727272727,
            "3": 0.7770700636942676
        },
        "rouge1": {
            "precision": 0.75091,
            "recall": 0.68368,
            "fmeasure": 0.70091
        },
        "rouge2": {
            "precision": 0.45065,
            "recall": 0.4338,
            "fmeasure": 0.43506
        },
        "rougeL": {
            "precision": 0.63301,
            "recall": 0.58014,
            "fmeasure": 0.59319
        },
        "rougeLsum": {
            "precision": 0.63301,
            "recall": 0.58014,
            "fmeasure": 0.59319
        },
        "nist": 5.172489147533161,
        "bleurt": 0.18969,
        "bertscore": {
            "precision": 0.91495,
            "recall": 0.90779,
            "f1": 0.9108
        },
        "nubia": {
            "semantic_relation": 4.2794,
            "contradiction": 0.83158,
            "irrelevancy": 36.95747,
            "logical_agreement": 62.21095,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.8637,
            "nubia_score": 0.72076
        },
        "meteor": 0.3505830471268413
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.8166378315169185,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.75,
        "vocab_size-1": 45,
        "unique-1": 37,
        "entropy-1": 5.2882336709624544,
        "distinct-2": 0.9818181818181818,
        "vocab_size-2": 54,
        "unique-2": 53,
        "entropy-2": 5.744996077161019,
        "cond_entropy-2": 0.30191957254026713,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.09750352374993501,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 10.2,
        "std_pred_length-nopunct": 3.7094473981982814,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8431372549019608,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.32909642031803,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.18830563591871155,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.11722946363405139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.26221,
        "local_recall": {
            "1": 0.1,
            "2": 0.75,
            "3": 0.7631578947368421
        },
        "rouge1": {
            "precision": 0.74185,
            "recall": 0.79661,
            "fmeasure": 0.7641
        },
        "rouge2": {
            "precision": 0.37398,
            "recall": 0.36721,
            "fmeasure": 0.36764
        },
        "rougeL": {
            "precision": 0.68053,
            "recall": 0.75481,
            "fmeasure": 0.70714
        },
        "rougeLsum": {
            "precision": 0.68053,
            "recall": 0.75481,
            "fmeasure": 0.70714
        },
        "nist": 3.9470823412504883,
        "bleurt": 0.25777,
        "bertscore": {
            "precision": 0.92249,
            "recall": 0.92722,
            "f1": 0.92384
        },
        "nubia": {
            "semantic_relation": 4.22827,
            "contradiction": 16.60679,
            "irrelevancy": 50.38972,
            "logical_agreement": 33.00349,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.18927,
            "nubia_score": 0.76282
        },
        "meteor": 0.38753311794096473
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.745,
        "total_length": 264,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 5.32290647422377,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 156,
        "unique-1": 128,
        "entropy-1": 6.559095570454658,
        "distinct-2": 0.9065040650406504,
        "vocab_size-2": 223,
        "unique-2": 210,
        "entropy-2": 7.679064768318242,
        "cond_entropy-2": 0.9235331159704911,
        "distinct-3": 0.9824561403508771,
        "vocab_size-3": 224,
        "unique-3": 220,
        "entropy-3": 7.79780229486653,
        "cond_entropy-3": 0.13076426017275503,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.011098792790969,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6495726495726496,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.657369480541652,
        "distinct-2-nopunct": 0.9074074074074074,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.48612015121434,
        "cond_entropy-2-nopunct": 0.9086069290154182,
        "distinct-3-nopunct": 0.9848484848484849,
        "vocab_size-3-nopunct": 195,
        "unique-3-nopunct": 192,
        "entropy-3-nopunct": 7.599053589776562,
        "cond_entropy-3-nopunct": 0.1323163290525562,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.87595,
        "local_recall": {
            "1": 0.17307692307692307,
            "2": 0.4482758620689655,
            "3": 0.8043478260869565
        },
        "rouge1": {
            "precision": 0.81266,
            "recall": 0.79148,
            "fmeasure": 0.79108
        },
        "rouge2": {
            "precision": 0.53881,
            "recall": 0.54687,
            "fmeasure": 0.53526
        },
        "rougeL": {
            "precision": 0.70078,
            "recall": 0.69093,
            "fmeasure": 0.68518
        },
        "rougeLsum": {
            "precision": 0.70078,
            "recall": 0.69093,
            "fmeasure": 0.68518
        },
        "nist": 5.858178660719594,
        "bleurt": 0.23915,
        "bertscore": {
            "precision": 0.93055,
            "recall": 0.93174,
            "f1": 0.93024
        },
        "nubia": {
            "semantic_relation": 4.32415,
            "contradiction": 5.65661,
            "irrelevancy": 28.6192,
            "logical_agreement": 65.72419,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.72552,
            "nubia_score": 0.7459
        },
        "meteor": 0.40077672804576264
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "total_length": 111,
        "mean_pred_length": 18.5,
        "std_pred_length": 4.681523968396046,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 74,
        "unique-1": 59,
        "entropy-1": 5.79761223649341,
        "distinct-2": 0.9238095238095239,
        "vocab_size-2": 97,
        "unique-2": 91,
        "entropy-2": 6.542816946237543,
        "cond_entropy-2": 0.6417446359040984,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 96,
        "unique-3": 93,
        "entropy-3": 6.56875055947356,
        "cond_entropy-3": 0.036323223625608275,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.82749724649119,
        "distinct-2-nopunct": 0.9139784946236559,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.345610424011262,
        "cond_entropy-2-nopunct": 0.5698460403322295,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.373977978607343,
        "cond_entropy-3-nopunct": 0.04171571922345565,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.73211,
        "local_recall": {
            "1": 0.1,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.57697,
            "recall": 0.70538,
            "fmeasure": 0.61698
        },
        "rouge2": {
            "precision": 0.35584,
            "recall": 0.45311,
            "fmeasure": 0.38659
        },
        "rougeL": {
            "precision": 0.47466,
            "recall": 0.60469,
            "fmeasure": 0.51803
        },
        "rougeLsum": {
            "precision": 0.47466,
            "recall": 0.60469,
            "fmeasure": 0.51803
        },
        "nist": 3.4213668208094967,
        "bleurt": -0.05222,
        "bertscore": {
            "precision": 0.86445,
            "recall": 0.89037,
            "f1": 0.87617
        },
        "nubia": {
            "semantic_relation": 3.66587,
            "contradiction": 1.24964,
            "irrelevancy": 73.38122,
            "logical_agreement": 25.36914,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.23145,
            "nubia_score": 0.58462
        },
        "meteor": 0.3606258418439894
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.73,
        "total_length": 135,
        "mean_pred_length": 22.5,
        "std_pred_length": 12.446552400832395,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 46,
        "distinct-1": 0.6592592592592592,
        "vocab_size-1": 89,
        "unique-1": 72,
        "entropy-1": 6.060879001934025,
        "distinct-2": 0.9457364341085271,
        "vocab_size-2": 122,
        "unique-2": 116,
        "entropy-2": 6.896848282538248,
        "cond_entropy-2": 0.7629913315063802,
        "distinct-3": 0.991869918699187,
        "vocab_size-3": 122,
        "unique-3": 121,
        "entropy-3": 6.926254342737602,
        "cond_entropy-3": 0.0349855222912984,
        "total_length-nopunct": 116,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 9.3571125650788,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.7241379310344828,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.095719060751957,
        "distinct-2-nopunct": 0.9727272727272728,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.726814258979213,
        "cond_entropy-2-nopunct": 0.6635822128295448,
        "distinct-3-nopunct": 0.9903846153846154,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.68120894891033,
        "cond_entropy-3-nopunct": -0.04245845692202885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.15745,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5319148936170213,
            "3": 0.8548387096774194
        },
        "rouge1": {
            "precision": 0.8075,
            "recall": 0.75623,
            "fmeasure": 0.77226
        },
        "rouge2": {
            "precision": 0.46092,
            "recall": 0.44928,
            "fmeasure": 0.44992
        },
        "rougeL": {
            "precision": 0.66053,
            "recall": 0.63883,
            "fmeasure": 0.64174
        },
        "rougeLsum": {
            "precision": 0.66053,
            "recall": 0.63883,
            "fmeasure": 0.64174
        },
        "nist": 5.612399574208388,
        "bleurt": 0.07679,
        "bertscore": {
            "precision": 0.92301,
            "recall": 0.91158,
            "f1": 0.91576
        },
        "nubia": {
            "semantic_relation": 3.89743,
            "contradiction": 6.58267,
            "irrelevancy": 30.05263,
            "logical_agreement": 63.36471,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.99055,
            "nubia_score": 0.61169
        },
        "meteor": 0.3807936771067704
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 121,
        "mean_pred_length": 13.444444444444445,
        "std_pred_length": 4.139541335599368,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6528925619834711,
        "vocab_size-1": 79,
        "unique-1": 59,
        "entropy-1": 5.9836688943318626,
        "distinct-2": 0.8928571428571429,
        "vocab_size-2": 100,
        "unique-2": 88,
        "entropy-2": 6.593069207771883,
        "cond_entropy-2": 0.4298237426677487,
        "distinct-3": 0.9223300970873787,
        "vocab_size-3": 95,
        "unique-3": 87,
        "entropy-3": 6.531160721357992,
        "cond_entropy-3": -0.04318449196176438,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 11.777777777777779,
        "std_pred_length-nopunct": 3.8232556742411674,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7264150943396226,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 6.075850497216359,
        "distinct-2-nopunct": 0.8865979381443299,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.373108718475797,
        "cond_entropy-2-nopunct": 0.34745027915757515,
        "distinct-3-nopunct": 0.9204545454545454,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.300340709546395,
        "cond_entropy-3-nopunct": -0.06093576900437598,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.75363,
        "local_recall": {
            "1": 0.43243243243243246,
            "2": 0.6,
            "3": 0.8117647058823529
        },
        "rouge1": {
            "precision": 0.88796,
            "recall": 0.78321,
            "fmeasure": 0.82299
        },
        "rouge2": {
            "precision": 0.70316,
            "recall": 0.61695,
            "fmeasure": 0.64877
        },
        "rougeL": {
            "precision": 0.82454,
            "recall": 0.73842,
            "fmeasure": 0.76783
        },
        "rougeLsum": {
            "precision": 0.82454,
            "recall": 0.73842,
            "fmeasure": 0.76783
        },
        "nist": 6.039131472488949,
        "bleurt": 0.33795,
        "bertscore": {
            "precision": 0.96175,
            "recall": 0.93487,
            "f1": 0.94695
        },
        "nubia": {
            "semantic_relation": 4.2845,
            "contradiction": 0.77769,
            "irrelevancy": 18.28724,
            "logical_agreement": 80.93507,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.013,
            "nubia_score": 0.73355
        },
        "meteor": 0.43569657087536606
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75333,
        "total_length": 414,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.971993664094504,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.5652173913043478,
        "vocab_size-1": 234,
        "unique-1": 197,
        "entropy-1": 6.993314738915027,
        "distinct-2": 0.9335038363171355,
        "vocab_size-2": 365,
        "unique-2": 350,
        "entropy-2": 8.432062729657694,
        "cond_entropy-2": 1.272666241479538,
        "distinct-3": 0.9891304347826086,
        "vocab_size-3": 364,
        "unique-3": 360,
        "entropy-3": 8.501822825622305,
        "cond_entropy-3": 0.06802433524116504,
        "total_length-nopunct": 353,
        "mean_pred_length-nopunct": 15.347826086956522,
        "std_pred_length-nopunct": 6.040505994153671,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6487252124645893,
        "vocab_size-1-nopunct": 229,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 7.181050099187363,
        "distinct-2-nopunct": 0.9303030303030303,
        "vocab_size-2-nopunct": 307,
        "unique-2-nopunct": 294,
        "entropy-2-nopunct": 8.17474863561291,
        "cond_entropy-2-nopunct": 1.0674166676451267,
        "distinct-3-nopunct": 0.990228013029316,
        "vocab_size-3-nopunct": 304,
        "unique-3-nopunct": 301,
        "entropy-3-nopunct": 8.24255087142877,
        "cond_entropy-3-nopunct": 0.08215465375913066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.75887,
        "local_recall": {
            "1": 0.3561643835616438,
            "2": 0.37209302325581395,
            "3": 0.7948717948717948
        },
        "rouge1": {
            "precision": 0.75537,
            "recall": 0.71121,
            "fmeasure": 0.71906
        },
        "rouge2": {
            "precision": 0.56405,
            "recall": 0.52922,
            "fmeasure": 0.53428
        },
        "rougeL": {
            "precision": 0.6781,
            "recall": 0.65443,
            "fmeasure": 0.65319
        },
        "rougeLsum": {
            "precision": 0.6781,
            "recall": 0.65443,
            "fmeasure": 0.65319
        },
        "nist": 6.46536006936123,
        "bleurt": 0.32604,
        "bertscore": {
            "precision": 0.93666,
            "recall": 0.92681,
            "f1": 0.93018
        },
        "nubia": {
            "semantic_relation": 4.2844,
            "contradiction": 4.79908,
            "irrelevancy": 29.33285,
            "logical_agreement": 65.86807,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.36522,
            "nubia_score": 0.76092
        },
        "meteor": 0.38370648888849584
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.556088322639177,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.07301345156046951,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.031031312388743938,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.504706483564823,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.07916418769779474,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.95863,
        "local_recall": {
            "1": 0.3125,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.7627,
            "recall": 0.69778,
            "fmeasure": 0.72197
        },
        "rouge2": {
            "precision": 0.63004,
            "recall": 0.58333,
            "fmeasure": 0.60126
        },
        "rougeL": {
            "precision": 0.72698,
            "recall": 0.66676,
            "fmeasure": 0.68959
        },
        "rougeLsum": {
            "precision": 0.72698,
            "recall": 0.66676,
            "fmeasure": 0.68959
        },
        "nist": 4.362135172179068,
        "bleurt": 0.27294,
        "bertscore": {
            "precision": 0.93763,
            "recall": 0.9456,
            "f1": 0.9323
        },
        "nubia": {
            "semantic_relation": 3.43039,
            "contradiction": 30.95395,
            "irrelevancy": 11.89626,
            "logical_agreement": 57.14979,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.29886,
            "nubia_score": 0.52818
        },
        "meteor": 0.42023235312219764
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.745,
        "total_length": 328,
        "mean_pred_length": 18.22222222222222,
        "std_pred_length": 6.721074282149607,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.600609756097561,
        "vocab_size-1": 197,
        "unique-1": 165,
        "entropy-1": 6.9052646585298625,
        "distinct-2": 0.964516129032258,
        "vocab_size-2": 299,
        "unique-2": 289,
        "entropy-2": 8.202721542364005,
        "cond_entropy-2": 1.139658568362006,
        "distinct-3": 0.9965753424657534,
        "vocab_size-3": 291,
        "unique-3": 290,
        "entropy-3": 8.182975243811564,
        "cond_entropy-3": -0.015221464537496107,
        "total_length-nopunct": 287,
        "mean_pred_length-nopunct": 15.944444444444445,
        "std_pred_length-nopunct": 5.967245988842594,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6689895470383276,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 7.067858015200988,
        "distinct-2-nopunct": 0.966542750929368,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 8.001741591173088,
        "cond_entropy-2-nopunct": 1.0072920533198477,
        "distinct-3-nopunct": 0.9960159362549801,
        "vocab_size-3-nopunct": 250,
        "unique-3-nopunct": 249,
        "entropy-3-nopunct": 7.963575426460726,
        "cond_entropy-3-nopunct": -0.03316626875659519,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.93383,
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.5352112676056338,
            "3": 0.7150537634408602
        },
        "rouge1": {
            "precision": 0.70494,
            "recall": 0.70125,
            "fmeasure": 0.686
        },
        "rouge2": {
            "precision": 0.45401,
            "recall": 0.44833,
            "fmeasure": 0.43898
        },
        "rougeL": {
            "precision": 0.59329,
            "recall": 0.59455,
            "fmeasure": 0.58021
        },
        "rougeLsum": {
            "precision": 0.59329,
            "recall": 0.59455,
            "fmeasure": 0.58021
        },
        "nist": 5.322071703277924,
        "bleurt": 0.03639,
        "bertscore": {
            "precision": 0.90309,
            "recall": 0.90923,
            "f1": 0.90367
        },
        "nubia": {
            "semantic_relation": 3.88844,
            "contradiction": 17.86453,
            "irrelevancy": 36.59966,
            "logical_agreement": 45.53581,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.4839,
            "nubia_score": 0.63077
        },
        "meteor": 0.3524325719866158
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.11603,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.55,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "nist": 3.7913310434313825,
        "bleurt": 0.29208,
        "bertscore": {
            "precision": 0.96286,
            "recall": 0.94809,
            "f1": 0.95542
        },
        "nubia": {
            "semantic_relation": 4.0584,
            "contradiction": 0.41127,
            "irrelevancy": 35.16538,
            "logical_agreement": 64.42336,
            "grammar_ref": 4.09688,
            "grammar_hyp": 4.65525,
            "nubia_score": 0.68652
        },
        "meteor": 0.5566661162140665
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8809523809523809,
        "vocab_size-1": 37,
        "unique-1": 34,
        "entropy-1": 5.1182751607709775,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.06628703972870521,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.982289237493324,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.07916267858776121,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.28335,
        "local_recall": {
            "1": 0.25,
            "2": 0.42857142857142855,
            "3": 0.8928571428571429
        },
        "rouge1": {
            "precision": 0.86532,
            "recall": 0.81125,
            "fmeasure": 0.83317
        },
        "rouge2": {
            "precision": 0.63651,
            "recall": 0.57258,
            "fmeasure": 0.59893
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.76821,
            "fmeasure": 0.78663
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.76821,
            "fmeasure": 0.78663
        },
        "nist": 5.109197517678356,
        "bleurt": 0.35669,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.95525,
            "f1": 0.95393
        },
        "nubia": {
            "semantic_relation": 4.56557,
            "contradiction": 0.39114,
            "irrelevancy": 36.55433,
            "logical_agreement": 63.05453,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.86111,
            "nubia_score": 0.8421
        },
        "meteor": 0.4244125852843265
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.70518,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.42892,
            "fmeasure": 0.46165
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "nist": 2.685626501798519,
        "bleurt": 0.46477,
        "bertscore": {
            "precision": 0.96128,
            "recall": 0.93692,
            "f1": 0.94894
        },
        "nubia": {
            "semantic_relation": 4.87694,
            "contradiction": 0.09518,
            "irrelevancy": 0.57155,
            "logical_agreement": 99.33328,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.4232,
            "nubia_score": 0.97292
        },
        "meteor": 0.41081248021664324
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.73286,
        "msttr-100_nopunct": 0.77,
        "total_length": 762,
        "mean_pred_length": 18.142857142857142,
        "std_pred_length": 5.9584730729058615,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5564304461942258,
        "vocab_size-1": 424,
        "unique-1": 345,
        "entropy-1": 7.775403687729493,
        "distinct-2": 0.9208333333333333,
        "vocab_size-2": 663,
        "unique-2": 625,
        "entropy-2": 9.293528113663829,
        "cond_entropy-2": 1.306489852729467,
        "distinct-3": 0.9852507374631269,
        "vocab_size-3": 668,
        "unique-3": 659,
        "entropy-3": 9.374529534667001,
        "cond_entropy-3": 0.09033718689119331,
        "total_length-nopunct": 674,
        "mean_pred_length-nopunct": 16.047619047619047,
        "std_pred_length-nopunct": 5.232464506067503,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6216617210682492,
        "vocab_size-1-nopunct": 419,
        "unique-1-nopunct": 345,
        "entropy-1-nopunct": 7.97442347582665,
        "distinct-2-nopunct": 0.9193037974683544,
        "vocab_size-2-nopunct": 581,
        "unique-2-nopunct": 549,
        "entropy-2-nopunct": 9.096828236279201,
        "cond_entropy-2-nopunct": 1.1960783202998253,
        "distinct-3-nopunct": 0.9864406779661017,
        "vocab_size-3-nopunct": 582,
        "unique-3-nopunct": 575,
        "entropy-3-nopunct": 9.176173029838854,
        "cond_entropy-3-nopunct": 0.09238209101668994,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.71589,
        "local_recall": {
            "1": 0.16521739130434782,
            "2": 0.46236559139784944,
            "3": 0.8223140495867769
        },
        "rouge1": {
            "precision": 0.74344,
            "recall": 0.78213,
            "fmeasure": 0.75387
        },
        "rouge2": {
            "precision": 0.54299,
            "recall": 0.57007,
            "fmeasure": 0.55152
        },
        "rougeL": {
            "precision": 0.64093,
            "recall": 0.67868,
            "fmeasure": 0.65245
        },
        "rougeLsum": {
            "precision": 0.64093,
            "recall": 0.67868,
            "fmeasure": 0.65245
        },
        "nist": 6.56702764493014,
        "bleurt": 0.36278,
        "bertscore": {
            "precision": 0.92776,
            "recall": 0.93608,
            "f1": 0.93074
        },
        "nubia": {
            "semantic_relation": 4.34566,
            "contradiction": 9.12191,
            "irrelevancy": 28.74984,
            "logical_agreement": 62.12825,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.53058,
            "nubia_score": 0.76797
        },
        "meteor": 0.4168790712487163
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 5.931905258852336,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6557377049180327,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.041152706308944,
        "distinct-2": 0.9649122807017544,
        "vocab_size-2": 55,
        "unique-2": 53,
        "entropy-2": 5.762714575568245,
        "cond_entropy-2": 0.6436379837332662,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.029497861488334932,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 5.629165124598851,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6909090909090909,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9765476679521035,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.59399396942248,
        "cond_entropy-2-nopunct": 0.6609609717113538,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.054006703059815496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.1195,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.775
        },
        "rouge1": {
            "precision": 0.69927,
            "recall": 0.81919,
            "fmeasure": 0.75104
        },
        "rouge2": {
            "precision": 0.46434,
            "recall": 0.55079,
            "fmeasure": 0.50068
        },
        "rougeL": {
            "precision": 0.57882,
            "recall": 0.69045,
            "fmeasure": 0.6264
        },
        "rougeLsum": {
            "precision": 0.57882,
            "recall": 0.69045,
            "fmeasure": 0.6264
        },
        "nist": 4.392191969073799,
        "bleurt": 0.19401,
        "bertscore": {
            "precision": 0.91532,
            "recall": 0.9312,
            "f1": 0.92306
        },
        "nubia": {
            "semantic_relation": 4.61295,
            "contradiction": 0.34188,
            "irrelevancy": 26.37498,
            "logical_agreement": 73.28315,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.69141,
            "nubia_score": 0.84868
        },
        "meteor": 0.43667331465214504
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.8,
        "total_length": 441,
        "mean_pred_length": 17.64,
        "std_pred_length": 7.7659770795438225,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.6145124716553289,
        "vocab_size-1": 271,
        "unique-1": 238,
        "entropy-1": 7.300246202161765,
        "distinct-2": 0.9182692307692307,
        "vocab_size-2": 382,
        "unique-2": 361,
        "entropy-2": 8.500237284210439,
        "cond_entropy-2": 1.0101192343095948,
        "distinct-3": 0.9872122762148338,
        "vocab_size-3": 386,
        "unique-3": 382,
        "entropy-3": 8.58351869116376,
        "cond_entropy-3": 0.09096698457030337,
        "total_length-nopunct": 381,
        "mean_pred_length-nopunct": 15.24,
        "std_pred_length-nopunct": 6.7009253092390155,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6981627296587927,
        "vocab_size-1-nopunct": 266,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.503502831919321,
        "distinct-2-nopunct": 0.9297752808988764,
        "vocab_size-2-nopunct": 331,
        "unique-2-nopunct": 318,
        "entropy-2-nopunct": 8.294471282053559,
        "cond_entropy-2-nopunct": 0.8633100481380188,
        "distinct-3-nopunct": 0.9909365558912386,
        "vocab_size-3-nopunct": 328,
        "unique-3-nopunct": 326,
        "entropy-3-nopunct": 8.350279891694887,
        "cond_entropy-3-nopunct": 0.06949910427229258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.42012,
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.32558139534883723,
            "3": 0.8733766233766234
        },
        "rouge1": {
            "precision": 0.81712,
            "recall": 0.7996,
            "fmeasure": 0.8018
        },
        "rouge2": {
            "precision": 0.61568,
            "recall": 0.61407,
            "fmeasure": 0.61164
        },
        "rougeL": {
            "precision": 0.73126,
            "recall": 0.71456,
            "fmeasure": 0.7171
        },
        "rougeLsum": {
            "precision": 0.73126,
            "recall": 0.71456,
            "fmeasure": 0.7171
        },
        "nist": 6.84923955814598,
        "bleurt": 0.44729,
        "bertscore": {
            "precision": 0.9485,
            "recall": 0.94959,
            "f1": 0.94863
        },
        "nubia": {
            "semantic_relation": 4.46678,
            "contradiction": 5.23341,
            "irrelevancy": 27.0394,
            "logical_agreement": 67.72719,
            "grammar_ref": 4.85173,
            "grammar_hyp": 4.9636,
            "nubia_score": 0.79307
        },
        "meteor": 0.4491252554582316
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 14.142857142857142,
        "std_pred_length": 3.5225222874108435,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7474747474747475,
        "vocab_size-1": 74,
        "unique-1": 66,
        "entropy-1": 5.88172013087756,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 90,
        "unique-2": 88,
        "entropy-2": 6.480083695187461,
        "cond_entropy-2": 0.4416458574621893,
        "distinct-3": 1.0,
        "vocab_size-3": 85,
        "unique-3": 85,
        "entropy-3": 6.409390936137707,
        "cond_entropy-3": -0.06711219638989925,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 12.571428571428571,
        "std_pred_length-nopunct": 2.9692299558323607,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.932561982539573,
        "distinct-2-nopunct": 0.9753086419753086,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.290467286835232,
        "cond_entropy-2-nopunct": 0.40343724815597315,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.07634258320162127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.03881,
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 0.6296296296296297,
            "3": 0.6461538461538462
        },
        "rouge1": {
            "precision": 0.72905,
            "recall": 0.68259,
            "fmeasure": 0.68811
        },
        "rouge2": {
            "precision": 0.50397,
            "recall": 0.4549,
            "fmeasure": 0.46528
        },
        "rougeL": {
            "precision": 0.68126,
            "recall": 0.65889,
            "fmeasure": 0.65587
        },
        "rougeLsum": {
            "precision": 0.68126,
            "recall": 0.65889,
            "fmeasure": 0.65587
        },
        "nist": 5.0806790361746055,
        "bleurt": 0.29166,
        "bertscore": {
            "precision": 0.94367,
            "recall": 0.93405,
            "f1": 0.93847
        },
        "nubia": {
            "semantic_relation": 4.23372,
            "contradiction": 5.70739,
            "irrelevancy": 42.43271,
            "logical_agreement": 51.8599,
            "grammar_ref": 4.57813,
            "grammar_hyp": 3.99052,
            "nubia_score": 0.77128
        },
        "meteor": 0.3552806826953125
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.9375,
        "vocab_size-1": 30,
        "unique-1": 28,
        "entropy-1": 4.875,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.02644273772481478,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9629629629629629,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6808134280893965,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.031031312388743945,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.12492,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7307692307692307
        },
        "rouge1": {
            "precision": 0.87255,
            "recall": 0.78393,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.78125,
            "recall": 0.71104,
            "fmeasure": 0.74111
        },
        "rougeL": {
            "precision": 0.81373,
            "recall": 0.73913,
            "fmeasure": 0.77137
        },
        "rougeLsum": {
            "precision": 0.81373,
            "recall": 0.73913,
            "fmeasure": 0.77137
        },
        "nist": 3.650004148963776,
        "bleurt": 0.09667,
        "bertscore": {
            "precision": 0.92734,
            "recall": 0.92441,
            "f1": 0.92587
        },
        "nubia": {
            "semantic_relation": 4.17416,
            "contradiction": 0.50895,
            "irrelevancy": 1.32963,
            "logical_agreement": 98.16143,
            "grammar_ref": 4.36539,
            "grammar_hyp": 5.22687,
            "nubia_score": 0.68281
        },
        "meteor": 0.3902892917378163
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.373660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.22255995686990962,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1523912776298655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.254547113768295,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.66757,
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.49275,
            "recall": 0.67236,
            "fmeasure": 0.5664
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.57026,
            "fmeasure": 0.47411
        },
        "rougeL": {
            "precision": 0.31884,
            "recall": 0.45014,
            "fmeasure": 0.37127
        },
        "rougeLsum": {
            "precision": 0.31884,
            "recall": 0.45014,
            "fmeasure": 0.37127
        },
        "nist": 3.1225342922902652,
        "bleurt": -0.40555,
        "bertscore": {
            "precision": 0.89877,
            "recall": 0.91744,
            "f1": 0.90801
        },
        "nubia": {
            "semantic_relation": 1.82552,
            "contradiction": 97.47153,
            "irrelevancy": 2.24117,
            "logical_agreement": 0.28731,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.22665,
            "nubia_score": 0.23451
        },
        "meteor": 0.39730943737410385
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 18.8,
        "std_pred_length": 7.782030583337488,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 70,
        "unique-1": 62,
        "entropy-1": 5.828643841491166,
        "distinct-2": 0.9887640449438202,
        "vocab_size-2": 88,
        "unique-2": 87,
        "entropy-2": 6.453261520854051,
        "cond_entropy-2": 0.5349557083122509,
        "distinct-3": 1.0,
        "vocab_size-3": 84,
        "unique-3": 84,
        "entropy-3": 6.39231742277876,
        "cond_entropy-3": -0.059606484378113646,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 16.4,
        "std_pred_length-nopunct": 7.863841300535,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8048780487804879,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.808533102073527,
        "distinct-2-nopunct": 0.987012987012987,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.240812514720878,
        "cond_entropy-2-nopunct": 0.46792999073465985,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.06908376147481121,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.40323,
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.3125,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.68071,
            "recall": 0.68662,
            "fmeasure": 0.67403
        },
        "rouge2": {
            "precision": 0.42878,
            "recall": 0.46965,
            "fmeasure": 0.43483
        },
        "rougeL": {
            "precision": 0.51551,
            "recall": 0.60742,
            "fmeasure": 0.53488
        },
        "rougeLsum": {
            "precision": 0.51551,
            "recall": 0.60742,
            "fmeasure": 0.53488
        },
        "nist": 4.509192187582734,
        "bleurt": -0.05174,
        "bertscore": {
            "precision": 0.90948,
            "recall": 0.9194,
            "f1": 0.90206
        },
        "nubia": {
            "semantic_relation": 3.71446,
            "contradiction": 9.94809,
            "irrelevancy": 51.43691,
            "logical_agreement": 38.615,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.19893,
            "nubia_score": 0.55077
        },
        "meteor": 0.3621937476938176
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74,
        "total_length": 240,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.164414002968976,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6208333333333333,
        "vocab_size-1": 149,
        "unique-1": 119,
        "entropy-1": 6.6743564096394215,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 222,
        "unique-2": 217,
        "entropy-2": 7.776947525120199,
        "cond_entropy-2": 0.9787790989148721,
        "distinct-3": 0.9953703703703703,
        "vocab_size-3": 215,
        "unique-3": 214,
        "entropy-3": 7.745628242904204,
        "cond_entropy-3": -0.028211366157923874,
        "total_length-nopunct": 210,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.86657196893268,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6857142857142857,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.758612478198966,
        "distinct-2-nopunct": 0.9646464646464646,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.554836986230282,
        "cond_entropy-2-nopunct": 0.8440406518374142,
        "distinct-3-nopunct": 0.9946236559139785,
        "vocab_size-3-nopunct": 185,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.528406122936004,
        "cond_entropy-3-nopunct": -0.02162314498145196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.70488,
        "local_recall": {
            "1": 0.16,
            "2": 0.15384615384615385,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.77295,
            "recall": 0.74793,
            "fmeasure": 0.74875
        },
        "rouge2": {
            "precision": 0.5311,
            "recall": 0.50939,
            "fmeasure": 0.51042
        },
        "rougeL": {
            "precision": 0.65493,
            "recall": 0.62723,
            "fmeasure": 0.62961
        },
        "rougeLsum": {
            "precision": 0.65493,
            "recall": 0.62723,
            "fmeasure": 0.62961
        },
        "nist": 5.476536693477702,
        "bleurt": 0.31638,
        "bertscore": {
            "precision": 0.93304,
            "recall": 0.92278,
            "f1": 0.92606
        },
        "nubia": {
            "semantic_relation": 4.35043,
            "contradiction": 12.09422,
            "irrelevancy": 24.47629,
            "logical_agreement": 63.4295,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.38927,
            "nubia_score": 0.77833
        },
        "meteor": 0.3566725022099864
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 12.25,
        "std_pred_length": 3.526683994916471,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.5510204081632653,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.302167084083674,
        "distinct-2": 0.7444444444444445,
        "vocab_size-2": 67,
        "unique-2": 57,
        "entropy-2": 5.822245735146438,
        "cond_entropy-2": 0.3700824519544693,
        "distinct-3": 0.8170731707317073,
        "vocab_size-3": 67,
        "unique-3": 60,
        "entropy-3": 5.900115724077512,
        "cond_entropy-3": 0.11880729246113399,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 10.625,
        "std_pred_length-nopunct": 2.6427968139832467,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5882352941176471,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.234399136362091,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.510102612039182,
        "cond_entropy-2-nopunct": 0.3416516094864134,
        "distinct-3-nopunct": 0.7971014492753623,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.5938900364255995,
        "cond_entropy-3-nopunct": 0.14253338712911512,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.067,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.86858,
            "recall": 0.82796,
            "fmeasure": 0.83457
        },
        "rouge2": {
            "precision": 0.75685,
            "recall": 0.70592,
            "fmeasure": 0.71956
        },
        "rougeL": {
            "precision": 0.8441,
            "recall": 0.79237,
            "fmeasure": 0.80593
        },
        "rougeLsum": {
            "precision": 0.8441,
            "recall": 0.79237,
            "fmeasure": 0.80593
        },
        "nist": 5.276879659659092,
        "bleurt": 0.67733,
        "bertscore": {
            "precision": 0.9691,
            "recall": 0.96259,
            "f1": 0.96499
        },
        "nubia": {
            "semantic_relation": 4.62599,
            "contradiction": 0.30158,
            "irrelevancy": 24.98816,
            "logical_agreement": 74.71026,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.91525,
            "nubia_score": 0.91554
        },
        "meteor": 0.5048314535620491
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.82,
        "total_length": 121,
        "mean_pred_length": 17.285714285714285,
        "std_pred_length": 4.526565576501389,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.743801652892562,
        "vocab_size-1": 90,
        "unique-1": 75,
        "entropy-1": 6.255386584898616,
        "distinct-2": 0.9912280701754386,
        "vocab_size-2": 113,
        "unique-2": 112,
        "entropy-2": 6.81534615451563,
        "cond_entropy-2": 0.4283179214786616,
        "distinct-3": 1.0,
        "vocab_size-3": 107,
        "unique-3": 107,
        "entropy-3": 6.741466986401138,
        "cond_entropy-3": -0.07273143897854793,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 15.142857142857142,
        "std_pred_length-nopunct": 4.389226141639204,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8018867924528302,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.245661817971077,
        "distinct-2-nopunct": 0.98989898989899,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.609154599877599,
        "cond_entropy-2-nopunct": 0.397591877423115,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.523561956057027,
        "cond_entropy-3-nopunct": -0.0840555335878139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.40264,
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.5217391304347826,
            "3": 0.7017543859649122
        },
        "rouge1": {
            "precision": 0.60665,
            "recall": 0.67642,
            "fmeasure": 0.61374
        },
        "rouge2": {
            "precision": 0.26168,
            "recall": 0.33156,
            "fmeasure": 0.27954
        },
        "rougeL": {
            "precision": 0.45609,
            "recall": 0.52426,
            "fmeasure": 0.46564
        },
        "rougeLsum": {
            "precision": 0.45609,
            "recall": 0.52426,
            "fmeasure": 0.46564
        },
        "nist": 3.915859073350929,
        "bleurt": -0.02365,
        "bertscore": {
            "precision": 0.88696,
            "recall": 0.89054,
            "f1": 0.88426
        },
        "nubia": {
            "semantic_relation": 3.88188,
            "contradiction": 0.31909,
            "irrelevancy": 56.00883,
            "logical_agreement": 43.67208,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.58101,
            "nubia_score": 0.63242
        },
        "meteor": 0.30705497754152883
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 44,
        "unique-1": 36,
        "entropy-1": 5.347480094756062,
        "distinct-2": 0.94,
        "vocab_size-2": 47,
        "unique-2": 44,
        "entropy-2": 5.523856189774728,
        "cond_entropy-2": 0.04896868761125601,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 44,
        "unique-3": 42,
        "entropy-3": 5.43660543431788,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 0.82915619758885,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.328995558400923,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.358519762996339,
        "cond_entropy-2-nopunct": 0.05492102999224414,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.259991029008325,
        "cond_entropy-3-nopunct": -0.08552060390671316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.37046,
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.89886,
            "recall": 0.82916,
            "fmeasure": 0.86101
        },
        "rouge2": {
            "precision": 0.71117,
            "recall": 0.66311,
            "fmeasure": 0.68508
        },
        "rougeL": {
            "precision": 0.82479,
            "recall": 0.77108,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.82479,
            "recall": 0.77108,
            "fmeasure": 0.79593
        },
        "nist": 5.609615547481571,
        "bleurt": 0.51397,
        "bertscore": {
            "precision": 0.97257,
            "recall": 0.96112,
            "f1": 0.96227
        },
        "nubia": {
            "semantic_relation": 4.82247,
            "contradiction": 0.41518,
            "irrelevancy": 0.62628,
            "logical_agreement": 98.95854,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.62446,
            "nubia_score": 0.94791
        },
        "meteor": 0.4994876571578188
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.752,
        "msttr-100_nopunct": 0.814,
        "total_length": 589,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.543422685124546,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.5534804753820034,
        "vocab_size-1": 326,
        "unique-1": 260,
        "entropy-1": 7.530143296981911,
        "distinct-2": 0.8960573476702509,
        "vocab_size-2": 500,
        "unique-2": 460,
        "entropy-2": 8.877260010822354,
        "cond_entropy-2": 1.1647713925327061,
        "distinct-3": 0.9563567362428842,
        "vocab_size-3": 504,
        "unique-3": 485,
        "entropy-3": 8.94609078735525,
        "cond_entropy-3": 0.07955696311970374,
        "total_length-nopunct": 503,
        "mean_pred_length-nopunct": 16.225806451612904,
        "std_pred_length-nopunct": 6.333269437580454,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6381709741550696,
        "vocab_size-1-nopunct": 321,
        "unique-1-nopunct": 260,
        "entropy-1-nopunct": 7.777007242259167,
        "distinct-2-nopunct": 0.9216101694915254,
        "vocab_size-2-nopunct": 435,
        "unique-2-nopunct": 408,
        "entropy-2-nopunct": 8.699318208232663,
        "cond_entropy-2-nopunct": 0.9820837142326236,
        "distinct-3-nopunct": 0.9682539682539683,
        "vocab_size-3-nopunct": 427,
        "unique-3-nopunct": 413,
        "entropy-3-nopunct": 8.721142782065497,
        "cond_entropy-3-nopunct": 0.030176206655952952,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.17361,
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.3875,
            "3": 0.8837837837837837
        },
        "rouge1": {
            "precision": 0.81699,
            "recall": 0.83129,
            "fmeasure": 0.81732
        },
        "rouge2": {
            "precision": 0.60785,
            "recall": 0.62132,
            "fmeasure": 0.60795
        },
        "rougeL": {
            "precision": 0.70415,
            "recall": 0.72925,
            "fmeasure": 0.70847
        },
        "rougeLsum": {
            "precision": 0.70415,
            "recall": 0.72925,
            "fmeasure": 0.70847
        },
        "nist": 7.5444909015124715,
        "bleurt": 0.47599,
        "bertscore": {
            "precision": 0.94851,
            "recall": 0.94925,
            "f1": 0.94682
        },
        "nubia": {
            "semantic_relation": 4.50005,
            "contradiction": 4.94811,
            "irrelevancy": 19.36181,
            "logical_agreement": 75.69008,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.6319,
            "nubia_score": 0.80441
        },
        "meteor": 0.454219664627832
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.5495097567963922,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.19423567775942,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.11889837932894697,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.13750352374993507,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 1.7853571071357126,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.926829268292683,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.211210541203447,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.01406352317302826,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.16505924627049623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.42473,
        "local_recall": {
            "1": 0.12,
            "2": 0.625,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.77399,
            "recall": 0.81187,
            "fmeasure": 0.78858
        },
        "rouge2": {
            "precision": 0.62464,
            "recall": 0.64827,
            "fmeasure": 0.633
        },
        "rougeL": {
            "precision": 0.62816,
            "recall": 0.66421,
            "fmeasure": 0.64183
        },
        "rougeLsum": {
            "precision": 0.62816,
            "recall": 0.66421,
            "fmeasure": 0.64183
        },
        "nist": 4.681094823802718,
        "bleurt": 0.16216,
        "bertscore": {
            "precision": 0.91661,
            "recall": 0.93987,
            "f1": 0.92449
        },
        "nubia": {
            "semantic_relation": 4.15481,
            "contradiction": 4.85931,
            "irrelevancy": 26.0025,
            "logical_agreement": 69.13819,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.2574,
            "nubia_score": 0.68009
        },
        "meteor": 0.39750024852749244
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.49941,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.39683,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.7,
            "fmeasure": 0.72222
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.7,
            "fmeasure": 0.72222
        },
        "nist": 2.787249197694734,
        "bleurt": 0.55935,
        "bertscore": {
            "precision": 0.97602,
            "recall": 0.97602,
            "f1": 0.97602
        },
        "nubia": {
            "semantic_relation": 4.61525,
            "contradiction": 0.46042,
            "irrelevancy": 0.49333,
            "logical_agreement": 99.04625,
            "grammar_ref": 5.68329,
            "grammar_hyp": 6.18622,
            "nubia_score": 0.80546
        },
        "meteor": 0.48681894622545224
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 7.790218225441442,
        "median_pred_length": 20.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.8309859154929577,
        "vocab_size-1": 59,
        "unique-1": 51,
        "entropy-1": 5.762285499725426,
        "distinct-2": 1.0,
        "vocab_size-2": 67,
        "unique-2": 67,
        "entropy-2": 6.066089190457767,
        "cond_entropy-2": 0.20753274265946275,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.08880926695785608,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 6.442049363362563,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.72764247057246,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.807354922057609,
        "cond_entropy-2-nopunct": 0.09251588898771892,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.46026,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.2894736842105263,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.51553,
            "recall": 0.44798,
            "fmeasure": 0.44286
        },
        "rouge2": {
            "precision": 0.30878,
            "recall": 0.27946,
            "fmeasure": 0.2621
        },
        "rougeL": {
            "precision": 0.4548,
            "recall": 0.38632,
            "fmeasure": 0.38215
        },
        "rougeLsum": {
            "precision": 0.4548,
            "recall": 0.38632,
            "fmeasure": 0.38215
        },
        "nist": 2.9864748309728086,
        "bleurt": -0.53713,
        "bertscore": {
            "precision": 0.82926,
            "recall": 0.8214,
            "f1": 0.82087
        },
        "nubia": {
            "semantic_relation": 3.04537,
            "contradiction": 29.50364,
            "irrelevancy": 43.93502,
            "logical_agreement": 26.56134,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.86015,
            "nubia_score": 0.45893
        },
        "meteor": 0.2885783201971542
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.2972690158966973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.60059,
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.4166666666666667
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.54167,
            "fmeasure": 0.59091
        },
        "rouge2": {
            "precision": 0.31579,
            "recall": 0.26087,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "nist": 2.7645242106209524,
        "bleurt": -0.36268,
        "bertscore": {
            "precision": 0.85317,
            "recall": 0.85095,
            "f1": 0.85206
        },
        "nubia": {
            "semantic_relation": 3.2335,
            "contradiction": 73.92248,
            "irrelevancy": 23.26439,
            "logical_agreement": 2.81313,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.75136,
            "nubia_score": 0.42576
        },
        "meteor": 0.2629380773392699
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.70389,
        "msttr-100_nopunct": 0.75375,
        "total_length": 1878,
        "mean_pred_length": 18.233009708737864,
        "std_pred_length": 6.126821319847889,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.4371671991480298,
        "vocab_size-1": 821,
        "unique-1": 627,
        "entropy-1": 8.144499950724537,
        "distinct-2": 0.819718309859155,
        "vocab_size-2": 1455,
        "unique-2": 1327,
        "entropy-2": 10.2285166227131,
        "cond_entropy-2": 1.853647259546417,
        "distinct-3": 0.9144736842105263,
        "vocab_size-3": 1529,
        "unique-3": 1471,
        "entropy-3": 10.45581131849279,
        "cond_entropy-3": 0.22911447404365368,
        "total_length-nopunct": 1643,
        "mean_pred_length-nopunct": 15.951456310679612,
        "std_pred_length-nopunct": 5.8846165101382955,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.49421789409616557,
        "vocab_size-1-nopunct": 812,
        "unique-1-nopunct": 623,
        "entropy-1-nopunct": 8.40175834749569,
        "distinct-2-nopunct": 0.827922077922078,
        "vocab_size-2-nopunct": 1275,
        "unique-2-nopunct": 1179,
        "entropy-2-nopunct": 10.026209461087571,
        "cond_entropy-2-nopunct": 1.7290421351820697,
        "distinct-3-nopunct": 0.9081419624217119,
        "vocab_size-3-nopunct": 1305,
        "unique-3-nopunct": 1257,
        "entropy-3-nopunct": 10.210460940840756,
        "cond_entropy-3-nopunct": 0.21900306846097758,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.04213,
        "local_recall": {
            "1": 0.20426829268292682,
            "2": 0.5454545454545454,
            "3": 0.8220640569395018
        },
        "rouge1": {
            "precision": 0.7513,
            "recall": 0.77012,
            "fmeasure": 0.74952
        },
        "rouge2": {
            "precision": 0.53155,
            "recall": 0.54651,
            "fmeasure": 0.53023
        },
        "rougeL": {
            "precision": 0.65957,
            "recall": 0.68194,
            "fmeasure": 0.65995
        },
        "rougeLsum": {
            "precision": 0.65957,
            "recall": 0.68194,
            "fmeasure": 0.65995
        },
        "nist": 7.802199567675527,
        "bleurt": 0.30862,
        "bertscore": {
            "precision": 0.92928,
            "recall": 0.93474,
            "f1": 0.93073
        },
        "nubia": {
            "semantic_relation": 4.29008,
            "contradiction": 3.90007,
            "irrelevancy": 38.246,
            "logical_agreement": 57.85393,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.53651,
            "nubia_score": 0.75595
        },
        "meteor": 0.4203875702660061
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 3.7712361663282534,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 34,
        "unique-1": 31,
        "entropy-1": 5.017535737070865,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": -0.004358782212904644,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.969815782426808,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": -0.004234272798947963,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.81083,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6875,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.71759,
            "recall": 0.63607,
            "fmeasure": 0.67181
        },
        "rouge2": {
            "precision": 0.39028,
            "recall": 0.36019,
            "fmeasure": 0.37331
        },
        "rougeL": {
            "precision": 0.64352,
            "recall": 0.57547,
            "fmeasure": 0.60514
        },
        "rougeLsum": {
            "precision": 0.64352,
            "recall": 0.57547,
            "fmeasure": 0.60514
        },
        "nist": 3.8307891438107387,
        "bleurt": 0.20583,
        "bertscore": {
            "precision": 0.90395,
            "recall": 0.89758,
            "f1": 0.90057
        },
        "nubia": {
            "semantic_relation": 3.91603,
            "contradiction": 0.6023,
            "irrelevancy": 36.83666,
            "logical_agreement": 62.56105,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.99908,
            "nubia_score": 0.53212
        },
        "meteor": 0.39250082934928815
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.5,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.427287210976628,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.5022063193058501,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.250826743850996,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.4333543065887286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.08313,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.76491,
            "recall": 0.92857,
            "fmeasure": 0.83467
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.64828,
            "fmeasure": 0.57871
        },
        "rougeL": {
            "precision": 0.61842,
            "recall": 0.76128,
            "fmeasure": 0.6795
        },
        "rougeLsum": {
            "precision": 0.61842,
            "recall": 0.76128,
            "fmeasure": 0.6795
        },
        "nist": 3.2956997104995427,
        "bleurt": 0.3456,
        "bertscore": {
            "precision": 0.93625,
            "recall": 0.95969,
            "f1": 0.94782
        },
        "nubia": {
            "semantic_relation": 4.41935,
            "contradiction": 0.40204,
            "irrelevancy": 5.46832,
            "logical_agreement": 94.12964,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.14271,
            "nubia_score": 0.8222
        },
        "meteor": 0.4395002016928218
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.72,
        "total_length": 207,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.044028519516976,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6135265700483091,
        "vocab_size-1": 127,
        "unique-1": 105,
        "entropy-1": 6.4156780913741445,
        "distinct-2": 0.9384615384615385,
        "vocab_size-2": 183,
        "unique-2": 174,
        "entropy-2": 7.470125762456498,
        "cond_entropy-2": 0.9124689858763999,
        "distinct-3": 0.9781420765027322,
        "vocab_size-3": 179,
        "unique-3": 175,
        "entropy-3": 7.471983991289502,
        "cond_entropy-3": 0.010855248589969781,
        "total_length-nopunct": 179,
        "mean_pred_length-nopunct": 14.916666666666666,
        "std_pred_length-nopunct": 3.7295740001000413,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6815642458100558,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.4589678149069965,
        "distinct-2-nopunct": 0.9401197604790419,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.247447481083831,
        "cond_entropy-2-nopunct": 0.8501453880228782,
        "distinct-3-nopunct": 0.9870967741935484,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.250317953661354,
        "cond_entropy-3-nopunct": 0.006967774104465838,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.98709,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.3448275862068966,
            "3": 0.7768595041322314
        },
        "rouge1": {
            "precision": 0.76036,
            "recall": 0.77753,
            "fmeasure": 0.7573
        },
        "rouge2": {
            "precision": 0.52194,
            "recall": 0.52504,
            "fmeasure": 0.51668
        },
        "rougeL": {
            "precision": 0.67675,
            "recall": 0.68661,
            "fmeasure": 0.67231
        },
        "rougeLsum": {
            "precision": 0.67675,
            "recall": 0.68661,
            "fmeasure": 0.67231
        },
        "nist": 5.423387590159479,
        "bleurt": 0.33683,
        "bertscore": {
            "precision": 0.92756,
            "recall": 0.9377,
            "f1": 0.93012
        },
        "nubia": {
            "semantic_relation": 4.58489,
            "contradiction": 0.58495,
            "irrelevancy": 26.62728,
            "logical_agreement": 72.78777,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.25253,
            "nubia_score": 0.83245
        },
        "meteor": 0.3908116428603709
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 114,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 5.872801368884133,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.7456140350877193,
        "vocab_size-1": 85,
        "unique-1": 73,
        "entropy-1": 6.120949141719748,
        "distinct-2": 1.0,
        "vocab_size-2": 107,
        "unique-2": 107,
        "entropy-2": 6.741466986401138,
        "cond_entropy-2": 0.4834346825572173,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.09761079662642244,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.7207747548166585,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8367346938775511,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.231957037948614,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.507794640198703,
        "cond_entropy-2-nopunct": 0.3052801258013662,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.72173,
        "local_recall": {
            "1": 0.47368421052631576,
            "2": 0.4375,
            "3": 0.810126582278481
        },
        "rouge1": {
            "precision": 0.80971,
            "recall": 0.80925,
            "fmeasure": 0.80016
        },
        "rouge2": {
            "precision": 0.61093,
            "recall": 0.62503,
            "fmeasure": 0.61091
        },
        "rougeL": {
            "precision": 0.6908,
            "recall": 0.70749,
            "fmeasure": 0.69134
        },
        "rougeLsum": {
            "precision": 0.6908,
            "recall": 0.70749,
            "fmeasure": 0.69134
        },
        "nist": 5.542273420585244,
        "bleurt": 0.31493,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.94008,
            "f1": 0.94031
        },
        "nubia": {
            "semantic_relation": 4.319,
            "contradiction": 1.64804,
            "irrelevancy": 40.14844,
            "logical_agreement": 58.20352,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.92054,
            "nubia_score": 0.72358
        },
        "meteor": 0.4019639695851458
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.903055907333276,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 36,
        "unique-2": 35,
        "entropy-2": 5.1553993115749,
        "cond_entropy-2": 0.15779554101185758,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.06316699496684555,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.885129041304629,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838574,
        "cond_entropy-2-nopunct": 0.1721271226802133,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.12396,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.7727272727272727
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76159,
            "fmeasure": 0.67059
        },
        "rouge2": {
            "precision": 0.43704,
            "recall": 0.43889,
            "fmeasure": 0.43713
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76159,
            "fmeasure": 0.67059
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76159,
            "fmeasure": 0.67059
        },
        "nist": 3.2432379635759383,
        "bleurt": 0.19236,
        "bertscore": {
            "precision": 0.89112,
            "recall": 0.91019,
            "f1": 0.90023
        },
        "nubia": {
            "semantic_relation": 4.05998,
            "contradiction": 14.59112,
            "irrelevancy": 50.40386,
            "logical_agreement": 35.00502,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.62552,
            "nubia_score": 0.69973
        },
        "meteor": 0.35916044414713527
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 182,
        "mean_pred_length": 18.2,
        "std_pred_length": 7.533923280734945,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.6703296703296703,
        "vocab_size-1": 122,
        "unique-1": 101,
        "entropy-1": 6.523319212027967,
        "distinct-2": 0.9593023255813954,
        "vocab_size-2": 165,
        "unique-2": 158,
        "entropy-2": 7.344869405864858,
        "cond_entropy-2": 0.6856517829813152,
        "distinct-3": 0.9938271604938271,
        "vocab_size-3": 161,
        "unique-3": 160,
        "entropy-3": 7.32750432387226,
        "cond_entropy-3": -0.012340677743399277,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 16.3,
        "std_pred_length-nopunct": 6.957729514719583,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7239263803680982,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.573858445496137,
        "distinct-2-nopunct": 0.954248366013072,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.165884574718775,
        "cond_entropy-2-nopunct": 0.6426712082249603,
        "distinct-3-nopunct": 0.993006993006993,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.145885322792383,
        "cond_entropy-3-nopunct": -0.01360042199817853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.97753,
        "local_recall": {
            "1": 0.34782608695652173,
            "2": 0.7037037037037037,
            "3": 0.8210526315789474
        },
        "rouge1": {
            "precision": 0.71349,
            "recall": 0.77466,
            "fmeasure": 0.71814
        },
        "rouge2": {
            "precision": 0.4827,
            "recall": 0.49234,
            "fmeasure": 0.47802
        },
        "rougeL": {
            "precision": 0.6051,
            "recall": 0.63432,
            "fmeasure": 0.60438
        },
        "rougeLsum": {
            "precision": 0.6051,
            "recall": 0.63432,
            "fmeasure": 0.60438
        },
        "nist": 5.296321609141891,
        "bleurt": 0.26917,
        "bertscore": {
            "precision": 0.91997,
            "recall": 0.93105,
            "f1": 0.92345
        },
        "nubia": {
            "semantic_relation": 4.25214,
            "contradiction": 0.75578,
            "irrelevancy": 35.80401,
            "logical_agreement": 63.44021,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.01462,
            "nubia_score": 0.71686
        },
        "meteor": 0.42068083353166785
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.209867121904035,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.2493097618368753,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.03462179117476821,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.136842188131012,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.2724185498326622,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.81348,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.73309,
            "fmeasure": 0.76401
        },
        "rouge2": {
            "precision": 0.59048,
            "recall": 0.54669,
            "fmeasure": 0.55813
        },
        "rougeL": {
            "precision": 0.78125,
            "recall": 0.70476,
            "fmeasure": 0.7343
        },
        "rougeLsum": {
            "precision": 0.78125,
            "recall": 0.70476,
            "fmeasure": 0.7343
        },
        "nist": 4.560344952824209,
        "bleurt": 0.20802,
        "bertscore": {
            "precision": 0.92499,
            "recall": 0.91177,
            "f1": 0.91813
        },
        "nubia": {
            "semantic_relation": 4.17556,
            "contradiction": 0.26421,
            "irrelevancy": 18.2574,
            "logical_agreement": 81.4784,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.27758,
            "nubia_score": 0.69799
        },
        "meteor": 0.4309999971679519
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.72273,
        "msttr-100_nopunct": 0.78579,
        "total_length": 2209,
        "mean_pred_length": 16.862595419847327,
        "std_pred_length": 7.04918744576105,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.4563150746944319,
        "vocab_size-1": 1008,
        "unique-1": 808,
        "entropy-1": 8.382246988616593,
        "distinct-2": 0.861405197305101,
        "vocab_size-2": 1790,
        "unique-2": 1647,
        "entropy-2": 10.627332921708348,
        "cond_entropy-2": 1.9722206417442574,
        "distinct-3": 0.9686697483307652,
        "vocab_size-3": 1886,
        "unique-3": 1841,
        "entropy-3": 10.857417818427104,
        "cond_entropy-3": 0.22253641019897352,
        "total_length-nopunct": 1907,
        "mean_pred_length-nopunct": 14.557251908396946,
        "std_pred_length-nopunct": 6.232346433432046,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5222863135815417,
        "vocab_size-1-nopunct": 996,
        "unique-1-nopunct": 804,
        "entropy-1-nopunct": 8.714488877435834,
        "distinct-2-nopunct": 0.884009009009009,
        "vocab_size-2-nopunct": 1570,
        "unique-2-nopunct": 1466,
        "entropy-2-nopunct": 10.456459337208797,
        "cond_entropy-2-nopunct": 1.8311683067950102,
        "distinct-3-nopunct": 0.9781155015197568,
        "vocab_size-3-nopunct": 1609,
        "unique-3-nopunct": 1579,
        "entropy-3-nopunct": 10.63705147348024,
        "cond_entropy-3-nopunct": 0.19783554947626922,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.25273,
        "local_recall": {
            "1": 0.22546419098143236,
            "2": 0.4519230769230769,
            "3": 0.7503506311360448
        },
        "rouge1": {
            "precision": 0.76257,
            "recall": 0.71717,
            "fmeasure": 0.72661
        },
        "rouge2": {
            "precision": 0.52499,
            "recall": 0.49324,
            "fmeasure": 0.49989
        },
        "rougeL": {
            "precision": 0.64849,
            "recall": 0.61323,
            "fmeasure": 0.61975
        },
        "rougeLsum": {
            "precision": 0.64849,
            "recall": 0.61323,
            "fmeasure": 0.61975
        },
        "nist": 7.601424619238403,
        "bleurt": 0.25414,
        "bertscore": {
            "precision": 0.92743,
            "recall": 0.92096,
            "f1": 0.92264
        },
        "nubia": {
            "semantic_relation": 4.2194,
            "contradiction": 7.4983,
            "irrelevancy": 26.43147,
            "logical_agreement": 66.07023,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.70085,
            "nubia_score": 0.71909
        },
        "meteor": 0.3755957047451266
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.55406,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.96078,
            "fmeasure": 0.94819
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.69048,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.89673,
            "fmeasure": 0.88498
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.89673,
            "fmeasure": 0.88498
        },
        "nist": 4.4298657600240885,
        "bleurt": 0.66822,
        "bertscore": {
            "precision": 0.98388,
            "recall": 0.98957,
            "f1": 0.98672
        },
        "nubia": {
            "semantic_relation": 4.99858,
            "contradiction": 0.16539,
            "irrelevancy": 0.57367,
            "logical_agreement": 99.26093,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.23151,
            "nubia_score": 0.98142
        },
        "meteor": 0.5223555607585055
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.185230132909402,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.680813428089397,
        "cond_entropy-2": 0.47134261830726476,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.03103131238874395,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.106377316818028,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.5093596877843336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.38199,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.74412,
            "recall": 0.83462,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.50347,
            "recall": 0.54167,
            "fmeasure": 0.51984
        },
        "rougeL": {
            "precision": 0.65588,
            "recall": 0.71923,
            "fmeasure": 0.68333
        },
        "rougeLsum": {
            "precision": 0.65588,
            "recall": 0.71923,
            "fmeasure": 0.68333
        },
        "nist": 3.3140436326931444,
        "bleurt": 0.45755,
        "bertscore": {
            "precision": 0.92333,
            "recall": 0.92781,
            "f1": 0.92556
        },
        "nubia": {
            "semantic_relation": 4.59333,
            "contradiction": 2.77805,
            "irrelevancy": 3.36649,
            "logical_agreement": 93.85546,
            "grammar_ref": 3.96214,
            "grammar_hyp": 3.54969,
            "nubia_score": 0.86056
        },
        "meteor": 0.41678147556733797
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 4.63033476111609,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.5795454545454546,
        "vocab_size-1": 51,
        "unique-1": 32,
        "entropy-1": 5.349786840322019,
        "distinct-2": 0.7831325301204819,
        "vocab_size-2": 65,
        "unique-2": 49,
        "entropy-2": 5.923114431294796,
        "cond_entropy-2": 0.500298475516625,
        "distinct-3": 0.8846153846153846,
        "vocab_size-3": 69,
        "unique-3": 60,
        "entropy-3": 6.054632988093024,
        "cond_entropy-3": 0.13484708244259203,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 4.079215610874227,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6233766233766234,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.279265761249348,
        "distinct-2-nopunct": 0.7916666666666666,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.73228923749333,
        "cond_entropy-2-nopunct": 0.49382353037214455,
        "distinct-3-nopunct": 0.9104477611940298,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.886984712845829,
        "cond_entropy-3-nopunct": 0.1575041144531756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 75.98745,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.921875
        },
        "rouge1": {
            "precision": 0.92571,
            "recall": 0.89278,
            "fmeasure": 0.90851
        },
        "rouge2": {
            "precision": 0.79407,
            "recall": 0.77106,
            "fmeasure": 0.78202
        },
        "rougeL": {
            "precision": 0.89714,
            "recall": 0.8667,
            "fmeasure": 0.88124
        },
        "rougeLsum": {
            "precision": 0.89714,
            "recall": 0.8667,
            "fmeasure": 0.88124
        },
        "nist": 6.013618521420793,
        "bleurt": 0.75693,
        "bertscore": {
            "precision": 0.98723,
            "recall": 0.98005,
            "f1": 0.98335
        },
        "nubia": {
            "semantic_relation": 4.73447,
            "contradiction": 13.19129,
            "irrelevancy": 7.24095,
            "logical_agreement": 79.56776,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.71035,
            "nubia_score": 0.93054
        },
        "meteor": 0.5433132924960868
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 5.153208277913436,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.75,
        "vocab_size-1": 78,
        "unique-1": 66,
        "entropy-1": 6.032882776167823,
        "distinct-2": 0.9897959183673469,
        "vocab_size-2": 97,
        "unique-2": 96,
        "entropy-2": 6.594301680849911,
        "cond_entropy-2": 0.4440267276158883,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.06940875762341292,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 5.273097339852125,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8021978021978022,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.003221596672397,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.41825684842010713,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.08029373226439636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.53219,
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.782051282051282
        },
        "rouge1": {
            "precision": 0.81989,
            "recall": 0.74683,
            "fmeasure": 0.77566
        },
        "rouge2": {
            "precision": 0.58726,
            "recall": 0.54778,
            "fmeasure": 0.56306
        },
        "rougeL": {
            "precision": 0.68667,
            "recall": 0.63544,
            "fmeasure": 0.65575
        },
        "rougeLsum": {
            "precision": 0.68667,
            "recall": 0.63544,
            "fmeasure": 0.65575
        },
        "nist": 5.504170344895035,
        "bleurt": 0.22954,
        "bertscore": {
            "precision": 0.93219,
            "recall": 0.93131,
            "f1": 0.93171
        },
        "nubia": {
            "semantic_relation": 4.31529,
            "contradiction": 7.95636,
            "irrelevancy": 20.26756,
            "logical_agreement": 71.77608,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.41932,
            "nubia_score": 0.73942
        },
        "meteor": 0.41406990061561494
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 17.2,
        "std_pred_length": 4.261455150532504,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7093023255813954,
        "vocab_size-1": 61,
        "unique-1": 51,
        "entropy-1": 5.641081179872675,
        "distinct-2": 0.9876543209876543,
        "vocab_size-2": 80,
        "unique-2": 79,
        "entropy-2": 6.315158644859922,
        "cond_entropy-2": 0.5492520731830507,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.06560669996735524,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 3.2,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7945205479452054,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.693048360160978,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.087462841250345,
        "cond_entropy-2-nopunct": 0.4309421427598875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.11018291775042297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.34081,
        "local_recall": {
            "1": 0.1,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.65402,
            "recall": 0.71029,
            "fmeasure": 0.67306
        },
        "rouge2": {
            "precision": 0.4638,
            "recall": 0.52939,
            "fmeasure": 0.48805
        },
        "rougeL": {
            "precision": 0.53245,
            "recall": 0.59264,
            "fmeasure": 0.55321
        },
        "rougeLsum": {
            "precision": 0.53245,
            "recall": 0.59264,
            "fmeasure": 0.55321
        },
        "nist": 4.365407811409965,
        "bleurt": 0.07315,
        "bertscore": {
            "precision": 0.90825,
            "recall": 0.92075,
            "f1": 0.91394
        },
        "nubia": {
            "semantic_relation": 4.27449,
            "contradiction": 1.35059,
            "irrelevancy": 37.78425,
            "logical_agreement": 60.86515,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.44492,
            "nubia_score": 0.75526
        },
        "meteor": 0.3638460471869744
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "total_length": 130,
        "mean_pred_length": 16.25,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6692307692307692,
        "vocab_size-1": 87,
        "unique-1": 69,
        "entropy-1": 6.0779973824860845,
        "distinct-2": 0.9508196721311475,
        "vocab_size-2": 116,
        "unique-2": 111,
        "entropy-2": 6.826189079348446,
        "cond_entropy-2": 0.6133963152585704,
        "distinct-3": 1.0,
        "vocab_size-3": 114,
        "unique-3": 114,
        "entropy-3": 6.832890014164754,
        "cond_entropy-3": 0.014037654691008893,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 14.375,
        "std_pred_length-nopunct": 4.181432170919432,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7217391304347827,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.0627659773066025,
        "distinct-2-nopunct": 0.9439252336448598,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.622262430306153,
        "cond_entropy-2-nopunct": 0.5993262902808967,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 99,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.62935662007962,
        "cond_entropy-3-nopunct": -0.003475139026956945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.42729,
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.45714285714285713,
            "3": 0.8405797101449275
        },
        "rouge1": {
            "precision": 0.74575,
            "recall": 0.77847,
            "fmeasure": 0.75301
        },
        "rouge2": {
            "precision": 0.47585,
            "recall": 0.50834,
            "fmeasure": 0.48608
        },
        "rougeL": {
            "precision": 0.61074,
            "recall": 0.64388,
            "fmeasure": 0.618
        },
        "rougeLsum": {
            "precision": 0.61074,
            "recall": 0.64388,
            "fmeasure": 0.618
        },
        "nist": 5.213383179380466,
        "bleurt": 0.2073,
        "bertscore": {
            "precision": 0.91576,
            "recall": 0.94333,
            "f1": 0.92673
        },
        "nubia": {
            "semantic_relation": 4.14816,
            "contradiction": 19.87654,
            "irrelevancy": 36.6178,
            "logical_agreement": 43.50567,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.47096,
            "nubia_score": 0.73711
        },
        "meteor": 0.3965221745256995
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.5,
        "median_pred_length": 18.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.668912825088411,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 33,
        "unique-2": 31,
        "entropy-2": 5.014997302659249,
        "cond_entropy-2": 0.3198296513160167,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": -0.02428283698045265,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.5,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275186,
        "cond_entropy-2-nopunct": 0.27355726227518523,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": -0.028107102122342933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 96.12221,
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.9583333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "nist": 5.47016276840381,
        "bleurt": 0.81354,
        "bertscore": {
            "precision": 0.99581,
            "recall": 0.99056,
            "f1": 0.99317
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.53906,
            "irrelevancy": 0.72266,
            "logical_agreement": 98.73828,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.66544,
            "nubia_score": 0.98279
        },
        "meteor": 0.6581712478767607
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.2381054815525046,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.09199,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "nist": 2.306664886548115,
        "bleurt": 0.67831,
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        },
        "meteor": 0.4912092865802179
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.272001872658765,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7592592592592593,
        "vocab_size-1": 41,
        "unique-1": 32,
        "entropy-1": 5.208410187268525,
        "distinct-2": 0.9,
        "vocab_size-2": 45,
        "unique-2": 41,
        "entropy-2": 5.4287584397314586,
        "cond_entropy-2": 0.10406643765452546,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 44,
        "unique-3": 42,
        "entropy-3": 5.43660543431788,
        "cond_entropy-3": 0.026551146764102772,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.9370039370059056,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.178508854797682,
        "distinct-2-nopunct": 0.8863636363636364,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.215002357224489,
        "cond_entropy-2-nopunct": 0.07344383387440158,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.221928094887364,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.56121,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.88312,
            "recall": 0.85165,
            "fmeasure": 0.86607
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.77083,
            "fmeasure": 0.7803
        },
        "rougeL": {
            "precision": 0.86039,
            "recall": 0.83242,
            "fmeasure": 0.84524
        },
        "rougeLsum": {
            "precision": 0.86039,
            "recall": 0.83242,
            "fmeasure": 0.84524
        },
        "nist": 4.928016538908434,
        "bleurt": 0.80783,
        "bertscore": {
            "precision": 0.97577,
            "recall": 0.95987,
            "f1": 0.96753
        },
        "nubia": {
            "semantic_relation": 4.65074,
            "contradiction": 3.02129,
            "irrelevancy": 1.05266,
            "logical_agreement": 95.92605,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.15478,
            "nubia_score": 0.85796
        },
        "meteor": 0.5218676937775568
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.7,
        "total_length": 140,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.9396356140913875,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6142857142857143,
        "vocab_size-1": 86,
        "unique-1": 64,
        "entropy-1": 6.068429403409107,
        "distinct-2": 0.8615384615384616,
        "vocab_size-2": 112,
        "unique-2": 102,
        "entropy-2": 6.698990120587626,
        "cond_entropy-2": 0.4566319109207189,
        "distinct-3": 0.9,
        "vocab_size-3": 108,
        "unique-3": 102,
        "entropy-3": 6.669146220500358,
        "cond_entropy-3": -0.019562425717211365,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 12.7,
        "std_pred_length-nopunct": 4.428317965096906,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6614173228346457,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 6.11824895886677,
        "distinct-2-nopunct": 0.8547008547008547,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.528150189520934,
        "cond_entropy-2-nopunct": 0.46720342962043965,
        "distinct-3-nopunct": 0.8878504672897196,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.474837780672348,
        "cond_entropy-3-nopunct": -0.021329742487613143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 75.17215,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.36363636363636365,
            "3": 0.9339622641509434
        },
        "rouge1": {
            "precision": 0.89481,
            "recall": 0.92233,
            "fmeasure": 0.90256
        },
        "rouge2": {
            "precision": 0.79887,
            "recall": 0.85271,
            "fmeasure": 0.82091
        },
        "rougeL": {
            "precision": 0.84325,
            "recall": 0.88159,
            "fmeasure": 0.85883
        },
        "rougeLsum": {
            "precision": 0.84325,
            "recall": 0.88159,
            "fmeasure": 0.85883
        },
        "nist": 6.282171515731423,
        "bleurt": 0.79867,
        "bertscore": {
            "precision": 0.97669,
            "recall": 0.97936,
            "f1": 0.9767
        },
        "nubia": {
            "semantic_relation": 4.86473,
            "contradiction": 2.71047,
            "irrelevancy": 13.88269,
            "logical_agreement": 83.40684,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.88994,
            "nubia_score": 0.93627
        },
        "meteor": 0.5502493772422232
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.75,
        "total_length": 111,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.075908711186061,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 31,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 78,
        "unique-1": 67,
        "entropy-1": 5.908796384153737,
        "distinct-2": 0.9904761904761905,
        "vocab_size-2": 104,
        "unique-2": 103,
        "entropy-2": 6.695197898618494,
        "cond_entropy-2": 0.689296199120504,
        "distinct-3": 1.0,
        "vocab_size-3": 99,
        "unique-3": 99,
        "entropy-3": 6.62935662007962,
        "cond_entropy-3": -0.06468687738449275,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 16.833333333333332,
        "std_pred_length-nopunct": 5.520165053893065,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7524752475247525,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 5.917676952856028,
        "distinct-2-nopunct": 0.9894736842105263,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.548802976752,
        "cond_entropy-2-nopunct": 0.6778966257841121,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.47573343096641,
        "cond_entropy-3-nopunct": -0.07165026725219042,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.42164,
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.2222222222222222,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.79114,
            "recall": 0.83291,
            "fmeasure": 0.80719
        },
        "rouge2": {
            "precision": 0.56854,
            "recall": 0.59426,
            "fmeasure": 0.57894
        },
        "rougeL": {
            "precision": 0.66958,
            "recall": 0.71326,
            "fmeasure": 0.68506
        },
        "rougeLsum": {
            "precision": 0.66958,
            "recall": 0.71326,
            "fmeasure": 0.68506
        },
        "nist": 5.316256376368744,
        "bleurt": -0.02266,
        "bertscore": {
            "precision": 0.92516,
            "recall": 0.9365,
            "f1": 0.92959
        },
        "nubia": {
            "semantic_relation": 4.24875,
            "contradiction": 13.63869,
            "irrelevancy": 30.14468,
            "logical_agreement": 56.21662,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.23962,
            "nubia_score": 0.63357
        },
        "meteor": 0.40488545617804383
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.912072431289048,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.24589590367621073,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.844324311457954,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.27535579927806436,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.91158,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8571428571428571,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.71267,
            "recall": 0.62717,
            "fmeasure": 0.6546
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.33006,
            "fmeasure": 0.3428
        },
        "rougeL": {
            "precision": 0.51642,
            "recall": 0.47025,
            "fmeasure": 0.48234
        },
        "rougeLsum": {
            "precision": 0.51642,
            "recall": 0.47025,
            "fmeasure": 0.48234
        },
        "nist": 3.549040148966727,
        "bleurt": 0.38143,
        "bertscore": {
            "precision": 0.90569,
            "recall": 0.89093,
            "f1": 0.89757
        },
        "nubia": {
            "semantic_relation": 4.38497,
            "contradiction": 0.26732,
            "irrelevancy": 33.47129,
            "logical_agreement": 66.26139,
            "grammar_ref": 3.54742,
            "grammar_hyp": 4.02893,
            "nubia_score": 0.81177
        },
        "meteor": 0.3563721596366696
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 22.75,
        "std_pred_length": 6.179603547154137,
        "median_pred_length": 22.5,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.6593406593406593,
        "vocab_size-1": 60,
        "unique-1": 47,
        "entropy-1": 5.572240487344113,
        "distinct-2": 0.9425287356321839,
        "vocab_size-2": 82,
        "unique-2": 77,
        "entropy-2": 6.328000967113091,
        "cond_entropy-2": 0.706820440819771,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": 0.05257786320903958,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 5.1478150704935,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.502855751945727,
        "distinct-2-nopunct": 0.9342105263157895,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.11634856607517,
        "cond_entropy-2-nopunct": 0.6566018848105716,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": 0.06088637688761568,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.75907,
        "local_recall": {
            "1": 0.16,
            "2": 0.8666666666666667,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.75775,
            "recall": 0.80645,
            "fmeasure": 0.77909
        },
        "rouge2": {
            "precision": 0.52868,
            "recall": 0.55409,
            "fmeasure": 0.53895
        },
        "rougeL": {
            "precision": 0.59364,
            "recall": 0.6171,
            "fmeasure": 0.6032
        },
        "rougeLsum": {
            "precision": 0.59364,
            "recall": 0.6171,
            "fmeasure": 0.6032
        },
        "nist": 5.035710172385711,
        "bleurt": 0.22414,
        "bertscore": {
            "precision": 0.92861,
            "recall": 0.93805,
            "f1": 0.93273
        },
        "nubia": {
            "semantic_relation": 4.02043,
            "contradiction": 0.73271,
            "irrelevancy": 62.77373,
            "logical_agreement": 36.49357,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.3868,
            "nubia_score": 0.66078
        },
        "meteor": 0.4403233866709607
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 24.75,
        "std_pred_length": 10.662434056068061,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 40,
        "distinct-1": 0.7373737373737373,
        "vocab_size-1": 73,
        "unique-1": 58,
        "entropy-1": 5.960016594761531,
        "distinct-2": 0.9368421052631579,
        "vocab_size-2": 89,
        "unique-2": 83,
        "entropy-2": 6.443539818857263,
        "cond_entropy-2": 0.42749543568807963,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 90,
        "unique-3": 89,
        "entropy-3": 6.48581661822068,
        "cond_entropy-3": 0.04782914175785822,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 20.25,
        "std_pred_length-nopunct": 7.628073151196179,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.03423410779618,
        "distinct-2-nopunct": 0.974025974025974,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.214838488746853,
        "cond_entropy-2-nopunct": 0.1834935183578539,
        "distinct-3-nopunct": 0.9863013698630136,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.162427298606055,
        "cond_entropy-3-nopunct": -0.049564721540911245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.50967,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8194444444444444
        },
        "rouge1": {
            "precision": 0.86988,
            "recall": 0.81478,
            "fmeasure": 0.84038
        },
        "rouge2": {
            "precision": 0.72076,
            "recall": 0.67824,
            "fmeasure": 0.69789
        },
        "rougeL": {
            "precision": 0.72208,
            "recall": 0.67534,
            "fmeasure": 0.69704
        },
        "rougeLsum": {
            "precision": 0.72208,
            "recall": 0.67534,
            "fmeasure": 0.69704
        },
        "nist": 5.624275463283855,
        "bleurt": 0.51595,
        "bertscore": {
            "precision": 0.96522,
            "recall": 0.95189,
            "f1": 0.95846
        },
        "nubia": {
            "semantic_relation": 4.34619,
            "contradiction": 38.56809,
            "irrelevancy": 4.56491,
            "logical_agreement": 56.867,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.31859,
            "nubia_score": 0.77824
        },
        "meteor": 0.464945981597975
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.24942,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.95833,
            "fmeasure": 0.83974
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.61616,
            "fmeasure": 0.52652
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.78333,
            "fmeasure": 0.68269
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.78333,
            "fmeasure": 0.68269
        },
        "nist": 3.2542543449815526,
        "bleurt": 0.54827,
        "bertscore": {
            "precision": 0.83239,
            "recall": 0.95102,
            "f1": 0.88776
        },
        "nubia": {
            "semantic_relation": 4.31067,
            "contradiction": 0.21829,
            "irrelevancy": 97.89645,
            "logical_agreement": 1.88526,
            "grammar_ref": 4.59758,
            "grammar_hyp": 3.83665,
            "nubia_score": 0.8542
        },
        "meteor": 0.48103772615573454
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.63,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 21.2,
        "std_pred_length": 10.067770358922576,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.6226415094339622,
        "vocab_size-1": 66,
        "unique-1": 52,
        "entropy-1": 5.576318942902685,
        "distinct-2": 0.9207920792079208,
        "vocab_size-2": 93,
        "unique-2": 87,
        "entropy-2": 6.484847373798049,
        "cond_entropy-2": 0.8505914713296858,
        "distinct-3": 1.0,
        "vocab_size-3": 96,
        "unique-3": 96,
        "entropy-3": 6.5849625007211605,
        "cond_entropy-3": 0.10914450759776728,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 18.6,
        "std_pred_length-nopunct": 8.957678270623477,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6881720430107527,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.609480103994302,
        "distinct-2-nopunct": 0.9204545454545454,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.2831841754063165,
        "cond_entropy-2-nopunct": 0.7151630888616534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": 0.10247257179790376,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.42168,
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.82735,
            "recall": 0.83799,
            "fmeasure": 0.82788
        },
        "rouge2": {
            "precision": 0.61056,
            "recall": 0.63988,
            "fmeasure": 0.62187
        },
        "rougeL": {
            "precision": 0.76343,
            "recall": 0.77618,
            "fmeasure": 0.76497
        },
        "rougeLsum": {
            "precision": 0.76343,
            "recall": 0.77618,
            "fmeasure": 0.76497
        },
        "nist": 5.915256267997438,
        "bleurt": 0.30168,
        "bertscore": {
            "precision": 0.95472,
            "recall": 0.95727,
            "f1": 0.95506
        },
        "nubia": {
            "semantic_relation": 4.33435,
            "contradiction": 3.34891,
            "irrelevancy": 39.31632,
            "logical_agreement": 57.33477,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.04957,
            "nubia_score": 0.81103
        },
        "meteor": 0.4670513215443461
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.871928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.3470520501351706,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.680757755722092,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.29689896522197035,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.41629,
        "local_recall": {
            "1": 0,
            "2": 0.625,
            "3": 0.9047619047619048
        },
        "rouge1": {
            "precision": 0.77696,
            "recall": 0.80539,
            "fmeasure": 0.78965
        },
        "rouge2": {
            "precision": 0.61458,
            "recall": 0.65576,
            "fmeasure": 0.63366
        },
        "rougeL": {
            "precision": 0.74755,
            "recall": 0.77646,
            "fmeasure": 0.7605
        },
        "rougeLsum": {
            "precision": 0.74755,
            "recall": 0.77646,
            "fmeasure": 0.7605
        },
        "nist": 3.6367725700434637,
        "bleurt": 0.29233,
        "bertscore": {
            "precision": 0.92718,
            "recall": 0.94243,
            "f1": 0.92944
        },
        "nubia": {
            "semantic_relation": 3.58155,
            "contradiction": 45.18928,
            "irrelevancy": 51.56371,
            "logical_agreement": 3.247,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.31328,
            "nubia_score": 0.64774
        },
        "meteor": 0.4586752817168771
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.0,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.892147223664533,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.15283195745508588,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.7562,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.61136,
            "recall": 0.45443,
            "fmeasure": 0.5201
        },
        "rouge2": {
            "precision": 0.39211,
            "recall": 0.281,
            "fmeasure": 0.32684
        },
        "rougeL": {
            "precision": 0.43636,
            "recall": 0.33087,
            "fmeasure": 0.37526
        },
        "rougeLsum": {
            "precision": 0.43636,
            "recall": 0.33087,
            "fmeasure": 0.37526
        },
        "nist": 2.807098788745926,
        "bleurt": 0.12409,
        "bertscore": {
            "precision": 0.88993,
            "recall": 0.87587,
            "f1": 0.88246
        },
        "nubia": {
            "semantic_relation": 3.5073,
            "contradiction": 9.22471,
            "irrelevancy": 39.08854,
            "logical_agreement": 51.68675,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.73433,
            "nubia_score": 0.4979
        },
        "meteor": 0.3037263228670468
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.71244,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "nist": 2.230455916866335,
        "bleurt": 0.70415,
        "bertscore": {
            "precision": 0.9494,
            "recall": 0.95274,
            "f1": 0.95106
        },
        "nubia": {
            "semantic_relation": 4.73895,
            "contradiction": 0.43396,
            "irrelevancy": 0.5522,
            "logical_agreement": 99.01384,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.75433,
            "nubia_score": 0.90491
        },
        "meteor": 0.39611737519230206
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 21.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 19.0,
        "min_pred_length": 18,
        "max_pred_length": 26,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 48,
        "unique-1": 39,
        "entropy-1": 5.413632701209015,
        "distinct-2": 1.0,
        "vocab_size-2": 60,
        "unique-2": 60,
        "entropy-2": 5.906890595608517,
        "cond_entropy-2": 0.44219213047799305,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.07400058144377668,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.293874788090403,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.4442426551879244,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.08406426478847459,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.91665,
        "local_recall": {
            "1": 0.8,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.80465,
            "recall": 0.84751,
            "fmeasure": 0.82319
        },
        "rouge2": {
            "precision": 0.58768,
            "recall": 0.60852,
            "fmeasure": 0.59637
        },
        "rougeL": {
            "precision": 0.67314,
            "recall": 0.70386,
            "fmeasure": 0.68626
        },
        "rougeLsum": {
            "precision": 0.67314,
            "recall": 0.70386,
            "fmeasure": 0.68626
        },
        "nist": 5.197926998435771,
        "bleurt": 0.51196,
        "bertscore": {
            "precision": 0.95452,
            "recall": 0.95897,
            "f1": 0.95666
        },
        "nubia": {
            "semantic_relation": 4.71266,
            "contradiction": 1.02121,
            "irrelevancy": 64.50435,
            "logical_agreement": 34.47445,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.75085,
            "nubia_score": 0.93792
        },
        "meteor": 0.46590268261336765
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.79159,
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.57143,
            "fmeasure": 0.64
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.33333,
            "fmeasure": 0.37681
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.40476,
            "fmeasure": 0.45333
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.40476,
            "fmeasure": 0.45333
        },
        "nist": 3.3208158134418766,
        "bleurt": 0.2495,
        "bertscore": {
            "precision": 0.92125,
            "recall": 0.89994,
            "f1": 0.91047
        },
        "nubia": {
            "semantic_relation": 4.33579,
            "contradiction": 0.24238,
            "irrelevancy": 15.37286,
            "logical_agreement": 84.38476,
            "grammar_ref": 5.70189,
            "grammar_hyp": 4.75496,
            "nubia_score": 0.89386
        },
        "meteor": 0.3808612936777379
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 5.356071321407137,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7671232876712328,
        "vocab_size-1": 56,
        "unique-1": 46,
        "entropy-1": 5.626544894787369,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 66,
        "unique-2": 63,
        "entropy-2": 6.021567935039033,
        "cond_entropy-2": 0.31173490483675687,
        "distinct-3": 0.9846153846153847,
        "vocab_size-3": 64,
        "unique-3": 63,
        "entropy-3": 5.991598582259227,
        "cond_entropy-3": -0.024618182211253073,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.607264455478375,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.754532719265501,
        "cond_entropy-2-nopunct": 0.15395321929805814,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.717850465126429,
        "cond_entropy-3-nopunct": -0.029019418890029278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.75599,
        "local_recall": {
            "1": 0.4,
            "2": 0.6666666666666666,
            "3": 0.9361702127659575
        },
        "rouge1": {
            "precision": 0.90939,
            "recall": 0.89303,
            "fmeasure": 0.90077
        },
        "rouge2": {
            "precision": 0.75278,
            "recall": 0.75354,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.80838,
            "recall": 0.7976,
            "fmeasure": 0.80261
        },
        "rougeLsum": {
            "precision": 0.80838,
            "recall": 0.7976,
            "fmeasure": 0.80261
        },
        "nist": 5.797573891186031,
        "bleurt": 0.61403,
        "bertscore": {
            "precision": 0.97106,
            "recall": 0.97453,
            "f1": 0.97277
        },
        "nubia": {
            "semantic_relation": 4.78946,
            "contradiction": 0.73687,
            "irrelevancy": 23.85529,
            "logical_agreement": 75.40784,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.4333,
            "nubia_score": 0.88547
        },
        "meteor": 0.5323230261989208
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094904,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.59493,
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.38571,
            "fmeasure": 0.41296
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "nist": 2.530450380057439,
        "bleurt": -0.09464,
        "bertscore": {
            "precision": 0.89571,
            "recall": 0.87941,
            "f1": 0.88748
        },
        "nubia": {
            "semantic_relation": 4.03154,
            "contradiction": 3.72972,
            "irrelevancy": 62.78613,
            "logical_agreement": 33.48415,
            "grammar_ref": 4.70322,
            "grammar_hyp": 5.30126,
            "nubia_score": 0.55397
        },
        "meteor": 0.3042404250366658
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 6.944222218666553,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.8088235294117647,
        "vocab_size-1": 55,
        "unique-1": 48,
        "entropy-1": 5.5814867830655395,
        "distinct-2": 0.9846153846153847,
        "vocab_size-2": 64,
        "unique-2": 63,
        "entropy-2": 5.991598582259227,
        "cond_entropy-2": 0.3603124249227798,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.03591343812545021,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 5.312459150169742,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.9137931034482759,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.685567202024123,
        "distinct-2-nopunct": 0.9818181818181818,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.744996077161019,
        "cond_entropy-2-nopunct": 0.06883326385163309,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": -0.04245845692202903,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.36282,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.73989,
            "fmeasure": 0.81826
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.61219,
            "fmeasure": 0.68225
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.73989,
            "fmeasure": 0.81826
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.73989,
            "fmeasure": 0.81826
        },
        "nist": 5.0204904881896475,
        "bleurt": 0.47426,
        "bertscore": {
            "precision": 0.9776,
            "recall": 0.93052,
            "f1": 0.95303
        },
        "nubia": {
            "semantic_relation": 4.11578,
            "contradiction": 23.40355,
            "irrelevancy": 3.38808,
            "logical_agreement": 73.20837,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.77784,
            "nubia_score": 0.74435
        },
        "meteor": 0.429837389432503
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.7096774193548387,
        "vocab_size-1": 22,
        "unique-1": 16,
        "entropy-1": 4.300497519854926,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.5336006332403661,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.103465189601646,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.42360902733998096,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.40699,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.7702,
            "recall": 0.57868,
            "fmeasure": 0.66071
        },
        "rouge2": {
            "precision": 0.52647,
            "recall": 0.37397,
            "fmeasure": 0.43675
        },
        "rougeL": {
            "precision": 0.68687,
            "recall": 0.50261,
            "fmeasure": 0.57988
        },
        "rougeLsum": {
            "precision": 0.68687,
            "recall": 0.50261,
            "fmeasure": 0.57988
        },
        "nist": 2.7821008166704813,
        "bleurt": 0.27202,
        "bertscore": {
            "precision": 0.92288,
            "recall": 0.87075,
            "f1": 0.89481
        },
        "nubia": {
            "semantic_relation": 3.73805,
            "contradiction": 47.06952,
            "irrelevancy": 2.39583,
            "logical_agreement": 50.53465,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.36543,
            "nubia_score": 0.55356
        },
        "meteor": 0.29593826036464826
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 3.5,
        "median_pred_length": 22.5,
        "min_pred_length": 19,
        "max_pred_length": 26,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 5.002964207440784,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.39952793744219084,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.06871275008401433,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.831074987250575,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.3198296513160167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.58,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7096774193548387
        },
        "rouge1": {
            "precision": 0.60119,
            "recall": 0.55652,
            "fmeasure": 0.57699
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.42719,
            "fmeasure": 0.44886
        },
        "rougeL": {
            "precision": 0.60119,
            "recall": 0.55139,
            "fmeasure": 0.57391
        },
        "rougeLsum": {
            "precision": 0.60119,
            "recall": 0.55139,
            "fmeasure": 0.57391
        },
        "nist": 4.09837371842548,
        "bleurt": -0.34706,
        "bertscore": {
            "precision": 0.84627,
            "recall": 0.88583,
            "f1": 0.86229
        },
        "nubia": {
            "semantic_relation": 3.21029,
            "contradiction": 7.85389,
            "irrelevancy": 43.0148,
            "logical_agreement": 49.13131,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.33793,
            "nubia_score": 0.48698
        },
        "meteor": 0.35499692513870035
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.82,
        "total_length": 228,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 5.297284633639759,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.618421052631579,
        "vocab_size-1": 141,
        "unique-1": 113,
        "entropy-1": 6.602254082384493,
        "distinct-2": 0.9252336448598131,
        "vocab_size-2": 198,
        "unique-2": 185,
        "entropy-2": 7.579060970035865,
        "cond_entropy-2": 0.8082364864183302,
        "distinct-3": 0.975,
        "vocab_size-3": 195,
        "unique-3": 190,
        "entropy-3": 7.593856189774741,
        "cond_entropy-3": 0.02616364088439499,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 14.214285714285714,
        "std_pred_length-nopunct": 4.7385737973205675,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6884422110552764,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.709622669639527,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.354328014558661,
        "cond_entropy-2-nopunct": 0.7094514385010856,
        "distinct-3-nopunct": 0.9707602339181286,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.359372982722147,
        "cond_entropy-3-nopunct": 0.019540571926097414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.94975,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5,
            "3": 0.8974358974358975
        },
        "rouge1": {
            "precision": 0.8246,
            "recall": 0.8392,
            "fmeasure": 0.82569
        },
        "rouge2": {
            "precision": 0.66627,
            "recall": 0.66811,
            "fmeasure": 0.66238
        },
        "rougeL": {
            "precision": 0.72417,
            "recall": 0.73261,
            "fmeasure": 0.72243
        },
        "rougeLsum": {
            "precision": 0.72417,
            "recall": 0.73261,
            "fmeasure": 0.72243
        },
        "nist": 6.3633283549547315,
        "bleurt": 0.47271,
        "bertscore": {
            "precision": 0.94826,
            "recall": 0.94152,
            "f1": 0.94434
        },
        "nubia": {
            "semantic_relation": 4.27464,
            "contradiction": 8.75238,
            "irrelevancy": 20.71887,
            "logical_agreement": 70.52874,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.84044,
            "nubia_score": 0.7407
        },
        "meteor": 0.454835539467107
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 11,
        "unique-1": 8,
        "entropy-1": 3.32323142879762,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.5258134337464763,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.0269868333592873,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.6140967410936865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 78.25423,
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.88736,
            "fmeasure": 0.87169
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.79808,
            "fmeasure": 0.78308
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.88736,
            "fmeasure": 0.87169
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.88736,
            "fmeasure": 0.87169
        },
        "nist": 3.8312824248223967,
        "bleurt": 0.43426,
        "bertscore": {
            "precision": 0.9939,
            "recall": 0.9939,
            "f1": 0.9939
        },
        "nubia": {
            "semantic_relation": 2.92184,
            "contradiction": 86.80516,
            "irrelevancy": 12.84809,
            "logical_agreement": 0.34675,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.47393,
            "nubia_score": 0.41858
        },
        "meteor": 0.5523635444737205
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.77683,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.82601,
            "fmeasure": 0.80511
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.39899,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.56838,
            "fmeasure": 0.53181
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.56838,
            "fmeasure": 0.53181
        },
        "nist": 2.8665993620497217,
        "bleurt": 0.43729,
        "bertscore": {
            "precision": 0.93181,
            "recall": 0.94592,
            "f1": 0.93881
        },
        "nubia": {
            "semantic_relation": 4.78728,
            "contradiction": 0.13891,
            "irrelevancy": 4.20126,
            "logical_agreement": 95.65984,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.44877,
            "nubia_score": 0.93376
        },
        "meteor": 0.4226737601263325
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 21.0,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.6476190476190476,
        "vocab_size-1": 68,
        "unique-1": 52,
        "entropy-1": 5.696867920159666,
        "distinct-2": 0.89,
        "vocab_size-2": 89,
        "unique-2": 78,
        "entropy-2": 6.423856189774736,
        "cond_entropy-2": 0.6617607447460073,
        "distinct-3": 0.9368421052631579,
        "vocab_size-3": 89,
        "unique-3": 83,
        "entropy-3": 6.443539818857263,
        "cond_entropy-3": 0.03126257645096006,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 19.8,
        "std_pred_length-nopunct": 5.5641710972974225,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.667588869940822,
        "distinct-2-nopunct": 0.8829787234042553,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.320546298486141,
        "cond_entropy-2-nopunct": 0.6828386918505858,
        "distinct-3-nopunct": 0.9325842696629213,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.34090197029225,
        "cond_entropy-3-nopunct": 0.022268174794378457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.68211,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.0,
            "3": 0.8285714285714286
        },
        "rouge1": {
            "precision": 0.71729,
            "recall": 0.78263,
            "fmeasure": 0.74495
        },
        "rouge2": {
            "precision": 0.52843,
            "recall": 0.55654,
            "fmeasure": 0.53767
        },
        "rougeL": {
            "precision": 0.62673,
            "recall": 0.70413,
            "fmeasure": 0.65583
        },
        "rougeLsum": {
            "precision": 0.62673,
            "recall": 0.70413,
            "fmeasure": 0.65583
        },
        "nist": 4.821608944503376,
        "bleurt": 0.39203,
        "bertscore": {
            "precision": 0.92669,
            "recall": 0.93701,
            "f1": 0.92803
        },
        "nubia": {
            "semantic_relation": 4.52177,
            "contradiction": 0.55874,
            "irrelevancy": 30.33577,
            "logical_agreement": 69.10549,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.0983,
            "nubia_score": 0.86467
        },
        "meteor": 0.4295999115895864
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.78,
        "total_length": 487,
        "mean_pred_length": 15.709677419354838,
        "std_pred_length": 5.377333242339323,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5749486652977412,
        "vocab_size-1": 280,
        "unique-1": 224,
        "entropy-1": 7.333156722764275,
        "distinct-2": 0.9495614035087719,
        "vocab_size-2": 433,
        "unique-2": 417,
        "entropy-2": 8.714525609666904,
        "cond_entropy-2": 1.1468448533910487,
        "distinct-3": 0.9905882352941177,
        "vocab_size-3": 421,
        "unique-3": 417,
        "entropy-3": 8.712495501613363,
        "cond_entropy-3": 0.001897648509821377,
        "total_length-nopunct": 420,
        "mean_pred_length-nopunct": 13.548387096774194,
        "std_pred_length-nopunct": 4.164664798325808,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6523809523809524,
        "vocab_size-1-nopunct": 274,
        "unique-1-nopunct": 222,
        "entropy-1-nopunct": 7.575211398777845,
        "distinct-2-nopunct": 0.9537275064267352,
        "vocab_size-2-nopunct": 371,
        "unique-2-nopunct": 360,
        "entropy-2-nopunct": 8.49058221015071,
        "cond_entropy-2-nopunct": 0.9789314673748587,
        "distinct-3-nopunct": 0.9916201117318436,
        "vocab_size-3-nopunct": 355,
        "unique-3-nopunct": 352,
        "entropy-3-nopunct": 8.467056000727943,
        "cond_entropy-3-nopunct": -0.016530767579373797,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.68977,
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.5822784810126582,
            "3": 0.796875
        },
        "rouge1": {
            "precision": 0.78451,
            "recall": 0.7655,
            "fmeasure": 0.76989
        },
        "rouge2": {
            "precision": 0.56966,
            "recall": 0.55646,
            "fmeasure": 0.55993
        },
        "rougeL": {
            "precision": 0.65531,
            "recall": 0.64886,
            "fmeasure": 0.64735
        },
        "rougeLsum": {
            "precision": 0.65531,
            "recall": 0.64886,
            "fmeasure": 0.64735
        },
        "nist": 6.769086828277548,
        "bleurt": 0.30015,
        "bertscore": {
            "precision": 0.92797,
            "recall": 0.92469,
            "f1": 0.92523
        },
        "nubia": {
            "semantic_relation": 4.2978,
            "contradiction": 4.97371,
            "irrelevancy": 29.33341,
            "logical_agreement": 65.69288,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.45573,
            "nubia_score": 0.77617
        },
        "meteor": 0.4158967053621014
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 13.857142857142858,
        "std_pred_length": 2.899683304312063,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.6494845360824743,
        "vocab_size-1": 63,
        "unique-1": 48,
        "entropy-1": 5.623922796176237,
        "distinct-2": 0.8777777777777778,
        "vocab_size-2": 79,
        "unique-2": 69,
        "entropy-2": 6.239021012972294,
        "cond_entropy-2": 0.47265872643688456,
        "distinct-3": 0.9156626506024096,
        "vocab_size-3": 76,
        "unique-3": 69,
        "entropy-3": 6.206364732551751,
        "cond_entropy-3": -0.03542947820969597,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 2.8642768079662035,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7093023255813954,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.646967661578216,
        "distinct-2-nopunct": 0.8860759493670886,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.0663771089092124,
        "cond_entropy-2-nopunct": 0.4631446327976682,
        "distinct-3-nopunct": 0.9305555555555556,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 6.031036112553428,
        "cond_entropy-3-nopunct": -0.040037864760297824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.46079,
        "local_recall": {
            "1": 0.5,
            "2": 0.5384615384615384,
            "3": 0.8035714285714286
        },
        "rouge1": {
            "precision": 0.78547,
            "recall": 0.84704,
            "fmeasure": 0.81115
        },
        "rouge2": {
            "precision": 0.61731,
            "recall": 0.66926,
            "fmeasure": 0.63838
        },
        "rougeL": {
            "precision": 0.72833,
            "recall": 0.78117,
            "fmeasure": 0.74853
        },
        "rougeLsum": {
            "precision": 0.72833,
            "recall": 0.78117,
            "fmeasure": 0.74853
        },
        "nist": 4.618410868007914,
        "bleurt": 0.28416,
        "bertscore": {
            "precision": 0.92339,
            "recall": 0.94855,
            "f1": 0.93179
        },
        "nubia": {
            "semantic_relation": 4.39449,
            "contradiction": 15.88445,
            "irrelevancy": 33.35747,
            "logical_agreement": 50.75808,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.41573,
            "nubia_score": 0.7069
        },
        "meteor": 0.43795826304290925
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 12.4,
        "std_pred_length": 4.409081537009721,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6290322580645161,
        "vocab_size-1": 39,
        "unique-1": 27,
        "entropy-1": 5.0329154155681035,
        "distinct-2": 0.7894736842105263,
        "vocab_size-2": 45,
        "unique-2": 37,
        "entropy-2": 5.35026238250988,
        "cond_entropy-2": 0.1944831774620768,
        "distinct-3": 0.8653846153846154,
        "vocab_size-3": 45,
        "unique-3": 39,
        "entropy-3": 5.416691881561027,
        "cond_entropy-3": 0.11283600209487858,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 11.4,
        "std_pred_length-nopunct": 4.409081537009721,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.03447290882567,
        "distinct-2-nopunct": 0.7692307692307693,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.171405583442499,
        "cond_entropy-2-nopunct": 0.1752420116686581,
        "distinct-3-nopunct": 0.851063829787234,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.240655075035864,
        "cond_entropy-3-nopunct": 0.12552971868895968,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.93801,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7966101694915254
        },
        "rouge1": {
            "precision": 0.84928,
            "recall": 0.79392,
            "fmeasure": 0.81238
        },
        "rouge2": {
            "precision": 0.67222,
            "recall": 0.65146,
            "fmeasure": 0.65678
        },
        "rougeL": {
            "precision": 0.80227,
            "recall": 0.77064,
            "fmeasure": 0.77985
        },
        "rougeLsum": {
            "precision": 0.80227,
            "recall": 0.77064,
            "fmeasure": 0.77985
        },
        "nist": 4.287181085902787,
        "bleurt": 0.69,
        "bertscore": {
            "precision": 0.97446,
            "recall": 0.95352,
            "f1": 0.96368
        },
        "nubia": {
            "semantic_relation": 4.34902,
            "contradiction": 0.59343,
            "irrelevancy": 0.62199,
            "logical_agreement": 98.78458,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.86394,
            "nubia_score": 0.78147
        },
        "meteor": 0.41779964074166775
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.6825,
        "msttr-100_nopunct": 0.72667,
        "total_length": 405,
        "mean_pred_length": 17.608695652173914,
        "std_pred_length": 6.611841356593767,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.5358024691358024,
        "vocab_size-1": 217,
        "unique-1": 172,
        "entropy-1": 6.966984982575279,
        "distinct-2": 0.900523560209424,
        "vocab_size-2": 344,
        "unique-2": 321,
        "entropy-2": 8.330359350528955,
        "cond_entropy-2": 1.1893589337466353,
        "distinct-3": 0.9637883008356546,
        "vocab_size-3": 346,
        "unique-3": 335,
        "entropy-3": 8.409845604853706,
        "cond_entropy-3": 0.0841731567834137,
        "total_length-nopunct": 356,
        "mean_pred_length-nopunct": 15.478260869565217,
        "std_pred_length-nopunct": 5.918795156605786,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5926966292134831,
        "vocab_size-1-nopunct": 211,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.084459662395127,
        "distinct-2-nopunct": 0.9009009009009009,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 282,
        "entropy-2-nopunct": 8.125983350832236,
        "cond_entropy-2-nopunct": 1.0894609949373617,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 300,
        "unique-3-nopunct": 292,
        "entropy-3-nopunct": 8.205156663338723,
        "cond_entropy-3-nopunct": 0.07142901148396837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.847,
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.6229508196721312,
            "3": 0.7627118644067796
        },
        "rouge1": {
            "precision": 0.74542,
            "recall": 0.76731,
            "fmeasure": 0.74763
        },
        "rouge2": {
            "precision": 0.54184,
            "recall": 0.55883,
            "fmeasure": 0.54398
        },
        "rougeL": {
            "precision": 0.63529,
            "recall": 0.65668,
            "fmeasure": 0.63748
        },
        "rougeLsum": {
            "precision": 0.63529,
            "recall": 0.65668,
            "fmeasure": 0.63748
        },
        "nist": 5.86148917358043,
        "bleurt": 0.22753,
        "bertscore": {
            "precision": 0.91368,
            "recall": 0.9191,
            "f1": 0.91436
        },
        "nubia": {
            "semantic_relation": 4.17683,
            "contradiction": 8.19586,
            "irrelevancy": 40.20995,
            "logical_agreement": 51.59419,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.06111,
            "nubia_score": 0.75592
        },
        "meteor": 0.3994320649990285
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.815,
        "total_length": 239,
        "mean_pred_length": 17.071428571428573,
        "std_pred_length": 5.216242294359935,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.6610878661087866,
        "vocab_size-1": 158,
        "unique-1": 137,
        "entropy-1": 6.731101850958433,
        "distinct-2": 0.9688888888888889,
        "vocab_size-2": 218,
        "unique-2": 212,
        "entropy-2": 7.748203913429598,
        "cond_entropy-2": 0.8529853535357116,
        "distinct-3": 1.0,
        "vocab_size-3": 211,
        "unique-3": 211,
        "entropy-3": 7.721099188707212,
        "cond_entropy-3": -0.022753625722347258,
        "total_length-nopunct": 208,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 5.1110125199995196,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7355769230769231,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 134,
        "entropy-1-nopunct": 6.868863338762575,
        "distinct-2-nopunct": 0.9742268041237113,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.5444752777429605,
        "cond_entropy-2-nopunct": 0.7222980565606943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 180,
        "entropy-3-nopunct": 7.491853096329661,
        "cond_entropy-3-nopunct": -0.04831037084543395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.20048,
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5116279069767442,
            "3": 0.7883211678832117
        },
        "rouge1": {
            "precision": 0.74032,
            "recall": 0.71931,
            "fmeasure": 0.72047
        },
        "rouge2": {
            "precision": 0.51511,
            "recall": 0.50716,
            "fmeasure": 0.50446
        },
        "rougeL": {
            "precision": 0.67183,
            "recall": 0.65113,
            "fmeasure": 0.65386
        },
        "rougeLsum": {
            "precision": 0.67183,
            "recall": 0.65113,
            "fmeasure": 0.65386
        },
        "nist": 6.1114722936088315,
        "bleurt": 0.21735,
        "bertscore": {
            "precision": 0.92344,
            "recall": 0.92363,
            "f1": 0.92163
        },
        "nubia": {
            "semantic_relation": 4.12247,
            "contradiction": 17.195,
            "irrelevancy": 37.90611,
            "logical_agreement": 44.89889,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.60125,
            "nubia_score": 0.70655
        },
        "meteor": 0.397765286654551
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.775,
        "total_length": 246,
        "mean_pred_length": 17.571428571428573,
        "std_pred_length": 9.744700286487491,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.6219512195121951,
        "vocab_size-1": 153,
        "unique-1": 127,
        "entropy-1": 6.623352501719218,
        "distinct-2": 0.9568965517241379,
        "vocab_size-2": 222,
        "unique-2": 213,
        "entropy-2": 7.768520273135469,
        "cond_entropy-2": 0.9950181987519583,
        "distinct-3": 0.9954128440366973,
        "vocab_size-3": 217,
        "unique-3": 216,
        "entropy-3": 7.759010012850308,
        "cond_entropy-3": -0.02211370015723533,
        "total_length-nopunct": 216,
        "mean_pred_length-nopunct": 15.428571428571429,
        "std_pred_length-nopunct": 8.641381219906636,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6898148148148148,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.720459509242599,
        "distinct-2-nopunct": 0.9702970297029703,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 191,
        "entropy-2-nopunct": 7.595068475315313,
        "cond_entropy-2-nopunct": 0.9165990249880464,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 188,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.554588851677659,
        "cond_entropy-3-nopunct": -0.03577748478605372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.41531,
        "local_recall": {
            "1": 0.2054794520547945,
            "2": 0.49230769230769234,
            "3": 0.6956521739130435
        },
        "rouge1": {
            "precision": 0.64027,
            "recall": 0.59897,
            "fmeasure": 0.60779
        },
        "rouge2": {
            "precision": 0.42081,
            "recall": 0.3899,
            "fmeasure": 0.39652
        },
        "rougeL": {
            "precision": 0.52769,
            "recall": 0.49734,
            "fmeasure": 0.50204
        },
        "rougeLsum": {
            "precision": 0.52769,
            "recall": 0.49734,
            "fmeasure": 0.50204
        },
        "nist": 4.935677602474444,
        "bleurt": -0.03579,
        "bertscore": {
            "precision": 0.90559,
            "recall": 0.89807,
            "f1": 0.90112
        },
        "nubia": {
            "semantic_relation": 3.64539,
            "contradiction": 5.1046,
            "irrelevancy": 59.27606,
            "logical_agreement": 35.61934,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.18113,
            "nubia_score": 0.62622
        },
        "meteor": 0.3417872578198145
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.51582,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "nist": 2.0052535157554314,
        "bleurt": 0.11529,
        "bertscore": {
            "precision": 0.87779,
            "recall": 0.87807,
            "f1": 0.87793
        },
        "nubia": {
            "semantic_relation": 3.3707,
            "contradiction": 81.05109,
            "irrelevancy": 11.0637,
            "logical_agreement": 7.88521,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.6162,
            "nubia_score": 0.3874
        },
        "meteor": 0.31253823342571707
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.44615,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.63971,
            "fmeasure": 0.71877
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.29722,
            "fmeasure": 0.33686
        },
        "rougeL": {
            "precision": 0.5641,
            "recall": 0.59091,
            "fmeasure": 0.5728
        },
        "rougeLsum": {
            "precision": 0.5641,
            "recall": 0.59091,
            "fmeasure": 0.5728
        },
        "nist": 3.7994206833057182,
        "bleurt": 0.03241,
        "bertscore": {
            "precision": 0.91477,
            "recall": 0.88217,
            "f1": 0.89817
        },
        "nubia": {
            "semantic_relation": 2.94357,
            "contradiction": 21.37408,
            "irrelevancy": 60.26671,
            "logical_agreement": 18.35921,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.38322,
            "nubia_score": 0.35229
        },
        "meteor": 0.3150063967846925
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 164,
        "mean_pred_length": 20.5,
        "std_pred_length": 8.689073598491383,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 41,
        "distinct-1": 0.6646341463414634,
        "vocab_size-1": 109,
        "unique-1": 84,
        "entropy-1": 6.4087893375826175,
        "distinct-2": 0.9551282051282052,
        "vocab_size-2": 149,
        "unique-2": 142,
        "entropy-2": 7.195658629118674,
        "cond_entropy-2": 0.6651685003641639,
        "distinct-3": 0.9864864864864865,
        "vocab_size-3": 146,
        "unique-3": 144,
        "entropy-3": 7.182426338601919,
        "cond_entropy-3": -0.008381285665731191,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 17.75,
        "std_pred_length-nopunct": 6.475916923494309,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7183098591549296,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.3978586971771625,
        "distinct-2-nopunct": 0.9626865671641791,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.991462324786138,
        "cond_entropy-2-nopunct": 0.6310298020762859,
        "distinct-3-nopunct": 0.9920634920634921,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 6.961406907626909,
        "cond_entropy-3-nopunct": -0.02531720346579252,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.13417,
        "local_recall": {
            "1": 0.24,
            "2": 0.36363636363636365,
            "3": 0.8297872340425532
        },
        "rouge1": {
            "precision": 0.69631,
            "recall": 0.73955,
            "fmeasure": 0.71203
        },
        "rouge2": {
            "precision": 0.47279,
            "recall": 0.52207,
            "fmeasure": 0.49237
        },
        "rougeL": {
            "precision": 0.58182,
            "recall": 0.62641,
            "fmeasure": 0.59824
        },
        "rougeLsum": {
            "precision": 0.58182,
            "recall": 0.62641,
            "fmeasure": 0.59824
        },
        "nist": 5.343190375077683,
        "bleurt": 0.31203,
        "bertscore": {
            "precision": 0.92937,
            "recall": 0.92962,
            "f1": 0.92782
        },
        "nubia": {
            "semantic_relation": 3.95302,
            "contradiction": 26.78882,
            "irrelevancy": 22.79984,
            "logical_agreement": 50.41134,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.7795,
            "nubia_score": 0.65634
        },
        "meteor": 0.3843069176941524
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.680813428089397,
        "cond_entropy-2": 0.2717876727785855,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.02247529290070043,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.3565583354166755,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.2822786583685261,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": 0.023416471633632495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.97668,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.7284,
            "recall": 0.5619,
            "fmeasure": 0.63441
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.21569,
            "fmeasure": 0.24444
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.37143,
            "fmeasure": 0.41935
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.37143,
            "fmeasure": 0.41935
        },
        "nist": 2.578378313227244,
        "bleurt": 0.09072,
        "bertscore": {
            "precision": 0.91886,
            "recall": 0.88805,
            "f1": 0.90319
        },
        "nubia": {
            "semantic_relation": 3.77209,
            "contradiction": 0.18263,
            "irrelevancy": 92.48961,
            "logical_agreement": 7.32776,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.15255,
            "nubia_score": 0.56636
        },
        "meteor": 0.33203074225648177
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 1.795054935711501,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.7162162162162162,
        "vocab_size-1": 53,
        "unique-1": 42,
        "entropy-1": 5.472570595183266,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 64,
        "unique-2": 60,
        "entropy-2": 5.969815782426816,
        "cond_entropy-2": 0.33417932868982864,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 60,
        "unique-3": 58,
        "entropy-3": 5.889680181354614,
        "cond_entropy-3": -0.06875040183120612,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 1.3743685418725535,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.765625,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.421569531114784,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.720049960644811,
        "cond_entropy-2-nopunct": 0.32383530562160434,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.623516641218019,
        "cond_entropy-3-nopunct": -0.09984896929417227,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.20615,
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.8666666666666667,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.70939,
            "recall": 0.83941,
            "fmeasure": 0.76009
        },
        "rouge2": {
            "precision": 0.48127,
            "recall": 0.5347,
            "fmeasure": 0.50122
        },
        "rougeL": {
            "precision": 0.64179,
            "recall": 0.75171,
            "fmeasure": 0.68386
        },
        "rougeLsum": {
            "precision": 0.64179,
            "recall": 0.75171,
            "fmeasure": 0.68386
        },
        "nist": 4.444542419318597,
        "bleurt": 0.26128,
        "bertscore": {
            "precision": 0.91646,
            "recall": 0.93245,
            "f1": 0.92413
        },
        "nubia": {
            "semantic_relation": 4.12555,
            "contradiction": 1.63903,
            "irrelevancy": 43.61696,
            "logical_agreement": 54.74401,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.66009,
            "nubia_score": 0.71395
        },
        "meteor": 0.41849914533656524
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.72,
        "total_length": 124,
        "mean_pred_length": 15.5,
        "std_pred_length": 8.261355820929152,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.6532258064516129,
        "vocab_size-1": 81,
        "unique-1": 66,
        "entropy-1": 5.980259568689218,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 104,
        "unique-2": 97,
        "entropy-2": 6.618546188999821,
        "cond_entropy-2": 0.4985581197380325,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 99,
        "unique-3": 93,
        "entropy-3": 6.567251738214473,
        "cond_entropy-3": -0.03355853922033547,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 7.378177281686853,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7169811320754716,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.96227408195874,
        "distinct-2-nopunct": 0.8775510204081632,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.323594282758271,
        "cond_entropy-2-nopunct": 0.4238219455019143,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.227692679542804,
        "cond_entropy-3-nopunct": -0.07002466442816177,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.89228,
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.7553191489361702
        },
        "rouge1": {
            "precision": 0.81131,
            "recall": 0.77884,
            "fmeasure": 0.78403
        },
        "rouge2": {
            "precision": 0.65945,
            "recall": 0.6396,
            "fmeasure": 0.64338
        },
        "rougeL": {
            "precision": 0.79226,
            "recall": 0.75552,
            "fmeasure": 0.76326
        },
        "rougeLsum": {
            "precision": 0.79226,
            "recall": 0.75552,
            "fmeasure": 0.76326
        },
        "nist": 5.230946153454508,
        "bleurt": 0.55865,
        "bertscore": {
            "precision": 0.94123,
            "recall": 0.92742,
            "f1": 0.93299
        },
        "nubia": {
            "semantic_relation": 4.36218,
            "contradiction": 5.96281,
            "irrelevancy": 35.28053,
            "logical_agreement": 58.75667,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.84626,
            "nubia_score": 0.76623
        },
        "meteor": 0.39988363472803223
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 22.0,
        "min_pred_length": 20,
        "max_pred_length": 26,
        "distinct-1": 0.75,
        "vocab_size-1": 51,
        "unique-1": 38,
        "entropy-1": 5.535848502951418,
        "distinct-2": 0.8923076923076924,
        "vocab_size-2": 58,
        "unique-2": 51,
        "entropy-2": 5.806983197643842,
        "cond_entropy-2": 0.2234417025806297,
        "distinct-3": 0.9193548387096774,
        "vocab_size-3": 57,
        "unique-3": 52,
        "entropy-3": 5.792905987806228,
        "cond_entropy-3": -0.0036553736093211907,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8070175438596491,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.433681461495203,
        "distinct-2-nopunct": 0.8703703703703703,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.495628242904208,
        "cond_entropy-2-nopunct": 0.04708799729805033,
        "distinct-3-nopunct": 0.9019607843137255,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.476346910598951,
        "cond_entropy-3-nopunct": -0.023638630780208256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.78069,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.3548387096774194,
            "3": 0.68
        },
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.56615,
            "fmeasure": 0.5805
        },
        "rouge2": {
            "precision": 0.42262,
            "recall": 0.39885,
            "fmeasure": 0.40797
        },
        "rougeL": {
            "precision": 0.58572,
            "recall": 0.55102,
            "fmeasure": 0.56323
        },
        "rougeLsum": {
            "precision": 0.58572,
            "recall": 0.55102,
            "fmeasure": 0.56323
        },
        "nist": 3.7416930102212413,
        "bleurt": 0.20244,
        "bertscore": {
            "precision": 0.91077,
            "recall": 0.89736,
            "f1": 0.90221
        },
        "nubia": {
            "semantic_relation": 3.9504,
            "contradiction": 0.46408,
            "irrelevancy": 65.78796,
            "logical_agreement": 33.74796,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.46662,
            "nubia_score": 0.7135
        },
        "meteor": 0.28073689686184106
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 3.299831645537222,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.8448275862068966,
        "vocab_size-1": 49,
        "unique-1": 43,
        "entropy-1": 5.508590262257046,
        "distinct-2": 0.9818181818181818,
        "vocab_size-2": 54,
        "unique-2": 53,
        "entropy-2": 5.744996077161019,
        "cond_entropy-2": 0.1690109912030318,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.04245845692202902,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9038461538461539,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.4936149584841045,
        "distinct-2-nopunct": 0.9795918367346939,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.5738935175845965,
        "cond_entropy-2-nopunct": 0.09294129948765635,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.047669627188630194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.71717,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7169811320754716
        },
        "rouge1": {
            "precision": 0.825,
            "recall": 0.79061,
            "fmeasure": 0.80107
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.61264,
            "fmeasure": 0.61411
        },
        "rougeL": {
            "precision": 0.72417,
            "recall": 0.70737,
            "fmeasure": 0.71065
        },
        "rougeLsum": {
            "precision": 0.72417,
            "recall": 0.70737,
            "fmeasure": 0.71065
        },
        "nist": 4.349665085524628,
        "bleurt": 0.45466,
        "bertscore": {
            "precision": 0.9498,
            "recall": 0.93928,
            "f1": 0.94428
        },
        "nubia": {
            "semantic_relation": 4.3091,
            "contradiction": 0.35159,
            "irrelevancy": 63.74262,
            "logical_agreement": 35.90579,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.47474,
            "nubia_score": 0.75108
        },
        "meteor": 0.38780522917875465
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 6.548960901462833,
        "median_pred_length": 22.0,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 50,
        "unique-1": 40,
        "entropy-1": 5.412225385943083,
        "distinct-2": 0.9846153846153847,
        "vocab_size-2": 64,
        "unique-2": 63,
        "entropy-2": 5.991598582259227,
        "cond_entropy-2": 0.5373858865278097,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.03591343812545021,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 20.333333333333332,
        "std_pred_length-nopunct": 4.9216076867444665,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7704918032786885,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.321536362829604,
        "distinct-2-nopunct": 0.9827586206896551,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.823498236506881,
        "cond_entropy-2-nopunct": 0.5334722689221021,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.04025764523927601,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.63518,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6875,
            "3": 0.9642857142857143
        },
        "rouge1": {
            "precision": 0.71846,
            "recall": 0.82854,
            "fmeasure": 0.7691
        },
        "rouge2": {
            "precision": 0.49564,
            "recall": 0.5736,
            "fmeasure": 0.53146
        },
        "rougeL": {
            "precision": 0.64276,
            "recall": 0.74572,
            "fmeasure": 0.69006
        },
        "rougeLsum": {
            "precision": 0.64276,
            "recall": 0.74572,
            "fmeasure": 0.69006
        },
        "nist": 4.1169477170413264,
        "bleurt": 0.40904,
        "bertscore": {
            "precision": 0.92353,
            "recall": 0.94585,
            "f1": 0.93454
        },
        "nubia": {
            "semantic_relation": 4.2196,
            "contradiction": 30.25645,
            "irrelevancy": 18.25937,
            "logical_agreement": 51.48419,
            "grammar_ref": 4.44265,
            "grammar_hyp": 3.85585,
            "nubia_score": 0.80963
        },
        "meteor": 0.41876200412138004
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.765,
        "total_length": 327,
        "mean_pred_length": 16.35,
        "std_pred_length": 5.208406666150407,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.581039755351682,
        "vocab_size-1": 190,
        "unique-1": 152,
        "entropy-1": 6.873736074451996,
        "distinct-2": 0.9153094462540716,
        "vocab_size-2": 281,
        "unique-2": 261,
        "entropy-2": 8.074766588027057,
        "cond_entropy-2": 1.0068923463052857,
        "distinct-3": 0.9790940766550522,
        "vocab_size-3": 281,
        "unique-3": 275,
        "entropy-3": 8.123095079985758,
        "cond_entropy-3": 0.061382725919888456,
        "total_length-nopunct": 285,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 5.078139423056441,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6526315789473685,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.064989442539557,
        "distinct-2-nopunct": 0.9132075471698113,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 225,
        "entropy-2-nopunct": 7.855472040000226,
        "cond_entropy-2-nopunct": 0.8554320722891389,
        "distinct-3-nopunct": 0.9836734693877551,
        "vocab_size-3-nopunct": 241,
        "unique-3-nopunct": 237,
        "entropy-3-nopunct": 7.903984877778112,
        "cond_entropy-3-nopunct": 0.05621704263089461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.56202,
        "local_recall": {
            "1": 0.20270270270270271,
            "2": 0.5384615384615384,
            "3": 0.8263157894736842
        },
        "rouge1": {
            "precision": 0.81471,
            "recall": 0.82849,
            "fmeasure": 0.81467
        },
        "rouge2": {
            "precision": 0.63123,
            "recall": 0.63918,
            "fmeasure": 0.62901
        },
        "rougeL": {
            "precision": 0.71971,
            "recall": 0.72346,
            "fmeasure": 0.71581
        },
        "rougeLsum": {
            "precision": 0.71971,
            "recall": 0.72346,
            "fmeasure": 0.71581
        },
        "nist": 6.249378540498102,
        "bleurt": 0.39128,
        "bertscore": {
            "precision": 0.94626,
            "recall": 0.94222,
            "f1": 0.94194
        },
        "nubia": {
            "semantic_relation": 4.29738,
            "contradiction": 2.51975,
            "irrelevancy": 20.85876,
            "logical_agreement": 76.62149,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.46222,
            "nubia_score": 0.76927
        },
        "meteor": 0.4235169123210902
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.10394,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.47059,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.1875,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "nist": 1.8933307446855945,
        "bleurt": 0.046,
        "bertscore": {
            "precision": 0.90428,
            "recall": 0.8772,
            "f1": 0.89053
        },
        "nubia": {
            "semantic_relation": 3.86908,
            "contradiction": 0.66264,
            "irrelevancy": 2.47701,
            "logical_agreement": 96.86035,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.8487,
            "nubia_score": 0.68659
        },
        "meteor": 0.22738021864929275
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.50789957099271,
        "bleurt": 0.89367,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.6875,
        "msttr-100_nopunct": 0.74333,
        "total_length": 438,
        "mean_pred_length": 16.846153846153847,
        "std_pred_length": 7.3048577498512675,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 46,
        "distinct-1": 0.5525114155251142,
        "vocab_size-1": 242,
        "unique-1": 195,
        "entropy-1": 7.047514919677448,
        "distinct-2": 0.9174757281553398,
        "vocab_size-2": 378,
        "unique-2": 353,
        "entropy-2": 8.491683385177145,
        "cond_entropy-2": 1.2565413853209835,
        "distinct-3": 0.9922279792746114,
        "vocab_size-3": 383,
        "unique-3": 380,
        "entropy-3": 8.57691299581728,
        "cond_entropy-3": 0.09317066165607976,
        "total_length-nopunct": 372,
        "mean_pred_length-nopunct": 14.307692307692308,
        "std_pred_length-nopunct": 5.231334811052093,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6344086021505376,
        "vocab_size-1-nopunct": 236,
        "unique-1-nopunct": 194,
        "entropy-1-nopunct": 7.195642020012051,
        "distinct-2-nopunct": 0.9248554913294798,
        "vocab_size-2-nopunct": 320,
        "unique-2-nopunct": 303,
        "entropy-2-nopunct": 8.248892208831819,
        "cond_entropy-2-nopunct": 1.13806658785963,
        "distinct-3-nopunct": 0.990625,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 314,
        "entropy-3-nopunct": 8.303178094887327,
        "cond_entropy-3-nopunct": 0.06625193758341995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.45582,
        "local_recall": {
            "1": 0.21839080459770116,
            "2": 0.5161290322580645,
            "3": 0.7639484978540773
        },
        "rouge1": {
            "precision": 0.6977,
            "recall": 0.7323,
            "fmeasure": 0.70305
        },
        "rouge2": {
            "precision": 0.45481,
            "recall": 0.46248,
            "fmeasure": 0.45067
        },
        "rougeL": {
            "precision": 0.59148,
            "recall": 0.62344,
            "fmeasure": 0.59717
        },
        "rougeLsum": {
            "precision": 0.59148,
            "recall": 0.62344,
            "fmeasure": 0.59717
        },
        "nist": 6.01604007464603,
        "bleurt": 0.08346,
        "bertscore": {
            "precision": 0.90546,
            "recall": 0.91047,
            "f1": 0.90647
        },
        "nubia": {
            "semantic_relation": 3.87356,
            "contradiction": 11.5639,
            "irrelevancy": 45.96307,
            "logical_agreement": 42.47302,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.54784,
            "nubia_score": 0.65674
        },
        "meteor": 0.3644054031968968
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77667,
        "total_length": 1819,
        "mean_pred_length": 16.536363636363635,
        "std_pred_length": 6.6806059506431446,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.47003848268279275,
        "vocab_size-1": 855,
        "unique-1": 685,
        "entropy-1": 8.267317421452614,
        "distinct-2": 0.8607372732592159,
        "vocab_size-2": 1471,
        "unique-2": 1354,
        "entropy-2": 10.338315608998169,
        "cond_entropy-2": 1.7993936212461135,
        "distinct-3": 0.9555972482801751,
        "vocab_size-3": 1528,
        "unique-3": 1481,
        "entropy-3": 10.5412854148307,
        "cond_entropy-3": 0.19808801409631843,
        "total_length-nopunct": 1598,
        "mean_pred_length-nopunct": 14.527272727272727,
        "std_pred_length-nopunct": 5.9828681034936455,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5300375469336671,
        "vocab_size-1-nopunct": 847,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 8.536596119657196,
        "distinct-2-nopunct": 0.866263440860215,
        "vocab_size-2-nopunct": 1289,
        "unique-2-nopunct": 1198,
        "entropy-2-nopunct": 10.140958241404533,
        "cond_entropy-2-nopunct": 1.7085993554583059,
        "distinct-3-nopunct": 0.9528301886792453,
        "vocab_size-3-nopunct": 1313,
        "unique-3-nopunct": 1271,
        "entropy-3-nopunct": 10.319642075804566,
        "cond_entropy-3-nopunct": 0.20381600977430822,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.81456,
        "local_recall": {
            "1": 0.24338624338624337,
            "2": 0.5145888594164456,
            "3": 0.7915094339622641
        },
        "rouge1": {
            "precision": 0.75426,
            "recall": 0.73682,
            "fmeasure": 0.73534
        },
        "rouge2": {
            "precision": 0.53077,
            "recall": 0.51538,
            "fmeasure": 0.51516
        },
        "rougeL": {
            "precision": 0.65355,
            "recall": 0.6401,
            "fmeasure": 0.63779
        },
        "rougeLsum": {
            "precision": 0.65355,
            "recall": 0.6401,
            "fmeasure": 0.63779
        },
        "nist": 7.696965585929952,
        "bleurt": 0.29206,
        "bertscore": {
            "precision": 0.93118,
            "recall": 0.92995,
            "f1": 0.92947
        },
        "nubia": {
            "semantic_relation": 4.27444,
            "contradiction": 5.13841,
            "irrelevancy": 27.38062,
            "logical_agreement": 67.48097,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.79215,
            "nubia_score": 0.75135
        },
        "meteor": 0.3984072003012417
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 21,
        "entropy-1": 4.6534955617749425,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.31112739319226923,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.487122805397798,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.2952356737826916,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.74657,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2,
            "3": 0.65
        },
        "rouge1": {
            "precision": 0.54209,
            "recall": 0.56673,
            "fmeasure": 0.55388
        },
        "rouge2": {
            "precision": 0.27647,
            "recall": 0.29345,
            "fmeasure": 0.28442
        },
        "rougeL": {
            "precision": 0.36616,
            "recall": 0.38046,
            "fmeasure": 0.37293
        },
        "rougeLsum": {
            "precision": 0.36616,
            "recall": 0.38046,
            "fmeasure": 0.37293
        },
        "nist": 3.2430169976677554,
        "bleurt": 0.21469,
        "bertscore": {
            "precision": 0.90218,
            "recall": 0.90059,
            "f1": 0.90133
        },
        "nubia": {
            "semantic_relation": 4.4429,
            "contradiction": 0.45744,
            "irrelevancy": 26.96284,
            "logical_agreement": 72.57973,
            "grammar_ref": 5.35082,
            "grammar_hyp": 4.85816,
            "nubia_score": 0.89316
        },
        "meteor": 0.3342564351172593
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.24227,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.78571,
            "fmeasure": 0.75862
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.78307,
            "fmeasure": 0.62835
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.78307,
            "fmeasure": 0.62835
        },
        "nist": 3.1718077340143003,
        "bleurt": 0.23105,
        "bertscore": {
            "precision": 0.91505,
            "recall": 0.95779,
            "f1": 0.91767
        },
        "nubia": {
            "semantic_relation": 4.0561,
            "contradiction": 0.10872,
            "irrelevancy": 99.75743,
            "logical_agreement": 0.13385,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.37821,
            "nubia_score": 0.75842
        },
        "meteor": 0.4276745333701023
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.795,
        "total_length": 923,
        "mean_pred_length": 17.09259259259259,
        "std_pred_length": 6.788521135298142,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 34,
        "distinct-1": 0.504875406283857,
        "vocab_size-1": 466,
        "unique-1": 368,
        "entropy-1": 7.7884765322299385,
        "distinct-2": 0.8872266973532796,
        "vocab_size-2": 771,
        "unique-2": 717,
        "entropy-2": 9.469103160964266,
        "cond_entropy-2": 1.4494861591856114,
        "distinct-3": 0.9766871165644172,
        "vocab_size-3": 796,
        "unique-3": 779,
        "entropy-3": 9.6221779975796,
        "cond_entropy-3": 0.16765385148111098,
        "total_length-nopunct": 814,
        "mean_pred_length-nopunct": 15.074074074074074,
        "std_pred_length-nopunct": 6.133852187751161,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5626535626535627,
        "vocab_size-1-nopunct": 458,
        "unique-1-nopunct": 366,
        "entropy-1-nopunct": 8.007217995500818,
        "distinct-2-nopunct": 0.8934210526315789,
        "vocab_size-2-nopunct": 679,
        "unique-2-nopunct": 637,
        "entropy-2-nopunct": 9.283913190729587,
        "cond_entropy-2-nopunct": 1.3548700471587891,
        "distinct-3-nopunct": 0.9759206798866855,
        "vocab_size-3-nopunct": 689,
        "unique-3-nopunct": 674,
        "entropy-3-nopunct": 9.413227241537044,
        "cond_entropy-3-nopunct": 0.14693570881109067,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.47035,
        "local_recall": {
            "1": 0.22905027932960895,
            "2": 0.41714285714285715,
            "3": 0.7564516129032258
        },
        "rouge1": {
            "precision": 0.76623,
            "recall": 0.73292,
            "fmeasure": 0.73626
        },
        "rouge2": {
            "precision": 0.54132,
            "recall": 0.5202,
            "fmeasure": 0.5196
        },
        "rougeL": {
            "precision": 0.6576,
            "recall": 0.63839,
            "fmeasure": 0.63552
        },
        "rougeLsum": {
            "precision": 0.6576,
            "recall": 0.63839,
            "fmeasure": 0.63552
        },
        "nist": 6.889589180905006,
        "bleurt": 0.2743,
        "bertscore": {
            "precision": 0.9326,
            "recall": 0.93187,
            "f1": 0.931
        },
        "nubia": {
            "semantic_relation": 4.21272,
            "contradiction": 9.52694,
            "irrelevancy": 28.52314,
            "logical_agreement": 61.94992,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.56372,
            "nubia_score": 0.74212
        },
        "meteor": 0.3846704843013292
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 7.0710678118654755,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7733333333333333,
        "vocab_size-1": 58,
        "unique-1": 49,
        "entropy-1": 5.659097944453213,
        "distinct-2": 0.9857142857142858,
        "vocab_size-2": 69,
        "unique-2": 68,
        "entropy-2": 6.100711588373543,
        "cond_entropy-2": 0.3164559761457105,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.07614597314728143,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 6.406246951218787,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.659236143033229,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.28853796286487454,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.08481616975165489,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.18642,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.81183,
            "recall": 0.87599,
            "fmeasure": 0.83318
        },
        "rouge2": {
            "precision": 0.62579,
            "recall": 0.6703,
            "fmeasure": 0.64022
        },
        "rougeL": {
            "precision": 0.70597,
            "recall": 0.75511,
            "fmeasure": 0.72117
        },
        "rougeLsum": {
            "precision": 0.70597,
            "recall": 0.75511,
            "fmeasure": 0.72117
        },
        "nist": 4.458820429389465,
        "bleurt": 0.29583,
        "bertscore": {
            "precision": 0.93354,
            "recall": 0.94844,
            "f1": 0.93793
        },
        "nubia": {
            "semantic_relation": 4.03279,
            "contradiction": 19.96538,
            "irrelevancy": 33.57062,
            "logical_agreement": 46.46399,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.47399,
            "nubia_score": 0.64508
        },
        "meteor": 0.4389575296433121
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.735,
        "total_length": 245,
        "mean_pred_length": 18.846153846153847,
        "std_pred_length": 6.757857578645353,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 34,
        "distinct-1": 0.5877551020408164,
        "vocab_size-1": 144,
        "unique-1": 109,
        "entropy-1": 6.584393645647312,
        "distinct-2": 0.9094827586206896,
        "vocab_size-2": 211,
        "unique-2": 195,
        "entropy-2": 7.654880066339778,
        "cond_entropy-2": 0.9389065046484647,
        "distinct-3": 0.9680365296803652,
        "vocab_size-3": 212,
        "unique-3": 206,
        "entropy-3": 7.707413144066191,
        "cond_entropy-3": 0.04632445706081746,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 16.53846153846154,
        "std_pred_length-nopunct": 5.678778100089769,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6511627906976745,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.673362992843524,
        "distinct-2-nopunct": 0.9257425742574258,
        "vocab_size-2-nopunct": 187,
        "unique-2-nopunct": 176,
        "entropy-2-nopunct": 7.488090057125032,
        "cond_entropy-2-nopunct": 0.830657265447533,
        "distinct-3-nopunct": 0.9841269841269841,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.530496392475051,
        "cond_entropy-3-nopunct": 0.02953714139957196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.17577,
        "local_recall": {
            "1": 0.16901408450704225,
            "2": 0.6037735849056604,
            "3": 0.7301587301587301
        },
        "rouge1": {
            "precision": 0.67025,
            "recall": 0.69371,
            "fmeasure": 0.67148
        },
        "rouge2": {
            "precision": 0.4447,
            "recall": 0.46741,
            "fmeasure": 0.44769
        },
        "rougeL": {
            "precision": 0.58217,
            "recall": 0.60586,
            "fmeasure": 0.58457
        },
        "rougeLsum": {
            "precision": 0.58217,
            "recall": 0.60586,
            "fmeasure": 0.58457
        },
        "nist": 5.2433600078820986,
        "bleurt": 0.1005,
        "bertscore": {
            "precision": 0.90573,
            "recall": 0.91094,
            "f1": 0.9064
        },
        "nubia": {
            "semantic_relation": 3.84481,
            "contradiction": 19.61295,
            "irrelevancy": 53.67251,
            "logical_agreement": 26.71454,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.25579,
            "nubia_score": 0.64565
        },
        "meteor": 0.37173748111876576
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.064,
        "local_recall": {
            "1": 0.5,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.5625,
            "fmeasure": 0.47368
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.14286,
            "fmeasure": 0.11765
        },
        "rougeL": {
            "precision": 0.31818,
            "recall": 0.4375,
            "fmeasure": 0.36842
        },
        "rougeLsum": {
            "precision": 0.31818,
            "recall": 0.4375,
            "fmeasure": 0.36842
        },
        "nist": 1.4041354172676301,
        "bleurt": -1.08796,
        "bertscore": {
            "precision": 0.81139,
            "recall": 0.86095,
            "f1": 0.83485
        },
        "nubia": {
            "semantic_relation": 3.03653,
            "contradiction": 7.48997,
            "irrelevancy": 88.37979,
            "logical_agreement": 4.13024,
            "grammar_ref": 5.1072,
            "grammar_hyp": 6.03709,
            "nubia_score": 0.24749
        },
        "meteor": 0.28215831922474516
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.606739354015322,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.09939836982377731,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.025555977074987173,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.24212,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9444444444444444
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.89412,
            "fmeasure": 0.80098
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.59211,
            "fmeasure": 0.52703
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.73787,
            "fmeasure": 0.65583
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.73787,
            "fmeasure": 0.65583
        },
        "nist": 4.089587982422759,
        "bleurt": 0.34152,
        "bertscore": {
            "precision": 0.91155,
            "recall": 0.94916,
            "f1": 0.92998
        },
        "nubia": {
            "semantic_relation": 4.51178,
            "contradiction": 0.13324,
            "irrelevancy": 82.63288,
            "logical_agreement": 17.23389,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.62826,
            "nubia_score": 0.88633
        },
        "meteor": 0.4337080372374232
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.76551,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.48485,
            "fmeasure": 0.57734
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21481,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.48485,
            "fmeasure": 0.57734
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.48485,
            "fmeasure": 0.57734
        },
        "nist": 1.1203007814753612,
        "bleurt": 0.39279,
        "bertscore": {
            "precision": 0.958,
            "recall": 0.90747,
            "f1": 0.93205
        },
        "nubia": {
            "semantic_relation": 4.44954,
            "contradiction": 0.74137,
            "irrelevancy": 0.63531,
            "logical_agreement": 98.62332,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75454,
            "nubia_score": 0.83218
        },
        "meteor": 0.32677380297002073
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.847076812334269,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.501080610501581,
        "distinct-2": 0.9846153846153847,
        "vocab_size-2": 64,
        "unique-2": 63,
        "entropy-2": 5.991598582259227,
        "cond_entropy-2": 0.3602313803388768,
        "distinct-3": 1.0,
        "vocab_size-3": 60,
        "unique-3": 60,
        "entropy-3": 5.906890595608517,
        "cond_entropy-3": -0.08214388408660254,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 4.029888335921977,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7936507936507936,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.495303288950706,
        "distinct-2-nopunct": 0.9827586206896551,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.823498236506881,
        "cond_entropy-2-nopunct": 0.36974465743110874,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.727920454563195,
        "cond_entropy-3-nopunct": -0.09232469150776919,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.70917,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.06666666666666667,
            "3": 0.6964285714285714
        },
        "rouge1": {
            "precision": 0.75063,
            "recall": 0.60335,
            "fmeasure": 0.66401
        },
        "rouge2": {
            "precision": 0.49264,
            "recall": 0.40483,
            "fmeasure": 0.44012
        },
        "rougeL": {
            "precision": 0.64998,
            "recall": 0.52852,
            "fmeasure": 0.57805
        },
        "rougeLsum": {
            "precision": 0.64998,
            "recall": 0.52852,
            "fmeasure": 0.57805
        },
        "nist": 4.40104246577686,
        "bleurt": 0.23674,
        "bertscore": {
            "precision": 0.92916,
            "recall": 0.88993,
            "f1": 0.90762
        },
        "nubia": {
            "semantic_relation": 4.36339,
            "contradiction": 0.33426,
            "irrelevancy": 13.97522,
            "logical_agreement": 85.69052,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.67806,
            "nubia_score": 0.80529
        },
        "meteor": 0.3677637348425636
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.76,
        "total_length": 229,
        "mean_pred_length": 16.357142857142858,
        "std_pred_length": 5.862802143991544,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.5982532751091703,
        "vocab_size-1": 137,
        "unique-1": 111,
        "entropy-1": 6.49876500383022,
        "distinct-2": 0.9162790697674419,
        "vocab_size-2": 197,
        "unique-2": 183,
        "entropy-2": 7.564426454220476,
        "cond_entropy-2": 0.9050250507201786,
        "distinct-3": 0.9701492537313433,
        "vocab_size-3": 195,
        "unique-3": 190,
        "entropy-3": 7.587594539426882,
        "cond_entropy-3": 0.03596773463505788,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 14.214285714285714,
        "std_pred_length-nopunct": 6.002125473870205,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6683417085427136,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.629817867883016,
        "distinct-2-nopunct": 0.9243243243243243,
        "vocab_size-2-nopunct": 171,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 7.365138825369472,
        "cond_entropy-2-nopunct": 0.8029443739001367,
        "distinct-3-nopunct": 0.9824561403508771,
        "vocab_size-3-nopunct": 168,
        "unique-3-nopunct": 165,
        "entropy-3-nopunct": 7.382764795587644,
        "cond_entropy-3-nopunct": 0.031236478358845972,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.51229,
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.5909090909090909,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8422,
            "recall": 0.82506,
            "fmeasure": 0.82735
        },
        "rouge2": {
            "precision": 0.69967,
            "recall": 0.68868,
            "fmeasure": 0.68972
        },
        "rougeL": {
            "precision": 0.75626,
            "recall": 0.75152,
            "fmeasure": 0.74929
        },
        "rougeLsum": {
            "precision": 0.75626,
            "recall": 0.75152,
            "fmeasure": 0.74929
        },
        "nist": 6.852576001623648,
        "bleurt": 0.45272,
        "bertscore": {
            "precision": 0.95694,
            "recall": 0.95206,
            "f1": 0.9519
        },
        "nubia": {
            "semantic_relation": 4.48154,
            "contradiction": 3.24748,
            "irrelevancy": 20.92363,
            "logical_agreement": 75.8289,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.71782,
            "nubia_score": 0.81015
        },
        "meteor": 0.4719457389691724
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.293660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.30589329020324296,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.061482186720775,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.30216616138734265,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.00429,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.82038,
            "fmeasure": 0.78729
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.53704,
            "fmeasure": 0.50448
        },
        "rougeL": {
            "precision": 0.39394,
            "recall": 0.42607,
            "fmeasure": 0.40915
        },
        "rougeLsum": {
            "precision": 0.39394,
            "recall": 0.42607,
            "fmeasure": 0.40915
        },
        "nist": 3.644503405504696,
        "bleurt": 0.14863,
        "bertscore": {
            "precision": 0.93751,
            "recall": 0.9456,
            "f1": 0.94154
        },
        "nubia": {
            "semantic_relation": 4.62149,
            "contradiction": 0.26671,
            "irrelevancy": 3.17167,
            "logical_agreement": 96.56162,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.64524,
            "nubia_score": 0.874
        },
        "meteor": 0.42747320848498865
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 22.0,
        "std_pred_length": 8.524474568362947,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 34,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 46,
        "unique-1": 38,
        "entropy-1": 5.197179771466131,
        "distinct-2": 0.9365079365079365,
        "vocab_size-2": 59,
        "unique-2": 55,
        "entropy-2": 5.850295796515793,
        "cond_entropy-2": 0.6179851606292434,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 58,
        "unique-3": 56,
        "entropy-3": 5.8402239289418505,
        "cond_entropy-3": -0.003722661224731353,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 20.666666666666668,
        "std_pred_length-nopunct": 8.73053390247253,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.129014706213807,
        "distinct-2-nopunct": 0.9322033898305084,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.7470498290228536,
        "cond_entropy-2-nopunct": 0.6599935094619185,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.735926350629038,
        "cond_entropy-3-nopunct": -0.00385955587566578,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.81316,
        "local_recall": {
            "1": 0.1,
            "2": 0.7333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6814,
            "fmeasure": 0.68809
        },
        "rouge2": {
            "precision": 0.46484,
            "recall": 0.43179,
            "fmeasure": 0.44535
        },
        "rougeL": {
            "precision": 0.63272,
            "recall": 0.62435,
            "fmeasure": 0.62355
        },
        "rougeLsum": {
            "precision": 0.63272,
            "recall": 0.62435,
            "fmeasure": 0.62355
        },
        "nist": 3.948737986281735,
        "bleurt": 0.21763,
        "bertscore": {
            "precision": 0.9215,
            "recall": 0.92432,
            "f1": 0.92129
        },
        "nubia": {
            "semantic_relation": 3.83317,
            "contradiction": 28.3823,
            "irrelevancy": 37.73687,
            "logical_agreement": 33.88083,
            "grammar_ref": 3.79025,
            "grammar_hyp": 3.90262,
            "nubia_score": 0.6238
        },
        "meteor": 0.3378704284769004
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411754,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.11768784439846629,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.84852,
        "local_recall": {
            "1": 0.0,
            "2": 0.08333333333333333,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.85507,
            "recall": 0.4575,
            "fmeasure": 0.59593
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.33075,
            "fmeasure": 0.4421
        },
        "rougeL": {
            "precision": 0.81159,
            "recall": 0.41173,
            "fmeasure": 0.54625
        },
        "rougeLsum": {
            "precision": 0.81159,
            "recall": 0.41173,
            "fmeasure": 0.54625
        },
        "nist": 0.7142614467978315,
        "bleurt": -0.18207,
        "bertscore": {
            "precision": 0.94235,
            "recall": 0.85107,
            "f1": 0.89226
        },
        "nubia": {
            "semantic_relation": 3.50046,
            "contradiction": 0.30274,
            "irrelevancy": 6.21432,
            "logical_agreement": 93.48293,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.30756,
            "nubia_score": 0.49534
        },
        "meteor": 0.2511046845106929
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.1312445332782524,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.5639,
        "local_recall": {
            "1": 0.6,
            "2": 0.125,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.79125,
            "recall": 0.73701,
            "fmeasure": 0.75333
        },
        "rouge2": {
            "precision": 0.5375,
            "recall": 0.51496,
            "fmeasure": 0.51759
        },
        "rougeL": {
            "precision": 0.68519,
            "recall": 0.65368,
            "fmeasure": 0.66
        },
        "rougeLsum": {
            "precision": 0.68519,
            "recall": 0.65368,
            "fmeasure": 0.66
        },
        "nist": 3.7069534304511813,
        "bleurt": -0.07376,
        "bertscore": {
            "precision": 0.9148,
            "recall": 0.92745,
            "f1": 0.91751
        },
        "nubia": {
            "semantic_relation": 3.76779,
            "contradiction": 27.62278,
            "irrelevancy": 19.36948,
            "logical_agreement": 53.00774,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.2307,
            "nubia_score": 0.45038
        },
        "meteor": 0.37905306248180004
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleurt": 1.00634,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.43993,
        "local_recall": {
            "1": 0.0,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.54762,
            "fmeasure": 0.4569
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.10096,
            "fmeasure": 0.08249
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.54762,
            "fmeasure": 0.4569
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.54762,
            "fmeasure": 0.4569
        },
        "nist": 1.554586579812756,
        "bleurt": 0.33721,
        "bertscore": {
            "precision": 0.84992,
            "recall": 0.93499,
            "f1": 0.89043
        },
        "nubia": {
            "semantic_relation": 2.85128,
            "contradiction": 49.38721,
            "irrelevancy": 50.26361,
            "logical_agreement": 0.34918,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.21944,
            "nubia_score": 0.39344
        },
        "meteor": 0.3422639844142198
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.67372,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.47475,
            "fmeasure": 0.4188
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.61111,
            "fmeasure": 0.54762
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.61111,
            "fmeasure": 0.54762
        },
        "nist": 2.5236911396313286,
        "bleurt": 0.54019,
        "bertscore": {
            "precision": 0.89121,
            "recall": 0.94371,
            "f1": 0.90911
        },
        "nubia": {
            "semantic_relation": 4.24238,
            "contradiction": 0.8098,
            "irrelevancy": 37.412,
            "logical_agreement": 61.7782,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.949,
            "nubia_score": 0.65942
        },
        "meteor": 0.4013662009406466
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 2.5,
        "median_pred_length": 22.5,
        "min_pred_length": 20,
        "max_pred_length": 25,
        "distinct-1": 0.9111111111111111,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.314075318551895,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.07394654209335363,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.06871275008401433,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9487179487179487,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.182838116298145,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.005132227847782368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.08017034868398329,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.3862,
        "local_recall": {
            "1": 0.0,
            "2": 0.26666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.69602,
            "recall": 0.59916,
            "fmeasure": 0.63734
        },
        "rouge2": {
            "precision": 0.50952,
            "recall": 0.45507,
            "fmeasure": 0.47626
        },
        "rougeL": {
            "precision": 0.62027,
            "recall": 0.53718,
            "fmeasure": 0.56908
        },
        "rougeLsum": {
            "precision": 0.62027,
            "recall": 0.53718,
            "fmeasure": 0.56908
        },
        "nist": 3.086496069827816,
        "bleurt": 0.19302,
        "bertscore": {
            "precision": 0.92853,
            "recall": 0.88675,
            "f1": 0.90714
        },
        "nubia": {
            "semantic_relation": 4.08063,
            "contradiction": 0.52541,
            "irrelevancy": 8.49657,
            "logical_agreement": 90.97803,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.79293,
            "nubia_score": 0.68066
        },
        "meteor": 0.2803782635595085
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 9.195409482755814,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.7282608695652174,
        "vocab_size-1": 67,
        "unique-1": 57,
        "entropy-1": 5.808622417895966,
        "distinct-2": 0.8488372093023255,
        "vocab_size-2": 73,
        "unique-2": 68,
        "entropy-2": 6.036616208140158,
        "cond_entropy-2": 0.0975270719260556,
        "distinct-3": 0.8875,
        "vocab_size-3": 71,
        "unique-3": 67,
        "entropy-3": 6.0436198135562265,
        "cond_entropy-3": -0.06377275359177917,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 7.762087348130012,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.778000928757123,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.888688357104864,
        "cond_entropy-2-nopunct": 0.048968687611256015,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.901790217553665,
        "cond_entropy-3-nopunct": -0.07326361780703737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.27595,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8648648648648649
        },
        "rouge1": {
            "precision": 0.88983,
            "recall": 0.89133,
            "fmeasure": 0.89039
        },
        "rouge2": {
            "precision": 0.83889,
            "recall": 0.84444,
            "fmeasure": 0.84141
        },
        "rougeL": {
            "precision": 0.82683,
            "recall": 0.83669,
            "fmeasure": 0.83134
        },
        "rougeLsum": {
            "precision": 0.82683,
            "recall": 0.83669,
            "fmeasure": 0.83134
        },
        "nist": 4.7753784581962835,
        "bleurt": 0.64678,
        "bertscore": {
            "precision": 0.96035,
            "recall": 0.96512,
            "f1": 0.96255
        },
        "nubia": {
            "semantic_relation": 4.69869,
            "contradiction": 16.72755,
            "irrelevancy": 2.45902,
            "logical_agreement": 80.81343,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.96948,
            "nubia_score": 0.84041
        },
        "meteor": 0.5114802687583682
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 5.973901572674261,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7843137254901961,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.17223367521999,
        "distinct-2": 0.9361702127659575,
        "vocab_size-2": 44,
        "unique-2": 41,
        "entropy-2": 5.426929277209555,
        "cond_entropy-2": 0.12705233958543843,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": -0.03530084116158587,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 5.545268253204709,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.142914673354252,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.249460279921618,
        "cond_entropy-2-nopunct": 0.11898820492000795,
        "distinct-3-nopunct": 0.9736842105263158,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.19529593449622,
        "cond_entropy-3-nopunct": -0.039126751440438125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.88559,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.575
        },
        "rouge1": {
            "precision": 0.69601,
            "recall": 0.54095,
            "fmeasure": 0.58677
        },
        "rouge2": {
            "precision": 0.46496,
            "recall": 0.34166,
            "fmeasure": 0.37632
        },
        "rougeL": {
            "precision": 0.66496,
            "recall": 0.52033,
            "fmeasure": 0.56304
        },
        "rougeLsum": {
            "precision": 0.66496,
            "recall": 0.52033,
            "fmeasure": 0.56304
        },
        "nist": 3.118915336876681,
        "bleurt": 0.1331,
        "bertscore": {
            "precision": 0.93704,
            "recall": 0.88786,
            "f1": 0.91009
        },
        "nubia": {
            "semantic_relation": 4.01683,
            "contradiction": 26.77784,
            "irrelevancy": 40.79308,
            "logical_agreement": 32.42907,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.64405,
            "nubia_score": 0.58173
        },
        "meteor": 0.2951313508813463
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 4.988876515698588,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.052628805870279,
        "distinct-2": 0.9622641509433962,
        "vocab_size-2": 51,
        "unique-2": 49,
        "entropy-2": 5.652448756449988,
        "cond_entropy-2": 0.5528254382476127,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.0040642647884745415,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 4.642796092394706,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.979097891134805,
        "distinct-2-nopunct": 0.9591836734693877,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.533077191053984,
        "cond_entropy-2-nopunct": 0.5981430852460947,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.004191366319064993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.36719,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6153846153846154,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.75946,
            "recall": 0.82417,
            "fmeasure": 0.78961
        },
        "rouge2": {
            "precision": 0.55707,
            "recall": 0.59955,
            "fmeasure": 0.57676
        },
        "rougeL": {
            "precision": 0.63247,
            "recall": 0.72192,
            "fmeasure": 0.67114
        },
        "rougeLsum": {
            "precision": 0.63247,
            "recall": 0.72192,
            "fmeasure": 0.67114
        },
        "nist": 5.103147759521338,
        "bleurt": 0.44493,
        "bertscore": {
            "precision": 0.94172,
            "recall": 0.95495,
            "f1": 0.94711
        },
        "nubia": {
            "semantic_relation": 4.59213,
            "contradiction": 0.25762,
            "irrelevancy": 40.70735,
            "logical_agreement": 59.03503,
            "grammar_ref": 4.38609,
            "grammar_hyp": 3.87301,
            "nubia_score": 0.82538
        },
        "meteor": 0.5150078602848148
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 25,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 44,
        "unique-1": 37,
        "entropy-1": 5.207321121424566,
        "distinct-2": 0.9298245614035088,
        "vocab_size-2": 53,
        "unique-2": 50,
        "entropy-2": 5.679295496582922,
        "cond_entropy-2": 0.42537474218271737,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": 0.0841250343350873,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 3.299831645537222,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.1410091508178635,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.532076496945644,
        "cond_entropy-2-nopunct": 0.4280106478223973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": 0.09294129948765635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.95182,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.77328,
            "recall": 0.77447,
            "fmeasure": 0.76354
        },
        "rouge2": {
            "precision": 0.4531,
            "recall": 0.42791,
            "fmeasure": 0.43638
        },
        "rougeL": {
            "precision": 0.58606,
            "recall": 0.59431,
            "fmeasure": 0.58346
        },
        "rougeLsum": {
            "precision": 0.58606,
            "recall": 0.59431,
            "fmeasure": 0.58346
        },
        "nist": 4.871458597294762,
        "bleurt": 0.21206,
        "bertscore": {
            "precision": 0.92446,
            "recall": 0.93712,
            "f1": 0.92629
        },
        "nubia": {
            "semantic_relation": 4.55887,
            "contradiction": 0.7147,
            "irrelevancy": 29.35107,
            "logical_agreement": 69.93423,
            "grammar_ref": 4.10939,
            "grammar_hyp": 3.98162,
            "nubia_score": 0.83278
        },
        "meteor": 0.398673288241199
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.0,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.852168723603279,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.10003715874966063,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.760647923290102,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.11068123646483496,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.25532,
        "local_recall": {
            "1": 0.6,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.86508,
            "recall": 0.91649,
            "fmeasure": 0.88574
        },
        "rouge2": {
            "precision": 0.75833,
            "recall": 0.79363,
            "fmeasure": 0.77163
        },
        "rougeL": {
            "precision": 0.80159,
            "recall": 0.8563,
            "fmeasure": 0.82291
        },
        "rougeLsum": {
            "precision": 0.80159,
            "recall": 0.8563,
            "fmeasure": 0.82291
        },
        "nist": 4.772236865426867,
        "bleurt": 0.6093,
        "bertscore": {
            "precision": 0.96262,
            "recall": 0.98148,
            "f1": 0.97029
        },
        "nubia": {
            "semantic_relation": 4.78492,
            "contradiction": 0.50139,
            "irrelevancy": 16.67465,
            "logical_agreement": 82.82396,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.35858,
            "nubia_score": 0.93484
        },
        "meteor": 0.5357959955226289
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 6.3966136874651625,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6344086021505376,
        "vocab_size-1": 59,
        "unique-1": 48,
        "entropy-1": 5.436970709344399,
        "distinct-2": 0.8390804597701149,
        "vocab_size-2": 73,
        "unique-2": 64,
        "entropy-2": 6.077720076184158,
        "cond_entropy-2": 0.5384890634633831,
        "distinct-3": 0.9012345679012346,
        "vocab_size-3": 73,
        "unique-3": 67,
        "entropy-3": 6.123679941102801,
        "cond_entropy-3": 0.048322093535778175,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 6.175669104549635,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6705882352941176,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.40946483661193,
        "distinct-2-nopunct": 0.8354430379746836,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.926889134116125,
        "cond_entropy-2-nopunct": 0.5680515962023578,
        "distinct-3-nopunct": 0.9041095890410958,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.977361887587877,
        "cond_entropy-3-nopunct": 0.05405288613428978,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.84036,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.782608695652174
        },
        "rouge1": {
            "precision": 0.88277,
            "recall": 0.83527,
            "fmeasure": 0.85453
        },
        "rouge2": {
            "precision": 0.71022,
            "recall": 0.67962,
            "fmeasure": 0.69144
        },
        "rougeL": {
            "precision": 0.81647,
            "recall": 0.77842,
            "fmeasure": 0.7935
        },
        "rougeLsum": {
            "precision": 0.81647,
            "recall": 0.77842,
            "fmeasure": 0.7935
        },
        "nist": 5.69712090047095,
        "bleurt": 0.52348,
        "bertscore": {
            "precision": 0.969,
            "recall": 0.94759,
            "f1": 0.95806
        },
        "nubia": {
            "semantic_relation": 4.42102,
            "contradiction": 10.58151,
            "irrelevancy": 9.49061,
            "logical_agreement": 79.92788,
            "grammar_ref": 4.9652,
            "grammar_hyp": 4.89856,
            "nubia_score": 0.81491
        },
        "meteor": 0.43262341804021875
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7021276595744681,
        "vocab_size-1": 33,
        "unique-1": 23,
        "entropy-1": 4.884168106904723,
        "distinct-2": 0.7954545454545454,
        "vocab_size-2": 35,
        "unique-2": 26,
        "entropy-2": 5.050340709546387,
        "cond_entropy-2": 0.10381748291792031,
        "distinct-3": 0.8292682926829268,
        "vocab_size-3": 34,
        "unique-3": 27,
        "entropy-3": 5.016088589983937,
        "cond_entropy-3": -0.05309912621433558,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7073170731707317,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.704993772857999,
        "distinct-2-nopunct": 0.7894736842105263,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.826874881864638,
        "cond_entropy-2-nopunct": 0.1207672851982249,
        "distinct-3-nopunct": 0.8285714285714286,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.786425874087822,
        "cond_entropy-3-nopunct": -0.06150163935576179,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.52447,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.6,
            "3": 0.896551724137931
        },
        "rouge1": {
            "precision": 0.81155,
            "recall": 0.88345,
            "fmeasure": 0.84279
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.76682,
            "fmeasure": 0.72866
        },
        "rougeL": {
            "precision": 0.81155,
            "recall": 0.88345,
            "fmeasure": 0.84279
        },
        "rougeLsum": {
            "precision": 0.81155,
            "recall": 0.88345,
            "fmeasure": 0.84279
        },
        "nist": 4.465047984158867,
        "bleurt": 0.50311,
        "bertscore": {
            "precision": 0.94712,
            "recall": 0.96241,
            "f1": 0.95459
        },
        "nubia": {
            "semantic_relation": 4.64646,
            "contradiction": 0.23603,
            "irrelevancy": 22.8469,
            "logical_agreement": 76.91706,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.29269,
            "nubia_score": 0.85148
        },
        "meteor": 0.5082350164796284
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.85714,
            "recall": 0.77778,
            "fmeasure": 0.8125
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94444
        },
        "nist": 3.441361420586434,
        "bleurt": 0.86036,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19342,
            "irrelevancy": 0.44316,
            "logical_agreement": 99.36343,
            "grammar_ref": 6.57359,
            "grammar_hyp": 6.70859,
            "nubia_score": 0.97019
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69571,
        "msttr-100_nopunct": 0.735,
        "total_length": 768,
        "mean_pred_length": 16.340425531914892,
        "std_pred_length": 6.524182824005643,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5169270833333334,
        "vocab_size-1": 397,
        "unique-1": 321,
        "entropy-1": 7.50289844727552,
        "distinct-2": 0.8932038834951457,
        "vocab_size-2": 644,
        "unique-2": 598,
        "entropy-2": 9.217008387614362,
        "cond_entropy-2": 1.4877456331032655,
        "distinct-3": 0.9599406528189911,
        "vocab_size-3": 647,
        "unique-3": 624,
        "entropy-3": 9.312006042296602,
        "cond_entropy-3": 0.09649885927627426,
        "total_length-nopunct": 672,
        "mean_pred_length-nopunct": 14.297872340425531,
        "std_pred_length-nopunct": 5.881506876017337,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.5803571428571429,
        "vocab_size-1-nopunct": 390,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.678993644207742,
        "distinct-2-nopunct": 0.9008,
        "vocab_size-2-nopunct": 563,
        "unique-2-nopunct": 527,
        "entropy-2-nopunct": 9.023165069267666,
        "cond_entropy-2-nopunct": 1.4484982882567068,
        "distinct-3-nopunct": 0.9653979238754326,
        "vocab_size-3-nopunct": 558,
        "unique-3-nopunct": 540,
        "entropy-3-nopunct": 9.103109462770087,
        "cond_entropy-3-nopunct": 0.0876151955494781,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.9389,
        "local_recall": {
            "1": 0.1592920353982301,
            "2": 0.4588235294117647,
            "3": 0.7395833333333334
        },
        "rouge1": {
            "precision": 0.75409,
            "recall": 0.69515,
            "fmeasure": 0.71446
        },
        "rouge2": {
            "precision": 0.49812,
            "recall": 0.46353,
            "fmeasure": 0.47471
        },
        "rougeL": {
            "precision": 0.65091,
            "recall": 0.60868,
            "fmeasure": 0.62121
        },
        "rougeLsum": {
            "precision": 0.65091,
            "recall": 0.60868,
            "fmeasure": 0.62121
        },
        "nist": 6.31490635264253,
        "bleurt": 0.28483,
        "bertscore": {
            "precision": 0.9285,
            "recall": 0.91522,
            "f1": 0.92084
        },
        "nubia": {
            "semantic_relation": 4.28917,
            "contradiction": 7.66746,
            "irrelevancy": 27.10107,
            "logical_agreement": 65.23147,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.89262,
            "nubia_score": 0.72451
        },
        "meteor": 0.365969435454379
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.0195,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "nist": 2.9898332363522426,
        "bleurt": 0.83294,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "meteor": 0.5064321156600579
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.73154,
        "msttr-100_nopunct": 0.79364,
        "total_length": 1320,
        "mean_pred_length": 16.70886075949367,
        "std_pred_length": 6.673491672819737,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.49696969696969695,
        "vocab_size-1": 656,
        "unique-1": 525,
        "entropy-1": 8.09834773371102,
        "distinct-2": 0.8759065269943593,
        "vocab_size-2": 1087,
        "unique-2": 997,
        "entropy-2": 9.958627750641721,
        "cond_entropy-2": 1.602212059208069,
        "distinct-3": 0.9672977624784854,
        "vocab_size-3": 1124,
        "unique-3": 1094,
        "entropy-3": 10.111792718277709,
        "cond_entropy-3": 0.14878411548723952,
        "total_length-nopunct": 1151,
        "mean_pred_length-nopunct": 14.569620253164556,
        "std_pred_length-nopunct": 6.049758953883711,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5647263249348393,
        "vocab_size-1-nopunct": 650,
        "unique-1-nopunct": 525,
        "entropy-1-nopunct": 8.368251417692559,
        "distinct-2-nopunct": 0.8871268656716418,
        "vocab_size-2-nopunct": 951,
        "unique-2-nopunct": 880,
        "entropy-2-nopunct": 9.771856424601326,
        "cond_entropy-2-nopunct": 1.4978956824129788,
        "distinct-3-nopunct": 0.9677744209466264,
        "vocab_size-3-nopunct": 961,
        "unique-3-nopunct": 936,
        "entropy-3-nopunct": 9.885877286667172,
        "cond_entropy-3-nopunct": 0.1313868122195741,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.66654,
        "local_recall": {
            "1": 0.2733118971061093,
            "2": 0.4486301369863014,
            "3": 0.7325428194993412
        },
        "rouge1": {
            "precision": 0.6957,
            "recall": 0.68222,
            "fmeasure": 0.67344
        },
        "rouge2": {
            "precision": 0.46549,
            "recall": 0.46192,
            "fmeasure": 0.45201
        },
        "rougeL": {
            "precision": 0.60779,
            "recall": 0.59977,
            "fmeasure": 0.58938
        },
        "rougeLsum": {
            "precision": 0.60779,
            "recall": 0.59977,
            "fmeasure": 0.58938
        },
        "nist": 7.048902004483349,
        "bleurt": 0.15883,
        "bertscore": {
            "precision": 0.91981,
            "recall": 0.91285,
            "f1": 0.91443
        },
        "nubia": {
            "semantic_relation": 4.06568,
            "contradiction": 7.39071,
            "irrelevancy": 31.8393,
            "logical_agreement": 60.76999,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.79337,
            "nubia_score": 0.68079
        },
        "meteor": 0.3676640614368834
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.63327,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.5,
            "fmeasure": 0.48
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27273,
            "fmeasure": 0.26087
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "nist": 1.4339850002884627,
        "bleurt": -0.04467,
        "bertscore": {
            "precision": 0.80968,
            "recall": 0.81344,
            "f1": 0.81156
        },
        "nubia": {
            "semantic_relation": 3.76003,
            "contradiction": 0.20885,
            "irrelevancy": 98.95903,
            "logical_agreement": 0.83211,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.72532,
            "nubia_score": 0.63981
        },
        "meteor": 0.26621783112461456
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 5.312459150169743,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 5.003055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.10374148695780358,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.852168723603279,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.12479798526556812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.65463,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.69691,
            "recall": 0.74669,
            "fmeasure": 0.69897
        },
        "rouge2": {
            "precision": 0.50763,
            "recall": 0.51029,
            "fmeasure": 0.49417
        },
        "rougeL": {
            "precision": 0.56111,
            "recall": 0.64087,
            "fmeasure": 0.58055
        },
        "rougeLsum": {
            "precision": 0.56111,
            "recall": 0.64087,
            "fmeasure": 0.58055
        },
        "nist": 3.8280512821364048,
        "bleurt": 0.33907,
        "bertscore": {
            "precision": 0.92696,
            "recall": 0.9433,
            "f1": 0.93202
        },
        "nubia": {
            "semantic_relation": 4.12735,
            "contradiction": 1.77127,
            "irrelevancy": 43.04481,
            "logical_agreement": 55.18392,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.30052,
            "nubia_score": 0.7648
        },
        "meteor": 0.34028019535046644
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.003984245472128352,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.16349873228287956,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664497779200463,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.0034987322828795697,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.6998,
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.7727272727272727
        },
        "rouge1": {
            "precision": 0.79365,
            "recall": 0.71606,
            "fmeasure": 0.74405
        },
        "rouge2": {
            "precision": 0.43056,
            "recall": 0.37831,
            "fmeasure": 0.39884
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.54591,
            "fmeasure": 0.56811
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.54591,
            "fmeasure": 0.56811
        },
        "nist": 4.105580328942636,
        "bleurt": -0.00053,
        "bertscore": {
            "precision": 0.92794,
            "recall": 0.91658,
            "f1": 0.92208
        },
        "nubia": {
            "semantic_relation": 4.17749,
            "contradiction": 0.30939,
            "irrelevancy": 33.64825,
            "logical_agreement": 66.04236,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.3219,
            "nubia_score": 0.67197
        },
        "meteor": 0.3624613862227659
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.74014,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.94118,
            "fmeasure": 0.9697
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.94118,
            "fmeasure": 0.9697
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.94118,
            "fmeasure": 0.9697
        },
        "nist": 4.909258632132364,
        "bleurt": 0.71161,
        "bertscore": {
            "precision": 0.99236,
            "recall": 0.98935,
            "f1": 0.99085
        },
        "nubia": {
            "semantic_relation": 4.96627,
            "contradiction": 0.29937,
            "irrelevancy": 0.72756,
            "logical_agreement": 98.97308,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.80081,
            "nubia_score": 0.98896
        },
        "meteor": 0.6135131870855077
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 118,
        "mean_pred_length": 14.75,
        "std_pred_length": 6.319612329882269,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.7203389830508474,
        "vocab_size-1": 85,
        "unique-1": 67,
        "entropy-1": 6.161292070728243,
        "distinct-2": 0.9454545454545454,
        "vocab_size-2": 104,
        "unique-2": 98,
        "entropy-2": 6.672268804433759,
        "cond_entropy-2": 0.34525680487885213,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 100,
        "unique-3": 98,
        "entropy-3": 6.63320965569699,
        "cond_entropy-3": -0.03050299900414438,
        "total_length-nopunct": 104,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.522680508593631,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.224384189253338,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.45996250072116,
        "cond_entropy-2-nopunct": 0.2752496055418034,
        "distinct-3-nopunct": 0.9772727272727273,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.41397707318276,
        "cond_entropy-3-nopunct": -0.0346217911747682,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.02359,
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.839622641509434
        },
        "rouge1": {
            "precision": 0.90069,
            "recall": 0.82937,
            "fmeasure": 0.85361
        },
        "rouge2": {
            "precision": 0.78909,
            "recall": 0.73679,
            "fmeasure": 0.7532
        },
        "rougeL": {
            "precision": 0.86635,
            "recall": 0.80906,
            "fmeasure": 0.82815
        },
        "rougeLsum": {
            "precision": 0.86635,
            "recall": 0.80906,
            "fmeasure": 0.82815
        },
        "nist": 5.984149258324489,
        "bleurt": 0.5403,
        "bertscore": {
            "precision": 0.9683,
            "recall": 0.9482,
            "f1": 0.95741
        },
        "nubia": {
            "semantic_relation": 4.32516,
            "contradiction": 8.55266,
            "irrelevancy": 5.10781,
            "logical_agreement": 86.33953,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.12131,
            "nubia_score": 0.74629
        },
        "meteor": 0.4672889301682057
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 21.0,
        "std_pred_length": 12.165525060596439,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.7238095238095238,
        "vocab_size-1": 76,
        "unique-1": 65,
        "entropy-1": 5.952434271170492,
        "distinct-2": 0.96,
        "vocab_size-2": 96,
        "unique-2": 93,
        "entropy-2": 6.556307314753105,
        "cond_entropy-2": 0.5258672011630057,
        "distinct-3": 1.0,
        "vocab_size-3": 95,
        "unique-3": 95,
        "entropy-3": 6.569855608330948,
        "cond_entropy-3": 0.018156129105312353,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 8.966604708583958,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.934021854295745,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.271928094887357,
        "cond_entropy-2-nopunct": 0.36761680820674414,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.039776071058148135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.32711,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.125,
            "3": 0.8441558441558441
        },
        "rouge1": {
            "precision": 0.83348,
            "recall": 0.76446,
            "fmeasure": 0.79601
        },
        "rouge2": {
            "precision": 0.66041,
            "recall": 0.60248,
            "fmeasure": 0.6277
        },
        "rougeL": {
            "precision": 0.72513,
            "recall": 0.673,
            "fmeasure": 0.69517
        },
        "rougeLsum": {
            "precision": 0.72513,
            "recall": 0.673,
            "fmeasure": 0.69517
        },
        "nist": 5.601008816778977,
        "bleurt": 0.43663,
        "bertscore": {
            "precision": 0.93808,
            "recall": 0.93478,
            "f1": 0.93507
        },
        "nubia": {
            "semantic_relation": 4.41576,
            "contradiction": 0.62481,
            "irrelevancy": 16.86768,
            "logical_agreement": 82.50751,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.72228,
            "nubia_score": 0.83703
        },
        "meteor": 0.45891728967620876
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 14.4,
        "std_pred_length": 3.8781438859330635,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 52,
        "unique-1": 44,
        "entropy-1": 5.421670793373882,
        "distinct-2": 0.9701492537313433,
        "vocab_size-2": 65,
        "unique-2": 63,
        "entropy-2": 6.006387697920454,
        "cond_entropy-2": 0.46727855478397334,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 61,
        "unique-3": 60,
        "entropy-3": 5.921938245870743,
        "cond_entropy-3": -0.07963481555476803,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.521363372331802,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.402911466774758,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.8402239289418505,
        "cond_entropy-2-nopunct": 0.48893382435490446,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.744996077161019,
        "cond_entropy-3-nopunct": -0.08916724572022233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.06785,
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.8809523809523809
        },
        "rouge1": {
            "precision": 0.84646,
            "recall": 0.84384,
            "fmeasure": 0.83605
        },
        "rouge2": {
            "precision": 0.60596,
            "recall": 0.58866,
            "fmeasure": 0.59188
        },
        "rougeL": {
            "precision": 0.77503,
            "recall": 0.76735,
            "fmeasure": 0.76545
        },
        "rougeLsum": {
            "precision": 0.77503,
            "recall": 0.76735,
            "fmeasure": 0.76545
        },
        "nist": 5.374542125585636,
        "bleurt": 0.35932,
        "bertscore": {
            "precision": 0.94997,
            "recall": 0.95067,
            "f1": 0.95004
        },
        "nubia": {
            "semantic_relation": 4.31265,
            "contradiction": 16.37184,
            "irrelevancy": 19.08302,
            "logical_agreement": 64.54514,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.79758,
            "nubia_score": 0.76024
        },
        "meteor": 0.47985972190787013
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.76729,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.55988,
            "fmeasure": 0.62418
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.15657,
            "fmeasure": 0.17527
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.39664,
            "fmeasure": 0.44151
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.39664,
            "fmeasure": 0.44151
        },
        "nist": 2.0200795743014575,
        "bleurt": -0.14501,
        "bertscore": {
            "precision": 0.87583,
            "recall": 0.84107,
            "f1": 0.8581
        },
        "nubia": {
            "semantic_relation": 3.94349,
            "contradiction": 1.24176,
            "irrelevancy": 6.83558,
            "logical_agreement": 91.92266,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.85456,
            "nubia_score": 0.44387
        },
        "meteor": 0.2754929092672577
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.8205128205128205,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.887715680289761,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.1832696576401605,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.0806182000634031,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.17687776208407924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.06305,
        "local_recall": {
            "1": 0.1,
            "2": 0.4166666666666667,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.74026,
            "recall": 0.56778,
            "fmeasure": 0.63372
        },
        "rouge2": {
            "precision": 0.47037,
            "recall": 0.34614,
            "fmeasure": 0.3904
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.40283,
            "fmeasure": 0.44406
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.40283,
            "fmeasure": 0.44406
        },
        "nist": 4.245673194443666,
        "bleurt": 0.07365,
        "bertscore": {
            "precision": 0.88665,
            "recall": 0.88028,
            "f1": 0.88179
        },
        "nubia": {
            "semantic_relation": 3.82499,
            "contradiction": 10.55942,
            "irrelevancy": 26.70997,
            "logical_agreement": 62.73061,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.52141,
            "nubia_score": 0.63809
        },
        "meteor": 0.36092965947366107
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 5.557777333511022,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7872340425531915,
        "vocab_size-1": 37,
        "unique-1": 32,
        "entropy-1": 5.020133203193304,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.3676729482460296,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.952671080827672,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.4047765396002711,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.65232,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.25,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.59226,
            "recall": 0.71925,
            "fmeasure": 0.64793
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.46667,
            "fmeasure": 0.4169
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.67291,
            "fmeasure": 0.60719
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.67291,
            "fmeasure": 0.60719
        },
        "nist": 3.037675726547556,
        "bleurt": 0.33169,
        "bertscore": {
            "precision": 0.89012,
            "recall": 0.92254,
            "f1": 0.90594
        },
        "nubia": {
            "semantic_relation": 4.46895,
            "contradiction": 32.89664,
            "irrelevancy": 1.69212,
            "logical_agreement": 65.41124,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.32002,
            "nubia_score": 0.82919
        },
        "meteor": 0.3744423309707058
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.11336,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nist": 2.1055161915432032,
        "bleurt": 0.18287,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        },
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.785151577725659,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 5.003258334775643,
        "cond_entropy-2": 0.12771410208460493,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": 0.05628729973432273,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.760067015271104,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.862575937540274,
        "cond_entropy-2-nopunct": 0.1397687391938218,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": 0.06249647625006526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.81565,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.8064516129032258
        },
        "rouge1": {
            "precision": 0.82571,
            "recall": 0.80199,
            "fmeasure": 0.80931
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.69485,
            "fmeasure": 0.69297
        },
        "rougeL": {
            "precision": 0.748,
            "recall": 0.75491,
            "fmeasure": 0.74351
        },
        "rougeLsum": {
            "precision": 0.748,
            "recall": 0.75491,
            "fmeasure": 0.74351
        },
        "nist": 4.657079378221635,
        "bleurt": 0.46253,
        "bertscore": {
            "precision": 0.94896,
            "recall": 0.93668,
            "f1": 0.94255
        },
        "nubia": {
            "semantic_relation": 4.48768,
            "contradiction": 0.43627,
            "irrelevancy": 41.60011,
            "logical_agreement": 57.96362,
            "grammar_ref": 4.92539,
            "grammar_hyp": 5.16353,
            "nubia_score": 0.78932
        },
        "meteor": 0.4740594880981088
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.38958,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.64935,
            "fmeasure": 0.68364
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "nist": 3.8107815848368243,
        "bleurt": 0.61973,
        "bertscore": {
            "precision": 0.98905,
            "recall": 0.98905,
            "f1": 0.98905
        },
        "nubia": {
            "semantic_relation": 4.6448,
            "contradiction": 0.52652,
            "irrelevancy": 0.67281,
            "logical_agreement": 98.80067,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.73563,
            "nubia_score": 0.8067
        },
        "meteor": 0.9233576642335767
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.852168723603279,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.10003715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.04332146930622845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.23207,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.70128,
            "recall": 0.69623,
            "fmeasure": 0.69856
        },
        "rouge2": {
            "precision": 0.43421,
            "recall": 0.44103,
            "fmeasure": 0.43753
        },
        "rougeL": {
            "precision": 0.63462,
            "recall": 0.64339,
            "fmeasure": 0.63889
        },
        "rougeLsum": {
            "precision": 0.63462,
            "recall": 0.64339,
            "fmeasure": 0.63889
        },
        "nist": 3.5493447752864444,
        "bleurt": 0.49743,
        "bertscore": {
            "precision": 0.92526,
            "recall": 0.93204,
            "f1": 0.92862
        },
        "nubia": {
            "semantic_relation": 4.50698,
            "contradiction": 3.59489,
            "irrelevancy": 3.79009,
            "logical_agreement": 92.61503,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.40257,
            "nubia_score": 0.86572
        },
        "meteor": 0.3835711439557871
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.5495097567963922,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.879664004902594,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.30024085135823825,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 2.48746859276655,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.8647266763812915,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.2214524962193058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.18641312423088147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.41356,
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.1111111111111111,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.75917,
            "recall": 0.71507,
            "fmeasure": 0.73098
        },
        "rouge2": {
            "precision": 0.64038,
            "recall": 0.59924,
            "fmeasure": 0.61434
        },
        "rougeL": {
            "precision": 0.72142,
            "recall": 0.68451,
            "fmeasure": 0.69731
        },
        "rougeLsum": {
            "precision": 0.72142,
            "recall": 0.68451,
            "fmeasure": 0.69731
        },
        "nist": 4.1818465399202776,
        "bleurt": 0.18551,
        "bertscore": {
            "precision": 0.94479,
            "recall": 0.94761,
            "f1": 0.94609
        },
        "nubia": {
            "semantic_relation": 4.11027,
            "contradiction": 4.96115,
            "irrelevancy": 31.09479,
            "logical_agreement": 63.94406,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.14612,
            "nubia_score": 0.61162
        },
        "meteor": 0.3886110651610497
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.62159,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.51754,
            "fmeasure": 0.55055
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16374,
            "fmeasure": 0.17479
        },
        "rougeL": {
            "precision": 0.23529,
            "recall": 0.20702,
            "fmeasure": 0.22022
        },
        "rougeLsum": {
            "precision": 0.23529,
            "recall": 0.20702,
            "fmeasure": 0.22022
        },
        "nist": 1.7836687626488865,
        "bleurt": -0.22406,
        "bertscore": {
            "precision": 0.81244,
            "recall": 0.84039,
            "f1": 0.82508
        },
        "nubia": {
            "semantic_relation": 3.81959,
            "contradiction": 0.38712,
            "irrelevancy": 95.89808,
            "logical_agreement": 3.71481,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.45884,
            "nubia_score": 0.5842
        },
        "meteor": 0.2226582629821129
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.22239242133644807,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.055725754669781385,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.45096,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.9,
            "fmeasure": 0.87584
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.67315,
            "fmeasure": 0.69366
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.9,
            "fmeasure": 0.87584
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.9,
            "fmeasure": 0.87584
        },
        "nist": 3.7210567218885284,
        "bleurt": 0.55993,
        "bertscore": {
            "precision": 0.97785,
            "recall": 0.97455,
            "f1": 0.97587
        },
        "nubia": {
            "semantic_relation": 4.55236,
            "contradiction": 7.76585,
            "irrelevancy": 2.92343,
            "logical_agreement": 89.31072,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.5674,
            "nubia_score": 0.83831
        },
        "meteor": 0.4702632178166407
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.83437,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.80471,
            "fmeasure": 0.71212
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.45833,
            "fmeasure": 0.40303
        },
        "rougeL": {
            "precision": 0.5641,
            "recall": 0.70707,
            "fmeasure": 0.62626
        },
        "rougeLsum": {
            "precision": 0.5641,
            "recall": 0.70707,
            "fmeasure": 0.62626
        },
        "nist": 2.0604444995361937,
        "bleurt": -0.39488,
        "bertscore": {
            "precision": 0.8653,
            "recall": 0.9218,
            "f1": 0.89266
        },
        "nubia": {
            "semantic_relation": 4.16385,
            "contradiction": 4.82245,
            "irrelevancy": 87.9071,
            "logical_agreement": 7.27046,
            "grammar_ref": 6.0554,
            "grammar_hyp": 6.54443,
            "nubia_score": 0.48349
        },
        "meteor": 0.37351300806959326
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569684,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966062,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 90.8655,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "nist": 4.476798555485602,
        "bleurt": 0.71432,
        "bertscore": {
            "precision": 0.98484,
            "recall": 0.98886,
            "f1": 0.98685
        },
        "nubia": {
            "semantic_relation": 3.73924,
            "contradiction": 97.74814,
            "irrelevancy": 1.732,
            "logical_agreement": 0.51986,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.11348,
            "nubia_score": 0.53087
        },
        "meteor": 0.5772487688020834
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.7555555555555555,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.889199419023813,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 40,
        "unique-2": 38,
        "entropy-2": 5.297079327540667,
        "cond_entropy-2": 0.3377149925586158,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": -0.055633152634460586,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.859828661431136,
        "distinct-2-nopunct": 0.9487179487179487,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.182838116298145,
        "cond_entropy-2-nopunct": 0.3639701288168287,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": -0.059921661864380305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.96863,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.48
        },
        "rouge1": {
            "precision": 0.57013,
            "recall": 0.562,
            "fmeasure": 0.56531
        },
        "rouge2": {
            "precision": 0.29081,
            "recall": 0.29533,
            "fmeasure": 0.29293
        },
        "rougeL": {
            "precision": 0.47123,
            "recall": 0.46706,
            "fmeasure": 0.46853
        },
        "rougeLsum": {
            "precision": 0.47123,
            "recall": 0.46706,
            "fmeasure": 0.46853
        },
        "nist": 3.3755628129326065,
        "bleurt": 0.06908,
        "bertscore": {
            "precision": 0.90183,
            "recall": 0.90256,
            "f1": 0.90127
        },
        "nubia": {
            "semantic_relation": 3.66975,
            "contradiction": 30.9332,
            "irrelevancy": 19.26729,
            "logical_agreement": 49.79951,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.87611,
            "nubia_score": 0.68236
        },
        "meteor": 0.31506361818393047
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.17712,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.4902,
            "recall": 0.66132,
            "fmeasure": 0.55742
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.42222,
            "fmeasure": 0.34243
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.5615,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.5615,
            "fmeasure": 0.47059
        },
        "nist": 3.0103198016575936,
        "bleurt": -0.08548,
        "bertscore": {
            "precision": 0.87426,
            "recall": 0.92627,
            "f1": 0.89199
        },
        "nubia": {
            "semantic_relation": 3.83337,
            "contradiction": 0.107,
            "irrelevancy": 99.77519,
            "logical_agreement": 0.11781,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.05085,
            "nubia_score": 0.72403
        },
        "meteor": 0.39034719310137744
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.4142135623730951,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.8541666666666666,
        "vocab_size-1": 41,
        "unique-1": 36,
        "entropy-1": 5.261842188131015,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.14588809565659525,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.136248672727251,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.16885114229280787,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.11887,
        "local_recall": {
            "1": 0.5,
            "2": 0.5238095238095238,
            "3": 0.5909090909090909
        },
        "rouge1": {
            "precision": 0.63172,
            "recall": 0.51863,
            "fmeasure": 0.56264
        },
        "rouge2": {
            "precision": 0.35043,
            "recall": 0.26601,
            "fmeasure": 0.29963
        },
        "rougeL": {
            "precision": 0.46665,
            "recall": 0.38847,
            "fmeasure": 0.4197
        },
        "rougeLsum": {
            "precision": 0.46665,
            "recall": 0.38847,
            "fmeasure": 0.4197
        },
        "nist": 3.601075012553625,
        "bleurt": 0.11776,
        "bertscore": {
            "precision": 0.87691,
            "recall": 0.85904,
            "f1": 0.86781
        },
        "nubia": {
            "semantic_relation": 3.37819,
            "contradiction": 32.88648,
            "irrelevancy": 19.05578,
            "logical_agreement": 48.05775,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.84945,
            "nubia_score": 0.4865
        },
        "meteor": 0.26826982819846984
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.8541666666666666,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.235902344426086,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.17355726227518486,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.106603137064477,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.20077710377579597,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.38765,
        "local_recall": {
            "1": 0.25,
            "2": 0.4,
            "3": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.74921,
            "recall": 0.6826,
            "fmeasure": 0.70838
        },
        "rouge2": {
            "precision": 0.52405,
            "recall": 0.47408,
            "fmeasure": 0.49191
        },
        "rougeL": {
            "precision": 0.65132,
            "recall": 0.59438,
            "fmeasure": 0.61514
        },
        "rougeLsum": {
            "precision": 0.65132,
            "recall": 0.59438,
            "fmeasure": 0.61514
        },
        "nist": 4.24665475638704,
        "bleurt": 0.21373,
        "bertscore": {
            "precision": 0.92306,
            "recall": 0.91727,
            "f1": 0.91925
        },
        "nubia": {
            "semantic_relation": 4.27139,
            "contradiction": 0.17901,
            "irrelevancy": 11.8611,
            "logical_agreement": 87.9599,
            "grammar_ref": 5.35172,
            "grammar_hyp": 4.92823,
            "nubia_score": 0.76997
        },
        "meteor": 0.3807425594130609
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 7.5,
        "median_pred_length": 18.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.8647266763812915,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.22711215137782997,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.779094498080775,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.1922179169046629,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.75023,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.80781,
            "recall": 0.66436,
            "fmeasure": 0.7233
        },
        "rouge2": {
            "precision": 0.50556,
            "recall": 0.40721,
            "fmeasure": 0.44689
        },
        "rougeL": {
            "precision": 0.67943,
            "recall": 0.56053,
            "fmeasure": 0.60939
        },
        "rougeLsum": {
            "precision": 0.67943,
            "recall": 0.56053,
            "fmeasure": 0.60939
        },
        "nist": 3.969443786053185,
        "bleurt": -0.19232,
        "bertscore": {
            "precision": 0.91408,
            "recall": 0.86664,
            "f1": 0.8873
        },
        "nubia": {
            "semantic_relation": 3.67708,
            "contradiction": 14.55325,
            "irrelevancy": 10.55128,
            "logical_agreement": 74.89548,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.97296,
            "nubia_score": 0.50205
        },
        "meteor": 0.34122177970156325
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.37428,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.69048,
            "recall": 0.70696,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.64957,
            "fmeasure": 0.63179
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.67582,
            "fmeasure": 0.65873
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.67582,
            "fmeasure": 0.65873
        },
        "nist": 2.846571200721927,
        "bleurt": -0.21895,
        "bertscore": {
            "precision": 0.91046,
            "recall": 0.89717,
            "f1": 0.90377
        },
        "nubia": {
            "semantic_relation": 3.36614,
            "contradiction": 0.58414,
            "irrelevancy": 98.37326,
            "logical_agreement": 1.0426,
            "grammar_ref": 5.35534,
            "grammar_hyp": 4.28785,
            "nubia_score": 0.54875
        },
        "meteor": 0.41797142813686233
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.00572,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.63333,
            "fmeasure": 0.59091
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "nist": 4.27630381192071,
        "bleurt": 0.21352,
        "bertscore": {
            "precision": 0.928,
            "recall": 0.96387,
            "f1": 0.94559
        },
        "nubia": {
            "semantic_relation": 4.80973,
            "contradiction": 0.62133,
            "irrelevancy": 38.0045,
            "logical_agreement": 61.37417,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.76683,
            "nubia_score": 0.85605
        },
        "meteor": 0.5205559484776897
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 2.0,
        "median_pred_length": 19.0,
        "min_pred_length": 17,
        "max_pred_length": 21,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 29,
        "unique-1": 23,
        "entropy-1": 4.714646921167523,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.42934922429012695,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.635006998015213,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2944735621124794,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.96286,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.63725,
            "recall": 0.85745,
            "fmeasure": 0.73054
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.48582,
            "fmeasure": 0.40932
        },
        "rougeL": {
            "precision": 0.5098,
            "recall": 0.69444,
            "fmeasure": 0.58774
        },
        "rougeLsum": {
            "precision": 0.5098,
            "recall": 0.69444,
            "fmeasure": 0.58774
        },
        "nist": 3.3869514434759327,
        "bleurt": 0.15684,
        "bertscore": {
            "precision": 0.91317,
            "recall": 0.94909,
            "f1": 0.93078
        },
        "nubia": {
            "semantic_relation": 4.2144,
            "contradiction": 0.08198,
            "irrelevancy": 50.77937,
            "logical_agreement": 49.13865,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.09873,
            "nubia_score": 0.79353
        },
        "meteor": 0.4276106968804667
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.77284,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.75,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "nist": 2.7311026318526266,
        "bleurt": 0.65851,
        "bertscore": {
            "precision": 0.97906,
            "recall": 0.98524,
            "f1": 0.98214
        },
        "nubia": {
            "semantic_relation": 4.89889,
            "contradiction": 0.74374,
            "irrelevancy": 28.23508,
            "logical_agreement": 71.02118,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.27646,
            "nubia_score": 1.0
        },
        "meteor": 0.5459967999267895
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "total_length": 142,
        "mean_pred_length": 20.285714285714285,
        "std_pred_length": 6.963461489687966,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 33,
        "distinct-1": 0.6830985915492958,
        "vocab_size-1": 97,
        "unique-1": 82,
        "entropy-1": 6.15445919580853,
        "distinct-2": 0.9481481481481482,
        "vocab_size-2": 128,
        "unique-2": 122,
        "entropy-2": 6.967520134071865,
        "cond_entropy-2": 0.7191019087186467,
        "distinct-3": 0.96875,
        "vocab_size-3": 124,
        "unique-3": 120,
        "entropy-3": 6.9375,
        "cond_entropy-3": -0.024043038440178764,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 18.285714285714285,
        "std_pred_length-nopunct": 6.540298938434056,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7421875,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.20290690424963,
        "distinct-2-nopunct": 0.9421487603305785,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.796922018248457,
        "cond_entropy-2-nopunct": 0.6318634749099988,
        "distinct-3-nopunct": 0.9649122807017544,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.762714575568262,
        "cond_entropy-3-nopunct": -0.026719823968067945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.45397,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.4666666666666667,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.75376,
            "recall": 0.83626,
            "fmeasure": 0.77916
        },
        "rouge2": {
            "precision": 0.5235,
            "recall": 0.62523,
            "fmeasure": 0.5592
        },
        "rougeL": {
            "precision": 0.6244,
            "recall": 0.71676,
            "fmeasure": 0.65462
        },
        "rougeLsum": {
            "precision": 0.6244,
            "recall": 0.71676,
            "fmeasure": 0.65462
        },
        "nist": 4.802068350837252,
        "bleurt": 0.41875,
        "bertscore": {
            "precision": 0.91962,
            "recall": 0.93842,
            "f1": 0.92633
        },
        "nubia": {
            "semantic_relation": 4.39795,
            "contradiction": 0.33925,
            "irrelevancy": 25.90265,
            "logical_agreement": 73.7581,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.34364,
            "nubia_score": 0.78297
        },
        "meteor": 0.42668888210210404
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.82,
        "total_length": 211,
        "mean_pred_length": 19.181818181818183,
        "std_pred_length": 8.088355061649171,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.6587677725118484,
        "vocab_size-1": 139,
        "unique-1": 120,
        "entropy-1": 6.613845448978802,
        "distinct-2": 0.975,
        "vocab_size-2": 195,
        "unique-2": 190,
        "entropy-2": 7.593856189774741,
        "cond_entropy-2": 0.8506409574559508,
        "distinct-3": 1.0,
        "vocab_size-3": 189,
        "unique-3": 189,
        "entropy-3": 7.562242424221083,
        "cond_entropy-3": -0.03928572322560971,
        "total_length-nopunct": 182,
        "mean_pred_length-nopunct": 16.545454545454547,
        "std_pred_length-nopunct": 7.632033404296494,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7417582417582418,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.692643484545914,
        "distinct-2-nopunct": 0.9824561403508771,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 165,
        "entropy-2-nopunct": 7.382764795587644,
        "cond_entropy-2-nopunct": 0.7308620286568409,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 160,
        "unique-3-nopunct": 160,
        "entropy-3-nopunct": 7.321928094887368,
        "cond_entropy-3-nopunct": -0.058424419998535454,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.80571,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.48,
            "3": 0.7872340425531915
        },
        "rouge1": {
            "precision": 0.74374,
            "recall": 0.72555,
            "fmeasure": 0.72515
        },
        "rouge2": {
            "precision": 0.47056,
            "recall": 0.4384,
            "fmeasure": 0.44804
        },
        "rougeL": {
            "precision": 0.63135,
            "recall": 0.59884,
            "fmeasure": 0.60681
        },
        "rougeLsum": {
            "precision": 0.63135,
            "recall": 0.59884,
            "fmeasure": 0.60681
        },
        "nist": 5.353508864608758,
        "bleurt": 0.23716,
        "bertscore": {
            "precision": 0.91094,
            "recall": 0.92673,
            "f1": 0.91648
        },
        "nubia": {
            "semantic_relation": 4.36972,
            "contradiction": 1.51763,
            "irrelevancy": 47.63647,
            "logical_agreement": 50.8459,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.69247,
            "nubia_score": 0.79323
        },
        "meteor": 0.381206198764622
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.602988159880492,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 54,
        "unique-1": 48,
        "entropy-1": 5.5125908991149215,
        "distinct-2": 1.0,
        "vocab_size-2": 65,
        "unique-2": 65,
        "entropy-2": 6.022367813028458,
        "cond_entropy-2": 0.4233728251543431,
        "distinct-3": 1.0,
        "vocab_size-3": 61,
        "unique-3": 61,
        "entropy-3": 5.930737337562883,
        "cond_entropy-3": -0.09163047546556848,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 4.380353866983808,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8813559322033898,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.584174566744264,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.7813597135246555,
        "cond_entropy-2-nopunct": 0.21889194551621488,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.10893437155316402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.01174,
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.6,
            "3": 0.7636363636363637
        },
        "rouge1": {
            "precision": 0.86367,
            "recall": 0.73812,
            "fmeasure": 0.79329
        },
        "rouge2": {
            "precision": 0.51726,
            "recall": 0.44702,
            "fmeasure": 0.47758
        },
        "rougeL": {
            "precision": 0.74159,
            "recall": 0.62886,
            "fmeasure": 0.67819
        },
        "rougeLsum": {
            "precision": 0.74159,
            "recall": 0.62886,
            "fmeasure": 0.67819
        },
        "nist": 4.569341762043671,
        "bleurt": 0.20523,
        "bertscore": {
            "precision": 0.9303,
            "recall": 0.91829,
            "f1": 0.92389
        },
        "nubia": {
            "semantic_relation": 4.28448,
            "contradiction": 0.47603,
            "irrelevancy": 47.13826,
            "logical_agreement": 52.38571,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.83698,
            "nubia_score": 0.70752
        },
        "meteor": 0.379505718471325
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673073,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.60844,
        "local_recall": {
            "1": 0.0,
            "2": 0.8888888888888888
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "nist": 2.733880981892677,
        "bleurt": -0.0324,
        "bertscore": {
            "precision": 0.90565,
            "recall": 0.94307,
            "f1": 0.92398
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.39232,
            "irrelevancy": 0.99354,
            "logical_agreement": 97.61415,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.79546,
            "nubia_score": 0.75076
        },
        "meteor": 0.45231505213245843
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.11606,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "nist": 4.090634124990776,
        "bleurt": 0.48581,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.381780460041329,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.8307692307692308,
        "vocab_size-1": 54,
        "unique-1": 47,
        "entropy-1": 5.61675969031153,
        "distinct-2": 0.9833333333333333,
        "vocab_size-2": 59,
        "unique-2": 58,
        "entropy-2": 5.873557262275184,
        "cond_entropy-2": 0.09710424094945537,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.08916724572022233,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 11.4,
        "std_pred_length-nopunct": 3.49857113690718,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8771929824561403,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.574032338688185,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.11283600209487855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.10329767497409284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.41994,
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.868421052631579
        },
        "rouge1": {
            "precision": 0.75121,
            "recall": 0.81631,
            "fmeasure": 0.77838
        },
        "rouge2": {
            "precision": 0.58786,
            "recall": 0.6323,
            "fmeasure": 0.60567
        },
        "rougeL": {
            "precision": 0.7136,
            "recall": 0.7747,
            "fmeasure": 0.73901
        },
        "rougeLsum": {
            "precision": 0.7136,
            "recall": 0.7747,
            "fmeasure": 0.73901
        },
        "nist": 4.318236566166102,
        "bleurt": 0.51591,
        "bertscore": {
            "precision": 0.94432,
            "recall": 0.95031,
            "f1": 0.94605
        },
        "nubia": {
            "semantic_relation": 4.60986,
            "contradiction": 0.36333,
            "irrelevancy": 17.73533,
            "logical_agreement": 81.90134,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.7825,
            "nubia_score": 0.89572
        },
        "meteor": 0.44735624620101394
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.032143884086602556,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.03600643804015717,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.65175,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.66288,
            "recall": 0.66288,
            "fmeasure": 0.66233
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.38333,
            "fmeasure": 0.38333
        },
        "rougeL": {
            "precision": 0.60732,
            "recall": 0.57071,
            "fmeasure": 0.58667
        },
        "rougeLsum": {
            "precision": 0.60732,
            "recall": 0.57071,
            "fmeasure": 0.58667
        },
        "nist": 3.4859774761673674,
        "bleurt": 0.43099,
        "bertscore": {
            "precision": 0.88373,
            "recall": 0.91138,
            "f1": 0.89494
        },
        "nubia": {
            "semantic_relation": 4.44551,
            "contradiction": 0.38122,
            "irrelevancy": 51.75538,
            "logical_agreement": 47.86339,
            "grammar_ref": 5.62679,
            "grammar_hyp": 4.71486,
            "nubia_score": 0.93195
        },
        "meteor": 0.3218706419974628
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 1.5,
        "median_pred_length": 17.5,
        "min_pred_length": 16,
        "max_pred_length": 19,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.822000516883151,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.14495845092018841,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.760647923290102,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.11068123646483502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.37185,
        "local_recall": {
            "1": 0.5,
            "2": 0.8,
            "3": 0.6086956521739131
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.73386,
            "fmeasure": 0.71423
        },
        "rouge2": {
            "precision": 0.34048,
            "recall": 0.38419,
            "fmeasure": 0.35962
        },
        "rougeL": {
            "precision": 0.64583,
            "recall": 0.68796,
            "fmeasure": 0.66358
        },
        "rougeLsum": {
            "precision": 0.64583,
            "recall": 0.68796,
            "fmeasure": 0.66358
        },
        "nist": 3.388889606341961,
        "bleurt": 0.20616,
        "bertscore": {
            "precision": 0.93133,
            "recall": 0.93492,
            "f1": 0.93311
        },
        "nubia": {
            "semantic_relation": 4.12869,
            "contradiction": 1.18697,
            "irrelevancy": 65.59053,
            "logical_agreement": 33.2225,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.44067,
            "nubia_score": 0.68788
        },
        "meteor": 0.39615906921661004
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 4.0276819911981905,
        "median_pred_length": 23.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.7096774193548387,
        "vocab_size-1": 44,
        "unique-1": 35,
        "entropy-1": 5.234370657433798,
        "distinct-2": 0.9661016949152542,
        "vocab_size-2": 57,
        "unique-2": 55,
        "entropy-2": 5.814846439192345,
        "cond_entropy-2": 0.5364857725500036,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 55,
        "unique-3": 54,
        "entropy-3": 5.7716406363433235,
        "cond_entropy-3": -0.0395738415899515,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.201826932053253,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.623516641218018,
        "cond_entropy-2-nopunct": 0.45512429271118704,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.5738935175845965,
        "cond_entropy-3-nopunct": -0.044913547495271496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.25067,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.11764705882352941,
            "3": 0.6944444444444444
        },
        "rouge1": {
            "precision": 0.75432,
            "recall": 0.72439,
            "fmeasure": 0.73716
        },
        "rouge2": {
            "precision": 0.49444,
            "recall": 0.47142,
            "fmeasure": 0.48139
        },
        "rougeL": {
            "precision": 0.64716,
            "recall": 0.62274,
            "fmeasure": 0.63272
        },
        "rougeLsum": {
            "precision": 0.64716,
            "recall": 0.62274,
            "fmeasure": 0.63272
        },
        "nist": 4.045360760167638,
        "bleurt": -0.01917,
        "bertscore": {
            "precision": 0.88152,
            "recall": 0.86561,
            "f1": 0.87244
        },
        "nubia": {
            "semantic_relation": 4.16429,
            "contradiction": 32.35537,
            "irrelevancy": 22.54811,
            "logical_agreement": 45.09651,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.2842,
            "nubia_score": 0.68444
        },
        "meteor": 0.30493906509703217
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.752192476461084,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7523809523809524,
        "vocab_size-1": 79,
        "unique-1": 68,
        "entropy-1": 6.026010636651921,
        "distinct-2": 0.98989898989899,
        "vocab_size-2": 98,
        "unique-2": 97,
        "entropy-2": 6.609154599877599,
        "cond_entropy-2": 0.46819077415251265,
        "distinct-3": 1.0,
        "vocab_size-3": 93,
        "unique-3": 93,
        "entropy-3": 6.539158811108037,
        "cond_entropy-3": -0.06869243262749226,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 3.9440531887330774,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.035919835697165,
        "distinct-2-nopunct": 0.9886363636363636,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.436704345910032,
        "cond_entropy-2-nopunct": 0.4247846703933363,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.07748937011677476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.19316,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5454545454545454,
            "3": 0.855072463768116
        },
        "rouge1": {
            "precision": 0.77383,
            "recall": 0.77057,
            "fmeasure": 0.76577
        },
        "rouge2": {
            "precision": 0.60074,
            "recall": 0.62291,
            "fmeasure": 0.60737
        },
        "rougeL": {
            "precision": 0.73883,
            "recall": 0.75995,
            "fmeasure": 0.74214
        },
        "rougeLsum": {
            "precision": 0.73883,
            "recall": 0.75995,
            "fmeasure": 0.74214
        },
        "nist": 5.589436201008077,
        "bleurt": 0.35952,
        "bertscore": {
            "precision": 0.94448,
            "recall": 0.94053,
            "f1": 0.94075
        },
        "nubia": {
            "semantic_relation": 4.568,
            "contradiction": 4.30823,
            "irrelevancy": 40.77929,
            "logical_agreement": 54.91248,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.81697,
            "nubia_score": 0.81138
        },
        "meteor": 0.4729613244089396
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.6996621467371855,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7454545454545455,
        "vocab_size-1": 41,
        "unique-1": 31,
        "entropy-1": 5.2084547134459855,
        "distinct-2": 0.8627450980392157,
        "vocab_size-2": 44,
        "unique-2": 38,
        "entropy-2": 5.383113822321234,
        "cond_entropy-2": 0.06273008927357071,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.06843771187983272,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.77162,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "rouge1": {
            "precision": 0.975,
            "recall": 0.92643,
            "fmeasure": 0.94807
        },
        "rouge2": {
            "precision": 0.89425,
            "recall": 0.86591,
            "fmeasure": 0.87912
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "nist": 5.241055744777296,
        "bleurt": 0.7169,
        "bertscore": {
            "precision": 0.9814,
            "recall": 0.98087,
            "f1": 0.97983
        },
        "nubia": {
            "semantic_relation": 4.80834,
            "contradiction": 0.26911,
            "irrelevancy": 8.74777,
            "logical_agreement": 90.98312,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.0072,
            "nubia_score": 0.94106
        },
        "meteor": 0.5361682206451123
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "nist": 4.01117167855772,
        "bleurt": 0.77386,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 1.479019945774904,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.6981132075471698,
        "vocab_size-1": 37,
        "unique-1": 28,
        "entropy-1": 4.9898182757186,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 42,
        "unique-2": 36,
        "entropy-2": 5.313589691009831,
        "cond_entropy-2": 0.22075934825813748,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 42,
        "unique-3": 39,
        "entropy-3": 5.358519762996339,
        "cond_entropy-3": 0.07169630781809898,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 1.0897247358851685,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.723404255319149,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.892473628725219,
        "distinct-2-nopunct": 0.8372093023255814,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.083127836047133,
        "cond_entropy-2-nopunct": 0.2289905071314438,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.131556065016094,
        "cond_entropy-3-nopunct": 0.057980733446393096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.1291,
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.0,
            "3": 0.8055555555555556
        },
        "rouge1": {
            "precision": 0.62804,
            "recall": 0.61924,
            "fmeasure": 0.61908
        },
        "rouge2": {
            "precision": 0.45906,
            "recall": 0.4236,
            "fmeasure": 0.43968
        },
        "rougeL": {
            "precision": 0.56874,
            "recall": 0.55448,
            "fmeasure": 0.55829
        },
        "rougeLsum": {
            "precision": 0.56874,
            "recall": 0.55448,
            "fmeasure": 0.55829
        },
        "nist": 3.6458141818041048,
        "bleurt": 0.20499,
        "bertscore": {
            "precision": 0.90895,
            "recall": 0.92399,
            "f1": 0.91585
        },
        "nubia": {
            "semantic_relation": 4.26479,
            "contradiction": 0.35996,
            "irrelevancy": 49.56371,
            "logical_agreement": 50.07633,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.01523,
            "nubia_score": 0.75942
        },
        "meteor": 0.35129937338759426
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.13455,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.53788,
            "fmeasure": 0.52549
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.35238,
            "fmeasure": 0.34074
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.53788,
            "fmeasure": 0.52549
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.53788,
            "fmeasure": 0.52549
        },
        "nist": 1.3464372969835736,
        "bleurt": -0.3029,
        "bertscore": {
            "precision": 0.82823,
            "recall": 0.8577,
            "f1": 0.84271
        },
        "nubia": {
            "semantic_relation": 2.24353,
            "contradiction": 39.72678,
            "irrelevancy": 59.63567,
            "logical_agreement": 0.63755,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.85853,
            "nubia_score": 0.1397
        },
        "meteor": 0.3064431015469261
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.7297297297297297,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 4.648510460165075,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 28,
        "unique-2": 22,
        "entropy-2": 4.73452166477975,
        "cond_entropy-2": -0.004343465555080844,
        "distinct-3": 0.8387096774193549,
        "vocab_size-3": 26,
        "unique-3": 21,
        "entropy-3": 4.631615665225586,
        "cond_entropy-3": -0.06875040183120606,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.5625,
        "distinct-2-nopunct": 0.7931034482758621,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.444187891679296,
        "cond_entropy-2-nopunct": -0.07305348763104855,
        "distinct-3-nopunct": 0.8076923076923077,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.315824333525707,
        "cond_entropy-3-nopunct": -0.08061820006340306,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.76041,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.96296,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "nist": 4.812992206716754,
        "bleurt": 0.86452,
        "bertscore": {
            "precision": 0.99188,
            "recall": 0.99744,
            "f1": 0.99464
        },
        "nubia": {
            "semantic_relation": 4.85827,
            "contradiction": 0.46429,
            "irrelevancy": 24.59219,
            "logical_agreement": 74.94353,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.63976,
            "nubia_score": 0.94042
        },
        "meteor": 0.6597926430809401
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.75,
        "total_length": 239,
        "mean_pred_length": 15.933333333333334,
        "std_pred_length": 5.039400317057135,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6401673640167364,
        "vocab_size-1": 153,
        "unique-1": 125,
        "entropy-1": 6.702023948062484,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 216,
        "unique-2": 210,
        "entropy-2": 7.729186283645397,
        "cond_entropy-2": 0.845819853282284,
        "distinct-3": 1.0,
        "vocab_size-3": 209,
        "unique-3": 209,
        "entropy-3": 7.707359132080901,
        "cond_entropy-3": -0.016216962204822195,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.880801391392834,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6930232558139535,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.760702411859654,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 192,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.556307314753107,
        "cond_entropy-2-nopunct": 0.8496666857231578,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 185,
        "unique-3-nopunct": 185,
        "entropy-3-nopunct": 7.5313814605163,
        "cond_entropy-3-nopunct": -0.023232702207996607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.71075,
        "local_recall": {
            "1": 0.3617021276595745,
            "2": 0.4074074074074074,
            "3": 0.8516129032258064
        },
        "rouge1": {
            "precision": 0.78082,
            "recall": 0.81129,
            "fmeasure": 0.79098
        },
        "rouge2": {
            "precision": 0.60692,
            "recall": 0.62784,
            "fmeasure": 0.61105
        },
        "rougeL": {
            "precision": 0.6853,
            "recall": 0.71916,
            "fmeasure": 0.69782
        },
        "rougeLsum": {
            "precision": 0.6853,
            "recall": 0.71916,
            "fmeasure": 0.69782
        },
        "nist": 6.566033167461666,
        "bleurt": 0.37934,
        "bertscore": {
            "precision": 0.94956,
            "recall": 0.96035,
            "f1": 0.95364
        },
        "nubia": {
            "semantic_relation": 4.51749,
            "contradiction": 13.52985,
            "irrelevancy": 31.72983,
            "logical_agreement": 54.74032,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.51524,
            "nubia_score": 0.84065
        },
        "meteor": 0.46888727041744066
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 27.5,
        "std_pred_length": 2.5,
        "median_pred_length": 27.5,
        "min_pred_length": 25,
        "max_pred_length": 30,
        "distinct-1": 0.8,
        "vocab_size-1": 44,
        "unique-1": 39,
        "entropy-1": 5.265641023041015,
        "distinct-2": 0.9622641509433962,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.638205596031809,
        "cond_entropy-2": 0.3542898065939508,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": 0.03773797568601138,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 23.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.851063829787234,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.1638542138776335,
        "distinct-2-nopunct": 0.9555555555555556,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.38618892961493,
        "cond_entropy-2-nopunct": 0.2397006996395223,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": 0.04499043749250406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.54247,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.8214285714285714
        },
        "rouge1": {
            "precision": 0.69768,
            "recall": 0.79859,
            "fmeasure": 0.7432
        },
        "rouge2": {
            "precision": 0.50126,
            "recall": 0.57058,
            "fmeasure": 0.53253
        },
        "rougeL": {
            "precision": 0.50029,
            "recall": 0.58045,
            "fmeasure": 0.53631
        },
        "rougeLsum": {
            "precision": 0.50029,
            "recall": 0.58045,
            "fmeasure": 0.53631
        },
        "nist": 3.99265883199761,
        "bleurt": 0.31628,
        "bertscore": {
            "precision": 0.92138,
            "recall": 0.93982,
            "f1": 0.9305
        },
        "nubia": {
            "semantic_relation": 4.5232,
            "contradiction": 0.35283,
            "irrelevancy": 26.25501,
            "logical_agreement": 73.39216,
            "grammar_ref": 4.42501,
            "grammar_hyp": 3.85041,
            "nubia_score": 0.80309
        },
        "meteor": 0.42011260730500777
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.74,
        "vocab_size-1": 37,
        "unique-1": 31,
        "entropy-1": 4.991272380112912,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.5038029380928534,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.09515723304034036,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7954545454545454,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.933990357756302,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.4620085683896585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.52843,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.7241379310344828
        },
        "rouge1": {
            "precision": 0.55446,
            "recall": 0.71109,
            "fmeasure": 0.6196
        },
        "rouge2": {
            "precision": 0.28597,
            "recall": 0.38929,
            "fmeasure": 0.32742
        },
        "rougeL": {
            "precision": 0.47076,
            "recall": 0.60177,
            "fmeasure": 0.52532
        },
        "rougeLsum": {
            "precision": 0.47076,
            "recall": 0.60177,
            "fmeasure": 0.52532
        },
        "nist": 3.039424159193115,
        "bleurt": -0.11787,
        "bertscore": {
            "precision": 0.87526,
            "recall": 0.91494,
            "f1": 0.89408
        },
        "nubia": {
            "semantic_relation": 3.25821,
            "contradiction": 35.15483,
            "irrelevancy": 49.06915,
            "logical_agreement": 15.77601,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.84162,
            "nubia_score": 0.47843
        },
        "meteor": 0.31896591053933226
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.7037037037037037,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.162294909570877,
        "distinct-2": 0.84,
        "vocab_size-2": 21,
        "unique-2": 17,
        "entropy-2": 4.323856189774722,
        "cond_entropy-2": 0.12896868761125604,
        "distinct-3": 0.8695652173913043,
        "vocab_size-3": 20,
        "unique-3": 17,
        "entropy-3": 4.2626923908396215,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.083856189774723,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.1757358691004915,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.106603137064473,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.81531,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.95303,
            "fmeasure": 0.9119
        },
        "rouge2": {
            "precision": 0.74868,
            "recall": 0.79327,
            "fmeasure": 0.76542
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.91136,
            "fmeasure": 0.87487
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.91136,
            "fmeasure": 0.87487
        },
        "nist": 4.573610318507378,
        "bleurt": 0.69336,
        "bertscore": {
            "precision": 0.95789,
            "recall": 0.95754,
            "f1": 0.95764
        },
        "nubia": {
            "semantic_relation": 4.76798,
            "contradiction": 0.14332,
            "irrelevancy": 0.80158,
            "logical_agreement": 99.05511,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.26444,
            "nubia_score": 0.90459
        },
        "meteor": 0.5085891935215902
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 2.277608394786075,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.723404255319149,
        "vocab_size-1": 34,
        "unique-1": 25,
        "entropy-1": 4.926721298394087,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 42,
        "unique-2": 41,
        "entropy-2": 5.379753126795121,
        "cond_entropy-2": 0.3253916007995055,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.08958048455779839,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.88017992267574,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.19529593449622,
        "cond_entropy-2-nopunct": 0.3427094328839551,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.10164114278148138,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.91087,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3888888888888889,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.76042,
            "recall": 0.73351,
            "fmeasure": 0.71831
        },
        "rouge2": {
            "precision": 0.49459,
            "recall": 0.49225,
            "fmeasure": 0.47449
        },
        "rougeL": {
            "precision": 0.65625,
            "recall": 0.64844,
            "fmeasure": 0.63102
        },
        "rougeLsum": {
            "precision": 0.65625,
            "recall": 0.64844,
            "fmeasure": 0.63102
        },
        "nist": 4.147051701633438,
        "bleurt": 0.25947,
        "bertscore": {
            "precision": 0.91816,
            "recall": 0.90642,
            "f1": 0.91056
        },
        "nubia": {
            "semantic_relation": 4.05787,
            "contradiction": 18.44864,
            "irrelevancy": 28.65889,
            "logical_agreement": 52.89247,
            "grammar_ref": 4.6519,
            "grammar_hyp": 5.10455,
            "nubia_score": 0.6211
        },
        "meteor": 0.37388934482585356
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.0,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.49468036840891,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.15288816155131352,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.17339652724591728,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.71617,
        "local_recall": {
            "1": 0.375,
            "2": 1.0,
            "3": 0.72
        },
        "rouge1": {
            "precision": 0.90809,
            "recall": 0.78243,
            "fmeasure": 0.81452
        },
        "rouge2": {
            "precision": 0.74107,
            "recall": 0.68298,
            "fmeasure": 0.68534
        },
        "rougeL": {
            "precision": 0.87868,
            "recall": 0.76478,
            "fmeasure": 0.79246
        },
        "rougeLsum": {
            "precision": 0.87868,
            "recall": 0.76478,
            "fmeasure": 0.79246
        },
        "nist": 3.573858345363292,
        "bleurt": 0.42753,
        "bertscore": {
            "precision": 0.98264,
            "recall": 0.9424,
            "f1": 0.96165
        },
        "nubia": {
            "semantic_relation": 4.26061,
            "contradiction": 0.16971,
            "irrelevancy": 33.43321,
            "logical_agreement": 66.39708,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.71533,
            "nubia_score": 0.81024
        },
        "meteor": 0.38214462173101543
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7381,
            "fmeasure": 0.72222
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "nist": 3.0878882661357028,
        "bleurt": 0.74402,
        "bertscore": {
            "precision": 0.99641,
            "recall": 0.99641,
            "f1": 0.99641
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.51679,
            "irrelevancy": 0.90907,
            "logical_agreement": 96.57414,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.43289,
            "nubia_score": 0.86087
        },
        "meteor": 0.96
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 24.75,
        "std_pred_length": 7.495832175282475,
        "median_pred_length": 23.0,
        "min_pred_length": 17,
        "max_pred_length": 36,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 75,
        "unique-1": 66,
        "entropy-1": 5.96790264578301,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.524540498307802,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.0400829461542297,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 6.324555320336759,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.9824524316937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.39231742277876,
        "cond_entropy-2-nopunct": 0.4325782857014281,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.07038932789139805,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.22414,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.6,
            "3": 0.8656716417910447
        },
        "rouge1": {
            "precision": 0.84219,
            "recall": 0.81987,
            "fmeasure": 0.82209
        },
        "rouge2": {
            "precision": 0.59134,
            "recall": 0.56546,
            "fmeasure": 0.57117
        },
        "rougeL": {
            "precision": 0.7687,
            "recall": 0.74117,
            "fmeasure": 0.74669
        },
        "rougeLsum": {
            "precision": 0.7687,
            "recall": 0.74117,
            "fmeasure": 0.74669
        },
        "nist": 5.611985976898727,
        "bleurt": 0.30164,
        "bertscore": {
            "precision": 0.95355,
            "recall": 0.93799,
            "f1": 0.94483
        },
        "nubia": {
            "semantic_relation": 4.25984,
            "contradiction": 0.24218,
            "irrelevancy": 72.49223,
            "logical_agreement": 27.26559,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.24269,
            "nubia_score": 0.74977
        },
        "meteor": 0.4387646663599847
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.8,
        "total_length": 141,
        "mean_pred_length": 23.5,
        "std_pred_length": 7.297259759663212,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 37,
        "distinct-1": 0.7092198581560284,
        "vocab_size-1": 100,
        "unique-1": 82,
        "entropy-1": 6.323399533819891,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 132,
        "unique-2": 129,
        "entropy-2": 7.0323711526064105,
        "cond_entropy-2": 0.630357810691273,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": -0.01907671372059987,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 21.166666666666668,
        "std_pred_length-nopunct": 6.841458583924597,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7716535433070866,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.3936639669666695,
        "distinct-2-nopunct": 0.9752066115702479,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.869276460415098,
        "cond_entropy-2-nopunct": 0.4968531902982703,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.84549005094439,
        "cond_entropy-3-nopunct": -0.029894925460653917,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.19073,
        "local_recall": {
            "1": 0.22641509433962265,
            "2": 0.6756756756756757,
            "3": 0.6904761904761905
        },
        "rouge1": {
            "precision": 0.5681,
            "recall": 0.63936,
            "fmeasure": 0.5914
        },
        "rouge2": {
            "precision": 0.33576,
            "recall": 0.36741,
            "fmeasure": 0.34379
        },
        "rougeL": {
            "precision": 0.41467,
            "recall": 0.50552,
            "fmeasure": 0.44906
        },
        "rougeLsum": {
            "precision": 0.41467,
            "recall": 0.50552,
            "fmeasure": 0.44906
        },
        "nist": 3.9894694340408674,
        "bleurt": -0.01848,
        "bertscore": {
            "precision": 0.89259,
            "recall": 0.91672,
            "f1": 0.90259
        },
        "nubia": {
            "semantic_relation": 3.95941,
            "contradiction": 2.93284,
            "irrelevancy": 60.37806,
            "logical_agreement": 36.68909,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.33435,
            "nubia_score": 0.69564
        },
        "meteor": 0.34096455252339003
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.47302,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56614,
            "fmeasure": 0.56899
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "nist": 4.474416099899872,
        "bleurt": 0.33863,
        "bertscore": {
            "precision": 0.96933,
            "recall": 0.95282,
            "f1": 0.95899
        },
        "nubia": {
            "semantic_relation": 4.58246,
            "contradiction": 0.86231,
            "irrelevancy": 56.25508,
            "logical_agreement": 42.88262,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.26027,
            "nubia_score": 0.74168
        },
        "meteor": 0.4748101853768951
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.21676,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.62857,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.37546,
            "fmeasure": 0.41111
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.55873,
            "fmeasure": 0.60779
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.55873,
            "fmeasure": 0.60779
        },
        "nist": 2.56550038441974,
        "bleurt": 0.22381,
        "bertscore": {
            "precision": 0.94424,
            "recall": 0.92087,
            "f1": 0.93241
        },
        "nubia": {
            "semantic_relation": 4.20661,
            "contradiction": 1.82878,
            "irrelevancy": 2.3021,
            "logical_agreement": 95.86911,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.47173,
            "nubia_score": 0.56615
        },
        "meteor": 0.3456819922529988
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.96656,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.65909,
            "fmeasure": 0.6142
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.40741,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.37121,
            "fmeasure": 0.34877
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.37121,
            "fmeasure": 0.34877
        },
        "nist": 2.6619630614723326,
        "bleurt": -0.08584,
        "bertscore": {
            "precision": 0.90105,
            "recall": 0.93341,
            "f1": 0.90822
        },
        "nubia": {
            "semantic_relation": 3.94593,
            "contradiction": 0.32722,
            "irrelevancy": 47.35908,
            "logical_agreement": 52.3137,
            "grammar_ref": 5.84412,
            "grammar_hyp": 5.10263,
            "nubia_score": 0.63986
        },
        "meteor": 0.34119261573023246
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 4.548351349665063,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 26,
        "distinct-1": 0.6986301369863014,
        "vocab_size-1": 51,
        "unique-1": 39,
        "entropy-1": 5.4401114636307,
        "distinct-2": 0.9420289855072463,
        "vocab_size-2": 65,
        "unique-2": 61,
        "entropy-2": 5.992582427792657,
        "cond_entropy-2": 0.4799905638865659,
        "distinct-3": 0.9846153846153847,
        "vocab_size-3": 64,
        "unique-3": 63,
        "entropy-3": 5.991598582259227,
        "cond_entropy-3": 0.006151048557977767,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.278719262151,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7424242424242424,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.40842187010032,
        "distinct-2-nopunct": 0.9354838709677419,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.825164052322356,
        "cond_entropy-2-nopunct": 0.45777264991611655,
        "distinct-3-nopunct": 0.9827586206896551,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.823498236506881,
        "cond_entropy-3-nopunct": 0.0072329606027659935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.01342,
        "local_recall": {
            "1": 0.4375,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.67634,
            "recall": 0.79199,
            "fmeasure": 0.71613
        },
        "rouge2": {
            "precision": 0.44158,
            "recall": 0.50251,
            "fmeasure": 0.46521
        },
        "rougeL": {
            "precision": 0.51637,
            "recall": 0.63375,
            "fmeasure": 0.55789
        },
        "rougeLsum": {
            "precision": 0.51637,
            "recall": 0.63375,
            "fmeasure": 0.55789
        },
        "nist": 4.43335101182293,
        "bleurt": 0.47901,
        "bertscore": {
            "precision": 0.89819,
            "recall": 0.90691,
            "f1": 0.90209
        },
        "nubia": {
            "semantic_relation": 4.6103,
            "contradiction": 2.79546,
            "irrelevancy": 25.2668,
            "logical_agreement": 71.93775,
            "grammar_ref": 4.54108,
            "grammar_hyp": 3.96052,
            "nubia_score": 0.86407
        },
        "meteor": 0.41546872248729144
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 13.857142857142858,
        "std_pred_length": 4.15515416349971,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6288659793814433,
        "vocab_size-1": 61,
        "unique-1": 44,
        "entropy-1": 5.5436229477378856,
        "distinct-2": 0.9111111111111111,
        "vocab_size-2": 82,
        "unique-2": 74,
        "entropy-2": 6.314075318551888,
        "cond_entropy-2": 0.6342584242222552,
        "distinct-3": 0.9759036144578314,
        "vocab_size-3": 81,
        "unique-3": 79,
        "entropy-3": 6.326846660262594,
        "cond_entropy-3": 0.02776464827026221,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 3.958973274443148,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.514108607260521,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.121928094887357,
        "cond_entropy-2-nopunct": 0.6640925403783062,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.135030038332083,
        "cond_entropy-3-nopunct": 0.018581395499504293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.52817,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.625,
            "3": 0.6086956521739131
        },
        "rouge1": {
            "precision": 0.52317,
            "recall": 0.58167,
            "fmeasure": 0.52965
        },
        "rouge2": {
            "precision": 0.21699,
            "recall": 0.24014,
            "fmeasure": 0.21217
        },
        "rougeL": {
            "precision": 0.46091,
            "recall": 0.5151,
            "fmeasure": 0.46563
        },
        "rougeLsum": {
            "precision": 0.46091,
            "recall": 0.5151,
            "fmeasure": 0.46563
        },
        "nist": 3.498844519838698,
        "bleurt": 0.15797,
        "bertscore": {
            "precision": 0.89472,
            "recall": 0.89863,
            "f1": 0.8965
        },
        "nubia": {
            "semantic_relation": 3.82231,
            "contradiction": 15.23111,
            "irrelevancy": 38.84749,
            "logical_agreement": 45.92139,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.59047,
            "nubia_score": 0.63591
        },
        "meteor": 0.29350887378519047
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 3.0912061651652345,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 35,
        "unique-1": 31,
        "entropy-1": 5.053055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.04968743290374958,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.014997302659249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": -0.004283016944966456,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.90825,
        "local_recall": {
            "1": 0.125,
            "2": 0.3333333333333333,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.73497,
            "recall": 0.6142,
            "fmeasure": 0.65562
        },
        "rouge2": {
            "precision": 0.50132,
            "recall": 0.45162,
            "fmeasure": 0.46807
        },
        "rougeL": {
            "precision": 0.65406,
            "recall": 0.51861,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.65406,
            "recall": 0.51861,
            "fmeasure": 0.5641
        },
        "nist": 3.5632002196773382,
        "bleurt": 0.29521,
        "bertscore": {
            "precision": 0.93071,
            "recall": 0.90889,
            "f1": 0.91082
        },
        "nubia": {
            "semantic_relation": 4.19874,
            "contradiction": 0.21808,
            "irrelevancy": 33.54976,
            "logical_agreement": 66.23215,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.48031,
            "nubia_score": 0.79272
        },
        "meteor": 0.365168764014561
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69,
        "total_length": 126,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.5456210417116734,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.6190476190476191,
        "vocab_size-1": 78,
        "unique-1": 62,
        "entropy-1": 5.845175138467428,
        "distinct-2": 0.957983193277311,
        "vocab_size-2": 114,
        "unique-2": 109,
        "entropy-2": 6.810784149862564,
        "cond_entropy-2": 0.8670648856877824,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 110,
        "unique-3": 108,
        "entropy-3": 6.771640636343306,
        "cond_entropy-3": -0.05174855553605363,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 15.857142857142858,
        "std_pred_length-nopunct": 3.562846832382836,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6846846846846847,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.902580564911458,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.623516641218022,
        "cond_entropy-2-nopunct": 0.7425019139033986,
        "distinct-3-nopunct": 0.979381443298969,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.55867572878508,
        "cond_entropy-3-nopunct": -0.06959904090241806,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.74631,
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.7142857142857143,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73123,
            "recall": 0.68093,
            "fmeasure": 0.68373
        },
        "rouge2": {
            "precision": 0.44068,
            "recall": 0.38861,
            "fmeasure": 0.39987
        },
        "rougeL": {
            "precision": 0.60739,
            "recall": 0.59447,
            "fmeasure": 0.58643
        },
        "rougeLsum": {
            "precision": 0.60739,
            "recall": 0.59447,
            "fmeasure": 0.58643
        },
        "nist": 4.998887261514954,
        "bleurt": 0.10579,
        "bertscore": {
            "precision": 0.91241,
            "recall": 0.90235,
            "f1": 0.90597
        },
        "nubia": {
            "semantic_relation": 4.22744,
            "contradiction": 14.52278,
            "irrelevancy": 40.81617,
            "logical_agreement": 44.66106,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.44464,
            "nubia_score": 0.74784
        },
        "meteor": 0.3398100364492322
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.040223928941851936,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.029992126993435266,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 91.23321,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9629629629629629
        },
        "rouge1": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.90625,
            "fmeasure": 0.91935
        },
        "rougeL": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rougeLsum": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "nist": 4.961719276477761,
        "bleurt": 0.84934,
        "bertscore": {
            "precision": 0.99648,
            "recall": 0.99439,
            "f1": 0.99543
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30569,
            "irrelevancy": 0.54296,
            "logical_agreement": 99.15136,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.85235,
            "nubia_score": 1.0
        },
        "meteor": 0.6177006141496403
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.0,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.681880802803404,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 34,
        "unique-2": 32,
        "entropy-2": 5.058813890331199,
        "cond_entropy-2": 0.3528245714522529,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838573,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.513645929358369,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.875,
        "cond_entropy-2-nopunct": 0.3972176276348775,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.840223928941852,
        "cond_entropy-3-nopunct": -0.026442737724814785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 79.73583,
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.82468,
            "recall": 0.82828,
            "fmeasure": 0.82575
        },
        "rouge2": {
            "precision": 0.68333,
            "recall": 0.69187,
            "fmeasure": 0.68694
        },
        "rougeL": {
            "precision": 0.82468,
            "recall": 0.82828,
            "fmeasure": 0.82575
        },
        "rougeLsum": {
            "precision": 0.82468,
            "recall": 0.82828,
            "fmeasure": 0.82575
        },
        "nist": 5.032935069399443,
        "bleurt": 0.72393,
        "bertscore": {
            "precision": 0.98069,
            "recall": 0.97459,
            "f1": 0.9776
        },
        "nubia": {
            "semantic_relation": 4.69196,
            "contradiction": 0.40884,
            "irrelevancy": 0.91852,
            "logical_agreement": 98.67264,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.80991,
            "nubia_score": 0.88848
        },
        "meteor": 0.5352233950446788
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 193,
        "mean_pred_length": 19.3,
        "std_pred_length": 4.9,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.5854922279792746,
        "vocab_size-1": 113,
        "unique-1": 85,
        "entropy-1": 6.280603169934289,
        "distinct-2": 0.8469945355191257,
        "vocab_size-2": 155,
        "unique-2": 129,
        "entropy-2": 7.198759947573654,
        "cond_entropy-2": 0.8083166559151231,
        "distinct-3": 0.8670520231213873,
        "vocab_size-3": 150,
        "unique-3": 127,
        "entropy-3": 7.168732273879498,
        "cond_entropy-3": -0.023268142439225106,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 17.4,
        "std_pred_length-nopunct": 5.023942674832188,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6379310344827587,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.342718263471903,
        "distinct-2-nopunct": 0.8475609756097561,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 7.040478833886397,
        "cond_entropy-2-nopunct": 0.7209470337006283,
        "distinct-3-nopunct": 0.8636363636363636,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.994059267967643,
        "cond_entropy-3-nopunct": -0.03881741197513066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.9012,
        "local_recall": {
            "1": 0.2,
            "2": 0.4166666666666667,
            "3": 0.8717948717948718
        },
        "rouge1": {
            "precision": 0.83757,
            "recall": 0.81072,
            "fmeasure": 0.81797
        },
        "rouge2": {
            "precision": 0.63228,
            "recall": 0.61854,
            "fmeasure": 0.62133
        },
        "rougeL": {
            "precision": 0.70639,
            "recall": 0.67811,
            "fmeasure": 0.68802
        },
        "rougeLsum": {
            "precision": 0.70639,
            "recall": 0.67811,
            "fmeasure": 0.68802
        },
        "nist": 5.824840060534129,
        "bleurt": 0.42307,
        "bertscore": {
            "precision": 0.94123,
            "recall": 0.94694,
            "f1": 0.9435
        },
        "nubia": {
            "semantic_relation": 4.42058,
            "contradiction": 18.87955,
            "irrelevancy": 14.59725,
            "logical_agreement": 66.52321,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.50365,
            "nubia_score": 0.77548
        },
        "meteor": 0.4479384904937009
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.7878787878787878,
        "vocab_size-1": 26,
        "unique-1": 21,
        "entropy-1": 4.574400937409154,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.22099272632218087,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.15200309344505,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 4.320493798938574,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.548394345536403,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.20928903626470807,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.52665,
        "local_recall": {
            "1": 0.1875,
            "2": 0.7692307692307693,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.84821,
            "recall": 0.84781,
            "fmeasure": 0.84779
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.72073,
            "fmeasure": 0.7213
        },
        "rougeL": {
            "precision": 0.84821,
            "recall": 0.84781,
            "fmeasure": 0.84779
        },
        "rougeLsum": {
            "precision": 0.84821,
            "recall": 0.84781,
            "fmeasure": 0.84779
        },
        "nist": 4.648483940538105,
        "bleurt": 0.68331,
        "bertscore": {
            "precision": 0.98515,
            "recall": 0.97914,
            "f1": 0.98149
        },
        "nubia": {
            "semantic_relation": 4.74658,
            "contradiction": 0.41754,
            "irrelevancy": 0.50071,
            "logical_agreement": 99.08175,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.369,
            "nubia_score": 0.91641
        },
        "meteor": 0.5605260635358952
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.137317546507322,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6777777777777778,
        "vocab_size-1": 61,
        "unique-1": 47,
        "entropy-1": 5.653142613492289,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 76,
        "unique-2": 68,
        "entropy-2": 6.20184123230257,
        "cond_entropy-2": 0.4239663318185752,
        "distinct-3": 0.9487179487179487,
        "vocab_size-3": 74,
        "unique-3": 70,
        "entropy-3": 6.182838116298154,
        "cond_entropy-3": -0.029992126993434936,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 4.844813951249544,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7402597402597403,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.638675787752042,
        "distinct-2-nopunct": 0.9154929577464789,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.980733034997634,
        "cond_entropy-2-nopunct": 0.35288350805767166,
        "distinct-3-nopunct": 0.9538461538461539,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.930060120720765,
        "cond_entropy-3-nopunct": -0.06584084493776618,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.46875,
        "local_recall": {
            "1": 0.25,
            "2": 0.3,
            "3": 0.7580645161290323
        },
        "rouge1": {
            "precision": 0.79133,
            "recall": 0.73202,
            "fmeasure": 0.73813
        },
        "rouge2": {
            "precision": 0.58008,
            "recall": 0.54047,
            "fmeasure": 0.54481
        },
        "rougeL": {
            "precision": 0.69767,
            "recall": 0.65093,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.69767,
            "recall": 0.65093,
            "fmeasure": 0.65497
        },
        "nist": 4.849385080623077,
        "bleurt": 0.41297,
        "bertscore": {
            "precision": 0.92792,
            "recall": 0.92452,
            "f1": 0.92518
        },
        "nubia": {
            "semantic_relation": 4.34931,
            "contradiction": 3.50358,
            "irrelevancy": 14.69132,
            "logical_agreement": 81.8051,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.57502,
            "nubia_score": 0.78432
        },
        "meteor": 0.43171993274603265
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.87,
        "total_length": 139,
        "mean_pred_length": 17.375,
        "std_pred_length": 5.588772226527039,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.7482014388489209,
        "vocab_size-1": 104,
        "unique-1": 92,
        "entropy-1": 6.373985137316076,
        "distinct-2": 1.0,
        "vocab_size-2": 131,
        "unique-2": 131,
        "entropy-2": 7.03342300153745,
        "cond_entropy-2": 0.5113481502650591,
        "distinct-3": 1.0,
        "vocab_size-3": 123,
        "unique-3": 123,
        "entropy-3": 6.942514505339227,
        "cond_entropy-3": -0.0909084961982105,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 5.0682837331783235,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8360655737704918,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.51254430470508,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.832890014164754,
        "cond_entropy-2-nopunct": 0.34969258895846855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.10496955960154261,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.27781,
        "local_recall": {
            "1": 0.21951219512195122,
            "2": 0.44,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.68633,
            "recall": 0.73355,
            "fmeasure": 0.6987
        },
        "rouge2": {
            "precision": 0.41775,
            "recall": 0.45155,
            "fmeasure": 0.42422
        },
        "rougeL": {
            "precision": 0.54321,
            "recall": 0.57539,
            "fmeasure": 0.54974
        },
        "rougeLsum": {
            "precision": 0.54321,
            "recall": 0.57539,
            "fmeasure": 0.54974
        },
        "nist": 4.894889051022615,
        "bleurt": 0.03161,
        "bertscore": {
            "precision": 0.89662,
            "recall": 0.90796,
            "f1": 0.89702
        },
        "nubia": {
            "semantic_relation": 3.70743,
            "contradiction": 5.14849,
            "irrelevancy": 62.26905,
            "logical_agreement": 32.58245,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.49124,
            "nubia_score": 0.60334
        },
        "meteor": 0.36916643646148695
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.656854249492381,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.880179922675739,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 38,
        "unique-2": 37,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.27141524485691054,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.05992166186438029,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.18931411429782607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.07541281690069976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.20425,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.6
        },
        "rouge1": {
            "precision": 0.51111,
            "recall": 0.45695,
            "fmeasure": 0.41666
        },
        "rouge2": {
            "precision": 0.26905,
            "recall": 0.27465,
            "fmeasure": 0.2465
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.45695,
            "fmeasure": 0.41666
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.45695,
            "fmeasure": 0.41666
        },
        "nist": 3.107667996176668,
        "bleurt": -0.19952,
        "bertscore": {
            "precision": 0.87488,
            "recall": 0.88783,
            "f1": 0.87759
        },
        "nubia": {
            "semantic_relation": 3.42254,
            "contradiction": 3.74067,
            "irrelevancy": 67.11467,
            "logical_agreement": 29.14466,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.86006,
            "nubia_score": 0.5199
        },
        "meteor": 0.25781206322298583
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 3.590109871423003,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.527027027027027,
        "vocab_size-1": 39,
        "unique-1": 28,
        "entropy-1": 4.841096866085961,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 52,
        "unique-2": 43,
        "entropy-2": 5.539165598380575,
        "cond_entropy-2": 0.5907211439553621,
        "distinct-3": 0.8225806451612904,
        "vocab_size-3": 51,
        "unique-3": 44,
        "entropy-3": 5.550655181215035,
        "cond_entropy-3": -0.012141127567868351,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 3.4840908267278117,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.5522388059701493,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.7862592507286,
        "distinct-2-nopunct": 0.7704918032786885,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.397469714399262,
        "cond_entropy-2-nopunct": 0.6591464003298704,
        "distinct-3-nopunct": 0.8181818181818182,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.362822440640041,
        "cond_entropy-3-nopunct": -0.012836260323191302,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 81.03332,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7692307692307693,
            "3": 0.9761904761904762
        },
        "rouge1": {
            "precision": 0.908,
            "recall": 0.94874,
            "fmeasure": 0.9253
        },
        "rouge2": {
            "precision": 0.78772,
            "recall": 0.81877,
            "fmeasure": 0.80044
        },
        "rougeL": {
            "precision": 0.89566,
            "recall": 0.92067,
            "fmeasure": 0.90497
        },
        "rougeLsum": {
            "precision": 0.89566,
            "recall": 0.92067,
            "fmeasure": 0.90497
        },
        "nist": 6.151251699039089,
        "bleurt": 0.68331,
        "bertscore": {
            "precision": 0.98266,
            "recall": 0.98237,
            "f1": 0.98141
        },
        "nubia": {
            "semantic_relation": 4.51153,
            "contradiction": 21.96536,
            "irrelevancy": 22.8087,
            "logical_agreement": 55.22594,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.10136,
            "nubia_score": 0.86162
        },
        "meteor": 0.5560258275737214
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219521,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.53741,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.36111,
            "recall": 0.54365,
            "fmeasure": 0.4294
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.15385,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.36111,
            "fmeasure": 0.29282
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.36111,
            "fmeasure": 0.29282
        },
        "nist": 2.1274437510817346,
        "bleurt": 0.02317,
        "bertscore": {
            "precision": 0.91107,
            "recall": 0.92446,
            "f1": 0.91772
        },
        "nubia": {
            "semantic_relation": 3.695,
            "contradiction": 0.15833,
            "irrelevancy": 53.8232,
            "logical_agreement": 46.01847,
            "grammar_ref": 5.77141,
            "grammar_hyp": 4.3697,
            "nubia_score": 0.64121
        },
        "meteor": 0.3213247879508707
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "nist": 2.8936441277848375,
        "bleurt": 0.55466,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        },
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "meteor": 0.9652173913043478
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.2875371587496605,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.506890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.25760718359194273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.43545,
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.69697,
            "fmeasure": 0.60399
        },
        "rougeL": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rougeLsum": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "nist": 2.5686174422834114,
        "bleurt": 0.44181,
        "bertscore": {
            "precision": 0.89548,
            "recall": 0.91617,
            "f1": 0.90291
        },
        "nubia": {
            "semantic_relation": 2.96421,
            "contradiction": 94.69212,
            "irrelevancy": 4.53489,
            "logical_agreement": 0.77299,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.91859,
            "nubia_score": 0.37788
        },
        "meteor": 0.424905167368575
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960075,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.022446956445717602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.66666,
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.77632,
            "fmeasure": 0.78273
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.47368,
            "fmeasure": 0.47748
        },
        "rougeL": {
            "precision": 0.64912,
            "recall": 0.63947,
            "fmeasure": 0.64417
        },
        "rougeLsum": {
            "precision": 0.64912,
            "recall": 0.63947,
            "fmeasure": 0.64417
        },
        "nist": 4.145748457670282,
        "bleurt": 0.36368,
        "bertscore": {
            "precision": 0.92838,
            "recall": 0.91791,
            "f1": 0.92244
        },
        "nubia": {
            "semantic_relation": 4.62315,
            "contradiction": 0.19605,
            "irrelevancy": 3.38039,
            "logical_agreement": 96.42356,
            "grammar_ref": 5.26752,
            "grammar_hyp": 5.22218,
            "nubia_score": 0.81168
        },
        "meteor": 0.44387002457362923
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "total_length": 118,
        "mean_pred_length": 16.857142857142858,
        "std_pred_length": 3.270149469217028,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6779661016949152,
        "vocab_size-1": 80,
        "unique-1": 67,
        "entropy-1": 5.954458410079374,
        "distinct-2": 0.954954954954955,
        "vocab_size-2": 106,
        "unique-2": 102,
        "entropy-2": 6.697524987952251,
        "cond_entropy-2": 0.6245603438239745,
        "distinct-3": 1.0,
        "vocab_size-3": 104,
        "unique-3": 104,
        "entropy-3": 6.7004397181411,
        "cond_entropy-3": 0.009436231619481136,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 2.6418917155581334,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.984161640474292,
        "distinct-2-nopunct": 0.967391304347826,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.458344564752678,
        "cond_entropy-2-nopunct": 0.5232738466396563,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": -0.06711219638989935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.5193,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.3333333333333333,
            "3": 0.9010989010989011
        },
        "rouge1": {
            "precision": 0.90918,
            "recall": 0.89407,
            "fmeasure": 0.90015
        },
        "rouge2": {
            "precision": 0.7617,
            "recall": 0.75201,
            "fmeasure": 0.75565
        },
        "rougeL": {
            "precision": 0.85781,
            "recall": 0.84666,
            "fmeasure": 0.85095
        },
        "rougeLsum": {
            "precision": 0.85781,
            "recall": 0.84666,
            "fmeasure": 0.85095
        },
        "nist": 6.29621971287294,
        "bleurt": 0.57937,
        "bertscore": {
            "precision": 0.97203,
            "recall": 0.97583,
            "f1": 0.97381
        },
        "nubia": {
            "semantic_relation": 4.678,
            "contradiction": 0.29025,
            "irrelevancy": 19.23152,
            "logical_agreement": 80.47823,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.06765,
            "nubia_score": 0.87535
        },
        "meteor": 0.512534493887138
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.458591205867174,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.04896868761125601,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910023,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.333,
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.52976,
            "recall": 0.62281,
            "fmeasure": 0.55808
        },
        "rouge2": {
            "precision": 0.32984,
            "recall": 0.43492,
            "fmeasure": 0.3661
        },
        "rougeL": {
            "precision": 0.52976,
            "recall": 0.62281,
            "fmeasure": 0.55808
        },
        "rougeLsum": {
            "precision": 0.52976,
            "recall": 0.62281,
            "fmeasure": 0.55808
        },
        "nist": 2.278593854664052,
        "bleurt": 0.13153,
        "bertscore": {
            "precision": 0.84426,
            "recall": 0.88962,
            "f1": 0.86372
        },
        "nubia": {
            "semantic_relation": 3.80361,
            "contradiction": 32.33333,
            "irrelevancy": 36.67866,
            "logical_agreement": 30.98801,
            "grammar_ref": 4.27476,
            "grammar_hyp": 3.99578,
            "nubia_score": 0.56891
        },
        "meteor": 0.2958491089081011
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.73535,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.71795,
            "fmeasure": 0.77037
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.42857,
            "fmeasure": 0.46087
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.61282,
            "fmeasure": 0.6563
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.61282,
            "fmeasure": 0.6563
        },
        "nist": 3.7616949618508597,
        "bleurt": 0.21222,
        "bertscore": {
            "precision": 0.93582,
            "recall": 0.91552,
            "f1": 0.92556
        },
        "nubia": {
            "semantic_relation": 4.07647,
            "contradiction": 0.15276,
            "irrelevancy": 7.8279,
            "logical_agreement": 92.01935,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.53807,
            "nubia_score": 0.71254
        },
        "meteor": 0.4361206570186019
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.024937810560445,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.104527956260435,
        "distinct-2": 0.96,
        "vocab_size-2": 48,
        "unique-2": 46,
        "entropy-2": 5.563856189774728,
        "cond_entropy-2": 0.41625924714326173,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.922749974675523,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.3927633101039407,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.0399905308810258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.00333,
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.5,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.8179,
            "recall": 0.63647,
            "fmeasure": 0.69894
        },
        "rouge2": {
            "precision": 0.65962,
            "recall": 0.48422,
            "fmeasure": 0.53834
        },
        "rougeL": {
            "precision": 0.74647,
            "recall": 0.60869,
            "fmeasure": 0.65364
        },
        "rougeLsum": {
            "precision": 0.74647,
            "recall": 0.60869,
            "fmeasure": 0.65364
        },
        "nist": 4.022802141477907,
        "bleurt": 0.06992,
        "bertscore": {
            "precision": 0.91976,
            "recall": 0.91342,
            "f1": 0.91587
        },
        "nubia": {
            "semantic_relation": 3.4389,
            "contradiction": 26.23173,
            "irrelevancy": 39.40736,
            "logical_agreement": 34.36091,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.72852,
            "nubia_score": 0.50068
        },
        "meteor": 0.3975752521638712
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.548394345536403,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 26,
        "unique-2": 24,
        "entropy-2": 4.664497779200462,
        "cond_entropy-2": 0.07028173724063808,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 25,
        "unique-3": 24,
        "entropy-3": 4.623516641218013,
        "cond_entropy-3": -0.02999212699343526,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.43063240949075,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": 0.07916418769779475,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.33307,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.4,
            "3": 0.68
        },
        "rouge1": {
            "precision": 0.89205,
            "recall": 0.71077,
            "fmeasure": 0.78381
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.51852,
            "fmeasure": 0.57341
        },
        "rougeL": {
            "precision": 0.77367,
            "recall": 0.64571,
            "fmeasure": 0.69814
        },
        "rougeLsum": {
            "precision": 0.77367,
            "recall": 0.64571,
            "fmeasure": 0.69814
        },
        "nist": 4.351103821554853,
        "bleurt": 0.06516,
        "bertscore": {
            "precision": 0.95133,
            "recall": 0.91502,
            "f1": 0.93112
        },
        "nubia": {
            "semantic_relation": 3.89385,
            "contradiction": 1.64882,
            "irrelevancy": 10.96483,
            "logical_agreement": 87.38635,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.29164,
            "nubia_score": 0.63047
        },
        "meteor": 0.3734654890870653
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.74,
        "vocab_size-1": 37,
        "unique-1": 30,
        "entropy-1": 5.006370130156182,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.48774150187660953,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.09515723304034036,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8292682926829268,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.979264809390595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.2985274826235791,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.24083,
        "local_recall": {
            "1": 0.0,
            "2": 0.6153846153846154,
            "3": 0.9259259259259259
        },
        "rouge1": {
            "precision": 0.85,
            "recall": 0.7951,
            "fmeasure": 0.80739
        },
        "rouge2": {
            "precision": 0.55892,
            "recall": 0.56157,
            "fmeasure": 0.55444
        },
        "rougeL": {
            "precision": 0.71667,
            "recall": 0.71422,
            "fmeasure": 0.70673
        },
        "rougeLsum": {
            "precision": 0.71667,
            "recall": 0.71422,
            "fmeasure": 0.70673
        },
        "nist": 4.52253498930898,
        "bleurt": 0.26561,
        "bertscore": {
            "precision": 0.91445,
            "recall": 0.90595,
            "f1": 0.90956
        },
        "nubia": {
            "semantic_relation": 4.32932,
            "contradiction": 0.58494,
            "irrelevancy": 18.87732,
            "logical_agreement": 80.53774,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.08311,
            "nubia_score": 0.74072
        },
        "meteor": 0.46401919518888074
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 14.38363267359428,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.7313432835820896,
        "vocab_size-1": 49,
        "unique-1": 38,
        "entropy-1": 5.435273332151942,
        "distinct-2": 0.921875,
        "vocab_size-2": 59,
        "unique-2": 55,
        "entropy-2": 5.831954882778696,
        "cond_entropy-2": 0.35195592676353127,
        "distinct-3": 0.9836065573770492,
        "vocab_size-3": 60,
        "unique-3": 59,
        "entropy-3": 5.897950452316981,
        "cond_entropy-3": 0.07426008349999212,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 10.780641085864152,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.8035714285714286,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.35182322555177,
        "distinct-2-nopunct": 0.9811320754716981,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.690184605506591,
        "cond_entropy-2-nopunct": 0.3641461929645936,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.04406426478847453,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.30449,
        "local_recall": {
            "1": 0.375,
            "2": 0.6521739130434783,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.59716,
            "recall": 0.75724,
            "fmeasure": 0.65924
        },
        "rouge2": {
            "precision": 0.34347,
            "recall": 0.43106,
            "fmeasure": 0.37748
        },
        "rougeL": {
            "precision": 0.53907,
            "recall": 0.66096,
            "fmeasure": 0.58559
        },
        "rougeLsum": {
            "precision": 0.53907,
            "recall": 0.66096,
            "fmeasure": 0.58559
        },
        "nist": 3.2956788499412704,
        "bleurt": 0.31643,
        "bertscore": {
            "precision": 0.91623,
            "recall": 0.93893,
            "f1": 0.92676
        },
        "nubia": {
            "semantic_relation": 4.32394,
            "contradiction": 0.61971,
            "irrelevancy": 33.871,
            "logical_agreement": 65.50928,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.65919,
            "nubia_score": 0.60946
        },
        "meteor": 0.39539063694449467
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.10885,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.60714,
            "fmeasure": 0.58791
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.24476,
            "fmeasure": 0.23718
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.45833,
            "fmeasure": 0.44231
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.45833,
            "fmeasure": 0.44231
        },
        "nist": 3.168611283529246,
        "bleurt": 0.2281,
        "bertscore": {
            "precision": 0.88713,
            "recall": 0.89014,
            "f1": 0.88863
        },
        "nubia": {
            "semantic_relation": 4.05355,
            "contradiction": 0.80029,
            "irrelevancy": 92.68307,
            "logical_agreement": 6.51664,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.26687,
            "nubia_score": 0.81132
        },
        "meteor": 0.3222084247769806
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.8,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 1.498298354528788,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.7706422018348624,
        "vocab_size-1": 84,
        "unique-1": 75,
        "entropy-1": 6.1087870497225385,
        "distinct-2": 0.9901960784313726,
        "vocab_size-2": 101,
        "unique-2": 100,
        "entropy-2": 6.652817498834245,
        "cond_entropy-2": 0.38340085034091437,
        "distinct-3": 1.0,
        "vocab_size-3": 95,
        "unique-3": 95,
        "entropy-3": 6.569855608330948,
        "cond_entropy-3": -0.08151710206160055,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 1.8070158058105024,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.845360824742268,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.188837553723972,
        "distinct-2-nopunct": 0.9888888888888889,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.46963087410744,
        "cond_entropy-2-nopunct": 0.3127658428195161,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": -0.09271727944058132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.94729,
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.5,
            "3": 0.9420289855072463
        },
        "rouge1": {
            "precision": 0.82962,
            "recall": 0.83527,
            "fmeasure": 0.82313
        },
        "rouge2": {
            "precision": 0.67536,
            "recall": 0.69961,
            "fmeasure": 0.68239
        },
        "rougeL": {
            "precision": 0.69531,
            "recall": 0.71271,
            "fmeasure": 0.69768
        },
        "rougeLsum": {
            "precision": 0.69531,
            "recall": 0.71271,
            "fmeasure": 0.69768
        },
        "nist": 5.586328797130101,
        "bleurt": 0.42976,
        "bertscore": {
            "precision": 0.94433,
            "recall": 0.95559,
            "f1": 0.94721
        },
        "nubia": {
            "semantic_relation": 4.28169,
            "contradiction": 0.62025,
            "irrelevancy": 45.17324,
            "logical_agreement": 54.20651,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.61707,
            "nubia_score": 0.72358
        },
        "meteor": 0.463590650349317
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.001629167387823,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.2626923908396215,
        "cond_entropy-2": 0.2864255422923784,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 20,
        "unique-3": 18,
        "entropy-3": 4.277613436819113,
        "cond_entropy-3": 0.026778753489375348,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8230679822736597,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064474,
        "cond_entropy-2-nopunct": 0.3138381850938441,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": 0.02961067210860201,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.74672,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.86538,
            "fmeasure": 0.66767
        },
        "rouge2": {
            "precision": 0.46032,
            "recall": 0.75556,
            "fmeasure": 0.57071
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.86538,
            "fmeasure": 0.66767
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.86538,
            "fmeasure": 0.66767
        },
        "nist": 3.0195193138163225,
        "bleurt": 0.639,
        "bertscore": {
            "precision": 0.90615,
            "recall": 0.98205,
            "f1": 0.94237
        },
        "nubia": {
            "semantic_relation": 4.17109,
            "contradiction": 0.11911,
            "irrelevancy": 99.11671,
            "logical_agreement": 0.76417,
            "grammar_ref": 4.55634,
            "grammar_hyp": 3.42365,
            "nubia_score": 0.87427
        },
        "meteor": 0.47582132386128856
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 39,
        "unique-1": 30,
        "entropy-1": 5.097299076157414,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.5205748496543694,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.08746284125033933,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7608695652173914,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.958344564752664,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.4608423335288057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.1043366598147359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.08314,
        "local_recall": {
            "1": 0.5,
            "2": 0.6,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.54965,
            "recall": 0.77653,
            "fmeasure": 0.63248
        },
        "rouge2": {
            "precision": 0.28485,
            "recall": 0.4438,
            "fmeasure": 0.33817
        },
        "rougeL": {
            "precision": 0.45388,
            "recall": 0.67082,
            "fmeasure": 0.53007
        },
        "rougeLsum": {
            "precision": 0.45388,
            "recall": 0.67082,
            "fmeasure": 0.53007
        },
        "nist": 2.905647540520463,
        "bleurt": 0.21942,
        "bertscore": {
            "precision": 0.87131,
            "recall": 0.92121,
            "f1": 0.89383
        },
        "nubia": {
            "semantic_relation": 3.54925,
            "contradiction": 30.94509,
            "irrelevancy": 38.00966,
            "logical_agreement": 31.04525,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.97826,
            "nubia_score": 0.55706
        },
        "meteor": 0.38115389647241904
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.09956,
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.86111,
            "fmeasure": 0.75556
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.65455,
            "fmeasure": 0.55061
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.83333,
            "fmeasure": 0.72381
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.83333,
            "fmeasure": 0.72381
        },
        "nist": 3.0935856287134254,
        "bleurt": 0.3268,
        "bertscore": {
            "precision": 0.95965,
            "recall": 0.96564,
            "f1": 0.96263
        },
        "nubia": {
            "semantic_relation": 4.02743,
            "contradiction": 0.21891,
            "irrelevancy": 33.81697,
            "logical_agreement": 65.96412,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.02129,
            "nubia_score": 0.744
        },
        "meteor": 0.4461486611543757
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "nist": 3.944797625754069,
        "bleurt": 0.56963,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 81.96501,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "nist": 4.00193538757769,
        "bleurt": 0.86304,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        },
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "meteor": 0.5249299242820813
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.8843,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.54286,
            "fmeasure": 0.56667
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.38571,
            "fmeasure": 0.40336
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.48254,
            "fmeasure": 0.5037
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.48254,
            "fmeasure": 0.5037
        },
        "nist": 1.4507518765263763,
        "bleurt": -0.12529,
        "bertscore": {
            "precision": 0.87628,
            "recall": 0.8769,
            "f1": 0.87659
        },
        "nubia": {
            "semantic_relation": 4.30334,
            "contradiction": 0.09689,
            "irrelevancy": 1.20002,
            "logical_agreement": 98.70308,
            "grammar_ref": 2.70093,
            "grammar_hyp": 3.79646,
            "nubia_score": 0.80103
        },
        "meteor": 0.322793831030442
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.321627262824397,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 27,
        "unique-2": 25,
        "entropy-2": 4.720049960644813,
        "cond_entropy-2": 0.3730826321350699,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": 0.04505465518404472,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.250752013250441,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.606739354015323,
        "cond_entropy-2-nopunct": 0.40096726534837135,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": 0.04896868761125604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.5158,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.8127,
            "fmeasure": 0.80614
        },
        "rouge2": {
            "precision": 0.64037,
            "recall": 0.64446,
            "fmeasure": 0.63932
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.8127,
            "fmeasure": 0.80614
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.8127,
            "fmeasure": 0.80614
        },
        "nist": 4.729590725122255,
        "bleurt": 0.51018,
        "bertscore": {
            "precision": 0.95702,
            "recall": 0.95639,
            "f1": 0.95018
        },
        "nubia": {
            "semantic_relation": 3.64372,
            "contradiction": 49.33249,
            "irrelevancy": 1.1619,
            "logical_agreement": 49.50561,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.25614,
            "nubia_score": 0.58431
        },
        "meteor": 0.4538817575969018
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.07118,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.93333,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "nist": 3.2409567319242063,
        "bleurt": 0.84415,
        "bertscore": {
            "precision": 0.9946,
            "recall": 0.98653,
            "f1": 0.99055
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29491,
            "irrelevancy": 0.47333,
            "logical_agreement": 99.23176,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.20648,
            "nubia_score": 0.99508
        },
        "meteor": 0.5407825953587019
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.6996621467371855,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.6909090909090909,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 4.988457159443987,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.5892938730436365,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7346938775510204,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9287988140246615,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.5795797072019508,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.14067,
        "local_recall": {
            "1": 0.0,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.73584,
            "recall": 0.82075,
            "fmeasure": 0.77138
        },
        "rouge2": {
            "precision": 0.4736,
            "recall": 0.5255,
            "fmeasure": 0.49552
        },
        "rougeL": {
            "precision": 0.68186,
            "recall": 0.76867,
            "fmeasure": 0.71933
        },
        "rougeLsum": {
            "precision": 0.68186,
            "recall": 0.76867,
            "fmeasure": 0.71933
        },
        "nist": 4.5779704181532646,
        "bleurt": 0.6037,
        "bertscore": {
            "precision": 0.94446,
            "recall": 0.95509,
            "f1": 0.94794
        },
        "nubia": {
            "semantic_relation": 4.52625,
            "contradiction": 10.14671,
            "irrelevancy": 42.2717,
            "logical_agreement": 47.58159,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.10096,
            "nubia_score": 0.78493
        },
        "meteor": 0.45380518718104107
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.82745,
        "local_recall": {
            "1": 0.1,
            "2": 0.7692307692307693,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.81843,
            "fmeasure": 0.8799
        },
        "rouge2": {
            "precision": 0.725,
            "recall": 0.60934,
            "fmeasure": 0.66095
        },
        "rougeL": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "rougeLsum": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "nist": 3.45193483039471,
        "bleurt": 0.52275,
        "bertscore": {
            "precision": 0.98978,
            "recall": 0.95077,
            "f1": 0.96988
        },
        "nubia": {
            "semantic_relation": 4.44566,
            "contradiction": 1.89347,
            "irrelevancy": 2.26282,
            "logical_agreement": 95.84371,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.67834,
            "nubia_score": 0.80478
        },
        "meteor": 0.4376641492357371
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.3764992953429935,
        "bleurt": 0.91462,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 70.97039,
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "nist": 3.8998572512287097,
        "bleurt": 0.5631,
        "bertscore": {
            "precision": 0.98967,
            "recall": 0.97294,
            "f1": 0.98123
        },
        "nubia": {
            "semantic_relation": 4.63806,
            "contradiction": 0.24928,
            "irrelevancy": 0.95419,
            "logical_agreement": 98.79652,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.32995,
            "nubia_score": 0.87141
        },
        "meteor": 0.5047034859011716
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.37543,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.76389,
            "fmeasure": 0.73504
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.39192,
            "fmeasure": 0.37302
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53472,
            "fmeasure": 0.51453
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53472,
            "fmeasure": 0.51453
        },
        "nist": 3.043059324604207,
        "bleurt": 0.0861,
        "bertscore": {
            "precision": 0.89197,
            "recall": 0.88013,
            "f1": 0.8826
        },
        "nubia": {
            "semantic_relation": 3.91474,
            "contradiction": 0.49108,
            "irrelevancy": 78.39504,
            "logical_agreement": 21.11388,
            "grammar_ref": 5.53377,
            "grammar_hyp": 5.27885,
            "nubia_score": 0.62264
        },
        "meteor": 0.3542620392786924
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.96903,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.39899,
            "fmeasure": 0.49903
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.21515,
            "fmeasure": 0.27696
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.36667,
            "fmeasure": 0.47209
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.36667,
            "fmeasure": 0.47209
        },
        "nist": 1.0274418494859223,
        "bleurt": -0.20324,
        "bertscore": {
            "precision": 0.89036,
            "recall": 0.86938,
            "f1": 0.87975
        },
        "nubia": {
            "semantic_relation": 3.80066,
            "contradiction": 1.18504,
            "irrelevancy": 56.78988,
            "logical_agreement": 42.02507,
            "grammar_ref": 4.53537,
            "grammar_hyp": 5.94279,
            "nubia_score": 0.43068
        },
        "meteor": 0.23933344234939066
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 4.251192788981044,
        "bleurt": 0.64779,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.8936170212765957,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.325761458014588,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.041206403323296094,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9512195121951219,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.259991029008325,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": -0.004361333279761104,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.20652,
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.82164,
            "fmeasure": 0.81659
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66361,
            "fmeasure": 0.66098
        },
        "rougeL": {
            "precision": 0.67778,
            "recall": 0.67622,
            "fmeasure": 0.67316
        },
        "rougeLsum": {
            "precision": 0.67778,
            "recall": 0.67622,
            "fmeasure": 0.67316
        },
        "nist": 3.9362515974762133,
        "bleurt": 0.37684,
        "bertscore": {
            "precision": 0.92532,
            "recall": 0.95302,
            "f1": 0.93842
        },
        "nubia": {
            "semantic_relation": 4.21339,
            "contradiction": 3.87437,
            "irrelevancy": 62.10892,
            "logical_agreement": 34.01671,
            "grammar_ref": 4.8308,
            "grammar_hyp": 4.92338,
            "nubia_score": 0.69007
        },
        "meteor": 0.46462044394398927
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.43545,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.63636,
            "fmeasure": 0.58333
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nist": 3.050094228405057,
        "bleurt": 0.46996,
        "bertscore": {
            "precision": 0.93126,
            "recall": 0.92667,
            "f1": 0.92896
        },
        "nubia": {
            "semantic_relation": 4.51776,
            "contradiction": 0.20339,
            "irrelevancy": 33.71147,
            "logical_agreement": 66.08514,
            "grammar_ref": 4.00353,
            "grammar_hyp": 4.51885,
            "nubia_score": 0.77221
        },
        "meteor": 0.43386146233495876
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.74,
        "total_length": 305,
        "mean_pred_length": 17.941176470588236,
        "std_pred_length": 6.812364090260436,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.6032786885245902,
        "vocab_size-1": 184,
        "unique-1": 152,
        "entropy-1": 6.840683252489176,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 256,
        "unique-2": 232,
        "entropy-2": 7.920361449425175,
        "cond_entropy-2": 0.9122786460012706,
        "distinct-3": 0.959409594095941,
        "vocab_size-3": 260,
        "unique-3": 249,
        "entropy-3": 8.000968229545718,
        "cond_entropy-3": 0.08888198449062579,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 15.588235294117647,
        "std_pred_length-nopunct": 5.801204981618416,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6792452830188679,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 6.97121373512277,
        "distinct-2-nopunct": 0.8911290322580645,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.704703153205739,
        "cond_entropy-2-nopunct": 0.7744848488979518,
        "distinct-3-nopunct": 0.961038961038961,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.773826963493949,
        "cond_entropy-3-nopunct": 0.06510415085379205,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.50904,
        "local_recall": {
            "1": 0.15555555555555556,
            "2": 0.4,
            "3": 0.7486338797814208
        },
        "rouge1": {
            "precision": 0.76225,
            "recall": 0.71635,
            "fmeasure": 0.72256
        },
        "rouge2": {
            "precision": 0.53636,
            "recall": 0.50709,
            "fmeasure": 0.50985
        },
        "rougeL": {
            "precision": 0.66974,
            "recall": 0.64048,
            "fmeasure": 0.64187
        },
        "rougeLsum": {
            "precision": 0.66974,
            "recall": 0.64048,
            "fmeasure": 0.64187
        },
        "nist": 5.877876891686532,
        "bleurt": 0.2459,
        "bertscore": {
            "precision": 0.92755,
            "recall": 0.92633,
            "f1": 0.92539
        },
        "nubia": {
            "semantic_relation": 4.15017,
            "contradiction": 16.25203,
            "irrelevancy": 31.06993,
            "logical_agreement": 52.67803,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.34906,
            "nubia_score": 0.72078
        },
        "meteor": 0.40646531632665533
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.26936,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.54167,
            "fmeasure": 0.59091
        },
        "rouge2": {
            "precision": 0.50877,
            "recall": 0.42029,
            "fmeasure": 0.46032
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.52778,
            "fmeasure": 0.57576
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.52778,
            "fmeasure": 0.57576
        },
        "nist": 3.486918021990142,
        "bleurt": -0.12806,
        "bertscore": {
            "precision": 0.87279,
            "recall": 0.8523,
            "f1": 0.86242
        },
        "nubia": {
            "semantic_relation": 3.80432,
            "contradiction": 0.22431,
            "irrelevancy": 98.41154,
            "logical_agreement": 1.36415,
            "grammar_ref": 3.8277,
            "grammar_hyp": 4.46088,
            "nubia_score": 0.56769
        },
        "meteor": 0.29363976372196043
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.69107,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.61905,
            "fmeasure": 0.65
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.41905,
            "fmeasure": 0.44804
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.46898,
            "fmeasure": 0.49593
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.46898,
            "fmeasure": 0.49593
        },
        "nist": 2.5283964825830854,
        "bleurt": 0.04387,
        "bertscore": {
            "precision": 0.9037,
            "recall": 0.8751,
            "f1": 0.88917
        },
        "nubia": {
            "semantic_relation": 3.71737,
            "contradiction": 0.10883,
            "irrelevancy": 99.70491,
            "logical_agreement": 0.18626,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.28532,
            "nubia_score": 0.58535
        },
        "meteor": 0.3653696150584731
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 0.5,
        "median_pred_length": 17.5,
        "min_pred_length": 17,
        "max_pred_length": 18,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.729283016944964,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.2787474660498503,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.567099536193328,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.317577788188973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.03145,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.71988,
            "fmeasure": 0.66959
        },
        "rouge2": {
            "precision": 0.36878,
            "recall": 0.38793,
            "fmeasure": 0.36947
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.49818,
            "fmeasure": 0.50088
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.49818,
            "fmeasure": 0.50088
        },
        "nist": 3.4512569018826778,
        "bleurt": 0.29911,
        "bertscore": {
            "precision": 0.92346,
            "recall": 0.906,
            "f1": 0.91319
        },
        "nubia": {
            "semantic_relation": 4.81546,
            "contradiction": 10.92892,
            "irrelevancy": 18.20345,
            "logical_agreement": 70.86763,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.66163,
            "nubia_score": 0.92624
        },
        "meteor": 0.3674896703125769
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.44615,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 1.0,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.25,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "nist": 1.938721875540867,
        "bleurt": 0.69689,
        "bertscore": {
            "precision": 0.93881,
            "recall": 0.96091,
            "f1": 0.94973
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24782,
            "irrelevancy": 0.42258,
            "logical_agreement": 99.3296,
            "grammar_ref": 6.34893,
            "grammar_hyp": 5.2329,
            "nubia_score": 1.0
        },
        "meteor": 0.43736318486388026
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.85342,
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "nist": 4.018549068142959,
        "bleurt": 0.6035,
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        },
        "nubia": {
            "semantic_relation": 4.40194,
            "contradiction": 0.18499,
            "irrelevancy": 63.6692,
            "logical_agreement": 36.14582,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.41374,
            "nubia_score": 0.97573
        },
        "meteor": 0.5255759325753065
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.7439427079182686,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.38386386470375694,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.6871792978845495,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.3057541296022394,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.24678,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.84259,
            "recall": 0.76852,
            "fmeasure": 0.7906
        },
        "rouge2": {
            "precision": 0.61728,
            "recall": 0.56665,
            "fmeasure": 0.57954
        },
        "rougeL": {
            "precision": 0.72963,
            "recall": 0.66944,
            "fmeasure": 0.68539
        },
        "rougeLsum": {
            "precision": 0.72963,
            "recall": 0.66944,
            "fmeasure": 0.68539
        },
        "nist": 4.242179964910005,
        "bleurt": 0.30956,
        "bertscore": {
            "precision": 0.94136,
            "recall": 0.93483,
            "f1": 0.93343
        },
        "nubia": {
            "semantic_relation": 3.83358,
            "contradiction": 3.30065,
            "irrelevancy": 58.08897,
            "logical_agreement": 38.61037,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.17414,
            "nubia_score": 0.64396
        },
        "meteor": 0.42015842725746666
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 6.599663291074443,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.209867121904037,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 47,
        "unique-2": 45,
        "entropy-2": 5.533077191053985,
        "cond_entropy-2": 0.25620660561010566,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 45,
        "unique-3": 44,
        "entropy-3": 5.480083695187445,
        "cond_entropy-3": -0.047669627188630194,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8372093023255814,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.083127836047133,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.23953552773935105,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.95468,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.656,
            "recall": 0.57115,
            "fmeasure": 0.60644
        },
        "rouge2": {
            "precision": 0.42724,
            "recall": 0.37205,
            "fmeasure": 0.39544
        },
        "rougeL": {
            "precision": 0.57346,
            "recall": 0.50682,
            "fmeasure": 0.53444
        },
        "rougeLsum": {
            "precision": 0.57346,
            "recall": 0.50682,
            "fmeasure": 0.53444
        },
        "nist": 4.457802004803118,
        "bleurt": 0.08371,
        "bertscore": {
            "precision": 0.9168,
            "recall": 0.88615,
            "f1": 0.90055
        },
        "nubia": {
            "semantic_relation": 3.97295,
            "contradiction": 0.26669,
            "irrelevancy": 27.77825,
            "logical_agreement": 71.95506,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.72791,
            "nubia_score": 0.67086
        },
        "meteor": 0.3889417110435164
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.1471,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "nist": 1.4089039873913056,
        "bleurt": 0.14403,
        "bertscore": {
            "precision": 0.84745,
            "recall": 0.8339,
            "f1": 0.84062
        },
        "nubia": {
            "semantic_relation": 4.34836,
            "contradiction": 0.26908,
            "irrelevancy": 85.70123,
            "logical_agreement": 14.02968,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.95602,
            "nubia_score": 0.88307
        },
        "meteor": 0.21184095372658285
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.2875371587496605,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.86751,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "rouge1": {
            "precision": 0.95556,
            "recall": 0.47068,
            "fmeasure": 0.62626
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.23932,
            "fmeasure": 0.32138
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.33025,
            "fmeasure": 0.43867
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.33025,
            "fmeasure": 0.43867
        },
        "nist": 0.21538770909954755,
        "bleurt": -0.37058,
        "bertscore": {
            "precision": 0.89543,
            "recall": 0.80882,
            "f1": 0.84148
        },
        "nubia": {
            "semantic_relation": 3.62676,
            "contradiction": 0.19963,
            "irrelevancy": 0.42195,
            "logical_agreement": 99.37842,
            "grammar_ref": 3.4256,
            "grammar_hyp": 4.43378,
            "nubia_score": 0.42301
        },
        "meteor": 0.25827957315867417
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.75,
        "vocab_size-2": 18,
        "unique-2": 12,
        "entropy-2": 4.084962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 0.7727272727272727,
        "vocab_size-3": 17,
        "unique-3": 12,
        "entropy-3": 4.004886164091842,
        "cond_entropy-3": -0.03462179117476819,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.6539967386657093,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.8208888513501886,
        "cond_entropy-2-nopunct": 0.20208880005508081,
        "distinct-3-nopunct": 0.7368421052631579,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.7216117239699003,
        "cond_entropy-3-nopunct": -0.09175833038780652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.85878,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.74038,
            "fmeasure": 0.65821
        },
        "rouge2": {
            "precision": 0.39091,
            "recall": 0.45505,
            "fmeasure": 0.40061
        },
        "rougeL": {
            "precision": 0.57576,
            "recall": 0.68697,
            "fmeasure": 0.60145
        },
        "rougeLsum": {
            "precision": 0.57576,
            "recall": 0.68697,
            "fmeasure": 0.60145
        },
        "nist": 3.43798358342976,
        "bleurt": -0.05721,
        "bertscore": {
            "precision": 0.90086,
            "recall": 0.94898,
            "f1": 0.92274
        },
        "nubia": {
            "semantic_relation": 3.78924,
            "contradiction": 0.43148,
            "irrelevancy": 66.17099,
            "logical_agreement": 33.39753,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.62392,
            "nubia_score": 0.63935
        },
        "meteor": 0.42635146016938613
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.65512,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.74411,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.25,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.55556,
            "fmeasure": 0.45455
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.55556,
            "fmeasure": 0.45455
        },
        "nist": 2.303443174348202,
        "bleurt": 0.24969,
        "bertscore": {
            "precision": 0.90864,
            "recall": 0.9038,
            "f1": 0.90621
        },
        "nubia": {
            "semantic_relation": 4.41665,
            "contradiction": 0.27765,
            "irrelevancy": 99.14812,
            "logical_agreement": 0.57423,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.52675,
            "nubia_score": 0.77672
        },
        "meteor": 0.32321360755468
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.52469,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.84444,
            "fmeasure": 0.71146
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.84444,
            "fmeasure": 0.71146
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.84444,
            "fmeasure": 0.71146
        },
        "nist": 3.076931185648967,
        "bleurt": 0.20965,
        "bertscore": {
            "precision": 0.91029,
            "recall": 0.98214,
            "f1": 0.94485
        },
        "nubia": {
            "semantic_relation": 4.00594,
            "contradiction": 0.18476,
            "irrelevancy": 99.72015,
            "logical_agreement": 0.09509,
            "grammar_ref": 5.68221,
            "grammar_hyp": 5.00859,
            "nubia_score": 0.7469
        },
        "meteor": 0.4904747585430141
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 25.75,
        "std_pred_length": 8.257572282456872,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 37,
        "distinct-1": 0.6893203883495146,
        "vocab_size-1": 71,
        "unique-1": 56,
        "entropy-1": 5.809019552352122,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 96,
        "unique-2": 93,
        "entropy-2": 6.568750559473558,
        "cond_entropy-2": 0.7143767030742075,
        "distinct-3": 0.9894736842105263,
        "vocab_size-3": 94,
        "unique-3": 93,
        "entropy-3": 6.548802976752,
        "cond_entropy-3": -0.017395748590766973,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 22.25,
        "std_pred_length-nopunct": 7.1545440106270926,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7752808988764045,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.923359729182921,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.47673114586224746,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.04484957522838574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 25.54481,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.5789473684210527,
            "3": 0.7037037037037037
        },
        "rouge1": {
            "precision": 0.6017,
            "recall": 0.63067,
            "fmeasure": 0.60307
        },
        "rouge2": {
            "precision": 0.26029,
            "recall": 0.26646,
            "fmeasure": 0.25728
        },
        "rougeL": {
            "precision": 0.41807,
            "recall": 0.42758,
            "fmeasure": 0.41421
        },
        "rougeLsum": {
            "precision": 0.41807,
            "recall": 0.42758,
            "fmeasure": 0.41421
        },
        "nist": 4.261563355842097,
        "bleurt": -0.15021,
        "bertscore": {
            "precision": 0.8488,
            "recall": 0.8614,
            "f1": 0.85014
        },
        "nubia": {
            "semantic_relation": 3.61986,
            "contradiction": 9.15723,
            "irrelevancy": 66.17215,
            "logical_agreement": 24.67062,
            "grammar_ref": 4.54253,
            "grammar_hyp": 3.75517,
            "nubia_score": 0.56771
        },
        "meteor": 0.31892614573893346
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.9321380397593733,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.25533082133206014,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.24209,
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.9
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.93795,
            "fmeasure": 0.96787
        },
        "rouge2": {
            "precision": 0.82456,
            "recall": 0.77143,
            "fmeasure": 0.79701
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.65714,
            "fmeasure": 0.63229
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.65714,
            "fmeasure": 0.63229
        },
        "nist": 4.551507442006764,
        "bleurt": 0.34082,
        "bertscore": {
            "precision": 0.9667,
            "recall": 0.97356,
            "f1": 0.96777
        },
        "nubia": {
            "semantic_relation": 4.49662,
            "contradiction": 66.4325,
            "irrelevancy": 22.6463,
            "logical_agreement": 10.9212,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.7854,
            "nubia_score": 0.80164
        },
        "meteor": 0.4736718448947174
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleurt": 0.99428,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.92017,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.69123,
            "fmeasure": 0.78614
        },
        "rougeL": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "rougeLsum": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "nist": 2.4090636926463773,
        "bleurt": 0.39244,
        "bertscore": {
            "precision": 0.98531,
            "recall": 0.92036,
            "f1": 0.95173
        },
        "nubia": {
            "semantic_relation": 3.76609,
            "contradiction": 0.20429,
            "irrelevancy": 1.0493,
            "logical_agreement": 98.74641,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.64234,
            "nubia_score": 0.5936
        },
        "meteor": 0.46533854723503365
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.64838,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.25
        },
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.32479,
            "fmeasure": 0.39899
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.07937,
            "fmeasure": 0.09697
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.29402,
            "fmeasure": 0.35354
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.29402,
            "fmeasure": 0.35354
        },
        "nist": 0.6425898657104263,
        "bleurt": -0.59635,
        "bertscore": {
            "precision": 0.79112,
            "recall": 0.74453,
            "f1": 0.76711
        },
        "nubia": {
            "semantic_relation": 2.70476,
            "contradiction": 11.04692,
            "irrelevancy": 42.85918,
            "logical_agreement": 46.0939,
            "grammar_ref": 4.61776,
            "grammar_hyp": 4.63992,
            "nubia_score": 0.24509
        },
        "meteor": 0.12941716215613697
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "nist": 4.548645758111165,
        "bleurt": 0.7198,
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        },
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "meteor": 0.5161210442123606
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 5.436502143433364,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.5849056603773585,
        "vocab_size-1": 31,
        "unique-1": 22,
        "entropy-1": 4.652567276078462,
        "distinct-2": 0.88,
        "vocab_size-2": 44,
        "unique-2": 41,
        "entropy-2": 5.331663380285991,
        "cond_entropy-2": 0.6485195448733391,
        "distinct-3": 0.9787234042553191,
        "vocab_size-3": 46,
        "unique-3": 45,
        "entropy-3": 5.512035660188278,
        "cond_entropy-3": 0.2002994805079513,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.599079570624175,
        "distinct-2-nopunct": 0.8723404255319149,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.22246884158324,
        "cond_entropy-2-nopunct": 0.622631927469899,
        "distinct-3-nopunct": 0.9772727272727273,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.41397707318275,
        "cond_entropy-3-nopunct": 0.21415277774231442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.77898,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.5789473684210527
        },
        "rouge1": {
            "precision": 0.74524,
            "recall": 0.6613,
            "fmeasure": 0.65577
        },
        "rouge2": {
            "precision": 0.6557,
            "recall": 0.58423,
            "fmeasure": 0.5709
        },
        "rougeL": {
            "precision": 0.74524,
            "recall": 0.6613,
            "fmeasure": 0.65577
        },
        "rougeLsum": {
            "precision": 0.74524,
            "recall": 0.6613,
            "fmeasure": 0.65577
        },
        "nist": 3.6551353451165216,
        "bleurt": -0.21122,
        "bertscore": {
            "precision": 0.91514,
            "recall": 0.88589,
            "f1": 0.89878
        },
        "nubia": {
            "semantic_relation": 3.49934,
            "contradiction": 1.54915,
            "irrelevancy": 32.00653,
            "logical_agreement": 66.44432,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.2593,
            "nubia_score": 0.46088
        },
        "meteor": 0.3825328339467749
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 3.975418017913833,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.3673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7946534735443413,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.3148841634647016,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.25597,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.79365,
            "fmeasure": 0.8547
        },
        "rouge2": {
            "precision": 0.56863,
            "recall": 0.64487,
            "fmeasure": 0.5982
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.60317,
            "fmeasure": 0.64957
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.60317,
            "fmeasure": 0.64957
        },
        "nist": 4.990371243018509,
        "bleurt": 0.39828,
        "bertscore": {
            "precision": 0.96851,
            "recall": 0.94997,
            "f1": 0.94548
        },
        "nubia": {
            "semantic_relation": 4.17184,
            "contradiction": 0.14477,
            "irrelevancy": 33.54059,
            "logical_agreement": 66.31464,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.36814,
            "nubia_score": 0.85832
        },
        "meteor": 0.484222175901938
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 0.5,
        "median_pred_length": 19.5,
        "min_pred_length": 19,
        "max_pred_length": 20,
        "distinct-1": 0.8974358974358975,
        "vocab_size-1": 35,
        "unique-1": 32,
        "entropy-1": 5.060917923934979,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.07499607921862442,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.01499730265925,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.03632322362560796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.56765,
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.60764,
            "recall": 0.62566,
            "fmeasure": 0.60838
        },
        "rouge2": {
            "precision": 0.34271,
            "recall": 0.34872,
            "fmeasure": 0.34026
        },
        "rougeL": {
            "precision": 0.40278,
            "recall": 0.42601,
            "fmeasure": 0.40906
        },
        "rougeLsum": {
            "precision": 0.40278,
            "recall": 0.42601,
            "fmeasure": 0.40906
        },
        "nist": 4.554969375989453,
        "bleurt": -0.14779,
        "bertscore": {
            "precision": 0.9091,
            "recall": 0.91112,
            "f1": 0.90587
        },
        "nubia": {
            "semantic_relation": 3.84926,
            "contradiction": 0.22988,
            "irrelevancy": 64.33473,
            "logical_agreement": 35.43539,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.73989,
            "nubia_score": 0.62817
        },
        "meteor": 0.2968359985177462
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.6682958340544896,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.3290145724615955,
        "distinct-3": 0.8,
        "vocab_size-3": 16,
        "unique-3": 12,
        "entropy-3": 3.9219280948873623,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.5503407095463877,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.362496476250065,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.31012,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.8323,
            "fmeasure": 0.864
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.70694,
            "fmeasure": 0.73147
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "nist": 4.232198344961961,
        "bleurt": 0.61954,
        "bertscore": {
            "precision": 0.98829,
            "recall": 0.98829,
            "f1": 0.98829
        },
        "nubia": {
            "semantic_relation": 4.98669,
            "contradiction": 0.38304,
            "irrelevancy": 0.50825,
            "logical_agreement": 99.1087,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.63384,
            "nubia_score": 0.98188
        },
        "meteor": 0.9692307692307691
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.04044,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.3157894736842105
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.35837,
            "fmeasure": 0.44044
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.14069,
            "fmeasure": 0.17479
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.17918,
            "fmeasure": 0.22022
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.17918,
            "fmeasure": 0.22022
        },
        "nist": 0.9897460057194477,
        "bleurt": -0.46478,
        "bertscore": {
            "precision": 0.84446,
            "recall": 0.81157,
            "f1": 0.82769
        },
        "nubia": {
            "semantic_relation": 3.75389,
            "contradiction": 3.02347,
            "irrelevancy": 2.76136,
            "logical_agreement": 94.21517,
            "grammar_ref": 4.34096,
            "grammar_hyp": 6.95523,
            "nubia_score": 0.34874
        },
        "meteor": 0.16800472389127238
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 7.5,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 26,
        "unique-1": 19,
        "entropy-1": 4.571860873964195,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.38510428436278793,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.025681679939320107,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.389898095464287,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.32635048729214916,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 62.64592,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2857142857142857,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.81699,
            "recall": 0.81528,
            "fmeasure": 0.81518
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.59196,
            "fmeasure": 0.5922
        },
        "rougeL": {
            "precision": 0.79739,
            "recall": 0.74444,
            "fmeasure": 0.76877
        },
        "rougeLsum": {
            "precision": 0.79739,
            "recall": 0.74444,
            "fmeasure": 0.76877
        },
        "nist": 4.907381944241014,
        "bleurt": 0.61255,
        "bertscore": {
            "precision": 0.96208,
            "recall": 0.96168,
            "f1": 0.95631
        },
        "nubia": {
            "semantic_relation": 4.68807,
            "contradiction": 0.13348,
            "irrelevancy": 0.92622,
            "logical_agreement": 98.9403,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.2194,
            "nubia_score": 0.94061
        },
        "meteor": 0.48678439088174563
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.0,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.11475004073479986,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432274,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 52.82785,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.7272727272727273,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.81985,
            "recall": 0.7004,
            "fmeasure": 0.73602
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.50668,
            "fmeasure": 0.53546
        },
        "rougeL": {
            "precision": 0.75123,
            "recall": 0.68056,
            "fmeasure": 0.69244
        },
        "rougeLsum": {
            "precision": 0.75123,
            "recall": 0.68056,
            "fmeasure": 0.69244
        },
        "nist": 4.736258204190636,
        "bleurt": 0.22266,
        "bertscore": {
            "precision": 0.95181,
            "recall": 0.9409,
            "f1": 0.94032
        },
        "nubia": {
            "semantic_relation": 4.30547,
            "contradiction": 0.56132,
            "irrelevancy": 19.02283,
            "logical_agreement": 80.41585,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.39955,
            "nubia_score": 0.75753
        },
        "meteor": 0.40902156846734844
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.163856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.44110631094643166,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.13652573434569687,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.22636,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.48333,
            "recall": 0.57524,
            "fmeasure": 0.5159
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.1993,
            "fmeasure": 0.17378
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.3181,
            "fmeasure": 0.28497
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.3181,
            "fmeasure": 0.28497
        },
        "nist": 2.1313355458663334,
        "bleurt": -0.18289,
        "bertscore": {
            "precision": 0.82546,
            "recall": 0.87468,
            "f1": 0.84936
        },
        "nubia": {
            "semantic_relation": 3.99988,
            "contradiction": 0.07608,
            "irrelevancy": 99.75433,
            "logical_agreement": 0.16959,
            "grammar_ref": 4.57081,
            "grammar_hyp": 4.14436,
            "nubia_score": 0.7323
        },
        "meteor": 0.30007621894931374
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.33573,
        "local_recall": {
            "1": 0,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.55556,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.125,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.22222,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.22222,
            "fmeasure": 0.26667
        },
        "nist": 0.6304149766941763,
        "bleurt": 0.00942,
        "bertscore": {
            "precision": 0.78067,
            "recall": 0.76674,
            "f1": 0.77364
        },
        "nubia": {
            "semantic_relation": 4.02683,
            "contradiction": 3.15839,
            "irrelevancy": 22.2673,
            "logical_agreement": 74.57432,
            "grammar_ref": 4.80739,
            "grammar_hyp": 4.13608,
            "nubia_score": 0.7704
        },
        "meteor": 0.23200981519179284
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 9.899494936611665,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 39,
        "unique-1": 30,
        "entropy-1": 5.147819704674176,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.37087049208299394,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 8.013876853447538,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.050340709546386,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.31275453232224987,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.84771,
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.967741935483871
        },
        "rouge1": {
            "precision": 0.77104,
            "recall": 0.9176,
            "fmeasure": 0.83654
        },
        "rouge2": {
            "precision": 0.49405,
            "recall": 0.62544,
            "fmeasure": 0.55142
        },
        "rougeL": {
            "precision": 0.67845,
            "recall": 0.8076,
            "fmeasure": 0.73667
        },
        "rougeLsum": {
            "precision": 0.67845,
            "recall": 0.8076,
            "fmeasure": 0.73667
        },
        "nist": 4.435156006790995,
        "bleurt": 0.22133,
        "bertscore": {
            "precision": 0.93693,
            "recall": 0.9538,
            "f1": 0.94527
        },
        "nubia": {
            "semantic_relation": 4.40591,
            "contradiction": 0.52595,
            "irrelevancy": 64.48793,
            "logical_agreement": 34.98611,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.78874,
            "nubia_score": 0.81011
        },
        "meteor": 0.495921998870017
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.46697,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "nist": 2.6017006625380596,
        "bleurt": -0.11575,
        "bertscore": {
            "precision": 0.89081,
            "recall": 0.92678,
            "f1": 0.90844
        },
        "nubia": {
            "semantic_relation": 4.27352,
            "contradiction": 6.06656,
            "irrelevancy": 34.69403,
            "logical_agreement": 59.23942,
            "grammar_ref": 4.85143,
            "grammar_hyp": 5.53057,
            "nubia_score": 0.55699
        },
        "meteor": 0.4486121983053691
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4565647621309536,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.24009914803219046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.0167,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.91071,
            "fmeasure": 0.86413
        },
        "rougeL": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rougeLsum": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "nist": 4.026196058544812,
        "bleurt": 0.81116,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.99714,
            "f1": 0.99064
        },
        "nubia": {
            "semantic_relation": 4.96299,
            "contradiction": 0.14795,
            "irrelevancy": 3.49378,
            "logical_agreement": 96.35828,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.07239,
            "nubia_score": 0.98909
        },
        "meteor": 0.6108178404694528
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393865,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.211,
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92857,
            "fmeasure": 0.96154
        },
        "rouge2": {
            "precision": 0.93939,
            "recall": 0.87179,
            "fmeasure": 0.90278
        },
        "rougeL": {
            "precision": 0.93056,
            "recall": 0.86905,
            "fmeasure": 0.89744
        },
        "rougeLsum": {
            "precision": 0.93056,
            "recall": 0.86905,
            "fmeasure": 0.89744
        },
        "nist": 4.397844835611353,
        "bleurt": 0.7228,
        "bertscore": {
            "precision": 0.99485,
            "recall": 0.9876,
            "f1": 0.9912
        },
        "nubia": {
            "semantic_relation": 4.74767,
            "contradiction": 1.91921,
            "irrelevancy": 22.8732,
            "logical_agreement": 75.20758,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.83769,
            "nubia_score": 0.89738
        },
        "meteor": 0.5782089453357577
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 4.437059837324712,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.5373134328358209,
        "vocab_size-1": 36,
        "unique-1": 24,
        "entropy-1": 4.753041900143784,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 51,
        "unique-2": 39,
        "entropy-2": 5.596327542547537,
        "cond_entropy-2": 0.7996695973443204,
        "distinct-3": 0.8813559322033898,
        "vocab_size-3": 52,
        "unique-3": 45,
        "entropy-3": 5.6453549137686165,
        "cond_entropy-3": 0.040956346200907774,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.437059837324712,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5555555555555556,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.70784867824536,
        "distinct-2-nopunct": 0.8135593220338984,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.509761693429634,
        "cond_entropy-2-nopunct": 0.8201795402862825,
        "distinct-3-nopunct": 0.8909090909090909,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.563177895342839,
        "cond_entropy-3-nopunct": 0.04417120961736376,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.09488,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.803921568627451
        },
        "rouge1": {
            "precision": 0.8123,
            "recall": 0.80529,
            "fmeasure": 0.80667
        },
        "rouge2": {
            "precision": 0.64837,
            "recall": 0.64483,
            "fmeasure": 0.64463
        },
        "rougeL": {
            "precision": 0.79563,
            "recall": 0.78783,
            "fmeasure": 0.78962
        },
        "rougeLsum": {
            "precision": 0.79563,
            "recall": 0.78783,
            "fmeasure": 0.78962
        },
        "nist": 4.492443179212771,
        "bleurt": 0.51551,
        "bertscore": {
            "precision": 0.95535,
            "recall": 0.94732,
            "f1": 0.95119
        },
        "nubia": {
            "semantic_relation": 3.85973,
            "contradiction": 28.74806,
            "irrelevancy": 23.40522,
            "logical_agreement": 47.84671,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.16578,
            "nubia_score": 0.61459
        },
        "meteor": 0.439608526538526
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.583,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 0.64286,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.20513,
            "fmeasure": 0.24242
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.52381,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.52381,
            "fmeasure": 0.61111
        },
        "nist": 2.3142155788699523,
        "bleurt": 0.31679,
        "bertscore": {
            "precision": 0.93233,
            "recall": 0.89928,
            "f1": 0.91551
        },
        "nubia": {
            "semantic_relation": 4.59234,
            "contradiction": 0.48727,
            "irrelevancy": 0.60649,
            "logical_agreement": 98.90624,
            "grammar_ref": 4.18993,
            "grammar_hyp": 5.17477,
            "nubia_score": 0.78693
        },
        "meteor": 0.3470035400631017
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.48214285714285715,
        "vocab_size-1": 27,
        "unique-1": 14,
        "entropy-1": 4.478718707880676,
        "distinct-2": 0.660377358490566,
        "vocab_size-2": 35,
        "unique-2": 23,
        "entropy-2": 4.9632162090352585,
        "cond_entropy-2": 0.46998846606717515,
        "distinct-3": 0.74,
        "vocab_size-3": 37,
        "unique-3": 28,
        "entropy-3": 5.063465189601648,
        "cond_entropy-3": 0.10613123529806424,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.49019607843137253,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.345979449976506,
        "distinct-2-nopunct": 0.6458333333333334,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.782268229617391,
        "cond_entropy-2-nopunct": 0.4114848770271906,
        "distinct-3-nopunct": 0.7333333333333333,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.891418651692921,
        "cond_entropy-3-nopunct": 0.0922205956726211,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.71843,
        "local_recall": {
            "1": 0.7,
            "2": 0.3333333333333333,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.79367,
            "recall": 0.75592,
            "fmeasure": 0.76483
        },
        "rouge2": {
            "precision": 0.53671,
            "recall": 0.50623,
            "fmeasure": 0.51345
        },
        "rougeL": {
            "precision": 0.71469,
            "recall": 0.67772,
            "fmeasure": 0.68713
        },
        "rougeLsum": {
            "precision": 0.71469,
            "recall": 0.67772,
            "fmeasure": 0.68713
        },
        "nist": 4.806905966018058,
        "bleurt": 0.02219,
        "bertscore": {
            "precision": 0.93355,
            "recall": 0.92163,
            "f1": 0.92712
        },
        "nubia": {
            "semantic_relation": 4.3747,
            "contradiction": 0.65648,
            "irrelevancy": 45.4347,
            "logical_agreement": 53.90882,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.59229,
            "nubia_score": 0.7511
        },
        "meteor": 0.42140757052911954
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964168,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.0738,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.84615,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.66667,
            "fmeasure": 0.64
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.84615,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.84615,
            "fmeasure": 0.81481
        },
        "nist": 2.6536051641070806,
        "bleurt": 0.25957,
        "bertscore": {
            "precision": 0.92467,
            "recall": 0.95905,
            "f1": 0.94155
        },
        "nubia": {
            "semantic_relation": 3.9366,
            "contradiction": 0.07565,
            "irrelevancy": 99.77117,
            "logical_agreement": 0.15319,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.07136,
            "nubia_score": 0.88338
        },
        "meteor": 0.4409770071918785
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.73595,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "nist": 1.3321359956185042,
        "bleurt": 0.12593,
        "bertscore": {
            "precision": 0.92135,
            "recall": 0.89099,
            "f1": 0.90301
        },
        "nubia": {
            "semantic_relation": 2.7902,
            "contradiction": 12.34727,
            "irrelevancy": 85.81607,
            "logical_agreement": 1.83667,
            "grammar_ref": 5.49813,
            "grammar_hyp": 4.874,
            "nubia_score": 0.25648
        },
        "meteor": 0.22974091960993615
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.5625,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.30689059560851856,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.506890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.32903575502051413,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.57621,
        "local_recall": {
            "1": 0.5,
            "2": 0.2222222222222222,
            "3": 0.8823529411764706
        },
        "rouge1": {
            "precision": 0.71319,
            "recall": 0.76777,
            "fmeasure": 0.73147
        },
        "rouge2": {
            "precision": 0.4881,
            "recall": 0.61466,
            "fmeasure": 0.52338
        },
        "rougeL": {
            "precision": 0.63958,
            "recall": 0.75492,
            "fmeasure": 0.67571
        },
        "rougeLsum": {
            "precision": 0.63958,
            "recall": 0.75492,
            "fmeasure": 0.67571
        },
        "nist": 3.966054384034455,
        "bleurt": 0.47976,
        "bertscore": {
            "precision": 0.92335,
            "recall": 0.96372,
            "f1": 0.9428
        },
        "nubia": {
            "semantic_relation": 4.04991,
            "contradiction": 47.95674,
            "irrelevancy": 49.11493,
            "logical_agreement": 2.92833,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.6273,
            "nubia_score": 0.73004
        },
        "meteor": 0.46025669847032746
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.42096,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.86667,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.51852,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "nist": 2.9066733640678954,
        "bleurt": 0.54612,
        "bertscore": {
            "precision": 0.92701,
            "recall": 0.95814,
            "f1": 0.94232
        },
        "nubia": {
            "semantic_relation": 4.91061,
            "contradiction": 0.26067,
            "irrelevancy": 1.02487,
            "logical_agreement": 98.71446,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.12469,
            "nubia_score": 0.97214
        },
        "meteor": 0.4599797110107353
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064473,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.17961067210860202,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.70962,
        "local_recall": {
            "1": 0.0,
            "2": 0.375,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.64141,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.51282,
            "recall": 0.36975,
            "fmeasure": 0.42876
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.49123,
            "fmeasure": 0.55682
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.49123,
            "fmeasure": 0.55682
        },
        "nist": 2.442949554556624,
        "bleurt": 0.046,
        "bertscore": {
            "precision": 0.95609,
            "recall": 0.90756,
            "f1": 0.93119
        },
        "nubia": {
            "semantic_relation": 3.05176,
            "contradiction": 97.93874,
            "irrelevancy": 0.9729,
            "logical_agreement": 1.08836,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.52847,
            "nubia_score": 0.26231
        },
        "meteor": 0.29812142654985063
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 1.299038105676658,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.800310530134925,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.38080660289240265,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.09404458493507994,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.224744871391589,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.7439427079182686,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.114369445886754,
        "cond_entropy-2-nopunct": 0.4346473365206097,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.10742500144231229,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.85896,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4,
            "3": 0.76
        },
        "rouge1": {
            "precision": 0.67083,
            "recall": 0.71005,
            "fmeasure": 0.67607
        },
        "rouge2": {
            "precision": 0.47064,
            "recall": 0.47894,
            "fmeasure": 0.46194
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.68413,
            "fmeasure": 0.65298
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.68413,
            "fmeasure": 0.65298
        },
        "nist": 3.7084270874973115,
        "bleurt": 0.2755,
        "bertscore": {
            "precision": 0.92273,
            "recall": 0.93392,
            "f1": 0.9271
        },
        "nubia": {
            "semantic_relation": 4.00863,
            "contradiction": 0.6782,
            "irrelevancy": 68.62099,
            "logical_agreement": 30.70081,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.94269,
            "nubia_score": 0.70317
        },
        "meteor": 0.42161920731030755
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.6530437207411035,
        "bleurt": 0.9828,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.59039,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2,
            "fmeasure": 0.21053
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.27273,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.27273,
            "fmeasure": 0.28571
        },
        "nist": 1.9360262190260422,
        "bleurt": -0.54417,
        "bertscore": {
            "precision": 0.79738,
            "recall": 0.79261,
            "f1": 0.7949
        },
        "nubia": {
            "semantic_relation": 2.27266,
            "contradiction": 81.13699,
            "irrelevancy": 16.29642,
            "logical_agreement": 2.5666,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.89921,
            "nubia_score": 0.15851
        },
        "meteor": 0.2173333919152598
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.958353821370876,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.10674500480228635,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.900711588373535,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.08946698305503359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.52669,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.64444,
            "recall": 0.62536,
            "fmeasure": 0.62003
        },
        "rouge2": {
            "precision": 0.2642,
            "recall": 0.25131,
            "fmeasure": 0.25105
        },
        "rougeL": {
            "precision": 0.50278,
            "recall": 0.48535,
            "fmeasure": 0.48283
        },
        "rougeLsum": {
            "precision": 0.50278,
            "recall": 0.48535,
            "fmeasure": 0.48283
        },
        "nist": 3.644470803367836,
        "bleurt": -0.1234,
        "bertscore": {
            "precision": 0.92707,
            "recall": 0.90675,
            "f1": 0.9164
        },
        "nubia": {
            "semantic_relation": 4.0365,
            "contradiction": 3.88793,
            "irrelevancy": 55.52505,
            "logical_agreement": 40.58701,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.68549,
            "nubia_score": 0.64309
        },
        "meteor": 0.32357058408726874
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.450212064914749,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.546593564294937,
        "cond_entropy-2": 0.046930949929641676,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 23,
        "unique-3": 22,
        "entropy-3": 4.501629167387823,
        "cond_entropy-3": -0.03214388408660256,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.392747410448783,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.418295834054489,
        "cond_entropy-2-nopunct": 0.009522782580064101,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.368522527728204,
        "cond_entropy-3-nopunct": -0.08007633662931364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.47074,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.77576,
            "recall": 0.83413,
            "fmeasure": 0.80367
        },
        "rouge2": {
            "precision": 0.57619,
            "recall": 0.61966,
            "fmeasure": 0.59682
        },
        "rougeL": {
            "precision": 0.76465,
            "recall": 0.81349,
            "fmeasure": 0.78796
        },
        "rougeLsum": {
            "precision": 0.76465,
            "recall": 0.81349,
            "fmeasure": 0.78796
        },
        "nist": 3.9828918477592694,
        "bleurt": 0.52216,
        "bertscore": {
            "precision": 0.93499,
            "recall": 0.94302,
            "f1": 0.93899
        },
        "nubia": {
            "semantic_relation": 4.89197,
            "contradiction": 0.32917,
            "irrelevancy": 22.87803,
            "logical_agreement": 76.7928,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.47633,
            "nubia_score": 0.91824
        },
        "meteor": 0.4782746751232425
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.88827,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.66756,
            "fmeasure": 0.71292
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.47917,
            "fmeasure": 0.49462
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.459,
            "fmeasure": 0.48644
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.459,
            "fmeasure": 0.48644
        },
        "nist": 3.184708942997051,
        "bleurt": 0.39894,
        "bertscore": {
            "precision": 0.94738,
            "recall": 0.94049,
            "f1": 0.93959
        },
        "nubia": {
            "semantic_relation": 4.43722,
            "contradiction": 21.13762,
            "irrelevancy": 19.87984,
            "logical_agreement": 58.98255,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.32315,
            "nubia_score": 0.73696
        },
        "meteor": 0.37854228244832855
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 38.0,
        "std_pred_length": 0.0,
        "median_pred_length": 38.0,
        "min_pred_length": 38,
        "max_pred_length": 38,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.734512381750773,
        "distinct-2": 0.918918918918919,
        "vocab_size-2": 34,
        "unique-2": 31,
        "entropy-2": 5.047291203466791,
        "cond_entropy-2": 0.2838180820125474,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 34,
        "unique-3": 32,
        "entropy-3": 5.058813890331199,
        "cond_entropy-3": 0.01602719136891827,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 34.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 34,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.6534955617749425,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.2525339296888253,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.9375,
        "cond_entropy-3-nopunct": 0.018105880641546567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.80999,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.8333333333333334,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.64762,
            "recall": 0.86135,
            "fmeasure": 0.73929
        },
        "rouge2": {
            "precision": 0.44118,
            "recall": 0.59231,
            "fmeasure": 0.50565
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.63343,
            "fmeasure": 0.54363
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.63343,
            "fmeasure": 0.54363
        },
        "nist": 3.7458137776491984,
        "bleurt": -0.3009,
        "bertscore": {
            "precision": 0.89687,
            "recall": 0.944,
            "f1": 0.91983
        },
        "nubia": {
            "semantic_relation": 3.74069,
            "contradiction": 22.77246,
            "irrelevancy": 71.0364,
            "logical_agreement": 6.19114,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.99788,
            "nubia_score": 0.47329
        },
        "meteor": 0.44602144564435636
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.794653473544342,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.690116517593666,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.33856,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.59708,
            "fmeasure": 0.69075
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.49023,
            "fmeasure": 0.571
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.34119,
            "fmeasure": 0.39472
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.34119,
            "fmeasure": 0.39472
        },
        "nist": 1.8157081486822657,
        "bleurt": -0.14396,
        "bertscore": {
            "precision": 0.89698,
            "recall": 0.87686,
            "f1": 0.88681
        },
        "nubia": {
            "semantic_relation": 3.96695,
            "contradiction": 9.55806,
            "irrelevancy": 1.45686,
            "logical_agreement": 88.98509,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.25186,
            "nubia_score": 0.57118
        },
        "meteor": 0.343587055856617
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.07471,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.64133,
            "fmeasure": 0.57008
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2037,
            "fmeasure": 0.17778
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "nist": 2.355710589176038,
        "bleurt": 0.44036,
        "bertscore": {
            "precision": 0.91479,
            "recall": 0.93784,
            "f1": 0.92617
        },
        "nubia": {
            "semantic_relation": 4.41641,
            "contradiction": 0.08277,
            "irrelevancy": 5.98007,
            "logical_agreement": 93.93716,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.51199,
            "nubia_score": 0.85963
        },
        "meteor": 0.400724566671953
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.51582,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.56944,
            "fmeasure": 0.54359
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.13333,
            "fmeasure": 0.12121
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "nist": 2.0949385676221532,
        "bleurt": -0.04532,
        "bertscore": {
            "precision": 0.83661,
            "recall": 0.87925,
            "f1": 0.8574
        },
        "nubia": {
            "semantic_relation": 4.03033,
            "contradiction": 6.85329,
            "irrelevancy": 56.30165,
            "logical_agreement": 36.84506,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.99399,
            "nubia_score": 0.57323
        },
        "meteor": 0.3262776065014196
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411757,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.11768784439846627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.3311,
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.40278,
            "recall": 0.80556,
            "fmeasure": 0.53704
        },
        "rouge2": {
            "precision": 0.26087,
            "recall": 0.54545,
            "fmeasure": 0.35294
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.75,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.75,
            "fmeasure": 0.5
        },
        "nist": 1.7659027521135249,
        "bleurt": 0.01073,
        "bertscore": {
            "precision": 0.78601,
            "recall": 0.89635,
            "f1": 0.83722
        },
        "nubia": {
            "semantic_relation": 3.51792,
            "contradiction": 0.47848,
            "irrelevancy": 99.2636,
            "logical_agreement": 0.25791,
            "grammar_ref": 5.08958,
            "grammar_hyp": 2.89986,
            "nubia_score": 0.54995
        },
        "meteor": 0.3528555051434854
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 21.333333333333332,
        "std_pred_length": 8.576453553512405,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.8125,
        "vocab_size-1": 52,
        "unique-1": 47,
        "entropy-1": 5.495864648336088,
        "distinct-2": 1.0,
        "vocab_size-2": 61,
        "unique-2": 61,
        "entropy-2": 5.930737337562883,
        "cond_entropy-2": 0.3817172556666062,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.07275634243531406,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 8.16496580927726,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.448394345536402,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.832890014164737,
        "cond_entropy-2-nopunct": 0.4086270502110821,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.65091,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.23076923076923078,
            "3": 0.8292682926829268
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.683,
            "fmeasure": 0.70165
        },
        "rouge2": {
            "precision": 0.48831,
            "recall": 0.496,
            "fmeasure": 0.48897
        },
        "rougeL": {
            "precision": 0.55185,
            "recall": 0.55871,
            "fmeasure": 0.55213
        },
        "rougeLsum": {
            "precision": 0.55185,
            "recall": 0.55871,
            "fmeasure": 0.55213
        },
        "nist": 4.316949481678843,
        "bleurt": 0.09715,
        "bertscore": {
            "precision": 0.91267,
            "recall": 0.90528,
            "f1": 0.90505
        },
        "nubia": {
            "semantic_relation": 3.98169,
            "contradiction": 0.23897,
            "irrelevancy": 54.11617,
            "logical_agreement": 45.64487,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.24031,
            "nubia_score": 0.7028
        },
        "meteor": 0.40372774556354274
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 86.68779,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.69841,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nist": 3.0476314089081704,
        "bleurt": 0.30208,
        "bertscore": {
            "precision": 0.99092,
            "recall": 0.97079,
            "f1": 0.98075
        },
        "nubia": {
            "semantic_relation": 4.22675,
            "contradiction": 0.58601,
            "irrelevancy": 0.55339,
            "logical_agreement": 98.8606,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.5844,
            "nubia_score": 0.77636
        },
        "meteor": 0.5570133484098374
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.50281,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "nist": 3.2909179807127322,
        "bleurt": 0.60142,
        "bertscore": {
            "precision": 0.96394,
            "recall": 0.9737,
            "f1": 0.9688
        },
        "nubia": {
            "semantic_relation": 4.16782,
            "contradiction": 56.42182,
            "irrelevancy": 35.47333,
            "logical_agreement": 8.10484,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.07695,
            "nubia_score": 0.57888
        },
        "meteor": 0.4129577005372853
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.09636959855866797,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 67.42215,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.79762,
            "recall": 0.82963,
            "fmeasure": 0.80835
        },
        "rouge2": {
            "precision": 0.70513,
            "recall": 0.77976,
            "fmeasure": 0.7328
        },
        "rougeL": {
            "precision": 0.79762,
            "recall": 0.82963,
            "fmeasure": 0.80835
        },
        "rougeLsum": {
            "precision": 0.79762,
            "recall": 0.82963,
            "fmeasure": 0.80835
        },
        "nist": 4.455310479415575,
        "bleurt": 0.57306,
        "bertscore": {
            "precision": 0.95786,
            "recall": 0.95533,
            "f1": 0.95315
        },
        "nubia": {
            "semantic_relation": 4.50896,
            "contradiction": 18.76155,
            "irrelevancy": 16.95831,
            "logical_agreement": 64.28014,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.52965,
            "nubia_score": 0.81982
        },
        "meteor": 0.46716868871270956
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.51655,
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94872,
            "fmeasure": 0.90667
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.7381,
            "fmeasure": 0.70692
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "nist": 3.9024801311398734,
        "bleurt": -0.00284,
        "bertscore": {
            "precision": 0.98044,
            "recall": 0.97622,
            "f1": 0.97833
        },
        "nubia": {
            "semantic_relation": 4.16958,
            "contradiction": 0.28804,
            "irrelevancy": 50.15351,
            "logical_agreement": 49.55844,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.37029,
            "nubia_score": 0.72136
        },
        "meteor": 0.5319853951676884
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 3.82542,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.24074,
            "fmeasure": 0.30514
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.07692,
            "fmeasure": 0.09756
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.22222,
            "fmeasure": 0.27907
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.22222,
            "fmeasure": 0.27907
        },
        "nist": 0.9464913764780661,
        "bleurt": -0.58442,
        "bertscore": {
            "precision": 0.81478,
            "recall": 0.7978,
            "f1": 0.8055
        },
        "nubia": {
            "semantic_relation": 1.73344,
            "contradiction": 2.30398,
            "irrelevancy": 95.58841,
            "logical_agreement": 2.10762,
            "grammar_ref": 4.95946,
            "grammar_hyp": 5.36739,
            "nubia_score": 0.10383
        },
        "meteor": 0.1199289270096546
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 8.5,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.55954563450997,
        "distinct-2": 0.9032258064516129,
        "vocab_size-2": 28,
        "unique-2": 25,
        "entropy-2": 4.760647923290102,
        "cond_entropy-2": 0.16786670715745416,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": 0.11068123646483499,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.277613436819114,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.6338,
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.80672,
            "recall": 0.71801,
            "fmeasure": 0.75604
        },
        "rouge2": {
            "precision": 0.52431,
            "recall": 0.46648,
            "fmeasure": 0.49069
        },
        "rougeL": {
            "precision": 0.66947,
            "recall": 0.60903,
            "fmeasure": 0.63444
        },
        "rougeLsum": {
            "precision": 0.66947,
            "recall": 0.60903,
            "fmeasure": 0.63444
        },
        "nist": 4.209644179235616,
        "bleurt": -0.03245,
        "bertscore": {
            "precision": 0.90992,
            "recall": 0.88191,
            "f1": 0.89559
        },
        "nubia": {
            "semantic_relation": 4.47501,
            "contradiction": 0.27868,
            "irrelevancy": 26.06116,
            "logical_agreement": 73.66016,
            "grammar_ref": 6.00658,
            "grammar_hyp": 5.69461,
            "nubia_score": 0.85422
        },
        "meteor": 0.36921046229888127
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.87632,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.38431,
            "fmeasure": 0.45055
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.06845,
            "fmeasure": 0.0812
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.25621,
            "fmeasure": 0.30037
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.25621,
            "fmeasure": 0.30037
        },
        "nist": 0.8188756096871375,
        "bleurt": -0.12045,
        "bertscore": {
            "precision": 0.87483,
            "recall": 0.83173,
            "f1": 0.84911
        },
        "nubia": {
            "semantic_relation": 3.60252,
            "contradiction": 0.94543,
            "irrelevancy": 65.28369,
            "logical_agreement": 33.77088,
            "grammar_ref": 4.4151,
            "grammar_hyp": 6.05498,
            "nubia_score": 0.35671
        },
        "meteor": 0.15613004516269768
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8222222222222222,
        "vocab_size-1": 37,
        "unique-1": 32,
        "entropy-1": 5.085971707296554,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.2221256360759176,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.972834784489399,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.13550616686149175,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.72702,
        "local_recall": {
            "1": 0.0,
            "2": 0.3,
            "3": 0.6388888888888888
        },
        "rouge1": {
            "precision": 0.79798,
            "recall": 0.70988,
            "fmeasure": 0.73929
        },
        "rouge2": {
            "precision": 0.50686,
            "recall": 0.48282,
            "fmeasure": 0.48719
        },
        "rougeL": {
            "precision": 0.70034,
            "recall": 0.64074,
            "fmeasure": 0.65922
        },
        "rougeLsum": {
            "precision": 0.70034,
            "recall": 0.64074,
            "fmeasure": 0.65922
        },
        "nist": 3.5093722646088743,
        "bleurt": 0.17916,
        "bertscore": {
            "precision": 0.9382,
            "recall": 0.90595,
            "f1": 0.91543
        },
        "nubia": {
            "semantic_relation": 4.24892,
            "contradiction": 17.40272,
            "irrelevancy": 16.97369,
            "logical_agreement": 65.6236,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.8585,
            "nubia_score": 0.64852
        },
        "meteor": 0.33164736524464666
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660605,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.28662,
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.55238,
            "fmeasure": 0.60399
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.2967,
            "fmeasure": 0.32667
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.55238,
            "fmeasure": 0.60399
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.55238,
            "fmeasure": 0.60399
        },
        "nist": 2.470872572302499,
        "bleurt": -0.16326,
        "bertscore": {
            "precision": 0.85441,
            "recall": 0.84511,
            "f1": 0.84875
        },
        "nubia": {
            "semantic_relation": 4.62624,
            "contradiction": 0.23222,
            "irrelevancy": 1.86577,
            "logical_agreement": 97.902,
            "grammar_ref": 5.03823,
            "grammar_hyp": 5.01203,
            "nubia_score": 0.84974
        },
        "meteor": 0.3003207524315037
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.867976246918685,
        "bleurt": 0.73788,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.0002,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.76153,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.55267,
            "fmeasure": 0.60427
        },
        "rougeL": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "rougeLsum": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "nist": 3.0398761319201837,
        "bleurt": 0.43261,
        "bertscore": {
            "precision": 0.95573,
            "recall": 0.93158,
            "f1": 0.9435
        },
        "nubia": {
            "semantic_relation": 4.34275,
            "contradiction": 0.11339,
            "irrelevancy": 1.47731,
            "logical_agreement": 98.40931,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.85893,
            "nubia_score": 0.92287
        },
        "meteor": 0.41086177530149887
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.32517,
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.69841,
            "fmeasure": 0.71545
        },
        "rouge2": {
            "precision": 0.47368,
            "recall": 0.45,
            "fmeasure": 0.46154
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.38095,
            "fmeasure": 0.39024
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.38095,
            "fmeasure": 0.39024
        },
        "nist": 3.2954539846630717,
        "bleurt": -0.21326,
        "bertscore": {
            "precision": 0.89709,
            "recall": 0.89583,
            "f1": 0.89574
        },
        "nubia": {
            "semantic_relation": 3.11777,
            "contradiction": 89.54095,
            "irrelevancy": 5.59624,
            "logical_agreement": 4.86281,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.67087,
            "nubia_score": 0.36893
        },
        "meteor": 0.3649246384283472
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.82478,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.73846,
            "fmeasure": 0.77656
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.5119,
            "fmeasure": 0.54487
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.64274,
            "fmeasure": 0.67766
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.64274,
            "fmeasure": 0.67766
        },
        "nist": 3.8302145228411035,
        "bleurt": 0.4061,
        "bertscore": {
            "precision": 0.97507,
            "recall": 0.91595,
            "f1": 0.94459
        },
        "nubia": {
            "semantic_relation": 4.81956,
            "contradiction": 0.3267,
            "irrelevancy": 0.52077,
            "logical_agreement": 99.15253,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.51816,
            "nubia_score": 0.91197
        },
        "meteor": 0.40195307296036104
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.30393,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.72807,
            "fmeasure": 0.74762
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.5037,
            "fmeasure": 0.51717
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.53289,
            "fmeasure": 0.54643
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.53289,
            "fmeasure": 0.54643
        },
        "nist": 2.489870649457386,
        "bleurt": -0.13132,
        "bertscore": {
            "precision": 0.88689,
            "recall": 0.81338,
            "f1": 0.84795
        },
        "nubia": {
            "semantic_relation": 4.23324,
            "contradiction": 0.08035,
            "irrelevancy": 5.78534,
            "logical_agreement": 94.1343,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.02563,
            "nubia_score": 0.83932
        },
        "meteor": 0.36462415670739146
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.78843,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.83135,
            "fmeasure": 0.8121
        },
        "rouge2": {
            "precision": 0.64912,
            "recall": 0.67778,
            "fmeasure": 0.66013
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.78968,
            "fmeasure": 0.77507
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.78968,
            "fmeasure": 0.77507
        },
        "nist": 3.5347819057941297,
        "bleurt": 0.09027,
        "bertscore": {
            "precision": 0.92732,
            "recall": 0.93692,
            "f1": 0.9321
        },
        "nubia": {
            "semantic_relation": 4.08256,
            "contradiction": 0.16688,
            "irrelevancy": 66.41107,
            "logical_agreement": 33.42205,
            "grammar_ref": 3.89472,
            "grammar_hyp": 4.72312,
            "nubia_score": 0.64547
        },
        "meteor": 0.4194023265285353
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 31.0,
        "std_pred_length": 0.0,
        "median_pred_length": 31.0,
        "min_pred_length": 31,
        "max_pred_length": 31,
        "distinct-1": 0.8064516129032258,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.502583407161069,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.35269428522164303,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": 0.020055916760432793,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 30.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 30,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.440223928941852,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.3648835029673293,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": 0.0208024983586036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.59012,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.68889,
            "recall": 0.76543,
            "fmeasure": 0.72515
        },
        "rouge2": {
            "precision": 0.57471,
            "recall": 0.64103,
            "fmeasure": 0.60606
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.76543,
            "fmeasure": 0.72515
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.76543,
            "fmeasure": 0.72515
        },
        "nist": 3.458287319649081,
        "bleurt": 0.04744,
        "bertscore": {
            "precision": 0.92767,
            "recall": 0.93852,
            "f1": 0.93307
        },
        "nubia": {
            "semantic_relation": 4.30195,
            "contradiction": 0.09864,
            "irrelevancy": 1.06625,
            "logical_agreement": 98.83511,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.18852,
            "nubia_score": 0.76251
        },
        "meteor": 0.4155782563686787
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.60039,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.85458,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.45833,
            "fmeasure": 0.38562
        },
        "rougeL": {
            "precision": 0.53968,
            "recall": 0.72941,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.53968,
            "recall": 0.72941,
            "fmeasure": 0.61988
        },
        "nist": 3.540164333868083,
        "bleurt": 0.28372,
        "bertscore": {
            "precision": 0.90612,
            "recall": 0.93755,
            "f1": 0.92091
        },
        "nubia": {
            "semantic_relation": 4.49176,
            "contradiction": 5.4189,
            "irrelevancy": 48.87754,
            "logical_agreement": 45.70355,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.61734,
            "nubia_score": 0.86416
        },
        "meteor": 0.44850240944907965
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.6197,
        "local_recall": {
            "1": 0.8,
            "2": 0.42857142857142855,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.7453,
            "fmeasure": 0.72698
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.2381,
            "fmeasure": 0.22527
        },
        "rougeL": {
            "precision": 0.31111,
            "recall": 0.40456,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.31111,
            "recall": 0.40456,
            "fmeasure": 0.34921
        },
        "nist": 3.826979175425021,
        "bleurt": 0.01883,
        "bertscore": {
            "precision": 0.89142,
            "recall": 0.88242,
            "f1": 0.8869
        },
        "nubia": {
            "semantic_relation": 4.39649,
            "contradiction": 0.08928,
            "irrelevancy": 64.51509,
            "logical_agreement": 35.39563,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.07467,
            "nubia_score": 0.8408
        },
        "meteor": 0.3307200509072622
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.088779347361362,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.15446975243603325,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.932138039759373,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.07482944545381268,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.047238912308487487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.65026,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "rouge2": {
            "precision": 0.36905,
            "recall": 0.45899,
            "fmeasure": 0.40384
        },
        "rougeL": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "rougeLsum": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "nist": 2.622764927150191,
        "bleurt": 0.3509,
        "bertscore": {
            "precision": 0.91502,
            "recall": 0.93272,
            "f1": 0.92316
        },
        "nubia": {
            "semantic_relation": 4.68873,
            "contradiction": 0.12825,
            "irrelevancy": 50.13221,
            "logical_agreement": 49.73954,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.25087,
            "nubia_score": 0.89744
        },
        "meteor": 0.39649237666101833
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9615384615384616,
        "vocab_size-1": 25,
        "unique-1": 24,
        "entropy-1": 4.623516641218013,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.023416471633632502,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.02677875348937534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.37205,
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.52174,
            "recall": 0.88081,
            "fmeasure": 0.65222
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.53333,
            "fmeasure": 0.38426
        },
        "rougeL": {
            "precision": 0.49275,
            "recall": 0.83636,
            "fmeasure": 0.61713
        },
        "rougeLsum": {
            "precision": 0.49275,
            "recall": 0.83636,
            "fmeasure": 0.61713
        },
        "nist": 2.9121271693617197,
        "bleurt": 0.06641,
        "bertscore": {
            "precision": 0.86616,
            "recall": 0.93917,
            "f1": 0.90119
        },
        "nubia": {
            "semantic_relation": 4.46578,
            "contradiction": 0.32521,
            "irrelevancy": 43.06135,
            "logical_agreement": 56.61344,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.6999,
            "nubia_score": 0.46674
        },
        "meteor": 0.41269640850771794
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 26.54762,
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.47059,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.35294,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.35294,
            "fmeasure": 0.42857
        },
        "nist": 1.5415400784954403,
        "bleurt": 0.10314,
        "bertscore": {
            "precision": 0.91271,
            "recall": 0.85471,
            "f1": 0.88276
        },
        "nubia": {
            "semantic_relation": 2.79502,
            "contradiction": 40.83041,
            "irrelevancy": 6.63763,
            "logical_agreement": 52.53196,
            "grammar_ref": 4.28272,
            "grammar_hyp": 3.96172,
            "nubia_score": 0.32803
        },
        "meteor": 0.24818063453983968
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.08389415539832848,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.24983,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.88736,
            "fmeasure": 0.76109
        },
        "rouge2": {
            "precision": 0.38235,
            "recall": 0.51923,
            "fmeasure": 0.44023
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.7033,
            "fmeasure": 0.60282
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.7033,
            "fmeasure": 0.60282
        },
        "nist": 2.697051046704942,
        "bleurt": -0.26776,
        "bertscore": {
            "precision": 0.87411,
            "recall": 0.91322,
            "f1": 0.89324
        },
        "nubia": {
            "semantic_relation": 4.57807,
            "contradiction": 0.13899,
            "irrelevancy": 87.13529,
            "logical_agreement": 12.72572,
            "grammar_ref": 4.1674,
            "grammar_hyp": 5.51226,
            "nubia_score": 0.55951
        },
        "meteor": 0.3535672594709769
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.0,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.6388888888888888,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.263558599134236,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.7595728540165763,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339412,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 7.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.116236831992069,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.8333244646765081,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.24617,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.67992,
            "recall": 0.7662,
            "fmeasure": 0.71115
        },
        "rouge2": {
            "precision": 0.39493,
            "recall": 0.44165,
            "fmeasure": 0.4109
        },
        "rougeL": {
            "precision": 0.5928,
            "recall": 0.66435,
            "fmeasure": 0.61846
        },
        "rougeLsum": {
            "precision": 0.5928,
            "recall": 0.66435,
            "fmeasure": 0.61846
        },
        "nist": 2.8689212747599044,
        "bleurt": 0.3198,
        "bertscore": {
            "precision": 0.8998,
            "recall": 0.92382,
            "f1": 0.91156
        },
        "nubia": {
            "semantic_relation": 4.27438,
            "contradiction": 0.64374,
            "irrelevancy": 50.24513,
            "logical_agreement": 49.11114,
            "grammar_ref": 3.22845,
            "grammar_hyp": 2.64941,
            "nubia_score": 0.87776
        },
        "meteor": 0.3922234341972673
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.59452,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.83333,
            "fmeasure": 0.70924
        },
        "rouge2": {
            "precision": 0.48718,
            "recall": 0.68137,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.83333,
            "fmeasure": 0.70924
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.83333,
            "fmeasure": 0.70924
        },
        "nist": 3.047952625392786,
        "bleurt": 0.02341,
        "bertscore": {
            "precision": 0.88422,
            "recall": 0.97406,
            "f1": 0.92697
        },
        "nubia": {
            "semantic_relation": 4.06737,
            "contradiction": 0.05979,
            "irrelevancy": 66.65112,
            "logical_agreement": 33.28909,
            "grammar_ref": 4.62828,
            "grammar_hyp": 5.2412,
            "nubia_score": 0.61344
        },
        "meteor": 0.5431954619825489
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.42516,
        "local_recall": {
            "1": 0.2,
            "2": 0.3684210526315789,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73889,
            "recall": 0.67668,
            "fmeasure": 0.70278
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.32857,
            "fmeasure": 0.34302
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.46086,
            "fmeasure": 0.51071
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.46086,
            "fmeasure": 0.51071
        },
        "nist": 2.9682069740800117,
        "bleurt": 0.28901,
        "bertscore": {
            "precision": 0.92061,
            "recall": 0.89312,
            "f1": 0.90665
        },
        "nubia": {
            "semantic_relation": 4.2055,
            "contradiction": 4.42534,
            "irrelevancy": 63.70272,
            "logical_agreement": 31.87194,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.58359,
            "nubia_score": 0.58958
        },
        "meteor": 0.3247297484416705
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.88419,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.65556,
            "fmeasure": 0.6661
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.51732,
            "fmeasure": 0.52998
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.65556,
            "fmeasure": 0.6661
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.65556,
            "fmeasure": 0.6661
        },
        "nist": 2.5048693478247257,
        "bleurt": -0.214,
        "bertscore": {
            "precision": 0.84454,
            "recall": 0.91377,
            "f1": 0.87779
        },
        "nubia": {
            "semantic_relation": 3.06064,
            "contradiction": 62.20636,
            "irrelevancy": 37.31313,
            "logical_agreement": 0.48051,
            "grammar_ref": 4.44297,
            "grammar_hyp": 5.73214,
            "nubia_score": 0.19992
        },
        "meteor": 0.37436754545945555
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 4.5,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.37355726227518526,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.440223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.4004643264490856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.58489,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.73148,
            "recall": 0.89061,
            "fmeasure": 0.79408
        },
        "rouge2": {
            "precision": 0.541,
            "recall": 0.66501,
            "fmeasure": 0.58831
        },
        "rougeL": {
            "precision": 0.73148,
            "recall": 0.89061,
            "fmeasure": 0.79408
        },
        "rougeLsum": {
            "precision": 0.73148,
            "recall": 0.89061,
            "fmeasure": 0.79408
        },
        "nist": 3.431004441957639,
        "bleurt": 0.17332,
        "bertscore": {
            "precision": 0.93258,
            "recall": 0.94762,
            "f1": 0.93968
        },
        "nubia": {
            "semantic_relation": 4.12398,
            "contradiction": 24.66806,
            "irrelevancy": 72.23646,
            "logical_agreement": 3.09548,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.9731,
            "nubia_score": 0.69082
        },
        "meteor": 0.45581101582866185
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 59.46036,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.63492,
            "fmeasure": 0.66964
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.52083,
            "fmeasure": 0.54762
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.57937,
            "fmeasure": 0.60714
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.57937,
            "fmeasure": 0.60714
        },
        "nist": 3.288433235432248,
        "bleurt": 0.48243,
        "bertscore": {
            "precision": 0.955,
            "recall": 0.94223,
            "f1": 0.94775
        },
        "nubia": {
            "semantic_relation": 3.84322,
            "contradiction": 0.25768,
            "irrelevancy": 50.17496,
            "logical_agreement": 49.56736,
            "grammar_ref": 4.8549,
            "grammar_hyp": 4.99286,
            "nubia_score": 0.6666
        },
        "meteor": 0.4349301492287381
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.6682958340544896,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091842,
        "cond_entropy-2": 0.3290145724615955,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887362,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.550340709546388,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.921928094887362,
        "cond_entropy-2-nopunct": 0.362496476250065,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 73.33531,
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.8963,
            "fmeasure": 0.8627
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.76389,
            "fmeasure": 0.72904
        },
        "rougeL": {
            "precision": 0.80303,
            "recall": 0.87593,
            "fmeasure": 0.83651
        },
        "rougeLsum": {
            "precision": 0.80303,
            "recall": 0.87593,
            "fmeasure": 0.83651
        },
        "nist": 3.966408398768099,
        "bleurt": 0.70264,
        "bertscore": {
            "precision": 0.95044,
            "recall": 0.9673,
            "f1": 0.95872
        },
        "nubia": {
            "semantic_relation": 4.98362,
            "contradiction": 0.60283,
            "irrelevancy": 1.16011,
            "logical_agreement": 98.23706,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.07851,
            "nubia_score": 0.87735
        },
        "meteor": 0.6022939309987095
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.78571,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "nist": 3.273915542852983,
        "bleurt": 0.56444,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.30531,
            "contradiction": 0.13077,
            "irrelevancy": 33.52146,
            "logical_agreement": 66.34777,
            "grammar_ref": 5.27628,
            "grammar_hyp": 5.33569,
            "nubia_score": 0.8039
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.42347,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.27273,
            "fmeasure": 0.3
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "nist": 2.2096681043646837,
        "bleurt": 0.01717,
        "bertscore": {
            "precision": 0.89938,
            "recall": 0.87949,
            "f1": 0.88932
        },
        "nubia": {
            "semantic_relation": 3.93821,
            "contradiction": 0.10011,
            "irrelevancy": 99.7579,
            "logical_agreement": 0.14199,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.1183,
            "nubia_score": 0.6121
        },
        "meteor": 0.3432203599232642
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 2.4156844010247407,
        "bleurt": 0.6432,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 20.51175,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.85714,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.46154,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.5,
            "fmeasure": 0.46667
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.5,
            "fmeasure": 0.46667
        },
        "nist": 2.868308696276671,
        "bleurt": 0.27299,
        "bertscore": {
            "precision": 0.93429,
            "recall": 0.94227,
            "f1": 0.93827
        },
        "nubia": {
            "semantic_relation": 4.86433,
            "contradiction": 1.82853,
            "irrelevancy": 97.45179,
            "logical_agreement": 0.71968,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.13314,
            "nubia_score": 0.8558
        },
        "meteor": 0.44884291269404547
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.82727,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "nist": 2.8043533630124777,
        "bleurt": 0.39135,
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.92424,
            "f1": 0.94002
        },
        "nubia": {
            "semantic_relation": 4.8136,
            "contradiction": 0.69691,
            "irrelevancy": 56.12808,
            "logical_agreement": 43.17501,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.94905,
            "nubia_score": 0.99874
        },
        "meteor": 0.45626915779345323
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.098214829261011,
        "bleurt": 0.94053,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 2.8483609718589222,
        "bleurt": 0.96931,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 84.15565,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "rouge2": {
            "precision": 0.95,
            "recall": 0.875,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "nist": 3.926459146568544,
        "bleurt": 0.84989,
        "bertscore": {
            "precision": 0.99834,
            "recall": 0.98391,
            "f1": 0.99107
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18557,
            "irrelevancy": 0.52009,
            "logical_agreement": 99.29434,
            "grammar_ref": 4.75081,
            "grammar_hyp": 4.86853,
            "nubia_score": 0.98938
        },
        "meteor": 0.5623201842518945
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.95324,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.60769,
            "fmeasure": 0.56856
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.19444,
            "fmeasure": 0.17857
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.34231,
            "fmeasure": 0.32274
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.34231,
            "fmeasure": 0.32274
        },
        "nist": 2.4907793283138786,
        "bleurt": -0.53387,
        "bertscore": {
            "precision": 0.90756,
            "recall": 0.90736,
            "f1": 0.90746
        },
        "nubia": {
            "semantic_relation": 3.27828,
            "contradiction": 48.84302,
            "irrelevancy": 50.37019,
            "logical_agreement": 0.78678,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.21595,
            "nubia_score": 0.33884
        },
        "meteor": 0.31179211082668573
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029347,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.032143884086602556,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.90118,
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.6666666666666666,
            "3": 0.7307692307692307
        },
        "rouge1": {
            "precision": 0.92532,
            "recall": 0.7496,
            "fmeasure": 0.81604
        },
        "rouge2": {
            "precision": 0.75385,
            "recall": 0.61678,
            "fmeasure": 0.66773
        },
        "rougeL": {
            "precision": 0.84199,
            "recall": 0.69841,
            "fmeasure": 0.75301
        },
        "rougeLsum": {
            "precision": 0.84199,
            "recall": 0.69841,
            "fmeasure": 0.75301
        },
        "nist": 3.3623705756984705,
        "bleurt": 0.16158,
        "bertscore": {
            "precision": 0.93525,
            "recall": 0.92726,
            "f1": 0.9245
        },
        "nubia": {
            "semantic_relation": 4.22918,
            "contradiction": 37.51523,
            "irrelevancy": 8.32645,
            "logical_agreement": 54.15832,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.05748,
            "nubia_score": 0.53672
        },
        "meteor": 0.3718448895832309
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.9354838709677419,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.825164052322361,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": -0.027249798017923647,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660255,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.80776,
        "local_recall": {
            "1": 0.5,
            "2": 0.25,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.85836,
            "fmeasure": 0.8199
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.67949,
            "fmeasure": 0.65949
        },
        "rougeL": {
            "precision": 0.67857,
            "recall": 0.74573,
            "fmeasure": 0.71035
        },
        "rougeLsum": {
            "precision": 0.67857,
            "recall": 0.74573,
            "fmeasure": 0.71035
        },
        "nist": 4.300371290689134,
        "bleurt": 0.47994,
        "bertscore": {
            "precision": 0.94671,
            "recall": 0.95192,
            "f1": 0.94879
        },
        "nubia": {
            "semantic_relation": 4.61231,
            "contradiction": 0.21241,
            "irrelevancy": 46.21603,
            "logical_agreement": 53.57155,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.64759,
            "nubia_score": 0.83775
        },
        "meteor": 0.49561880498022665
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.482289237493326,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 28,
        "unique-2": 22,
        "entropy-2": 4.73452166477975,
        "cond_entropy-2": 0.19944850159394345,
        "distinct-3": 0.875,
        "vocab_size-3": 28,
        "unique-3": 24,
        "entropy-3": 4.75,
        "cond_entropy-3": 0.037537158749660626,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.438333513297848,
        "distinct-2-nopunct": 0.8064516129032258,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.567099536193328,
        "cond_entropy-2-nopunct": 0.13560864264132513,
        "distinct-3-nopunct": 0.8620689655172413,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.582118926162054,
        "cond_entropy-3-nopunct": 0.0072329606027659935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 69.37339,
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.9565217391304348
        },
        "rouge1": {
            "precision": 0.84872,
            "recall": 0.93106,
            "fmeasure": 0.88679
        },
        "rouge2": {
            "precision": 0.7712,
            "recall": 0.85164,
            "fmeasure": 0.80821
        },
        "rougeL": {
            "precision": 0.84872,
            "recall": 0.93106,
            "fmeasure": 0.88679
        },
        "rougeLsum": {
            "precision": 0.84872,
            "recall": 0.93106,
            "fmeasure": 0.88679
        },
        "nist": 4.460040680351823,
        "bleurt": 0.59356,
        "bertscore": {
            "precision": 0.97716,
            "recall": 0.98554,
            "f1": 0.98131
        },
        "nubia": {
            "semantic_relation": 4.58697,
            "contradiction": 39.8427,
            "irrelevancy": 33.69619,
            "logical_agreement": 26.46111,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.90085,
            "nubia_score": 0.8676
        },
        "meteor": 0.5260751102731065
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 7.75806032459145,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.3676344862125935,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.1803771480971002,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 6.96419413859206,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.31923567775942,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.14162565205621974,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.68477,
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.80291,
            "recall": 0.68083,
            "fmeasure": 0.72796
        },
        "rouge2": {
            "precision": 0.50784,
            "recall": 0.45985,
            "fmeasure": 0.48111
        },
        "rougeL": {
            "precision": 0.77513,
            "recall": 0.6508,
            "fmeasure": 0.69911
        },
        "rougeLsum": {
            "precision": 0.77513,
            "recall": 0.6508,
            "fmeasure": 0.69911
        },
        "nist": 4.58203862628407,
        "bleurt": 0.14946,
        "bertscore": {
            "precision": 0.92532,
            "recall": 0.87918,
            "f1": 0.9012
        },
        "nubia": {
            "semantic_relation": 4.20595,
            "contradiction": 2.90958,
            "irrelevancy": 3.12003,
            "logical_agreement": 93.97039,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.63685,
            "nubia_score": 0.66829
        },
        "meteor": 0.39954963398848703
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 33.0,
        "std_pred_length": 0.0,
        "median_pred_length": 33.0,
        "min_pred_length": 33,
        "max_pred_length": 33,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6578823768686535,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.32294611508415483,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.04580368961312477,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 29.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.556088322639176,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.26204848057872737,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.05246741989413545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 72.68097,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.84,
            "fmeasure": 0.79245
        },
        "rougeL": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 0.86207,
            "recall": 0.96154,
            "fmeasure": 0.90909
        },
        "nist": 4.551504254137757,
        "bleurt": 0.72834,
        "bertscore": {
            "precision": 0.97878,
            "recall": 0.98665,
            "f1": 0.9827
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25247,
            "irrelevancy": 0.51348,
            "logical_agreement": 99.23406,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.57103,
            "nubia_score": 0.96954
        },
        "meteor": 0.571578962227484
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.5345,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "nist": 2.8441645853579183,
        "bleurt": 0.30287,
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        },
        "nubia": {
            "semantic_relation": 4.22765,
            "contradiction": 0.25393,
            "irrelevancy": 86.02728,
            "logical_agreement": 13.71879,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31451,
            "nubia_score": 0.76427
        },
        "meteor": 0.4505163353501177
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.81818,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "nist": 3.7224676484285957,
        "bleurt": 0.68577,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.65972,
            "irrelevancy": 2.65283,
            "logical_agreement": 91.68745,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.81914,
            "nubia_score": 0.8297
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.21860008985574886,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.17961067210860202,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.58221,
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.5676,
            "fmeasure": 0.51754
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.26111,
            "fmeasure": 0.22646
        },
        "rougeL": {
            "precision": 0.2381,
            "recall": 0.2838,
            "fmeasure": 0.25877
        },
        "rougeLsum": {
            "precision": 0.2381,
            "recall": 0.2838,
            "fmeasure": 0.25877
        },
        "nist": 2.1859019070055417,
        "bleurt": -0.09961,
        "bertscore": {
            "precision": 0.85268,
            "recall": 0.87053,
            "f1": 0.86017
        },
        "nubia": {
            "semantic_relation": 2.50826,
            "contradiction": 1.53792,
            "irrelevancy": 86.35515,
            "logical_agreement": 12.10692,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.46211,
            "nubia_score": 0.36438
        },
        "meteor": 0.28401316374609087
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 3.681787005729087,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.8085106382978723,
        "vocab_size-1": 38,
        "unique-1": 34,
        "entropy-1": 5.070442309078417,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.3139336760505687,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.963745994207334,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.3546232576219498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.57299,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.8108108108108109
        },
        "rouge1": {
            "precision": 0.80423,
            "recall": 0.73843,
            "fmeasure": 0.7663
        },
        "rouge2": {
            "precision": 0.6101,
            "recall": 0.53824,
            "fmeasure": 0.56954
        },
        "rougeL": {
            "precision": 0.72354,
            "recall": 0.65578,
            "fmeasure": 0.68481
        },
        "rougeLsum": {
            "precision": 0.72354,
            "recall": 0.65578,
            "fmeasure": 0.68481
        },
        "nist": 4.253722717504658,
        "bleurt": 0.14449,
        "bertscore": {
            "precision": 0.93607,
            "recall": 0.9213,
            "f1": 0.92649
        },
        "nubia": {
            "semantic_relation": 3.9744,
            "contradiction": 0.20576,
            "irrelevancy": 2.24112,
            "logical_agreement": 97.55312,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.61824,
            "nubia_score": 0.71223
        },
        "meteor": 0.39632251729946216
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 23,
        "unique-1": 15,
        "entropy-1": 4.392582755590972,
        "distinct-2": 0.8709677419354839,
        "vocab_size-2": 27,
        "unique-2": 23,
        "entropy-2": 4.696131794257844,
        "cond_entropy-2": 0.28108525568412956,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 27,
        "unique-3": 25,
        "entropy-3": 4.720049960644813,
        "cond_entropy-3": 0.04171571922345565,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.324848729602135,
        "distinct-2-nopunct": 0.8620689655172413,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.582118926162054,
        "cond_entropy-2-nopunct": 0.26619071937266037,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.606739354015323,
        "cond_entropy-3-nopunct": 0.045054655184044716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.93185,
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.2857142857142857,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.50408,
            "recall": 0.68086,
            "fmeasure": 0.57286
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.49845,
            "fmeasure": 0.41353
        },
        "rougeL": {
            "precision": 0.48135,
            "recall": 0.64332,
            "fmeasure": 0.54455
        },
        "rougeLsum": {
            "precision": 0.48135,
            "recall": 0.64332,
            "fmeasure": 0.54455
        },
        "nist": 3.222831458595095,
        "bleurt": -0.02947,
        "bertscore": {
            "precision": 0.86914,
            "recall": 0.9021,
            "f1": 0.8853
        },
        "nubia": {
            "semantic_relation": 3.79346,
            "contradiction": 1.29085,
            "irrelevancy": 50.05694,
            "logical_agreement": 48.6522,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.36086,
            "nubia_score": 0.64193
        },
        "meteor": 0.3800393113049751
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.5,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.3565583354166755,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.2391641876977948,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.19041677634857931,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.19973,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.65801,
            "fmeasure": 0.66597
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.33578,
            "fmeasure": 0.34215
        },
        "rougeL": {
            "precision": 0.52917,
            "recall": 0.44753,
            "fmeasure": 0.47746
        },
        "rougeLsum": {
            "precision": 0.52917,
            "recall": 0.44753,
            "fmeasure": 0.47746
        },
        "nist": 3.106114703993042,
        "bleurt": 0.18659,
        "bertscore": {
            "precision": 0.92907,
            "recall": 0.93053,
            "f1": 0.9298
        },
        "nubia": {
            "semantic_relation": 3.64195,
            "contradiction": 0.64079,
            "irrelevancy": 5.18667,
            "logical_agreement": 94.17253,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.05659,
            "nubia_score": 0.61131
        },
        "meteor": 0.4060945418048424
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029344,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9629629629629629,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6808134280893965,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.031031312388743966,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.2298,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.88
        },
        "rouge1": {
            "precision": 0.86895,
            "recall": 0.80548,
            "fmeasure": 0.83435
        },
        "rouge2": {
            "precision": 0.68137,
            "recall": 0.64956,
            "fmeasure": 0.66441
        },
        "rougeL": {
            "precision": 0.73932,
            "recall": 0.70757,
            "fmeasure": 0.72245
        },
        "rougeLsum": {
            "precision": 0.73932,
            "recall": 0.70757,
            "fmeasure": 0.72245
        },
        "nist": 3.9892908843117025,
        "bleurt": 0.50772,
        "bertscore": {
            "precision": 0.96492,
            "recall": 0.95541,
            "f1": 0.9593
        },
        "nubia": {
            "semantic_relation": 4.70491,
            "contradiction": 0.54294,
            "irrelevancy": 3.46219,
            "logical_agreement": 95.99487,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.64229,
            "nubia_score": 0.89374
        },
        "meteor": 0.4222190362324687
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "total_length": 139,
        "mean_pred_length": 27.8,
        "std_pred_length": 25.63123094976127,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 78,
        "distinct-1": 0.6618705035971223,
        "vocab_size-1": 92,
        "unique-1": 76,
        "entropy-1": 6.126623379256632,
        "distinct-2": 0.9029850746268657,
        "vocab_size-2": 121,
        "unique-2": 111,
        "entropy-2": 6.84512172423064,
        "cond_entropy-2": 0.6688860165627982,
        "distinct-3": 0.9534883720930233,
        "vocab_size-3": 123,
        "unique-3": 117,
        "entropy-3": 6.918203999609283,
        "cond_entropy-3": 0.08164690585258862,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 17.515707236649053,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.7818181818181819,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.208454713445994,
        "distinct-2-nopunct": 0.9238095238095239,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.561864565285161,
        "cond_entropy-2-nopunct": 0.36164342327149973,
        "distinct-3-nopunct": 0.94,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.523856189774739,
        "cond_entropy-3-nopunct": -0.04038932789139768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.90991,
        "local_recall": {
            "1": 0.0,
            "2": 0.803921568627451,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.6994,
            "recall": 0.78876,
            "fmeasure": 0.7355
        },
        "rouge2": {
            "precision": 0.5412,
            "recall": 0.61636,
            "fmeasure": 0.57127
        },
        "rougeL": {
            "precision": 0.63092,
            "recall": 0.70794,
            "fmeasure": 0.66154
        },
        "rougeLsum": {
            "precision": 0.63092,
            "recall": 0.70794,
            "fmeasure": 0.66154
        },
        "nist": 4.9805509154393,
        "bleurt": 0.20246,
        "bertscore": {
            "precision": 0.92683,
            "recall": 0.9497,
            "f1": 0.93785
        },
        "nubia": {
            "semantic_relation": 4.11109,
            "contradiction": 1.0984,
            "irrelevancy": 52.53598,
            "logical_agreement": 46.36562,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.81834,
            "nubia_score": 0.73253
        },
        "meteor": 0.49361820430308506
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 4.450162589830066,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.4778551095586415,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.31971753049182,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.4750413394224453,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.77053,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.63716,
            "recall": 0.67125,
            "fmeasure": 0.64083
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.34744,
            "fmeasure": 0.34796
        },
        "rougeL": {
            "precision": 0.4673,
            "recall": 0.48077,
            "fmeasure": 0.46486
        },
        "rougeLsum": {
            "precision": 0.4673,
            "recall": 0.48077,
            "fmeasure": 0.46486
        },
        "nist": 2.5383831954847036,
        "bleurt": -0.05528,
        "bertscore": {
            "precision": 0.88549,
            "recall": 0.8838,
            "f1": 0.88459
        },
        "nubia": {
            "semantic_relation": 4.05643,
            "contradiction": 10.16606,
            "irrelevancy": 38.77574,
            "logical_agreement": 51.0582,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.84064,
            "nubia_score": 0.74614
        },
        "meteor": 0.29999517509556006
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.9629629629629629,
        "vocab_size-1": 26,
        "unique-1": 25,
        "entropy-1": 4.6808134280893965,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.0224752929007004,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.02677875348937537,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.13879,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.73913,
            "recall": 0.75,
            "fmeasure": 0.7432
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.44622,
            "fmeasure": 0.42602
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.67778,
            "fmeasure": 0.67095
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.67778,
            "fmeasure": 0.67095
        },
        "nist": 3.6221620150837546,
        "bleurt": 0.16755,
        "bertscore": {
            "precision": 0.91239,
            "recall": 0.92057,
            "f1": 0.91646
        },
        "nubia": {
            "semantic_relation": 4.30981,
            "contradiction": 24.87688,
            "irrelevancy": 70.8516,
            "logical_agreement": 4.27151,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.40703,
            "nubia_score": 0.78146
        },
        "meteor": 0.38948018571098336
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 5.5,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044716,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.94117,
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.65336,
            "fmeasure": 0.64206
        },
        "rouge2": {
            "precision": 0.32633,
            "recall": 0.36966,
            "fmeasure": 0.34331
        },
        "rougeL": {
            "precision": 0.5463,
            "recall": 0.56415,
            "fmeasure": 0.54841
        },
        "rougeLsum": {
            "precision": 0.5463,
            "recall": 0.56415,
            "fmeasure": 0.54841
        },
        "nist": 3.804834078517283,
        "bleurt": 0.51704,
        "bertscore": {
            "precision": 0.91879,
            "recall": 0.92839,
            "f1": 0.92246
        },
        "nubia": {
            "semantic_relation": 4.46598,
            "contradiction": 6.63263,
            "irrelevancy": 8.31336,
            "logical_agreement": 85.05401,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.03987,
            "nubia_score": 0.75713
        },
        "meteor": 0.35637189644805395
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.681727678869737,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.1840175547660697,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.061400544664143256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.80689,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.87427,
            "fmeasure": 0.78358
        },
        "rougeL": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rougeLsum": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "nist": 3.8845712522117304,
        "bleurt": 0.40305,
        "bertscore": {
            "precision": 0.94963,
            "recall": 0.98839,
            "f1": 0.96862
        },
        "nubia": {
            "semantic_relation": 4.02249,
            "contradiction": 5.87379,
            "irrelevancy": 90.84886,
            "logical_agreement": 3.27735,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.93296,
            "nubia_score": 0.66863
        },
        "meteor": 0.5524065536515756
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 33.5,
        "std_pred_length": 2.5,
        "median_pred_length": 33.5,
        "min_pred_length": 31,
        "max_pred_length": 36,
        "distinct-1": 0.7611940298507462,
        "vocab_size-1": 51,
        "unique-1": 43,
        "entropy-1": 5.433158265732893,
        "distinct-2": 0.9846153846153847,
        "vocab_size-2": 64,
        "unique-2": 63,
        "entropy-2": 5.991598582259227,
        "cond_entropy-2": 0.5471458834409386,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.013341857782506145,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 30.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 30.5,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7704918032786885,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.301124682537201,
        "distinct-2-nopunct": 0.9830508474576272,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.848744744277091,
        "cond_entropy-2-nopunct": 0.5689628636051706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.01466531589885381,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.21485,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0,
            "3": 0.717948717948718
        },
        "rouge1": {
            "precision": 0.61656,
            "recall": 0.70084,
            "fmeasure": 0.65442
        },
        "rouge2": {
            "precision": 0.37442,
            "recall": 0.43991,
            "fmeasure": 0.40369
        },
        "rougeL": {
            "precision": 0.4727,
            "recall": 0.56527,
            "fmeasure": 0.51291
        },
        "rougeLsum": {
            "precision": 0.4727,
            "recall": 0.56527,
            "fmeasure": 0.51291
        },
        "nist": 4.313626402307032,
        "bleurt": 0.17245,
        "bertscore": {
            "precision": 0.89024,
            "recall": 0.90229,
            "f1": 0.89228
        },
        "nubia": {
            "semantic_relation": 3.61452,
            "contradiction": 50.05287,
            "irrelevancy": 2.33259,
            "logical_agreement": 47.61454,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.9283,
            "nubia_score": 0.57435
        },
        "meteor": 0.35021265876383284
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "nist": 2.456435556800404,
        "bleurt": 0.93658,
        "bertscore": {
            "precision": 0.986,
            "recall": 0.99497,
            "f1": 0.99047
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.0697,
            "irrelevancy": 0.59577,
            "logical_agreement": 98.33453,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.1752,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.55954563450997,
        "distinct-2": 0.8387096774193549,
        "vocab_size-2": 26,
        "unique-2": 21,
        "entropy-2": 4.631615665225586,
        "cond_entropy-2": 0.03883444909293795,
        "distinct-3": 0.896551724137931,
        "vocab_size-3": 26,
        "unique-3": 23,
        "entropy-3": 4.651084443403434,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.444187891679296,
        "distinct-2-nopunct": 0.8518518518518519,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.458591205867173,
        "cond_entropy-2-nopunct": -0.029019418890029347,
        "distinct-3-nopunct": 0.92,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.483856189774723,
        "cond_entropy-3-nopunct": -0.03103131238874396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.71763,
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.70098,
            "recall": 0.68306,
            "fmeasure": 0.6905
        },
        "rouge2": {
            "precision": 0.44886,
            "recall": 0.47492,
            "fmeasure": 0.45731
        },
        "rougeL": {
            "precision": 0.51471,
            "recall": 0.60167,
            "fmeasure": 0.5511
        },
        "rougeLsum": {
            "precision": 0.51471,
            "recall": 0.60167,
            "fmeasure": 0.5511
        },
        "nist": 3.671070094568652,
        "bleurt": -0.00761,
        "bertscore": {
            "precision": 0.92802,
            "recall": 0.92651,
            "f1": 0.92513
        },
        "nubia": {
            "semantic_relation": 4.65451,
            "contradiction": 0.64292,
            "irrelevancy": 23.19679,
            "logical_agreement": 76.16028,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.97191,
            "nubia_score": 0.88036
        },
        "meteor": 0.4204601658880015
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.47872969366552,
        "bleurt": 0.9148,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.398,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.53846,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2037,
            "fmeasure": 0.22353
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.38462,
            "fmeasure": 0.45455
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.38462,
            "fmeasure": 0.45455
        },
        "nist": 1.7261486371803938,
        "bleurt": -0.28081,
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.86531,
            "f1": 0.88931
        },
        "nubia": {
            "semantic_relation": 4.09766,
            "contradiction": 14.14997,
            "irrelevancy": 73.59059,
            "logical_agreement": 12.25944,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.83618,
            "nubia_score": 0.61823
        },
        "meteor": 0.26327612233306297
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 2.277608394786075,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 34,
        "unique-1": 24,
        "entropy-1": 4.856550038551168,
        "distinct-2": 0.9148936170212766,
        "vocab_size-2": 43,
        "unique-2": 39,
        "entropy-2": 5.384376085720193,
        "cond_entropy-2": 0.4270494772473506,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": 0.011210786745390874,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 1.920286436967152,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7111111111111111,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.789416641342189,
        "distinct-2-nopunct": 0.926829268292683,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.211210541203447,
        "cond_entropy-2-nopunct": 0.4659340418112579,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.012963503853998769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.93297,
        "local_recall": {
            "1": 0.3,
            "2": 0.3333333333333333,
            "3": 0.8055555555555556
        },
        "rouge1": {
            "precision": 0.79024,
            "recall": 0.77496,
            "fmeasure": 0.7628
        },
        "rouge2": {
            "precision": 0.67519,
            "recall": 0.67083,
            "fmeasure": 0.64802
        },
        "rougeL": {
            "precision": 0.79024,
            "recall": 0.77496,
            "fmeasure": 0.7628
        },
        "rougeLsum": {
            "precision": 0.79024,
            "recall": 0.77496,
            "fmeasure": 0.7628
        },
        "nist": 4.4807218357194625,
        "bleurt": 0.4309,
        "bertscore": {
            "precision": 0.94793,
            "recall": 0.95624,
            "f1": 0.94915
        },
        "nubia": {
            "semantic_relation": 4.68006,
            "contradiction": 8.70455,
            "irrelevancy": 32.85249,
            "logical_agreement": 58.44296,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.33751,
            "nubia_score": 0.83551
        },
        "meteor": 0.4762370843997975
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 36.0,
        "std_pred_length": 0.0,
        "median_pred_length": 36.0,
        "min_pred_length": 36,
        "max_pred_length": 36,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 25,
        "unique-1": 14,
        "entropy-1": 4.5588138903312005,
        "distinct-2": 0.8,
        "vocab_size-2": 28,
        "unique-2": 21,
        "entropy-2": 4.729283016944964,
        "cond_entropy-2": 0.18792944407408246,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 30,
        "unique-3": 26,
        "entropy-3": 4.852168723603279,
        "cond_entropy-3": 0.13465041254066692,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 30.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 30,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.306890595608518,
        "distinct-2-nopunct": 0.7931034482758621,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.444187891679296,
        "cond_entropy-2-nopunct": 0.15798695124319143,
        "distinct-3-nopunct": 0.8928571428571429,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.593069207771892,
        "cond_entropy-3-nopunct": 0.16365964121574647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 9.90362,
        "local_recall": {
            "1": 0.4,
            "2": 0.6,
            "3": 0.35
        },
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.45185,
            "fmeasure": 0.46426
        },
        "rouge2": {
            "precision": 0.15054,
            "recall": 0.14286,
            "fmeasure": 0.14621
        },
        "rougeL": {
            "precision": 0.26042,
            "recall": 0.24713,
            "fmeasure": 0.25297
        },
        "rougeLsum": {
            "precision": 0.26042,
            "recall": 0.24713,
            "fmeasure": 0.25297
        },
        "nist": 2.690780004902772,
        "bleurt": -0.481,
        "bertscore": {
            "precision": 0.79268,
            "recall": 0.75134,
            "f1": 0.77016
        },
        "nubia": {
            "semantic_relation": 3.03316,
            "contradiction": 12.49488,
            "irrelevancy": 16.21927,
            "logical_agreement": 71.28584,
            "grammar_ref": 5.53052,
            "grammar_hyp": 3.81832,
            "nubia_score": 0.63986
        },
        "meteor": 0.19102789176554902
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.5766176449086644,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.6306023492300306,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.25086,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9375,
            "recall": 1.0,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "nist": 3.6850099544647112,
        "bleurt": 0.66623,
        "bertscore": {
            "precision": 0.96362,
            "recall": 0.96971,
            "f1": 0.96666
        },
        "nubia": {
            "semantic_relation": 4.92011,
            "contradiction": 0.61901,
            "irrelevancy": 12.82002,
            "logical_agreement": 86.56097,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.73453,
            "nubia_score": 0.97673
        },
        "meteor": 0.5159842562220408
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.02369,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.4166666666666667
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "nist": 2.1274343891345255,
        "bleurt": 0.51696,
        "bertscore": {
            "precision": 0.8896,
            "recall": 0.91075,
            "f1": 0.90005
        },
        "nubia": {
            "semantic_relation": 4.88067,
            "contradiction": 0.95175,
            "irrelevancy": 9.9209,
            "logical_agreement": 89.12735,
            "grammar_ref": 4.23153,
            "grammar_hyp": 4.32201,
            "nubia_score": 0.9158
        },
        "meteor": 0.37718991160128096
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 11,
        "unique-2": 10,
        "entropy-2": 3.418295834054489,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": 0.056287299734322706,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.277613436819116,
        "cond_entropy-2-nopunct": -0.03462179117476821,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 10.29783,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.51282,
            "recall": 0.425,
            "fmeasure": 0.4647
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.24921,
            "fmeasure": 0.27445
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.38431,
            "fmeasure": 0.41905
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.38431,
            "fmeasure": 0.41905
        },
        "nist": 2.0122500297555286,
        "bleurt": -0.34563,
        "bertscore": {
            "precision": 0.87413,
            "recall": 0.77276,
            "f1": 0.81609
        },
        "nubia": {
            "semantic_relation": 2.5714,
            "contradiction": 2.41189,
            "irrelevancy": 97.33662,
            "logical_agreement": 0.2515,
            "grammar_ref": 4.68072,
            "grammar_hyp": 3.83544,
            "nubia_score": 0.30172
        },
        "meteor": 0.18130334691207742
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 56.81097,
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.84615,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "nist": 3.1459650141452595,
        "bleurt": 0.42948,
        "bertscore": {
            "precision": 0.94984,
            "recall": 0.98641,
            "f1": 0.95678
        },
        "nubia": {
            "semantic_relation": 4.55528,
            "contradiction": 0.19952,
            "irrelevancy": 34.31028,
            "logical_agreement": 65.4902,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.56337,
            "nubia_score": 0.77801
        },
        "meteor": 0.49467060723934386
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.004886164091841,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.4090762803319393,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.94626,
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.67708,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.48333,
            "fmeasure": 0.39247
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.67708,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.67708,
            "fmeasure": 0.5641
        },
        "nist": 2.5589368217961623,
        "bleurt": -0.22291,
        "bertscore": {
            "precision": 0.90466,
            "recall": 0.94917,
            "f1": 0.92638
        },
        "nubia": {
            "semantic_relation": 3.05486,
            "contradiction": 0.24565,
            "irrelevancy": 99.27359,
            "logical_agreement": 0.48076,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.72362,
            "nubia_score": 0.47802
        },
        "meteor": 0.4263821400554381
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 4,
        "entropy-1": 3.7516291673878226,
        "distinct-2": 0.6363636363636364,
        "vocab_size-2": 14,
        "unique-2": 6,
        "entropy-2": 3.7321588913645702,
        "cond_entropy-2": -0.03462179117476821,
        "distinct-3": 0.7,
        "vocab_size-3": 14,
        "unique-3": 8,
        "entropy-3": 3.721928094887362,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.65,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.621928094887362,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 0.7222222222222222,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.6143694458867563,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 81.15886,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9545454545454546
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.95455,
            "fmeasure": 0.95445
        },
        "rouge2": {
            "precision": 0.85354,
            "recall": 0.85,
            "fmeasure": 0.84962
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.95455,
            "fmeasure": 0.95445
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.95455,
            "fmeasure": 0.95445
        },
        "nist": 3.393093817790147,
        "bleurt": 0.46969,
        "bertscore": {
            "precision": 0.96673,
            "recall": 0.97237,
            "f1": 0.9693
        },
        "nubia": {
            "semantic_relation": 4.10722,
            "contradiction": 0.94858,
            "irrelevancy": 48.64353,
            "logical_agreement": 50.40788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.64346,
            "nubia_score": 0.7927
        },
        "meteor": 0.537770423073367
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 68.94026,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nist": 3.0881978509745025,
        "bleurt": 0.64449,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        },
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.490498678107601,
        "bleurt": 0.92254,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094907,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.18525,
        "local_recall": {
            "1": 0.5,
            "2": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.85797,
            "fmeasure": 0.77838
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.45581
        },
        "rougeL": {
            "precision": 0.61364,
            "recall": 0.71449,
            "fmeasure": 0.65285
        },
        "rougeLsum": {
            "precision": 0.61364,
            "recall": 0.71449,
            "fmeasure": 0.65285
        },
        "nist": 3.733534826556246,
        "bleurt": 0.02639,
        "bertscore": {
            "precision": 0.91937,
            "recall": 0.94964,
            "f1": 0.93426
        },
        "nubia": {
            "semantic_relation": 4.20933,
            "contradiction": 0.15777,
            "irrelevancy": 99.51941,
            "logical_agreement": 0.32282,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.29285,
            "nubia_score": 0.69852
        },
        "meteor": 0.41784362912226924
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 3.191786333700926,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.803921568627451,
        "vocab_size-1": 41,
        "unique-1": 36,
        "entropy-1": 5.196647645765805,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 46,
        "unique-2": 45,
        "entropy-2": 5.512035660188278,
        "cond_entropy-2": 0.18566696729104418,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.08181246906856265,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.5495097567963922,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8409090909090909,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.089780198035242,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.21911303891232498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.09644753788949417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.37425,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.16666666666666666,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.60703,
            "recall": 0.67606,
            "fmeasure": 0.60985
        },
        "rouge2": {
            "precision": 0.31582,
            "recall": 0.37788,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.52776,
            "recall": 0.60981,
            "fmeasure": 0.5399
        },
        "rougeLsum": {
            "precision": 0.52776,
            "recall": 0.60981,
            "fmeasure": 0.5399
        },
        "nist": 3.1718127872716733,
        "bleurt": 0.0569,
        "bertscore": {
            "precision": 0.88214,
            "recall": 0.8731,
            "f1": 0.87415
        },
        "nubia": {
            "semantic_relation": 3.8881,
            "contradiction": 1.68292,
            "irrelevancy": 29.54714,
            "logical_agreement": 68.76993,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.69381,
            "nubia_score": 0.65398
        },
        "meteor": 0.26810425654022685
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.784941827437642,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.5673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.5766176449086644,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.6306023492300307,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.26627,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.71053,
            "recall": 0.66544,
            "fmeasure": 0.68217
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.30842,
            "fmeasure": 0.31779
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.48529,
            "fmeasure": 0.50129
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.48529,
            "fmeasure": 0.50129
        },
        "nist": 3.6096164960595045,
        "bleurt": 0.43116,
        "bertscore": {
            "precision": 0.94952,
            "recall": 0.91409,
            "f1": 0.92037
        },
        "nubia": {
            "semantic_relation": 4.68374,
            "contradiction": 0.96011,
            "irrelevancy": 0.83656,
            "logical_agreement": 98.20333,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.96844,
            "nubia_score": 0.83385
        },
        "meteor": 0.3331924646230318
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.04514,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "rouge1": {
            "precision": 0.22222,
            "recall": 0.20513,
            "fmeasure": 0.21333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.19306,
            "fmeasure": 0.20598
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.19306,
            "fmeasure": 0.20598
        },
        "nist": 1.0676340391447454,
        "bleurt": -0.52876,
        "bertscore": {
            "precision": 0.73609,
            "recall": 0.73293,
            "f1": 0.7345
        },
        "nubia": {
            "semantic_relation": 1.7206,
            "contradiction": 23.35197,
            "irrelevancy": 69.19117,
            "logical_agreement": 7.45686,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.56427,
            "nubia_score": 0.12882
        },
        "meteor": 0.10613598673300165
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.95851,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.1875,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.41176,
            "fmeasure": 0.4375
        },
        "nist": 2.2027635479763847,
        "bleurt": -0.21676,
        "bertscore": {
            "precision": 0.8802,
            "recall": 0.87594,
            "f1": 0.87806
        },
        "nubia": {
            "semantic_relation": 2.60733,
            "contradiction": 99.51584,
            "irrelevancy": 0.37772,
            "logical_agreement": 0.10644,
            "grammar_ref": 3.64996,
            "grammar_hyp": 4.05573,
            "nubia_score": 0.27061
        },
        "meteor": 0.21523612979663512
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.97142,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35714,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.12821,
            "fmeasure": 0.15152
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "nist": 1.6449508967673327,
        "bleurt": -0.24248,
        "bertscore": {
            "precision": 0.77637,
            "recall": 0.78045,
            "f1": 0.7784
        },
        "nubia": {
            "semantic_relation": 3.10004,
            "contradiction": 0.35242,
            "irrelevancy": 99.20395,
            "logical_agreement": 0.44363,
            "grammar_ref": 3.90604,
            "grammar_hyp": 4.77201,
            "nubia_score": 0.31901
        },
        "meteor": 0.22774597660352036
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219521,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.905764584655453,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.67644,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.72303,
            "fmeasure": 0.76019
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.57734,
            "fmeasure": 0.56614
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.65497,
            "fmeasure": 0.64296
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.65497,
            "fmeasure": 0.64296
        },
        "nist": 4.315393113609542,
        "bleurt": 0.08664,
        "bertscore": {
            "precision": 0.92737,
            "recall": 0.93254,
            "f1": 0.92994
        },
        "nubia": {
            "semantic_relation": 4.2297,
            "contradiction": 3.09359,
            "irrelevancy": 63.05972,
            "logical_agreement": 33.84669,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.65255,
            "nubia_score": 0.7147
        },
        "meteor": 0.47483657534774015
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.315824333525707,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.3434164716336325,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.37338206403150886,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 55.70964,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.82609,
            "fmeasure": 0.80851
        },
        "rouge2": {
            "precision": 0.65217,
            "recall": 0.68182,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.82609,
            "fmeasure": 0.80851
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.82609,
            "fmeasure": 0.80851
        },
        "nist": 3.6023214828176005,
        "bleurt": 0.5893,
        "bertscore": {
            "precision": 0.94819,
            "recall": 0.97853,
            "f1": 0.96312
        },
        "nubia": {
            "semantic_relation": 4.45266,
            "contradiction": 0.30267,
            "irrelevancy": 7.30964,
            "logical_agreement": 92.38769,
            "grammar_ref": 4.20692,
            "grammar_hyp": 3.99446,
            "nubia_score": 0.84882
        },
        "meteor": 0.508588244008151
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.13455,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.71429,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.71429,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.71429,
            "fmeasure": 0.625
        },
        "nist": 1.8,
        "bleurt": 0.60407,
        "bertscore": {
            "precision": 0.90745,
            "recall": 0.94545,
            "f1": 0.92606
        },
        "nubia": {
            "semantic_relation": 4.9147,
            "contradiction": 0.15044,
            "irrelevancy": 92.31916,
            "logical_agreement": 7.53039,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.54928,
            "nubia_score": 1.0
        },
        "meteor": 0.37677903783484845
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.13953,
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "nist": 1.353289509199005,
        "bleurt": 0.02674,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        },
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "meteor": 0.2969362339094229
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.48019,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.21481,
            "fmeasure": 0.2792
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.57778,
            "fmeasure": 0.66263
        },
        "nist": 1.0840739693530494,
        "bleurt": -0.05999,
        "bertscore": {
            "precision": 0.93801,
            "recall": 0.91617,
            "f1": 0.92696
        },
        "nubia": {
            "semantic_relation": 4.12476,
            "contradiction": 6.37468,
            "irrelevancy": 4.30299,
            "logical_agreement": 89.32234,
            "grammar_ref": 7.45181,
            "grammar_hyp": 8.06495,
            "nubia_score": 0.64224
        },
        "meteor": 0.4011806382969706
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 3.0,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.10742500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.12121650651382439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 80.17494,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rouge2": {
            "precision": 0.84167,
            "recall": 0.85354,
            "fmeasure": 0.84585
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "nist": 3.980352302429953,
        "bleurt": 0.80221,
        "bertscore": {
            "precision": 0.98723,
            "recall": 0.99228,
            "f1": 0.98974
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.82427,
            "irrelevancy": 0.91292,
            "logical_agreement": 98.26281,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.10466,
            "nubia_score": 0.9183
        },
        "meteor": 0.5859552163896863
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 54.08439,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.74661,
            "fmeasure": 0.81931
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.58333,
            "fmeasure": 0.64412
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "nist": 3.2414851729709646,
        "bleurt": 0.49037,
        "bertscore": {
            "precision": 0.96632,
            "recall": 0.95761,
            "f1": 0.96195
        },
        "nubia": {
            "semantic_relation": 4.2138,
            "contradiction": 0.33094,
            "irrelevancy": 1.07867,
            "logical_agreement": 98.59039,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.73091,
            "nubia_score": 0.70856
        },
        "meteor": 0.47058904521438194
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.94175,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.64706,
            "recall": 0.57895,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.33333,
            "fmeasure": 0.35294
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.36842,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.36842,
            "fmeasure": 0.38889
        },
        "nist": 2.7879483765528805,
        "bleurt": 0.15787,
        "bertscore": {
            "precision": 0.90683,
            "recall": 0.8823,
            "f1": 0.89439
        },
        "nubia": {
            "semantic_relation": 4.03286,
            "contradiction": 0.21459,
            "irrelevancy": 1.40891,
            "logical_agreement": 98.3765,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.11249,
            "nubia_score": 0.59997
        },
        "meteor": 0.2870018200793545
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.773557262275185,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941852,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.043321469306228495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.3228,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.52306,
            "fmeasure": 0.53876
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.31313,
            "fmeasure": 0.32288
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.34119,
            "fmeasure": 0.35917
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.34119,
            "fmeasure": 0.35917
        },
        "nist": 1.8035208822491118,
        "bleurt": 0.20035,
        "bertscore": {
            "precision": 0.90673,
            "recall": 0.89716,
            "f1": 0.90192
        },
        "nubia": {
            "semantic_relation": 4.39823,
            "contradiction": 2.32477,
            "irrelevancy": 7.07888,
            "logical_agreement": 90.59635,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.80585,
            "nubia_score": 0.81006
        },
        "meteor": 0.2753664949203688
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.44814,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.70455,
            "recall": 0.69913,
            "fmeasure": 0.69974
        },
        "rouge2": {
            "precision": 0.52121,
            "recall": 0.53219,
            "fmeasure": 0.52515
        },
        "rougeL": {
            "precision": 0.70455,
            "recall": 0.69913,
            "fmeasure": 0.69974
        },
        "rougeLsum": {
            "precision": 0.70455,
            "recall": 0.69913,
            "fmeasure": 0.69974
        },
        "nist": 2.7633859571849655,
        "bleurt": 0.2775,
        "bertscore": {
            "precision": 0.92482,
            "recall": 0.91949,
            "f1": 0.91692
        },
        "nubia": {
            "semantic_relation": 4.13377,
            "contradiction": 19.74998,
            "irrelevancy": 47.47272,
            "logical_agreement": 32.7773,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.68408,
            "nubia_score": 0.5894
        },
        "meteor": 0.3783801382466318
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.0,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.815622570826659,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.17503453104812905,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.02496284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.6150610122030695,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.14171030866920953,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 71.43414,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.97368,
            "recall": 0.92,
            "fmeasure": 0.94406
        },
        "rouge2": {
            "precision": 0.85185,
            "recall": 0.81898,
            "fmeasure": 0.83423
        },
        "rougeL": {
            "precision": 0.79825,
            "recall": 0.76333,
            "fmeasure": 0.77894
        },
        "rougeLsum": {
            "precision": 0.79825,
            "recall": 0.76333,
            "fmeasure": 0.77894
        },
        "nist": 5.154118131900451,
        "bleurt": 0.66593,
        "bertscore": {
            "precision": 0.96901,
            "recall": 0.97629,
            "f1": 0.97262
        },
        "nubia": {
            "semantic_relation": 4.67173,
            "contradiction": 0.36063,
            "irrelevancy": 0.59955,
            "logical_agreement": 99.03981,
            "grammar_ref": 4.2058,
            "grammar_hyp": 3.88973,
            "nubia_score": 0.94289
        },
        "meteor": 0.5367666769772169
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 4.019950248448356,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 45,
        "unique-1": 32,
        "entropy-1": 5.275772059461482,
        "distinct-2": 0.8688524590163934,
        "vocab_size-2": 53,
        "unique-2": 46,
        "entropy-2": 5.6560670506421715,
        "cond_entropy-2": 0.25297482437820773,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 52,
        "unique-3": 48,
        "entropy-3": 5.664497779200466,
        "cond_entropy-3": 0.03295486131906561,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 3.9191835884530852,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.711864406779661,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.219602109043808,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.407574770641924,
        "cond_entropy-2-nopunct": 0.24936534125718793,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.369811884931536,
        "cond_entropy-3-nopunct": -0.002322811065332272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 66.26013,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.8043478260869565
        },
        "rouge1": {
            "precision": 0.8697,
            "recall": 0.79908,
            "fmeasure": 0.83115
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.71968,
            "fmeasure": 0.74598
        },
        "rougeL": {
            "precision": 0.81515,
            "recall": 0.75623,
            "fmeasure": 0.78315
        },
        "rougeLsum": {
            "precision": 0.81515,
            "recall": 0.75623,
            "fmeasure": 0.78315
        },
        "nist": 5.259046679299975,
        "bleurt": 0.33538,
        "bertscore": {
            "precision": 0.93579,
            "recall": 0.93557,
            "f1": 0.93539
        },
        "nubia": {
            "semantic_relation": 3.78025,
            "contradiction": 20.19498,
            "irrelevancy": 6.00277,
            "logical_agreement": 73.80226,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.93536,
            "nubia_score": 0.70024
        },
        "meteor": 0.487078534704016
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.12485,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.66138,
            "fmeasure": 0.68452
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "nist": 2.2366665738478613,
        "bleurt": 0.22673,
        "bertscore": {
            "precision": 0.923,
            "recall": 0.90472,
            "f1": 0.91377
        },
        "nubia": {
            "semantic_relation": 4.56022,
            "contradiction": 0.30787,
            "irrelevancy": 36.25219,
            "logical_agreement": 63.43994,
            "grammar_ref": 4.01433,
            "grammar_hyp": 4.18683,
            "nubia_score": 0.93016
        },
        "meteor": 0.4490582600386075
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.8037,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.68452,
            "fmeasure": 0.69841
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "nist": 3.218725846082821,
        "bleurt": 0.58344,
        "bertscore": {
            "precision": 0.98124,
            "recall": 0.97997,
            "f1": 0.97952
        },
        "nubia": {
            "semantic_relation": 4.68121,
            "contradiction": 0.23407,
            "irrelevancy": 0.60193,
            "logical_agreement": 99.164,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.22369,
            "nubia_score": 0.89839
        },
        "meteor": 0.5312513743477362
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.47882,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.75556,
            "recall": 0.7591,
            "fmeasure": 0.75575
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.64904,
            "fmeasure": 0.64444
        },
        "rougeL": {
            "precision": 0.75556,
            "recall": 0.7591,
            "fmeasure": 0.75575
        },
        "rougeLsum": {
            "precision": 0.75556,
            "recall": 0.7591,
            "fmeasure": 0.75575
        },
        "nist": 3.9137004048653803,
        "bleurt": 0.19514,
        "bertscore": {
            "precision": 0.95844,
            "recall": 0.93599,
            "f1": 0.92929
        },
        "nubia": {
            "semantic_relation": 4.05961,
            "contradiction": 16.63065,
            "irrelevancy": 70.11527,
            "logical_agreement": 13.25408,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.29422,
            "nubia_score": 0.69849
        },
        "meteor": 0.444374897151957
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.8372,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.44192,
            "fmeasure": 0.42874
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.19394,
            "fmeasure": 0.18759
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.44192,
            "fmeasure": 0.42874
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.44192,
            "fmeasure": 0.42874
        },
        "nist": 0.7880855767566562,
        "bleurt": -0.71581,
        "bertscore": {
            "precision": 0.74487,
            "recall": 0.80183,
            "f1": 0.7723
        },
        "nubia": {
            "semantic_relation": 2.74885,
            "contradiction": 0.14826,
            "irrelevancy": 99.63832,
            "logical_agreement": 0.21342,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.64557,
            "nubia_score": 0.4089
        },
        "meteor": 0.25652921877486906
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.08718,
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.68182,
            "fmeasure": 0.65217
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "nist": 2.9997292837160456,
        "bleurt": -0.17979,
        "bertscore": {
            "precision": 0.88097,
            "recall": 0.89407,
            "f1": 0.88747
        },
        "nubia": {
            "semantic_relation": 3.22419,
            "contradiction": 0.08178,
            "irrelevancy": 99.56479,
            "logical_agreement": 0.35343,
            "grammar_ref": 4.25346,
            "grammar_hyp": 3.90368,
            "nubia_score": 0.53738
        },
        "meteor": 0.32475256955519033
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.925938214656137,
        "bleurt": 0.92236,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.62106,
            "irrelevancy": 0.60577,
            "logical_agreement": 98.77318,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.78782,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 6.5,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.373551149096553,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.38654330543035226,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7407407407407407,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.162294909570877,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.4089686876112561,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.33853,
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 0.0,
            "3": 0.2647058823529412
        },
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.24078,
            "fmeasure": 0.33086
        },
        "rouge2": {
            "precision": 0.17544,
            "recall": 0.0777,
            "fmeasure": 0.10764
        },
        "rougeL": {
            "precision": 0.32083,
            "recall": 0.143,
            "fmeasure": 0.19734
        },
        "rougeLsum": {
            "precision": 0.32083,
            "recall": 0.143,
            "fmeasure": 0.19734
        },
        "nist": 0.1968226988827588,
        "bleurt": -0.59398,
        "bertscore": {
            "precision": 0.85398,
            "recall": 0.77364,
            "f1": 0.80972
        },
        "nubia": {
            "semantic_relation": 1.95393,
            "contradiction": 43.73313,
            "irrelevancy": 20.17529,
            "logical_agreement": 36.09158,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.96102,
            "nubia_score": 0.16517
        },
        "meteor": 0.12955891403834052
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7288135593220338,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.151096278874886,
        "distinct-2": 1.0,
        "vocab_size-2": 55,
        "unique-2": 55,
        "entropy-2": 5.7813597135246555,
        "cond_entropy-2": 0.5380122906851846,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.10893437155316402,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.142064087002289,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.5805020884219376,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.11783649029385802,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.41581,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6818181818181818,
            "3": 0.4864864864864865
        },
        "rouge1": {
            "precision": 0.71781,
            "recall": 0.61938,
            "fmeasure": 0.66174
        },
        "rouge2": {
            "precision": 0.53982,
            "recall": 0.48086,
            "fmeasure": 0.50716
        },
        "rougeL": {
            "precision": 0.59559,
            "recall": 0.52723,
            "fmeasure": 0.55612
        },
        "rougeLsum": {
            "precision": 0.59559,
            "recall": 0.52723,
            "fmeasure": 0.55612
        },
        "nist": 3.5038709009874354,
        "bleurt": 0.25639,
        "bertscore": {
            "precision": 0.90152,
            "recall": 0.87847,
            "f1": 0.88887
        },
        "nubia": {
            "semantic_relation": 3.2217,
            "contradiction": 40.17018,
            "irrelevancy": 10.18009,
            "logical_agreement": 49.64973,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.78918,
            "nubia_score": 0.49673
        },
        "meteor": 0.3041121133813054
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 9.463379711052259,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.6440677966101694,
        "vocab_size-1": 38,
        "unique-1": 28,
        "entropy-1": 4.95672456659759,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 52,
        "unique-2": 49,
        "entropy-2": 5.651017645233261,
        "cond_entropy-2": 0.6589871491022588,
        "distinct-3": 0.9622641509433962,
        "vocab_size-3": 51,
        "unique-3": 49,
        "entropy-3": 5.652448756449988,
        "cond_entropy-3": 0.01028039103698129,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 9.030811456096044,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6730769230769231,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.83275865124179,
        "distinct-2-nopunct": 0.9183673469387755,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.436038670601668,
        "cond_entropy-2-nopunct": 0.6359951867210609,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.43660543431788,
        "cond_entropy-3-nopunct": 0.012219231554053876,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 35.01429,
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.66883,
            "recall": 0.69384,
            "fmeasure": 0.64488
        },
        "rouge2": {
            "precision": 0.36178,
            "recall": 0.39463,
            "fmeasure": 0.36041
        },
        "rougeL": {
            "precision": 0.55417,
            "recall": 0.58304,
            "fmeasure": 0.54335
        },
        "rougeLsum": {
            "precision": 0.55417,
            "recall": 0.58304,
            "fmeasure": 0.54335
        },
        "nist": 3.5525254549263927,
        "bleurt": -0.12189,
        "bertscore": {
            "precision": 0.90831,
            "recall": 0.91668,
            "f1": 0.91189
        },
        "nubia": {
            "semantic_relation": 3.87722,
            "contradiction": 9.62433,
            "irrelevancy": 63.37951,
            "logical_agreement": 26.99616,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.61518,
            "nubia_score": 0.51037
        },
        "meteor": 0.3683903487583994
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 29.5,
        "std_pred_length": 8.5,
        "median_pred_length": 29.5,
        "min_pred_length": 21,
        "max_pred_length": 38,
        "distinct-1": 0.6440677966101694,
        "vocab_size-1": 38,
        "unique-1": 25,
        "entropy-1": 5.037315880193581,
        "distinct-2": 0.8771929824561403,
        "vocab_size-2": 50,
        "unique-2": 43,
        "entropy-2": 5.587275979077019,
        "cond_entropy-2": 0.5445329820121501,
        "distinct-3": 0.9454545454545454,
        "vocab_size-3": 52,
        "unique-3": 49,
        "entropy-3": 5.672268804433747,
        "cond_entropy-3": 0.09392424481446333,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 23.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.723404255319149,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.908535064941463,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.358519762996339,
        "cond_entropy-2-nopunct": 0.4564759774653769,
        "distinct-3-nopunct": 0.9767441860465116,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.379753126795121,
        "cond_entropy-3-nopunct": 0.027434914186376922,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 18.0336,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.8,
            "3": 0.5652173913043478
        },
        "rouge1": {
            "precision": 0.50316,
            "recall": 0.64713,
            "fmeasure": 0.55854
        },
        "rouge2": {
            "precision": 0.27153,
            "recall": 0.38398,
            "fmeasure": 0.31333
        },
        "rougeL": {
            "precision": 0.32416,
            "recall": 0.4996,
            "fmeasure": 0.38869
        },
        "rougeLsum": {
            "precision": 0.32416,
            "recall": 0.4996,
            "fmeasure": 0.38869
        },
        "nist": 3.365379168328805,
        "bleurt": 0.27816,
        "bertscore": {
            "precision": 0.86848,
            "recall": 0.91637,
            "f1": 0.89062
        },
        "nubia": {
            "semantic_relation": 4.10437,
            "contradiction": 0.21411,
            "irrelevancy": 75.10588,
            "logical_agreement": 24.68,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.36761,
            "nubia_score": 0.79392
        },
        "meteor": 0.31477974622858984
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960096,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 64.67686,
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.9,
            "fmeasure": 0.87805
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.68421,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.84127,
            "recall": 0.88333,
            "fmeasure": 0.86179
        },
        "rougeLsum": {
            "precision": 0.84127,
            "recall": 0.88333,
            "fmeasure": 0.86179
        },
        "nist": 4.967303022699003,
        "bleurt": 0.53032,
        "bertscore": {
            "precision": 0.9743,
            "recall": 0.98371,
            "f1": 0.97898
        },
        "nubia": {
            "semantic_relation": 4.62589,
            "contradiction": 59.63898,
            "irrelevancy": 38.73587,
            "logical_agreement": 1.62515,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.45382,
            "nubia_score": 0.81552
        },
        "meteor": 0.4844377510542316
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.39764,
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.78519,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.46841,
            "fmeasure": 0.49858
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.7,
            "fmeasure": 0.74762
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.7,
            "fmeasure": 0.74762
        },
        "nist": 1.8624225380190047,
        "bleurt": 0.37068,
        "bertscore": {
            "precision": 0.96535,
            "recall": 0.93889,
            "f1": 0.95193
        },
        "nubia": {
            "semantic_relation": 4.47539,
            "contradiction": 2.1921,
            "irrelevancy": 0.8557,
            "logical_agreement": 96.9522,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.92342,
            "nubia_score": 0.83127
        },
        "meteor": 0.4250259665043535
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.768492245572466,
        "bleurt": 0.97268,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.2238830957527498,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.589898095464287,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 7.47387,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.52083,
            "recall": 0.89167,
            "fmeasure": 0.65598
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.68254,
            "fmeasure": 0.48485
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.89167,
            "fmeasure": 0.65598
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.89167,
            "fmeasure": 0.65598
        },
        "nist": 1.6415414066556506,
        "bleurt": 0.23245,
        "bertscore": {
            "precision": 0.87362,
            "recall": 0.94266,
            "f1": 0.89317
        },
        "nubia": {
            "semantic_relation": 3.98801,
            "contradiction": 0.11025,
            "irrelevancy": 98.87366,
            "logical_agreement": 1.01608,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.53917,
            "nubia_score": 0.81175
        },
        "meteor": 0.4446233121300989
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 36.0,
        "std_pred_length": 0.0,
        "median_pred_length": 36.0,
        "min_pred_length": 36,
        "max_pred_length": 36,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.648955904159992,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.43806908699303887,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": 0.017003353717137487,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 31.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 31,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.607264455478377,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.24452386862709224,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": 0.0200559167604328,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 63.33747,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.95699,
            "recall": 0.90814,
            "fmeasure": 0.93188
        },
        "rouge2": {
            "precision": 0.75556,
            "recall": 0.71573,
            "fmeasure": 0.73506
        },
        "rougeL": {
            "precision": 0.73118,
            "recall": 0.69381,
            "fmeasure": 0.71197
        },
        "rougeLsum": {
            "precision": 0.73118,
            "recall": 0.69381,
            "fmeasure": 0.71197
        },
        "nist": 5.048892973832225,
        "bleurt": 0.49467,
        "bertscore": {
            "precision": 0.97975,
            "recall": 0.95494,
            "f1": 0.96719
        },
        "nubia": {
            "semantic_relation": 3.73731,
            "contradiction": 0.12672,
            "irrelevancy": 0.6081,
            "logical_agreement": 99.26519,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.17541,
            "nubia_score": 0.71434
        },
        "meteor": 0.4839537851454707
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.4677201004745006,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 46.82569,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.66138,
            "fmeasure": 0.70888
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.3635,
            "fmeasure": 0.4092
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.46667,
            "fmeasure": 0.56254
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.46667,
            "fmeasure": 0.56254
        },
        "nist": 2.6480557839832715,
        "bleurt": -0.225,
        "bertscore": {
            "precision": 0.90895,
            "recall": 0.86858,
            "f1": 0.8883
        },
        "nubia": {
            "semantic_relation": 3.01738,
            "contradiction": 0.11455,
            "irrelevancy": 99.18123,
            "logical_agreement": 0.70422,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.86454,
            "nubia_score": 0.54736
        },
        "meteor": 0.28423318731906977
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 2.7726341266023544,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 22,
        "distinct-1": 0.7101449275362319,
        "vocab_size-1": 49,
        "unique-1": 39,
        "entropy-1": 5.3443352400651145,
        "distinct-2": 0.9692307692307692,
        "vocab_size-2": 63,
        "unique-2": 61,
        "entropy-2": 5.960829351489997,
        "cond_entropy-2": 0.5044465247166845,
        "distinct-3": 1.0,
        "vocab_size-3": 61,
        "unique-3": 61,
        "entropy-3": 5.930737337562883,
        "cond_entropy-3": -0.026056704973765058,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8070175438596491,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.383598076016723,
        "distinct-2-nopunct": 0.9811320754716981,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.690184605506591,
        "cond_entropy-2-nopunct": 0.32162743048217063,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.09280244718268457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.26608,
        "local_recall": {
            "1": 0.175,
            "2": 0.2962962962962963,
            "3": 0.5862068965517241
        },
        "rouge1": {
            "precision": 0.5653,
            "recall": 0.47628,
            "fmeasure": 0.48236
        },
        "rouge2": {
            "precision": 0.30128,
            "recall": 0.2514,
            "fmeasure": 0.25355
        },
        "rougeL": {
            "precision": 0.35574,
            "recall": 0.37283,
            "fmeasure": 0.33657
        },
        "rougeLsum": {
            "precision": 0.35574,
            "recall": 0.37283,
            "fmeasure": 0.33657
        },
        "nist": 3.1792455476705683,
        "bleurt": -0.22315,
        "bertscore": {
            "precision": 0.85755,
            "recall": 0.83839,
            "f1": 0.83952
        },
        "nubia": {
            "semantic_relation": 3.57171,
            "contradiction": 0.9871,
            "irrelevancy": 67.17189,
            "logical_agreement": 31.84101,
            "grammar_ref": 5.44243,
            "grammar_hyp": 4.87928,
            "nubia_score": 0.52465
        },
        "meteor": 0.22127306746351016
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.5476190476190477,
        "vocab_size-1": 23,
        "unique-1": 12,
        "entropy-1": 4.279720852464461,
        "distinct-2": 0.8205128205128205,
        "vocab_size-2": 32,
        "unique-2": 28,
        "entropy-2": 4.83387297592797,
        "cond_entropy-2": 0.5178162826629823,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": 0.3736794624255309,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.044306775486763,
        "distinct-2-nopunct": 0.84375,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.5746987351738495,
        "cond_entropy-2-nopunct": 0.510018151211026,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": 0.21272969787065654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 51.18113,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.78889,
            "recall": 0.72682,
            "fmeasure": 0.755
        },
        "rouge2": {
            "precision": 0.60317,
            "recall": 0.56731,
            "fmeasure": 0.58349
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.62751,
            "fmeasure": 0.64556
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.62751,
            "fmeasure": 0.64556
        },
        "nist": 3.6067236666207734,
        "bleurt": 0.50115,
        "bertscore": {
            "precision": 0.92887,
            "recall": 0.92375,
            "f1": 0.92628
        },
        "nubia": {
            "semantic_relation": 4.1142,
            "contradiction": 16.29382,
            "irrelevancy": 17.09047,
            "logical_agreement": 66.6157,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.10795,
            "nubia_score": 0.73325
        },
        "meteor": 0.3909212230034104
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.87237,
        "local_recall": {
            "1": 0.0,
            "2": 0.47368421052631576
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.34565,
            "fmeasure": 0.43684
        },
        "rouge2": {
            "precision": 0.17857,
            "recall": 0.09718,
            "fmeasure": 0.12532
        },
        "rougeL": {
            "precision": 0.56667,
            "recall": 0.32391,
            "fmeasure": 0.41053
        },
        "rougeLsum": {
            "precision": 0.56667,
            "recall": 0.32391,
            "fmeasure": 0.41053
        },
        "nist": 0.8442747566668881,
        "bleurt": -0.24707,
        "bertscore": {
            "precision": 0.8595,
            "recall": 0.79708,
            "f1": 0.82708
        },
        "nubia": {
            "semantic_relation": 3.00175,
            "contradiction": 12.29489,
            "irrelevancy": 87.3202,
            "logical_agreement": 0.38491,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.37347,
            "nubia_score": 0.23222
        },
        "meteor": 0.23425550037052376
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 23.9761,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.42892,
            "fmeasure": 0.55282
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.26111,
            "fmeasure": 0.343
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.36765,
            "fmeasure": 0.47385
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.36765,
            "fmeasure": 0.47385
        },
        "nist": 0.6985400336115563,
        "bleurt": -0.08437,
        "bertscore": {
            "precision": 0.89305,
            "recall": 0.85996,
            "f1": 0.87619
        },
        "nubia": {
            "semantic_relation": 3.68431,
            "contradiction": 21.61204,
            "irrelevancy": 26.44381,
            "logical_agreement": 51.94416,
            "grammar_ref": 4.86284,
            "grammar_hyp": 6.40588,
            "nubia_score": 0.32504
        },
        "meteor": 0.23636632436805652
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.53478,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.38095238095238093
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.41806,
            "fmeasure": 0.57234
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.26182,
            "fmeasure": 0.36429
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "nist": 0.16916029185586146,
        "bleurt": 0.12432,
        "bertscore": {
            "precision": 0.94312,
            "recall": 0.76732,
            "f1": 0.8459
        },
        "nubia": {
            "semantic_relation": 3.59355,
            "contradiction": 0.11709,
            "irrelevancy": 0.85004,
            "logical_agreement": 99.03287,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.27801,
            "nubia_score": 0.65524
        },
        "meteor": 0.2726771323971795
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.99975,
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.47348,
            "fmeasure": 0.54677
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.25325,
            "fmeasure": 0.28725
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.34091,
            "fmeasure": 0.38208
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.34091,
            "fmeasure": 0.38208
        },
        "nist": 1.5293120760641343,
        "bleurt": -0.07633,
        "bertscore": {
            "precision": 0.91974,
            "recall": 0.90658,
            "f1": 0.91312
        },
        "nubia": {
            "semantic_relation": 3.19021,
            "contradiction": 3.66679,
            "irrelevancy": 71.0034,
            "logical_agreement": 25.3298,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.22209,
            "nubia_score": 0.39294
        },
        "meteor": 0.3451939237435506
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 2.8483609718589222,
        "bleurt": 0.90755,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37344,
            "irrelevancy": 0.48743,
            "logical_agreement": 99.13913,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.40603,
            "nubia_score": 0.97334
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.40212,
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.37143,
            "fmeasure": 0.41111
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.08625,
            "fmeasure": 0.09697
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.29048,
            "fmeasure": 0.32222
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.29048,
            "fmeasure": 0.32222
        },
        "nist": 2.497740205469652,
        "bleurt": -0.02094,
        "bertscore": {
            "precision": 0.87013,
            "recall": 0.85563,
            "f1": 0.86034
        },
        "nubia": {
            "semantic_relation": 2.77081,
            "contradiction": 62.72328,
            "irrelevancy": 17.67582,
            "logical_agreement": 19.6009,
            "grammar_ref": 4.72922,
            "grammar_hyp": 4.26591,
            "nubia_score": 0.3018
        },
        "meteor": 0.22772701466614845
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69683,
        "msttr-100_nopunct": 0.71758,
        "total_length": 10157,
        "mean_pred_length": 21.65671641791045,
        "std_pred_length": 5.8502512736084515,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 45,
        "distinct-1": 0.11893275573496111,
        "vocab_size-1": 1208,
        "unique-1": 610,
        "entropy-1": 7.862364258353038,
        "distinct-2": 0.3504335260115607,
        "vocab_size-2": 3395,
        "unique-2": 2151,
        "entropy-2": 10.57191642525394,
        "cond_entropy-2": 2.5731334087491113,
        "distinct-3": 0.5557001844017789,
        "vocab_size-3": 5123,
        "unique-3": 3792,
        "entropy-3": 11.715935041083114,
        "cond_entropy-3": 1.165804380335452,
        "total_length-nopunct": 9102,
        "mean_pred_length-nopunct": 19.407249466950958,
        "std_pred_length-nopunct": 5.2362553050886484,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.13172929026587563,
        "vocab_size-1-nopunct": 1199,
        "unique-1-nopunct": 610,
        "entropy-1-nopunct": 8.025444414987227,
        "distinct-2-nopunct": 0.36951233638364417,
        "vocab_size-2-nopunct": 3190,
        "unique-2-nopunct": 2059,
        "entropy-2-nopunct": 10.512304453522324,
        "cond_entropy-2-nopunct": 2.576861169903318,
        "distinct-3-nopunct": 0.5814551690347869,
        "vocab_size-3-nopunct": 4747,
        "unique-3-nopunct": 3567,
        "entropy-3-nopunct": 11.655101716587664,
        "cond_entropy-3-nopunct": 1.1614575978242396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.38379,
        "local_recall": {
            "1": 0.642501447596989
        },
        "rouge1": {
            "precision": 0.66593,
            "recall": 0.66148,
            "fmeasure": 0.65271
        },
        "rouge2": {
            "precision": 0.43701,
            "recall": 0.43441,
            "fmeasure": 0.42852
        },
        "rougeL": {
            "precision": 0.56675,
            "recall": 0.56455,
            "fmeasure": 0.5567
        },
        "rougeLsum": {
            "precision": 0.56675,
            "recall": 0.56455,
            "fmeasure": 0.5567
        },
        "nist": 6.624297210912585,
        "bleurt": -0.01024,
        "bertscore": {
            "precision": 0.89197,
            "recall": 0.88897,
            "f1": 0.89009
        },
        "nubia": {
            "semantic_relation": 4.24112,
            "contradiction": 6.67004,
            "irrelevancy": 21.80717,
            "logical_agreement": 71.52279,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.72792,
            "nubia_score": 0.72951
        },
        "meteor": 0.3482989811042554
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.78169,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.48485,
            "fmeasure": 0.61581
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.24206,
            "fmeasure": 0.31762
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.31313,
            "fmeasure": 0.39707
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.31313,
            "fmeasure": 0.39707
        },
        "nist": 0.8871273736210642,
        "bleurt": -0.65137,
        "bertscore": {
            "precision": 0.92544,
            "recall": 0.88779,
            "f1": 0.90544
        },
        "nubia": {
            "semantic_relation": 3.28959,
            "contradiction": 33.35786,
            "irrelevancy": 3.05299,
            "logical_agreement": 63.58915,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.99399,
            "nubia_score": 0.37027
        },
        "meteor": 0.2478868714487855
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.24222,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "nist": 2.139975000480771,
        "bleurt": 0.1522,
        "bertscore": {
            "precision": 0.87218,
            "recall": 0.89554,
            "f1": 0.8837
        },
        "nubia": {
            "semantic_relation": 4.15374,
            "contradiction": 1.30801,
            "irrelevancy": 98.14326,
            "logical_agreement": 0.54874,
            "grammar_ref": 5.42176,
            "grammar_hyp": 5.45434,
            "nubia_score": 0.57365
        },
        "meteor": 0.2680288367785235
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375348,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601997,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 36.25565,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.68254,
            "recall": 0.84649,
            "fmeasure": 0.7545
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.44074,
            "fmeasure": 0.38947
        },
        "rougeL": {
            "precision": 0.49206,
            "recall": 0.61623,
            "fmeasure": 0.5464
        },
        "rougeLsum": {
            "precision": 0.49206,
            "recall": 0.61623,
            "fmeasure": 0.5464
        },
        "nist": 3.8341939891339947,
        "bleurt": 0.22887,
        "bertscore": {
            "precision": 0.89043,
            "recall": 0.90994,
            "f1": 0.90008
        },
        "nubia": {
            "semantic_relation": 4.2065,
            "contradiction": 0.1195,
            "irrelevancy": 0.54172,
            "logical_agreement": 99.33877,
            "grammar_ref": 5.46955,
            "grammar_hyp": 3.90897,
            "nubia_score": 0.92394
        },
        "meteor": 0.4088470716310917
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.88462,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "nist": 4.23331430181648,
        "bleurt": 0.56405,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 3.77055,
            "contradiction": 48.79365,
            "irrelevancy": 1.17603,
            "logical_agreement": 50.03032,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.40036,
            "nubia_score": 0.71443
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.09306920777188989,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688533,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.08959,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.33333,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53333
        },
        "nist": 1.5628452981362178,
        "bleurt": 0.54796,
        "bertscore": {
            "precision": 0.93104,
            "recall": 0.94752,
            "f1": 0.93921
        },
        "nubia": {
            "semantic_relation": 4.31945,
            "contradiction": 0.10753,
            "irrelevancy": 0.80807,
            "logical_agreement": 99.08439,
            "grammar_ref": 4.92688,
            "grammar_hyp": 4.41502,
            "nubia_score": 0.84228
        },
        "meteor": 0.3198077509165212
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.19447,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "nist": 3.616961879953846,
        "bleurt": 0.65172,
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.96353,
            "f1": 0.96239
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24117,
            "irrelevancy": 0.43431,
            "logical_agreement": 99.32451,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.55935,
            "nubia_score": 0.9976
        },
        "meteor": 0.549453875996166
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 41.10546,
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "nist": 2.32249814589546,
        "bleurt": 0.65075,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "meteor": 0.8569614896318238
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.98048,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.62222,
            "fmeasure": 0.73016
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.45887,
            "fmeasure": 0.54226
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.57778,
            "fmeasure": 0.6746
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.57778,
            "fmeasure": 0.6746
        },
        "nist": 1.9446616610533678,
        "bleurt": 0.2729,
        "bertscore": {
            "precision": 0.93873,
            "recall": 0.87074,
            "f1": 0.90346
        },
        "nubia": {
            "semantic_relation": 4.47767,
            "contradiction": 0.28392,
            "irrelevancy": 0.721,
            "logical_agreement": 98.99508,
            "grammar_ref": 4.47457,
            "grammar_hyp": 5.02376,
            "nubia_score": 0.84041
        },
        "meteor": 0.3613362424002765
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "nist": 4.190572262757721,
        "bleurt": 0.83087,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.44405,
            "irrelevancy": 0.50174,
            "logical_agreement": 99.05421,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.68353,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.75409,
        "msttr-100_nopunct": 0.778,
        "total_length": 2237,
        "mean_pred_length": 21.10377358490566,
        "std_pred_length": 4.797659109385355,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 40,
        "distinct-1": 0.4421099687080912,
        "vocab_size-1": 989,
        "unique-1": 777,
        "entropy-1": 8.453302725370872,
        "distinct-2": 0.8793993430314406,
        "vocab_size-2": 1874,
        "unique-2": 1745,
        "entropy-2": 10.720769991371144,
        "cond_entropy-2": 2.069650833859488,
        "distinct-3": 0.9822222222222222,
        "vocab_size-3": 1989,
        "unique-3": 1960,
        "entropy-3": 10.944876962790989,
        "cond_entropy-3": 0.23011387658296872,
        "total_length-nopunct": 2073,
        "mean_pred_length-nopunct": 19.556603773584907,
        "std_pred_length-nopunct": 4.584798896186869,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.472744814278823,
        "vocab_size-1-nopunct": 980,
        "unique-1-nopunct": 774,
        "entropy-1-nopunct": 8.58909771016822,
        "distinct-2-nopunct": 0.8810371123538383,
        "vocab_size-2-nopunct": 1733,
        "unique-2-nopunct": 1615,
        "entropy-2-nopunct": 10.607366867617744,
        "cond_entropy-2-nopunct": 2.1120043011680742,
        "distinct-3-nopunct": 0.984954325631381,
        "vocab_size-3-nopunct": 1833,
        "unique-3-nopunct": 1808,
        "entropy-3-nopunct": 10.830554085084795,
        "cond_entropy-3-nopunct": 0.23166983198438656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.45605,
        "local_recall": {
            "1": 0.377041530564629
        },
        "rouge1": {
            "precision": 0.43686,
            "recall": 0.39613,
            "fmeasure": 0.40644
        },
        "rouge2": {
            "precision": 0.18164,
            "recall": 0.16495,
            "fmeasure": 0.16909
        },
        "rougeL": {
            "precision": 0.34687,
            "recall": 0.31658,
            "fmeasure": 0.32368
        },
        "rougeLsum": {
            "precision": 0.34687,
            "recall": 0.31658,
            "fmeasure": 0.32368
        },
        "nist": 3.6177980081077226,
        "bleurt": -0.18413,
        "bertscore": {
            "precision": 0.84571,
            "recall": 0.8327,
            "f1": 0.83882
        },
        "nubia": {
            "semantic_relation": 3.21036,
            "contradiction": 12.68503,
            "irrelevancy": 59.00986,
            "logical_agreement": 28.3051,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.54807,
            "nubia_score": 0.51126
        },
        "meteor": 0.18654555123776836
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 76.11606,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "nist": 3.9682591176000703,
        "bleurt": 0.77776,
        "bertscore": {
            "precision": 0.98018,
            "recall": 0.99668,
            "f1": 0.98836
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.17539,
            "irrelevancy": 5.81074,
            "logical_agreement": 94.01388,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.63407,
            "nubia_score": 0.9946
        },
        "meteor": 0.544209755399708
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74136,
        "msttr-100_nopunct": 0.769,
        "total_length": 2232,
        "mean_pred_length": 21.056603773584907,
        "std_pred_length": 4.271074692824263,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.44086021505376344,
        "vocab_size-1": 984,
        "unique-1": 776,
        "entropy-1": 8.410783154678771,
        "distinct-2": 0.8777046095954845,
        "vocab_size-2": 1866,
        "unique-2": 1752,
        "entropy-2": 10.692330463133741,
        "cond_entropy-2": 2.081384691556107,
        "distinct-3": 0.9841584158415841,
        "vocab_size-3": 1988,
        "unique-3": 1962,
        "entropy-3": 10.945548338540164,
        "cond_entropy-3": 0.25956408300312483,
        "total_length-nopunct": 2076,
        "mean_pred_length-nopunct": 19.58490566037736,
        "std_pred_length-nopunct": 4.076781760089927,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4701348747591522,
        "vocab_size-1-nopunct": 976,
        "unique-1-nopunct": 774,
        "entropy-1-nopunct": 8.548689980253512,
        "distinct-2-nopunct": 0.8817258883248731,
        "vocab_size-2-nopunct": 1737,
        "unique-2-nopunct": 1637,
        "entropy-2-nopunct": 10.588440237650605,
        "cond_entropy-2-nopunct": 2.133311224587289,
        "distinct-3-nopunct": 0.9881974248927039,
        "vocab_size-3-nopunct": 1842,
        "unique-3-nopunct": 1822,
        "entropy-3-nopunct": 10.839771029308338,
        "cond_entropy-3-nopunct": 0.26224675503073824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 9.88931,
        "local_recall": {
            "1": 0.3723502304147465
        },
        "rouge1": {
            "precision": 0.4394,
            "recall": 0.3994,
            "fmeasure": 0.41141
        },
        "rouge2": {
            "precision": 0.17511,
            "recall": 0.1568,
            "fmeasure": 0.1627
        },
        "rougeL": {
            "precision": 0.34675,
            "recall": 0.31347,
            "fmeasure": 0.32396
        },
        "rougeLsum": {
            "precision": 0.34675,
            "recall": 0.31347,
            "fmeasure": 0.32396
        },
        "nist": 3.5904705118192966,
        "bleurt": -0.27457,
        "bertscore": {
            "precision": 0.8436,
            "recall": 0.83271,
            "f1": 0.83786
        },
        "nubia": {
            "semantic_relation": 3.16701,
            "contradiction": 18.70328,
            "irrelevancy": 64.01714,
            "logical_agreement": 17.27958,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.61938,
            "nubia_score": 0.48785
        },
        "meteor": 0.18591294454060303
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 22.04388,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.51754,
            "fmeasure": 0.60012
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.25536,
            "fmeasure": 0.29839
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.41404,
            "fmeasure": 0.4801
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.41404,
            "fmeasure": 0.4801
        },
        "nist": 2.519037647507591,
        "bleurt": 0.04424,
        "bertscore": {
            "precision": 0.87476,
            "recall": 0.773,
            "f1": 0.82074
        },
        "nubia": {
            "semantic_relation": 3.37275,
            "contradiction": 93.77078,
            "irrelevancy": 5.34328,
            "logical_agreement": 0.88594,
            "grammar_ref": 4.62058,
            "grammar_hyp": 5.11689,
            "nubia_score": 0.34441
        },
        "meteor": 0.27668278697810483
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 27.78826,
        "local_recall": {
            "1": 0.3,
            "2": 0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.66944,
            "recall": 0.84444,
            "fmeasure": 0.74495
        },
        "rouge2": {
            "precision": 0.41414,
            "recall": 0.57037,
            "fmeasure": 0.47619
        },
        "rougeL": {
            "precision": 0.51944,
            "recall": 0.71667,
            "fmeasure": 0.59848
        },
        "rougeLsum": {
            "precision": 0.51944,
            "recall": 0.71667,
            "fmeasure": 0.59848
        },
        "nist": 3.5632520565638037,
        "bleurt": 0.25594,
        "bertscore": {
            "precision": 0.90759,
            "recall": 0.91848,
            "f1": 0.91159
        },
        "nubia": {
            "semantic_relation": 4.23833,
            "contradiction": 0.20407,
            "irrelevancy": 50.56407,
            "logical_agreement": 49.23186,
            "grammar_ref": 5.47595,
            "grammar_hyp": 4.94077,
            "nubia_score": 0.78302
        },
        "meteor": 0.41066622526806273
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 58.33511,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "nist": 3.0088906840841796,
        "bleurt": 0.7528,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "meteor": 0.4630505936482093
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 24.50341,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.69758,
            "fmeasure": 0.74659
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32222,
            "fmeasure": 0.34641
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "nist": 3.926592062147975,
        "bleurt": 0.26882,
        "bertscore": {
            "precision": 0.93037,
            "recall": 0.92685,
            "f1": 0.92861
        },
        "nubia": {
            "semantic_relation": 4.18498,
            "contradiction": 0.21419,
            "irrelevancy": 33.28813,
            "logical_agreement": 66.49768,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.43353,
            "nubia_score": 0.74514
        },
        "meteor": 0.37423520854850306
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.7585,
        "total_length": 2169,
        "mean_pred_length": 20.462264150943398,
        "std_pred_length": 4.440751526363925,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.4310742277547257,
        "vocab_size-1": 935,
        "unique-1": 728,
        "entropy-1": 8.318029758744535,
        "distinct-2": 0.8734852157052836,
        "vocab_size-2": 1802,
        "unique-2": 1676,
        "entropy-2": 10.646920681094777,
        "cond_entropy-2": 2.1305320428193464,
        "distinct-3": 0.977005620848237,
        "vocab_size-3": 1912,
        "unique-3": 1880,
        "entropy-3": 10.88154917325063,
        "cond_entropy-3": 0.24026600468748507,
        "total_length-nopunct": 2022,
        "mean_pred_length-nopunct": 19.07547169811321,
        "std_pred_length-nopunct": 4.316921757079479,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.45845697329376855,
        "vocab_size-1-nopunct": 927,
        "unique-1-nopunct": 724,
        "entropy-1-nopunct": 8.450112247828972,
        "distinct-2-nopunct": 0.8731732776617954,
        "vocab_size-2-nopunct": 1673,
        "unique-2-nopunct": 1555,
        "entropy-2-nopunct": 10.53736419732013,
        "cond_entropy-2-nopunct": 2.1785355765523797,
        "distinct-3-nopunct": 0.9773480662983426,
        "vocab_size-3-nopunct": 1769,
        "unique-3-nopunct": 1739,
        "entropy-3-nopunct": 10.770125394426426,
        "cond_entropy-3-nopunct": 0.2381612275675157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 11.20781,
        "local_recall": {
            "1": 0.36619718309859156
        },
        "rouge1": {
            "precision": 0.4374,
            "recall": 0.39429,
            "fmeasure": 0.40877
        },
        "rouge2": {
            "precision": 0.18572,
            "recall": 0.16737,
            "fmeasure": 0.17359
        },
        "rougeL": {
            "precision": 0.34729,
            "recall": 0.30986,
            "fmeasure": 0.32279
        },
        "rougeLsum": {
            "precision": 0.34729,
            "recall": 0.30986,
            "fmeasure": 0.32279
        },
        "nist": 3.545035981329855,
        "bleurt": -0.25893,
        "bertscore": {
            "precision": 0.84627,
            "recall": 0.83218,
            "f1": 0.83891
        },
        "nubia": {
            "semantic_relation": 3.06479,
            "contradiction": 19.0758,
            "irrelevancy": 58.74989,
            "logical_agreement": 22.17431,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.64636,
            "nubia_score": 0.47217
        },
        "meteor": 0.1798269959622838
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 13,
        "entropy-1": 4.163856189774723,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.2626923908396215,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": 0.05923165719793805,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.088779347361361,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064473,
        "cond_entropy-2-nopunct": 0.05923165719793804,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548846,
        "cond_entropy-3-nopunct": 0.06613640645429875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.60595,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.72378,
            "recall": 0.76435,
            "fmeasure": 0.72929
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.57479,
            "fmeasure": 0.55837
        },
        "rougeL": {
            "precision": 0.72378,
            "recall": 0.76435,
            "fmeasure": 0.72929
        },
        "rougeLsum": {
            "precision": 0.72378,
            "recall": 0.76435,
            "fmeasure": 0.72929
        },
        "nist": 3.133601447263269,
        "bleurt": 0.60605,
        "bertscore": {
            "precision": 0.95391,
            "recall": 0.95949,
            "f1": 0.95655
        },
        "nubia": {
            "semantic_relation": 4.19373,
            "contradiction": 0.90793,
            "irrelevancy": 14.14576,
            "logical_agreement": 84.94632,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.4252,
            "nubia_score": 0.74023
        },
        "meteor": 0.43895503799189145
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "nist": 3.462425934400558,
        "bleurt": 0.45919,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.6129032258064516,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.082597923010943,
        "distinct-2": 0.7857142857142857,
        "vocab_size-2": 22,
        "unique-2": 16,
        "entropy-2": 4.378783493486177,
        "cond_entropy-2": 0.21975370118824328,
        "distinct-3": 0.84,
        "vocab_size-3": 21,
        "unique-3": 17,
        "entropy-3": 4.323856189774722,
        "cond_entropy-3": -0.08349873228287957,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 8.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6538461538461539,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.921029621737614,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.1757358691004915,
        "cond_entropy-2-nopunct": 0.21854560770062054,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": -0.10163386116965065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.66581,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6296296296296297
        },
        "rouge1": {
            "precision": 0.86768,
            "recall": 0.77351,
            "fmeasure": 0.81205
        },
        "rouge2": {
            "precision": 0.70494,
            "recall": 0.65741,
            "fmeasure": 0.67604
        },
        "rougeL": {
            "precision": 0.83737,
            "recall": 0.75377,
            "fmeasure": 0.78818
        },
        "rougeLsum": {
            "precision": 0.83737,
            "recall": 0.75377,
            "fmeasure": 0.78818
        },
        "nist": 3.1358178919036583,
        "bleurt": 0.33945,
        "bertscore": {
            "precision": 0.94189,
            "recall": 0.91973,
            "f1": 0.92979
        },
        "nubia": {
            "semantic_relation": 4.038,
            "contradiction": 31.87053,
            "irrelevancy": 16.76796,
            "logical_agreement": 51.36151,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.4946,
            "nubia_score": 0.63139
        },
        "meteor": 0.4207199233458685
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 30.23267,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.9375,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.51453,
            "fmeasure": 0.47238
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.34226,
            "fmeasure": 0.31606
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.34226,
            "fmeasure": 0.31606
        },
        "nist": 3.2570184389275245,
        "bleurt": -0.25512,
        "bertscore": {
            "precision": 0.90315,
            "recall": 0.91523,
            "f1": 0.90915
        },
        "nubia": {
            "semantic_relation": 4.32127,
            "contradiction": 0.24247,
            "irrelevancy": 65.30295,
            "logical_agreement": 34.45458,
            "grammar_ref": 4.41465,
            "grammar_hyp": 4.92798,
            "nubia_score": 0.67806
        },
        "meteor": 0.3887057498420411
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74952,
        "msttr-100_nopunct": 0.76368,
        "total_length": 2134,
        "mean_pred_length": 20.132075471698112,
        "std_pred_length": 6.045543301112381,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.4381443298969072,
        "vocab_size-1": 935,
        "unique-1": 735,
        "entropy-1": 8.395985974281988,
        "distinct-2": 0.8708086785009862,
        "vocab_size-2": 1766,
        "unique-2": 1646,
        "entropy-2": 10.606011608667442,
        "cond_entropy-2": 2.0051293172686098,
        "distinct-3": 0.9734651404786681,
        "vocab_size-3": 1871,
        "unique-3": 1830,
        "entropy-3": 10.85018538717299,
        "cond_entropy-3": 0.24639126799739233,
        "total_length-nopunct": 1993,
        "mean_pred_length-nopunct": 18.80188679245283,
        "std_pred_length-nopunct": 5.842944158556904,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.4651279478173608,
        "vocab_size-1-nopunct": 927,
        "unique-1-nopunct": 732,
        "entropy-1-nopunct": 8.525683309480787,
        "distinct-2-nopunct": 0.8712241653418124,
        "vocab_size-2-nopunct": 1644,
        "unique-2-nopunct": 1535,
        "entropy-2-nopunct": 10.499904075453484,
        "cond_entropy-2-nopunct": 2.0661647011260267,
        "distinct-3-nopunct": 0.974171813587872,
        "vocab_size-3-nopunct": 1735,
        "unique-3-nopunct": 1699,
        "entropy-3-nopunct": 10.741271181797368,
        "cond_entropy-3-nopunct": 0.25413208304511825,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 9.99164,
        "local_recall": {
            "1": 0.3404669260700389
        },
        "rouge1": {
            "precision": 0.40975,
            "recall": 0.37309,
            "fmeasure": 0.37879
        },
        "rouge2": {
            "precision": 0.16237,
            "recall": 0.15055,
            "fmeasure": 0.15119
        },
        "rougeL": {
            "precision": 0.33734,
            "recall": 0.30449,
            "fmeasure": 0.31
        },
        "rougeLsum": {
            "precision": 0.33734,
            "recall": 0.30449,
            "fmeasure": 0.31
        },
        "nist": 3.183979353709082,
        "bleurt": -0.3343,
        "bertscore": {
            "precision": 0.8366,
            "recall": 0.82487,
            "f1": 0.83023
        },
        "nubia": {
            "semantic_relation": 2.82477,
            "contradiction": 21.79941,
            "irrelevancy": 60.4594,
            "logical_agreement": 17.74119,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.72671,
            "nubia_score": 0.41674
        },
        "meteor": 0.16082286873162652
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.62607,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.94872,
            "recall": 0.79186,
            "fmeasure": 0.85983
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.5,
            "fmeasure": 0.54762
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.66214,
            "fmeasure": 0.71966
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.66214,
            "fmeasure": 0.71966
        },
        "nist": 4.563669500604573,
        "bleurt": 0.30415,
        "bertscore": {
            "precision": 0.97809,
            "recall": 0.95382,
            "f1": 0.96138
        },
        "nubia": {
            "semantic_relation": 4.48825,
            "contradiction": 12.61481,
            "irrelevancy": 46.43867,
            "logical_agreement": 40.94652,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.59355,
            "nubia_score": 0.76043
        },
        "meteor": 0.36863596446896896
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 60.76796,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "nist": 3.187041294443259,
        "bleurt": 0.08591,
        "bertscore": {
            "precision": 0.96776,
            "recall": 0.90667,
            "f1": 0.93622
        },
        "nubia": {
            "semantic_relation": 4.04063,
            "contradiction": 0.33448,
            "irrelevancy": 33.54517,
            "logical_agreement": 66.12035,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.29909,
            "nubia_score": 0.60229
        },
        "meteor": 0.49950351059188686
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.99111,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "nist": 1.1227137604546689,
        "bleurt": 0.34221,
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        },
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "meteor": 0.2731132551770082
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 37.0,
        "std_pred_length": 0.0,
        "median_pred_length": 37.0,
        "min_pred_length": 37,
        "max_pred_length": 37,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.3656890156593935,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.84743498826351,
        "cond_entropy-2": 0.5051838712143853,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.2910620290579914,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 32,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.274397470347699,
        "distinct-2-nopunct": 0.8709677419354839,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.57969177895343,
        "cond_entropy-2-nopunct": 0.32870084182032067,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": 0.33968230103620356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 49.10467,
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.6129,
            "recall": 0.63333,
            "fmeasure": 0.62295
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.83871,
            "fmeasure": 0.8254
        },
        "nist": 4.231300971690577,
        "bleurt": 0.16886,
        "bertscore": {
            "precision": 0.97984,
            "recall": 0.98469,
            "f1": 0.98226
        },
        "nubia": {
            "semantic_relation": 2.81049,
            "contradiction": 65.54044,
            "irrelevancy": 27.70076,
            "logical_agreement": 6.75881,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.78477,
            "nubia_score": 0.31902
        },
        "meteor": 0.41111102167313035
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 7,
        "entropy-1": 3.327819531114783,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.5068905956085183,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.18617861216337128,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.873140679513133,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.084962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.2776134368191165,
        "cond_entropy-3-nopunct": 0.23810548155250458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.41525,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "nist": 2.335875509205763,
        "bleurt": 0.72955,
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.97904,
            "f1": 0.9633
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.80225,
            "irrelevancy": 2.20481,
            "logical_agreement": 94.99294,
            "grammar_ref": 7.00423,
            "grammar_hyp": 4.8462,
            "nubia_score": 1.0
        },
        "meteor": 0.5158883169898099
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.22144,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.4986,
            "fmeasure": 0.56944
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.25417,
            "fmeasure": 0.29673
        },
        "rougeL": {
            "precision": 0.64444,
            "recall": 0.47899,
            "fmeasure": 0.54861
        },
        "rougeLsum": {
            "precision": 0.64444,
            "recall": 0.47899,
            "fmeasure": 0.54861
        },
        "nist": 3.6364491497338154,
        "bleurt": -0.09954,
        "bertscore": {
            "precision": 0.91626,
            "recall": 0.89408,
            "f1": 0.90503
        },
        "nubia": {
            "semantic_relation": 3.05917,
            "contradiction": 0.14916,
            "irrelevancy": 99.43503,
            "logical_agreement": 0.41582,
            "grammar_ref": 5.50536,
            "grammar_hyp": 5.19124,
            "nubia_score": 0.34948
        },
        "meteor": 0.302847650778664
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.59375,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.125,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 22,
        "unique-2": 14,
        "entropy-2": 4.3735572622751855,
        "cond_entropy-2": 0.24022392894185185,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.8349625007211565,
        "distinct-2-nopunct": 0.7272727272727273,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.913977073182751,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.9219280948873623,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 79.81519,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.282514138572009,
        "bleurt": 0.4515,
        "bertscore": {
            "precision": 0.98345,
            "recall": 0.93834,
            "f1": 0.95858
        },
        "nubia": {
            "semantic_relation": 4.32726,
            "contradiction": 43.9504,
            "irrelevancy": 13.81033,
            "logical_agreement": 42.23927,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.60786,
            "nubia_score": 0.66303
        },
        "meteor": 0.4570160089905608
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.582118926162054,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.11912872925811879,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.532665279941249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.088968687611256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.92972,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.8,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73431,
            "recall": 0.7772,
            "fmeasure": 0.75436
        },
        "rouge2": {
            "precision": 0.50926,
            "recall": 0.54461,
            "fmeasure": 0.52573
        },
        "rougeL": {
            "precision": 0.73431,
            "recall": 0.7772,
            "fmeasure": 0.75436
        },
        "rougeLsum": {
            "precision": 0.73431,
            "recall": 0.7772,
            "fmeasure": 0.75436
        },
        "nist": 4.3157876567987685,
        "bleurt": 0.52379,
        "bertscore": {
            "precision": 0.96074,
            "recall": 0.97172,
            "f1": 0.96619
        },
        "nubia": {
            "semantic_relation": 4.3316,
            "contradiction": 1.32434,
            "irrelevancy": 51.36227,
            "logical_agreement": 47.31339,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.66498,
            "nubia_score": 0.73982
        },
        "meteor": 0.471463356313671
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.8110378683422774,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 3.939470994001286,
        "cond_entropy-2": 0.15930901853019971,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 17,
        "entropy-3": 4.084183719779189,
        "cond_entropy-3": 0.1673550472167754,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.608694969562842,
        "distinct-2-nopunct": 0.7894736842105263,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7474130395316396,
        "cond_entropy-2-nopunct": 0.17625665551219524,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.9057645846554525,
        "cond_entropy-3-nopunct": 0.1861579047855862,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.54631,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.56667,
            "fmeasure": 0.37928
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.20875,
            "fmeasure": 0.13496
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.56667,
            "fmeasure": 0.37928
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.56667,
            "fmeasure": 0.37928
        },
        "nist": 0.9818165701771026,
        "bleurt": -0.45649,
        "bertscore": {
            "precision": 0.78474,
            "recall": 0.84028,
            "f1": 0.80964
        },
        "nubia": {
            "semantic_relation": 3.14455,
            "contradiction": 14.03874,
            "irrelevancy": 85.76659,
            "logical_agreement": 0.19467,
            "grammar_ref": 4.40566,
            "grammar_hyp": 3.38613,
            "nubia_score": 0.44289
        },
        "meteor": 0.2259595952479643
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.6875,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.57143,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.6875,
            "fmeasure": 0.6875
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.6875,
            "fmeasure": 0.6875
        },
        "nist": 4.021986650774149,
        "bleurt": 0.57571,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.48665,
            "contradiction": 0.1881,
            "irrelevancy": 50.03339,
            "logical_agreement": 49.77851,
            "grammar_ref": 5.57872,
            "grammar_hyp": 5.29076,
            "nubia_score": 0.88333
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.74766,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.76768,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.38788,
            "fmeasure": 0.37518
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.70707,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.70707,
            "fmeasure": 0.68599
        },
        "nist": 2.6690478395205015,
        "bleurt": 0.567,
        "bertscore": {
            "precision": 0.94949,
            "recall": 0.97247,
            "f1": 0.96084
        },
        "nubia": {
            "semantic_relation": 4.90475,
            "contradiction": 0.85065,
            "irrelevancy": 0.98066,
            "logical_agreement": 98.16868,
            "grammar_ref": 6.27756,
            "grammar_hyp": 5.92085,
            "nubia_score": 0.94447
        },
        "meteor": 0.4043035537569496
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 19.43406,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "nist": 2.4929182263680483,
        "bleurt": 0.5593,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94875
        },
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "meteor": 0.38388402914845343
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.98928,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.48333,
            "fmeasure": 0.50926
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.18407,
            "fmeasure": 0.19538
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.48333,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.48333,
            "fmeasure": 0.50926
        },
        "nist": 2.7920166638763146,
        "bleurt": 0.17292,
        "bertscore": {
            "precision": 0.90058,
            "recall": 0.89671,
            "f1": 0.89864
        },
        "nubia": {
            "semantic_relation": 3.9554,
            "contradiction": 22.00223,
            "irrelevancy": 45.93595,
            "logical_agreement": 32.06181,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.49617,
            "nubia_score": 0.63529
        },
        "meteor": 0.2647654698066604
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.87433,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58333
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58333
        },
        "nist": 1.8287759656137208,
        "bleurt": 0.19793,
        "bertscore": {
            "precision": 0.87411,
            "recall": 0.84385,
            "f1": 0.85871
        },
        "nubia": {
            "semantic_relation": 3.59118,
            "contradiction": 1.24678,
            "irrelevancy": 73.61602,
            "logical_agreement": 25.1372,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.89495,
            "nubia_score": 0.49369
        },
        "meteor": 0.29662139809946136
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.2178561159133974,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393867,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.90869,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.45299,
            "fmeasure": 0.4714
        },
        "rouge2": {
            "precision": 0.05556,
            "recall": 0.04167,
            "fmeasure": 0.04762
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.41453,
            "fmeasure": 0.42792
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.41453,
            "fmeasure": 0.42792
        },
        "nist": 2.3799293921449522,
        "bleurt": -0.03901,
        "bertscore": {
            "precision": 0.81692,
            "recall": 0.84051,
            "f1": 0.81698
        },
        "nubia": {
            "semantic_relation": 3.60169,
            "contradiction": 1.77662,
            "irrelevancy": 45.3078,
            "logical_agreement": 52.91558,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.25782,
            "nubia_score": 0.57
        },
        "meteor": 0.27062803751933634
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.05852,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.38889,
            "recall": 0.33636,
            "fmeasure": 0.36053
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16111,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.33636,
            "fmeasure": 0.36053
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.33636,
            "fmeasure": 0.36053
        },
        "nist": 1.9320408231319313,
        "bleurt": 0.30104,
        "bertscore": {
            "precision": 0.88044,
            "recall": 0.85802,
            "f1": 0.86908
        },
        "nubia": {
            "semantic_relation": 3.23197,
            "contradiction": 55.54036,
            "irrelevancy": 31.39781,
            "logical_agreement": 13.06182,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.25312,
            "nubia_score": 0.3073
        },
        "meteor": 0.20533560164753298
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 3.9701755214643453,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819114,
        "cond_entropy-2": 0.2724185498326622,
        "distinct-3": 0.95,
        "vocab_size-3": 19,
        "unique-3": 18,
        "entropy-3": 4.221928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.7841837197791883,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.33437954556403177,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.20507,
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.75975,
            "fmeasure": 0.79956
        },
        "rouge2": {
            "precision": 0.62121,
            "recall": 0.54285,
            "fmeasure": 0.56704
        },
        "rougeL": {
            "precision": 0.74167,
            "recall": 0.71324,
            "fmeasure": 0.70692
        },
        "rougeLsum": {
            "precision": 0.74167,
            "recall": 0.71324,
            "fmeasure": 0.70692
        },
        "nist": 4.004761157864898,
        "bleurt": 0.31387,
        "bertscore": {
            "precision": 0.94208,
            "recall": 0.95387,
            "f1": 0.94184
        },
        "nubia": {
            "semantic_relation": 4.23153,
            "contradiction": 0.33469,
            "irrelevancy": 33.28321,
            "logical_agreement": 66.38211,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.80118,
            "nubia_score": 0.73018
        },
        "meteor": 0.46398621269246326
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 3.73744,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.14285714285714285
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.42803,
            "fmeasure": 0.37302
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.14286,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "rougeLsum": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "nist": 0.8250533418130888,
        "bleurt": -1.18688,
        "bertscore": {
            "precision": 0.72865,
            "recall": 0.73571,
            "f1": 0.73216
        },
        "nubia": {
            "semantic_relation": 1.99073,
            "contradiction": 0.47138,
            "irrelevancy": 98.25057,
            "logical_agreement": 1.27805,
            "grammar_ref": 5.51883,
            "grammar_hyp": 5.16826,
            "nubia_score": 0.16523
        },
        "meteor": 0.11700182815356491
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411754,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.93985,
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.69975,
            "fmeasure": 0.61925
        },
        "rouge2": {
            "precision": 0.18333,
            "recall": 0.23333,
            "fmeasure": 0.20529
        },
        "rougeL": {
            "precision": 0.26984,
            "recall": 0.33946,
            "fmeasure": 0.30062
        },
        "rougeLsum": {
            "precision": 0.26984,
            "recall": 0.33946,
            "fmeasure": 0.30062
        },
        "nist": 3.043250137776905,
        "bleurt": 0.33302,
        "bertscore": {
            "precision": 0.88907,
            "recall": 0.90785,
            "f1": 0.89748
        },
        "nubia": {
            "semantic_relation": 4.77092,
            "contradiction": 0.08635,
            "irrelevancy": 1.53154,
            "logical_agreement": 98.3821,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.49123,
            "nubia_score": 1.0
        },
        "meteor": 0.32088620465284906
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.73452166477975,
        "distinct-2": 0.9375,
        "vocab_size-2": 30,
        "unique-2": 28,
        "entropy-2": 4.875,
        "cond_entropy-2": 0.10003715874966056,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 29,
        "unique-3": 28,
        "entropy-3": 4.840223928941852,
        "cond_entropy-3": -0.026442737724814782,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.513153408920675,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.606739354015323,
        "cond_entropy-2-nopunct": 0.08209169222108179,
        "distinct-3-nopunct": 0.96,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.5638561897747225,
        "cond_entropy-3-nopunct": -0.03103131238874396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 37.89011,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.58253,
            "recall": 0.77441,
            "fmeasure": 0.66394
        },
        "rouge2": {
            "precision": 0.39167,
            "recall": 0.56843,
            "fmeasure": 0.46352
        },
        "rougeL": {
            "precision": 0.5617,
            "recall": 0.76052,
            "fmeasure": 0.64498
        },
        "rougeLsum": {
            "precision": 0.5617,
            "recall": 0.76052,
            "fmeasure": 0.64498
        },
        "nist": 3.321384766825257,
        "bleurt": 0.12797,
        "bertscore": {
            "precision": 0.88696,
            "recall": 0.91353,
            "f1": 0.8995
        },
        "nubia": {
            "semantic_relation": 4.38449,
            "contradiction": 0.73704,
            "irrelevancy": 47.58004,
            "logical_agreement": 51.68292,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.37464,
            "nubia_score": 0.77584
        },
        "meteor": 0.3707926924723174
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375362,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601983,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.63752,
        "local_recall": {
            "1": 0.125,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.43056,
            "recall": 0.49206,
            "fmeasure": 0.45926
        },
        "rouge2": {
            "precision": 0.17391,
            "recall": 0.2,
            "fmeasure": 0.18605
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.38916,
            "fmeasure": 0.37987
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.38916,
            "fmeasure": 0.37987
        },
        "nist": 2.2156932357449826,
        "bleurt": 0.24605,
        "bertscore": {
            "precision": 0.88757,
            "recall": 0.89449,
            "f1": 0.89102
        },
        "nubia": {
            "semantic_relation": 4.1092,
            "contradiction": 74.64342,
            "irrelevancy": 24.96328,
            "logical_agreement": 0.39329,
            "grammar_ref": 3.9898,
            "grammar_hyp": 3.99446,
            "nubia_score": 0.6586
        },
        "meteor": 0.282948052959554
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 1.0,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.65,
        "vocab_size-1": 26,
        "unique-1": 19,
        "entropy-1": 4.3928966084191075,
        "distinct-2": 0.9210526315789473,
        "vocab_size-2": 35,
        "unique-2": 32,
        "entropy-2": 5.090032776601483,
        "cond_entropy-2": 0.6934009832596488,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.389898095464288,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.38295629088933325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.17708,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9545454545454546
        },
        "rouge1": {
            "precision": 0.76621,
            "recall": 0.96047,
            "fmeasure": 0.85144
        },
        "rouge2": {
            "precision": 0.69792,
            "recall": 0.90909,
            "fmeasure": 0.78788
        },
        "rougeL": {
            "precision": 0.76621,
            "recall": 0.96047,
            "fmeasure": 0.85144
        },
        "rougeLsum": {
            "precision": 0.76621,
            "recall": 0.96047,
            "fmeasure": 0.85144
        },
        "nist": 3.381599740098316,
        "bleurt": -0.18344,
        "bertscore": {
            "precision": 0.88351,
            "recall": 0.97649,
            "f1": 0.9265
        },
        "nubia": {
            "semantic_relation": 4.16669,
            "contradiction": 19.80346,
            "irrelevancy": 72.24079,
            "logical_agreement": 7.95575,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.39556,
            "nubia_score": 0.62878
        },
        "meteor": 0.5116329143321938
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.65534,
        "msttr-100_nopunct": 0.6565,
        "total_length": 8832,
        "mean_pred_length": 26.36417910447761,
        "std_pred_length": 5.208365873515338,
        "median_pred_length": 26.0,
        "min_pred_length": 15,
        "max_pred_length": 46,
        "distinct-1": 0.10597826086956522,
        "vocab_size-1": 936,
        "unique-1": 465,
        "entropy-1": 7.491818629341414,
        "distinct-2": 0.3037542662116041,
        "vocab_size-2": 2581,
        "unique-2": 1545,
        "entropy-2": 10.090834367553866,
        "cond_entropy-2": 2.5149376442824516,
        "distinct-3": 0.4992648860573389,
        "vocab_size-3": 4075,
        "unique-3": 2909,
        "entropy-3": 11.260832291277948,
        "cond_entropy-3": 1.1515219884799748,
        "total_length-nopunct": 8053,
        "mean_pred_length-nopunct": 24.038805970149255,
        "std_pred_length-nopunct": 4.483633761651488,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.11473984850366323,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 463,
        "entropy-1-nopunct": 7.539104970968943,
        "distinct-2-nopunct": 0.3192536926664939,
        "vocab_size-2-nopunct": 2464,
        "unique-2-nopunct": 1517,
        "entropy-2-nopunct": 10.03575752446825,
        "cond_entropy-2-nopunct": 2.5180293981976347,
        "distinct-3-nopunct": 0.5180820804550995,
        "vocab_size-3-nopunct": 3825,
        "unique-3-nopunct": 2810,
        "entropy-3-nopunct": 11.163089363791196,
        "cond_entropy-3-nopunct": 1.1305704245467674,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 41.17623,
        "local_recall": {
            "1": 0.6844585987261147
        },
        "rouge1": {
            "precision": 0.74595,
            "recall": 0.70318,
            "fmeasure": 0.71608
        },
        "rouge2": {
            "precision": 0.53252,
            "recall": 0.50126,
            "fmeasure": 0.51076
        },
        "rougeL": {
            "precision": 0.62945,
            "recall": 0.59274,
            "fmeasure": 0.60402
        },
        "rougeLsum": {
            "precision": 0.62945,
            "recall": 0.59274,
            "fmeasure": 0.60402
        },
        "nist": 7.108574426991544,
        "bleurt": 0.0904,
        "bertscore": {
            "precision": 0.91219,
            "recall": 0.90198,
            "f1": 0.9068
        },
        "nubia": {
            "semantic_relation": 4.47506,
            "contradiction": 2.69822,
            "irrelevancy": 10.39508,
            "logical_agreement": 86.90669,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.36853,
            "nubia_score": 0.81318
        },
        "meteor": 0.3815670817361431
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.63293,
        "msttr-100_nopunct": 0.63882,
        "total_length": 7532,
        "mean_pred_length": 29.421875,
        "std_pred_length": 7.339543343040832,
        "median_pred_length": 29.0,
        "min_pred_length": 13,
        "max_pred_length": 53,
        "distinct-1": 0.08656399362719065,
        "vocab_size-1": 652,
        "unique-1": 296,
        "entropy-1": 7.176912292650254,
        "distinct-2": 0.2741891148982958,
        "vocab_size-2": 1995,
        "unique-2": 1076,
        "entropy-2": 9.759260387129983,
        "cond_entropy-2": 2.5211986451807467,
        "distinct-3": 0.48504273504273504,
        "vocab_size-3": 3405,
        "unique-3": 2345,
        "entropy-3": 11.017506303984309,
        "cond_entropy-3": 1.2743203038301274,
        "total_length-nopunct": 6871,
        "mean_pred_length-nopunct": 26.83984375,
        "std_pred_length-nopunct": 6.469409264035313,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.09372725949643429,
        "vocab_size-1-nopunct": 644,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.212996434918902,
        "distinct-2-nopunct": 0.28662131519274375,
        "vocab_size-2-nopunct": 1896,
        "unique-2-nopunct": 1043,
        "entropy-2-nopunct": 9.687500389707193,
        "cond_entropy-2-nopunct": 2.527117846467502,
        "distinct-3-nopunct": 0.4991350841327253,
        "vocab_size-3-nopunct": 3174,
        "unique-3-nopunct": 2217,
        "entropy-3-nopunct": 10.91952845056257,
        "cond_entropy-3-nopunct": 1.2539719516826564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 34.39136,
        "local_recall": {
            "1": 0.61880747552655
        },
        "rouge1": {
            "precision": 0.69375,
            "recall": 0.63032,
            "fmeasure": 0.65081
        },
        "rouge2": {
            "precision": 0.45186,
            "recall": 0.41205,
            "fmeasure": 0.42434
        },
        "rougeL": {
            "precision": 0.57647,
            "recall": 0.52406,
            "fmeasure": 0.54092
        },
        "rougeLsum": {
            "precision": 0.57647,
            "recall": 0.52406,
            "fmeasure": 0.54092
        },
        "nist": 6.267917286796129,
        "bleurt": -0.05405,
        "bertscore": {
            "precision": 0.89757,
            "recall": 0.88499,
            "f1": 0.8909
        },
        "nubia": {
            "semantic_relation": 3.93104,
            "contradiction": 5.26164,
            "irrelevancy": 16.95567,
            "logical_agreement": 77.78268,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.08261,
            "nubia_score": 0.65864
        },
        "meteor": 0.33869275994529136
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.58692,
        "msttr-100_nopunct": 0.58583,
        "total_length": 1323,
        "mean_pred_length": 28.76086956521739,
        "std_pred_length": 7.913073339647431,
        "median_pred_length": 28.0,
        "min_pred_length": 18,
        "max_pred_length": 48,
        "distinct-1": 0.15419501133786848,
        "vocab_size-1": 204,
        "unique-1": 74,
        "entropy-1": 6.504984195782073,
        "distinct-2": 0.42991386061080655,
        "vocab_size-2": 549,
        "unique-2": 295,
        "entropy-2": 8.540028450595855,
        "cond_entropy-2": 1.986183641290517,
        "distinct-3": 0.6620633631194152,
        "vocab_size-3": 815,
        "unique-3": 600,
        "entropy-3": 9.390359204117614,
        "cond_entropy-3": 0.8452185770366504,
        "total_length-nopunct": 1220,
        "mean_pred_length-nopunct": 26.52173913043478,
        "std_pred_length-nopunct": 7.002295059897156,
        "median_pred_length-nopunct": 26.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.16393442622950818,
        "vocab_size-1-nopunct": 200,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.490000585092399,
        "distinct-2-nopunct": 0.4403747870528109,
        "vocab_size-2-nopunct": 517,
        "unique-2-nopunct": 283,
        "entropy-2-nopunct": 8.454217079251173,
        "cond_entropy-2-nopunct": 1.975045111576162,
        "distinct-3-nopunct": 0.6657801418439716,
        "vocab_size-3-nopunct": 751,
        "unique-3-nopunct": 559,
        "entropy-3-nopunct": 9.270384338263218,
        "cond_entropy-3-nopunct": 0.8226188309822554,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 36.85952,
        "local_recall": {
            "1": 0.6366639141205616
        },
        "rouge1": {
            "precision": 0.68901,
            "recall": 0.65021,
            "fmeasure": 0.65602
        },
        "rouge2": {
            "precision": 0.45721,
            "recall": 0.43963,
            "fmeasure": 0.43932
        },
        "rougeL": {
            "precision": 0.56716,
            "recall": 0.53444,
            "fmeasure": 0.5399
        },
        "rougeLsum": {
            "precision": 0.56716,
            "recall": 0.53444,
            "fmeasure": 0.5399
        },
        "nist": 5.534688201404966,
        "bleurt": -0.08363,
        "bertscore": {
            "precision": 0.89866,
            "recall": 0.89392,
            "f1": 0.8959
        },
        "nubia": {
            "semantic_relation": 3.84164,
            "contradiction": 38.90314,
            "irrelevancy": 23.11177,
            "logical_agreement": 37.98509,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.48132,
            "nubia_score": 0.58814
        },
        "meteor": 0.3282292602717239
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 8,
        "entropy-1": 3.7219280948873625,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 14,
        "unique-2": 10,
        "entropy-2": 3.7254805569978675,
        "cond_entropy-2": -0.04089198233393865,
        "distinct-3": 0.8125,
        "vocab_size-3": 13,
        "unique-3": 10,
        "entropy-3": 3.625,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6143694458867563,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.5,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 0.7857142857142857,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.3787834934861767,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 89.76608,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92929,
            "fmeasure": 0.96265
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.85833,
            "fmeasure": 0.89123
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92929,
            "fmeasure": 0.96265
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92929,
            "fmeasure": 0.96265
        },
        "nist": 4.5357846114582925,
        "bleurt": 0.83633,
        "bertscore": {
            "precision": 0.99792,
            "recall": 0.9941,
            "f1": 0.9947
        },
        "nubia": {
            "semantic_relation": 4.8283,
            "contradiction": 0.45709,
            "irrelevancy": 0.50452,
            "logical_agreement": 99.03839,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.67991,
            "nubia_score": 0.96149
        },
        "meteor": 0.6012713613838102
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.6305,
        "msttr-100_nopunct": 0.63599,
        "total_length": 28058,
        "mean_pred_length": 20.084466714387975,
        "std_pred_length": 6.884569954308253,
        "median_pred_length": 19.0,
        "min_pred_length": 3,
        "max_pred_length": 47,
        "distinct-1": 0.06254900563119253,
        "vocab_size-1": 1755,
        "unique-1": 828,
        "entropy-1": 7.492020996243134,
        "distinct-2": 0.2076816323468737,
        "vocab_size-2": 5537,
        "unique-2": 3284,
        "entropy-2": 10.319253050115394,
        "cond_entropy-2": 2.713536662928814,
        "distinct-3": 0.38568714376187463,
        "vocab_size-3": 9744,
        "unique-3": 6879,
        "entropy-3": 11.825060657596184,
        "cond_entropy-3": 1.5129814774575405,
        "total_length-nopunct": 25284,
        "mean_pred_length-nopunct": 18.098783106657123,
        "std_pred_length-nopunct": 6.443875193535715,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.06889732637240943,
        "vocab_size-1-nopunct": 1742,
        "unique-1-nopunct": 826,
        "entropy-1-nopunct": 7.564146089931732,
        "distinct-2-nopunct": 0.2229664671160045,
        "vocab_size-2-nopunct": 5326,
        "unique-2-nopunct": 3240,
        "entropy-2-nopunct": 10.277479349778552,
        "cond_entropy-2-nopunct": 2.783773875427068,
        "distinct-3-nopunct": 0.4085371276122721,
        "vocab_size-3-nopunct": 9188,
        "unique-3-nopunct": 6617,
        "entropy-3-nopunct": 11.790456843403957,
        "cond_entropy-3-nopunct": 1.5288471258672627,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 37.16995,
        "local_recall": {
            "1": 0.6444489629930866
        },
        "rouge1": {
            "precision": 0.67512,
            "recall": 0.65546,
            "fmeasure": 0.65291
        },
        "rouge2": {
            "precision": 0.46205,
            "recall": 0.44944,
            "fmeasure": 0.44716
        },
        "rougeL": {
            "precision": 0.58495,
            "recall": 0.56898,
            "fmeasure": 0.56651
        },
        "rougeLsum": {
            "precision": 0.58495,
            "recall": 0.56898,
            "fmeasure": 0.56651
        },
        "nist": 6.877066373028683,
        "bleurt": -0.02313,
        "bertscore": {
            "precision": 0.88748,
            "recall": 0.88418,
            "f1": 0.88539
        },
        "nubia": {
            "semantic_relation": 4.15126,
            "contradiction": 4.97907,
            "irrelevancy": 19.91039,
            "logical_agreement": 75.11055,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.8244,
            "nubia_score": 0.71338
        },
        "meteor": 0.34968562108720247
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 17.37485,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.4902,
            "fmeasure": 0.6261
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.2451,
            "fmeasure": 0.3159
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.34641,
            "fmeasure": 0.43915
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.34641,
            "fmeasure": 0.43915
        },
        "nist": 0.914660434390841,
        "bleurt": 0.04468,
        "bertscore": {
            "precision": 0.90398,
            "recall": 0.856,
            "f1": 0.87933
        },
        "nubia": {
            "semantic_relation": 3.4059,
            "contradiction": 0.3122,
            "irrelevancy": 20.90415,
            "logical_agreement": 78.78365,
            "grammar_ref": 4.84215,
            "grammar_hyp": 5.25284,
            "nubia_score": 0.39631
        },
        "meteor": 0.2721181657461233
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750189,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.29361197172017117,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.293660689688185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.30589329020324285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.99666,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 1.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.45333,
            "recall": 0.77143,
            "fmeasure": 0.57094
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.36264,
            "fmeasure": 0.26458
        },
        "rougeL": {
            "precision": 0.34667,
            "recall": 0.59048,
            "fmeasure": 0.43675
        },
        "rougeLsum": {
            "precision": 0.34667,
            "recall": 0.59048,
            "fmeasure": 0.43675
        },
        "nist": 2.838332083653563,
        "bleurt": -0.03213,
        "bertscore": {
            "precision": 0.85586,
            "recall": 0.87967,
            "f1": 0.8676
        },
        "nubia": {
            "semantic_relation": 3.49228,
            "contradiction": 0.52457,
            "irrelevancy": 64.71254,
            "logical_agreement": 34.76289,
            "grammar_ref": 4.11472,
            "grammar_hyp": 2.87294,
            "nubia_score": 0.32128
        },
        "meteor": 0.34634727984808195
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 25.5,
        "std_pred_length": 7.5,
        "median_pred_length": 25.5,
        "min_pred_length": 18,
        "max_pred_length": 33,
        "distinct-1": 0.5294117647058824,
        "vocab_size-1": 27,
        "unique-1": 12,
        "entropy-1": 4.559584410556527,
        "distinct-2": 0.7142857142857143,
        "vocab_size-2": 35,
        "unique-2": 22,
        "entropy-2": 5.027875405295545,
        "cond_entropy-2": 0.47289674704167195,
        "distinct-3": 0.7446808510638298,
        "vocab_size-3": 35,
        "unique-3": 23,
        "entropy-3": 5.043950553805299,
        "cond_entropy-3": 0.041046826757396494,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5217391304347826,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.376716575575198,
        "distinct-2-nopunct": 0.6818181818181818,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.80591144813358,
        "cond_entropy-2-nopunct": 0.48132420803482995,
        "distinct-3-nopunct": 0.7142857142857143,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.8208888513501895,
        "cond_entropy-3-nopunct": 0.04609741133583156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 75.23838,
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.9142857142857143
        },
        "rouge1": {
            "precision": 0.93678,
            "recall": 0.88824,
            "fmeasure": 0.91073
        },
        "rouge2": {
            "precision": 0.82738,
            "recall": 0.78962,
            "fmeasure": 0.80707
        },
        "rougeL": {
            "precision": 0.84483,
            "recall": 0.80588,
            "fmeasure": 0.82392
        },
        "rougeLsum": {
            "precision": 0.84483,
            "recall": 0.80588,
            "fmeasure": 0.82392
        },
        "nist": 4.9460728142949995,
        "bleurt": 0.50357,
        "bertscore": {
            "precision": 0.96907,
            "recall": 0.96214,
            "f1": 0.96353
        },
        "nubia": {
            "semantic_relation": 4.90403,
            "contradiction": 1.01007,
            "irrelevancy": 1.07812,
            "logical_agreement": 97.91181,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.64675,
            "nubia_score": 0.90634
        },
        "meteor": 0.497855074804285
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.26964,
        "msttr-100_nopunct": 0.27273,
        "total_length": 5612,
        "mean_pred_length": 5.709053916581892,
        "std_pred_length": 1.7977009790037124,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 14,
        "distinct-1": 0.024411974340698504,
        "vocab_size-1": 137,
        "unique-1": 48,
        "entropy-1": 4.358865253956785,
        "distinct-2": 0.07474616547850507,
        "vocab_size-2": 346,
        "unique-2": 165,
        "entropy-2": 5.523041412673621,
        "cond_entropy-2": 0.9750888473533138,
        "distinct-3": 0.12918266593527153,
        "vocab_size-3": 471,
        "unique-3": 269,
        "entropy-3": 6.444028822247255,
        "cond_entropy-3": 0.7788290503747355,
        "total_length-nopunct": 4498,
        "mean_pred_length-nopunct": 4.575788402848423,
        "std_pred_length-nopunct": 1.4434416047471923,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.029568697198755003,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 4.231723336178098,
        "distinct-2-nopunct": 0.0802275960170697,
        "vocab_size-2-nopunct": 282,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 5.197849732375595,
        "cond_entropy-2-nopunct": 0.8603820812410834,
        "distinct-3-nopunct": 0.12830635609948676,
        "vocab_size-3-nopunct": 325,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 5.750437500454273,
        "cond_entropy-3-nopunct": 0.7302549716090672,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 27.48135,
        "local_recall": {
            "1": 0.48041104688503533
        },
        "rouge1": {
            "precision": 0.51152,
            "recall": 0.49903,
            "fmeasure": 0.49679
        },
        "rouge2": {
            "precision": 0.33491,
            "recall": 0.32436,
            "fmeasure": 0.32358
        },
        "rougeL": {
            "precision": 0.51076,
            "recall": 0.4983,
            "fmeasure": 0.49605
        },
        "rougeLsum": {
            "precision": 0.51076,
            "recall": 0.4983,
            "fmeasure": 0.49605
        },
        "nist": 2.666787831209611,
        "bleurt": 0.08799,
        "bertscore": {
            "precision": 0.85191,
            "recall": 0.85036,
            "f1": 0.85066
        },
        "nubia": {
            "semantic_relation": 3.03958,
            "contradiction": 3.99284,
            "irrelevancy": 26.09664,
            "logical_agreement": 69.91052,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.6491,
            "nubia_score": 0.57012
        },
        "meteor": 0.264530687626809
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleurt": 0.97683,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 5.85516,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "nist": 1.0600905711694244,
        "bleurt": -0.22976,
        "bertscore": {
            "precision": 0.79921,
            "recall": 0.78021,
            "f1": 0.78959
        },
        "nubia": {
            "semantic_relation": 2.27956,
            "contradiction": 0.98439,
            "irrelevancy": 92.54747,
            "logical_agreement": 6.46815,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.65186,
            "nubia_score": 0.24183
        },
        "meteor": 0.11611197449693993
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.854285871987245,
        "bleurt": 0.94692,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.1365257343456969,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 42.22374,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.73684,
            "fmeasure": 0.75676
        },
        "rouge2": {
            "precision": 0.58824,
            "recall": 0.55556,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.57895,
            "fmeasure": 0.59459
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.57895,
            "fmeasure": 0.59459
        },
        "nist": 3.519172466471895,
        "bleurt": 0.63231,
        "bertscore": {
            "precision": 0.92723,
            "recall": 0.91193,
            "f1": 0.91952
        },
        "nubia": {
            "semantic_relation": 4.42806,
            "contradiction": 0.1384,
            "irrelevancy": 0.55046,
            "logical_agreement": 99.31114,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.65274,
            "nubia_score": 0.87948
        },
        "meteor": 0.42603239523580966
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.386842188131012,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.1453336945603553,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.94417,
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.69841,
            "recall": 0.57784,
            "fmeasure": 0.62937
        },
        "rouge2": {
            "precision": 0.48333,
            "recall": 0.40303,
            "fmeasure": 0.43746
        },
        "rougeL": {
            "precision": 0.4127,
            "recall": 0.34976,
            "fmeasure": 0.3773
        },
        "rougeLsum": {
            "precision": 0.4127,
            "recall": 0.34976,
            "fmeasure": 0.3773
        },
        "nist": 3.349181988803456,
        "bleurt": 0.08599,
        "bertscore": {
            "precision": 0.93827,
            "recall": 0.92874,
            "f1": 0.93348
        },
        "nubia": {
            "semantic_relation": 4.52951,
            "contradiction": 15.0946,
            "irrelevancy": 28.50678,
            "logical_agreement": 56.39862,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.82529,
            "nubia_score": 0.81625
        },
        "meteor": 0.3633184383678451
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 50.16514,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.86364,
            "fmeasure": 0.81364
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.475,
            "fmeasure": 0.43333
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.68182,
            "fmeasure": 0.63182
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.68182,
            "fmeasure": 0.63182
        },
        "nist": 3.657513751259632,
        "bleurt": 0.67549,
        "bertscore": {
            "precision": 0.95273,
            "recall": 0.97509,
            "f1": 0.96378
        },
        "nubia": {
            "semantic_relation": 4.99632,
            "contradiction": 0.10339,
            "irrelevancy": 4.43908,
            "logical_agreement": 95.45753,
            "grammar_ref": 5.60099,
            "grammar_hyp": 4.79041,
            "nubia_score": 0.99938
        },
        "meteor": 0.5143698792090522
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.99784,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "nist": 2.573335161354208,
        "bleurt": -0.44974,
        "bertscore": {
            "precision": 0.83281,
            "recall": 0.89107,
            "f1": 0.86096
        },
        "nubia": {
            "semantic_relation": 2.61427,
            "contradiction": 26.87911,
            "irrelevancy": 70.24828,
            "logical_agreement": 2.87261,
            "grammar_ref": 3.66596,
            "grammar_hyp": 4.47148,
            "nubia_score": 0.2555
        },
        "meteor": 0.35544347173293367
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4182958340544896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 32.5234,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.79259,
            "fmeasure": 0.67589
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.53704,
            "fmeasure": 0.45079
        },
        "rougeL": {
            "precision": 0.51282,
            "recall": 0.68889,
            "fmeasure": 0.58762
        },
        "rougeLsum": {
            "precision": 0.51282,
            "recall": 0.68889,
            "fmeasure": 0.58762
        },
        "nist": 2.46308841429772,
        "bleurt": 0.62516,
        "bertscore": {
            "precision": 0.92104,
            "recall": 0.94251,
            "f1": 0.93165
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29937,
            "irrelevancy": 0.42901,
            "logical_agreement": 99.27162,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.67448,
            "nubia_score": 0.93254
        },
        "meteor": 0.3936162021814872
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 3.0,
        "median_pred_length": 23.0,
        "min_pred_length": 20,
        "max_pred_length": 26,
        "distinct-1": 0.7608695652173914,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 4.9854122277491095,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.41397707318275,
        "cond_entropy-2": 0.4075716512658179,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.019495148239489102,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.753055907333276,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.19529593449622,
        "cond_entropy-2-nopunct": 0.4458648791394723,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.07384,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.76511,
            "recall": 0.70926,
            "fmeasure": 0.73315
        },
        "rouge2": {
            "precision": 0.54937,
            "recall": 0.52934,
            "fmeasure": 0.53722
        },
        "rougeL": {
            "precision": 0.66789,
            "recall": 0.63148,
            "fmeasure": 0.64673
        },
        "rougeLsum": {
            "precision": 0.66789,
            "recall": 0.63148,
            "fmeasure": 0.64673
        },
        "nist": 4.187391483209298,
        "bleurt": 0.15436,
        "bertscore": {
            "precision": 0.90136,
            "recall": 0.89487,
            "f1": 0.89611
        },
        "nubia": {
            "semantic_relation": 4.22505,
            "contradiction": 2.42741,
            "irrelevancy": 45.03202,
            "logical_agreement": 52.54057,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.09458,
            "nubia_score": 0.74876
        },
        "meteor": 0.326176195523864
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.07154,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.84921,
            "fmeasure": 0.82784
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.64444,
            "fmeasure": 0.62626
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.84921,
            "fmeasure": 0.82784
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.84921,
            "fmeasure": 0.82784
        },
        "nist": 2.2441753173667918,
        "bleurt": 0.43509,
        "bertscore": {
            "precision": 0.94164,
            "recall": 0.95365,
            "f1": 0.94761
        },
        "nubia": {
            "semantic_relation": 4.39812,
            "contradiction": 0.52773,
            "irrelevancy": 0.8447,
            "logical_agreement": 98.62757,
            "grammar_ref": 6.44614,
            "grammar_hyp": 6.10071,
            "nubia_score": 0.80318
        },
        "meteor": 0.3968768705230004
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 53.68805,
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.78333,
            "recall": 0.72294,
            "fmeasure": 0.75184
        },
        "rouge2": {
            "precision": 0.63158,
            "recall": 0.59048,
            "fmeasure": 0.61026
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.61183,
            "fmeasure": 0.63802
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.61183,
            "fmeasure": 0.63802
        },
        "nist": 4.265983335925113,
        "bleurt": 0.56,
        "bertscore": {
            "precision": 0.96487,
            "recall": 0.95448,
            "f1": 0.95965
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18101,
            "irrelevancy": 0.7477,
            "logical_agreement": 99.07129,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.71992,
            "nubia_score": 0.98633
        },
        "meteor": 0.5160068008989984
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.5898980954642865,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219046,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.36548,
        "local_recall": {
            "1": 0.0,
            "2": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.6,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.14286,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.4,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.4,
            "fmeasure": 0.42857
        },
        "nist": 2.3919163166232815,
        "bleurt": -0.30609,
        "bertscore": {
            "precision": 0.8878,
            "recall": 0.87356,
            "f1": 0.88062
        },
        "nubia": {
            "semantic_relation": 3.66228,
            "contradiction": 6.08511,
            "irrelevancy": 93.58663,
            "logical_agreement": 0.32826,
            "grammar_ref": 5.62728,
            "grammar_hyp": 5.34298,
            "nubia_score": 0.49896
        },
        "meteor": 0.3167057782603418
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.20184123230257,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 11.59911,
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.46551,
            "fmeasure": 0.52827
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.13258,
            "fmeasure": 0.15134
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.29623,
            "fmeasure": 0.33617
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.29623,
            "fmeasure": 0.33617
        },
        "nist": 2.785387893633816,
        "bleurt": -0.2312,
        "bertscore": {
            "precision": 0.90075,
            "recall": 0.84975,
            "f1": 0.87451
        },
        "nubia": {
            "semantic_relation": 2.21318,
            "contradiction": 70.93848,
            "irrelevancy": 27.72868,
            "logical_agreement": 1.33284,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.25361,
            "nubia_score": 0.2342
        },
        "meteor": 0.2402462401421079
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5,
        "vocab_size-1": 12,
        "unique-1": 2,
        "entropy-1": 3.5016291673878226,
        "distinct-2": 0.5909090909090909,
        "vocab_size-2": 13,
        "unique-2": 4,
        "entropy-2": 3.6412498004554794,
        "cond_entropy-2": 0.14719639064341367,
        "distinct-3": 0.65,
        "vocab_size-3": 13,
        "unique-3": 6,
        "entropy-3": 3.6219280948873624,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.368522527728207,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": 0.162496476250065,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.503258334775645,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 33.51347,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.89394,
            "recall": 0.73769,
            "fmeasure": 0.80135
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.66667,
            "fmeasure": 0.64857
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "nist": 3.0753781696409983,
        "bleurt": 0.30361,
        "bertscore": {
            "precision": 0.96054,
            "recall": 0.88556,
            "f1": 0.92145
        },
        "nubia": {
            "semantic_relation": 4.02848,
            "contradiction": 0.21257,
            "irrelevancy": 17.70474,
            "logical_agreement": 82.08268,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.88377,
            "nubia_score": 0.53293
        },
        "meteor": 0.36452479981371805
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.49651,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.87395,
            "fmeasure": 0.8404
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.72115,
            "fmeasure": 0.69124
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53782,
            "fmeasure": 0.51717
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53782,
            "fmeasure": 0.51717
        },
        "nist": 2.95205649645858,
        "bleurt": 0.32124,
        "bertscore": {
            "precision": 0.92794,
            "recall": 0.94456,
            "f1": 0.93131
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23507,
            "irrelevancy": 0.45502,
            "logical_agreement": 99.30991,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.27144,
            "nubia_score": 0.88323
        },
        "meteor": 0.4952636339762765
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.9862,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "nist": 2.999613157008355,
        "bleurt": 0.32788,
        "bertscore": {
            "precision": 0.92121,
            "recall": 0.93507,
            "f1": 0.91522
        },
        "nubia": {
            "semantic_relation": 4.89848,
            "contradiction": 0.9382,
            "irrelevancy": 71.06404,
            "logical_agreement": 27.99776,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.92796,
            "nubia_score": 0.94178
        },
        "meteor": 0.35594327848477014
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 21,
        "entropy-1": 4.6534955617749425,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.3111273931922691,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.542748326446119,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.3091256330911615,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 43.01169,
        "local_recall": {
            "1": 0.2,
            "2": 0.29411764705882354,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.84545,
            "recall": 0.65055,
            "fmeasure": 0.71009
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.37575,
            "fmeasure": 0.38363
        },
        "rougeL": {
            "precision": 0.62121,
            "recall": 0.49784,
            "fmeasure": 0.53637
        },
        "rougeLsum": {
            "precision": 0.62121,
            "recall": 0.49784,
            "fmeasure": 0.53637
        },
        "nist": 2.82806530707011,
        "bleurt": 0.07519,
        "bertscore": {
            "precision": 0.92256,
            "recall": 0.91052,
            "f1": 0.91581
        },
        "nubia": {
            "semantic_relation": 4.41651,
            "contradiction": 0.54952,
            "irrelevancy": 16.88706,
            "logical_agreement": 82.56342,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.54378,
            "nubia_score": 0.67493
        },
        "meteor": 0.3510264293848364
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3248629576173574,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.2776134368191165,
        "cond_entropy-2-nopunct": 0.3067316181128199,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 31.12418,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.53571,
            "fmeasure": 0.57216
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.35897,
            "fmeasure": 0.38519
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.53571,
            "fmeasure": 0.57216
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.53571,
            "fmeasure": 0.57216
        },
        "nist": 2.7992659038640575,
        "bleurt": 0.51612,
        "bertscore": {
            "precision": 0.96062,
            "recall": 0.94124,
            "f1": 0.95083
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25523,
            "irrelevancy": 0.43086,
            "logical_agreement": 99.3139,
            "grammar_ref": 3.06207,
            "grammar_hyp": 2.88109,
            "nubia_score": 1.0
        },
        "meteor": 0.4209105062062473
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094893,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 67.49455,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.88988,
            "fmeasure": 0.82177
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.80855,
            "fmeasure": 0.74231
        },
        "rougeL": {
            "precision": 0.76471,
            "recall": 0.88988,
            "fmeasure": 0.82177
        },
        "rougeLsum": {
            "precision": 0.76471,
            "recall": 0.88988,
            "fmeasure": 0.82177
        },
        "nist": 3.6305042051392626,
        "bleurt": 0.37081,
        "bertscore": {
            "precision": 0.93719,
            "recall": 0.9741,
            "f1": 0.95529
        },
        "nubia": {
            "semantic_relation": 4.1055,
            "contradiction": 0.82828,
            "irrelevancy": 98.61827,
            "logical_agreement": 0.55345,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.87216,
            "nubia_score": 0.62185
        },
        "meteor": 0.5343641394985956
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 28.6419,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "nist": 1.3934338964335204,
        "bleurt": 0.82527,
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "meteor": 0.4307001776843669
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.9976702764876113,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.18615790478558608,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.807763576417195,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.20971762763487736,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.91308,
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.70085,
            "fmeasure": 0.67937
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27941,
            "fmeasure": 0.25758
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 0.5755,
            "fmeasure": 0.55873
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 0.5755,
            "fmeasure": 0.55873
        },
        "nist": 3.4698707927688233,
        "bleurt": 0.09678,
        "bertscore": {
            "precision": 0.94054,
            "recall": 0.95205,
            "f1": 0.94626
        },
        "nubia": {
            "semantic_relation": 3.90487,
            "contradiction": 0.17814,
            "irrelevancy": 72.61207,
            "logical_agreement": 27.2098,
            "grammar_ref": 5.3293,
            "grammar_hyp": 4.70781,
            "nubia_score": 0.65251
        },
        "meteor": 0.3405203605632155
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.788909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.06538684568063419,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.643856189774723,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.12029423371771175,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 61.3901,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.8303,
            "fmeasure": 0.84639
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.51429,
            "fmeasure": 0.53148
        },
        "rougeL": {
            "precision": 0.68182,
            "recall": 0.64848,
            "fmeasure": 0.66458
        },
        "rougeLsum": {
            "precision": 0.68182,
            "recall": 0.64848,
            "fmeasure": 0.66458
        },
        "nist": 4.407840135649856,
        "bleurt": 0.60638,
        "bertscore": {
            "precision": 0.94798,
            "recall": 0.95278,
            "f1": 0.95029
        },
        "nubia": {
            "semantic_relation": 4.83997,
            "contradiction": 0.16091,
            "irrelevancy": 48.51691,
            "logical_agreement": 51.32218,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.77471,
            "nubia_score": 0.98383
        },
        "meteor": 0.4656345869645458
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.23810548155250455,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.83287,
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.76852,
            "fmeasure": 0.67719
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "nist": 2.4544666759778946,
        "bleurt": 0.72015,
        "bertscore": {
            "precision": 0.94956,
            "recall": 0.97508,
            "f1": 0.96215
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35718,
            "irrelevancy": 0.72381,
            "logical_agreement": 98.91902,
            "grammar_ref": 4.6206,
            "grammar_hyp": 3.91998,
            "nubia_score": 0.96992
        },
        "meteor": 0.909197285279663
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 29.97005,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.66667,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.45455,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.58333,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.58333,
            "fmeasure": 0.66667
        },
        "nist": 2.4184325539668468,
        "bleurt": -0.34973,
        "bertscore": {
            "precision": 0.92753,
            "recall": 0.89287,
            "f1": 0.90987
        },
        "nubia": {
            "semantic_relation": 4.23607,
            "contradiction": 5.38698,
            "irrelevancy": 77.5092,
            "logical_agreement": 17.10382,
            "grammar_ref": 4.44512,
            "grammar_hyp": 5.66221,
            "nubia_score": 0.53089
        },
        "meteor": 0.35454376362834245
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6578823768686535,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.1922179169046628,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.423251796980338,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.22981123847439047,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 4.86848,
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.38317,
            "recall": 0.56481,
            "fmeasure": 0.45503
        },
        "rouge2": {
            "precision": 0.0767,
            "recall": 0.10764,
            "fmeasure": 0.08743
        },
        "rougeL": {
            "precision": 0.32761,
            "recall": 0.44717,
            "fmeasure": 0.36964
        },
        "rougeLsum": {
            "precision": 0.32761,
            "recall": 0.44717,
            "fmeasure": 0.36964
        },
        "nist": 1.6867468520972486,
        "bleurt": -0.00962,
        "bertscore": {
            "precision": 0.79199,
            "recall": 0.83417,
            "f1": 0.80891
        },
        "nubia": {
            "semantic_relation": 3.89856,
            "contradiction": 4.77585,
            "irrelevancy": 86.51,
            "logical_agreement": 8.71414,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.35217,
            "nubia_score": 0.60419
        },
        "meteor": 0.21221560314588347
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 57.8357,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.65278,
            "fmeasure": 0.60624
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "nist": 2.979989411179661,
        "bleurt": 0.27681,
        "bertscore": {
            "precision": 0.91451,
            "recall": 0.93052,
            "f1": 0.92245
        },
        "nubia": {
            "semantic_relation": 4.23391,
            "contradiction": 1.15822,
            "irrelevancy": 83.7616,
            "logical_agreement": 15.08019,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.16949,
            "nubia_score": 0.59609
        },
        "meteor": 0.47005324912871144
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 38.41045,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.60185,
            "fmeasure": 0.73256
        },
        "rouge2": {
            "precision": 0.71111,
            "recall": 0.47757,
            "fmeasure": 0.57115
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.57449,
            "fmeasure": 0.67281
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.57449,
            "fmeasure": 0.67281
        },
        "nist": 2.089797280529788,
        "bleurt": -0.39541,
        "bertscore": {
            "precision": 0.91142,
            "recall": 0.88608,
            "f1": 0.89774
        },
        "nubia": {
            "semantic_relation": 3.96695,
            "contradiction": 1.40639,
            "irrelevancy": 49.54798,
            "logical_agreement": 49.04563,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.27317,
            "nubia_score": 0.6
        },
        "meteor": 0.32670875432071766
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.94773,
        "local_recall": {
            "1": 0.5,
            "2": 0.3125
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.275,
            "fmeasure": 0.37931
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.13158,
            "fmeasure": 0.18519
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.225,
            "fmeasure": 0.31034
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.225,
            "fmeasure": 0.31034
        },
        "nist": 0.27955318352106245,
        "bleurt": -0.16252,
        "bertscore": {
            "precision": 0.8594,
            "recall": 0.79343,
            "f1": 0.8251
        },
        "nubia": {
            "semantic_relation": 3.43237,
            "contradiction": 0.33988,
            "irrelevancy": 0.53274,
            "logical_agreement": 99.12738,
            "grammar_ref": 4.55046,
            "grammar_hyp": 5.76496,
            "nubia_score": 0.38481
        },
        "meteor": 0.16734015292606902
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 74.26141,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.85714,
            "recall": 0.75,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "nist": 3.4723355925730734,
        "bleurt": 0.70747,
        "bertscore": {
            "precision": 0.97734,
            "recall": 0.95629,
            "f1": 0.9667
        },
        "nubia": {
            "semantic_relation": 4.86369,
            "contradiction": 1.31576,
            "irrelevancy": 0.75386,
            "logical_agreement": 97.93038,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.49013,
            "nubia_score": 0.91027
        },
        "meteor": 0.5112614165460022
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.64,
        "total_length": 126,
        "mean_pred_length": 15.75,
        "std_pred_length": 3.929058411375428,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5793650793650794,
        "vocab_size-1": 73,
        "unique-1": 45,
        "entropy-1": 5.83201196696184,
        "distinct-2": 0.8305084745762712,
        "vocab_size-2": 98,
        "unique-2": 80,
        "entropy-2": 6.530865295087878,
        "cond_entropy-2": 0.5731087828065965,
        "distinct-3": 0.8909090909090909,
        "vocab_size-3": 98,
        "unique-3": 86,
        "entropy-3": 6.563177895342848,
        "cond_entropy-3": 0.03971461874760869,
        "total_length-nopunct": 112,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.278719262151,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6160714285714286,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.786785613809401,
        "distinct-2-nopunct": 0.8269230769230769,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.339768804637957,
        "cond_entropy-2-nopunct": 0.6026423683860965,
        "distinct-3-nopunct": 0.8854166666666666,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.355795834054493,
        "cond_entropy-3-nopunct": 0.035666272208469726,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 44.95176,
        "local_recall": {
            "1": 0.34615384615384615,
            "2": 0.6216216216216216,
            "3": 0.6438356164383562
        },
        "rouge1": {
            "precision": 0.72607,
            "recall": 0.64871,
            "fmeasure": 0.6687
        },
        "rouge2": {
            "precision": 0.49303,
            "recall": 0.45711,
            "fmeasure": 0.46243
        },
        "rougeL": {
            "precision": 0.63699,
            "recall": 0.57551,
            "fmeasure": 0.59036
        },
        "rougeLsum": {
            "precision": 0.63699,
            "recall": 0.57551,
            "fmeasure": 0.59036
        },
        "nist": 4.702146423208933,
        "bleurt": 0.00671,
        "bertscore": {
            "precision": 0.89899,
            "recall": 0.87709,
            "f1": 0.88654
        },
        "nubia": {
            "semantic_relation": 3.59818,
            "contradiction": 16.37842,
            "irrelevancy": 44.61839,
            "logical_agreement": 39.00319,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.10593,
            "nubia_score": 0.53692
        },
        "meteor": 0.3355344054070746
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.05628729973432273,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.92522,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.89487,
            "recall": 0.96154,
            "fmeasure": 0.92548
        },
        "rouge2": {
            "precision": 0.78704,
            "recall": 0.85119,
            "fmeasure": 0.81618
        },
        "rougeL": {
            "precision": 0.85641,
            "recall": 0.92308,
            "fmeasure": 0.88701
        },
        "rougeLsum": {
            "precision": 0.85641,
            "recall": 0.92308,
            "fmeasure": 0.88701
        },
        "nist": 4.56765228686027,
        "bleurt": 0.58631,
        "bertscore": {
            "precision": 0.96647,
            "recall": 0.97013,
            "f1": 0.96823
        },
        "nubia": {
            "semantic_relation": 4.61445,
            "contradiction": 0.34589,
            "irrelevancy": 33.6482,
            "logical_agreement": 66.00591,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.1709,
            "nubia_score": 0.85959
        },
        "meteor": 0.5237466623582268
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 7,
        "unique-1": 5,
        "entropy-1": 2.725480556997868,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.33007499855768774,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.3787834934861755,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 92.77192,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.8,
            "fmeasure": 0.71154
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.91667,
            "fmeasure": 0.82381
        },
        "nist": 3.496977106830779,
        "bleurt": 0.73619,
        "bertscore": {
            "precision": 0.97485,
            "recall": 0.99229,
            "f1": 0.98349
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35547,
            "irrelevancy": 0.81342,
            "logical_agreement": 98.83111,
            "grammar_ref": 7.77345,
            "grammar_hyp": 6.71465,
            "nubia_score": 1.0
        },
        "meteor": 0.5991546711750068
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.423065265165703,
        "bleurt": 0.94038,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.63594,
        "msttr-100_nopunct": 0.68044,
        "total_length": 10664,
        "mean_pred_length": 10.383641674780915,
        "std_pred_length": 4.482232062821136,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 26,
        "distinct-1": 0.1140285071267817,
        "vocab_size-1": 1216,
        "unique-1": 655,
        "entropy-1": 7.456229034193045,
        "distinct-2": 0.3341288782816229,
        "vocab_size-2": 3220,
        "unique-2": 2077,
        "entropy-2": 10.361412058104122,
        "cond_entropy-2": 2.5353023030486797,
        "distinct-3": 0.5394263151782603,
        "vocab_size-3": 4645,
        "unique-3": 3431,
        "entropy-3": 11.487075107316334,
        "cond_entropy-3": 1.165346253885653,
        "total_length-nopunct": 9187,
        "mean_pred_length-nopunct": 8.945472249269718,
        "std_pred_length-nopunct": 4.166793480882667,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.13138129966256668,
        "vocab_size-1-nopunct": 1207,
        "unique-1-nopunct": 655,
        "entropy-1-nopunct": 7.7629221388885465,
        "distinct-2-nopunct": 0.35,
        "vocab_size-2-nopunct": 2856,
        "unique-2-nopunct": 1849,
        "entropy-2-nopunct": 10.222854095247671,
        "cond_entropy-2-nopunct": 2.6970665744496403,
        "distinct-3-nopunct": 0.5589635854341737,
        "vocab_size-3-nopunct": 3991,
        "unique-3-nopunct": 2994,
        "entropy-3-nopunct": 11.285570287734618,
        "cond_entropy-3-nopunct": 1.190907280033711,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 44.47156,
        "local_recall": {
            "1": 0.6245861840653277
        },
        "rouge1": {
            "precision": 0.67312,
            "recall": 0.65085,
            "fmeasure": 0.64951
        },
        "rouge2": {
            "precision": 0.47251,
            "recall": 0.4545,
            "fmeasure": 0.45213
        },
        "rougeL": {
            "precision": 0.61383,
            "recall": 0.59209,
            "fmeasure": 0.59116
        },
        "rougeLsum": {
            "precision": 0.61383,
            "recall": 0.59209,
            "fmeasure": 0.59116
        },
        "nist": 7.285477470745101,
        "bleurt": 0.18525,
        "bertscore": {
            "precision": 0.90272,
            "recall": 0.89864,
            "f1": 0.90027
        },
        "nubia": {
            "semantic_relation": 4.12795,
            "contradiction": 4.6563,
            "irrelevancy": 14.90114,
            "logical_agreement": 80.44257,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.79097,
            "nubia_score": 0.7625
        },
        "meteor": 0.37481853073802235
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.66738,
        "msttr-100_nopunct": 0.69696,
        "total_length": 20610,
        "mean_pred_length": 21.51356993736952,
        "std_pred_length": 6.162493766872073,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 51,
        "distinct-1": 0.08427947598253276,
        "vocab_size-1": 1737,
        "unique-1": 820,
        "entropy-1": 7.759884249306025,
        "distinct-2": 0.2692346834927743,
        "vocab_size-2": 5291,
        "unique-2": 3194,
        "entropy-2": 10.707274654147644,
        "cond_entropy-2": 2.8058795529449725,
        "distinct-3": 0.4605755857494383,
        "vocab_size-3": 8610,
        "unique-3": 6117,
        "entropy-3": 12.092894267433428,
        "cond_entropy-3": 1.4533162218417854,
        "total_length-nopunct": 18192,
        "mean_pred_length-nopunct": 18.989561586638832,
        "std_pred_length-nopunct": 5.6168453407873,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.09476693051890941,
        "vocab_size-1-nopunct": 1724,
        "unique-1-nopunct": 819,
        "entropy-1-nopunct": 7.977980912404603,
        "distinct-2-nopunct": 0.2891377509574098,
        "vocab_size-2-nopunct": 4983,
        "unique-2-nopunct": 3101,
        "entropy-2-nopunct": 10.691355111252212,
        "cond_entropy-2-nopunct": 2.858210298223242,
        "distinct-3-nopunct": 0.4934873433275989,
        "vocab_size-3-nopunct": 8032,
        "unique-3-nopunct": 5829,
        "entropy-3-nopunct": 12.11063533171367,
        "cond_entropy-3-nopunct": 1.4978532895986458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 32.19004,
        "local_recall": {
            "1": 0.6123547747237178
        },
        "rouge1": {
            "precision": 0.64567,
            "recall": 0.62633,
            "fmeasure": 0.62556
        },
        "rouge2": {
            "precision": 0.40852,
            "recall": 0.39515,
            "fmeasure": 0.39489
        },
        "rougeL": {
            "precision": 0.55972,
            "recall": 0.5428,
            "fmeasure": 0.54234
        },
        "rougeLsum": {
            "precision": 0.55972,
            "recall": 0.5428,
            "fmeasure": 0.54234
        },
        "nist": 6.627960433683619,
        "bleurt": -0.02701,
        "bertscore": {
            "precision": 0.88731,
            "recall": 0.88156,
            "f1": 0.88405
        },
        "nubia": {
            "semantic_relation": 4.35396,
            "contradiction": 4.36171,
            "irrelevancy": 18.86593,
            "logical_agreement": 76.77236,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.70672,
            "nubia_score": 0.76477
        },
        "meteor": 0.3382936263823026
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 1.5,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 11,
        "distinct-1": 0.6842105263157895,
        "vocab_size-1": 13,
        "unique-1": 7,
        "entropy-1": 3.6163485660751635,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.19247650427734211,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 14,
        "unique-3": 13,
        "entropy-3": 3.773557262275185,
        "cond_entropy-3": -0.047238912308487487,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.375,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.521640636343319,
        "cond_entropy-2-nopunct": 0.16449777920046132,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.418295834054489,
        "cond_entropy-3-nopunct": -0.05572575466978135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.79303,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.78042,
            "recall": 0.71528,
            "fmeasure": 0.74137
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.40233,
            "fmeasure": 0.40566
        },
        "rougeL": {
            "precision": 0.67196,
            "recall": 0.63226,
            "fmeasure": 0.64743
        },
        "rougeLsum": {
            "precision": 0.67196,
            "recall": 0.63226,
            "fmeasure": 0.64743
        },
        "nist": 4.075647954482343,
        "bleurt": 0.15708,
        "bertscore": {
            "precision": 0.91741,
            "recall": 0.89678,
            "f1": 0.9051
        },
        "nubia": {
            "semantic_relation": 4.06583,
            "contradiction": 16.06425,
            "irrelevancy": 18.13567,
            "logical_agreement": 65.80008,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.61375,
            "nubia_score": 0.6605
        },
        "meteor": 0.4105349957902004
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.75,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.73418371977919,
        "distinct-2": 0.918918918918919,
        "vocab_size-2": 34,
        "unique-2": 31,
        "entropy-2": 5.047291203466791,
        "cond_entropy-2": 0.2322519599892487,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838574,
        "cond_entropy-3": -0.06316699496684557,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7714285714285715,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.593429088311723,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.875,
        "cond_entropy-2-nopunct": 0.20680721749764197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.07305348763104855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 48.78487,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "rouge1": {
            "precision": 0.78081,
            "recall": 0.81734,
            "fmeasure": 0.79076
        },
        "rouge2": {
            "precision": 0.66614,
            "recall": 0.70404,
            "fmeasure": 0.67648
        },
        "rougeL": {
            "precision": 0.78081,
            "recall": 0.81734,
            "fmeasure": 0.79076
        },
        "rougeLsum": {
            "precision": 0.78081,
            "recall": 0.81734,
            "fmeasure": 0.79076
        },
        "nist": 3.803687594572273,
        "bleurt": 0.50465,
        "bertscore": {
            "precision": 0.95473,
            "recall": 0.96229,
            "f1": 0.95582
        },
        "nubia": {
            "semantic_relation": 4.53213,
            "contradiction": 0.64955,
            "irrelevancy": 33.6867,
            "logical_agreement": 65.66375,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.2158,
            "nubia_score": 0.8391
        },
        "meteor": 0.47735165825621306
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.36435,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.83333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.4,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.83333,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.83333,
            "fmeasure": 0.66667
        },
        "nist": 2.725079039070724,
        "bleurt": 0.01649,
        "bertscore": {
            "precision": 0.88586,
            "recall": 0.89922,
            "f1": 0.88313
        },
        "nubia": {
            "semantic_relation": 4.5535,
            "contradiction": 1.09867,
            "irrelevancy": 73.82184,
            "logical_agreement": 25.0795,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.91778,
            "nubia_score": 0.75091
        },
        "meteor": 0.3248983658988825
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.64435,
        "msttr-100_nopunct": 0.663,
        "total_length": 2334,
        "mean_pred_length": 32.416666666666664,
        "std_pred_length": 9.252251978122228,
        "median_pred_length": 31.5,
        "min_pred_length": 14,
        "max_pred_length": 53,
        "distinct-1": 0.18080548414738645,
        "vocab_size-1": 422,
        "unique-1": 220,
        "entropy-1": 7.100076828187858,
        "distinct-2": 0.4526967285587975,
        "vocab_size-2": 1024,
        "unique-2": 702,
        "entropy-2": 9.19862299855802,
        "cond_entropy-2": 2.0366092437080456,
        "distinct-3": 0.6378995433789955,
        "vocab_size-3": 1397,
        "unique-3": 1117,
        "entropy-3": 9.96172317413678,
        "cond_entropy-3": 0.7604085582836776,
        "total_length-nopunct": 2077,
        "mean_pred_length-nopunct": 28.84722222222222,
        "std_pred_length-nopunct": 8.536945397997757,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.1998074145402022,
        "vocab_size-1-nopunct": 415,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.184289348621294,
        "distinct-2-nopunct": 0.48179551122194514,
        "vocab_size-2-nopunct": 966,
        "unique-2-nopunct": 678,
        "entropy-2-nopunct": 9.169188360859227,
        "cond_entropy-2-nopunct": 2.0023953632636817,
        "distinct-3-nopunct": 0.6595964821520952,
        "vocab_size-3-nopunct": 1275,
        "unique-3-nopunct": 1027,
        "entropy-3-nopunct": 9.873680328657738,
        "cond_entropy-3-nopunct": 0.7228826585218586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 35.91842,
        "local_recall": {
            "1": 0.6321553011448482
        },
        "rouge1": {
            "precision": 0.67154,
            "recall": 0.61803,
            "fmeasure": 0.63699
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.40049,
            "fmeasure": 0.41288
        },
        "rougeL": {
            "precision": 0.53837,
            "recall": 0.49432,
            "fmeasure": 0.50968
        },
        "rougeLsum": {
            "precision": 0.53837,
            "recall": 0.49432,
            "fmeasure": 0.50968
        },
        "nist": 5.9472048862452445,
        "bleurt": -0.03955,
        "bertscore": {
            "precision": 0.89704,
            "recall": 0.8837,
            "f1": 0.89005
        },
        "nubia": {
            "semantic_relation": 4.02206,
            "contradiction": 4.0163,
            "irrelevancy": 12.95509,
            "logical_agreement": 83.02861,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.22304,
            "nubia_score": 0.67921
        },
        "meteor": 0.347095483178434
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.53051,
        "msttr-100_nopunct": 0.56155,
        "total_length": 9966,
        "mean_pred_length": 9.732421875,
        "std_pred_length": 5.859411132701092,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 34,
        "distinct-1": 0.08157736303431667,
        "vocab_size-1": 813,
        "unique-1": 445,
        "entropy-1": 6.601317497409598,
        "distinct-2": 0.2503914113173787,
        "vocab_size-2": 2239,
        "unique-2": 1350,
        "entropy-2": 9.434789922455645,
        "cond_entropy-2": 2.4970902024857518,
        "distinct-3": 0.4267491790856277,
        "vocab_size-3": 3379,
        "unique-3": 2364,
        "entropy-3": 10.589101443965086,
        "cond_entropy-3": 1.1305641557791932,
        "total_length-nopunct": 8445,
        "mean_pred_length-nopunct": 8.2470703125,
        "std_pred_length-nopunct": 5.181895618225163,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.0950858496151569,
        "vocab_size-1-nopunct": 803,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 6.866889456528337,
        "distinct-2-nopunct": 0.27718636302385125,
        "vocab_size-2-nopunct": 2057,
        "unique-2-nopunct": 1278,
        "entropy-2-nopunct": 9.36584548667766,
        "cond_entropy-2-nopunct": 2.6829440358547756,
        "distinct-3-nopunct": 0.4721788058768365,
        "vocab_size-3-nopunct": 3021,
        "unique-3-nopunct": 2194,
        "entropy-3-nopunct": 10.509766679693042,
        "cond_entropy-3-nopunct": 1.1503634812247399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 23.97062,
        "local_recall": {
            "1": 0.41102949238022146
        },
        "rouge1": {
            "precision": 0.40933,
            "recall": 0.37958,
            "fmeasure": 0.38296
        },
        "rouge2": {
            "precision": 0.19144,
            "recall": 0.1819,
            "fmeasure": 0.18234
        },
        "rougeL": {
            "precision": 0.36572,
            "recall": 0.33745,
            "fmeasure": 0.34097
        },
        "rougeLsum": {
            "precision": 0.36572,
            "recall": 0.33745,
            "fmeasure": 0.34097
        },
        "nist": 4.3600836228756705,
        "bleurt": -0.56477,
        "bertscore": {
            "precision": 0.84372,
            "recall": 0.83487,
            "f1": 0.83883
        },
        "nubia": {
            "semantic_relation": 2.38809,
            "contradiction": 12.86024,
            "irrelevancy": 32.01169,
            "logical_agreement": 55.12806,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.1945,
            "nubia_score": 0.38769
        },
        "meteor": 0.23867955948638409
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.67845,
        "msttr-100_nopunct": 0.70099,
        "total_length": 19376,
        "mean_pred_length": 15.55056179775281,
        "std_pred_length": 5.336081684360557,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.10012386457473163,
        "vocab_size-1": 1940,
        "unique-1": 915,
        "entropy-1": 7.990423283299733,
        "distinct-2": 0.3071704357418643,
        "vocab_size-2": 5569,
        "unique-2": 3492,
        "entropy-2": 10.878633305059308,
        "cond_entropy-2": 2.6810815501318395,
        "distinct-3": 0.4952025586353945,
        "vocab_size-3": 8361,
        "unique-3": 6076,
        "entropy-3": 12.12602227341651,
        "cond_entropy-3": 1.3067916606061682,
        "total_length-nopunct": 17299,
        "mean_pred_length-nopunct": 13.883627608346709,
        "std_pred_length-nopunct": 4.82919542092587,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.11127810856118851,
        "vocab_size-1-nopunct": 1925,
        "unique-1-nopunct": 913,
        "entropy-1-nopunct": 8.163736797716984,
        "distinct-2-nopunct": 0.3147075313025603,
        "vocab_size-2-nopunct": 5052,
        "unique-2-nopunct": 3239,
        "entropy-2-nopunct": 10.72233473755521,
        "cond_entropy-2-nopunct": 2.7180981851614425,
        "distinct-3-nopunct": 0.5067873303167421,
        "vocab_size-3-nopunct": 7504,
        "unique-3-nopunct": 5534,
        "entropy-3-nopunct": 11.973011096882715,
        "cond_entropy-3-nopunct": 1.3310087526512016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 38.76272,
        "local_recall": {
            "1": 0.6444934971960387
        },
        "rouge1": {
            "precision": 0.68342,
            "recall": 0.67084,
            "fmeasure": 0.66518
        },
        "rouge2": {
            "precision": 0.47678,
            "recall": 0.46742,
            "fmeasure": 0.46288
        },
        "rougeL": {
            "precision": 0.59354,
            "recall": 0.58107,
            "fmeasure": 0.57727
        },
        "rougeLsum": {
            "precision": 0.59354,
            "recall": 0.58107,
            "fmeasure": 0.57727
        },
        "nist": 7.210540254252562,
        "bleurt": -0.01676,
        "bertscore": {
            "precision": 0.89781,
            "recall": 0.89156,
            "f1": 0.8942
        },
        "nubia": {
            "semantic_relation": 4.30068,
            "contradiction": 5.44318,
            "irrelevancy": 22.34239,
            "logical_agreement": 72.21443,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.76142,
            "nubia_score": 0.76814
        },
        "meteor": 0.3680990527351029
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.375,
        "msttr-100_nopunct": 0.38351,
        "total_length": 4235,
        "mean_pred_length": 8.47,
        "std_pred_length": 1.9144450893143945,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.0332939787485242,
        "vocab_size-1": 141,
        "unique-1": 40,
        "entropy-1": 5.206931256866997,
        "distinct-2": 0.11834002677376171,
        "vocab_size-2": 442,
        "unique-2": 187,
        "entropy-2": 7.033987335293911,
        "cond_entropy-2": 1.5662585875745725,
        "distinct-3": 0.22442040185471407,
        "vocab_size-3": 726,
        "unique-3": 369,
        "entropy-3": 8.007252040559836,
        "cond_entropy-3": 1.0308507398996913,
        "total_length-nopunct": 3733,
        "mean_pred_length-nopunct": 7.466,
        "std_pred_length-nopunct": 1.8763912172039177,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.03643182427002411,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.279076280380777,
        "distinct-2-nopunct": 0.12001237240952675,
        "vocab_size-2-nopunct": 388,
        "unique-2-nopunct": 165,
        "entropy-2-nopunct": 6.760998584798701,
        "cond_entropy-2-nopunct": 1.6571705844147684,
        "distinct-3-nopunct": 0.22136845956824003,
        "vocab_size-3-nopunct": 605,
        "unique-3-nopunct": 313,
        "entropy-3-nopunct": 7.6405343191002135,
        "cond_entropy-3-nopunct": 1.1227797713207572,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 22.65927,
        "local_recall": {
            "1": 0.4871250331829042
        },
        "rouge1": {
            "precision": 0.52366,
            "recall": 0.51006,
            "fmeasure": 0.50683
        },
        "rouge2": {
            "precision": 0.28551,
            "recall": 0.27912,
            "fmeasure": 0.27598
        },
        "rougeL": {
            "precision": 0.49841,
            "recall": 0.48677,
            "fmeasure": 0.48307
        },
        "rougeLsum": {
            "precision": 0.49841,
            "recall": 0.48677,
            "fmeasure": 0.48307
        },
        "nist": 3.292013068595596,
        "bleurt": -0.01818,
        "bertscore": {
            "precision": 0.87906,
            "recall": 0.87703,
            "f1": 0.87771
        },
        "nubia": {
            "semantic_relation": 3.5168,
            "contradiction": 6.622,
            "irrelevancy": 25.50846,
            "logical_agreement": 67.86955,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.26283,
            "nubia_score": 0.64241
        },
        "meteor": 0.2702463351332385
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleurt": 0.95702,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "meteor": 1.0
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.52523,
        "msttr-100_nopunct": 0.5488,
        "total_length": 22078,
        "mean_pred_length": 10.624639076034649,
        "std_pred_length": 5.598931669686856,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 43,
        "distinct-1": 0.027131080713832776,
        "vocab_size-1": 599,
        "unique-1": 212,
        "entropy-1": 6.401253825525347,
        "distinct-2": 0.1399,
        "vocab_size-2": 2798,
        "unique-2": 1338,
        "entropy-2": 9.414675808448353,
        "cond_entropy-2": 2.7079471784519975,
        "distinct-3": 0.2993527508090615,
        "vocab_size-3": 5365,
        "unique-3": 3311,
        "entropy-3": 10.86764193185748,
        "cond_entropy-3": 1.490612905045748,
        "total_length-nopunct": 19240,
        "mean_pred_length-nopunct": 9.258902791145331,
        "std_pred_length-nopunct": 5.078531987722382,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.03076923076923077,
        "vocab_size-1-nopunct": 592,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 6.583731114055734,
        "distinct-2-nopunct": 0.15342034727887194,
        "vocab_size-2-nopunct": 2633,
        "unique-2-nopunct": 1364,
        "entropy-2-nopunct": 9.197084739127753,
        "cond_entropy-2-nopunct": 2.7858182817253208,
        "distinct-3-nopunct": 0.31587669870732515,
        "vocab_size-3-nopunct": 4765,
        "unique-3-nopunct": 3100,
        "entropy-3-nopunct": 10.62576275357878,
        "cond_entropy-3-nopunct": 1.5096998131030541,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 16.51565,
        "local_recall": {
            "1": 0.42779531225746364
        },
        "rouge1": {
            "precision": 0.46965,
            "recall": 0.43607,
            "fmeasure": 0.43537
        },
        "rouge2": {
            "precision": 0.23322,
            "recall": 0.21371,
            "fmeasure": 0.21243
        },
        "rougeL": {
            "precision": 0.42728,
            "recall": 0.39732,
            "fmeasure": 0.39648
        },
        "rougeLsum": {
            "precision": 0.42728,
            "recall": 0.39732,
            "fmeasure": 0.39648
        },
        "nist": 3.5711567720227673,
        "bleurt": -0.27582,
        "bertscore": {
            "precision": 0.84441,
            "recall": 0.83534,
            "f1": 0.83901
        },
        "nubia": {
            "semantic_relation": 3.1552,
            "contradiction": 9.69003,
            "irrelevancy": 26.99247,
            "logical_agreement": 63.3175,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.44189,
            "nubia_score": 0.52634
        },
        "meteor": 0.22996382140512242
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.29603,
        "msttr-100_nopunct": 0.29018,
        "total_length": 6359,
        "mean_pred_length": 8.893706293706293,
        "std_pred_length": 3.516180715325582,
        "median_pred_length": 8.0,
        "min_pred_length": 1,
        "max_pred_length": 27,
        "distinct-1": 0.025947476018241863,
        "vocab_size-1": 165,
        "unique-1": 55,
        "entropy-1": 4.791778294969209,
        "distinct-2": 0.08841247342310418,
        "vocab_size-2": 499,
        "unique-2": 247,
        "entropy-2": 6.309317175282584,
        "cond_entropy-2": 1.3248986788156476,
        "distinct-3": 0.1482758620689655,
        "vocab_size-3": 731,
        "unique-3": 427,
        "entropy-3": 6.973136162891839,
        "cond_entropy-3": 0.6348600289753976,
        "total_length-nopunct": 5548,
        "mean_pred_length-nopunct": 7.759440559440559,
        "std_pred_length-nopunct": 3.2045910632763204,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.02883922134102379,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 4.75078524176792,
        "distinct-2-nopunct": 0.09435133457479826,
        "vocab_size-2-nopunct": 456,
        "unique-2-nopunct": 242,
        "entropy-2-nopunct": 6.050278471554462,
        "cond_entropy-2-nopunct": 1.2727677395739017,
        "distinct-3-nopunct": 0.1529497450837582,
        "vocab_size-3-nopunct": 630,
        "unique-3-nopunct": 368,
        "entropy-3-nopunct": 6.689157086605814,
        "cond_entropy-3-nopunct": 0.5849886589715584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 24.73969,
        "local_recall": {
            "1": 0.513726897541719
        },
        "rouge1": {
            "precision": 0.5285,
            "recall": 0.52408,
            "fmeasure": 0.51247
        },
        "rouge2": {
            "precision": 0.29518,
            "recall": 0.28567,
            "fmeasure": 0.28018
        },
        "rougeL": {
            "precision": 0.4605,
            "recall": 0.44952,
            "fmeasure": 0.44267
        },
        "rougeLsum": {
            "precision": 0.4605,
            "recall": 0.44952,
            "fmeasure": 0.44267
        },
        "nist": 2.9164737015193736,
        "bleurt": 0.07001,
        "bertscore": {
            "precision": 0.84956,
            "recall": 0.84468,
            "f1": 0.8464
        },
        "nubia": {
            "semantic_relation": 3.50865,
            "contradiction": 2.67362,
            "irrelevancy": 25.81738,
            "logical_agreement": 71.509,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.86528,
            "nubia_score": 0.67538
        },
        "meteor": 0.27056060073574417
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73826,
        "msttr-100_nopunct": 0.76714,
        "total_length": 2310,
        "mean_pred_length": 21.79245283018868,
        "std_pred_length": 4.867522288485907,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 40,
        "distinct-1": 0.43333333333333335,
        "vocab_size-1": 1001,
        "unique-1": 780,
        "entropy-1": 8.403677405805634,
        "distinct-2": 0.8679673321234119,
        "vocab_size-2": 1913,
        "unique-2": 1776,
        "entropy-2": 10.732429486578267,
        "cond_entropy-2": 2.1383983617390476,
        "distinct-3": 0.9733079122974261,
        "vocab_size-3": 2042,
        "unique-3": 2005,
        "entropy-3": 10.971269785973426,
        "cond_entropy-3": 0.23243859602130862,
        "total_length-nopunct": 2132,
        "mean_pred_length-nopunct": 20.11320754716981,
        "std_pred_length-nopunct": 4.56467311590188,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.46622889305816134,
        "vocab_size-1-nopunct": 994,
        "unique-1-nopunct": 778,
        "entropy-1-nopunct": 8.558409803114394,
        "distinct-2-nopunct": 0.8795656465942744,
        "vocab_size-2-nopunct": 1782,
        "unique-2-nopunct": 1666,
        "entropy-2-nopunct": 10.641746241880186,
        "cond_entropy-2-nopunct": 2.158586871964657,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 1888,
        "unique-3-nopunct": 1862,
        "entropy-3-nopunct": 10.870942913312359,
        "cond_entropy-3-nopunct": 0.2228001831428417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 22.74777,
        "local_recall": {
            "1": 0.5068423720223011
        },
        "rouge1": {
            "precision": 0.52291,
            "recall": 0.52846,
            "fmeasure": 0.51517
        },
        "rouge2": {
            "precision": 0.28495,
            "recall": 0.28496,
            "fmeasure": 0.27941
        },
        "rougeL": {
            "precision": 0.43324,
            "recall": 0.43658,
            "fmeasure": 0.42632
        },
        "rougeLsum": {
            "precision": 0.43324,
            "recall": 0.43658,
            "fmeasure": 0.42632
        },
        "nist": 4.7665675737369435,
        "bleurt": -0.081,
        "bertscore": {
            "precision": 0.86784,
            "recall": 0.86743,
            "f1": 0.86725
        },
        "nubia": {
            "semantic_relation": 3.50136,
            "contradiction": 12.27954,
            "irrelevancy": 61.64403,
            "logical_agreement": 26.07643,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.57419,
            "nubia_score": 0.58994
        },
        "meteor": 0.25776683836329184
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.75227,
        "msttr-100_nopunct": 0.7725,
        "total_length": 2221,
        "mean_pred_length": 20.952830188679247,
        "std_pred_length": 4.5170162038959365,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 40,
        "distinct-1": 0.43538946420531294,
        "vocab_size-1": 967,
        "unique-1": 742,
        "entropy-1": 8.392234636504234,
        "distinct-2": 0.8638297872340426,
        "vocab_size-2": 1827,
        "unique-2": 1700,
        "entropy-2": 10.639757090003537,
        "cond_entropy-2": 2.0468911958946605,
        "distinct-3": 0.9741164758586361,
        "vocab_size-3": 1957,
        "unique-3": 1919,
        "entropy-3": 10.913407278819342,
        "cond_entropy-3": 0.27698628786610885,
        "total_length-nopunct": 2071,
        "mean_pred_length-nopunct": 19.537735849056602,
        "std_pred_length-nopunct": 4.339755945450543,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.4635441815548044,
        "vocab_size-1-nopunct": 960,
        "unique-1-nopunct": 738,
        "entropy-1-nopunct": 8.535614968852519,
        "distinct-2-nopunct": 0.870737913486005,
        "vocab_size-2-nopunct": 1711,
        "unique-2-nopunct": 1599,
        "entropy-2-nopunct": 10.549994403650038,
        "cond_entropy-2-nopunct": 2.1015284190461863,
        "distinct-3-nopunct": 0.9790209790209791,
        "vocab_size-3-nopunct": 1820,
        "unique-3-nopunct": 1790,
        "entropy-3-nopunct": 10.813711167623644,
        "cond_entropy-3-nopunct": 0.26676963207621046,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 17.60183,
        "local_recall": {
            "1": 0.45570819516816674
        },
        "rouge1": {
            "precision": 0.52622,
            "recall": 0.49018,
            "fmeasure": 0.50055
        },
        "rouge2": {
            "precision": 0.26051,
            "recall": 0.24371,
            "fmeasure": 0.24846
        },
        "rougeL": {
            "precision": 0.41513,
            "recall": 0.38591,
            "fmeasure": 0.39443
        },
        "rougeLsum": {
            "precision": 0.41513,
            "recall": 0.38591,
            "fmeasure": 0.39443
        },
        "nist": 4.478448571040586,
        "bleurt": -0.10506,
        "bertscore": {
            "precision": 0.86602,
            "recall": 0.85445,
            "f1": 0.85986
        },
        "nubia": {
            "semantic_relation": 3.53364,
            "contradiction": 12.39174,
            "irrelevancy": 61.16575,
            "logical_agreement": 26.44251,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.65756,
            "nubia_score": 0.59227
        },
        "meteor": 0.2286722727578874
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74909,
        "msttr-100_nopunct": 0.77381,
        "total_length": 2296,
        "mean_pred_length": 21.660377358490567,
        "std_pred_length": 5.003558719311743,
        "median_pred_length": 21.5,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.4268292682926829,
        "vocab_size-1": 980,
        "unique-1": 764,
        "entropy-1": 8.41606126589389,
        "distinct-2": 0.8575342465753425,
        "vocab_size-2": 1878,
        "unique-2": 1735,
        "entropy-2": 10.684231190526473,
        "cond_entropy-2": 2.0767434713509183,
        "distinct-3": 0.9716890595009597,
        "vocab_size-3": 2025,
        "unique-3": 1980,
        "entropy-3": 10.958960988880387,
        "cond_entropy-3": 0.2723154090438143,
        "total_length-nopunct": 2141,
        "mean_pred_length-nopunct": 20.19811320754717,
        "std_pred_length-nopunct": 4.826068776575885,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.45539467538533396,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 762,
        "entropy-1-nopunct": 8.565677357061766,
        "distinct-2-nopunct": 0.8673218673218673,
        "vocab_size-2-nopunct": 1765,
        "unique-2-nopunct": 1638,
        "entropy-2-nopunct": 10.608044770004257,
        "cond_entropy-2-nopunct": 2.1197400370232464,
        "distinct-3-nopunct": 0.9782270606531882,
        "vocab_size-3-nopunct": 1887,
        "unique-3-nopunct": 1848,
        "entropy-3-nopunct": 10.868917540798797,
        "cond_entropy-3-nopunct": 0.2594479458463058,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 15.12731,
        "local_recall": {
            "1": 0.4382488479262673
        },
        "rouge1": {
            "precision": 0.49832,
            "recall": 0.45621,
            "fmeasure": 0.46791
        },
        "rouge2": {
            "precision": 0.24046,
            "recall": 0.21838,
            "fmeasure": 0.22463
        },
        "rougeL": {
            "precision": 0.4052,
            "recall": 0.36919,
            "fmeasure": 0.37941
        },
        "rougeLsum": {
            "precision": 0.4052,
            "recall": 0.36919,
            "fmeasure": 0.37941
        },
        "nist": 4.314135087033586,
        "bleurt": -0.20519,
        "bertscore": {
            "precision": 0.86122,
            "recall": 0.84807,
            "f1": 0.85426
        },
        "nubia": {
            "semantic_relation": 3.31453,
            "contradiction": 14.86718,
            "irrelevancy": 57.03867,
            "logical_agreement": 28.09415,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.59866,
            "nubia_score": 0.53239
        },
        "meteor": 0.2207481722473383
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 39.59377,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.54762,
            "fmeasure": 0.55873
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "nist": 3.3909356245676445,
        "bleurt": 0.55609,
        "bertscore": {
            "precision": 0.96974,
            "recall": 0.96195,
            "f1": 0.96583
        },
        "nubia": {
            "semantic_relation": 4.85169,
            "contradiction": 1.64,
            "irrelevancy": 2.46738,
            "logical_agreement": 95.89262,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.30373,
            "nubia_score": 0.77531
        },
        "meteor": 0.4549807933512556
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.58767,
        "msttr-100_nopunct": 0.616,
        "total_length": 38272,
        "mean_pred_length": 7.580114874232521,
        "std_pred_length": 2.972703556630841,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 34,
        "distinct-1": 0.03422867892976589,
        "vocab_size-1": 1310,
        "unique-1": 558,
        "entropy-1": 7.008732009760286,
        "distinct-2": 0.1504680492429943,
        "vocab_size-2": 4999,
        "unique-2": 2586,
        "entropy-2": 9.983478565203393,
        "cond_entropy-2": 2.5797882056554884,
        "distinct-3": 0.2852427597955707,
        "vocab_size-3": 8037,
        "unique-3": 5084,
        "entropy-3": 11.151834460719483,
        "cond_entropy-3": 1.17225385255359,
        "total_length-nopunct": 32536,
        "mean_pred_length-nopunct": 6.444048326401267,
        "std_pred_length-nopunct": 2.7478162038820155,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.039894270961396604,
        "vocab_size-1-nopunct": 1298,
        "unique-1-nopunct": 557,
        "entropy-1-nopunct": 7.217472775944526,
        "distinct-2-nopunct": 0.15858405791828864,
        "vocab_size-2-nopunct": 4359,
        "unique-2-nopunct": 2348,
        "entropy-2-nopunct": 9.715436063607214,
        "cond_entropy-2-nopunct": 2.7007684621048846,
        "distinct-3-nopunct": 0.29310882444652325,
        "vocab_size-3-nopunct": 6580,
        "unique-3-nopunct": 4267,
        "entropy-3-nopunct": 10.793132011309808,
        "cond_entropy-3-nopunct": 1.1977505084348887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 24.33133,
        "local_recall": {
            "1": 0.4452479943784037
        },
        "rouge1": {
            "precision": 0.49075,
            "recall": 0.46799,
            "fmeasure": 0.46546
        },
        "rouge2": {
            "precision": 0.28339,
            "recall": 0.26884,
            "fmeasure": 0.26662
        },
        "rougeL": {
            "precision": 0.46691,
            "recall": 0.44406,
            "fmeasure": 0.44233
        },
        "rougeLsum": {
            "precision": 0.46691,
            "recall": 0.44406,
            "fmeasure": 0.44233
        },
        "nist": 4.505985322825808,
        "bleurt": -0.15438,
        "bertscore": {
            "precision": 0.85271,
            "recall": 0.84682,
            "f1": 0.84909
        },
        "nubia": {
            "semantic_relation": 3.09739,
            "contradiction": 7.87738,
            "irrelevancy": 27.10783,
            "logical_agreement": 65.01479,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.68689,
            "nubia_score": 0.55131
        },
        "meteor": 0.2537855987396374
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74478,
        "msttr-100_nopunct": 0.7681,
        "total_length": 2335,
        "mean_pred_length": 22.028301886792452,
        "std_pred_length": 4.329489810828975,
        "median_pred_length": 21.5,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.40856531049250533,
        "vocab_size-1": 954,
        "unique-1": 712,
        "entropy-1": 8.362294865659145,
        "distinct-2": 0.8456707043517272,
        "vocab_size-2": 1885,
        "unique-2": 1727,
        "entropy-2": 10.674919281706053,
        "cond_entropy-2": 2.1307746580169233,
        "distinct-3": 0.96938294865756,
        "vocab_size-3": 2058,
        "unique-3": 2010,
        "entropy-3": 10.982572350914724,
        "cond_entropy-3": 0.3045304275014717,
        "total_length-nopunct": 2174,
        "mean_pred_length-nopunct": 20.50943396226415,
        "std_pred_length-nopunct": 4.121378417102678,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4346826126954922,
        "vocab_size-1-nopunct": 945,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 8.480706967173044,
        "distinct-2-nopunct": 0.851063829787234,
        "vocab_size-2-nopunct": 1760,
        "unique-2-nopunct": 1620,
        "entropy-2-nopunct": 10.57892006678992,
        "cond_entropy-2-nopunct": 2.1754466775538543,
        "distinct-3-nopunct": 0.9760448521916412,
        "vocab_size-3-nopunct": 1915,
        "unique-3-nopunct": 1877,
        "entropy-3-nopunct": 10.886486384060824,
        "cond_entropy-3-nopunct": 0.3068748704182985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 14.53207,
        "local_recall": {
            "1": 0.4271662763466042
        },
        "rouge1": {
            "precision": 0.47787,
            "recall": 0.45002,
            "fmeasure": 0.45675
        },
        "rouge2": {
            "precision": 0.22225,
            "recall": 0.20763,
            "fmeasure": 0.21096
        },
        "rougeL": {
            "precision": 0.37823,
            "recall": 0.35885,
            "fmeasure": 0.36293
        },
        "rougeLsum": {
            "precision": 0.37823,
            "recall": 0.35885,
            "fmeasure": 0.36293
        },
        "nist": 4.066672626301922,
        "bleurt": -0.2001,
        "bertscore": {
            "precision": 0.84905,
            "recall": 0.84084,
            "f1": 0.84459
        },
        "nubia": {
            "semantic_relation": 3.28739,
            "contradiction": 13.56776,
            "irrelevancy": 63.5104,
            "logical_agreement": 22.92183,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.50094,
            "nubia_score": 0.54402
        },
        "meteor": 0.21181679687417024
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.7785,
        "total_length": 2256,
        "mean_pred_length": 21.28301886792453,
        "std_pred_length": 4.844282210164833,
        "median_pred_length": 20.5,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.4499113475177305,
        "vocab_size-1": 1015,
        "unique-1": 790,
        "entropy-1": 8.520239688278954,
        "distinct-2": 0.8879069767441861,
        "vocab_size-2": 1909,
        "unique-2": 1785,
        "entropy-2": 10.755619425096832,
        "cond_entropy-2": 2.0328157685449715,
        "distinct-3": 0.9833659491193738,
        "vocab_size-3": 2010,
        "unique-3": 1984,
        "entropy-3": 10.960058980458232,
        "cond_entropy-3": 0.20557341595056447,
        "total_length-nopunct": 2095,
        "mean_pred_length-nopunct": 19.764150943396228,
        "std_pred_length-nopunct": 4.608343308900476,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4801909307875895,
        "vocab_size-1-nopunct": 1006,
        "unique-1-nopunct": 789,
        "entropy-1-nopunct": 8.6606046016043,
        "distinct-2-nopunct": 0.893413775766717,
        "vocab_size-2-nopunct": 1777,
        "unique-2-nopunct": 1667,
        "entropy-2-nopunct": 10.656599454133554,
        "cond_entropy-2-nopunct": 2.082271918389946,
        "distinct-3-nopunct": 0.987254381306426,
        "vocab_size-3-nopunct": 1859,
        "unique-3-nopunct": 1838,
        "entropy-3-nopunct": 10.851863016158433,
        "cond_entropy-3-nopunct": 0.20110456613603378,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 12.1668,
        "local_recall": {
            "1": 0.385175079581628
        },
        "rouge1": {
            "precision": 0.45347,
            "recall": 0.40951,
            "fmeasure": 0.42435
        },
        "rouge2": {
            "precision": 0.18851,
            "recall": 0.1702,
            "fmeasure": 0.17616
        },
        "rougeL": {
            "precision": 0.35312,
            "recall": 0.31869,
            "fmeasure": 0.33031
        },
        "rougeLsum": {
            "precision": 0.35312,
            "recall": 0.31869,
            "fmeasure": 0.33031
        },
        "nist": 3.74251375295689,
        "bleurt": -0.2107,
        "bertscore": {
            "precision": 0.84682,
            "recall": 0.83264,
            "f1": 0.83939
        },
        "nubia": {
            "semantic_relation": 3.26356,
            "contradiction": 13.25723,
            "irrelevancy": 64.37531,
            "logical_agreement": 22.36746,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.6943,
            "nubia_score": 0.51387
        },
        "meteor": 0.19217836199285623
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.69734,
        "msttr-100_nopunct": 0.72547,
        "total_length": 37228,
        "mean_pred_length": 14.79062375844259,
        "std_pred_length": 4.467454317766067,
        "median_pred_length": 14.0,
        "min_pred_length": 3,
        "max_pred_length": 43,
        "distinct-1": 0.0691415063930375,
        "vocab_size-1": 2574,
        "unique-1": 1216,
        "entropy-1": 8.14717992593292,
        "distinct-2": 0.26740802627409177,
        "vocab_size-2": 9282,
        "unique-2": 5608,
        "entropy-2": 11.607978103020638,
        "cond_entropy-2": 3.2267494244239483,
        "distinct-3": 0.4739703050257812,
        "vocab_size-3": 15259,
        "unique-3": 10999,
        "entropy-3": 12.965624685520076,
        "cond_entropy-3": 1.4047509663198519,
        "total_length-nopunct": 32768,
        "mean_pred_length-nopunct": 13.018673023440604,
        "std_pred_length-nopunct": 4.004572394988723,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.078125,
        "vocab_size-1-nopunct": 2560,
        "unique-1-nopunct": 1214,
        "entropy-1-nopunct": 8.370009614682727,
        "distinct-2-nopunct": 0.28425506594823313,
        "vocab_size-2-nopunct": 8599,
        "unique-2-nopunct": 5346,
        "entropy-2-nopunct": 11.495162415995532,
        "cond_entropy-2-nopunct": 3.2954458789953125,
        "distinct-3-nopunct": 0.494915987596452,
        "vocab_size-3-nopunct": 13726,
        "unique-3-nopunct": 10131,
        "entropy-3-nopunct": 12.821796706237905,
        "cond_entropy-3-nopunct": 1.3981179005660382,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 33.28842,
        "local_recall": {
            "1": 0.5912059751867246
        },
        "rouge1": {
            "precision": 0.6333,
            "recall": 0.61378,
            "fmeasure": 0.61202
        },
        "rouge2": {
            "precision": 0.40275,
            "recall": 0.39004,
            "fmeasure": 0.38842
        },
        "rougeL": {
            "precision": 0.54907,
            "recall": 0.53208,
            "fmeasure": 0.53064
        },
        "rougeLsum": {
            "precision": 0.54907,
            "recall": 0.53208,
            "fmeasure": 0.53064
        },
        "nist": 6.878283607043155,
        "bleurt": -0.04156,
        "bertscore": {
            "precision": 0.8834,
            "recall": 0.87831,
            "f1": 0.8804
        },
        "nubia": {
            "semantic_relation": 4.05499,
            "contradiction": 5.02398,
            "irrelevancy": 21.35097,
            "logical_agreement": 73.62505,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.64105,
            "nubia_score": 0.71501
        },
        "meteor": 0.32841046128353835
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.69552,
        "msttr-100_nopunct": 0.72227,
        "total_length": 25948,
        "mean_pred_length": 19.539156626506024,
        "std_pred_length": 4.9699370204778575,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 40,
        "distinct-1": 0.0801988592569755,
        "vocab_size-1": 2081,
        "unique-1": 1008,
        "entropy-1": 8.05997220394159,
        "distinct-2": 0.2826969943135662,
        "vocab_size-2": 6960,
        "unique-2": 4190,
        "entropy-2": 11.284815867853474,
        "cond_entropy-2": 3.0551340708561137,
        "distinct-3": 0.485874978533402,
        "vocab_size-3": 11317,
        "unique-3": 8123,
        "entropy-3": 12.604517813752404,
        "cond_entropy-3": 1.373957225846402,
        "total_length-nopunct": 22953,
        "mean_pred_length-nopunct": 17.283885542168676,
        "std_pred_length-nopunct": 4.442569872409072,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.09005358776630505,
        "vocab_size-1-nopunct": 2067,
        "unique-1-nopunct": 1005,
        "entropy-1-nopunct": 8.271108614110972,
        "distinct-2-nopunct": 0.3027052023121387,
        "vocab_size-2-nopunct": 6546,
        "unique-2-nopunct": 4079,
        "entropy-2-nopunct": 11.212900131954811,
        "cond_entropy-2-nopunct": 3.082714872698241,
        "distinct-3-nopunct": 0.5125880672020495,
        "vocab_size-3-nopunct": 10404,
        "unique-3-nopunct": 7661,
        "entropy-3-nopunct": 12.52541154209419,
        "cond_entropy-3-nopunct": 1.3790372192183489,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "bleu": 32.61596,
        "local_recall": {
            "1": 0.6088165572574763
        },
        "rouge1": {
            "precision": 0.63795,
            "recall": 0.62859,
            "fmeasure": 0.62108
        },
        "rouge2": {
            "precision": 0.41163,
            "recall": 0.40734,
            "fmeasure": 0.40181
        },
        "rougeL": {
            "precision": 0.53858,
            "recall": 0.53086,
            "fmeasure": 0.52491
        },
        "rougeLsum": {
            "precision": 0.53858,
            "recall": 0.53086,
            "fmeasure": 0.52491
        },
        "nist": 6.770955428740051,
        "bleurt": -0.02968,
        "bertscore": {
            "precision": 0.88811,
            "recall": 0.88342,
            "f1": 0.88534
        },
        "nubia": {
            "semantic_relation": 4.21577,
            "contradiction": 4.40746,
            "irrelevancy": 19.56224,
            "logical_agreement": 76.03029,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.62547,
            "nubia_score": 0.73802
        },
        "meteor": 0.3332876410703958
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74955,
        "msttr-100_nopunct": 0.76857,
        "total_length": 2299,
        "mean_pred_length": 21.68867924528302,
        "std_pred_length": 4.656833500953945,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.42888212266202697,
        "vocab_size-1": 986,
        "unique-1": 764,
        "entropy-1": 8.385003860850643,
        "distinct-2": 0.8668490652074783,
        "vocab_size-2": 1901,
        "unique-2": 1761,
        "entropy-2": 10.709459047891773,
        "cond_entropy-2": 2.133716400968254,
        "distinct-3": 0.9789171058936272,
        "vocab_size-3": 2043,
        "unique-3": 2005,
        "entropy-3": 10.982643946008206,
        "cond_entropy-3": 0.28684259033943216,
        "total_length-nopunct": 2149,
        "mean_pred_length-nopunct": 20.27358490566038,
        "std_pred_length-nopunct": 4.471150750673014,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.4550953932061424,
        "vocab_size-1-nopunct": 978,
        "unique-1-nopunct": 762,
        "entropy-1-nopunct": 8.503157643764101,
        "distinct-2-nopunct": 0.863925599608419,
        "vocab_size-2-nopunct": 1765,
        "unique-2-nopunct": 1634,
        "entropy-2-nopunct": 10.594457322569326,
        "cond_entropy-2-nopunct": 2.192875968659753,
        "distinct-3-nopunct": 0.9819308208569953,
        "vocab_size-3-nopunct": 1902,
        "unique-3-nopunct": 1870,
        "entropy-3-nopunct": 10.882300720530417,
        "cond_entropy-3-nopunct": 0.2972074425269629,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 12.72012,
        "local_recall": {
            "1": 0.3996333638863428
        },
        "rouge1": {
            "precision": 0.46343,
            "recall": 0.42766,
            "fmeasure": 0.43774
        },
        "rouge2": {
            "precision": 0.20687,
            "recall": 0.19116,
            "fmeasure": 0.19509
        },
        "rougeL": {
            "precision": 0.37369,
            "recall": 0.34407,
            "fmeasure": 0.35241
        },
        "rougeLsum": {
            "precision": 0.37369,
            "recall": 0.34407,
            "fmeasure": 0.35241
        },
        "nist": 3.939892968373454,
        "bleurt": -0.17122,
        "bertscore": {
            "precision": 0.85666,
            "recall": 0.84415,
            "f1": 0.85008
        },
        "nubia": {
            "semantic_relation": 3.29002,
            "contradiction": 16.52347,
            "irrelevancy": 61.56025,
            "logical_agreement": 21.91629,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.60139,
            "nubia_score": 0.52395
        },
        "meteor": 0.20149545658400042
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 40.63798,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.73333,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.48148,
            "fmeasure": 0.45614
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.73333,
            "fmeasure": 0.69841
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.73333,
            "fmeasure": 0.69841
        },
        "nist": 2.8587341307648324,
        "bleurt": 0.12714,
        "bertscore": {
            "precision": 0.9425,
            "recall": 0.95011,
            "f1": 0.94629
        },
        "nubia": {
            "semantic_relation": 4.90035,
            "contradiction": 0.54505,
            "irrelevancy": 3.55497,
            "logical_agreement": 95.89999,
            "grammar_ref": 5.6957,
            "grammar_hyp": 4.71308,
            "nubia_score": 0.96765
        },
        "meteor": 0.4533407547499008
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "T5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74435,
        "msttr-100_nopunct": 0.75762,
        "total_length": 2335,
        "mean_pred_length": 22.028301886792452,
        "std_pred_length": 4.10581168214541,
        "median_pred_length": 21.5,
        "min_pred_length": 14,
        "max_pred_length": 35,
        "distinct-1": 0.4265524625267666,
        "vocab_size-1": 996,
        "unique-1": 781,
        "entropy-1": 8.368710256468576,
        "distinct-2": 0.8537460744728578,
        "vocab_size-2": 1903,
        "unique-2": 1770,
        "entropy-2": 10.677075289306503,
        "cond_entropy-2": 2.1225476569279285,
        "distinct-3": 0.9712670748940179,
        "vocab_size-3": 2062,
        "unique-3": 2022,
        "entropy-3": 10.981505623403425,
        "cond_entropy-3": 0.31463825678319146,
        "total_length-nopunct": 2180,
        "mean_pred_length-nopunct": 20.566037735849058,
        "std_pred_length-nopunct": 3.9069818200206963,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4541284403669725,
        "vocab_size-1-nopunct": 990,
        "unique-1-nopunct": 780,
        "entropy-1-nopunct": 8.486675161004516,
        "distinct-2-nopunct": 0.8563162970106075,
        "vocab_size-2-nopunct": 1776,
        "unique-2-nopunct": 1656,
        "entropy-2-nopunct": 10.57722065421215,
        "cond_entropy-2-nopunct": 2.184625076842357,
        "distinct-3-nopunct": 0.9751016260162602,
        "vocab_size-3-nopunct": 1919,
        "unique-3-nopunct": 1883,
        "entropy-3-nopunct": 10.885533323689002,
        "cond_entropy-3-nopunct": 0.32365468310653955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "bleu": 12.07888,
        "local_recall": {
            "1": 0.4040778498609824
        },
        "rouge1": {
            "precision": 0.45584,
            "recall": 0.43954,
            "fmeasure": 0.43962
        },
        "rouge2": {
            "precision": 0.18489,
            "recall": 0.18062,
            "fmeasure": 0.17836
        },
        "rougeL": {
            "precision": 0.35456,
            "recall": 0.34278,
            "fmeasure": 0.3422
        },
        "rougeLsum": {
            "precision": 0.35456,
            "recall": 0.34278,
            "fmeasure": 0.3422
        },
        "nist": 3.831354404893598,
        "bleurt": -0.19289,
        "bertscore": {
            "precision": 0.85123,
            "recall": 0.8445,
            "f1": 0.84751
        },
        "nubia": {
            "semantic_relation": 3.24555,
            "contradiction": 20.39879,
            "irrelevancy": 59.85979,
            "logical_agreement": 19.74142,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.56552,
            "nubia_score": 0.51794
        },
        "meteor": 0.19759574424808218
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 19,
        "distinct-1": 0.5471698113207547,
        "vocab_size-1": 29,
        "unique-1": 12,
        "entropy-1": 4.713308426057212,
        "distinct-2": 0.78,
        "vocab_size-2": 39,
        "unique-2": 28,
        "entropy-2": 5.203856189774726,
        "cond_entropy-2": 0.4563267353846029,
        "distinct-3": 0.851063829787234,
        "vocab_size-3": 40,
        "unique-3": 33,
        "entropy-3": 5.256716511252108,
        "cond_entropy-3": 0.08094542786035953,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.574468085106383,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.6127875217523115,
        "distinct-2-nopunct": 0.7727272727272727,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 5.00488616409184,
        "cond_entropy-2-nopunct": 0.3975632216362334,
        "distinct-3-nopunct": 0.8536585365853658,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 5.0648690777888135,
        "cond_entropy-3-nopunct": 0.06885209329785952,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 47.64329,
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 1.0,
            "3": 0.7333333333333333
        },
        "rouge1": {
            "precision": 0.90307,
            "recall": 0.77143,
            "fmeasure": 0.82618
        },
        "rouge2": {
            "precision": 0.6563,
            "recall": 0.55945,
            "fmeasure": 0.59913
        },
        "rougeL": {
            "precision": 0.69865,
            "recall": 0.592,
            "fmeasure": 0.63599
        },
        "rougeLsum": {
            "precision": 0.69865,
            "recall": 0.592,
            "fmeasure": 0.63599
        },
        "nist": 4.407011732703524,
        "bleurt": 0.1425,
        "bertscore": {
            "precision": 0.94946,
            "recall": 0.90734,
            "f1": 0.92743
        },
        "nubia": {
            "semantic_relation": 4.26785,
            "contradiction": 0.33173,
            "irrelevancy": 28.88903,
            "logical_agreement": 70.77924,
            "grammar_ref": 4.73012,
            "grammar_hyp": 5.48048,
            "nubia_score": 0.67132
        },
        "meteor": 0.41061285304816375
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.17632144674685432,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 15.04844,
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.34783,
            "recall": 0.69697,
            "fmeasure": 0.46387
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.38182,
            "fmeasure": 0.24621
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.69697,
            "fmeasure": 0.46387
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.69697,
            "fmeasure": 0.46387
        },
        "nist": 1.1790061943123726,
        "bleurt": -0.08882,
        "bertscore": {
            "precision": 0.80789,
            "recall": 0.89457,
            "f1": 0.84902
        },
        "nubia": {
            "semantic_relation": 4.34083,
            "contradiction": 0.17946,
            "irrelevancy": 78.51415,
            "logical_agreement": 21.30639,
            "grammar_ref": 5.10481,
            "grammar_hyp": 3.55907,
            "nubia_score": 0.44106
        },
        "meteor": 0.3061961757545051
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 13.83254,
        "local_recall": {
            "1": 0.25,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42657
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42657
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42657
        },
        "nist": 1.1912281254206742,
        "bleurt": -0.54495,
        "bertscore": {
            "precision": 0.873,
            "recall": 0.7918,
            "f1": 0.83042
        },
        "nubia": {
            "semantic_relation": 3.38262,
            "contradiction": 1.16047,
            "irrelevancy": 1.18702,
            "logical_agreement": 97.6525,
            "grammar_ref": 7.18676,
            "grammar_hyp": 8.39666,
            "nubia_score": 0.46887
        },
        "meteor": 0.2943643223618648
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 34.80442,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.48262,
            "fmeasure": 0.50302
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.29018,
            "fmeasure": 0.29983
        },
        "rougeL": {
            "precision": 0.44118,
            "recall": 0.40775,
            "fmeasure": 0.42232
        },
        "rougeLsum": {
            "precision": 0.44118,
            "recall": 0.40775,
            "fmeasure": 0.42232
        },
        "nist": 3.200329095786079,
        "bleurt": -0.2872,
        "bertscore": {
            "precision": 0.90946,
            "recall": 0.89499,
            "f1": 0.90217
        },
        "nubia": {
            "semantic_relation": 3.47803,
            "contradiction": 0.16951,
            "irrelevancy": 79.05091,
            "logical_agreement": 20.77958,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.04828,
            "nubia_score": 0.64766
        },
        "meteor": 0.3709830882686797
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.21860008985574889,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2417888922404337,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 45.43275,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "rouge2": {
            "precision": 0.47368,
            "recall": 0.5625,
            "fmeasure": 0.51429
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "nist": 3.5731022473852345,
        "bleurt": 0.47546,
        "bertscore": {
            "precision": 0.94649,
            "recall": 0.94654,
            "f1": 0.94652
        },
        "nubia": {
            "semantic_relation": 4.17509,
            "contradiction": 0.40047,
            "irrelevancy": 5.04901,
            "logical_agreement": 94.55052,
            "grammar_ref": 4.8802,
            "grammar_hyp": 4.73091,
            "nubia_score": 0.7002
        },
        "meteor": 0.46976349632660697
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601997,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 65.29942,
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 0.84211,
            "recall": 0.72727,
            "fmeasure": 0.78049
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.59091,
            "fmeasure": 0.63415
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.59091,
            "fmeasure": 0.63415
        },
        "nist": 4.181234317945789,
        "bleurt": 0.09935,
        "bertscore": {
            "precision": 0.96122,
            "recall": 0.93554,
            "f1": 0.94821
        },
        "nubia": {
            "semantic_relation": 4.42683,
            "contradiction": 0.20506,
            "irrelevancy": 31.52854,
            "logical_agreement": 68.2664,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.06698,
            "nubia_score": 0.87706
        },
        "meteor": 0.4326998734708674
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.487122805397797,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.2211615997086176,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464345,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.2724185498326621,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 16.49015,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5769230769230769
        },
        "rouge1": {
            "precision": 0.7581,
            "recall": 0.5875,
            "fmeasure": 0.65318
        },
        "rouge2": {
            "precision": 0.35833,
            "recall": 0.25111,
            "fmeasure": 0.29265
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.41635,
            "fmeasure": 0.45983
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.41635,
            "fmeasure": 0.45983
        },
        "nist": 3.0364877515782522,
        "bleurt": 0.06606,
        "bertscore": {
            "precision": 0.91411,
            "recall": 0.90301,
            "f1": 0.90834
        },
        "nubia": {
            "semantic_relation": 3.56272,
            "contradiction": 0.79998,
            "irrelevancy": 49.89199,
            "logical_agreement": 49.30803,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.61972,
            "nubia_score": 0.51501
        },
        "meteor": 0.2940186992082376
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.99111,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.28571,
            "fmeasure": 0.34231
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.11396,
            "fmeasure": 0.13596
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.28571,
            "fmeasure": 0.34231
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.28571,
            "fmeasure": 0.34231
        },
        "nist": 0.7191928165921433,
        "bleurt": -0.17159,
        "bertscore": {
            "precision": 0.83067,
            "recall": 0.80805,
            "f1": 0.81692
        },
        "nubia": {
            "semantic_relation": 3.06654,
            "contradiction": 0.64989,
            "irrelevancy": 89.94857,
            "logical_agreement": 9.40153,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.68302,
            "nubia_score": 0.5032
        },
        "meteor": 0.21263241648756162
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 6.43993,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.35185,
            "recall": 0.65556,
            "fmeasure": 0.44911
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.2381,
            "fmeasure": 0.15412
        },
        "rougeL": {
            "precision": 0.2963,
            "recall": 0.55,
            "fmeasure": 0.37762
        },
        "rougeLsum": {
            "precision": 0.2963,
            "recall": 0.55,
            "fmeasure": 0.37762
        },
        "nist": 1.6582838972385718,
        "bleurt": -0.24843,
        "bertscore": {
            "precision": 0.83185,
            "recall": 0.91501,
            "f1": 0.85233
        },
        "nubia": {
            "semantic_relation": 3.8936,
            "contradiction": 0.12013,
            "irrelevancy": 98.96701,
            "logical_agreement": 0.91287,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.40562,
            "nubia_score": 0.62481
        },
        "meteor": 0.26608974200661695
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.254525464966176,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.40419885073169187,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 21.5,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.76842,
            "fmeasure": 0.77868
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.51316,
            "fmeasure": 0.52027
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.66579,
            "fmeasure": 0.67476
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.66579,
            "fmeasure": 0.67476
        },
        "nist": 3.0464627635442234,
        "bleurt": -0.41233,
        "bertscore": {
            "precision": 0.85434,
            "recall": 0.86532,
            "f1": 0.8598
        },
        "nubia": {
            "semantic_relation": 3.89302,
            "contradiction": 2.01,
            "irrelevancy": 59.45778,
            "logical_agreement": 38.53222,
            "grammar_ref": 4.38153,
            "grammar_hyp": 5.26281,
            "nubia_score": 0.52841
        },
        "meteor": 0.3097351405210621
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.02555597707498716,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 14.1418,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.71014,
            "recall": 0.68061,
            "fmeasure": 0.69444
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.24603,
            "fmeasure": 0.25143
        },
        "rougeL": {
            "precision": 0.43478,
            "recall": 0.43636,
            "fmeasure": 0.43519
        },
        "rougeLsum": {
            "precision": 0.43478,
            "recall": 0.43636,
            "fmeasure": 0.43519
        },
        "nist": 3.539932103738777,
        "bleurt": -0.13689,
        "bertscore": {
            "precision": 0.8751,
            "recall": 0.85508,
            "f1": 0.86355
        },
        "nubia": {
            "semantic_relation": 4.11358,
            "contradiction": 0.32479,
            "irrelevancy": 95.86417,
            "logical_agreement": 3.81104,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.7364,
            "nubia_score": 0.67024
        },
        "meteor": 0.2938312299282118
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.0,
        "bleurt": 1.00232,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.52568,
            "irrelevancy": 0.55315,
            "logical_agreement": 98.92117,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.90011,
            "nubia_score": 0.96927
        },
        "meteor": 1.0
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.788909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.06538684568063419,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.694019357121935,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.0730134515604695,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 8.51174,
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.5333333333333333
        },
        "rouge1": {
            "precision": 0.70965,
            "recall": 0.55848,
            "fmeasure": 0.62405
        },
        "rouge2": {
            "precision": 0.36458,
            "recall": 0.28638,
            "fmeasure": 0.32022
        },
        "rougeL": {
            "precision": 0.5724,
            "recall": 0.45906,
            "fmeasure": 0.50806
        },
        "rougeLsum": {
            "precision": 0.5724,
            "recall": 0.45906,
            "fmeasure": 0.50806
        },
        "nist": 2.7213902048897127,
        "bleurt": 0.26775,
        "bertscore": {
            "precision": 0.90046,
            "recall": 0.86164,
            "f1": 0.87985
        },
        "nubia": {
            "semantic_relation": 4.08954,
            "contradiction": 0.49028,
            "irrelevancy": 2.73539,
            "logical_agreement": 96.77433,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.44562,
            "nubia_score": 0.68978
        },
        "meteor": 0.31586392412692865
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "T5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964168,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "bleu": 12.43902,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.64706,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.29412,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.29412,
            "fmeasure": 0.33333
        },
        "nist": 2.175723795979639,
        "bleurt": 0.34675,
        "bertscore": {
            "precision": 0.93259,
            "recall": 0.90762,
            "f1": 0.91979
        },
        "nubia": {
            "semantic_relation": 4.75569,
            "contradiction": 0.22946,
            "irrelevancy": 0.43404,
            "logical_agreement": 99.3365,
            "grammar_ref": 4.71038,
            "grammar_hyp": 5.33837,
            "nubia_score": 0.80513
        },
        "meteor": 0.30250512907151095
    },
    "web_nlg_ru_validation": {
        "predictions_file": "T5-xl (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.38272,
        "msttr-100_nopunct": 0.37166,
        "total_length": 35332,
        "mean_pred_length": 44.72405063291139,
        "std_pred_length": 19.237813602381326,
        "median_pred_length": 46.0,
        "min_pred_length": 9,
        "max_pred_length": 83,
        "distinct-1": 0.04103928450130193,
        "vocab_size-1": 1450,
        "unique-1": 489,
        "entropy-1": 5.634631024684163,
        "distinct-2": 0.11918823461293498,
        "vocab_size-2": 4117,
        "unique-2": 1780,
        "entropy-2": 9.785563039114082,
        "cond_entropy-2": 4.14652811964613,
        "distinct-3": 0.23148257881014458,
        "vocab_size-3": 7813,
        "unique-3": 4047,
        "entropy-3": 11.409980963705717,
        "cond_entropy-3": 1.6588881848877712,
        "total_length-nopunct": 32647,
        "mean_pred_length-nopunct": 41.3253164556962,
        "std_pred_length-nopunct": 18.16999173316818,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.04420007963978313,
        "vocab_size-1-nopunct": 1443,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 5.521699650189995,
        "distinct-2-nopunct": 0.11922026556172897,
        "vocab_size-2-nopunct": 3798,
        "unique-2-nopunct": 1655,
        "entropy-2-nopunct": 9.647173144864785,
        "cond_entropy-2-nopunct": 4.190174242558968,
        "distinct-3-nopunct": 0.23040525316251972,
        "vocab_size-3-nopunct": 7158,
        "unique-3-nopunct": 3772,
        "entropy-3-nopunct": 11.245987401657,
        "cond_entropy-3-nopunct": 1.636351613975426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "bleu": 1.40674,
        "local_recall": {
            "1": 0.06844106463878327,
            "2": 0.17491484672410337,
            "3": 0.24810655523635414,
            "4": 0.24242424242424243,
            "5": 0.2692307692307692,
            "6": 0.2,
            "7": 0.25,
            "8": 0,
            "9": 0.0
        },
        "rouge1": {
            "precision": 0.33623,
            "recall": 0.3253,
            "fmeasure": 0.32739
        },
        "rouge2": {
            "precision": 0.1246,
            "recall": 0.11908,
            "fmeasure": 0.12046
        },
        "rougeL": {
            "precision": 0.31748,
            "recall": 0.30711,
            "fmeasure": 0.30894
        },
        "rougeLsum": {
            "precision": 0.31748,
            "recall": 0.30711,
            "fmeasure": 0.30894
        },
        "nist": 0.9525429341702456,
        "bleurt": -0.50251,
        "bertscore": {
            "precision": 0.85372,
            "recall": 0.86766,
            "f1": 0.86005
        },
        "nubia": {
            "semantic_relation": 3.2925,
            "contradiction": 34.59564,
            "irrelevancy": 16.92088,
            "logical_agreement": 48.48348,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.56861,
            "nubia_score": 0.14929
        },
        "meteor": 0.11152819154298618
    }
}
