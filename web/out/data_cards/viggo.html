<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM viggo</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/8f219039bec51df6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f219039bec51df6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/9c6cbdf6de0d7f7f.css" as="style"/><link rel="stylesheet" href="/_next/static/css/9c6cbdf6de0d7f7f.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-a7ce780f37f41655.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-9d34f203832e9748.js" defer=""></script><script src="/_next/static/chunks/pages/_app-dcd786a11fa40981.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-215a96335ed97100.js" defer=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-d70bae37aff106ba.js" defer=""></script><script src="/_next/static/4qC7i6uP3uGR34Kebmohm/_buildManifest.js" defer=""></script><script src="/_next/static/4qC7i6uP3uGR34Kebmohm/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__qqb_S undefined"><header class="layout_header__kY0Lt"><div class="navbar_navwrapper__PQ35R"><div class="navbar_gradbar__2_FPI"></div><nav class="navbar_navbar__9q1fQ"><span class="utils_headingLg__5535D navbar_navbarlogo__R_s98"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__XS8Qx" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar___PSVO" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__wFPZL navbar_pushright__cG1uq"><a href="/resources">Resources</a></li><li class="navbar_navitem__wFPZL"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__wFPZL"><a href="/results">Results</a></li><li class="navbar_navitem__wFPZL"><a href="/papers">Papers</a></li><li class="navbar_navitem__wFPZL"><a href="/team">Team</a></li><li class="navbar_navitem__wFPZL"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__fbLkO layout_wideContainer__TSLbJ"><main><article><a href="/data_cards"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-left" class="svg-inline--fa fa-arrow-left utils_icon__9sxFf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg></a><span class="utils_spacer__AJA7_"></span><span class="utils_headingXl__u25Y2">viggo</span><span class="utils_smallSpace__n1Oyc"></span><span class="utils_lightText__eUzGY">Data-to-Text</span><div class="datacard-wrapper"><div class="datacard">
  <section class="datacard-section">
    <div class="datacard-summary">
      <h2>viggo</h2>
      <div class="summary-content">
        <p>ViGGO is an English data-to-text generation dataset in the video game domain, with target responses being
          more conversational than information-seeking, yet constrained to the information presented in a meaning
          representation. The dataset is relatively small with about 5,000 datasets but very clean, and can thus serve
          for evaluating transfer learning, low-resource, or few-shot capabilities of neural models.</p>
        <p>You can load the dataset via:</p>

        <div class="code-wrapper">
          <div class="toolbar">
            <div class="copy-icon" title="Click to copy code block"></div>
            <div class="expand-modal-icon" title="Click to expand code block"></div>
          </div>
          <pre><code>import datasets
data = datasets.load_dataset('GEM/viggo')
</code></pre>
        </div>

        <p>The data loader can be found <a href="https://huggingface.co/datasets/GEM/viggo">here</a>.</p>
      </div>
    </div>

    <div class="datacard-field-wrapper">

      <div class="datacard-field">

        <h5>website

        </h5>

        <p><a href="https://nlds.soe.ucsc.edu/viggo">Wesbite</a></p>
      </div>

      <div class="datacard-field">

        <h5>paper

        </h5>

        <p><a href="https://aclanthology.org/W19-8623/">ACL Anthology</a></p>
      </div>

      <div class="datacard-field">

        <h5>authors

        </h5>

        <p>Juraj Juraska, Kevin K. Bowden, Marilyn Walker</p>
      </div>
    </div>

  </section>

  <section class="datacard-section quick">
    <h3 class="section-title">Quick-Use</h3>

    <div class="datacard-field-wrapper">

      <div class="datacard-field periscope">

        <h5>Contact Name

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>If known, provide the name of at least one person the reader can contact for questions about the
                dataset.</p>
            </div>
          </div>

        </h5>

        <p>Juraj Juraska</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Multilingual?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Is the dataset multilingual?</p>
            </div>
          </div>

        </h5>

        <p>no</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Covered Languages

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What languages/dialects are covered in the dataset?</p>
            </div>
          </div>

        </h5>

        <p><code>English</code></p>
      </div>

      <div class="datacard-field telescope">

        <h5>License

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What is the license of the dataset?</p>
            </div>
          </div>

        </h5>

        <p>cc-by-sa-4.0: Creative Commons Attribution Share Alike 4.0 International</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Additional Annotations?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the dataset have additional annotations for each instance?</p>
            </div>
          </div>

        </h5>

        <p>none</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Contains PII?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the source language data likely contain Personal Identifying Information about the data creators
                or subjects?</p>
            </div>
          </div>

        </h5>

        <p>no PII</p>
      </div>
    </div>

  </section>


  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Overview

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Where to find the Data and its Documentation</h4>
              </li>
              <li>
                <h4>Languages and Intended Use</h4>
              </li>
              <li>
                <h4>Credit</h4>
              </li>
              <li>
                <h4>Dataset Structure</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Where to find the Data and its Documentation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Webpage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the webpage for the dataset (if it exists)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://nlds.soe.ucsc.edu/viggo">Wesbite</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Paper

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to the paper describing the dataset (open access preferred)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://aclanthology.org/W19-8623/">ACL Anthology</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>BibTex

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the BibTex-formatted reference for the dataset. Please use the correct published version
                    (ACL anthology, etc.) instead of google scholar created Bibtex.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>@inproceedings{juraska-etal-2019-viggo,
title = "{V}i{GGO}: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation",
author = "Juraska, Juraj  and
Bowden, Kevin  and
Walker, Marilyn",
booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
month = oct # "{--}" # nov,
year = "2019",
address = "Tokyo, Japan",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/W19-8623",
doi = "10.18653/v1/W19-8623",
pages = "164--172",
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Contact Name

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the name of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Juraj Juraska</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contact Email

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the email of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:jjuraska@ucsc.edu">jjuraska@ucsc.edu</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Has a Leaderboard?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have an active leaderboard?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Languages and Intended Use</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Multilingual?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset multilingual?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Covered Languages

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What languages/dialects are covered in the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>English</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>License

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>cc-by-sa-4.0: Creative Commons Attribution Share Alike 4.0 International</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Intended Use

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the intended use of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>ViGGO was designed for the task of data-to-text generation in chatbots (as opposed to task-oriented
              dialogue systems), with target responses being more conversational than information-seeking, yet
              constrained to the information presented in a meaning representation. The dataset, being relatively small
              and clean, can also serve for demonstrating transfer learning capabilities of neural models.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Primary Task

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What primary task does the dataset support?</p>
                </div>
              </div>

            </h5>

            <p>Data-to-Text</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Credit</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Curation Organization Type(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>In what kind of organization did the dataset curation happen?</p>
                </div>
              </div>

            </h5>

            <p><code>academic</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Curation Organization(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Name the organization(s).</p>
                </div>
              </div>

            </h5>

            <p>University of California, Santa Cruz</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Dataset Creators

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who created the original dataset? List the people involved in collecting the dataset and their
                    affiliation(s).</p>
                </div>
              </div>

            </h5>

            <p>Juraj Juraska, Kevin K. Bowden, Marilyn Walker</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Who added the Dataset to GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who contributed to the data card and adding the dataset to GEM? List the people+affiliations
                    involved in creating this data card and who helped integrate this dataset into GEM.</p>
                </div>
              </div>

            </h5>

            <p>Juraj Juraska</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Dataset Structure</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Data Fields

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the fields present in the dataset.</p>
                </div>
              </div>

            </h5>

            <p>Each example in the dataset has the following two fields:</p>
            <ul>
              <li><code>mr</code>: A meaning representation (MR) that, in a structured format, provides the information
                to convey, as well as the desired dialogue act (DA) type.</li>
              <li><code>ref</code>: A reference output, i.e., a corresponding utterance realizing all the information in
                the MR.</li>
            </ul>
            <p>Each MR is a flattened dictionary of attribute-and-value pairs, "wrapped" in the dialogue act type
              indication. This format was chosen primarily for its compactness, but also to allow for easy concatenation
              of multiple DAs (each with potentially different attributes) in a single MR.</p>
            <p>Following is the list of all possible attributes (which are also refered to as "slots") in ViGGO along
              with their types/possible values:</p>
            <ul>
              <li><code>name</code>: The name of a video game (e.g., Rise of the Tomb Raider).</li>
              <li><code>release_year</code>: The year a video game was released in (e.g., 2015).</li>
              <li><code>exp_release_date</code>: For a not-yet-released game, the date when it is expected to be
                released (e.g., February 22, 2019). <em>Note: This slot cannot appear together with
                  <code>release_year</code> in the same dialogue act.</em></li>
              <li><code>developer</code>: The name of the studio/person that created the game (e.g., Crystal Dynamics).
              </li>
              <li><code>genres</code>: A list of one or more genre labels from a set of possible values (e.g.,
                action-adventure, shooter).</li>
              <li><code>player_perspective</code>: A list of one or more perspectives from which the game is/can be
                played (possible values: first person, third person, side view, bird view).</li>
              <li><code>platforms</code>: A list of one or more gaming platforms the game was officially released for
                (possible values: PC, PlayStation, Xbox, Nintendo, Nintendo Switch).</li>
              <li><code>esrb</code>: A game's content rating as determined by the ESRB (possible values: E (for
                Everyone), E 10+ (for Everyone 10 and Older), T (for Teen), M (for Mature)).</li>
              <li><code>rating</code>: Depending on the dialogue act this slot is used with, it is a categorical
                representation of either the game's average rating or the game's liking (possible values: excellent,
                good, average, poor).</li>
              <li><code>has_multiplayer</code>: Indicates whether a game supports multiplayer or can only be played in
                single-player mode (possible values: yes, no).</li>
              <li><code>available_on_steam</code>: Indicates whether a game can be purchased through the Steam digital
                distribution service (possible values: yes, no).</li>
              <li><code>has_linux_release</code>: Indicates whether a game is supported on Linux operating systems
                (possible values: yes, no).</li>
              <li><code>has_mac_release</code>: Indicates whether a game is supported on macOS (possible values: yes,
                no).</li>
              <li><code>specifier</code>: A game specifier used by the <code>request</code> DA, typically an adjective
                (e.g., addictive, easiest, overrated, visually impressive).</li>
            </ul>
            <p>Each MR in the dataset has 3 distinct reference utterances, which are represented as 3 separate examples
              with the same MR.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Reason for Structure

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the dataset structure determined?</p>
                </div>
              </div>

            </h5>

            <p>The dataset structure mostly follows the format of the popular E2E dataset, however, with added dialogue
              act type indications, new list-type attributes introduced, and unified naming convention for multi-word
              attribute names.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Example Instance

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a JSON formatted example of a typical instance in the dataset.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>{
"mr": "give_opinion(name[SpellForce 3], rating[poor], genres[real-time strategy, role-playing], player_perspective[bird view])",
"ref": "I think that SpellForce 3 is one of the worst games I've ever played. Trying to combine the real-time strategy and role-playing genres just doesn't work, and the bird view perspective makes it near impossible to play."
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Data Splits

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe and name the splits in the dataset if there are more than one.</p>
                </div>
              </div>

            </h5>

            <p>ViGGO is split into 3 partitions, with no MRs in common between the training set and either of the
              validation and the test set (and that <em>after</em> delexicalizing the <code>name</code> and
              <code>developer</code> slots). The ratio of examples in the partitions is approximately 7.5 : 1 : 1.5,
              with their exact sizes listed below:</p>
            <ul>
              <li><strong>Train:</strong> 5,103 (1,675 unique MRs)</li>
              <li><strong>Validation:</strong> 714 (238 unique MRs)</li>
              <li><strong>Test:</strong> 1,083 (359 unique MRs)</li>
              <li><strong>TOTAL:</strong> 6,900 (2,253 unique MRs)</li>
            </ul>
            <p><em>Note: The reason why the number of unique MRs is not exactly one third of all examples is that for
                each <code>request_attribute</code> DA (which only has one slot, and that without a value) 12 reference
                utterances were collected instead of 3.</em></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Splitting Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any criteria for splitting the data, if used. If there are differences between the splits
                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by
                    humans, or if different numbers of annotators contributed to each example), describe them here.</p>
                </div>
              </div>

            </h5>

            <p>A similar MR length and slot distribution was preserved across the partitions. The distribution of DA
              types, on the other hand, is skewed slightly toward fewer <code>inform</code> DA instances (the most
              prevalent DA type) and a higher proportion of the less prevalent DAs in the validation and the test set.
            </p>
          </div>

          <div class="datacard-field microscope">

            <h5>

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does an outlier of the dataset in terms of length/perplexity/embedding look like?</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>{
"mr": "request_attribute(player_perspective[])",
"ref": "Is there a certain player perspective that you prefer over others in games you play?"
},
{
"mr": "inform(name[FIFA 12], esrb[E (for Everyone)], genres[simulation, sport], player_perspective[bird view, side view], platforms[PlayStation, Xbox, Nintendo, PC], available_on_steam[no])",
"ref": "Fifa 12 is a decent sports simulator. It's pretty cool how the game swaps from the bird's eye perspective down to a side view while you're playing. You can get the game for PlayStation, Xbox, Nintendo consoles, and PC, but unfortunately it's not on Steam. Of course, as a sports game there's not much objectionable content so it's rated E."
},
{
"mr": "inform(name[Super Bomberman], release_year[1993], genres[action, strategy], has_multiplayer[no], platforms[Nintendo, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])",
"ref": "Super Bomberman is one of my favorite Nintendo games, also available on PC, though not through Steam. It came out all the way back in 1993, and you can't get it for any modern consoles, unfortunately, so no online multiplayer, or of course Linux or Mac releases either. That said, it's still one of the most addicting action-strategy games out there."
}
</code></pre>
            </div>

          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset in GEM

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Rationale for Inclusion in GEM</h4>
              </li>
              <li>
                <h4>GEM-Specific Curation</h4>
              </li>
              <li>
                <h4>Getting Started with the Task</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Rationale for Inclusion in GEM</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Why is the Dataset in GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does this dataset contribute toward better generation evaluation and why is it part of GEM?
                  </p>
                </div>
              </div>

            </h5>

            <p>ViGGO is a fairly small dataset but includes a greater variety of utterance types than most other
              datasets for NLG from structured meaning representations. This makes it more interesting from the
              perspective of model evaluation, since models have to learn to differentiate between various dialogue act
              types that share the same slots.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Similar Datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Do other datasets for the high level task exist?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Unique Language Coverage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset cover other languages than other datasets for the same task?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Difference from other GEM datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What else sets this dataset apart from other similar datasets in GEM?</p>
                </div>
              </div>

            </h5>

            <p>ViGGO's language is more casual and conversational -- as opposed to information-seeking -- which
              differentiates it from the majority of popular datasets for the same type of data-to-text task. Moreover,
              the video game domain is a rather uncommon one in the NLG community, despite being very well-suited for
              data-to-text generation, considering it offers entities with many attributes to talk about, which can be
              described in a structured format.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>GEM-Specific Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Modificatied for GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Has the GEM version of the dataset been modified in any way (data, processing, splits) from the
                    original curated data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Additional Splits?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does GEM provide additional splits to the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Getting Started with the Task</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Pointers to Resources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Getting started with in-depth research on the task. Add relevant pointers to resources that
                    researchers can consult when they want to get started digging deeper into the task.</p>
                </div>
              </div>

            </h5>

            <ul>
              <li><a href="http://www.macs.hw.ac.uk/InteractionLab/E2E/">E2E NLG Challenge</a></li>
            </ul>
          </div>

          <div class="datacard-field microscope">

            <h5>Technical Terms

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Technical terms used in this card and the dataset and their definitions</p>
                </div>
              </div>

            </h5>

            <ul>
              <li>MR = meaning representation</li>
              <li>DA = dialogue act</li>
            </ul>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Previous Results

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Results</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Results</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field periscope">

            <h5>Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What metrics are typically used for this task?</p>
                </div>
              </div>

            </h5>

            <p><code>BLEU</code>, <code>METEOR</code>, <code>ROUGE</code>, <code>BERT-Score</code>, <code>BLEURT</code>,
              <code>Other: Other Metrics</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Other Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Definitions of other metrics</p>
                </div>
              </div>

            </h5>

            <p>SER (slot error rate): Indicates the proportion of missing/incorrect/duplicate/hallucinated slot mentions
              in the utterances across a test set. The closer to zero a model scores in this metric, the more
              semantically accurate its outputs are. This metric is typically calculated either manually on a small
              sample of generated outputs, or heuristically using domain-specific regex rules and gazetteers.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Previous results available?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are previous results available?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Relevant Previous Results

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What are the most relevant previous results for this task/dataset?</p>
                </div>
              </div>

            </h5>

            <ul>
              <li><a href="https://aclanthology.org/W19-8623/">Juraska et al., 2019. ViGGO: A Video Game Corpus for
                  Data-To-Text Generation in Open-Domain Conversation.</a></li>
              <li><a href="https://aclanthology.org/2020.coling-main.218/">Harkous et al., 2020. Have Your Text and Use
                  It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity.</a></li>
              <li><a href="https://aclanthology.org/2020.emnlp-main.419/">Kedzie and McKeown, 2020. Controllable Meaning
                  Representation to Text Generation: Linearization and Data Augmentation Strategies.</a></li>
              <li><a href="https://aclanthology.org/2021.inlg-1.45/">Juraska and Walker, 2021. Attention Is Indeed All
                  You Need: Semantically Attention-Guided Decoding for Data-to-Text NLG.</a></li>
            </ul>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Curation

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Original Curation</h4>
              </li>
              <li>
                <h4>Language Data</h4>
              </li>
              <li>
                <h4>Structured Annotations</h4>
              </li>
              <li>
                <h4>Consent</h4>
              </li>
              <li>
                <h4>Private Identifying Information (PII)</h4>
              </li>
              <li>
                <h4>Maintenance</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Original Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Original Curation Rationale

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Original curation rationale</p>
                </div>
              </div>

            </h5>

            <p>The primary motivation behind ViGGO was to create a data-to-text corpus in a new but conversational
              domain, and intended for use in open-domain chatbots rather than task-oriented dialogue systems. To this
              end, the dataset contains utterances of 9 generalizable and conversational dialogue act types, revolving
              around various aspects of video games. The idea is that similar, relatively small datasets could fairly
              easily be collected for other conversational domains -- especially other entertainment domains (such as
              music or books), but perhaps also topics like animals or food -- to support an open-domain conversational
              agent with controllable neural NLG.</p>
            <p>Another desired quality of the ViGGO dataset was cleanliness (no typos and grammatical errors) and
              semantic accuracy, which has often not been the case with other crowdsourced data-to-text corpora. In
              general, for the data-to-text generation task, there is arguably no need to put the burden on the
              generation model to figure out the noise, since the noise would not be expected to be there in a
              real-world system whose dialogue manager that creates the input for the NLG module is usually configurable
              and tightly controlled.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the communicative goal?</p>
                </div>
              </div>

            </h5>

            <p>Produce a response from a structured meaning representation in the context of a conversation about video
              games. It can be a brief opinion or a description of a game, as well as a request for attribute (e.g.,
              genre, player perspective, or platform) preference/confirmation or an inquiry about liking a particular
              type of games.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Sourced from Different Sources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset aggregated from different data sources?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Language Data</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>How was Language Data Obtained?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the language data obtained?</p>
                </div>
              </div>

            </h5>

            <p><code>Crowdsourced</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Where was it crowdsourced?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If crowdsourced, where from?</p>
                </div>
              </div>

            </h5>

            <p><code>Amazon Mechanical Turk</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Language Producers

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What further information do we have on the language producers?</p>
                </div>
              </div>

            </h5>

            <p>The paid crowdworkers who produced the reference utterances were from English-speaking countries, and
              they had at least 1,000 HITs approved and a HIT approval rate of 98% or more. Furthermore, in the
              instructions, crowdworkers were discouraged from taking on the task unless they considered themselves a
              gamer.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Topics Covered

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the language in the dataset focus on specific topics? How would you describe them?</p>
                </div>
              </div>

            </h5>

            <p>The dataset focuses on video games and their various aspects, and hence the language of the utterances
              may contain video game-specific jargon.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Data Validation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was the text validated by a different worker or a data curator?</p>
                </div>
              </div>

            </h5>

            <p>validated by data curator</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Data Preprocessing

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the text data pre-processed? (Enter N/A if the text was not pre-processed)</p>
                </div>
              </div>

            </h5>

            <p>First, regular expressions were used to enforce several standardization policies regarding special
              characters, punctuation, and the correction of undesired abbreviations/misspellings of standard
              domain-specific terms (e.g., terms like "Play station" or "PS4" would be changed to the uniform
              "PlayStation"). At the same time, hyphens were removed or enforced uniformly in certain terms, for
              example, "single-player". Although phrases such as "first person" should correctly have a hyphen when used
              as adjective, the crowdworkers used this rule very inconsistently. In order to avoid model outputs being
              penalized during the evaluation by the arbitrary choice of a hyphen presence or absence in the reference
              utterances, the hyphen was removed in all such phrases regardless of the noun vs. adjective use.</p>
            <p>Second, an extensive set of heuristics was developed to identify slot-related errors. This process
              revealed the vast majority of missing or incorrect slot mentions, which were subsequently fixed according
              to the corresponding MRs. This eventually led to the development of a robust, cross-domain, heuristic slot
              aligner that can be used for automatic slot error rate evaluation. For details, see the appendix in <a
                href="https://aclanthology.org/2021.inlg-1.45/">Juraska and Walker, 2021</a>.</p>
            <p>Crowdworkers would sometimes also inject a piece of information which was not present in the MR, some of
              which is not even represented by any of the slots, e.g., plot or main characters. This unsolicited
              information was removed from the utterances so as to avoid confusing the neural model. Finally, any
              remaining typos and grammatical errors were resolved.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Was Data Filtered?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Were text instances selected or filtered?</p>
                </div>
              </div>

            </h5>

            <p>manually</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Filter Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What were the selection criteria?</p>
                </div>
              </div>

            </h5>

            <p>Compliance with the indicated dialogue act type, semantic accuracy (i.e., all information in the
              corresponding MR mentioned and that correctly), and minimal extraneous information (e.g., personal
              experience/opinion). Whenever it was within a reasonable amount of effort, the utterances were manually
              fixed instead of being discarded/crowdsourced anew.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Structured Annotations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Additional Annotations?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have additional annotations for each instance?</p>
                </div>
              </div>

            </h5>

            <p>none</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Annotation Service?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was an annotation service used?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Consent</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Consent Policy?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was there a consent policy involved when gathering the data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Private Identifying Information (PII)</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Contains PII?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the source language data likely contain Personal Identifying Information about the data
                    creators or subjects?</p>
                </div>
              </div>

            </h5>

            <p>no PII</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Justification for no PII

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a justification for selecting <code>no PII</code> above.</p>
                </div>
              </div>

            </h5>

            <p>Crowdworkers were instructed to only express the information in the provided meaning representation,
              which never prompted them to mention anything about themselves. Occasionally, they would still include a
              bit of personal experience (e.g., "I used to like the game as a kid.") or opinion, but these would be too
              general to be considered PII.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Maintenance</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Maintenance Plan?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the original dataset have a maintenance plan?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Broader Social Context

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Work on the Social Impact of the Dataset</h4>
              </li>
              <li>
                <h4>Impact on Under-Served Communities</h4>
              </li>
              <li>
                <h4>Discussion of Biases</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Work on the Social Impact of the Dataset</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Usage of Models based on the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are you aware of cases where models trained on the task featured in this dataset ore related tasks
                    have been used in automated systems?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Impact on Under-Served Communities</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Addresses needs of underserved Communities?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset address the needs of communities that are traditionally underserved in language
                    technology, and particularly language generation technology? Communities may be underserved for
                    exemple because their language, language variety, or social or geographical context is
                    underepresented in NLP and NLG resources (datasets and models).</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Discussion of Biases</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Documented Social Biases?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are there documented social biases in the dataset? Biases in this context are variations in the
                    ways members of different social categories are represented that can have harmful downstream
                    consequences for members of the more disadvantaged group.</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Considerations for Using the Data

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>PII Risks and Liability</h4>
              </li>
              <li>
                <h4>Licenses</h4>
              </li>
              <li>
                <h4>Known Technical Limitations</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>PII Risks and Liability</h4>


      </div>

      <div class="datacard-subsection">
        <h4>Licenses</h4>


      </div>

      <div class="datacard-subsection">
        <h4>Known Technical Limitations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Technical Limitations

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any known technical limitations, such as spurrious correlations, train/test overlap,
                    annotation biases, or mis-annotations, and cite the works that first identified these limitations
                    when possible.</p>
                </div>
              </div>

            </h5>

            <p>The dataset is limited to a single domain: video games. One caveat of using a language generator trained
              on this dataset in a dialogue system as-is is that multiple subsequent turns discussing the same video
              game would be repeating its full name. ViGGO was designed for generation without context, and therefore it
              is up to the dialogue manager to ensure that pronouns are substituted for the names whenever it would
              sound more natural in a dialogue. Alternately, the dataset can easily be augmented with automatically
              constructed samples which omit the <code>name</code> slot in the MR and replace the name with a pronoun in
              the reference utterance.</p>
          </div>
        </div>

      </div>
    </div>
  </section>
</div></div></article></main><div class="layout_push__2FFZa"></div></div><footer class="layout_footer__dka_2 utils_eggshell__LF2UE"><span class="layout_backToHome__9sjx_"><a href="/"> Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__FmNQy">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"viggo","contentHtml":"\u003cdiv class=\"datacard\"\u003e\n  \u003csection class=\"datacard-section\"\u003e\n    \u003cdiv class=\"datacard-summary\"\u003e\n      \u003ch2\u003eviggo\u003c/h2\u003e\n      \u003cdiv class=\"summary-content\"\u003e\n        \u003cp\u003eViGGO is an English data-to-text generation dataset in the video game domain, with target responses being\n          more conversational than information-seeking, yet constrained to the information presented in a meaning\n          representation. The dataset is relatively small with about 5,000 datasets but very clean, and can thus serve\n          for evaluating transfer learning, low-resource, or few-shot capabilities of neural models.\u003c/p\u003e\n        \u003cp\u003eYou can load the dataset via:\u003c/p\u003e\n\n        \u003cdiv class=\"code-wrapper\"\u003e\n          \u003cdiv class=\"toolbar\"\u003e\n            \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\n          \u003c/div\u003e\n          \u003cpre\u003e\u003ccode\u003eimport datasets\ndata = datasets.load_dataset('GEM/viggo')\n\u003c/code\u003e\u003c/pre\u003e\n        \u003c/div\u003e\n\n        \u003cp\u003eThe data loader can be found \u003ca href=\"https://huggingface.co/datasets/GEM/viggo\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n      \u003cdiv class=\"datacard-field\"\u003e\n\n        \u003ch5\u003ewebsite\n\n        \u003c/h5\u003e\n\n        \u003cp\u003e\u003ca href=\"https://nlds.soe.ucsc.edu/viggo\"\u003eWesbite\u003c/a\u003e\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field\"\u003e\n\n        \u003ch5\u003epaper\n\n        \u003c/h5\u003e\n\n        \u003cp\u003e\u003ca href=\"https://aclanthology.org/W19-8623/\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field\"\u003e\n\n        \u003ch5\u003eauthors\n\n        \u003c/h5\u003e\n\n        \u003cp\u003eJuraj Juraska, Kevin K. Bowden, Marilyn Walker\u003c/p\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section quick\"\u003e\n    \u003ch3 class=\"section-title\"\u003eQuick-Use\u003c/h3\u003e\n\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n      \u003cdiv class=\"datacard-field periscope\"\u003e\n\n        \u003ch5\u003eContact Name\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\n                dataset.\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003eJuraj Juraska\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field telescope\"\u003e\n\n        \u003ch5\u003eMultilingual?\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003eno\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field telescope\"\u003e\n\n        \u003ch5\u003eCovered Languages\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003e\u003ccode\u003eEnglish\u003c/code\u003e\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field telescope\"\u003e\n\n        \u003ch5\u003eLicense\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003ecc-by-sa-4.0: Creative Commons Attribution Share Alike 4.0 International\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field telescope\"\u003e\n\n        \u003ch5\u003eAdditional Annotations?\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003enone\u003c/p\u003e\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-field telescope\"\u003e\n\n        \u003ch5\u003eContains PII?\n\n          \u003cdiv class=\"tooltip\"\u003e\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n            \u003cdiv class=\"tooltip-text\"\u003e\n              \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data creators\n                or subjects?\u003c/p\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n        \u003c/h5\u003e\n\n        \u003cp\u003eno PII\u003c/p\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n\n  \u003c/section\u003e\n\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003eDataset Overview\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eCredit\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eDataset Structure\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eWebpage\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat is the webpage for the dataset (if it exists)?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ca href=\"https://nlds.soe.ucsc.edu/viggo\"\u003eWesbite\u003c/a\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003ePaper\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat is the link to the paper describing the dataset (open access preferred)?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ca href=\"https://aclanthology.org/W19-8623/\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eBibTex\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eProvide the BibTex-formatted reference for the dataset. Please use the correct published version\n                    (ACL anthology, etc.) instead of google scholar created Bibtex.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n\n            \u003cdiv class=\"code-wrapper\"\u003e\n              \u003cdiv class=\"toolbar\"\u003e\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\n              \u003c/div\u003e\n              \u003cpre\u003e\u003ccode\u003e@inproceedings{juraska-etal-2019-viggo,\ntitle = \"{V}i{GGO}: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation\",\nauthor = \"Juraska, Juraj  and\nBowden, Kevin  and\nWalker, Marilyn\",\nbooktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\nmonth = oct # \"{--}\" # nov,\nyear = \"2019\",\naddress = \"Tokyo, Japan\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://aclanthology.org/W19-8623\",\ndoi = \"10.18653/v1/W19-8623\",\npages = \"164--172\",\n}\n\u003c/code\u003e\u003c/pre\u003e\n            \u003c/div\u003e\n\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eContact Name\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\n                    dataset.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eJuraj Juraska\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eContact Email\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIf known, provide the email of at least one person the reader can contact for questions about the\n                    dataset.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ca href=\"mailto:jjuraska@ucsc.edu\"\u003ejjuraska@ucsc.edu\u003c/a\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eHas a Leaderboard?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes the dataset have an active leaderboard?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eMultilingual?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eCovered Languages\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ccode\u003eEnglish\u003c/code\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eLicense\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003ecc-by-sa-4.0: Creative Commons Attribution Share Alike 4.0 International\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eIntended Use\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat is the intended use of the dataset?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eViGGO was designed for the task of data-to-text generation in chatbots (as opposed to task-oriented\n              dialogue systems), with target responses being more conversational than information-seeking, yet\n              constrained to the information presented in a meaning representation. The dataset, being relatively small\n              and clean, can also serve for demonstrating transfer learning capabilities of neural models.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003ePrimary Task\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat primary task does the dataset support?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eData-to-Text\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eCredit\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eCuration Organization Type(s)\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIn what kind of organization did the dataset curation happen?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ccode\u003eacademic\u003c/code\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eCuration Organization(s)\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eName the organization(s).\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eUniversity of California, Santa Cruz\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eDataset Creators\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWho created the original dataset? List the people involved in collecting the dataset and their\n                    affiliation(s).\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eJuraj Juraska, Kevin K. Bowden, Marilyn Walker\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eWho added the Dataset to GEM?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWho contributed to the data card and adding the dataset to GEM? List the people+affiliations\n                    involved in creating this data card and who helped integrate this dataset into GEM.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eJuraj Juraska\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eDataset Structure\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eData Fields\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eList and describe the fields present in the dataset.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eEach example in the dataset has the following two fields:\u003c/p\u003e\n            \u003cul\u003e\n              \u003cli\u003e\u003ccode\u003emr\u003c/code\u003e: A meaning representation (MR) that, in a structured format, provides the information\n                to convey, as well as the desired dialogue act (DA) type.\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eref\u003c/code\u003e: A reference output, i.e., a corresponding utterance realizing all the information in\n                the MR.\u003c/li\u003e\n            \u003c/ul\u003e\n            \u003cp\u003eEach MR is a flattened dictionary of attribute-and-value pairs, \"wrapped\" in the dialogue act type\n              indication. This format was chosen primarily for its compactness, but also to allow for easy concatenation\n              of multiple DAs (each with potentially different attributes) in a single MR.\u003c/p\u003e\n            \u003cp\u003eFollowing is the list of all possible attributes (which are also refered to as \"slots\") in ViGGO along\n              with their types/possible values:\u003c/p\u003e\n            \u003cul\u003e\n              \u003cli\u003e\u003ccode\u003ename\u003c/code\u003e: The name of a video game (e.g., Rise of the Tomb Raider).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003erelease_year\u003c/code\u003e: The year a video game was released in (e.g., 2015).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eexp_release_date\u003c/code\u003e: For a not-yet-released game, the date when it is expected to be\n                released (e.g., February 22, 2019). \u003cem\u003eNote: This slot cannot appear together with\n                  \u003ccode\u003erelease_year\u003c/code\u003e in the same dialogue act.\u003c/em\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003edeveloper\u003c/code\u003e: The name of the studio/person that created the game (e.g., Crystal Dynamics).\n              \u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003egenres\u003c/code\u003e: A list of one or more genre labels from a set of possible values (e.g.,\n                action-adventure, shooter).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eplayer_perspective\u003c/code\u003e: A list of one or more perspectives from which the game is/can be\n                played (possible values: first person, third person, side view, bird view).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eplatforms\u003c/code\u003e: A list of one or more gaming platforms the game was officially released for\n                (possible values: PC, PlayStation, Xbox, Nintendo, Nintendo Switch).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eesrb\u003c/code\u003e: A game's content rating as determined by the ESRB (possible values: E (for\n                Everyone), E 10+ (for Everyone 10 and Older), T (for Teen), M (for Mature)).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003erating\u003c/code\u003e: Depending on the dialogue act this slot is used with, it is a categorical\n                representation of either the game's average rating or the game's liking (possible values: excellent,\n                good, average, poor).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003ehas_multiplayer\u003c/code\u003e: Indicates whether a game supports multiplayer or can only be played in\n                single-player mode (possible values: yes, no).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003eavailable_on_steam\u003c/code\u003e: Indicates whether a game can be purchased through the Steam digital\n                distribution service (possible values: yes, no).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003ehas_linux_release\u003c/code\u003e: Indicates whether a game is supported on Linux operating systems\n                (possible values: yes, no).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003ehas_mac_release\u003c/code\u003e: Indicates whether a game is supported on macOS (possible values: yes,\n                no).\u003c/li\u003e\n              \u003cli\u003e\u003ccode\u003especifier\u003c/code\u003e: A game specifier used by the \u003ccode\u003erequest\u003c/code\u003e DA, typically an adjective\n                (e.g., addictive, easiest, overrated, visually impressive).\u003c/li\u003e\n            \u003c/ul\u003e\n            \u003cp\u003eEach MR in the dataset has 3 distinct reference utterances, which are represented as 3 separate examples\n              with the same MR.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eReason for Structure\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eHow was the dataset structure determined?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eThe dataset structure mostly follows the format of the popular E2E dataset, however, with added dialogue\n              act type indications, new list-type attributes introduced, and unified naming convention for multi-word\n              attribute names.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eExample Instance\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eProvide a JSON formatted example of a typical instance in the dataset.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n\n            \u003cdiv class=\"code-wrapper\"\u003e\n              \u003cdiv class=\"toolbar\"\u003e\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\n              \u003c/div\u003e\n              \u003cpre\u003e\u003ccode\u003e{\n\"mr\": \"give_opinion(name[SpellForce 3], rating[poor], genres[real-time strategy, role-playing], player_perspective[bird view])\",\n\"ref\": \"I think that SpellForce 3 is one of the worst games I've ever played. Trying to combine the real-time strategy and role-playing genres just doesn't work, and the bird view perspective makes it near impossible to play.\"\n}\n\u003c/code\u003e\u003c/pre\u003e\n            \u003c/div\u003e\n\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eData Splits\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDescribe and name the splits in the dataset if there are more than one.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eViGGO is split into 3 partitions, with no MRs in common between the training set and either of the\n              validation and the test set (and that \u003cem\u003eafter\u003c/em\u003e delexicalizing the \u003ccode\u003ename\u003c/code\u003e and\n              \u003ccode\u003edeveloper\u003c/code\u003e slots). The ratio of examples in the partitions is approximately 7.5 : 1 : 1.5,\n              with their exact sizes listed below:\u003c/p\u003e\n            \u003cul\u003e\n              \u003cli\u003e\u003cstrong\u003eTrain:\u003c/strong\u003e 5,103 (1,675 unique MRs)\u003c/li\u003e\n              \u003cli\u003e\u003cstrong\u003eValidation:\u003c/strong\u003e 714 (238 unique MRs)\u003c/li\u003e\n              \u003cli\u003e\u003cstrong\u003eTest:\u003c/strong\u003e 1,083 (359 unique MRs)\u003c/li\u003e\n              \u003cli\u003e\u003cstrong\u003eTOTAL:\u003c/strong\u003e 6,900 (2,253 unique MRs)\u003c/li\u003e\n            \u003c/ul\u003e\n            \u003cp\u003e\u003cem\u003eNote: The reason why the number of unique MRs is not exactly one third of all examples is that for\n                each \u003ccode\u003erequest_attribute\u003c/code\u003e DA (which only has one slot, and that without a value) 12 reference\n                utterances were collected instead of 3.\u003c/em\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eSplitting Criteria\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDescribe any criteria for splitting the data, if used. If there are differences between the splits\n                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by\n                    humans, or if different numbers of annotators contributed to each example), describe them here.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eA similar MR length and slot distribution was preserved across the partitions. The distribution of DA\n              types, on the other hand, is skewed slightly toward fewer \u003ccode\u003einform\u003c/code\u003e DA instances (the most\n              prevalent DA type) and a higher proportion of the less prevalent DAs in the validation and the test set.\n            \u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003e\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat does an outlier of the dataset in terms of length/perplexity/embedding look like?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n\n            \u003cdiv class=\"code-wrapper\"\u003e\n              \u003cdiv class=\"toolbar\"\u003e\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\n              \u003c/div\u003e\n              \u003cpre\u003e\u003ccode\u003e{\n\"mr\": \"request_attribute(player_perspective[])\",\n\"ref\": \"Is there a certain player perspective that you prefer over others in games you play?\"\n},\n{\n\"mr\": \"inform(name[FIFA 12], esrb[E (for Everyone)], genres[simulation, sport], player_perspective[bird view, side view], platforms[PlayStation, Xbox, Nintendo, PC], available_on_steam[no])\",\n\"ref\": \"Fifa 12 is a decent sports simulator. It's pretty cool how the game swaps from the bird's eye perspective down to a side view while you're playing. You can get the game for PlayStation, Xbox, Nintendo consoles, and PC, but unfortunately it's not on Steam. Of course, as a sports game there's not much objectionable content so it's rated E.\"\n},\n{\n\"mr\": \"inform(name[Super Bomberman], release_year[1993], genres[action, strategy], has_multiplayer[no], platforms[Nintendo, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])\",\n\"ref\": \"Super Bomberman is one of my favorite Nintendo games, also available on PC, though not through Steam. It came out all the way back in 1993, and you can't get it for any modern consoles, unfortunately, so no online multiplayer, or of course Linux or Mac releases either. That said, it's still one of the most addicting action-strategy games out there.\"\n}\n\u003c/code\u003e\u003c/pre\u003e\n            \u003c/div\u003e\n\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003eDataset in GEM\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eWhy is the Dataset in GEM?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat does this dataset contribute toward better generation evaluation and why is it part of GEM?\n                  \u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eViGGO is a fairly small dataset but includes a greater variety of utterance types than most other\n              datasets for NLG from structured meaning representations. This makes it more interesting from the\n              perspective of model evaluation, since models have to learn to differentiate between various dialogue act\n              types that share the same slots.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eSimilar Datasets\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDo other datasets for the high level task exist?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eyes\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eUnique Language Coverage\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes this dataset cover other languages than other datasets for the same task?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eDifference from other GEM datasets\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat else sets this dataset apart from other similar datasets in GEM?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eViGGO's language is more casual and conversational -- as opposed to information-seeking -- which\n              differentiates it from the majority of popular datasets for the same type of data-to-text task. Moreover,\n              the video game domain is a rather uncommon one in the NLG community, despite being very well-suited for\n              data-to-text generation, considering it offers entities with many attributes to talk about, which can be\n              described in a structured format.\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eModificatied for GEM?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eHas the GEM version of the dataset been modified in any way (data, processing, splits) from the\n                    original curated data?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAdditional Splits?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes GEM provide additional splits to the dataset?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003ePointers to Resources\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eGetting started with in-depth research on the task. Add relevant pointers to resources that\n                    researchers can consult when they want to get started digging deeper into the task.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"http://www.macs.hw.ac.uk/InteractionLab/E2E/\"\u003eE2E NLG Challenge\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eTechnical Terms\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eTechnical terms used in this card and the dataset and their definitions\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cul\u003e\n              \u003cli\u003eMR = meaning representation\u003c/li\u003e\n              \u003cli\u003eDA = dialogue act\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003ePrevious Results\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003ePrevious Results\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003ePrevious Results\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eMetrics\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat metrics are typically used for this task?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ccode\u003eBLEU\u003c/code\u003e, \u003ccode\u003eMETEOR\u003c/code\u003e, \u003ccode\u003eROUGE\u003c/code\u003e, \u003ccode\u003eBERT-Score\u003c/code\u003e, \u003ccode\u003eBLEURT\u003c/code\u003e,\n              \u003ccode\u003eOther: Other Metrics\u003c/code\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eOther Metrics\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDefinitions of other metrics\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eSER (slot error rate): Indicates the proportion of missing/incorrect/duplicate/hallucinated slot mentions\n              in the utterances across a test set. The closer to zero a model scores in this metric, the more\n              semantically accurate its outputs are. This metric is typically calculated either manually on a small\n              sample of generated outputs, or heuristically using domain-specific regex rules and gazetteers.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003ePrevious results available?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eAre previous results available?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eyes\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eRelevant Previous Results\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat are the most relevant previous results for this task/dataset?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cul\u003e\n              \u003cli\u003e\u003ca href=\"https://aclanthology.org/W19-8623/\"\u003eJuraska et al., 2019. ViGGO: A Video Game Corpus for\n                  Data-To-Text Generation in Open-Domain Conversation.\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"https://aclanthology.org/2020.coling-main.218/\"\u003eHarkous et al., 2020. Have Your Text and Use\n                  It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity.\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"https://aclanthology.org/2020.emnlp-main.419/\"\u003eKedzie and McKeown, 2020. Controllable Meaning\n                  Representation to Text Generation: Linearization and Data Augmentation Strategies.\u003c/a\u003e\u003c/li\u003e\n              \u003cli\u003e\u003ca href=\"https://aclanthology.org/2021.inlg-1.45/\"\u003eJuraska and Walker, 2021. Attention Is Indeed All\n                  You Need: Semantically Attention-Guided Decoding for Data-to-Text NLG.\u003c/a\u003e\u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003eDataset Curation\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003eOriginal Curation\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eLanguage Data\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eStructured Annotations\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eConsent\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eMaintenance\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eOriginal Curation\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eOriginal Curation Rationale\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eOriginal curation rationale\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eThe primary motivation behind ViGGO was to create a data-to-text corpus in a new but conversational\n              domain, and intended for use in open-domain chatbots rather than task-oriented dialogue systems. To this\n              end, the dataset contains utterances of 9 generalizable and conversational dialogue act types, revolving\n              around various aspects of video games. The idea is that similar, relatively small datasets could fairly\n              easily be collected for other conversational domains -- especially other entertainment domains (such as\n              music or books), but perhaps also topics like animals or food -- to support an open-domain conversational\n              agent with controllable neural NLG.\u003c/p\u003e\n            \u003cp\u003eAnother desired quality of the ViGGO dataset was cleanliness (no typos and grammatical errors) and\n              semantic accuracy, which has often not been the case with other crowdsourced data-to-text corpora. In\n              general, for the data-to-text generation task, there is arguably no need to put the burden on the\n              generation model to figure out the noise, since the noise would not be expected to be there in a\n              real-world system whose dialogue manager that creates the input for the NLG module is usually configurable\n              and tightly controlled.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eCommunicative Goal\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat was the communicative goal?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eProduce a response from a structured meaning representation in the context of a conversation about video\n              games. It can be a brief opinion or a description of a game, as well as a request for attribute (e.g.,\n              genre, player perspective, or platform) preference/confirmation or an inquiry about liking a particular\n              type of games.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eSourced from Different Sources\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIs the dataset aggregated from different data sources?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eLanguage Data\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eHow was Language Data Obtained?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eHow was the language data obtained?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ccode\u003eCrowdsourced\u003c/code\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eWhere was it crowdsourced?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eIf crowdsourced, where from?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003e\u003ccode\u003eAmazon Mechanical Turk\u003c/code\u003e\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eLanguage Producers\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat further information do we have on the language producers?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eThe paid crowdworkers who produced the reference utterances were from English-speaking countries, and\n              they had at least 1,000 HITs approved and a HIT approval rate of 98% or more. Furthermore, in the\n              instructions, crowdworkers were discouraged from taking on the task unless they considered themselves a\n              gamer.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eTopics Covered\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes the language in the dataset focus on specific topics? How would you describe them?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eThe dataset focuses on video games and their various aspects, and hence the language of the utterances\n              may contain video game-specific jargon.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eData Validation\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWas the text validated by a different worker or a data curator?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003evalidated by data curator\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eData Preprocessing\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eHow was the text data pre-processed? (Enter N/A if the text was not pre-processed)\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eFirst, regular expressions were used to enforce several standardization policies regarding special\n              characters, punctuation, and the correction of undesired abbreviations/misspellings of standard\n              domain-specific terms (e.g., terms like \"Play station\" or \"PS4\" would be changed to the uniform\n              \"PlayStation\"). At the same time, hyphens were removed or enforced uniformly in certain terms, for\n              example, \"single-player\". Although phrases such as \"first person\" should correctly have a hyphen when used\n              as adjective, the crowdworkers used this rule very inconsistently. In order to avoid model outputs being\n              penalized during the evaluation by the arbitrary choice of a hyphen presence or absence in the reference\n              utterances, the hyphen was removed in all such phrases regardless of the noun vs. adjective use.\u003c/p\u003e\n            \u003cp\u003eSecond, an extensive set of heuristics was developed to identify slot-related errors. This process\n              revealed the vast majority of missing or incorrect slot mentions, which were subsequently fixed according\n              to the corresponding MRs. This eventually led to the development of a robust, cross-domain, heuristic slot\n              aligner that can be used for automatic slot error rate evaluation. For details, see the appendix in \u003ca\n                href=\"https://aclanthology.org/2021.inlg-1.45/\"\u003eJuraska and Walker, 2021\u003c/a\u003e.\u003c/p\u003e\n            \u003cp\u003eCrowdworkers would sometimes also inject a piece of information which was not present in the MR, some of\n              which is not even represented by any of the slots, e.g., plot or main characters. This unsolicited\n              information was removed from the utterances so as to avoid confusing the neural model. Finally, any\n              remaining typos and grammatical errors were resolved.\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eWas Data Filtered?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWere text instances selected or filtered?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003emanually\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eFilter Criteria\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWhat were the selection criteria?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eCompliance with the indicated dialogue act type, semantic accuracy (i.e., all information in the\n              corresponding MR mentioned and that correctly), and minimal extraneous information (e.g., personal\n              experience/opinion). Whenever it was within a reasonable amount of effort, the utterances were manually\n              fixed instead of being discarded/crowdsourced anew.\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eStructured Annotations\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAdditional Annotations?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003enone\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAnnotation Service?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWas an annotation service used?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eConsent\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAny Consent Policy?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eWas there a consent policy involved when gathering the data?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eContains PII?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data\n                    creators or subjects?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno PII\u003c/p\u003e\n          \u003c/div\u003e\n\n          \u003cdiv class=\"datacard-field periscope\"\u003e\n\n            \u003ch5\u003eJustification for no PII\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eProvide a justification for selecting \u003ccode\u003eno PII\u003c/code\u003e above.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eCrowdworkers were instructed to only express the information in the provided meaning representation,\n              which never prompted them to mention anything about themselves. Occasionally, they would still include a\n              bit of personal experience (e.g., \"I used to like the game as a kid.\") or opinion, but these would be too\n              general to be considered PII.\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eMaintenance\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAny Maintenance Plan?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes the original dataset have a maintenance plan?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003eBroader Social Context\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eUsage of Models based on the Data\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eAre you aware of cases where models trained on the task featured in this dataset ore related tasks\n                    have been used in automated systems?\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAddresses needs of underserved Communities?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDoes this dataset address the needs of communities that are traditionally underserved in language\n                    technology, and particularly language generation technology? Communities may be underserved for\n                    exemple because their language, language variety, or social or geographical context is\n                    underepresented in NLP and NLG resources (datasets and models).\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field telescope\"\u003e\n\n            \u003ch5\u003eAny Documented Social Biases?\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eAre there documented social biases in the dataset? Biases in this context are variations in the\n                    ways members of different social categories are represented that can have harmful downstream\n                    consequences for members of the more disadvantaged group.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eno\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\n  \u003csection class=\"datacard-section open\"\u003e\n\n    \u003cdiv class=\"datacard-section-preview\"\u003e\n      \u003ch3\u003eConsiderations for Using the Data\n\n        \u003cdiv class=\"tooltip\"\u003e\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n          \u003cdiv class=\"tooltip-text\"\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eLicenses\u003c/h4\u003e\n              \u003c/li\u003e\n              \u003cli\u003e\n                \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/h3\u003e\n      \u003cbutton class=\"expand-button\"\u003e\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\n          \u003c/path\u003e\n        \u003c/svg\u003e\n      \u003c/button\u003e\n    \u003c/div\u003e\n\n    \u003cdiv class=\"datacard-collapsible\"\u003e\n\n\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\n\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eLicenses\u003c/h4\u003e\n\n\n      \u003c/div\u003e\n\n      \u003cdiv class=\"datacard-subsection\"\u003e\n        \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\n\n\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\n\n          \u003cdiv class=\"datacard-field microscope\"\u003e\n\n            \u003ch5\u003eTechnical Limitations\n\n              \u003cdiv class=\"tooltip\"\u003e\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\n                \u003cdiv class=\"tooltip-text\"\u003e\n                  \u003cp\u003eDescribe any known technical limitations, such as spurrious correlations, train/test overlap,\n                    annotation biases, or mis-annotations, and cite the works that first identified these limitations\n                    when possible.\u003c/p\u003e\n                \u003c/div\u003e\n              \u003c/div\u003e\n\n            \u003c/h5\u003e\n\n            \u003cp\u003eThe dataset is limited to a single domain: video games. One caveat of using a language generator trained\n              on this dataset in a dialogue system as-is is that multiple subsequent turns discussing the same video\n              game would be repeating its full name. ViGGO was designed for generation without context, and therefore it\n              is up to the dialogue manager to ensure that pronouns are substituted for the names whenever it would\n              sound more natural in a dialogue. Alternately, the dataset can easily be augmented with automatically\n              constructed samples which omit the \u003ccode\u003ename\u003c/code\u003e slot in the MR and replace the name with a pronoun in\n              the reference utterance.\u003c/p\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\u003c/div\u003e","title":"viggo","type":"Data-to-Text","languages":"English","summary":"ViGGO is an English data-to-text generation dataset in the video game domain, with target responses being more conversational than information-seeking, yet constrained to the information presented in a meaning representation. The dataset is relatively small with about 5,000 datasets but very clean, and can thus serve for evaluating transfer learning, low-resource, or few-shot capabilities of neural models."}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"viggo"},"buildId":"4qC7i6uP3uGR34Kebmohm","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>