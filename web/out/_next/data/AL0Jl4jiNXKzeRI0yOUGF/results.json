{"pageProps":{"evalConfig":{"common_metrics":{"rouge1":{"citation":"","description":"ROUGE score focusing on unigrams.","show_as":"ROUGE-1"},"rouge2":{"citation":"","description":"ROUGE score focusing on bigrams.","show_as":"ROUGE-2"},"rougeL":{"citation":"","description":"ROUGE score focusing on longest common subsequence.","show_as":"ROUGE-L"},"msttr-100":{"citation":"","description":"Mean Segmental Type-Token Ratio, a measure of lexical diversity.","show_as":"MSTTR"},"mean_pred_length":{"citation":"","description":"Average length of a system output.","show_as":"Output Length"},"distinct-1":{"citation":"","description":"Ratio of distinct unigrams / total number of unigrams.","show_as":"Distinct-1"},"vocab_size-1":{"citation":"","description":"Number of distinct words used by the system.","show_as":"Vocabulary Size"},"unique-1":{"citation":"","description":"number of unigrams that only occur once in the whole data.","show_as":"Unique-1"},"entropy-1":{"citation":"","description":"Shannon entropy over unigrams","show_as":"Entropy-1"},"distinct-2":{"citation":"","description":"Ratio of distinct bigrams / total number of bigrams.","show_as":"Distinct-2"},"vocab_size-2":{"citation":"","description":"Number of distinct bigrams used by the system.","show_as":"Bigram Vocabulary Size"},"unique-2":{"citation":"","description":"Number of bigrams that only occur once in the whole data","show_as":"Unique-2"},"entropy-2":{"citation":"","description":"Shannon entropy over bigrams.","show_as":"Entropy-2"},"cond_entropy-2":{"citation":"","description":"Language model style conditional entropy -- N-grams conditioned on N-1-grams.","show_as":"Bigram Conditional Entropy"},"distinct-3":{"citation":"","description":"Ratio of distinct trigrams / total number of trigrams.","show_as":"Distinct-3"},"vocab_size-3":{"citation":"","description":"Number of distinct trigrams used by the system.","show_as":"Trigram Vocabulary Size"},"unique-3":{"citation":"","description":"Number of trigrams that only occur once in the whole data.","show_as":"Unique-3"},"entropy-3":{"citation":"","description":"Shannon entropy over trigrams.","show_as":"Entropy-2"},"cond_entropy-3":{"citation":"","description":"Language model style conditional entropy -- N-grams conditioned on N-1-grams","show_as":"Trigram Conditional Entropy"},"bertscore":{"citation":"","description":"A BERT-based similarity measure between reference and generation.","show_as":"BERTScore"},"bleu":{"citation":"","description":"A measure of lexical similarity.","show_as":"BLEU"},"bleurt":{"citation":"","description":"A learned metric to measure semantic equivalence between reference and generation.","show_as":"BLEURT"},"meteor":{"citation":"","description":"An advanced lexical similarity metric also including stemming and synonymy matching.","show_as":"Meteor"},"nubia":{"citation":"","description":"A metric combining multiple aspects like entailment and similarity.","show_as":"NUBIA"},"sari":{"citation":"","description":"A simplification metric.","show_as":"SARI"},"nist":{"citation":"http://dl.acm.org/citation.cfm?id=1289189.1289273","description":"NIST is an alternative to BLEU with slightly different calculation.","show_as":"NIST"}},"challenges":{"data2text":{"datasets":["common_gen_test","dart_test","e2e_nlg_test","totto_test","cs_restaurants_test","web_nlg_en_test","web_nlg_ru_test"],"metrics":[]},"summarization":{"datasets":["mlsum_de_test","mlsum_es_test","xsum_test","wiki_lingua_turkish_tr_test","wiki_lingua_vietnamese_vi_test","wiki_lingua_spanish_es_test","wiki_lingua_russian_ru_test"],"metrics":[]},"dialog":{"datasets":["schema_guided_dialog_test"],"metrics":[]},"simplification":{"datasets":["wiki_auto_asset_turk_test_asset","wiki_auto_asset_turk_test_turk"],"metrics":[]}},"measures":{"diversity":["msttr-100","distinct-1","distinct-2","unique-1","unique-2","entropy-1","entropy-2","cond_entropy-2"],"lexical":["rouge1","rouge2","rougeL","bleu","meteor","sari","nist"],"semantic":["bertscore","bleurt"],"faithful":["nubia"],"descriptive":["mean_pred_length","vocab_size-1","vocab_size-2"]}}},"__N_SSG":true}