{"pageProps":{"taskData":{"id":"XSum","contentHtml":"<h2 id=\"table-of-contents\">Table of Contents</h2>\n<ul>\n<li><a href=\"#dataset-description\">Dataset Description</a>\n<ul>\n<li><a href=\"#dataset-and-task-summary\">Dataset and Task Summary</a></li>\n<li><a href=\"#why-is-this-dataset-part-of-gem\">Why is this dataset part of GEM?</a></li>\n<li><a href=\"#languages\">Languages</a></li>\n</ul>\n</li>\n<li><a href=\"#meta-information\">Meta Information</a>\n<ul>\n<li><a href=\"#dataset-curators\">Dataset Curators</a></li>\n<li><a href=\"#licensing-information\">Licensing Information</a></li>\n<li><a href=\"#citation-information\">Citation Information</a></li>\n<li><a href=\"#leaderboard\">Leaderboard</a></li>\n</ul>\n</li>\n<li><a href=\"#dataset-structure\">Dataset Structure</a>\n<ul>\n<li><a href=\"#data-instances\">Data Instances</a></li>\n<li><a href=\"#data-fields\">Data Fields</a></li>\n<li><a href=\"#data-statistics\">Data Statistics</a></li>\n</ul>\n</li>\n<li><a href=\"#dataset-creation\">Dataset Creation</a>\n<ul>\n<li><a href=\"#curation-rationale\">Curation Rationale</a></li>\n<li><a href=\"#communicative-goal\">Communicative Goal</a></li>\n<li><a href=\"#source-data\">Source Data</a>\n<ul>\n<li><a href=\"#initial-data-collection-and-normalization\">Initial Data Collection and Normalization</a></li>\n<li><a href=\"#who-are-the-source-language-producers\">Who are the source language producers?</a></li>\n</ul>\n</li>\n<li><a href=\"#annotations\">Annotations</a>\n<ul>\n<li><a href=\"#annotation-process\">Annotation process</a></li>\n<li><a href=\"#who-are-the-annotators\">Who are the annotators?</a></li>\n</ul>\n</li>\n<li><a href=\"#personal-and-sensitive-information\">Personal and Sensitive Information</a></li>\n</ul>\n</li>\n<li><a href=\"#changes-to-the-original-dataset-for-gem\">Changes to the Original Dataset for GEM</a>\n<ul>\n<li><a href=\"#special-test-sets\">Special test sets</a>\n<ul>\n<li><a href=\"#data-shift\">Data shift</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#considerations-for-using-the-data\">Considerations for Using the Data</a>\n<ul>\n<li><a href=\"#social-impact-of-the-dataset\">Social Impact of the Dataset</a></li>\n<li><a href=\"#impact-on-underserved-communities\">Impact on Underserved Communities</a></li>\n<li><a href=\"#discussion-of-biases\">Discussion of Biases</a></li>\n<li><a href=\"#other-known-limitations\">Other Known Limitations</a></li>\n</ul>\n</li>\n<li><a href=\"#getting-started-with-in-depth-research-on-the-task\">Getting started with in-depth research on the task</a></li>\n</ul>\n<h2 id=\"dataset-description\">Dataset Description</h2>\n<ul>\n<li><strong>Homepage:</strong>: NA (See Repository)</li>\n<li><strong>Repository:</strong> <a href=\"https://github.com/EdinburghNLP/XSum\">https://github.com/EdinburghNLP/XSum</a></li>\n<li><strong>Paper:</strong> <a href=\"https://www.aclweb.org/anthology/D18-1206\">Original Paper</a></li>\n<li><strong>Point of Contact:</strong> <a href=\"shashi.narayan@gmail.com\">Shashi Narayan</a></li>\n</ul>\n<h3 id=\"dataset-and-task-summary\">Dataset and Task Summary</h3>\n<p>The dataset is for the task of abstractive summarization in its extreme form, its about summarizing a document in a single sentence. It introduces extreme summarization, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question \"What is the article about?\".</p>\n<h3 id=\"why-is-this-dataset-part-of-gem\">Why is this dataset part of GEM?</h3>\n<p>This dataset is part of the GEM benchmark for the task of summarization, alongside MLSum and WikiLingua, and acts as a large-scale, high-quality resource for extreme summarization.</p>\n<h3 id=\"languages\">Languages</h3>\n<p>English</p>\n<h2 id=\"meta-information\">Meta Information</h2>\n<h3 id=\"dataset-curators\">Dataset Curators</h3>\n<p>Shashi Narayan and Shay B. Cohen and Mirella Lapata</p>\n<h3 id=\"licensing-information\">Licensing Information</h3>\n<p>CC 4.0 BY-SA (<a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons 4.0 Attribution â€“ Share-Alike</a>)</p>\n<h3 id=\"citation-information\">Citation Information</h3>\n<pre><code class=\"language-@InProceedings{xsum-emnlp,\">  author =      \"Shashi Narayan and Shay B. Cohen and Mirella Lapata\",\n  title =       \"Don't Give Me the Details, Just the Summary! {T}opic-Aware Convolutional Neural Networks for Extreme Summarization\",\n  booktitle =   \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing \",\n  year =        \"2018\",\n  address =     \"Brussels, Belgium\",\n}\n</code></pre>\n<h3 id=\"leaderboard\">Leaderboard</h3>\n<p>This dataset has no corresponding public leaderboard.</p>\n<h2 id=\"dataset-structure\">Dataset Structure</h2>\n<h3 id=\"data-instances\">Data Instances</h3>\n<p>[More Information Needed]</p>\n<h3 id=\"data-fields\">Data Fields</h3>\n<p>There are three features of each story file in the dataset:</p>\n<p>Document: Input news article.</p>\n<p>Summary: One sentence summary of the article.</p>\n<p>Id: BBC ID of the article.</p>\n<h3 id=\"data-statistics\">Data Statistics</h3>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n<th align=\"center\">Number of Documents</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Training</td>\n<td align=\"center\">204,045</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td align=\"center\">11,332</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td align=\"center\">11,334</td>\n</tr>\n<tr>\n<td>Total</td>\n<td align=\"center\">226k</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n<th align=\"center\">number of words</th>\n<th align=\"center\">number of sentences</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Documents</td>\n<td align=\"center\">431.07</td>\n<td align=\"center\">19.77</td>\n</tr>\n<tr>\n<td>Summary</td>\n<td align=\"center\">23.26</td>\n<td align=\"center\">1.00</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"dataset-creation\">Dataset Creation</h2>\n<h3 id=\"curation-rationale\">Curation Rationale</h3>\n<p>[More Information Needed]</p>\n<h3 id=\"communicative-goal\">Communicative Goal</h3>\n<p>[More Information Needed]</p>\n<h3 id=\"source-data\">Source Data</h3>\n<h4 id=\"initial-data-collection-and-normalization\">Initial Data Collection and Normalization</h4>\n<p>The dataset consists of BBC articles and accompanying single sentence summaries. Specifically, each article is prefaced with an introductory sentence (aka summary) which is professionally written, typically by the author of the article. They collected 226,711 Wayback archived BBC articles ranging over almost a decade (2010 to 2017) and covering a wide variety of domains (e.g., News, Politics, Sports, Weather, Business, Technology, Science, Health, Family, Education, Entertainment and Arts). Each article comes with a unique identifier in its URL, which was then used to randomly split the dataset into training (90%, 204,045), validation (5%, 11,332), and test (5%, 11,334) set.</p>\n<h4 id=\"who-are-the-source-language-producers\">Who are the source language producers?</h4>\n<p>Professional journalists.</p>\n<h3 id=\"annotations\">Annotations</h3>\n<p>Any additional annotations are not collected for this dataset.</p>\n<h4 id=\"annotation-process\">Annotation process</h4>\n<h4 id=\"who-are-the-annotators\">Who are the annotators?</h4>\n<h3 id=\"personal-and-sensitive-information\">Personal and Sensitive Information</h3>\n<h2 id=\"changes-to-the-original-dataset-for-gem\">Changes to the Original Dataset for GEM</h2>\n<p>In addition to the original dataset, a modified version of the dataset will be part of the GEM framework.</p>\n<p>XSum gold summaries often have divergence issues between the source and target texts due to the dataset artifact that gold summaries are introductory sentences prefacing each article.</p>\n<p>Models agnostic to such noises are vulnerable to hallucinations (Wiseman et al., 2017; Dhingra et al., 2019, Maynez et al., 2020).  For GEM, we have finetuned a BERT-based classifier on 500 document and gold summary pairs, manually annotated for faithfulness (Maynez et al., 2020) and excluded all document-summary pairs from the original XSum dataset where the classifier was not confident (p(faithfull) > 0.8) whether the summary is faithful to the document or not. As a result, we ended up with 23206 training, 1117 validation and 1166 test instances.</p>\n<h3 id=\"special-test-sets\">Special test sets</h3>\n<h4 id=\"data-shift\">Data shift</h4>\n<p>We compiled time-shifted test data in the form of new articles for the second semester of 2020 with Covid19-related keywords. We collected new articles from the Wayback archived BBC articles and used the scripts provided for the re-creation of the <a href=\"https://github.com/EdinburghNLP/XSum\">XSum dataset</a>. The new challenge test set contains 401 instances.</p>\n<h2 id=\"considerations-for-using-the-data\">Considerations for Using the Data</h2>\n<h3 id=\"social-impact-of-the-dataset\">Social Impact of the Dataset</h3>\n<h3 id=\"impact-on-underserved-communities\">Impact on Underserved Communities</h3>\n<h3 id=\"discussion-of-biases\">Discussion of Biases</h3>\n<h3 id=\"other-known-limitations\">Other Known Limitations</h3>\n<h2 id=\"getting-started-with-in-depth-research-on-the-task\">Getting started with in-depth research on the task</h2>\n","title":"XSum","type":"Summarization","motivation":"Large scale monolingual dataset for evaluating extreme summarization."}},"__N_SSG":true}