<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Model Cards</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/86a77084a15a5546.css" as="style"/><link rel="stylesheet" href="/_next/static/css/86a77084a15a5546.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6a1c82b8c4bd78ef.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6a1c82b8c4bd78ef.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-b48e3bfe07390621.js" defer=""></script><script src="/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/_next/static/chunks/main-a56c17dda72126ba.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da8862f0ec3a97c1.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-3dccc3616b494db8.js" defer=""></script><script src="/_next/static/chunks/pages/model_cards-c22039ba8c09fe44.js" defer=""></script><script src="/_next/static/qOy3stxgMDh9spQk1sgGe/_buildManifest.js" defer=""></script><script src="/_next/static/qOy3stxgMDh9spQk1sgGe/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__oCFQX undefined"><header class="layout_header__SFlEE"><div class="navbar_navwrapper__RkXSe"><div class="navbar_gradbar__Vli6s"></div><nav class="navbar_navbar__vdWdK"><span class="utils_headingLg__RYtYb navbar_navbarlogo__u28NK"><a href="/"><a>GEM BENCHMARK</a></a></span><div class="navbar_menutoggle__4Urrc" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar__f8cyd" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__15TsF navbar_pushright___9_8s"><a href="/resources"><a>Resources</a></a></li><li class="navbar_navitem__15TsF"><a href="/data_cards"><a>Data Cards</a></a></li><li class="navbar_navitem__15TsF"><a href="/model_cards"><a>Model Cards</a></a></li><li class="navbar_navitem__15TsF"><a href="/tutorials"><a>tutorials</a></a></li><li class="navbar_navitem__15TsF"><a href="/results"><a>Results</a></a></li><li class="navbar_navitem__15TsF"><a href="/papers"><a>Papers</a></a></li><li class="navbar_navitem__15TsF"><a href="/workshop"><a>Workshop</a></a></li></ul></nav></div></header><div class="layout_container__FUycR undefined"><main><article><span class="utils_headingXl__zlq1q">GEM Model Cards</span><p class="model_cards_description__3OL_g">The list below links to the work-in-progress data cards for models submitted to GEM. As part of our submission process, we ask participants a series of questions about their models. The current version of our model cards lists the provided answers verbatim. The submission form can be found <a href="https://forms.gle/pds6cbBf2Gf2VGMv7" target="_blank">here</a>. The template used to produce the statements and can be found here: [<a href="/model_card_template.md"><a download="" target="_blank">download template</a></a>].</p><span class="utils_smallSpace__dcJPu"></span><ul class="utils_list__zR_Au"><li class="utils_listItem__6FEiz"><a href="/model_cards/SimpleNER"><a class="model_cards_larger__R2cNM">SimpleNER</a></a><span class="utils_smallSpace__dcJPu"></span><small class="utils_lightText__B_gv3">Shared Task 2021</small><span class="utils_smallSpace__dcJPu"></span><div class="model_cards_model__JYTdb">Finetuned Transformer architecture for simplification.</div></li><li class="utils_listItem__6FEiz"><a href="/model_cards/FB"><a class="model_cards_larger__R2cNM">Self-Training, Acceptability Classifiers and Context-Conditioning</a></a><span class="utils_smallSpace__dcJPu"></span><small class="utils_lightText__B_gv3">Shared Task 2021</small><span class="utils_smallSpace__dcJPu"></span><div class="model_cards_model__JYTdb">BART together with RoBERTa classifiers and context.</div></li><li class="utils_listItem__6FEiz"><a href="/model_cards/POINTER"><a class="model_cards_larger__R2cNM">POINTER</a></a><span class="utils_smallSpace__dcJPu"></span><small class="utils_lightText__B_gv3">Shared Task 2021</small><span class="utils_smallSpace__dcJPu"></span><div class="model_cards_model__JYTdb">POINTER is a hybrid architecture, combining transformers with insertion-based networks.</div></li><li class="utils_listItem__6FEiz"><a href="/model_cards/NUIG-DSI"><a class="model_cards_larger__R2cNM">NUIG-DSI</a></a><span class="utils_smallSpace__dcJPu"></span><small class="utils_lightText__B_gv3">Shared Task 2021</small><span class="utils_smallSpace__dcJPu"></span><div class="model_cards_model__JYTdb">Finetuned T5 with additional pretraining data.</div></li></ul></article></main><div class="layout_push__lpoMK"></div></div><footer class="layout_footer__WlhMu utils_eggshell__3hbbY"><span class="layout_backToHome__D9QFr"><a href="/"><a>‚Üê Home</a></a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__VG89l">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allData":[{"id":"SimpleNER","title":"SimpleNER","type":"Shared Task 2021","background":"Finetuned Transformer architecture for simplification."},{"id":"FB","title":"Self-Training, Acceptability Classifiers and Context-Conditioning","type":"Shared Task 2021","background":"BART together with RoBERTa classifiers and context."},{"id":"POINTER","title":"POINTER","type":"Shared Task 2021","background":"POINTER is a hybrid architecture, combining transformers with insertion-based networks."},{"id":"NUIG-DSI","title":"NUIG-DSI","type":"Shared Task 2021","background":"Finetuned T5 with additional pretraining data."}]},"__N_SSG":true},"page":"/model_cards","query":{},"buildId":"qOy3stxgMDh9spQk1sgGe","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>