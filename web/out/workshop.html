<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Workshop 2022</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/8f219039bec51df6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f219039bec51df6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/9c6cbdf6de0d7f7f.css" as="style"/><link rel="stylesheet" href="/_next/static/css/9c6cbdf6de0d7f7f.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-8a2bbac2bbd375c6.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6dfdacc79861396c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-cde1c1d18a7915f1.js" defer=""></script><script src="/_next/static/chunks/cb1608f2-4ba41bd4c311e4ed.js" defer=""></script><script src="/_next/static/chunks/50-1fbacdd54a295188.js" defer=""></script><script src="/_next/static/chunks/pages/workshop-d87bce0bd48888a0.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_buildManifest.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_ssgManifest.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__qqb_S undefined"><header class="layout_header__kY0Lt"><div class="navbar_navwrapper__PQ35R"><div class="navbar_gradbar__2_FPI"></div><nav class="navbar_navbar__9q1fQ"><span class="utils_headingLg__5535D navbar_navbarlogo__R_s98"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__XS8Qx" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar___PSVO" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__wFPZL navbar_pushright__cG1uq"><a href="/resources">Resources</a></li><li class="navbar_navitem__wFPZL"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__wFPZL"><a href="/results">Results</a></li><li class="navbar_navitem__wFPZL"><a href="/papers">Papers</a></li><li class="navbar_navitem__wFPZL"><a href="/team">Team</a></li><li class="navbar_navitem__wFPZL"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__fbLkO undefined"><main><article><span class="utils_headingXl__u25Y2">GEM Workshop at EMNLP 2022</span><span class="utils_smallSpace__n1Oyc"></span><div><h1 id="user-content-the-gem--workshop-at-emnlp-2022">The GEM 💎 Workshop at EMNLP 2022</h1>
<p>The Second Version of <a href="https://gem-benchmark.com/">Generation, Evaluation &#x26; Metrics (GEM) Workshop 2022</a> workshop will be held as part of <a href="https://2022.emnlp.org/">EMNLP</a>, December 7-11, 2022. It is endorsed by the ACL Special Interest Group on Natural Language Generation (<a href="https://aclweb.org/aclwiki/SIGGEN">SIGGEN</a>).</p>
<h3 id="user-content-overview">Overview</h3>
<p>Natural language generation (NLG) is one of the most active research fields in NLP. Yet, much of the work is focused on English, and too little attention is given to evaluation processes. As many of the recent developments in few-shot and in-context learning have led to the treatment of many tasks as text generation problems, the need for better NLG evaluation processes is becoming more urgent. To that end, the GEM workshop aims to encourage the development of (semi-) automatic model audits and improved human evaluation strategies, and to popularize model evaluations in languages beyond English.</p>
<p>We welcome submissions related, but not limited to, the following topics:</p>
<ul>
<li>💎 Automatic evaluation of NLG systems (<a href="https://aclanthology.org/2021.gem-1.8/">example</a>, <a href="https://aclanthology.org/2021.gem-1.1/">example</a>)</li>
<li>💎 Creating NLG corpora and challenge sets (<a href="https://aclanthology.org/2022.tacl-1.4/">example</a>, <a href="https://openreview.net/forum?id=CSi1eu_2q96">example</a>)</li>
<li>💎 Critiques of benchmarking efforts and responsibly measuring progress in NLG (<a href="https://aclanthology.org/2020.emnlp-main.393/">example</a>, <a href="https://openreview.net/forum?id=j6NxpQbREA1">example</a>)</li>
<li>💎 Effective and/or efficient NLG methods that can be applied to a wide range of languages and tasks (<a href="https://aclanthology.org/2020.tacl-1.47/">example</a>, <a href="https://aclanthology.org/2021.gem-1.16/">example</a>)</li>
<li>💎 Standardizing human evaluation and making it more robust (<a href="https://aclanthology.org/2021.tacl-1.87/">example</a>, <a href="https://aclanthology.org/2022.humeval-1.7/">example</a>)</li>
</ul>
<p>We additionally invite submissions that conduct in-depth analyses of outputs of existing systems, for example through error analyses, by applying new metrics, or by testing the system on new test sets. While we encourage the use of the infrastructure the organizing team is developing as part of the <a href="https://arxiv.org/abs/2206.11249">GEM benchmark</a>, its use is not required.</p>
<p>If you are interested in seeing last year's workshop website from ACL 2021, please check <a href="/workshop/2021">here</a>.</p>
<h3 id="user-content-how-to-submit">How to submit?</h3>
<p>Submissions can take either of the following forms:</p>
<ul>
<li>💎 Archival Papers Papers describing original and unpublished work can be submitted in a between 4 and 8 page format.</li>
<li>💎 Non-Archival Abstracts To discuss work already presented or under review at a peer-reviewed venue, we allow the submission of 2-page abstracts.</li>
</ul>
<p>All submissions are allowed unlimited space for references and appendices and should conform to EMNLP 2022 style guidelines. Archival paper submissions must be anonymized while abstract submissions may include author information.</p>
<p>You can either commit a paper reviewed through ARR at <a href="https://openreview.net/group?id=EMNLP/2022/Workshop/GEM">here</a> or submit directly through SoftConf <a href="https://softconf.com/emnlp2022/gem2022">link</a>. Note that there are separate deadlines for the two options (see below)</p>
<p>We additionally invite presentations by authors of papers in the Findings of the EMNLP (details to be announced at a later date).</p>
<h3 id="user-content-shared-task">Shared Task</h3>
<p>We are organizing a shared task focused on multilingual summarization, including human and automatic evaluation. Participants of the shared task are invited to submit a system description of 4-8 pages.</p>
<p>More information to come soon!</p>
<h3 id="user-content-important-dates">Important Dates</h3>
<p>Paper Submission Dates</p>
<ul>
<li>📅 7 September 2022: Workshop paper submission deadline if using Softconf</li>
<li>📅 2 October 2022:   Latest ARR commitment deadline</li>
<li>📅 9 October 2022:   Workshop paper notification deadline</li>
<li>📅 16 October 2022:  Workshop paper camera ready deadline</li>
</ul>
<p>Workshop Dates</p>
<ul>
<li>📅 7-8 December 2022: Workshops</li>
</ul>
<h3 id="user-content-organization">Organization</h3>
<ul>
<li>Antoine Bosselut (EPFL)</li>
<li>Khyathi Chandu (Carnegie Mellon University)</li>
<li>Kaustubh Dhole (Emory University)</li>
<li>Varun Gangal (Carnegie Mellon University)</li>
<li>Sebastian Gehrmann (Google Research)</li>
<li>Yacine Jernite (Hugging Face)</li>
<li>Jekaterina Novikova (NoOverfitting Lab)</li>
<li>Laura Perez-Beltrachini (University of Edinburgh)</li>
</ul>
<p>Steering Committee</p>
<ul>
<li>Wei Xu (Georgia Tech)</li>
<li>Esin Durmus (Stanford University)</li>
<li>Samira Shaikh (UNC Charlotte)</li>
</ul>
</div></article></main><div class="layout_push__2FFZa"></div></div><footer class="layout_footer__dka_2 utils_eggshell__LF2UE"><span class="layout_backToHome__9sjx_"><a href="/">← Home</a></span><span>If you have any questions, please join our <!-- --><a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__FmNQy">google group</a> for support.<!-- --></span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"workshopData":{"contentHtml":"\u003ch1 id=\"user-content-the-gem--workshop-at-emnlp-2022\"\u003eThe GEM 💎 Workshop at EMNLP 2022\u003c/h1\u003e\n\u003cp\u003eThe Second Version of \u003ca href=\"https://gem-benchmark.com/\"\u003eGeneration, Evaluation \u0026#x26; Metrics (GEM) Workshop 2022\u003c/a\u003e workshop will be held as part of \u003ca href=\"https://2022.emnlp.org/\"\u003eEMNLP\u003c/a\u003e, December 7-11, 2022. It is endorsed by the ACL Special Interest Group on Natural Language Generation (\u003ca href=\"https://aclweb.org/aclwiki/SIGGEN\"\u003eSIGGEN\u003c/a\u003e).\u003c/p\u003e\n\u003ch3 id=\"user-content-overview\"\u003eOverview\u003c/h3\u003e\n\u003cp\u003eNatural language generation (NLG) is one of the most active research fields in NLP. Yet, much of the work is focused on English, and too little attention is given to evaluation processes. As many of the recent developments in few-shot and in-context learning have led to the treatment of many tasks as text generation problems, the need for better NLG evaluation processes is becoming more urgent. To that end, the GEM workshop aims to encourage the development of (semi-) automatic model audits and improved human evaluation strategies, and to popularize model evaluations in languages beyond English.\u003c/p\u003e\n\u003cp\u003eWe welcome submissions related, but not limited to, the following topics:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e💎 Automatic evaluation of NLG systems (\u003ca href=\"https://aclanthology.org/2021.gem-1.8/\"\u003eexample\u003c/a\u003e, \u003ca href=\"https://aclanthology.org/2021.gem-1.1/\"\u003eexample\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e💎 Creating NLG corpora and challenge sets (\u003ca href=\"https://aclanthology.org/2022.tacl-1.4/\"\u003eexample\u003c/a\u003e, \u003ca href=\"https://openreview.net/forum?id=CSi1eu_2q96\"\u003eexample\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e💎 Critiques of benchmarking efforts and responsibly measuring progress in NLG (\u003ca href=\"https://aclanthology.org/2020.emnlp-main.393/\"\u003eexample\u003c/a\u003e, \u003ca href=\"https://openreview.net/forum?id=j6NxpQbREA1\"\u003eexample\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e💎 Effective and/or efficient NLG methods that can be applied to a wide range of languages and tasks (\u003ca href=\"https://aclanthology.org/2020.tacl-1.47/\"\u003eexample\u003c/a\u003e, \u003ca href=\"https://aclanthology.org/2021.gem-1.16/\"\u003eexample\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e💎 Standardizing human evaluation and making it more robust (\u003ca href=\"https://aclanthology.org/2021.tacl-1.87/\"\u003eexample\u003c/a\u003e, \u003ca href=\"https://aclanthology.org/2022.humeval-1.7/\"\u003eexample\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe additionally invite submissions that conduct in-depth analyses of outputs of existing systems, for example through error analyses, by applying new metrics, or by testing the system on new test sets. While we encourage the use of the infrastructure the organizing team is developing as part of the \u003ca href=\"https://arxiv.org/abs/2206.11249\"\u003eGEM benchmark\u003c/a\u003e, its use is not required.\u003c/p\u003e\n\u003cp\u003eIf you are interested in seeing last year's workshop website from ACL 2021, please check \u003ca href=\"/workshop/2021\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"user-content-how-to-submit\"\u003eHow to submit?\u003c/h3\u003e\n\u003cp\u003eSubmissions can take either of the following forms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e💎 Archival Papers Papers describing original and unpublished work can be submitted in a between 4 and 8 page format.\u003c/li\u003e\n\u003cli\u003e💎 Non-Archival Abstracts To discuss work already presented or under review at a peer-reviewed venue, we allow the submission of 2-page abstracts.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll submissions are allowed unlimited space for references and appendices and should conform to EMNLP 2022 style guidelines. Archival paper submissions must be anonymized while abstract submissions may include author information.\u003c/p\u003e\n\u003cp\u003eYou can either commit a paper reviewed through ARR at \u003ca href=\"https://openreview.net/group?id=EMNLP/2022/Workshop/GEM\"\u003ehere\u003c/a\u003e or submit directly through SoftConf \u003ca href=\"https://softconf.com/emnlp2022/gem2022\"\u003elink\u003c/a\u003e. Note that there are separate deadlines for the two options (see below)\u003c/p\u003e\n\u003cp\u003eWe additionally invite presentations by authors of papers in the Findings of the EMNLP (details to be announced at a later date).\u003c/p\u003e\n\u003ch3 id=\"user-content-shared-task\"\u003eShared Task\u003c/h3\u003e\n\u003cp\u003eWe are organizing a shared task focused on multilingual summarization, including human and automatic evaluation. Participants of the shared task are invited to submit a system description of 4-8 pages.\u003c/p\u003e\n\u003cp\u003eMore information to come soon!\u003c/p\u003e\n\u003ch3 id=\"user-content-important-dates\"\u003eImportant Dates\u003c/h3\u003e\n\u003cp\u003ePaper Submission Dates\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e📅 7 September 2022: Workshop paper submission deadline if using Softconf\u003c/li\u003e\n\u003cli\u003e📅 2 October 2022:   Latest ARR commitment deadline\u003c/li\u003e\n\u003cli\u003e📅 9 October 2022:   Workshop paper notification deadline\u003c/li\u003e\n\u003cli\u003e📅 16 October 2022:  Workshop paper camera ready deadline\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWorkshop Dates\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e📅 7-8 December 2022: Workshops\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"user-content-organization\"\u003eOrganization\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAntoine Bosselut (EPFL)\u003c/li\u003e\n\u003cli\u003eKhyathi Chandu (Carnegie Mellon University)\u003c/li\u003e\n\u003cli\u003eKaustubh Dhole (Emory University)\u003c/li\u003e\n\u003cli\u003eVarun Gangal (Carnegie Mellon University)\u003c/li\u003e\n\u003cli\u003eSebastian Gehrmann (Google Research)\u003c/li\u003e\n\u003cli\u003eYacine Jernite (Hugging Face)\u003c/li\u003e\n\u003cli\u003eJekaterina Novikova (NoOverfitting Lab)\u003c/li\u003e\n\u003cli\u003eLaura Perez-Beltrachini (University of Edinburgh)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSteering Committee\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWei Xu (Georgia Tech)\u003c/li\u003e\n\u003cli\u003eEsin Durmus (Stanford University)\u003c/li\u003e\n\u003cli\u003eSamira Shaikh (UNC Charlotte)\u003c/li\u003e\n\u003c/ul\u003e\n"}},"__N_SSG":true},"page":"/workshop","query":{},"buildId":"yxHKZ8AjNlaFByMXSfhF5","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>