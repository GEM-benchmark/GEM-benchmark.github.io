<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Model Cards</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/8f219039bec51df6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f219039bec51df6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/316fcd1ae0a38176.css" as="style"/><link rel="stylesheet" href="/_next/static/css/316fcd1ae0a38176.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-a7ce780f37f41655.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-9d34f203832e9748.js" defer=""></script><script src="/_next/static/chunks/pages/_app-dcd786a11fa40981.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-215a96335ed97100.js" defer=""></script><script src="/_next/static/chunks/pages/model_cards-5c106aaef6b03a2e.js" defer=""></script><script src="/_next/static/rK2mEqfP-3BAQXdXHxDw8/_buildManifest.js" defer=""></script><script src="/_next/static/rK2mEqfP-3BAQXdXHxDw8/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__qqb_S undefined"><header class="layout_header__kY0Lt"><div class="navbar_navwrapper__PQ35R"><div class="navbar_gradbar__2_FPI"></div><nav class="navbar_navbar__9q1fQ"><span class="utils_headingLg__5535D navbar_navbarlogo__R_s98"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__XS8Qx" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar___PSVO" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__wFPZL navbar_pushright__cG1uq"><a href="/resources">Resources</a></li><li class="navbar_navitem__wFPZL"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__wFPZL"><a href="/results">Results</a></li><li class="navbar_navitem__wFPZL"><a href="/papers">Papers</a></li><li class="navbar_navitem__wFPZL"><a href="/team">Team</a></li><li class="navbar_navitem__wFPZL"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__fbLkO undefined"><main><article><span class="utils_headingXl__u25Y2">GEM Model Cards</span><p class="model_cards_description__o5se_">The list below links to the work-in-progress data cards for models submitted to GEM. As part of our submission process, we ask participants a series of questions about their models. The current version of our model cards lists the provided answers verbatim. The submission form can be found <a href="https://forms.gle/pds6cbBf2Gf2VGMv7" target="_blank">here</a>. The template used to produce the statements and can be found here: [<a download="" target="_blank" href="/model_card_template.md">download template</a>].</p><span class="utils_smallSpace__n1Oyc"></span><ul class="utils_list__4Mu4l"><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/SimpleNER">SimpleNER</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">Finetuned Transformer architecture for simplification.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/FB">Self-Training, Acceptability Classifiers and Context-Conditioning</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">BART together with RoBERTa classifiers and context.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/POINTER">POINTER</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">POINTER is a hybrid architecture, combining transformers with insertion-based networks.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/NUIG-DSI">NUIG-DSI</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">Finetuned T5 with additional pretraining data.</div></li></ul></article></main><div class="layout_push__2FFZa"></div></div><footer class="layout_footer__dka_2 utils_eggshell__LF2UE"><span class="layout_backToHome__9sjx_"><a href="/">‚Üê Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__FmNQy">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allData":[{"id":"SimpleNER","title":"SimpleNER","type":"Shared Task 2021","background":"Finetuned Transformer architecture for simplification."},{"id":"FB","title":"Self-Training, Acceptability Classifiers and Context-Conditioning","type":"Shared Task 2021","background":"BART together with RoBERTa classifiers and context."},{"id":"POINTER","title":"POINTER","type":"Shared Task 2021","background":"POINTER is a hybrid architecture, combining transformers with insertion-based networks."},{"id":"NUIG-DSI","title":"NUIG-DSI","type":"Shared Task 2021","background":"Finetuned T5 with additional pretraining data."}]},"__N_SSG":true},"page":"/model_cards","query":{},"buildId":"rK2mEqfP-3BAQXdXHxDw8","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>