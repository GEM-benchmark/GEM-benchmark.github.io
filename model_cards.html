<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Model Cards</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/8f219039bec51df6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f219039bec51df6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/316fcd1ae0a38176.css" as="style"/><link rel="stylesheet" href="/_next/static/css/316fcd1ae0a38176.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-8a2bbac2bbd375c6.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6dfdacc79861396c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-cde1c1d18a7915f1.js" defer=""></script><script src="/_next/static/chunks/cb1608f2-4ba41bd4c311e4ed.js" defer=""></script><script src="/_next/static/chunks/50-1fbacdd54a295188.js" defer=""></script><script src="/_next/static/chunks/pages/model_cards-262f56b90c08654a.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_buildManifest.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_ssgManifest.js" defer=""></script><script src="/_next/static/yxHKZ8AjNlaFByMXSfhF5/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__qqb_S undefined"><header class="layout_header__kY0Lt"><div class="navbar_navwrapper__PQ35R"><div class="navbar_gradbar__2_FPI"></div><nav class="navbar_navbar__9q1fQ"><span class="utils_headingLg__5535D navbar_navbarlogo__R_s98"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__XS8Qx" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar___PSVO" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__wFPZL navbar_pushright__cG1uq"><a href="/resources">Resources</a></li><li class="navbar_navitem__wFPZL"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__wFPZL"><a href="/results">Results</a></li><li class="navbar_navitem__wFPZL"><a href="/papers">Papers</a></li><li class="navbar_navitem__wFPZL"><a href="/team">Team</a></li><li class="navbar_navitem__wFPZL"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__fbLkO undefined"><main><article><span class="utils_headingXl__u25Y2">GEM Model Cards</span><p class="model_cards_description__o5se_">The list below links to the work-in-progress data cards for models submitted to GEM. As part of our submission process, we ask participants a series of questions about their models. The current version of our model cards lists the provided answers verbatim. The submission form can be found <!-- --><a href="https://forms.gle/pds6cbBf2Gf2VGMv7" target="_blank">here</a>. The template used to produce the statements and can be found here: [<!-- --><a download="" target="_blank" href="/model_card_template.md">download template</a>].<!-- --></p><span class="utils_smallSpace__n1Oyc"></span><ul class="utils_list__4Mu4l"><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/SimpleNER">SimpleNER</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">Finetuned Transformer architecture for simplification.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/FB">Self-Training, Acceptability Classifiers and Context-Conditioning</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">BART together with RoBERTa classifiers and context.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/POINTER">POINTER</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">POINTER is a hybrid architecture, combining transformers with insertion-based networks.</div></li><li class="utils_listItem__s2m6i"><a class="model_cards_larger__imoUA" href="/model_cards/NUIG-DSI">NUIG-DSI</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Shared Task 2021</small><span class="utils_smallSpace__n1Oyc"></span><div class="model_cards_model__Abt93">Finetuned T5 with additional pretraining data.</div></li></ul></article></main><div class="layout_push__2FFZa"></div></div><footer class="layout_footer__dka_2 utils_eggshell__LF2UE"><span class="layout_backToHome__9sjx_"><a href="/">‚Üê Home</a></span><span>If you have any questions, please join our <!-- --><a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__FmNQy">google group</a> for support.<!-- --></span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allData":[{"id":"SimpleNER","title":"SimpleNER","type":"Shared Task 2021","background":"Finetuned Transformer architecture for simplification."},{"id":"FB","title":"Self-Training, Acceptability Classifiers and Context-Conditioning","type":"Shared Task 2021","background":"BART together with RoBERTa classifiers and context."},{"id":"POINTER","title":"POINTER","type":"Shared Task 2021","background":"POINTER is a hybrid architecture, combining transformers with insertion-based networks."},{"id":"NUIG-DSI","title":"NUIG-DSI","type":"Shared Task 2021","background":"Finetuned T5 with additional pretraining data."}]},"__N_SSG":true},"page":"/model_cards","query":{},"buildId":"yxHKZ8AjNlaFByMXSfhF5","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>