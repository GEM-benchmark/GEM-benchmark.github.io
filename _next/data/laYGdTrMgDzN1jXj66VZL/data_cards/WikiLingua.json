{"pageProps":{"taskData":{"id":"WikiLingua","contentHtml":"<h2 id=\"user-content-table-of-contents\">Table of Contents</h2>\n<ul>\n<li><a href=\"#dataset-description\">Dataset Description</a>\n<ul>\n<li><a href=\"#dataset-and-task-summary\">Dataset and Task Summary</a></li>\n<li><a href=\"#why-is-this-dataset-part-of-gem\">Why is this dataset part of GEM?</a></li>\n<li><a href=\"#languages\">Languages</a></li>\n</ul>\n</li>\n<li><a href=\"#meta-information\">Meta Information</a>\n<ul>\n<li><a href=\"#dataset-curators\">Dataset Curators</a></li>\n<li><a href=\"#licensing-information\">Licensing Information</a></li>\n<li><a href=\"#citation-information\">Citation Information</a></li>\n<li><a href=\"#leaderboard\">Leaderboard</a></li>\n</ul>\n</li>\n<li><a href=\"#dataset-structure\">Dataset Structure</a>\n<ul>\n<li><a href=\"#data-instances\">Data Instances</a></li>\n<li><a href=\"#data-fields\">Data Fields</a></li>\n<li><a href=\"#data-statistics\">Data Statistics</a></li>\n</ul>\n</li>\n<li><a href=\"#dataset-creation\">Dataset Creation</a>\n<ul>\n<li><a href=\"#curation-rationale\">Curation Rationale</a></li>\n<li><a href=\"#communicative-goal\">Communicative Goal</a></li>\n<li><a href=\"#source-data\">Source Data</a>\n<ul>\n<li><a href=\"#initial-data-collection-and-normalization\">Initial Data Collection and Normalization</a></li>\n<li><a href=\"#who-are-the-source-language-producers\">Who are the source language producers?</a></li>\n</ul>\n</li>\n<li><a href=\"#annotations\">Annotations</a>\n<ul>\n<li><a href=\"#annotation-process\">Annotation process</a></li>\n<li><a href=\"#who-are-the-annotators\">Who are the annotators?</a></li>\n</ul>\n</li>\n<li><a href=\"#personal-and-sensitive-information\">Personal and Sensitive Information</a></li>\n</ul>\n</li>\n<li><a href=\"#changes-to-the-original-dataset-for-gem\">Changes to the Original Dataset for GEM</a></li>\n<li><a href=\"#considerations-for-using-the-data\">Considerations for Using the Data</a>\n<ul>\n<li><a href=\"#social-impact-of-the-dataset\">Social Impact of the Dataset</a></li>\n<li><a href=\"#impact-on-underserved-communities\">Impact on Underserved Communities</a></li>\n<li><a href=\"#discussion-of-biases\">Discussion of Biases</a></li>\n<li><a href=\"#other-known-limitations\">Other Known Limitations</a></li>\n</ul>\n</li>\n<li><a href=\"#getting-started-with-in-depth-research-on-the-task\">Getting started with in-depth research on the task</a></li>\n</ul>\n<h2 id=\"user-content-dataset-description\">Dataset Description</h2>\n<ul>\n<li><strong>Homepage:</strong> None (See <strong>Repository</strong>)</li>\n<li><strong>Repository:</strong> <a href=\"https://github.com/esdurmus/Wikilingua\">Wikilingua Repository</a></li>\n<li><strong>Paper:</strong> <a href=\"https://www.aclweb.org/anthology/2020.findings-emnlp.360/\">WikiLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization</a></li>\n<li><strong>Point of Contact:</strong> {faisal,kathy}@cs.columbia.edu, {ed459}@cornell.edu, {cardie}@cs.cornell.edu</li>\n</ul>\n<h3 id=\"user-content-dataset-and-task-summary\">Dataset and Task Summary</h3>\n<p>Wikilingua is a large-scale (~770k article-summary pairs), multilingual dataset for the evaluation of cross-lingual abstractive systems. It consists of parallel articles and summaries (article-summary pairs) from WikiHow across 18 languages (i.e. all the languages available on WikiHow). It contains 141,457 unique English articles and each of the other 17 languages has on average, 42,783 articles that align with an article in English.</p>\n<h3 id=\"user-content-why-is-this-dataset-part-of-gem\">Why is this dataset part of GEM?</h3>\n<p>This dataset is part of the GEM benchmark for the task of summarization, alongside <a href=\"https://huggingface.co/datasets/mlsum\">MLSum</a> and <a href=\"https://huggingface.co/datasets/xsum\">Xsum</a>, and acts as a large-scale, high-quality resource for cross-lingual summarization.</p>\n<h3 id=\"user-content-languages\">Languages</h3>\n<p>Wikilingua contains artcile-summary pairs across 18 languages. The statistics are presented below. Num. parallel corresponds to the number of articles with a parallel article in English.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Language</th>\n<th align=\"center\">ISO 639-1</th>\n<th align=\"right\">Num Parallel</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">English</td>\n<td align=\"center\">en</td>\n<td align=\"right\">141,457</td>\n</tr>\n<tr>\n<td align=\"left\">Spanish</td>\n<td align=\"center\">es</td>\n<td align=\"right\">113,215</td>\n</tr>\n<tr>\n<td align=\"left\">Portuguese</td>\n<td align=\"center\">pt</td>\n<td align=\"right\">81,695</td>\n</tr>\n<tr>\n<td align=\"left\">French</td>\n<td align=\"center\">fr</td>\n<td align=\"right\">63,692</td>\n</tr>\n<tr>\n<td align=\"left\">German</td>\n<td align=\"center\">de</td>\n<td align=\"right\">58,375</td>\n</tr>\n<tr>\n<td align=\"left\">Russian</td>\n<td align=\"center\">ru</td>\n<td align=\"right\">52,928</td>\n</tr>\n<tr>\n<td align=\"left\">Italian</td>\n<td align=\"center\">it</td>\n<td align=\"right\">50,968</td>\n</tr>\n<tr>\n<td align=\"left\">Indonesian</td>\n<td align=\"center\">id</td>\n<td align=\"right\">47,511</td>\n</tr>\n<tr>\n<td align=\"left\">Dutch</td>\n<td align=\"center\">nl</td>\n<td align=\"right\">31,270</td>\n</tr>\n<tr>\n<td align=\"left\">Arabic</td>\n<td align=\"center\">ar</td>\n<td align=\"right\">29,229</td>\n</tr>\n<tr>\n<td align=\"left\">Chinese</td>\n<td align=\"center\">zh</td>\n<td align=\"right\">18,887</td>\n</tr>\n<tr>\n<td align=\"left\">Vietnamese</td>\n<td align=\"center\">vi</td>\n<td align=\"right\">19,600</td>\n</tr>\n<tr>\n<td align=\"left\">Thai</td>\n<td align=\"center\">th</td>\n<td align=\"right\">14,770</td>\n</tr>\n<tr>\n<td align=\"left\">Japanese</td>\n<td align=\"center\">ja</td>\n<td align=\"right\">12,669</td>\n</tr>\n<tr>\n<td align=\"left\">Korean</td>\n<td align=\"center\">ko</td>\n<td align=\"right\">12,189</td>\n</tr>\n<tr>\n<td align=\"left\">Hindi</td>\n<td align=\"center\">hi</td>\n<td align=\"right\">9,929</td>\n</tr>\n<tr>\n<td align=\"left\">Czech</td>\n<td align=\"center\">cs</td>\n<td align=\"right\">7,200</td>\n</tr>\n<tr>\n<td align=\"left\">Turkish</td>\n<td align=\"center\">tr</td>\n<td align=\"right\">4,503</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"user-content-meta-information\">Meta Information</h2>\n<h3 id=\"user-content-dataset-curators\">Dataset Curators</h3>\n<p>This dataset was curated by a team of researchers from Columbia and Cornell Universities.</p>\n<h3 id=\"user-content-licensing-information\">Licensing Information</h3>\n<ul>\n<li>\n<p>Article provided by wikiHow <a href=\"https://www.wikihow.com/Main-Page\">https://www.wikihow.com/Main-Page</a>, a wiki building the world's largest, highest quality how-to manual. Please edit this article and find author credits at wikiHow.com. Content on wikiHow can be shared under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/\">Creative Commons license</a>.</p>\n</li>\n<li>\n<p>Refer to <a href=\"https://www.wikihow.com/wikiHow:Attribution\">this webpage</a> for the specific attribution guidelines.</p>\n</li>\n</ul>\n<h3 id=\"user-content-citation-information\">Citation Information</h3>\n<p>Please cite the following paper:</p>\n<pre><code>@inproceedings{ladhak-wiki-2020,\n    title={WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\n    author={Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\n    booktitle={Findings of EMNLP, 2020},\n    year={2020}\n}\n</code></pre>\n<h3 id=\"user-content-leaderboard\">Leaderboard</h3>\n<p>This dataset has no corresponding public leaderboard.</p>\n<h2 id=\"user-content-dataset-structure\">Dataset Structure</h2>\n<h3 id=\"user-content-data-instances\">Data Instances</h3>\n<p>Each language is provided a dictionary, where the key is the url of the corresponding WikiHow article and the value itself is a dictionary. This inner dictionary has section names as the keys and dictionary (with keys <code>document</code> and <code>summary</code>) as values. For languages other than English, the inner-most dictionary has additional keys <code>english_section_name</code> and <code>english_url</code> which are the corresponding section name and the url for the corresponding parallel English article.</p>\n<pre><code>( 'https://www.wikihow.com/Avoid-Drinking-and-Driving',\n\n   { 'Designating a Driver': \n   \n         {\n             'document': \"Designating a driver is a very popular tactic to avoid drinking and driving.  It is important to plan in advance, because your brain function will slow down and your decision making skills will be impaired once you start drinking. Decide before you begin drinking that you will not drive.  Figure out who will be getting you home before you leave. Make sure this person is responsible and keep them in your sight while you are drinking.  Have their contact information handy in case you can’t find them when you are ready to leave.  Choose a friend who doesn’t drink alcohol.  You likely have someone in your friend group who doesn’t drink.  This person is the most likely to remain sober. Decide on one person who will remain sober.  You can take turns within your friend group, alternating who will be the designated driver on each occasion.  Be sure that the designated driver actually remains sober.  The person who has drank the least is still not sober. If you don’t have your car with you, you can guarantee that you won’t make the choice to drive it home. If you are drinking at your home.  Give your keys to a responsible friend to ensure that you don't choose to drive somewhere after you have been drinking. It may be tempting to stay longer or leave with someone else.  Stick to the plan you made in advance and only leave with your sober, designated driver.  Keep the phone number of your driver handy in case you can't find them when you are ready to leave. If your designated driver drinks alcohol, find alternate transportation to get home.\",\n   \n             'summary': 'Plan in advance. Assign a designated driver. Leave your car at home. Leave the venue with your designated driver.'\n         }\n   }\n)\n</code></pre>\n<p>The inner dictionary is named <code>article</code> in the <a href=\"https://huggingface.co/datasets/wiki_lingua\">Huggingface API</a>.</p>\n<h3 id=\"user-content-data-fields\">Data Fields</h3>\n<p>The article-summary pairs are organized in <code>document</code> and <code>summary</code> fields in the data structure provided above.</p>\n<h3 id=\"user-content-data-statistics\">Data Statistics</h3>\n<p>Please refer to the Languages section for details on the number of article-summary pairs per language. Below table provides the number of examples in <code>Train/Validation/Test</code> splits per language.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"center\">Train</th>\n<th align=\"center\">Validation</th>\n<th align=\"right\">Test</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Spanish</td>\n<td align=\"center\">81,514</td>\n<td align=\"center\">9,057</td>\n<td align=\"right\">22,643</td>\n</tr>\n<tr>\n<td align=\"left\">Russian</td>\n<td align=\"center\">38,107</td>\n<td align=\"center\">4,234</td>\n<td align=\"right\">10,586</td>\n</tr>\n<tr>\n<td align=\"left\">Vietnamese</td>\n<td align=\"center\">9,473</td>\n<td align=\"center\">9,473</td>\n<td align=\"right\">2,632</td>\n</tr>\n<tr>\n<td align=\"left\">Turkish</td>\n<td align=\"center\">3,241</td>\n<td align=\"center\">360</td>\n<td align=\"right\">901</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"user-content-dataset-creation\">Dataset Creation</h2>\n<p>The authors extracted gold-standard article-summary alignments across languages by aligning the images that are used to describe each how-to step in a WikiHow article.</p>\n<h3 id=\"user-content-curation-rationale\">Curation Rationale</h3>\n<p>The dataset was created in order to enable new approaches for cross-lingual and multilingual summarization, which are currently understudied as well as open up inetersting new directions for research in summarization. E.g., exploration of multi-source cross-lingual architectures, i.e. models that can summarize from multiple source languages into a target language, building models that can summarize articles from any language to any other language for a given set of languages.</p>\n<h3 id=\"user-content-communicative-goal\">Communicative Goal</h3>\n<p>The speaker is required to produce high quality summaries of articles.</p>\n<h3 id=\"user-content-source-data\">Source Data</h3>\n<p>WikiHow, which is an online resource of how-to guides (written and reviewed by human authors) is used as the data source. The articles cover 19 broad categories including health, arts and entertainment, personal care and style, travel, education and communications, etc. The categories cover a broad set of genres and topics.</p>\n<h4 id=\"user-content-initial-data-collection-and-normalization\">Initial Data Collection and Normalization</h4>\n<p>Each WikiHow page includes multiple methods for completing a multi-step procedural task. Each step consists of a unique illustrative image, a one sentence summary and a paragraph providing more details. The authors combine the paragraphs and summaries from all the steps of each method to create article-summary pairs.</p>\n<h4 id=\"user-content-who-are-the-source-language-producers\">Who are the source language producers?</h4>\n<p>The authors did not have access to the demograhics of the writers and editors of the articles.</p>\n<h3 id=\"user-content-annotations\">Annotations</h3>\n<p>Any additional annotations are not collected for this dataset.</p>\n<h4 id=\"user-content-annotation-process\">Annotation process</h4>\n<h4 id=\"user-content-who-are-the-annotators\">Who are the annotators?</h4>\n<h3 id=\"user-content-personal-and-sensitive-information\">Personal and Sensitive Information</h3>\n<p>[N/A]</p>\n<h2 id=\"user-content-changes-to-the-original-dataset-for-gem\">Changes to the Original Dataset for GEM</h2>\n<p>None</p>\n<h2 id=\"user-content-considerations-for-using-the-data\">Considerations for Using the Data</h2>\n<h3 id=\"user-content-social-impact-of-the-dataset\">Social Impact of the Dataset</h3>\n<h3 id=\"user-content-impact-on-underserved-communities\">Impact on Underserved Communities</h3>\n<h3 id=\"user-content-discussion-of-biases\">Discussion of Biases</h3>\n<h3 id=\"user-content-other-known-limitations\">Other Known Limitations</h3>\n<h2 id=\"user-content-getting-started-with-in-depth-research-on-the-task\">Getting started with in-depth research on the task</h2>\n<p>Download the dataset using <a href=\"https://drive.google.com/drive/folders/1PFvXUOsW_KSEzFm5ixB8J8BDB8zRRfHW?usp=sharing\">this link</a> or the <a href=\"https://huggingface.co/datasets/wiki_lingua\">Huggingface API</a>. Please refer to this <a href=\"https://colab.research.google.com/drive/1HxonmcM7EOQVal2I6oTi9QWEP257BgDP?usp=sharing\">Collab notebook</a> to see how to align articles in other languages with the parallel English articles.</p>\n<p>The authors also propose a method for direct cross-lingual summarization by leveraging synthetic data and Neural Machine Translation as a pre-training step. Table 4 and Table 6 in the dataset paper present the results for this method for automated (ROUGE) and human evaluation (Fluency, Content) metrics.</p>\n","title":"WikiLingua","type":"Summarization","motivation":"Large-scale multilingual dataset for evaluating cross-lingual abstractive summarization"}},"__N_SSG":true}